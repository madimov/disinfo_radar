Todays	O
large	B
language	I
models	I
have	O
greatly	O
improved	O
their	O
task-agnostic	O
,	O
few-shot	O
performance	O
,	O
with	O
top	O
models	B
like	O
GPT	B
-	I
3	I
competitive	O
with	O
state-of-the-art	O
finetuning	O
approaches	O
when	O
provided	O
only	O
a	O
few	O
examples	O
in	O
a	O
natural	B
language	I
prompt	I
.	O

This	O
few-shot	O
,	O
in-context	O
learning	O
approach	O
is	O
gaining	O
traction	O
in	O
large	O
part	O
due	O
to	O
its	O
ability	O
to	O
learn	O
without	O
parameter	O
updates	O
.	O

Compared	O
to	O
traditional	O
finetuning	O
methods	O
,	O
few-shot	B
learning	I
enables	O
practitioners	O
to	O
more	O
quickly	O
prototype	O
NLP	B
models	I
,	O
allows	O
non-technical	O
users	O
to	O
create	O
NLP	B
systems	I
,	O
and	O
efficiently	O
reuses	O
models	B
to	O
reduce	O
system	O
memory	O
and	O
complexity	O
.	O

GPT	B
-	I
3s	I
accuracy	O
however	O
can	O
be	O
highly	O
unstable	O
across	O
different	O
prompts	O
(	O
training	O
examples	O
,	O
permutation	O
,	O
format	O
)	O
.	O

To	O
address	O
this	O
,	O
a	O
new	O
UC	O
Berkeley	O
,	O
University	O
of	O
Maryland	O
and	O
UC	O
Irvine	O
study	O
sets	O
out	O
to	O
identify	O
the	O
pitfalls	O
that	O
can	O
cause	O
instability	O
in	O
the	O
GPT	B
-	I
3	I
language	I
model	I
and	O
proposes	O
a	O
contextual	B
calibration	I
procedure	I
that	O
consistently	O
improves	O
GPT	B
-	I
3	I
(	O
and	O
GPT	B
-	I
2	I
)	O
accuracy	O
across	O
different	O
prompt	O
format	O
choices	O
and	O
examples	O
.	O

Typically	O
,	O
a	O
natural	B
language	I
prompt	I
is	O
fed	O
to	O
neural	B
autoregressive	I
language	I
models	I
to	O
ensure	O
they	O
perform	O
few-shot	B
learning	I
using	O
in-context	B
learning	I
.	O

The	O
prompt	O
consists	O
of	O
three	O
components	O
:	O
a	O
format	O
,	O
a	O
set	O
of	O
training	O
examples	O
,	O
and	O
a	O
permutation	O
of	O
the	O
training	O
examples	O
.	O

The	O
researchers	O
first	O
studied	O
how	O
GPT	B
-	I
3s	I
accuracy	O
changes	O
across	O
different	O
prompts	O
.	O

They	O
conducted	O
sentiment	B
analysis	I
task	O
experiments	O
on	O
three	O
GPT	B
-	I
3	I
model	O
sizes	O
(	O
2.7B	O
,	O
13B	O
,	O
and	O
175B	O
parameters	O
)	O
trained	O
on	O
SST	O
-	O
2	O
datasets	O
,	O
and	O
observed	O
high	O
variance	O
in	O
GPT	B
-	I
3s	I
accuracy	O
across	O
the	O
prompts	O
training	O
examples	O
,	O
permutation	O
of	O
examples	O
,	O
as	O
well	O
as	O
format	O
.	O

Surprising	O
,	O
varying	O
the	O
permutation	O
of	O
the	O
training	O
examples	O
could	O
cause	O
accuracy	O
to	O
range	O
from	O
54.3	O
percent	O
to	O
near	O
state-of-the-art	O
(	O
93.4	O
percent	O
)	O
.	O

Accuracy	O
across	O
training	O
sets	O
,	O
permutations	O
and	O
formats	O
The	O
researchers	O
next	O
analyzed	O
factors	O
that	O
contribute	O
to	O
GPT	B
-	I
3	I
instability	O
,	O
identifying	O
three	O
biases	O
behind	O
the	O
accuracy	O
variance	O
:	O
Majority	O
Label	O
Bias	O
GPT	B
-	I
3	I
is	O
biased	O
towards	O
answers	O
that	O
are	O
frequent	O
in	O
the	O
prompt	O
.	O

The	O
majority	O
label	O
bias	O
helps	O
explain	O
why	O
different	O
choices	O
for	O
the	O
training	O
examples	O
heavily	O
influence	O
GPT	B
-	I
3s	I
accuracy	O
as	O
this	O
shifts	O
the	O
distribution	O
of	O
model	O
predictions	O
.	O

Recency	O
Bias	O
The	O
models	B
majority	O
label	O
bias	O
is	O
aggravated	O
by	O
its	O
recency	O
bias	O
:	O
the	O
tendency	O
to	O
repeat	O
answers	O
that	O
appear	O
towards	O
the	O
end	O
of	O
the	O
prompt	O
.	O

Overall	O
,	O
recency	O
bias	O
helps	O
to	O
explain	O
why	O
the	O
permutation	O
of	O
the	O
training	O
examples	O
is	O
important	O
.	O

Common	O
Token	O
Bias	O
GPT	O
-	O
3	O
is	O
biased	O
towards	O
outputting	O
tokens	O
that	O
are	O
common	O
in	O
its	O
pretraining	O
distribution	O
.	O

The	O
common	O
token	O
bias	O
helps	O
explain	O
why	O
the	O
choice	O
of	O
label	O
names	O
is	O
important	O
,	O
and	O
why	O
the	O
model	B
struggles	O
with	O
rare	O
answers	O
.	O

The	O
team	O
says	O
these	O
three	O
biases	O
together	O
tend	O
to	O
contribute	O
to	O
a	O
simple	O
shift	O
in	O
a	O
models	O
output	O
distribution	O
.	O

Inspired	O
by	O
the	O
idea	O
that	O
model	B
biases	O
towards	O
certain	O
answers	O
can	O
be	O
estimated	O
by	O
feeding	O
content-free	O
inputs	O
,	O
the	O
researchers	O
proposed	O
a	O
novel	O
data-free	O
contextual	B
calibration	I
procedure	I
to	O
infer	O
parameters	O
.	O

To	O
evaluate	O
the	O
contextual	B
calibrations	I
effectiveness	O
,	O
they	O
conducted	O
experiments	O
on	O
text	B
classification	I
,	O
fact	B
retrieval	I
and	O
information	B
extraction	I
tasks	O
across	O
different	O
datasets	O
(	O
AGNews	O
,	O
MIT	O
Director	O
,	O
DBPedia	O
,	O
TREC	O
etc	O
.	O
)	O
.	O

Mean	O
accuracy	O
comparison	O
across	O
different	O
training	O
example	O
choices	O
for	O
different	O
datasets	O
and	O
model	B
sizes	O
.	O

The	O
steep	O
red	O
lines	O
on	O
all	O
three	O
model	O
sizes	O
indicate	O
that	O
few-shot	B
learning	I
can	O
be	O
highly	O
unstable	O
across	O
different	O
numbers	O
of	O
training	O
examples	O
.	O

The	O
more	O
stable	O
blue	O
lines	O
show	O
that	O
the	O
calibration	O
method	O
improves	O
the	O
accuracy	O
and	O
robustness	O
of	O
GPT	B
-	I
3	I
models	I
.	O

Contextual	B
calibration	I
improves	O
accuracy	O
across	O
a	O
range	O
of	O
tasks	O
The	O
proposed	O
contextual	B
calibration	I
method	I
improves	O
the	O
accuracy	O
and	O
reduces	O
the	O
variance	O
of	O
GPT	O
-	O
3	O
models	O
,	O
boosting	O
average	O
and	O
worst-case	O
absolute	O
accuracy	O
by	O
up	O
to	O
30	O
percent	O
.	O

The	O
study	O
highlights	O
the	O
need	O
for	O
better	O
understanding	O
and	O
analysis	O
of	O
the	O
dynamics	O
of	O
in-context	B
learning	I
.	O

