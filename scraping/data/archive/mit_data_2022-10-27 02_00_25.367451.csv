title,url,date,summary,text,cleaning,tokens
Machine learning could vastly speed up the search for new metals,https://www.technologyreview.com/2022/10/25/1062104/machine-learning-new-metals/,2022-10-25,"<p>It’s a development that could be useful for applications from outer space to the deep sea.</p>
","Machine learning could help develop new types of metals with useful properties, such as resistance to extreme temperatures and rust, according to new research. This could be useful in a range of sectors—for example, metals that perform well at lower temperatures could improve spacecraft, while metals that resist corrosion could be used for boats and submarines.  Currently, scientists typically run experiments in the lab to look for ways to combine metals to create new ones. Usually they start off with one well-known element, like iron, which is cheap and malleable, and add one or two others to see the effect on the original material. It’s a laborious process of trial and error that inevitably yields more duds than useful results.   But the new paper, published in Science earlier this month, suggests that with AI, researchers can far more precisely predict which combinations of metals will show promise.  Researchers from the Max Planck Institute managed to identify 17 promising new metals using this method. The team was hunting for metals with a low level of “invar,” which refers to how much materials expand or contract when exposed to high or low temperatures.  Metals with low invar don’t change size under extreme temperatures. They are commonly used in industries where that property is useful—for example, the transportation and storage of natural gas, explains Ziyuan Rao, a materials science researcher at the Max Planck Institute and a coauthor of the paper.  The machine-learning tool could help researchers discover entirely new proteins not yet known to science. The team managed to find these new metals through a combination of AI and lab experiments. First, they had to overcome a significant challenge: a lack of existing data they could use to train the machine-learning models. They trained the models on the data they had—several hundred data points describing the properties of existing metal alloys. The AI system used that data to make predictions for new metals that would exhibit low invar.  The researchers then created those metals in a lab, measured the results, and fed those results back into the machine-learning model. The process continued that way—the model suggesting metal combinations, the researchers testing them and feeding the data back in—until the 17 promising new metals emerged.  The findings could help pave the way for greater use of machine learning in materials science, a field that still relies heavily on laboratory experimentation. Also, the technique of using machine learning to make predictions that are then checked in the lab could be adapted for discovery in other fields, such as chemistry and physics, say experts in materials science. To understand why it’s a significant development, it’s worth looking at the traditional way new compounds are usually created, says Michael Titus, an assistant professor of materials engineering at Purdue University, who was not involved in the research. The process of tinkering in the lab is painstaking and inefficient.  “It’s truly like finding a needle in a haystack to find materials that exhibit a special property,” Titus says. He often tells his new graduate students that there are easily a million possible new materials waiting to be discovered. Machine learning could help researchers decide which paths to pursue. Easo George, a professor of materials science and engineering at the University of Tennessee, who wasn’t involved in this research, was surprised by what the team was able to accomplish using the new technique. “It’s very impressive,” he says. In the future, the team wants to use machine learning to help discover new alloys with more than just one desirable property. George agrees that computational methods will be crucial to the future of materials science. “The machine-learning approach is probably going to be dominant, because people have tried to scan very large spaces experimentally, but that is very time consuming and expensive,” he says. “The test is, are you finding something useful?” ","Machine learning could help develop new types of metals with useful properties, such as resistance to extreme temperatures and rust, according to new research. This could be useful in a range of sectors—for example, metals that perform well at lower temperatures could improve spacecraft, while metals that resist corrosion could be used for boats and submarines. Currently, scientists typically run experiments in the lab to look for ways to combine metals to create new ones. Usually they start off with one well-known element, like iron, which is cheap and malleable, and add one or two others to see the effect on the original material. It’s a laborious process of trial and error that inevitably yields more duds than useful results. But the new paper, published in Science earlier this month, suggests that with AI, researchers can far more precisely predict which combinations of metals will show promise. Researchers from the Max Planck Institute managed to identify 17 promising new metals using this method. The team was hunting for metals with a low level of “invar,” which refers to how much materials expand or contract when exposed to high or low temperatures. Metals with low invar don’t change size under extreme temperatures. They are commonly used in industries where that property is useful—for example, the transportation and storage of natural gas, explains Ziyuan Rao, a materials science researcher at the Max Planck Institute and a coauthor of the paper. The machine-learning tool could help researchers discover entirely new proteins not yet known to science. The team managed to find these new metals through a combination of AI and lab experiments. First, they had to overcome a significant challenge: a lack of existing data they could use to train the machine-learning models. They trained the models on the data they had—several hundred data points describing the properties of existing metal alloys. The AI system used that data to make predictions for new metals that would exhibit low invar. The researchers then created those metals in a lab, measured the results, and fed those results back into the machine-learning model. The process continued that way—the model suggesting metal combinations, the researchers testing them and feeding the data back in—until the 17 promising new metals emerged. The findings could help pave the way for greater use of machine learning in materials science, a field that still relies heavily on laboratory experimentation. Also, the technique of using machine learning to make predictions that are then checked in the lab could be adapted for discovery in other fields, such as chemistry and physics, say experts in materials science. To understand why it’s a significant development, it’s worth looking at the traditional way new compounds are usually created, says Michael Titus, an assistant professor of materials engineering at Purdue University, who was not involved in the research. The process of tinkering in the lab is painstaking and inefficient. “It’s truly like finding a needle in a haystack to find materials that exhibit a special property,” Titus says. He often tells his new graduate students that there are easily a million possible new materials waiting to be discovered. Machine learning could help researchers decide which paths to pursue. Easo George, a professor of materials science and engineering at the University of Tennessee, who wasn’t involved in this research, was surprised by what the team was able to accomplish using the new technique. “It’s very impressive,” he says. In the future, the team wants to use machine learning to help discover new alloys with more than just one desirable property. George agrees that computational methods will be crucial to the future of materials science. “The machine-learning approach is probably going to be dominant, because people have tried to scan very large spaces experimentally, but that is very time consuming and expensive,” he says. “The test is, are you finding something useful?”","['machine', 'learning', 'help', 'develop', 'new', 'type', 'metal', 'useful', 'property', 'resistance', 'extreme', 'temperature', 'rust', 'accord', 'new', 'research', 'useful', 'range', 'sector', 'example', 'metal', 'perform', 'well', 'low', 'temperature', 'improve', 'spacecraft', 'metal', 'resist', 'corrosion', 'use', 'boat', 'submarine', 'currently', 'scientist', 'typically', 'run', 'experiment', 'lab', 'look', 'way', 'combine', 'metal', 'create', 'new', 'one', 'usually', 'start', 'wellknown', 'element', 'iron', 'cheap', 'malleable', 'add', 'see', 'effect', 'original', 'material', '’', 'laborious', 'process', 'trial', 'error', 'inevitably', 'yield', 'dud', 'useful', 'result', 'new', 'paper', 'publish', 'science', 'early', 'month', 'suggest', 'ai', 'researcher', 'far', 'precisely', 'predict', 'combination', 'metal', 'show', 'promise', 'researcher', 'planck', 'institute', 'manage', 'identify', 'promise', 'new', 'metal', 'use', 'method', 'team', 'hunt', 'metal', 'low', 'level', 'invar', 'refer', 'much', 'material', 'expand', 'contract', 'expose', 'high', 'low', 'temperature', 'metal', 'low', 'invar', 'change', 'size', 'extreme', 'temperature', 'commonly', 'use', 'industry', 'property', 'useful', 'example', 'transportation', 'storage', 'natural', 'gas', 'explain', 'material', 'science', 'researcher', 'institute', 'coauthor', 'paper', 'machinelearne', 'tool', 'help', 'researcher', 'discover', 'entirely', 'new', 'protein', 'yet', 'know', 'science', 'team', 'manage', 'find', 'new', 'metal', 'combination', 'ai', 'lab', 'experiment', 'first', 'overcome', 'significant', 'challenge', 'lack', 'exist', 'datum', 'use', 'train', 'machinelearne', 'model', 'train', 'model', 'datum', 'several', 'datum', 'point', 'describe', 'property', 'exist', 'metal', 'alloy', 'ai', 'system', 'use', 'datum', 'make', 'prediction', 'new', 'metal', 'exhibit', 'low', 'invar', 'researcher', 'create', 'metal', 'lab', 'measure', 'result', 'feed', 'result', 'back', 'machinelearning', 'model', 'process', 'continue', 'way', 'model', 'suggest', 'metal', 'combination', 'researcher', 'test', 'feed', 'datum', 'back', 'promise', 'new', 'metal', 'emerge', 'finding', 'pave', 'way', 'great', 'use', 'machine', 'learning', 'material', 'science', 'field', 'still', 'rely', 'heavily', 'laboratory', 'experimentation', 'also', 'technique', 'use', 'machine', 'learning', 'make', 'prediction', 'check', 'lab', 'adapt', 'discovery', 'field', 'chemistry', 'physics', 'say', 'expert', 'material', 'science', 'understand', '’', 'significant', 'development', '’', 'worth', 'look', 'traditional', 'way', 'new', 'compound', 'usually', 'create', 'say', 'assistant', 'professor', 'material', 'engineering', 'involve', 'research', 'process', 'tinker', 'lab', 'painstaking', 'inefficient', '’', 'truly', 'find', 'needle', 'haystack', 'find', 'material', 'exhibit', 'special', 'property', 'titus', 'say', 'often', 'tell', 'new', 'graduate', 'student', 'easily', 'possible', 'new', 'material', 'wait', 'discover', 'machine', 'learning', 'help', 'researcher', 'decide', 'path', 'pursue', 'professor', 'material', 'science', 'engineering', 'involve', 'research', 'surprise', 'team', 'able', 'accomplish', 'use', 'new', 'technique', '’', 'impressive', 'say', 'future', 'team', 'want', 'use', 'machine', 'learning', 'help', 'discover', 'new', 'alloy', 'desirable', 'property', 'george', 'agree', 'computational', 'method', 'crucial', 'future', 'material', 'science', 'machinelearning', 'approach', 'probably', 'go', 'dominant', 'people', 'try', 'scan', 'large', 'space', 'experimentally', 'time', 'consume', 'expensive', 'say', 'test', 'find', 'useful']"
Do AI systems need to come with safety warnings?,https://www.technologyreview.com/2022/10/24/1062071/do-ai-systems-need-to-come-with-safety-warnings/,2022-10-24,"<p>Plus: Technology that lets us “speak” to our dead relatives has arrived.</p>
","To receive The Algorithm in your inbox every Monday, sign up here. Welcome to The Algorithm!  Considering how powerful AI systems are, and the roles they increasingly play in helping to make high-stakes decisions about our lives, homes, and societies, they receive surprisingly little formal scrutiny.  That’s starting to change, thanks to the blossoming field of AI audits. When they work well, these audits allow us to reliably check how well a system is working and figure out how to mitigate any possible bias or harm.  Famously, a 2018 audit of commercial facial recognition systems by AI researchers Joy Buolamwini and Timnit Gebru found that the system didn’t recognize darker-skinned people as well as white people. For dark-skinned women, the error rate was up to 34%. As AI researcher Abeba Birhane points out in a new essay in Nature, the audit “instigated a body of critical work that has exposed the bias, discrimination, and oppressive nature of facial-analysis algorithms.” The hope is that by doing these sorts of audits on different AI systems, we will be better able to root out problems and have a broader conversation about how AI systems are affecting our lives. Regulators are catching up, and that is partly driving the demand for audits. A new law in New York City will start requiring all AI-powered hiring tools to be audited for bias from January 2024. In the European Union, big tech companies will have to conduct annual audits of their AI systems from 2024, and the upcoming AI Act will require audits of “high-risk” AI systems.  It’s a great ambition, but there are some massive obstacles. There is no common understanding about what an AI audit should look like, and not enough people with the right skills to do them. The few audits that do happen today are mostly ad hoc and vary a lot in quality, Alex Engler, who studies AI governance at the Brookings Institution, told me. One example he gave is from AI hiring company HireVue, which implied in a press release that an external audit found its algorithms have no bias. It turns out that was nonsense—the audit had not actually examined the company’s models and was subject to a nondisclosure agreement, which meant there was no way to verify what it found. It was essentially nothing more than a PR stunt.  One way the AI community is trying to address the lack of auditors is through bias bounty competitions, which work in a similar way to cybersecurity bug bounties—that is, they call on people to create tools to identify and mitigate algorithmic biases in AI models. One such competition was launched just last week, organized by a group of volunteers including Twitter’s ethical AI lead, Rumman Chowdhury. The team behind it hopes it’ll be the first of many.  It’s a neat idea to create incentives for people to learn the skills needed to do audits—and also to start building standards for what audits should look like by showing which methods work best. You can read more about it here. The growth of these audits suggests that one day we might see cigarette-pack-style warnings that AI systems could harm your health and safety. Other sectors, such as chemicals and food, have regular audits to ensure that products are safe to use. Could something like this become the norm in AI? Anyone who owns and operates AI systems should be required to conduct regular audits, argue Buolamwini and coauthors in a paper that came out in June. They say that companies should be legally obliged to publish their AI audits, and that people should be notified when they have been subject to algorithmic decision making. Another way to make audits more effective is to track when AI causes harm in the real world, the researchers say. There are a couple of efforts to document AI harms, such as the AI Vulnerability Database and the AI Incidents Database, built by volunteer AI researchers and entrepreneurs. Tracking failures could help developers gain a better understanding of the pitfalls or unintentional failure cases associated with the models they are using, says Subho Majumdar of the software company Splunk, who is the founder of the AI Vulnerability Database and one of the organizers of the bias bounty competition.   But whatever direction audits end up going in, Buolamwini and co-authors wrote, the people who are most affected by algorithmic harms—such as ethnic minorities and marginalized groups—should play a key part in the process. I agree with this, although it will be challenging to get regular people interested in something as nebulous as artificial intelligence audits. Perhaps low-barrier, fun competitions such as bias bounties are part of the solution.  Technology that lets us “speak” to our dead relatives has arrived. Are we ready? Technology for “talking” to people who’ve died has been a mainstay of science fiction for decades. It’s an idea that’s been peddled by charlatans and spiritualists for centuries. But now it’s becoming a reality—and an increasingly accessible one, thanks to advances in AI and voice technology.  MIT Technology Review’s news editor, Charlotte Jee, has written a thoughtful and haunting story about how this kind of technology might change the way we grieve and remember those we’ve lost. But, she explains, creating a virtual version of someone is an ethical minefield—especially if that person hasn’t been able to provide consent. Read more here.  There is a lawsuit brewing against AI code generation initiative GitHub Copi­lotGitHub Copi­lot allows users to use an AI to automatically generate code. Critics have warned that this could lead to copyright issues and cause licensing information to ber lost. (Github Copilot Investigation) France has fined Clearview AIThe French data protection agency has fined the facial-recognition company €20 million ($19.7 million) for breaching the EU’s data protection regime, the GDPR. (TechCrunch) One company’s algorithm has been pushing rents up in the USTexas-based RealPage’s YieldStar software is supposed to help landlords get the highest possible price on their property. From the looks of it, it’s working exactly as intended, much to the detriment of renters. (ProPublica) Meta has developed a speech translation system for an unwritten language, HokkienMost AI translation systems focus on written languages. Meta’s new open-source speech-only translation system allows speakers of a mostly oral language, Hokkien, mostly spoken in the Chinese diaspora, to have conversations with English speakers. (Meta) Brutal tweet of the weekPeople are inserting pictures of themselves into CLIP interrogator to find out what an AI recommends the best prompts should be for a text-to-image AI. The results are brutal. (h/t to Brendan Dolan-Gavitt or “an orc smiling to the camera”) Thanks for making it this far! See you next week.  Melissa ","To receive The Algorithm in your inbox every Monday, sign up here. Welcome to The Algorithm! Considering how powerful AI systems are, and the roles they increasingly play in helping to make high-stakes decisions about our lives, homes, and societies, they receive surprisingly little formal scrutiny. That’s starting to change, thanks to the blossoming field of AI audits. When they work well, these audits allow us to reliably check how well a system is working and figure out how to mitigate any possible bias or harm. Famously, a 2018 audit of commercial facial recognition systems by AI researchers Joy Buolamwini and Timnit Gebru found that the system didn’t recognize darker-skinned people as well as white people. For dark-skinned women, the error rate was up to 34%. As AI researcher Abeba Birhane points out in a new essay in Nature, the audit “instigated a body of critical work that has exposed the bias, discrimination, and oppressive nature of facial-analysis algorithms.” The hope is that by doing these sorts of audits on different AI systems, we will be better able to root out problems and have a broader conversation about how AI systems are affecting our lives. Regulators are catching up, and that is partly driving the demand for audits. A new law in New York City will start requiring all AI-powered hiring tools to be audited for bias from January 2024. In the European Union, big tech companies will have to conduct annual audits of their AI systems from 2024, and the upcoming AI Act will require audits of “high-risk” AI systems. It’s a great ambition, but there are some massive obstacles. There is no common understanding about what an AI audit should look like, and not enough people with the right skills to do them. The few audits that do happen today are mostly ad hoc and vary a lot in quality, Alex Engler, who studies AI governance at the Brookings Institution, told me. One example he gave is from AI hiring company HireVue, which implied in a press release that an external audit found its algorithms have no bias. It turns out that was nonsense—the audit had not actually examined the company’s models and was subject to a nondisclosure agreement, which meant there was no way to verify what it found. It was essentially nothing more than a PR stunt. One way the AI community is trying to address the lack of auditors is through bias bounty competitions, which work in a similar way to cybersecurity bug bounties—that is, they call on people to create tools to identify and mitigate algorithmic biases in AI models. One such competition was launched just last week, organized by a group of volunteers including Twitter’s ethical AI lead, Rumman Chowdhury. The team behind it hopes it’ll be the first of many. It’s a neat idea to create incentives for people to learn the skills needed to do audits—and also to start building standards for what audits should look like by showing which methods work best. You can read more about it here. The growth of these audits suggests that one day we might see cigarette-pack-style warnings that AI systems could harm your health and safety. Other sectors, such as chemicals and food, have regular audits to ensure that products are safe to use. Could something like this become the norm in AI? Anyone who owns and operates AI systems should be required to conduct regular audits, argue Buolamwini and coauthors in a paper that came out in June. They say that companies should be legally obliged to publish their AI audits, and that people should be notified when they have been subject to algorithmic decision making. Another way to make audits more effective is to track when AI causes harm in the real world, the researchers say. There are a couple of efforts to document AI harms, such as the AI Vulnerability Database and the AI Incidents Database, built by volunteer AI researchers and entrepreneurs. Tracking failures could help developers gain a better understanding of the pitfalls or unintentional failure cases associated with the models they are using, says Subho Majumdar of the software company Splunk, who is the founder of the AI Vulnerability Database and one of the organizers of the bias bounty competition. But whatever direction audits end up going in, Buolamwini and co-authors wrote, the people who are most affected by algorithmic harms—such as ethnic minorities and marginalized groups—should play a key part in the process. I agree with this, although it will be challenging to get regular people interested in something as nebulous as artificial intelligence audits. Perhaps low-barrier, fun competitions such as bias bounties are part of the solution. Technology that lets us “speak” to our dead relatives has arrived. Are we ready? Technology for “talking” to people who’ve died has been a mainstay of science fiction for decades. It’s an idea that’s been peddled by charlatans and spiritualists for centuries. But now it’s becoming a reality—and an increasingly accessible one, thanks to advances in AI and voice technology. MIT Technology Review’s news editor, Charlotte Jee, has written a thoughtful and haunting story about how this kind of technology might change the way we grieve and remember those we’ve lost. But, she explains, creating a virtual version of someone is an ethical minefield—especially if that person hasn’t been able to provide consent. Read more here. There is a lawsuit brewing against AI code generation initiative GitHub Copi­lotGitHub Copi­lot allows users to use an AI to automatically generate code. Critics have warned that this could lead to copyright issues and cause licensing information to ber lost. (Github Copilot Investigation) France has fined Clearview AIThe French data protection agency has fined the facial-recognition company €20 million ($19.7 million) for breaching the EU’s data protection regime, the GDPR. (TechCrunch) One company’s algorithm has been pushing rents up in the USTexas-based RealPage’s YieldStar software is supposed to help landlords get the highest possible price on their property. From the looks of it, it’s working exactly as intended, much to the detriment of renters. (ProPublica) Meta has developed a speech translation system for an unwritten language, HokkienMost AI translation systems focus on written languages. Meta’s new open-source speech-only translation system allows speakers of a mostly oral language, Hokkien, mostly spoken in the Chinese diaspora, to have conversations with English speakers. (Meta) Brutal tweet of the weekPeople are inserting pictures of themselves into CLIP interrogator to find out what an AI recommends the best prompts should be for a text-to-image AI. The results are brutal. (h/t to Brendan Dolan-Gavitt or “an orc smiling to the camera”) Thanks for making it this far! See you next week. Melissa","['receive', 'algorithm', 'inbox', 'sign', 'welcome', 'consider', 'powerful', 'system', 'role', 'increasingly', 'play', 'help', 'make', 'highstake', 'decision', 'live', 'home', 'society', 'receive', 'surprisingly', 'little', 'formal', 'scrutiny', 'start', 'change', 'thank', 'blossom', 'field', 'ai', 'audits', 'work', 'audits', 'allow', 'reliably', 'check', 'well', 'system', 'work', 'figure', 'mitigate', 'possible', 'bias', 'harm', 'famously', 'audit', 'commercial', 'facial', 'recognition', 'system', 'researcher', 'joy', 'buolamwini', 'timnit', 'gebru', 'find', 'system', 'recognize', 'darkerskinne', 'people', 'well', 'white', 'people', 'darkskinned', 'woman', 'error', 'rate', 'researcher', 'point', 'new', 'essay', 'nature', 'audit', 'instigate', 'body', 'critical', 'work', 'expose', 'bias', 'discrimination', 'oppressive', 'nature', 'facialanalysis', 'algorithm', 'hope', 'sort', 'audits', 'different', 'ai', 'system', 'well', 'able', 'root', 'problem', 'broad', 'conversation', 'system', 'affect', 'life', 'regulator', 'catch', 'partly', 'drive', 'demand', 'audits', 'new', 'law', 'start', 'require', 'aipowere', 'hire', 'tool', 'audit', 'bias', 'big', 'tech', 'company', 'conduct', 'annual', 'audits', 'ai', 'system', 'upcoming', 'require', 'audits', 'highrisk', 'ai', 'system', '’', 'great', 'ambition', 'massive', 'obstacle', 'common', 'understanding', 'ai', 'audit', 'look', 'enough', 'people', 'right', 'skill', 'audits', 'happen', 'today', 'mostly', 'vary', 'lot', 'quality', 'study', 'governance', 'brooking', 'institution', 'tell', 'example', 'give', 'hire', 'company', 'hirevue', 'imply', 'press', 'release', 'external', 'audit', 'find', 'algorithm', 'bias', 'turn', 'nonsense', 'audit', 'actually', 'examine', 'company', 'model', 'subject', 'nondisclosure', 'agreement', 'mean', 'way', 'verify', 'find', 'essentially', 'pr', 'stunt', 'way', 'community', 'try', 'address', 'lack', 'auditor', 'bias', 'bounty', 'competition', 'work', 'similar', 'way', 'cybersecurity', 'bug', 'bounty', 'call', 'people', 'create', 'tool', 'identify', 'mitigate', 'algorithmic', 'bias', 'model', 'competition', 'launch', 'last', 'week', 'organize', 'group', 'volunteer', 'include', 'ethical', 'ai', 'lead', 'rumman', 'chowdhury', 'team', 'hope', 'first', 'many', '’', 'neat', 'idea', 'create', 'incentive', 'people', 'learn', 'skill', 'need', 'audits', 'also', 'start', 'build', 'standard', 'audits', 'look', 'show', 'method', 'work', 'well', 'read', 'growth', 'audits', 'suggest', 'day', 'see', 'cigarettepackstyle', 'warning', 'ai', 'system', 'harm', 'health', 'safety', 'sector', 'chemical', 'food', 'regular', 'audits', 'ensure', 'product', 'safe', 'use', 'become', 'norm', 'operate', 'ai', 'system', 'require', 'conduct', 'regular', 'audits', 'argue', 'coauthor', 'paper', 'come', 'say', 'company', 'legally', 'oblige', 'publish', 'ai', 'audits', 'people', 'notify', 'subject', 'algorithmic', 'decision', 'make', 'way', 'make', 'audits', 'effective', 'track', 'ai', 'cause', 'harm', 'real', 'world', 'researcher', 'say', 'couple', 'effort', 'document', 'ai', 'harm', 'ai', 'vulnerability', 'database', 'incident', 'database', 'build', 'volunteer', 'ai', 'researcher', 'entrepreneur', 'tracking', 'failure', 'help', 'developer', 'gain', 'well', 'understanding', 'pitfall', 'unintentional', 'failure', 'case', 'associate', 'model', 'use', 'say', 'subho', 'majumdar', 'software', 'company', 'splunk', 'founder', 'vulnerability', 'database', 'organizer', 'bias', 'bounty', 'competition', 'direction', 'audits', 'end', 'go', 'buolamwini', 'coauthor', 'write', 'people', 'affect', 'algorithmic', 'harm', 'ethnic', 'minority', 'marginalized', 'group', 'play', 'key', 'part', 'process', 'agree', 'challenge', 'get', 'regular', 'people', 'interested', 'nebulous', 'artificial', 'intelligence', 'audits', 'perhaps', 'lowbarri', 'fun', 'competition', 'bias', 'bounty', 'part', 'solution', 'technology', 'let', 'speak', 'dead', 'relative', 'arrive', 'ready', 'technology', 'talk', 'people', '’ve', 'die', 'mainstay', 'science', 'fiction', 'decade', '’', 'idea', 'peddle', 'charlatan', 'spiritualist', 'century', 'become', 'reality', 'increasingly', 'accessible', 'thank', 'advance', 'ai', 'voice', 'technology', 'mit', 'technology', 'write', 'thoughtful', 'haunt', 'story', 'kind', 'technology', 'change', 'way', 'grieve', 'remember', 'lose', 'explain', 'create', 'virtual', 'version', 'ethical', 'minefield', 'especially', 'person', 'able', 'provide', 'consent', 'read', 'lawsuit', 'brew', 'allow', 'user', 'use', 'ai', 'automatically', 'generate', 'code', 'critic', 'warn', 'lead', 'copyright', 'issue', 'cause', 'license', 'information', 'lose', 'copilot', 'investigation', 'fine', 'clearview', 'french', 'protection', 'agency', 'fine', 'facialrecognition', 'company', 'breach', 'protection', 'regime', 'gdpr', 'company', 'push', 'rent', 'ustexasbased', 'realpage', 'yieldstar', 'software', 'suppose', 'help', 'landlord', 'get', 'high', 'possible', 'price', 'property', 'look', 'work', 'exactly', 'intend', 'much', 'detriment', 'renter', 'develop', 'speech', 'translation', 'system', 'unwritten', 'language', 'hokkienmost', 'translation', 'system', 'focus', 'write', 'language', 'meta', 'new', 'speechonly', 'translation', 'system', 'allow', 'speaker', 'mostly', 'oral', 'language', 'hokkien', 'mostly', 'speak', 'conversation', 'english', 'speaker', 'meta', 'brutal', 'tweet', 'weekpeople', 'insert', 'picture', 'clip', 'interrogator', 'find', 'ai', 'recommend', 'good', 'prompt', 'texttoimage', 'result', 'brutal', 'orc', 'smile', 'camera', 'thank', 'make', 'far', 'see', 'next', 'week', 'melissa']"
A bias bounty for AI will help to catch unfair algorithms faster,https://www.technologyreview.com/2022/10/20/1061977/ai-bias-bounty-help-catch-unfair-algorithms-faster/,2022-10-20,"<p>The hope is it will boost a blossoming sector that works to hold artificial-intelligence systems accountable.</p>
","AI systems are deployed all the time, but it can take months or even years until it becomes clear whether, and how, they’re biased.  The stakes are often sky-high: unfair AI systems can cause innocent people to be arrested, and they can deny people housing, jobs, and basic services.   Today a group of AI and machine-learning experts are launching a new bias bounty competition, which they hope will speed the process of uncovering these kinds of embedded prejudice. The competition, which takes inspiration from bug bounties in cybersecurity, calls on participants to create tools to identify and mitigate algorithmic biases in AI models.  It’s being organized by a group of volunteers who work at companies like Twitter, software company Splunk, and deepfake detection startup Reality Defender. They’ve dubbed themselves the “Bias Buccaneers.”  The first bias bounty competition is going to focus on biased image detection. It’s a common problem: in the past, for example, flawed image detection systems have misidentified Black people as gorillas.  Competitors will be challenged to build a machine-learning model that labels each image with its skin tone, perceived gender, and age group, which will make it easier to measure and spot biases in datasets. They will be given access to a data set of around 15,000 images of synthetically generated human faces. Participants are ranked on how accurately their model tags images and how long the code takes to run, among other metrics. The competition closes on November 30.  Microsoft and startup Robust Intelligence have committed prize money of $6,000 for the winner, $4,000 for the runner-up, and $2,000 for whoever comes third. Amazon has contributed $5,000 to the first set of entrants for computing power.  The competition is an example of a budding industry that’s emerging in AI: auditing for algorithmic bias. Twitter launched the first AI bias bounty last year, and Stanford University just concluded its first AI audit challenge. Meanwhile, nonprofit Mozilla is creating tools for AI auditors.  These audits are likely to become more and more commonplace. They’ve been hailed by regulators and AI ethics experts as a good way to hold AI systems accountable, and they are going to become a legal requirement in certain jurisdictions. AI audits may overlook certain types of bias, and they don’t necessarily verify that a hiring tool picks the best candidates for a job.  The EU’s new content moderation law, the Digital Services Act, includes annual audit requirements for the data and algorithms used by large tech platforms, and the EU’s upcoming AI Act could also allow authorities to audit AI systems. The US National Institute of Standards and Technology also recommends AI audits as a gold standard. The idea is that these audits will act like the sorts of inspections we see in other high-risk sectors, such as chemical plants, says Alex Engler, who studies AI governance at the think tank the Brookings Institution.  The trouble is, there aren’t enough independent contractors out there to meet the coming demand for algorithmic audits, and companies are reluctant to give them access to their systems, argue researcher Deborah Raji, who specializes in AI accountability, and her coauthors in a paper from last June.  That’s what these competitions want to cultivate. The hope in the AI community is that they’ll lead more engineers, researchers, and experts to develop the skills and experience to carry out these audits.  Much of the limited scrutiny in the world of AI so far comes either from academics or from tech companies themselves. The aim of competitions like this one is to create a new sector of experts who specialize in auditing AI. “We are trying to create a third space for people who are interested in this kind of work, who want to get started or who are experts who don’t work at tech companies,” says Rumman Chowdhury, director of Twitter’s team on ethics, transparency, and accountability in machine learning, the leader of the Bias Buccaneers. These people could include hackers and data scientists who want to learn a new skill, she says.  The team behind the Bias Buccaneers’ bounty competition hopes it will be the first of many.  Competitions like this not only create incentives for the machine-learning community to do audits but also advance a shared understanding of “how best to audit and what types of audits we should be investing in,” says Sara Hooker, who leads Cohere for AI, a nonprofit AI research lab.  The effort is “fantastic and absolutely much needed,” says Abhishek Gupta, the founder of the Montreal AI Ethics Institute, who was a judge in Stanford’s AI audit challenge. “The more eyes that you have on a system, the more likely it is that we find places where there are flaws,” Gupta says.  ","AI systems are deployed all the time, but it can take months or even years until it becomes clear whether, and how, they’re biased. The stakes are often sky-high: unfair AI systems can cause innocent people to be arrested, and they can deny people housing, jobs, and basic services. Today a group of AI and machine-learning experts are launching a new bias bounty competition, which they hope will speed the process of uncovering these kinds of embedded prejudice. The competition, which takes inspiration from bug bounties in cybersecurity, calls on participants to create tools to identify and mitigate algorithmic biases in AI models. It’s being organized by a group of volunteers who work at companies like Twitter, software company Splunk, and deepfake detection startup Reality Defender. They’ve dubbed themselves the “Bias Buccaneers.” The first bias bounty competition is going to focus on biased image detection. It’s a common problem: in the past, for example, flawed image detection systems have misidentified Black people as gorillas. Competitors will be challenged to build a machine-learning model that labels each image with its skin tone, perceived gender, and age group, which will make it easier to measure and spot biases in datasets. They will be given access to a data set of around 15,000 images of synthetically generated human faces. Participants are ranked on how accurately their model tags images and how long the code takes to run, among other metrics. The competition closes on November 30. Microsoft and startup Robust Intelligence have committed prize money of $6,000 for the winner, $4,000 for the runner-up, and $2,000 for whoever comes third. Amazon has contributed $5,000 to the first set of entrants for computing power. The competition is an example of a budding industry that’s emerging in AI: auditing for algorithmic bias. Twitter launched the first AI bias bounty last year, and Stanford University just concluded its first AI audit challenge. Meanwhile, nonprofit Mozilla is creating tools for AI auditors. These audits are likely to become more and more commonplace. They’ve been hailed by regulators and AI ethics experts as a good way to hold AI systems accountable, and they are going to become a legal requirement in certain jurisdictions. AI audits may overlook certain types of bias, and they don’t necessarily verify that a hiring tool picks the best candidates for a job. The EU’s new content moderation law, the Digital Services Act, includes annual audit requirements for the data and algorithms used by large tech platforms, and the EU’s upcoming AI Act could also allow authorities to audit AI systems. The US National Institute of Standards and Technology also recommends AI audits as a gold standard. The idea is that these audits will act like the sorts of inspections we see in other high-risk sectors, such as chemical plants, says Alex Engler, who studies AI governance at the think tank the Brookings Institution. The trouble is, there aren’t enough independent contractors out there to meet the coming demand for algorithmic audits, and companies are reluctant to give them access to their systems, argue researcher Deborah Raji, who specializes in AI accountability, and her coauthors in a paper from last June. That’s what these competitions want to cultivate. The hope in the AI community is that they’ll lead more engineers, researchers, and experts to develop the skills and experience to carry out these audits. Much of the limited scrutiny in the world of AI so far comes either from academics or from tech companies themselves. The aim of competitions like this one is to create a new sector of experts who specialize in auditing AI. “We are trying to create a third space for people who are interested in this kind of work, who want to get started or who are experts who don’t work at tech companies,” says Rumman Chowdhury, director of Twitter’s team on ethics, transparency, and accountability in machine learning, the leader of the Bias Buccaneers. These people could include hackers and data scientists who want to learn a new skill, she says. The team behind the Bias Buccaneers’ bounty competition hopes it will be the first of many. Competitions like this not only create incentives for the machine-learning community to do audits but also advance a shared understanding of “how best to audit and what types of audits we should be investing in,” says Sara Hooker, who leads Cohere for AI, a nonprofit AI research lab. The effort is “fantastic and absolutely much needed,” says Abhishek Gupta, the founder of the Montreal AI Ethics Institute, who was a judge in Stanford’s AI audit challenge. “The more eyes that you have on a system, the more likely it is that we find places where there are flaws,” Gupta says.","['system', 'time', 'take', 'month', 'even', 'year', 'become', 'clear', 'bias', 'stake', 'often', 'skyhigh', 'unfair', 'system', 'cause', 'innocent', 'people', 'arrest', 'deny', 'people', 'housing', 'job', 'basic', 'service', 'today', 'group', 'ai', 'machinelearne', 'expert', 'launch', 'new', 'bias', 'bounty', 'competition', 'hope', 'speed', 'process', 'uncover', 'kind', 'embed', 'prejudice', 'competition', 'take', 'inspiration', 'bug', 'bounty', 'cybersecurity', 'call', 'participant', 'create', 'tool', 'identify', 'mitigate', 'algorithmic', 'bias', 'model', 'organize', 'group', 'volunteer', 'work', 'company', 'twitter', 'software', 'company', 'splunk', 'deepfake', 'detection', 'startup', 'reality', 'defender', 'dub', 'bias', 'buccaneer', 'first', 'bias', 'bounty', 'competition', 'go', 'focus', 'biased', 'image', 'detection', '’', 'common', 'problem', 'past', 'example', 'flawed', 'image', 'detection', 'system', 'misidentifie', 'black', 'people', 'gorilla', 'competitor', 'challenge', 'build', 'machinelearning', 'model', 'label', 'image', 'skin', 'tone', 'perceive', 'gender', 'age', 'group', 'make', 'easy', 'measure', 'spot', 'bias', 'dataset', 'give', 'access', 'data', 'set', 'image', 'synthetically', 'generate', 'human', 'face', 'participant', 'rank', 'accurately', 'model', 'tag', 'image', 'long', 'code', 'take', 'run', 'metric', 'competition', 'close', 'startup', 'robust', 'intelligence', 'commit', 'prize', 'money', 'winner', 'runnerup', 'come', 'third', 'amazon', 'contribute', 'first', 'set', 'entrant', 'compute', 'power', 'competition', 'example', 'bud', 'industry', 'emerge', 'audit', 'algorithmic', 'bias', 'twitter', 'launch', 'first', 'bias', 'bounty', 'last', 'year', 'conclude', 'first', 'audit', 'challenge', 'meanwhile', 'nonprofit', 'mozilla', 'create', 'tool', 'auditor', 'audit', 'likely', 'become', 'commonplace', 'hail', 'regulator', 'ai', 'ethic', 'expert', 'good', 'way', 'hold', 'system', 'accountable', 'go', 'become', 'legal', 'requirement', 'certain', 'jurisdiction', 'ai', 'overlook', 'certain', 'type', 'bias', 'necessarily', 'verify', 'hire', 'tool', 'pick', 'good', 'candidate', 'job', 'new', 'content', 'moderation', 'law', 'include', 'annual', 'audit', 'requirement', 'datum', 'algorithm', 'use', 'large', 'tech', 'platform', 'also', 'allow', 'authority', 'audit', 'system', 'standard', 'technology', 'also', 'recommend', 'ai', 'audits', 'gold', 'standard', 'idea', 'audits', 'act', 'sort', 'inspection', 'see', 'highrisk', 'sector', 'chemical', 'plant', 'say', 'study', 'governance', 'think', 'tank', 'brooking', 'institution', 'trouble', 'enough', 'independent', 'contractor', 'meet', 'come', 'demand', 'algorithmic', 'audits', 'company', 'reluctant', 'give', 'access', 'system', 'argue', 'researcher', 'specialize', 'accountability', 'coauthor', 'paper', 'last', '’', 'competition', 'want', 'cultivate', 'hope', 'community', 'lead', 'engineer', 'researcher', 'expert', 'develop', 'skill', 'experience', 'carry', 'audits', 'much', 'limited', 'scrutiny', 'world', 'far', 'come', 'academic', 'tech', 'company', 'aim', 'competition', 'one', 'create', 'new', 'sector', 'expert', 'specialize', 'auditing', 'try', 'create', 'third', 'space', 'people', 'interested', 'kind', 'work', 'want', 'start', 'expert', 'work', 'tech', 'company', 'say', 'rumman', 'director', 'team', 'ethic', 'transparency', 'accountability', 'machine', 'learn', 'leader', 'bias', 'buccaneer', 'people', 'include', 'hacker', 'datum', 'scientist', 'want', 'learn', 'new', 'skill', 'say', 'team', 'bias', 'buccaneer', 'bounty', 'competition', 'hope', 'first', 'many', 'competition', 'create', 'incentive', 'machinelearne', 'community', 'audits', 'also', 'advance', 'share', 'understanding', 'good', 'audit', 'type', 'audits', 'invest', 'say', 'lead', 'cohere', 'nonprofit', 'ai', 'research', 'lab', 'effort', 'fantastic', 'absolutely', 'much', 'need', 'say', 'founder', 'montreal', 'judge', 'challenge', 'eye', 'system', 'likely', 'find', 'place', 'flaw', 'gupta', 'say']"
Alex Hanna left Google to try to save AI’s future,https://www.technologyreview.com/2022/10/19/1061075/alex-hanna-google-ai-research/,2022-10-19,"<p>After her departure, she joined Timnit Gebru’s Distributed AI Research Institute, and work is well underway.</p>
","“I am quitting because I’m tired,” Alex Hanna wrote on February 2, her last day on Google’s Ethical AI team. She felt that the company, and the tech industry as a whole, did little to promote diversity or mitigate the harms its products had caused to marginalized people. “In a word, tech has a whiteness problem,” she wrote in her post on Medium. “Google is not just a tech organization. Google is a white tech organization.” Hanna did not take much of a break—she joined the Distributed AI Research Institute (DAIR) as the group’s second employee on February 3. It was a move that capped a dramatic period in Hanna’s professional life. In late 2020, her manager, Timnit Gebru, had been fired from her position as the co-lead of the Ethical AI team after she wrote a paper questioning the ethics of large language models (including Google’s). A few months later, Hanna’s next manager, Meg Mitchell, was also shown the door.  DAIR, which was founded by Gebru in late 2021 and is funded by various philanthropies, aims to challenge the existing understanding of AI through a community-­focused, bottom-up approach to research. The group works remotely and includes teams in Berlin and South Africa.   “We wanted to find a different way of AI, one that doesn’t have the same institutional constraints as corporate and much of academic research,” says Hanna, who is the group’s director of research. While these sorts of investigations are slower, she says, “it allows for research for community members—different kinds of knowledge that is respected and compensated, and used toward community work.” Less than a year in, DAIR is still sorting out its approach, Hanna says. But research is well underway. The institute has three full-time employees and five fellows—a mix of academics, activists, and practitioners who come in with their own research agendas but also aid in developing the institute’s programs. DAIR fellow Raesetje Sefala is using satellite imagery and computer vision technology to focus on neighborhood change in post-apartheid South Africa, for example. Her project is analyzing the impact of desegregation and mapping out low-income areas. Another DAIR fellow, Milagros Miceli, is working on a project on the power asymmetries in outsourced data work. Many data laborers, who analyze and manage vast amounts of data coming into tech companies, reside in the Global South and are typically paid a pittance.  For Hanna, DAIR feels like a natural fit. Her self-described “nontraditional pathway to tech” began with a PhD in sociology and work on labor justice. In graduate school, she used machine-learning tools to study how activists connected with one another during the 2008 revolution in Egypt, where her family is from. “People were saying [the revolution] happened on Facebook and Twitter, but you can’t just pull a movement out of thin air,” Hanna says. “I began interviewing activists and understanding what they are doing on the ground aside from online activity.”  DAIR is aiming for big, structural change by using research to shed light on issues that might not otherwise be explored and to disseminate knowledge that might not otherwise be valued. “In my Google resignation letter, I pointed out how tech organizations embody a lot of white supremacist values and practices,” Hanna says. “Unsettling that means interrogating what those perspectives are and navigating how to undo those organizational practices.” Those are values, she says, that DAIR champions. Anmol Irfan is a freelance journalist and founder of Perspective Magazine, based in Lahore, Pakistan. ","“I am quitting because I’m tired,” Alex Hanna wrote on February 2, her last day on Google’s Ethical AI team. She felt that the company, and the tech industry as a whole, did little to promote diversity or mitigate the harms its products had caused to marginalized people. “In a word, tech has a whiteness problem,” she wrote in her post on Medium. “Google is not just a tech organization. Google is a white tech organization.” Hanna did not take much of a break—she joined the Distributed AI Research Institute (DAIR) as the group’s second employee on February 3. It was a move that capped a dramatic period in Hanna’s professional life. In late 2020, her manager, Timnit Gebru, had been fired from her position as the co-lead of the Ethical AI team after she wrote a paper questioning the ethics of large language models (including Google’s). A few months later, Hanna’s next manager, Meg Mitchell, was also shown the door. DAIR, which was founded by Gebru in late 2021 and is funded by various philanthropies, aims to challenge the existing understanding of AI through a community-­focused, bottom-up approach to research. The group works remotely and includes teams in Berlin and South Africa. “We wanted to find a different way of AI, one that doesn’t have the same institutional constraints as corporate and much of academic research,” says Hanna, who is the group’s director of research. While these sorts of investigations are slower, she says, “it allows for research for community members—different kinds of knowledge that is respected and compensated, and used toward community work.” Less than a year in, DAIR is still sorting out its approach, Hanna says. But research is well underway. The institute has three full-time employees and five fellows—a mix of academics, activists, and practitioners who come in with their own research agendas but also aid in developing the institute’s programs. DAIR fellow Raesetje Sefala is using satellite imagery and computer vision technology to focus on neighborhood change in post-apartheid South Africa, for example. Her project is analyzing the impact of desegregation and mapping out low-income areas. Another DAIR fellow, Milagros Miceli, is working on a project on the power asymmetries in outsourced data work. Many data laborers, who analyze and manage vast amounts of data coming into tech companies, reside in the Global South and are typically paid a pittance. For Hanna, DAIR feels like a natural fit. Her self-described “nontraditional pathway to tech” began with a PhD in sociology and work on labor justice. In graduate school, she used machine-learning tools to study how activists connected with one another during the 2008 revolution in Egypt, where her family is from. “People were saying [the revolution] happened on Facebook and Twitter, but you can’t just pull a movement out of thin air,” Hanna says. “I began interviewing activists and understanding what they are doing on the ground aside from online activity.” DAIR is aiming for big, structural change by using research to shed light on issues that might not otherwise be explored and to disseminate knowledge that might not otherwise be valued. “In my Google resignation letter, I pointed out how tech organizations embody a lot of white supremacist values and practices,” Hanna says. “Unsettling that means interrogating what those perspectives are and navigating how to undo those organizational practices.” Those are values, she says, that DAIR champions. Anmol Irfan is a freelance journalist and founder of Perspective Magazine, based in Lahore, Pakistan.","['quit', '’m', 'tired', 'write', 'last', 'day', 'ethical', 'team', 'feel', 'company', 'tech', 'industry', 'whole', 'little', 'promote', 'diversity', 'mitigate', 'harm', 'product', 'cause', 'marginalize', 'people', 'word', 'tech', 'whiteness', 'problem', 'write', 'post', 'medium', 'google', 'tech', 'organization', 'google', 'white', 'tech', 'take', 'much', 'break', 'join', 'distribute', 'dair', 'group', 'second', 'employee', 'move', 'cap', 'dramatic', 'period', 'professional', 'life', 'late', 'manager', 'timnit', 'gebru', 'fire', 'position', 'colead', 'ethical', 'ai', 'team', 'write', 'paper', 'question', 'ethic', 'large', 'language', 'model', 'include', 'month', 'later', 'next', 'manager', 'also', 'show', 'door', 'dair', 'found', 'gebru', 'late', 'fund', 'various', 'philanthropy', 'aim', 'challenge', 'exist', 'understanding', 'ai', 'community\xadfocused', 'bottomup', 'approach', 'research', 'group', 'work', 'remotely', 'include', 'team', 'want', 'find', 'different', 'way', 'one', 'institutional', 'constraint', 'corporate', 'much', 'academic', 'research', 'say', 'group', 'director', 'research', 'sort', 'investigation', 'slow', 'say', 'allow', 'research', 'community', 'member', 'different', 'kind', 'knowledge', 'respect', 'compensate', 'use', 'community', 'work', 'less', 'year', 'dair', 'still', 'sort', 'approach', 'say', 'research', 'well', 'underway', 'institute', 'fulltime', 'employee', 'fellow', 'mix', 'academic', 'activist', 'practitioner', 'come', 'research', 'agenda', 'also', 'aid', 'develop', 'institute', 'sefala', 'use', 'satellite', 'imagery', 'computer', 'vision', 'technology', 'focus', 'neighborhood', 'change', 'example', 'project', 'analyze', 'impact', 'desegregation', 'mapping', 'lowincome', 'area', 'dair', 'fellow', 'miceli', 'work', 'project', 'power', 'asymmetry', 'outsource', 'datum', 'work', 'many', 'datum', 'laborer', 'analyze', 'manage', 'vast', 'amount', 'datum', 'come', 'tech', 'company', 'reside', 'global', 'south', 'typically', 'pay', 'pittance', 'feel', 'natural', 'fit', 'selfdescribe', 'nontraditional', 'pathway', 'tech', 'begin', 'phd', 'sociology', 'work', 'labor', 'justice', 'graduate', 'school', 'use', 'machinelearne', 'tool', 'study', 'activist', 'connect', 'revolution', 'family', 'people', 'say', 'revolution', 'happen', 'facebook', 'twitter', 'pull', 'movement', 'thin', 'say', 'begin', 'interview', 'activist', 'understand', 'ground', 'aside', 'online', 'activity', 'dair', 'aim', 'big', 'structural', 'change', 'use', 'research', 'shed', 'light', 'issue', 'otherwise', 'explore', 'disseminate', 'knowledge', 'otherwise', 'value', 'resignation', 'letter', 'point', 'tech', 'organization', 'embody', 'lot', 'white', 'supremacist', 'value', 'practice', 'say', 'unsettling', 'mean', 'interrogate', 'perspective', 'navigate', 'undo', 'organizational', 'practice', 'value', 'say', 'dair', 'champion', 'anmol', 'irfan', 'freelance', 'journalist', 'founder', 'magazine', 'base']"
Why AI shouldn’t be making life-and-death decisions,https://www.technologyreview.com/2022/10/17/1061738/why-ai-shouldnt-be-making-life-and-death-decisions/,2022-10-17,"<p>Plus: Meta wants to use AI to give people legs in the metaverse. </p>
","To receive The Algorithm in your inbox every Monday, sign up here. Welcome to The Algorithm!  Let me introduce you to Philip Nitschke, also known as “Dr. Death” or “the Elon Musk of assisted suicide.”  Nitschke has a curious goal: He wants to “demedicalize” death and make assisted suicide as unassisted as possible through technology. As my colleague Will Heaven reports, Nitschke  has developed a coffin-size machine called the Sarco. People seeking to end their lives can enter the machine after undergoing an algorithm-based psychiatric self-assessment. If they pass, the Sarco will release nitrogen gas, which asphyxiates them in minutes. A person who has chosen to die must answer three questions: Who are you? Where are you? And do you know what will happen when you press that button? In Switzerland, where assisted suicide is legal, candidates for euthanasia must demonstrate mental capacity, which is typically assessed by a psychiatrist. But Nitschke wants to take people out of the equation entirely. Nitschke is an extreme example. But as Will writes, AI is already being used to triage and treat patients in a growing number of health-care fields. Algorithms are becoming an increasingly important part of care, and we must try to ensure that their role is limited to medical decisions, not moral ones. Will explores the messy morality of efforts to develop AI that can help make life-and-death decisions here. I’m probably not the only one who feels extremely uneasy about letting algorithms make decisions about whether people live or die. Nitschke’s work seems like a classic case of misplaced trust in algorithms’ capabilities. He’s trying to sidestep complicated human judgments by introducing a technology that could make supposedly “unbiased” and “objective” decisions. That is a dangerous path, and we know where it leads. AI systems reflect the humans who build them, and they are riddled with biases. We’ve seen facial recognition systems that don’t recognize Black people and label them as criminals or gorillas. In the Netherlands, tax authorities used an algorithm to try to weed out benefits fraud, only to penalize innocent people—mostly lower-income people and members of ethnic minorities. This led to devastating consequences for thousands: bankruptcy, divorce, suicide, and children being taken into foster care.  As AI is rolled out in health care to help make some of the highest-stake decisions there are, it’s more crucial than ever to critically examine how these systems are built. Even if we manage to create a perfect algorithm with zero bias, algorithms lack the nuance and complexity to make decisions about humans and society on their own. We should carefully question how much decision-making we really want to turn over to AI. There is nothing inevitable about letting it deeper and deeper into our lives and societies. That is a choice made by humans. Meta wants to use AI to give people legs in the metaverse  Last week, Meta unveiled its latest virtual-reality headset. It has an eye-watering $1,499.99 price tag. At the virtual event, Meta pitched its vision for a “next-generation social platform” accessible to everyone. As my colleague Tanya Basu points out: “Even if you are among the lucky few who can shell out a grand and a half for a virtual-reality headset, would you really want to?” The legs were fake: One of the big selling points for the Metaverse was the ability for avatars to have legs. Legs! At the event, a leggy avatar of Meta CEO Mark Zuckerberg announced that the company was going to use artificial intelligence to enable this feature, allowing avatars not only to walk and run but also to wear digital clothing. But there’s one problem. Meta hasn’t actually figured out how to do this yet, and the “segment featured animations created from motion capture,” as Kotaku reports.  Meta’s AI lab is one of the biggest and richest in the industry, and it’s hired some of the field’s top engineers. I can’t imagine that this multibillion-dollar push to make VR Sims happen is very fulfilling work for Meta’s AI researchers. Do you work in AI/ML teams at Meta? I want to hear from you. (Drop me a line melissa.heikkila@technologyreview.com) Learn more about the exploited labor behind artificial intelligenceIn an essay, Timnit Gebru, former co-lead of Google’s ethical AI team, and researchers at her Distributed AI Research Institute argue that AI systems are driven by labor exploitation, and that AI ethics discussions should prioritize transnational worker organization efforts. (Noema) AI-generated art is the new clip artMicrosoft has teamed up with OpenAI to add text-to-image AI DALL-E 2 to its Office suite. Users will be able to enter prompts to create images that can be used in greeting cards or PowerPoint presentations. (The Verge)  An AI version of Joe Rogan interviewed an AI Steve JobsThis is pretty mind-blowing. Text-to-voice AI startup Play.ht trained an AI model on Steve Jobs’s biography and all the recordings it could find of him online in order to mimic the way Jobs would have spoken in a real podcast. The content is pretty silly, but it won’t be long until the technology develops enough to fool anyone. (Podcast.ai) Tour Amazon’s dream home, where every appliance is also a spyThis story offers a clever way to visualize how invasive Amazon’s push to embed “smart” devices in our homes really is. (The Washington Post) Tweet of the weekWhat it's like to build a machine-learning startup these days, from Hugging Face CEO and cofounder Clem Delangue.  Thanks for making it this far! Catch you next week.  Melissa ","To receive The Algorithm in your inbox every Monday, sign up here. Welcome to The Algorithm! Let me introduce you to Philip Nitschke, also known as “Dr. Death” or “the Elon Musk of assisted suicide.” Nitschke has a curious goal: He wants to “demedicalize” death and make assisted suicide as unassisted as possible through technology. As my colleague Will Heaven reports, Nitschke has developed a coffin-size machine called the Sarco. People seeking to end their lives can enter the machine after undergoing an algorithm-based psychiatric self-assessment. If they pass, the Sarco will release nitrogen gas, which asphyxiates them in minutes. A person who has chosen to die must answer three questions: Who are you? Where are you? And do you know what will happen when you press that button? In Switzerland, where assisted suicide is legal, candidates for euthanasia must demonstrate mental capacity, which is typically assessed by a psychiatrist. But Nitschke wants to take people out of the equation entirely. Nitschke is an extreme example. But as Will writes, AI is already being used to triage and treat patients in a growing number of health-care fields. Algorithms are becoming an increasingly important part of care, and we must try to ensure that their role is limited to medical decisions, not moral ones. Will explores the messy morality of efforts to develop AI that can help make life-and-death decisions here. I’m probably not the only one who feels extremely uneasy about letting algorithms make decisions about whether people live or die. Nitschke’s work seems like a classic case of misplaced trust in algorithms’ capabilities. He’s trying to sidestep complicated human judgments by introducing a technology that could make supposedly “unbiased” and “objective” decisions. That is a dangerous path, and we know where it leads. AI systems reflect the humans who build them, and they are riddled with biases. We’ve seen facial recognition systems that don’t recognize Black people and label them as criminals or gorillas. In the Netherlands, tax authorities used an algorithm to try to weed out benefits fraud, only to penalize innocent people—mostly lower-income people and members of ethnic minorities. This led to devastating consequences for thousands: bankruptcy, divorce, suicide, and children being taken into foster care. As AI is rolled out in health care to help make some of the highest-stake decisions there are, it’s more crucial than ever to critically examine how these systems are built. Even if we manage to create a perfect algorithm with zero bias, algorithms lack the nuance and complexity to make decisions about humans and society on their own. We should carefully question how much decision-making we really want to turn over to AI. There is nothing inevitable about letting it deeper and deeper into our lives and societies. That is a choice made by humans. Meta wants to use AI to give people legs in the metaverse Last week, Meta unveiled its latest virtual-reality headset. It has an eye-watering $1,499.99 price tag. At the virtual event, Meta pitched its vision for a “next-generation social platform” accessible to everyone. As my colleague Tanya Basu points out: “Even if you are among the lucky few who can shell out a grand and a half for a virtual-reality headset, would you really want to?” The legs were fake: One of the big selling points for the Metaverse was the ability for avatars to have legs. Legs! At the event, a leggy avatar of Meta CEO Mark Zuckerberg announced that the company was going to use artificial intelligence to enable this feature, allowing avatars not only to walk and run but also to wear digital clothing. But there’s one problem. Meta hasn’t actually figured out how to do this yet, and the “segment featured animations created from motion capture,” as Kotaku reports. Meta’s AI lab is one of the biggest and richest in the industry, and it’s hired some of the field’s top engineers. I can’t imagine that this multibillion-dollar push to make VR Sims happen is very fulfilling work for Meta’s AI researchers. Do you work in AI/ML teams at Meta? I want to hear from you. (Drop me a line melissa.heikkila@technologyreview.com) Learn more about the exploited labor behind artificial intelligenceIn an essay, Timnit Gebru, former co-lead of Google’s ethical AI team, and researchers at her Distributed AI Research Institute argue that AI systems are driven by labor exploitation, and that AI ethics discussions should prioritize transnational worker organization efforts. (Noema) AI-generated art is the new clip artMicrosoft has teamed up with OpenAI to add text-to-image AI DALL-E 2 to its Office suite. Users will be able to enter prompts to create images that can be used in greeting cards or PowerPoint presentations. (The Verge) An AI version of Joe Rogan interviewed an AI Steve JobsThis is pretty mind-blowing. Text-to-voice AI startup Play.ht trained an AI model on Steve Jobs’s biography and all the recordings it could find of him online in order to mimic the way Jobs would have spoken in a real podcast. The content is pretty silly, but it won’t be long until the technology develops enough to fool anyone. (Podcast.ai) Tour Amazon’s dream home, where every appliance is also a spyThis story offers a clever way to visualize how invasive Amazon’s push to embed “smart” devices in our homes really is. (The Washington Post) Tweet of the weekWhat it's like to build a machine-learning startup these days, from Hugging Face CEO and cofounder Clem Delangue. Thanks for making it this far! Catch you next week. Melissa","['receive', 'algorithm', 'inbox', 'sign', 'welcome', 'let', 'introduce', 'philip', 'also', 'know', 'death', 'elon', 'musk', 'assist', 'suicide', 'curious', 'goal', 'want', 'demedicalize', 'death', 'make', 'assist', 'suicide', 'unassisted', 'possible', 'technology', 'colleague', 'report', 'develop', 'coffinsize', 'machine', 'call', 'sarco', 'people', 'seek', 'end', 'life', 'enter', 'machine', 'undergo', 'algorithmbase', 'psychiatric', 'selfassessment', 'pass', 'sarco', 'release', 'nitrogen', 'gas', 'asphyxiate', 'minute', 'person', 'choose', 'die', 'answer', 'question', 'know', 'happen', 'press', 'button', 'assist', 'suicide', 'legal', 'candidate', 'euthanasia', 'demonstrate', 'mental', 'capacity', 'typically', 'assess', 'psychiatrist', 'want', 'take', 'people', 'equation', 'entirely', 'extreme', 'example', 'write', 'ai', 'already', 'use', 'triage', 'treat', 'patient', 'grow', 'number', 'healthcare', 'field', 'algorithm', 'become', 'increasingly', 'important', 'part', 'care', 'try', 'ensure', 'role', 'limit', 'medical', 'decision', 'moral', 'one', 'explore', 'messy', 'morality', 'effort', 'develop', 'help', 'make', 'lifeanddeath', 'decision', '’m', 'probably', 'one', 'feel', 'extremely', 'uneasy', 'let', 'algorithm', 'make', 'decision', 'people', 'live', 'die', '’s', 'work', 'seem', 'classic', 'case', 'misplaced', 'trust', 'algorithm', 'capability', 'try', 'sidestep', 'complicated', 'human', 'judgment', 'introduce', 'technology', 'make', 'supposedly', 'unbiased', 'objective', 'decision', 'dangerous', 'path', 'know', 'lead', 'system', 'reflect', 'human', 'build', 'riddle', 'bias', 'see', 'facial', 'recognition', 'system', 'recognize', 'black', 'people', 'label', 'criminal', 'gorilla', 'tax', 'authority', 'use', 'algorithm', 'try', 'weed', 'benefit', 'fraud', 'penalize', 'innocent', 'people', 'mostly', 'lowerincome', 'people', 'member', 'ethnic', 'minority', 'lead', 'devastating', 'consequence', 'thousand', 'bankruptcy', 'divorce', 'suicide', 'child', 'take', 'foster', 'care', 'ai', 'roll', 'health', 'care', 'help', 'make', 'higheststake', 'decision', '’s', 'crucial', 'ever', 'critically', 'examine', 'system', 'build', 'even', 'manage', 'create', 'perfect', 'algorithm', 'bias', 'algorithm', 'lack', 'nuance', 'complexity', 'make', 'decision', 'human', 'society', 'carefully', 'question', 'much', 'decisionmake', 'really', 'want', 'turn', 'ai', 'inevitable', 'let', 'deeply', 'deeply', 'life', 'society', 'choice', 'make', 'human', 'meta', 'want', 'use', 'give', 'people', 'leg', 'metaverse', 'last', 'week', 'unveil', 'late', 'virtualreality', 'headset', 'eyewatere', 'price', 'tag', 'virtual', 'event', 'meta', 'pitch', 'vision', 'nextgeneration', 'social', 'platform', 'accessible', 'colleague', 'tanya', 'basu', 'point', 'even', 'lucky', 'shell', 'grand', 'half', 'virtualreality', 'headset', 'really', 'want', 'leg', 'fake', 'big', 'selling', 'point', 'metaverse', 'ability', 'avatar', 'leg', 'leg', 'event', 'leggy', 'avatar', 'announce', 'company', 'go', 'use', 'artificial', 'intelligence', 'enable', 'feature', 'allow', 'avatar', 'walk', 'run', 'also', 'wear', 'digital', 'clothing', '’', 'problem', 'meta', 'actually', 'figure', 'yet', 'segment', 'feature', 'animation', 'create', 'motion', 'capture', 'report', 'ai', 'lab', 'big', 'rich', 'industry', 'hire', 'field', 'top', 'engineer', 'imagine', 'multibilliondollar', 'push', 'make', 'vr', 'sim', 'happen', 'fulfil', 'work', 'researcher', 'work', 'aiml', 'team', 'meta', 'want', 'hear', 'drop', 'line', 'melissaheikkilatechnologyreviewcom', 'learn', 'exploit', 'labor', 'artificial', 'essay', 'timnit', 'gebru', 'former', 'colead', 'ethical', 'team', 'researcher', 'distribute', 'argue', 'system', 'drive', 'labor', 'exploitation', 'ai', 'ethic', 'discussion', 'prioritize', 'transnational', 'worker', 'organization', 'effort', 'noema', 'aigenerated', 'art', 'new', 'clip', 'team', 'openai', 'add', 'texttoimage', 'dalle', 'office', 'suite', 'user', 'able', 'enter', 'prompt', 'create', 'image', 'use', 'greet', 'card', 'powerpoint', 'presentation', 'verge', 'version', 'interview', 'pretty', 'mindblowing', 'texttovoice', 'startup', 'train', 'ai', 'model', 'biography', 'recording', 'find', 'online', 'order', 'mimic', 'way', 'job', 'speak', 'real', 'podcast', 'content', 'pretty', 'silly', 'long', 'technology', 'develop', 'enough', 'fool', 'podcastai', 'tour', 'amazon', 'dream', 'home', 'appliance', 'also', 'spythis', 'story', 'offer', 'clever', 'way', 'visualize', 'invasive', 'amazon', 'push', 'embed', 'smart', 'device', 'home', 'really', 'post', 'tweet', 'like', 'build', 'machinelearning', 'startup', 'day', 'hug', 'face', 'ceo', 'cofounder', 'clem', 'delangue', 'thank', 'make', 'far', 'catch', 'next', 'week', 'melissa']"
The messy morality of letting AI make life-and-death decisions,https://www.technologyreview.com/2022/10/13/1060945/artificial-intelligence-life-death-decisions-hard-choices/,2022-10-13,"<p>Automation can help us make hard choices, but it can’t do it alone.</p>
","In a workshop in Rotterdam in the Netherlands, Philip Nitschke—“Dr. Death” or “the Elon Musk of assisted suicide” to some—is overseeing the last few rounds of testing on his new Sarco machine before shipping it to Switzerland, where he says its first user is waiting.  This is the third prototype that Nitschke’s nonprofit, Exit International, has 3D-printed and wired up. Number one has been exhibited in Germany and Poland. “Number two was a disaster,” he says. Now he’s ironed out the manufacturing errors and is ready to launch: “This is the one that will be used.” A coffin-size pod with Star Trek stylings, the Sarco is the culmination of Nitschke’s 25-year campaign to “demedicalize death” through technology. Sealed inside the machine, a person who has chosen to die must answer three questions: Who are you? Where are you? And do you know what will happen when you press that button?  Here’s what will happen: The Sarco will fill with nitrogen gas. Its occupant will pass out in less than a minute and die by asphyxiation in around five.  A recording of that short, final interview will then be handed over to the Swiss authorities. Nitschke has not approached the Swiss government for approval, but Switzerland is one of a handful of countries that have legalized assisted suicide. It is permitted as long as people who wish to die perform the final act themselves.  Nitschke wants to make assisted suicide as unassisted as possible, giving people who have chosen to kill themselves autonomy, and thus dignity, in their final moments. “You really don’t need a doctor to die,” he says.  Because the Sarco uses nitrogen, a widely available gas, rather than the barbiturates that are typically used in euthanasia clinics, it does not require a physician to administer an injection or sign off on lethal drugs.  At least that’s the idea. Nitschke has not yet been able to sidestep the medical establishment fully. Switzerland requires that candidates for euthanasia demonstrate mental capacity, Nitschke says, which is typically assessed by a psychiatrist. “There’s still a belief that if a person is asking to die, they’ve got some sort of undiagnosed mental illness,” he says. “That it’s not rational for a person to seek death.” He believes he has a solution, however. Exit International is working on an algorithm that Nitschke hopes will allow people to perform a kind of psychiatric self-assessment on a computer. In theory, if a person passed this online test, the program would provide a four-digit code to activate the Sarco. “That’s the goal,” says Nitschke. “Having said all that, the project is proving very difficult.”  Nitschke’s mission may seem extreme—even outrageous—to some. And his belief in the power of algorithms may prove to be overblown. But he is not the only one looking to involve technology, and AI in particular, in life-or-death decisions. Yet where Nitschke sees AI as a way to empower individuals to make the ultimate choice by themselves, others wonder if AI can help relieve humans from the burden of such choices. AI is already being used to triage and treat patients across a growing number of health-care fields. As algorithms become an increasingly important part of care, we must ensure that their role is limited to medical decisions, not moral ones. Medical care is a limited resource. Patients must wait for appointments to get tests or treatment. Those in need of organ transplants must wait for suitable hearts or kidneys. Vaccines must be rolled out first to the most vulnerable (in countries that have them). And during the worst of the pandemic, when hospitals faced a shortage of beds and ventilators, doctors had to make snap decisions about who would receive immediate care and who would not—with tragic consequences.  The covid crisis brought the need for such choices into harsh focus—and led many to wonder if algorithms could help. Hospitals around the world bought new or co-opted existing AI tools to assist with triage. Some hospitals in the UK that had been exploring the use of AI tools to screen chest x-rays jumped on those tools as a fast, cheap way to identify the most severe covid cases. Suppliers of this tech, such as Qure.ai, based in Mumbai, India, and Lunit, based in Seoul, Korea, took on contracts in Europe, the US, and Africa. Diagnostic Robotics, an Israeli firm that supplies AI-based triage tools to hospitals in Israel, India, and the US, has said it saw a sevenfold jump in demand for its technology in the first year of the pandemic. Business in health-care AI has been booming ever since.  This rush to automate raises big questions with no easy answers. What kinds of decision is it appropriate to use an algorithm to make? How should these algorithms be built? And who gets a say in how they work?  Rhema Vaithianathan, the director of the Centre for Social Data Analytics and a professor at the Auckland University of Technology in New Zealand, who focuses on tech in health and welfare, thinks it is right that people are asking AI to help make big decisions. “We should be addressing problems that clinicians find really hard,” she says.  One of the projects she is working on involves a teen mental-health service, where young people are diagnosed and treated for self-harming behaviors. There is high demand for the clinic, and so it needs to maintain a high turnover, discharging patients as soon as possible so that more can be brought in.  Doctors face the difficult choice between keeping existing patients in care and treating new ones. “Clinicians don’t discharge people because they’re super scared of them self-harming,” says Vaithianathan. “That’s their nightmare scenario.” Even when AI seems accurate, scholars and regulators alike call for caution. Vaithianathan and her colleagues have tried to develop a machine-learning model that can predict which patients are most at risk of future self-harming behavior and which are not, using a wide range of data, including health records and demographic information, to give doctors an additional resource in their decision-­making. “I’m always looking for those cases where a clinician is struggling and would appreciate an algorithm,” she says.  The project is in its early stages, but so far the researchers have found that there may not be enough data to train a model that can make accurate predictions. They will keep trying. The model does not have to be perfect to help doctors, Vaithianathan says.  They are not the only team trying to predict the risk of discharging patients. A review published in 2021 highlighted 43 studies by researchers claiming to use machine-learning models to predict whether patients will be readmitted or die after they leave hospitals in the US. None were accurate enough for clinical use, but the authors look forward to a time when such models “improve quality of care and reduce health-care costs.”   And yet even when AI seems accurate, scholars and regulators alike call for caution. For one thing, the data that algorithms follow and the way they follow it are human artifacts, riddled with prejudice. Health data is overpopulated by people who are white and male, for example, which skews its predictive power. And the models offer a veneer of objectivity that can lead people to pass the buck on ethical decisions, trusting the machine rather than questioning its output.  This ongoing problem is a theme in David Robinson’s new book, Voices in the Code, about the democratization of AI. Robinson, a visiting scholar at the Social Science Matrix at the University of California, Berkeley, and a member of the faculty of Apple University, tells the story of Belding Scribner. In 1960 Scribner, a nephrologist in Seattle, inserted a short Teflon tube known as a shunt into some of his patients’ arms to prevent their blood from clotting while they underwent dialysis treatment. The innovation allowed people with kidney disease to stay on dialysis indefinitely, transforming kidney failure from a fatal condition into a long-term illness.   When word got out, Scribner was inundated with requests for treatment. But he could not take everyone. Whom should he help and whom should he turn away? He soon realized that this wasn’t a medical decision but an ethical one. He set up a committee of laypeople to decide. Of course, their choices weren’t perfect. The prejudices at the time led the committee to favor married men with jobs and families, for example.  The way Robinson tells it, the lesson we should take from Scribner’s work is that certain processes—bureaucratic, technical, and algorithmic—can make difficult questions seem neutral and objective. They can obscure the moral aspects of a choice—and the sometimes awful consequences. “Bureaucracy itself can serve as a way of converting hard moral problems into boring technical ones,” Robinson writes. This phenomenon predates computers, he says, “but software-based systems can accelerate and amplify this trend. Quantification can be a moral anesthetic, and computers make that anesthetic easier than ever to administer.” Whatever the process, we need to let that moral anesthetic wear off and examine the painful implications of the decision at hand. For Scribner, that meant asking an open panel of laypeople—instead of a group of ostensibly objective doctors meeting behind closed doors—whom to save. Today, it could mean asking for high-stakes algorithms to be audited. For now, the auditing of algorithms by independent parties is more wish-list item than standard practice. But, again using the example of kidney disease, Robinson shows how it can be done.  By the 2000s, an algorithm had been developed in the US to identify recipients for donated kidneys. But some people were unhappy with how the algorithm had been designed. In 2007, Clive Grawe, a kidney transplant candidate from Los Angeles, told a room full of medical experts that their algorithm was biased against older people like him. The algorithm had been designed to allocate kidneys in a way that maximized years of life saved. This favored younger, wealthier, and whiter patients, Grawe and other patients argued. Such bias in algorithms is common. What’s less common is for the designers of those algorithms to agree that there is a problem. After years of consultation with laypeople like Grawe, the designers found a less biased way to maximize the number of years saved—by, among other things, considering overall health in addition to age. One key change was that the majority of donors, who are often people who have died young, would no longer be matched only to recipients in the same age bracket. Some of those kidneys could now go to older people if they were otherwise healthy. As with Scribner’s committee, the algorithm still wouldn’t make decisions that everyone would agree with. But the process by which it was developed is harder to fault.  “I didn’t want to sit there and give the injection. If you want it, you press the button.” Nitschke, too, is asking hard questions.  A former doctor who burned his medical license after a years-long legal dispute with the Australian Medical Board, Nitschke has the distinction of being the first person to legally administer a voluntary lethal injection to another human. In the nine months between July 1996, when the Northern Territory of Australia brought in a law that legalized euthanasia, and March 1997, when Australia’s federal government overturned it, Nitschke helped four of his patients to kill themselves. The first, a 66-year-old carpenter named Bob Dent, who had suffered from prostate cancer for five years, explained his decision in an open letter: “If I were to keep a pet animal in the same condition I am in, I would be prosecuted.”   Nitschke wanted to support his patients’ decisions. Even so, he was uncomfortable with the role they were asking him to play. So he made a machine to take his place. “I didn’t want to sit there and give the injection,” he says. “If you want it, you press the button.” The machine wasn’t much to look at: it was essentially a laptop hooked up to a syringe. But it achieved its purpose. The Sarco is an iteration of that original device, which was later acquired by the Science Museum in London. Nitschke hopes an algorithm that can carry out a psychiatric assessment will be the next step. But there’s a good chance those hopes will be dashed. Creating a program that can assess someone’s mental health is an unsolved problem—and a controversial one. As Nitschke himself notes, doctors do not agree on what it means for a person of sound mind to choose to die. “You can get a dozen different answers from a dozen different psychiatrists,” he says. In other words, there is no common ground on which an algorithm could even be built.  But that’s not the takeaway here. Like Scribner, Nitschke is asking what counts as a medical decision, what counts as an ethical one, and who gets to choose. Scribner thought that laypeople—representing society as a whole—should choose who received dialysis, because when patients have more or less equal chances of survival, who lives and who dies is no longer a technical question. As Robinson describes it, society must be responsible for such decisions, although the process can still be encoded in an algorithm if it’s done inclusively and transparently. For Nitschke, assisted suicide is also an ethical decision, one that individuals must make for themselves. The Sarco, and the theoretical algorithm he imagines, would only protect their ability to do so. AI will become increasingly useful, perhaps essential, as populations boom and resources stretch. Yet the real work will be acknowledging the awfulness and arbitrariness of many of the decisions AI will be called on to make. And that’s on us.  For Robinson, devising algorithms is a bit like legislation: “In a certain light, the question of how best to make software code that will govern people is just a special case of how best to make laws. People disagree about the merits of different ways of making high-stakes software, just as they disagree about the merits of different ways of making laws.” And it is people—in the broadest sense—who are ultimately responsible for the laws we have. ","In a workshop in Rotterdam in the Netherlands, Philip Nitschke—“Dr. Death” or “the Elon Musk of assisted suicide” to some—is overseeing the last few rounds of testing on his new Sarco machine before shipping it to Switzerland, where he says its first user is waiting. This is the third prototype that Nitschke’s nonprofit, Exit International, has 3D-printed and wired up. Number one has been exhibited in Germany and Poland. “Number two was a disaster,” he says. Now he’s ironed out the manufacturing errors and is ready to launch: “This is the one that will be used.” A coffin-size pod with Star Trek stylings, the Sarco is the culmination of Nitschke’s 25-year campaign to “demedicalize death” through technology. Sealed inside the machine, a person who has chosen to die must answer three questions: Who are you? Where are you? And do you know what will happen when you press that button? Here’s what will happen: The Sarco will fill with nitrogen gas. Its occupant will pass out in less than a minute and die by asphyxiation in around five. A recording of that short, final interview will then be handed over to the Swiss authorities. Nitschke has not approached the Swiss government for approval, but Switzerland is one of a handful of countries that have legalized assisted suicide. It is permitted as long as people who wish to die perform the final act themselves. Nitschke wants to make assisted suicide as unassisted as possible, giving people who have chosen to kill themselves autonomy, and thus dignity, in their final moments. “You really don’t need a doctor to die,” he says. Because the Sarco uses nitrogen, a widely available gas, rather than the barbiturates that are typically used in euthanasia clinics, it does not require a physician to administer an injection or sign off on lethal drugs. At least that’s the idea. Nitschke has not yet been able to sidestep the medical establishment fully. Switzerland requires that candidates for euthanasia demonstrate mental capacity, Nitschke says, which is typically assessed by a psychiatrist. “There’s still a belief that if a person is asking to die, they’ve got some sort of undiagnosed mental illness,” he says. “That it’s not rational for a person to seek death.” He believes he has a solution, however. Exit International is working on an algorithm that Nitschke hopes will allow people to perform a kind of psychiatric self-assessment on a computer. In theory, if a person passed this online test, the program would provide a four-digit code to activate the Sarco. “That’s the goal,” says Nitschke. “Having said all that, the project is proving very difficult.” Nitschke’s mission may seem extreme—even outrageous—to some. And his belief in the power of algorithms may prove to be overblown. But he is not the only one looking to involve technology, and AI in particular, in life-or-death decisions. Yet where Nitschke sees AI as a way to empower individuals to make the ultimate choice by themselves, others wonder if AI can help relieve humans from the burden of such choices. AI is already being used to triage and treat patients across a growing number of health-care fields. As algorithms become an increasingly important part of care, we must ensure that their role is limited to medical decisions, not moral ones. Medical care is a limited resource. Patients must wait for appointments to get tests or treatment. Those in need of organ transplants must wait for suitable hearts or kidneys. Vaccines must be rolled out first to the most vulnerable (in countries that have them). And during the worst of the pandemic, when hospitals faced a shortage of beds and ventilators, doctors had to make snap decisions about who would receive immediate care and who would not—with tragic consequences. The covid crisis brought the need for such choices into harsh focus—and led many to wonder if algorithms could help. Hospitals around the world bought new or co-opted existing AI tools to assist with triage. Some hospitals in the UK that had been exploring the use of AI tools to screen chest x-rays jumped on those tools as a fast, cheap way to identify the most severe covid cases. Suppliers of this tech, such as Qure.ai, based in Mumbai, India, and Lunit, based in Seoul, Korea, took on contracts in Europe, the US, and Africa. Diagnostic Robotics, an Israeli firm that supplies AI-based triage tools to hospitals in Israel, India, and the US, has said it saw a sevenfold jump in demand for its technology in the first year of the pandemic. Business in health-care AI has been booming ever since. This rush to automate raises big questions with no easy answers. What kinds of decision is it appropriate to use an algorithm to make? How should these algorithms be built? And who gets a say in how they work? Rhema Vaithianathan, the director of the Centre for Social Data Analytics and a professor at the Auckland University of Technology in New Zealand, who focuses on tech in health and welfare, thinks it is right that people are asking AI to help make big decisions. “We should be addressing problems that clinicians find really hard,” she says. One of the projects she is working on involves a teen mental-health service, where young people are diagnosed and treated for self-harming behaviors. There is high demand for the clinic, and so it needs to maintain a high turnover, discharging patients as soon as possible so that more can be brought in. Doctors face the difficult choice between keeping existing patients in care and treating new ones. “Clinicians don’t discharge people because they’re super scared of them self-harming,” says Vaithianathan. “That’s their nightmare scenario.” Even when AI seems accurate, scholars and regulators alike call for caution. Vaithianathan and her colleagues have tried to develop a machine-learning model that can predict which patients are most at risk of future self-harming behavior and which are not, using a wide range of data, including health records and demographic information, to give doctors an additional resource in their decision-­making. “I’m always looking for those cases where a clinician is struggling and would appreciate an algorithm,” she says. The project is in its early stages, but so far the researchers have found that there may not be enough data to train a model that can make accurate predictions. They will keep trying. The model does not have to be perfect to help doctors, Vaithianathan says. They are not the only team trying to predict the risk of discharging patients. A review published in 2021 highlighted 43 studies by researchers claiming to use machine-learning models to predict whether patients will be readmitted or die after they leave hospitals in the US. None were accurate enough for clinical use, but the authors look forward to a time when such models “improve quality of care and reduce health-care costs.” And yet even when AI seems accurate, scholars and regulators alike call for caution. For one thing, the data that algorithms follow and the way they follow it are human artifacts, riddled with prejudice. Health data is overpopulated by people who are white and male, for example, which skews its predictive power. And the models offer a veneer of objectivity that can lead people to pass the buck on ethical decisions, trusting the machine rather than questioning its output. This ongoing problem is a theme in David Robinson’s new book, Voices in the Code, about the democratization of AI. Robinson, a visiting scholar at the Social Science Matrix at the University of California, Berkeley, and a member of the faculty of Apple University, tells the story of Belding Scribner. In 1960 Scribner, a nephrologist in Seattle, inserted a short Teflon tube known as a shunt into some of his patients’ arms to prevent their blood from clotting while they underwent dialysis treatment. The innovation allowed people with kidney disease to stay on dialysis indefinitely, transforming kidney failure from a fatal condition into a long-term illness. When word got out, Scribner was inundated with requests for treatment. But he could not take everyone. Whom should he help and whom should he turn away? He soon realized that this wasn’t a medical decision but an ethical one. He set up a committee of laypeople to decide. Of course, their choices weren’t perfect. The prejudices at the time led the committee to favor married men with jobs and families, for example. The way Robinson tells it, the lesson we should take from Scribner’s work is that certain processes—bureaucratic, technical, and algorithmic—can make difficult questions seem neutral and objective. They can obscure the moral aspects of a choice—and the sometimes awful consequences. “Bureaucracy itself can serve as a way of converting hard moral problems into boring technical ones,” Robinson writes. This phenomenon predates computers, he says, “but software-based systems can accelerate and amplify this trend. Quantification can be a moral anesthetic, and computers make that anesthetic easier than ever to administer.” Whatever the process, we need to let that moral anesthetic wear off and examine the painful implications of the decision at hand. For Scribner, that meant asking an open panel of laypeople—instead of a group of ostensibly objective doctors meeting behind closed doors—whom to save. Today, it could mean asking for high-stakes algorithms to be audited. For now, the auditing of algorithms by independent parties is more wish-list item than standard practice. But, again using the example of kidney disease, Robinson shows how it can be done. By the 2000s, an algorithm had been developed in the US to identify recipients for donated kidneys. But some people were unhappy with how the algorithm had been designed. In 2007, Clive Grawe, a kidney transplant candidate from Los Angeles, told a room full of medical experts that their algorithm was biased against older people like him. The algorithm had been designed to allocate kidneys in a way that maximized years of life saved. This favored younger, wealthier, and whiter patients, Grawe and other patients argued. Such bias in algorithms is common. What’s less common is for the designers of those algorithms to agree that there is a problem. After years of consultation with laypeople like Grawe, the designers found a less biased way to maximize the number of years saved—by, among other things, considering overall health in addition to age. One key change was that the majority of donors, who are often people who have died young, would no longer be matched only to recipients in the same age bracket. Some of those kidneys could now go to older people if they were otherwise healthy. As with Scribner’s committee, the algorithm still wouldn’t make decisions that everyone would agree with. But the process by which it was developed is harder to fault. “I didn’t want to sit there and give the injection. If you want it, you press the button.” Nitschke, too, is asking hard questions. A former doctor who burned his medical license after a years-long legal dispute with the Australian Medical Board, Nitschke has the distinction of being the first person to legally administer a voluntary lethal injection to another human. In the nine months between July 1996, when the Northern Territory of Australia brought in a law that legalized euthanasia, and March 1997, when Australia’s federal government overturned it, Nitschke helped four of his patients to kill themselves. The first, a 66-year-old carpenter named Bob Dent, who had suffered from prostate cancer for five years, explained his decision in an open letter: “If I were to keep a pet animal in the same condition I am in, I would be prosecuted.” Nitschke wanted to support his patients’ decisions. Even so, he was uncomfortable with the role they were asking him to play. So he made a machine to take his place. “I didn’t want to sit there and give the injection,” he says. “If you want it, you press the button.” The machine wasn’t much to look at: it was essentially a laptop hooked up to a syringe. But it achieved its purpose. The Sarco is an iteration of that original device, which was later acquired by the Science Museum in London. Nitschke hopes an algorithm that can carry out a psychiatric assessment will be the next step. But there’s a good chance those hopes will be dashed. Creating a program that can assess someone’s mental health is an unsolved problem—and a controversial one. As Nitschke himself notes, doctors do not agree on what it means for a person of sound mind to choose to die. “You can get a dozen different answers from a dozen different psychiatrists,” he says. In other words, there is no common ground on which an algorithm could even be built. But that’s not the takeaway here. Like Scribner, Nitschke is asking what counts as a medical decision, what counts as an ethical one, and who gets to choose. Scribner thought that laypeople—representing society as a whole—should choose who received dialysis, because when patients have more or less equal chances of survival, who lives and who dies is no longer a technical question. As Robinson describes it, society must be responsible for such decisions, although the process can still be encoded in an algorithm if it’s done inclusively and transparently. For Nitschke, assisted suicide is also an ethical decision, one that individuals must make for themselves. The Sarco, and the theoretical algorithm he imagines, would only protect their ability to do so. AI will become increasingly useful, perhaps essential, as populations boom and resources stretch. Yet the real work will be acknowledging the awfulness and arbitrariness of many of the decisions AI will be called on to make. And that’s on us. For Robinson, devising algorithms is a bit like legislation: “In a certain light, the question of how best to make software code that will govern people is just a special case of how best to make laws. People disagree about the merits of different ways of making high-stakes software, just as they disagree about the merits of different ways of making laws.” And it is people—in the broadest sense—who are ultimately responsible for the laws we have.","['workshop', 'death', 'elon', 'musk', 'assist', 'suicide', 'oversee', 'last', 'round', 'testing', 'new', 'sarco', 'machine', 'ship', 'switzerland', 'say', 'first', 'user', 'wait', 'third', 'prototype', 'nonprofit', 'exit', 'international', 'wire', 'number', 'exhibit', 'number', 'disaster', 'say', 'iron', 'manufacture', 'error', 'ready', 'launch', 'one', 'use', 'coffinsize', 'pod', 'styling', 'sarco', 'culmination', 'campaign', 'demedicalize', 'death', 'technology', 'seal', 'machine', 'person', 'choose', 'die', 'answer', 'question', 'know', 'happen', 'press', 'button', '’', 'happen', 'fill', 'nitrogen', 'gas', 'occupant', 'pass', 'less', 'minute', 'die', 'asphyxiation', 'around', 'recording', 'short', 'final', 'interview', 'hand', 'swiss', 'authority', 'approach', 'swiss', 'government', 'approval', 'handful', 'country', 'legalize', 'assist', 'suicide', 'permit', 'long', 'people', 'wish', 'die', 'perform', 'final', 'act', 'want', 'make', 'assist', 'suicide', 'unassisted', 'possible', 'give', 'people', 'choose', 'kill', 'autonomy', 'thus', 'dignity', 'final', 'moment', 'really', 'need', 'doctor', 'die', 'say', 'use', 'nitrogen', 'widely', 'available', 'gas', 'rather', 'barbiturate', 'typically', 'use', 'euthanasia', 'clinic', 'require', 'physician', 'administer', 'injection', 'sign', 'lethal', 'drug', 'least', '’', 'idea', 'yet', 'able', 'sidestep', 'medical', 'establishment', 'fully', 'switzerland', 'require', 'candidate', 'euthanasia', 'demonstrate', 'mental', 'capacity', 'say', 'typically', 'assess', 'psychiatrist', '’', 'still', 'belief', 'person', 'ask', 'die', 'get', 'sort', 'undiagnosed', 'mental', 'illness', 'say', '’', 'rational', 'person', 'seek', 'death', 'believe', 'solution', 'exit', 'international', 'work', 'algorithm', 'hope', 'allow', 'people', 'perform', 'kind', 'psychiatric', 'selfassessment', 'computer', 'theory', 'person', 'pass', 'online', 'test', 'program', 'provide', 'fourdigit', 'code', 'activate', '’', 'goal', 'say', 'say', 'project', 'prove', 'difficult', 'mission', 'seem', 'extreme', 'even', 'outrageous', 'belief', 'power', 'algorithm', 'prove', 'overblown', 'look', 'involve', 'technology', 'ai', 'particular', 'lifeordeath', 'decision', 'yet', 'see', 'ai', 'way', 'empower', 'individual', 'make', 'ultimate', 'choice', 'wonder', 'help', 'relieve', 'human', 'burden', 'choice', 'ai', 'already', 'use', 'triage', 'treat', 'patient', 'grow', 'number', 'healthcare', 'field', 'algorithm', 'become', 'increasingly', 'important', 'part', 'care', 'ensure', 'role', 'limit', 'medical', 'decision', 'moral', 'one', 'medical', 'care', 'limited', 'resource', 'patient', 'wait', 'appointment', 'get', 'test', 'treatment', 'need', 'organ', 'transplant', 'wait', 'suitable', 'heart', 'kidney', 'vaccine', 'roll', 'first', 'vulnerable', 'country', 'bad', 'pandemic', 'hospital', 'face', 'shortage', 'bed', 'ventilator', 'doctor', 'make', 'snap', 'decision', 'receive', 'immediate', 'care', 'tragic', 'consequence', 'covid', 'crisis', 'bring', 'need', 'choice', 'harsh', 'focus', 'lead', 'many', 'wonder', 'algorithm', 'help', 'hospital', 'world', 'buy', 'new', 'coopte', 'exist', 'ai', 'tool', 'assist', 'triage', 'hospital', 'explore', 'use', 'ai', 'tool', 'screen', 'chest', 'xray', 'jump', 'tool', 'fast', 'cheap', 'way', 'identify', 'severe', 'covid', 'case', 'supplier', 'tech', 'qureai', 'base', 'base', 'take', 'contract', 'diagnostic', 'robotic', 'israeli', 'firm', 'supply', 'aibased', 'triage', 'tool', 'hospital', 'say', 'see', 'sevenfold', 'jump', 'demand', 'technology', 'first', 'year', 'pandemic', 'business', 'ai', 'boom', 'ever', 'rush', 'automate', 'raise', 'big', 'question', 'easy', 'answer', 'kind', 'decision', 'appropriate', 'use', 'make', 'algorithm', 'build', 'get', 'say', 'work', 'director', 'centre', 'social', 'datum', 'analytic', 'professor', 'auckland', 'technology', 'focus', 'tech', 'health', 'welfare', 'think', 'right', 'people', 'ask', 'ai', 'help', 'make', 'big', 'decision', 'address', 'problem', 'clinician', 'find', 'really', 'hard', 'say', 'project', 'work', 'involve', 'teen', 'mentalhealth', 'service', 'young', 'people', 'diagnose', 'treat', 'selfharme', 'behavior', 'high', 'demand', 'clinic', 'need', 'maintain', 'high', 'turnover', 'discharge', 'patient', 'soon', 'possible', 'bring', 'doctor', 'face', 'difficult', 'choice', 'keep', 'exist', 'patient', 'care', 'treat', 'new', 'one', 'clinician', 'discharge', 'people', '’re', 'super', 'scared', 'selfharme', 'say', '’', 'nightmare', 'scenario', 'even', 'ai', 'seem', 'accurate', 'scholar', 'regulator', 'alike', 'call', 'caution', 'colleague', 'try', 'develop', 'machinelearning', 'model', 'predict', 'patient', 'risk', 'future', 'selfharme', 'behavior', 'use', 'wide', 'range', 'datum', 'include', 'health', 'record', 'demographic', 'information', 'give', 'doctor', 'additional', 'resource', 'decision\xadmaking', 'always', 'look', 'case', 'clinician', 'struggle', 'appreciate', 'algorithm', 'say', 'project', 'early', 'stage', 'far', 'researcher', 'find', 'enough', 'datum', 'train', 'model', 'make', 'accurate', 'prediction', 'keep', 'try', 'model', 'perfect', 'help', 'doctor', 'say', 'team', 'try', 'predict', 'risk', 'discharge', 'patient', 'review', 'publish', 'highlight', 'study', 'researcher', 'claim', 'use', 'machinelearne', 'model', 'predict', 'patient', 'readmitte', 'die', 'leave', 'hospital', 'none', 'accurate', 'enough', 'clinical', 'use', 'author', 'look', 'forward', 'time', 'model', 'improve', 'quality', 'care', 'reduce', 'healthcare', 'cost', 'yet', 'even', 'ai', 'seem', 'accurate', 'scholar', 'regulator', 'alike', 'call', 'caution', 'thing', 'datum', 'algorithm', 'follow', 'way', 'follow', 'human', 'artifact', 'riddle', 'prejudice', 'health', 'datum', 'overpopulate', 'people', 'white', 'male', 'example', 'skew', 'predictive', 'power', 'model', 'offer', 'veneer', 'objectivity', 'lead', 'people', 'pass', 'buck', 'ethical', 'decision', 'trust', 'machine', 'rather', 'question', 'output', 'ongoing', 'problem', 'theme', 'new', 'book', 'voice', 'code', 'democratization', 'robinson', 'visit', 'scholar', 'social', 'science', 'matrix', 'member', 'faculty', 'apple', 'tell', 'story', 'belde', 'scribner', 'scribner', 'nephrologist', 'seattle', 'insert', 'short', 'teflon', 'tube', 'know', 'shunt', 'patient', 'arm', 'prevent', 'blood', 'clot', 'undergo', 'dialysis', 'treatment', 'innovation', 'allow', 'people', 'kidney', 'disease', 'stay', 'dialysis', 'indefinitely', 'transform', 'kidney', 'failure', 'fatal', 'condition', 'longterm', 'illness', 'word', 'get', 'scribner', 'inundate', 'request', 'treatment', 'take', 'help', 'turn', 'away', 'soon', 'realize', 'medical', 'decision', 'ethical', 'one', 'set', 'committee', 'laypeople', 'decide', 'course', 'choice', 'perfect', 'prejudice', 'time', 'lead', 'committee', 'favor', 'married', 'man', 'job', 'family', 'example', 'way', 'robinson', 'tell', 'lesson', 'take', 'work', 'certain', 'process', 'bureaucratic', 'technical', 'algorithmic', 'make', 'difficult', 'question', 'seem', 'neutral', 'objective', 'obscure', 'moral', 'aspect', 'choice', 'sometimes', 'awful', 'consequence', 'bureaucracy', 'serve', 'way', 'convert', 'hard', 'moral', 'problem', 'boring', 'technical', 'one', 'robinson', 'write', 'phenomenon', 'predate', 'computer', 'say', 'softwarebase', 'system', 'accelerate', 'amplify', 'trend', 'quantification', 'moral', 'anesthetic', 'computer', 'make', 'anesthetic', 'easy', 'ever', 'administer', 'process', 'need', 'let', 'moral', 'anesthetic', 'wear', 'examine', 'painful', 'implication', 'decision', 'hand', 'scribner', 'mean', 'ask', 'open', 'panel', 'laypeople', 'instead', 'group', 'ostensibly', 'objective', 'doctor', 'meet', 'closed', 'door', 'save', 'today', 'mean', 'ask', 'highstake', 'algorithm', 'audit', 'auditing', 'algorithm', 'independent', 'party', 'wishlist', 'item', 'standard', 'practice', 'use', 'example', 'show', 'develop', 'identify', 'recipient', 'donate', 'kidney', 'people', 'unhappy', 'design', 'clive', 'grawe', 'kidney', 'transplant', 'candidate', 'tell', 'room', 'full', 'medical', 'expert', 'algorithm', 'bias', 'old', 'people', 'design', 'allocate', 'kidney', 'way', 'maximize', 'year', 'life', 'save', 'favor', 'young', 'wealthy', 'whiter', 'patient', 'grawe', 'patient', 'argue', 'bias', 'algorithm', 'common', 'less', 'common', 'designer', 'algorithm', 'agree', 'problem', 'year', 'consultation', 'laypeople', 'grawe', 'designer', 'find', 'less', 'biased', 'way', 'maximize', 'number', 'year', 'save', 'thing', 'consider', 'overall', 'health', 'addition', 'age', 'key', 'change', 'majority', 'donor', 'often', 'people', 'die', 'young', 'long', 'match', 'recipient', 'age', 'bracket', 'kidney', 'go', 'old', 'people', 'otherwise', 'healthy', 'still', 'make', 'decision', 'agree', 'process', 'develop', 'hard', 'fault', 'want', 'sit', 'give', 'injection', 'want', 'press', 'button', 'nitschke', 'ask', 'hard', 'question', 'former', 'doctor', 'burn', 'medical', 'license', 'yearslong', 'legal', 'dispute', 'australian', 'distinction', 'first', 'person', 'legally', 'administer', 'voluntary', 'lethal', 'injection', 'human', 'month', 'northern', 'territory', 'bring', 'law', 'legalize', 'euthanasia', 'federal', 'government', 'overturn', 'help', 'patient', 'kill', 'first', 'carpenter', 'name', 'suffer', 'prostate', 'cancer', 'year', 'explain', 'decision', 'open', 'letter', 'keep', 'pet', 'animal', 'condition', 'prosecute', 'nitschke', 'want', 'support', 'patient', 'decision', 'even', 'uncomfortable', 'role', 'ask', 'play', 'make', 'machine', 'take', 'place', 'want', 'sit', 'give', 'injection', 'say', 'want', 'press', 'button', 'machine', 'much', 'look', 'essentially', 'laptop', 'hook', 'syringe', 'achieve', 'purpose', 'iteration', 'original', 'device', 'later', 'acquire', 'science', 'museum', 'hope', 'algorithm', 'carry', 'psychiatric', 'assessment', 'next', 'step', '’', 'good', 'chance', 'hope', 'dash', 'create', 'program', 'assess', 'mental', 'health', 'unsolved', 'problem', 'controversial', 'one', 'note', 'doctor', 'agree', 'mean', 'person', 'sound', 'mind', 'choose', 'die', 'get', 'dozen', 'different', 'answer', 'dozen', 'different', 'psychiatrist', 'say', 'word', 'common', 'ground', 'even', 'build', '’', 'takeaway', 'scribner', 'ask', 'count', 'medical', 'decision', 'count', 'ethical', 'one', 'get', 'choose', 'scribner', 'think', 'laypeople', 'represent', 'society', 'whole', 'choose', 'receive', 'dialysis', 'patient', 'less', 'equal', 'chance', 'survival', 'live', 'die', 'long', 'technical', 'question', 'robinson', 'describe', 'society', 'responsible', 'decision', 'process', 'still', 'encode', 'algorithm', 'inclusively', 'transparently', 'nitschke', 'assist', 'suicide', 'also', 'ethical', 'decision', 'individual', 'make', 'theoretical', 'imagine', 'protect', 'ability', 'ai', 'become', 'increasingly', 'useful', 'perhaps', 'essential', 'population', 'boom', 'resource', 'stretch', 'yet', 'real', 'work', 'acknowledge', 'awfulness', 'arbitrariness', 'many', 'decision', 'ai', 'call', 'make', '’', 'robinson', 'devise', 'algorithm', 'bit', 'legislation', 'certain', 'light', 'question', 'good', 'make', 'software', 'code', 'govern', 'people', 'special', 'case', 'good', 'make', 'law', 'people', 'disagree', 'merit', 'different', 'way', 'make', 'highstake', 'software', 'disagree', 'merit', 'different', 'way', 'make', 'law', 'people', 'broad', 'sense', 'ultimately', 'responsible', 'law']"
"Machine learning operations offer agility, spur innovation",https://www.technologyreview.com/2022/10/12/1060890/machine-learning-operations-offer-agility-spur-innovation/,2022-10-12,"Many organizations have adopted machine learning (ML) in a piecemeal fashion, building or buying ad hoc models, algorithms, tools, or services to accomplish specific goals. This approach was necessary as companies learned about the capabilities of ML and as the technology matured, but it also has created a hodge-podge of siloed, manual, and nonstandardized processes…","In association withCapital One Many organizations have adopted machine learning (ML) in a piecemeal fashion, building or buying ad hoc models, algorithms, tools, or services to accomplish specific goals. This approach was necessary as companies learned about the capabilities of ML and as the technology matured, but it also has created a hodge-podge of siloed, manual, and nonstandardized processes and components within organizations. This can lead, in turn, to inefficient, cumbersome services that fail to deliver on their promised value—or that stall innovation entirely.  As businesses look to scale ML applications across the enterprise, they need to better automate and standardize tools, processes, and workflows. They need to build and deploy ML models quickly, spending less time manually training and monitoring models and more time on value-driving, revenue-generating innovation. Developers need access to the data that will power their ML models, to work across lines of business, and to collaborate transparently on the same tech stack. In other words, businesses need to adopt best practices for machine learning operations (MLOps): a set of software development practices that keep ML models running effectively and with agility. The main function of MLOps is to automate the more repeatable steps in the ML workflows of data scientists and ML engineers, from model development and training to model deployment and operation (model serving). Automating these steps creates agility for businesses and better experiences for users and end customers, increasing the speed, power, and reliability of ML. These automated processes can also mitigate risk and free developers from rote tasks, allowing them to spend more time on innovation. This all contributes to the bottom line: a 2021 global study by McKinsey found that companies that successfully scale AI can add as much as 20 percent to their earnings before interest and taxes (EBIT).  “It’s not uncommon for companies with sophisticated ML capabilities to incubate different ML tools in individual pockets of the business,” says Vincent David, senior director for machine learning at Capital One. “But often you start seeing parallels—ML systems doing similar things, but with a slightly different twist. The companies that are figuring out how to make the most of their investments in ML are unifying and supercharging their best ML capabilities to create standardized, foundational tools and platforms that everyone can use — and ultimately create differentiated value in the market.”  In practice, MLOps requires close collaboration between data scientists, ML engineers, and site reliability engineers (SREs) to ensure consistent reproducibility, monitoring, and maintenance of ML models. Over the last several years, Capital One has developed MLOps best practices that apply across industries: balancing user needs, adopting a common, cloud-based technology stack and foundational platforms, leveraging open-source tools, and ensuring the right level of accessibility and governance for both data and models. ML applications generally have two main types of users—technical experts (data scientists and ML engineers) and nontechnical experts (business analysts)—and it’s important to strike a balance between their different needs. Technical experts often prefer complete freedom to use all tools available to build models for their intended use cases. Nontechnical experts, on the other hand, need user-friendly tools that enable them to access the data they need to create value in their own workflows. To build consistent processes and workflows while satisfying both groups, David recommends meeting with the application design team and subject matter experts across a breadth of use cases. “We look at specific cases to understand the issues, so users get what they need to benefit their work, specifically, but also the company generally,” he says. “The key is figuring out how to create the right capabilities while balancing the various stakeholder and business needs within the enterprise.” Collaboration among development teams—critical for successful MLOps—can be difficult and time-consuming if these teams are not using the same technology stack. A unified tech stack allows developers to standardize, reusing components, features, and tools across models like Lego bricks. “That makes it easier to combine related capabilities so developers don’t waste time switching from one model or system to another,” says David.  A cloud-native stack—built to take advantage of the cloud model of distributed computing—allows developers to self-service infrastructure on demand, continually leveraging new capabilities and introducing new services. Capital One’s decision to go all-in on the public cloud has had a notable impact on developer efficiency and speed. Code releases to production now happen much more rapidly, and ML platforms and models are reusable across the broader enterprise. Open-source ML tools (code and programs freely available for anyone to use and adapt) are core ingredients in creating a strong cloud foundation and unified tech stack. Using existing open-source tools means the business does not need to devote precious technical resources to reinventing the wheel, quickening the pace at which teams can build and deploy models.  To complement its use of open-source tools and packages, David says, Capital One also develops and releases its own tools. For example, to manage streams of dynamic data too large to manually monitor, Capital One built an open-source data profiling tool that uses ML to detect and protect sensitive data like bank account and credit card numbers. Additionally, Capital One recently released the open-source library rubicon-ml, which helps capture and store model training and execution information in a repeatable and searchable way. Releasing its own tools as open source ensures that Capital One builds ML capabilities that are flexible and repurposable (by others, as well as across its own businesses) and allows the company to connect with and contribute to the open-source community. A typical ML system includes a production environment (processing data in real-time) and an analytical environment (a store of data with which users can work). For many organizations, the lag time between these environments is a significant pain point. When data scientists and engineers need access to near-real-time data from the production environment, it’s important to set up appropriate controls. ML developers thus need to ensure integration and access to both environments without compromising governance integrity. “In an ideal world, the organization would establish a seamless integration between production data stores and analytical environments that can enforce all the controls and governance frameworks that the data scientists, engineers, and other stakeholders involved in the model governance process need,” says David.  Governing and managing the ML models themselves is equally important. As a machine learns and as input data changes, models tend to drift, which traditionally requires engineers to monitor and correct for that drift. MLOps practices, by contrast, help automate the management and training of models and workflows. An organization adopting MLOps could determine for each ML use case what needs to be monitored, how often, and how much drift to allow before retraining is required. It can then configure tools to automatically detect triggers and retrain models at an appropriate cadence. In the early days of ML, companies took pride in their ability to develop new and bespoke solutions for different parts of the business. But now companies seeking to scale ML in a well-governed, nimble way have to account for continuous updates to data sources, ML models, features, pipelines, and many other aspects of the ML model lifecycle. With its potential to offer standardized, reproducible, and adaptable processes across large-scale ML environments, MLOps could unlock the future of enterprise machine learning. This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. ","In association withCapital One Many organizations have adopted machine learning (ML) in a piecemeal fashion, building or buying ad hoc models, algorithms, tools, or services to accomplish specific goals. This approach was necessary as companies learned about the capabilities of ML and as the technology matured, but it also has created a hodge-podge of siloed, manual, and nonstandardized processes and components within organizations. This can lead, in turn, to inefficient, cumbersome services that fail to deliver on their promised value—or that stall innovation entirely. As businesses look to scale ML applications across the enterprise, they need to better automate and standardize tools, processes, and workflows. They need to build and deploy ML models quickly, spending less time manually training and monitoring models and more time on value-driving, revenue-generating innovation. Developers need access to the data that will power their ML models, to work across lines of business, and to collaborate transparently on the same tech stack. In other words, businesses need to adopt best practices for machine learning operations (MLOps): a set of software development practices that keep ML models running effectively and with agility. The main function of MLOps is to automate the more repeatable steps in the ML workflows of data scientists and ML engineers, from model development and training to model deployment and operation (model serving). Automating these steps creates agility for businesses and better experiences for users and end customers, increasing the speed, power, and reliability of ML. These automated processes can also mitigate risk and free developers from rote tasks, allowing them to spend more time on innovation. This all contributes to the bottom line: a 2021 global study by McKinsey found that companies that successfully scale AI can add as much as 20 percent to their earnings before interest and taxes (EBIT). “It’s not uncommon for companies with sophisticated ML capabilities to incubate different ML tools in individual pockets of the business,” says Vincent David, senior director for machine learning at Capital One. “But often you start seeing parallels—ML systems doing similar things, but with a slightly different twist. The companies that are figuring out how to make the most of their investments in ML are unifying and supercharging their best ML capabilities to create standardized, foundational tools and platforms that everyone can use — and ultimately create differentiated value in the market.” In practice, MLOps requires close collaboration between data scientists, ML engineers, and site reliability engineers (SREs) to ensure consistent reproducibility, monitoring, and maintenance of ML models. Over the last several years, Capital One has developed MLOps best practices that apply across industries: balancing user needs, adopting a common, cloud-based technology stack and foundational platforms, leveraging open-source tools, and ensuring the right level of accessibility and governance for both data and models. ML applications generally have two main types of users—technical experts (data scientists and ML engineers) and nontechnical experts (business analysts)—and it’s important to strike a balance between their different needs. Technical experts often prefer complete freedom to use all tools available to build models for their intended use cases. Nontechnical experts, on the other hand, need user-friendly tools that enable them to access the data they need to create value in their own workflows. To build consistent processes and workflows while satisfying both groups, David recommends meeting with the application design team and subject matter experts across a breadth of use cases. “We look at specific cases to understand the issues, so users get what they need to benefit their work, specifically, but also the company generally,” he says. “The key is figuring out how to create the right capabilities while balancing the various stakeholder and business needs within the enterprise.” Collaboration among development teams—critical for successful MLOps—can be difficult and time-consuming if these teams are not using the same technology stack. A unified tech stack allows developers to standardize, reusing components, features, and tools across models like Lego bricks. “That makes it easier to combine related capabilities so developers don’t waste time switching from one model or system to another,” says David. A cloud-native stack—built to take advantage of the cloud model of distributed computing—allows developers to self-service infrastructure on demand, continually leveraging new capabilities and introducing new services. Capital One’s decision to go all-in on the public cloud has had a notable impact on developer efficiency and speed. Code releases to production now happen much more rapidly, and ML platforms and models are reusable across the broader enterprise. Open-source ML tools (code and programs freely available for anyone to use and adapt) are core ingredients in creating a strong cloud foundation and unified tech stack. Using existing open-source tools means the business does not need to devote precious technical resources to reinventing the wheel, quickening the pace at which teams can build and deploy models. To complement its use of open-source tools and packages, David says, Capital One also develops and releases its own tools. For example, to manage streams of dynamic data too large to manually monitor, Capital One built an open-source data profiling tool that uses ML to detect and protect sensitive data like bank account and credit card numbers. Additionally, Capital One recently released the open-source library rubicon-ml, which helps capture and store model training and execution information in a repeatable and searchable way. Releasing its own tools as open source ensures that Capital One builds ML capabilities that are flexible and repurposable (by others, as well as across its own businesses) and allows the company to connect with and contribute to the open-source community. A typical ML system includes a production environment (processing data in real-time) and an analytical environment (a store of data with which users can work). For many organizations, the lag time between these environments is a significant pain point. When data scientists and engineers need access to near-real-time data from the production environment, it’s important to set up appropriate controls. ML developers thus need to ensure integration and access to both environments without compromising governance integrity. “In an ideal world, the organization would establish a seamless integration between production data stores and analytical environments that can enforce all the controls and governance frameworks that the data scientists, engineers, and other stakeholders involved in the model governance process need,” says David. Governing and managing the ML models themselves is equally important. As a machine learns and as input data changes, models tend to drift, which traditionally requires engineers to monitor and correct for that drift. MLOps practices, by contrast, help automate the management and training of models and workflows. An organization adopting MLOps could determine for each ML use case what needs to be monitored, how often, and how much drift to allow before retraining is required. It can then configure tools to automatically detect triggers and retrain models at an appropriate cadence. In the early days of ML, companies took pride in their ability to develop new and bespoke solutions for different parts of the business. But now companies seeking to scale ML in a well-governed, nimble way have to account for continuous updates to data sources, ML models, features, pipelines, and many other aspects of the ML model lifecycle. With its potential to offer standardized, reproducible, and adaptable processes across large-scale ML environments, MLOps could unlock the future of enterprise machine learning. This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.","['association', 'withcapital', 'many', 'organization', 'adopt', 'machine', 'learn', 'piecemeal', 'fashion', 'building', 'buy', 'ad', 'model', 'algorithm', 'tool', 'service', 'accomplish', 'specific', 'goal', 'approach', 'necessary', 'company', 'learn', 'capability', 'ml', 'technology', 'mature', 'also', 'create', 'hodgepodge', 'siloe', 'manual', 'nonstandardize', 'process', 'component', 'organization', 'lead', 'turn', 'inefficient', 'cumbersome', 'service', 'fail', 'deliver', 'promise', 'value', 'stall', 'innovation', 'entirely', 'business', 'look', 'scale', 'ml', 'application', 'enterprise', 'need', 'well', 'automate', 'standardize', 'tool', 'process', 'workflow', 'need', 'build', 'deploy', 'model', 'quickly', 'spend', 'less', 'time', 'manually', 'train', 'monitoring', 'model', 'time', 'valuedrive', 'revenuegenerate', 'innovation', 'developer', 'need', 'access', 'datum', 'power', 'ml', 'model', 'work', 'line', 'business', 'collaborate', 'transparently', 'tech', 'stack', 'word', 'business', 'need', 'adopt', 'good', 'practice', 'machine', 'learning', 'operation', 'mlop', 'set', 'software', 'development', 'practice', 'keep', 'ml', 'model', 'run', 'effectively', 'agility', 'main', 'function', 'mlop', 'automate', 'repeatable', 'step', 'ml', 'workflow', 'datum', 'scientist', 'ml', 'engineer', 'model', 'development', 'training', 'model', 'deployment', 'operation', 'model', 'serve', 'automate', 'step', 'create', 'agility', 'business', 'well', 'experience', 'user', 'end', 'customer', 'increase', 'speed', 'power', 'reliability', 'ml', 'automate', 'process', 'also', 'mitigate', 'risk', 'free', 'developer', 'rote', 'task', 'allow', 'spend', 'time', 'innovation', 'contribute', 'bottom', 'line', 'global', 'study', 'mckinsey', 'find', 'company', 'successfully', 'scale', 'ai', 'add', 'much', 'percent', 'earning', 'interest', 'taxis', 'ebit', '’', 'uncommon', 'company', 'sophisticated', 'ml', 'capability', 'incubate', 'different', 'ml', 'tool', 'individual', 'pocket', 'business', 'say', 'senior', 'director', 'machine', 'learning', 'capital', 'often', 'start', 'see', 'parallel', 'ml', 'system', 'similar', 'thing', 'slightly', 'different', 'twist', 'company', 'figure', 'make', 'investment', 'unify', 'supercharge', 'good', 'ml', 'capability', 'create', 'standardized', 'foundational', 'tool', 'platform', 'use', 'ultimately', 'create', 'differentiated', 'value', 'market', 'practice', 'mlop', 'require', 'close', 'collaboration', 'datum', 'scientist', 'engineer', 'site', 'reliability', 'engineer', 'sre', 'ensure', 'consistent', 'reproducibility', 'monitoring', 'maintenance', 'model', 'last', 'several', 'year', 'capital', 'develop', 'mlop', 'good', 'practice', 'apply', 'industry', 'balance', 'user', 'need', 'adopt', 'common', 'cloudbase', 'technology', 'stack', 'foundational', 'platform', 'leverage', 'opensource', 'tool', 'ensure', 'right', 'level', 'accessibility', 'governance', 'datum', 'model', 'ml', 'application', 'generally', 'main', 'type', 'user', 'technical', 'expert', 'datum', 'scientist', 'ml', 'engineer', 'nontechnical', 'expert', 'business', 'analyst', '’', 'important', 'strike', 'balance', 'different', 'need', 'technical', 'expert', 'often', 'prefer', 'complete', 'freedom', 'use', 'tool', 'available', 'build', 'model', 'intend', 'use', 'case', 'nontechnical', 'expert', 'hand', 'need', 'userfriendly', 'tool', 'enable', 'access', 'datum', 'need', 'create', 'value', 'workflow', 'build', 'consistent', 'process', 'workflow', 'satisfy', 'group', 'recommend', 'meet', 'application', 'design', 'team', 'subject', 'matter', 'expert', 'breadth', 'use', 'case', 'look', 'specific', 'case', 'understand', 'issue', 'user', 'get', 'need', 'benefit', 'work', 'specifically', 'also', 'company', 'generally', 'say', 'key', 'figure', 'create', 'right', 'capability', 'balance', 'various', 'stakeholder', 'business', 'need', 'enterprise', 'collaboration', 'development', 'team', 'critical', 'successful', 'mlop', 'difficult', 'timeconsuming', 'team', 'use', 'technology', 'stack', 'unified', 'tech', 'stack', 'allow', 'developer', 'standardize', 'reuse', 'component', 'feature', 'tool', 'model', 'lego', 'brick', 'make', 'easy', 'combine', 'related', 'capability', 'developer', 'waste', 'time', 'switch', 'model', 'system', 'say', 'cloudnative', 'stack', 'build', 'take', 'advantage', 'cloud', 'model', 'distribute', 'computing', 'allow', 'developer', 'selfservice', 'infrastructure', 'demand', 'continually', 'leverage', 'new', 'capability', 'introduce', 'new', 'service', 'capital', 'decision', 'go', 'allin', 'public', 'cloud', 'notable', 'impact', 'developer', 'efficiency', 'speed', 'code', 'release', 'production', 'happen', 'much', 'rapidly', 'platform', 'model', 'reusable', 'broad', 'enterprise', 'opensource', 'tool', 'code', 'program', 'freely', 'available', 'use', 'adapt', 'core', 'ingredient', 'create', 'strong', 'cloud', 'foundation', 'unified', 'tech', 'stack', 'use', 'exist', 'opensource', 'tool', 'mean', 'business', 'need', 'devote', 'precious', 'technical', 'resource', 'reinvent', 'wheel', 'quicken', 'pace', 'team', 'build', 'deploy', 'model', 'complement', 'use', 'opensource', 'tool', 'package', 'say', 'also', 'develop', 'release', 'tool', 'example', 'manage', 'stream', 'dynamic', 'datum', 'large', 'manually', 'monitor', 'capital', 'build', 'opensource', 'datum', 'profile', 'tool', 'use', 'ml', 'detect', 'protect', 'sensitive', 'datum', 'bank', 'account', 'credit', 'card', 'number', 'additionally', 'capital', 'recently', 'release', 'help', 'capture', 'store', 'model', 'training', 'execution', 'information', 'repeatable', 'searchable', 'way', 'release', 'tool', 'open', 'source', 'ensure', 'capital', 'build', 'ml', 'capability', 'flexible', 'repurposable', 'well', 'business', 'allow', 'company', 'connect', 'contribute', 'opensource', 'community', 'typical', 'ml', 'system', 'include', 'production', 'environment', 'process', 'datum', 'realtime', 'analytical', 'environment', 'store', 'datum', 'user', 'work', 'many', 'organization', 'lag', 'time', 'environment', 'significant', 'pain', 'point', 'data', 'scientist', 'engineer', 'need', 'access', 'nearrealtime', 'datum', 'production', 'environment', '’', 'important', 'set', 'appropriate', 'control', 'developer', 'thus', 'need', 'ensure', 'integration', 'access', 'environment', 'compromise', 'governance', 'integrity', 'ideal', 'world', 'organization', 'establish', 'seamless', 'integration', 'production', 'datum', 'store', 'analytical', 'environment', 'enforce', 'control', 'governance', 'framework', 'datum', 'scientist', 'engineer', 'stakeholder', 'involve', 'model', 'governance', 'process', 'need', 'say', 'govern', 'manage', 'model', 'equally', 'important', 'machine', 'learn', 'input', 'data', 'change', 'model', 'tend', 'drift', 'traditionally', 'require', 'engineer', 'monitor', 'correct', 'drift', 'mlop', 'practice', 'contrast', 'help', 'automate', 'management', 'training', 'model', 'workflow', 'organization', 'adopt', 'mlop', 'determine', 'ml', 'use', 'case', 'need', 'monitor', 'often', 'much', 'drift', 'allow', 'retraining', 'require', 'configure', 'tool', 'automatically', 'detect', 'trigger', 'retrain', 'model', 'appropriate', 'cadence', 'early', 'day', 'ml', 'company', 'take', 'pride', 'ability', 'develop', 'new', 'bespoke', 'solution', 'different', 'part', 'business', 'company', 'seek', 'scale', 'ml', 'wellgoverne', 'nimble', 'way', 'account', 'continuous', 'update', 'datum', 'source', 'model', 'feature', 'pipeline', 'many', 'aspect', 'model', 'lifecycle', 'potential', 'offer', 'standardized', 'reproducible', 'adaptable', 'process', 'largescale', 'ml', 'environment', 'mlop', 'unlock', 'future', 'enterprise', 'machine', 'learn', 'content', 'produce', 'insight', 'custom', 'content', 'arm', 'mit', 'technology', 'review', 'write', 'mit', 'technology', 'review', 'editorial', 'staff']"
Who’s going to save us from bad AI?,https://www.technologyreview.com/2022/10/10/1061016/whos-going-to-save-us-from-bad-ai/,2022-10-10,"<p>Plus: DeepMind does math.</p>
","To receive The Algorithm in your inbox every Monday, sign up here. Welcome to the Algorithm!  About damn time. That was the response from AI policy and ethics wonks to news last week that the Office of Science and Technology Policy, the White House’s science and technology advisory agency, had unveiled an AI Bill of Rights. The document is Biden’s vision of how the US government, technology companies, and citizens should work together to hold the AI sector accountable.  It’s a great initiative, and long overdue. The US has so far been one of the only Western nations without clear guidance on how to protect its citizens against AI harms. (As a reminder, these harms include wrongful arrests, suicides, and entire cohorts of schoolchildren being marked unjustly by an algorithm. And that’s just for starters.)   Tech companies say they want to mitigate these sorts of harms, but it’s really hard to hold them to account.  The AI Bill of Rights outlines five protections Americans should have in the AI age, including data privacy, the right to be protected from unsafe systems, and assurances that algorithms shouldn’t be discriminatory and that there will always be a human alternative. Read more about it here. So here’s the good news: The White House has demonstrated mature thinking about different kinds of AI harms, and this should filter down to how the federal government thinks about technology risks more broadly. The EU is pressing on with regulations that ambitiously try to mitigate all AI harms. That’s great but incredibly hard to do, and it could take years before their AI law, called the AI Act, is ready. The US, on the other hand, “can tackle one problem at a time,” and individual agencies can learn to handle AI challenges as they arise, says Alex Engler, who researches AI governance at the Brookings Institution, a DC think tank.  And the bad: The AI Bill of Rights is missing some pretty important areas of harm, such as law enforcement and worker surveillance. And unlike the actual US Bill of Rights, the AI Bill of Rights is more an enthusiastic recommendation than a binding law. “Principles are frankly not enough,” says Courtney Radsch, US tech policy expert for the human rights organization Article 19. “In the absence of, for example, a national privacy law that sets some boundaries, it’s only going part of the way,” she adds.  The US is walking on a tightrope. On the one hand, America doesn’t want to seem weak on the global stage when it comes to this issue. The US plays perhaps the most important role in AI harm mitigation, since most of the world’s biggest and richest AI companies are American. But that’s the problem. Globally, the US has to lobby against rules that would set limits on its tech giants, and domestically it’s loath to introduce any regulation that could potentially “hinder innovation.”  The next two years will be critical for global AI policy. If the Democrats don’t win a second term in the 2024 presidential election, it is very possible that these efforts will be abandoned. New people with new priorities might drastically change the progress made so far, or take things in a completely different direction. Nothing is impossible.  DeepMind’s game-playing AI has beaten a 50-year-old record in computer science They’ve done it again: AI lab DeepMind has used its board-game playing AI AlphaZero to discover a faster way to solve a fundamental math problem in computer science, beating a record that has stood for more than 50 years. The researchers trained a new version of AlphaZero, called AlphaTensor, to play a game that learned the best series of steps to solve the math problem. It was rewarded for winning the game in as few moves as possible. Why this is a big deal: The problem, matrix multiplication, is a crucial type of calculation at the heart of many different applications, from displaying images on a screen to simulating complex physics. It is also fundamental to machine learning itself. Speeding up this calculation could have a big impact on thousands of everyday computer tasks, cutting costs and saving energy. Read more from my colleague Will Heaven here. Google released an impressive text-to-video AIJust a week after Meta’s text-to-image AI reveal, Google has upped the ante. The videos that its system Imagen Video produces are of much higher definition than Meta’s. But, like Meta, Google is not releasing its model into the wild, because of “social biases and stereotypes which are challenging to detect and filter.” (Google) Google’s new AI can hear a snippet of a song—and then keep on playingThe technique, called AudioLM, generates naturalistic sounds without the need for human annotation. (MIT Technology Review) Even after $100 billion, self-driving cars are going nowhereWhat a quote from Anthony Levandowski, one of the field’s biggest stars: ""Forget about profits—what’s the combined revenue of all the [AV] companies? Is it a million dollars? Maybe. I think it’s more like zero."" (Bloomberg Businessweek) Robotics companies have pledged not to weaponize their techSix of the largest robotics companies in the world, including Boston Dynamics, have pledged not to weaponize their robots. (Unless, of course, it is for governments’ defense purposes.)  Meanwhile, defense AI startup Anduril says it has developed loitering munitions, also known as suicide drones, and this is apparently just the start of its new weapons program. I wrote last summer about how business is booming for military AI startups. The invasion of Ukraine has prompted militaries to update their arsenals—and Silicon Valley stands to capitalize. (MIT Technology Review) This is life in the MetaverseA fun story about life in the Metaverse and its early adopters. This is the first Metaverse story where I could kinda see the appeal of it. (But didn't make me want to plug and play anytime soon.) (The New York Times)  There’s a new AI that allows you to create interiorsThe model was built in five days using the open-source text-to-image model Stable Diffusion to generate snazzy interiors. It’s great to see people using the model to build new applications. On the downside, I can totally see this tech being used for Airbnb and real estate scams. (InteriorAI) See you next time, Melissa ","To receive The Algorithm in your inbox every Monday, sign up here. Welcome to the Algorithm! About damn time. That was the response from AI policy and ethics wonks to news last week that the Office of Science and Technology Policy, the White House’s science and technology advisory agency, had unveiled an AI Bill of Rights. The document is Biden’s vision of how the US government, technology companies, and citizens should work together to hold the AI sector accountable. It’s a great initiative, and long overdue. The US has so far been one of the only Western nations without clear guidance on how to protect its citizens against AI harms. (As a reminder, these harms include wrongful arrests, suicides, and entire cohorts of schoolchildren being marked unjustly by an algorithm. And that’s just for starters.) Tech companies say they want to mitigate these sorts of harms, but it’s really hard to hold them to account. The AI Bill of Rights outlines five protections Americans should have in the AI age, including data privacy, the right to be protected from unsafe systems, and assurances that algorithms shouldn’t be discriminatory and that there will always be a human alternative. Read more about it here. So here’s the good news: The White House has demonstrated mature thinking about different kinds of AI harms, and this should filter down to how the federal government thinks about technology risks more broadly. The EU is pressing on with regulations that ambitiously try to mitigate all AI harms. That’s great but incredibly hard to do, and it could take years before their AI law, called the AI Act, is ready. The US, on the other hand, “can tackle one problem at a time,” and individual agencies can learn to handle AI challenges as they arise, says Alex Engler, who researches AI governance at the Brookings Institution, a DC think tank. And the bad: The AI Bill of Rights is missing some pretty important areas of harm, such as law enforcement and worker surveillance. And unlike the actual US Bill of Rights, the AI Bill of Rights is more an enthusiastic recommendation than a binding law. “Principles are frankly not enough,” says Courtney Radsch, US tech policy expert for the human rights organization Article 19. “In the absence of, for example, a national privacy law that sets some boundaries, it’s only going part of the way,” she adds. The US is walking on a tightrope. On the one hand, America doesn’t want to seem weak on the global stage when it comes to this issue. The US plays perhaps the most important role in AI harm mitigation, since most of the world’s biggest and richest AI companies are American. But that’s the problem. Globally, the US has to lobby against rules that would set limits on its tech giants, and domestically it’s loath to introduce any regulation that could potentially “hinder innovation.” The next two years will be critical for global AI policy. If the Democrats don’t win a second term in the 2024 presidential election, it is very possible that these efforts will be abandoned. New people with new priorities might drastically change the progress made so far, or take things in a completely different direction. Nothing is impossible. DeepMind’s game-playing AI has beaten a 50-year-old record in computer science They’ve done it again: AI lab DeepMind has used its board-game playing AI AlphaZero to discover a faster way to solve a fundamental math problem in computer science, beating a record that has stood for more than 50 years. The researchers trained a new version of AlphaZero, called AlphaTensor, to play a game that learned the best series of steps to solve the math problem. It was rewarded for winning the game in as few moves as possible. Why this is a big deal: The problem, matrix multiplication, is a crucial type of calculation at the heart of many different applications, from displaying images on a screen to simulating complex physics. It is also fundamental to machine learning itself. Speeding up this calculation could have a big impact on thousands of everyday computer tasks, cutting costs and saving energy. Read more from my colleague Will Heaven here. Google released an impressive text-to-video AIJust a week after Meta’s text-to-image AI reveal, Google has upped the ante. The videos that its system Imagen Video produces are of much higher definition than Meta’s. But, like Meta, Google is not releasing its model into the wild, because of “social biases and stereotypes which are challenging to detect and filter.” (Google) Google’s new AI can hear a snippet of a song—and then keep on playingThe technique, called AudioLM, generates naturalistic sounds without the need for human annotation. (MIT Technology Review) Even after $100 billion, self-driving cars are going nowhereWhat a quote from Anthony Levandowski, one of the field’s biggest stars: ""Forget about profits—what’s the combined revenue of all the [AV] companies? Is it a million dollars? Maybe. I think it’s more like zero."" (Bloomberg Businessweek) Robotics companies have pledged not to weaponize their techSix of the largest robotics companies in the world, including Boston Dynamics, have pledged not to weaponize their robots. (Unless, of course, it is for governments’ defense purposes.) Meanwhile, defense AI startup Anduril says it has developed loitering munitions, also known as suicide drones, and this is apparently just the start of its new weapons program. I wrote last summer about how business is booming for military AI startups. The invasion of Ukraine has prompted militaries to update their arsenals—and Silicon Valley stands to capitalize. (MIT Technology Review) This is life in the MetaverseA fun story about life in the Metaverse and its early adopters. This is the first Metaverse story where I could kinda see the appeal of it. (But didn't make me want to plug and play anytime soon.) (The New York Times) There’s a new AI that allows you to create interiorsThe model was built in five days using the open-source text-to-image model Stable Diffusion to generate snazzy interiors. It’s great to see people using the model to build new applications. On the downside, I can totally see this tech being used for Airbnb and real estate scams. (InteriorAI) See you next time, Melissa","['receive', 'algorithm', 'inbox', 'sign', 'welcome', 'damn', 'time', 'response', 'policy', 'ethic', 'wonk', 'news', 'last', 'week', 'office', 'science', 'technology', 'policy', 'science', 'technology', 'advisory', 'agency', 'unveil', 'ai', 'bill', 'right', 'document', 'vision', 'government', 'technology', 'company', 'citizen', 'work', 'together', 'hold', 'ai', 'sector', 'accountable', '’', 'great', 'initiative', 'long', 'overdue', 'far', 'western', 'nation', 'clear', 'guidance', 'protect', 'citizen', 'harm', 'reminder', 'harm', 'include', 'wrongful', 'arrest', 'suicide', 'entire', 'cohort', 'schoolchildren', 'mark', 'unjustly', 'algorithm', '’', 'starter', 'tech', 'company', 'say', 'want', 'mitigate', 'sort', 'harm', '’', 'really', 'hard', 'hold', 'account', 'bill', 'right', 'outline', 'protection', 'ai', 'age', 'include', 'datum', 'privacy', 'right', 'protect', 'unsafe', 'system', 'assurance', 'algorithm', 'discriminatory', 'always', 'human', 'alternative', 'read', '’', 'good', 'news', 'demonstrate', 'mature', 'thinking', 'different', 'kind', 'harm', 'filter', 'federal', 'government', 'think', 'technology', 'risk', 'broadly', 'press', 'regulation', 'ambitiously', 'try', 'mitigate', 'harm', '’', 'great', 'incredibly', 'hard', 'take', 'year', 'ai', 'law', 'call', 'act', 'ready', 'hand', 'tackle', 'problem', 'time', 'individual', 'agency', 'learn', 'handle', 'ai', 'challenge', 'arise', 'say', 'research', 'governance', 'brooking', 'institution', 'think', 'tank', 'bad', 'bill', 'right', 'miss', 'pretty', 'important', 'area', 'harm', 'law', 'enforcement', 'worker', 'surveillance', 'actual', 'bill', 'right', 'bill', 'right', 'enthusiastic', 'recommendation', 'bind', 'law', 'principle', 'frankly', 'enough', 'say', 'courtney', 'radsch', 'tech', 'policy', 'expert', 'article', 'absence', 'example', 'national', 'privacy', 'law', 'set', 'boundary', 'go', 'part', 'way', 'add', 'walk', 'tightrope', 'hand', 'want', 'seem', 'weak', 'global', 'stage', 'come', 'issue', 'play', 'perhaps', 'important', 'role', 'harm', 'mitigation', 'world', 'big', 'rich', 'company', 'american', '’', 'problem', 'globally', 'lobby', 'rule', 'set', 'limit', 'tech', 'giant', 'domestically', '’', 'loath', 'introduce', 'regulation', 'potentially', 'hinder', 'innovation', 'next', 'year', 'critical', 'global', 'policy', 'win', 'second', 'term', 'presidential', 'election', 'possible', 'effort', 'abandon', 'new', 'people', 'new', 'priority', 'drastically', 'change', 'progress', 'make', 'far', 'take', 'thing', 'completely', 'different', 'direction', 'impossible', 'deepmind', '’s', 'gameplaying', 'ai', 'beat', 'record', 'computer', 'science', 'lab', 'deepmind', 'use', 'boardgame', 'play', 'ai', 'alphazero', 'discover', 'fast', 'way', 'solve', 'fundamental', 'math', 'problem', 'computer', 'science', 'beat', 'record', 'stand', 'year', 'researcher', 'train', 'new', 'version', 'alphazero', 'call', 'alphatensor', 'play', 'game', 'learn', 'good', 'series', 'step', 'solve', 'math', 'problem', 'reward', 'win', 'game', 'move', 'possible', 'big', 'deal', 'problem', 'matrix', 'multiplication', 'crucial', 'type', 'calculation', 'heart', 'many', 'different', 'application', 'display', 'image', 'screen', 'simulate', 'complex', 'physics', 'also', 'fundamental', 'machine', 'learn', 'speed', 'calculation', 'big', 'impact', 'thousand', 'everyday', 'computer', 'task', 'cut', 'cost', 'save', 'energy', 'read', 'colleague', 'heaven', 'release', 'impressive', 'texttovideo', 'aijust', 'week', 'texttoimage', 'reveal', 'ante', 'video', 'system', 'imagen', 'video', 'produce', 'much', 'high', 'definition', 'meta', 'google', 'release', 'model', 'wild', 'social', 'bias', 'stereotype', 'challenge', 'detect', 'filter', 'new', 'ai', 'hear', 'snippet', 'song', 'keep', 'playingthe', 'technique', 'call', 'generate', 'naturalistic', 'sound', 'need', 'human', 'annotation', 'mit', 'technology', 'review', 'even', 'selfdriving', 'car', 'go', 'quote', 'field', 'big', 'star', 'forget', 'profit', '’', 'combined', 'revenue', 'av', 'company', 'dollar', 'maybe', 'think', '’', 'bloomberg', 'businessweek', 'robotic', 'company', 'pledge', 'weaponize', 'techsix', 'large', 'robotic', 'company', 'world', 'include', 'dynamic', 'pledge', 'weaponize', 'robot', 'course', 'government', 'defense', 'purpose', 'meanwhile', 'defense', 'startup', 'anduril', 'say', 'develop', 'loitering', 'munition', 'also', 'know', 'suicide', 'drone', 'apparently', 'start', 'new', 'weapon', 'program', 'write', 'last', 'summer', 'business', 'boom', 'military', 'ai', 'startup', 'invasion', 'prompt', 'military', 'update', 'arsenal', 'stand', 'capitalize', 'mit', 'technology', 'review', 'life', 'metaversea', 'fun', 'story', 'life', 'metaverse', 'early', 'adopter', 'first', 'metaverse', 'story', 'kinda', 'see', 'appeal', 'make', 'want', 'plug', 'play', 'anytime', 'soon', 'time', '’', 'new', 'ai', 'allow', 'create', 'model', 'build', 'day', 'use', 'opensource', 'texttoimage', 'model', 'stable', 'diffusion', 'generate', 'snazzy', 'interior', '’', 'great', 'see', 'people', 'use', 'model', 'build', 'new', 'application', 'downside', 'totally', 'see', 'tech', 'use', 'airbnb', 'real', 'estate', 'scam', 'interiorai', 'see', 'next', 'time', 'melissa']"
Google’s new AI can hear a snippet of song—and then keep on playing,https://www.technologyreview.com/2022/10/07/1060897/ai-audio-generation/,2022-10-07,"<p>The technique, called AudioLM, generates naturalistic sounds without the need for human annotation.</p>
","A new AI system can create natural-sounding speech and music after being prompted with a few seconds of audio. AudioLM, developed by Google researchers, generates audio that fits the style of the prompt, including complex sounds like piano music, or people speaking, in a way that is almost indistinguishable from the original recording. The technique shows promise for speeding up the process of training AI to generate audio, and it could eventually be used to auto-generate music to accompany videos. (You can listen to all of the examples here.) AI-generated audio is commonplace: voices on home assistants like Alexa use natural language processing. AI music systems like OpenAI’s Jukebox have already generated impressive results, but most existing techniques need people to prepare transcriptions and label text-based training data, which takes a lot of time and human labor. Jukebox, for example, uses text-based data to generate song lyrics. AudioLM, described in a non-peer-reviewed paper last month, is different: it doesn’t require transcription or labeling. Instead, sound databases are fed into the program, and machine learning is used to compress the audio files into sound snippets, called “tokens,” without losing too much information. This tokenized training data is then fed into a machine-learning model that uses natural language processing to learn the sound’s patterns.  To generate the audio, a few seconds of sound are fed into AudioLM, which then predicts what comes next. The process is similar to the way language models like GPT-3 predict what sentences and words typically follow one another.  The audio clips released by the team sound pretty natural. In particular, piano music generated using AudioLM sounds more fluid than piano music generated using existing AI techniques, which tends to sound chaotic. A new wave of startups are using deep learning to build synthetic voice actors for digital assistants, video-game characters, and corporate videos. Roger Dannenberg, who researches computer-generated music at Carnegie Mellon University, says AudioLM already has much better sound quality than previous music generation programs. In particular, he says, AudioLM is surprisingly good at re-creating some of the repeating patterns inherent in human-made music. To generate realistic piano music, AudioLM has to capture a lot of the subtle vibrations contained in each note when piano keys are struck. The music also has to sustain its rhythms and harmonies over a period of time. “That’s really impressive, partly because it indicates that they are learning some kinds of structure at multiple levels,” Dannenberg says. AudioLM isn’t only confined to music. Because it was trained on a library of recordings of humans speaking sentences, the system can also generate speech that continues in the accent and cadence of the original speaker—although at this point those sentences can still seem like non sequiturs that don’t make any sense. AudioLM is trained to learn what types of sound snippets occur frequently together, and it uses the process in reverse to produce sentences. It also has the advantage of being able to learn the pauses and exclamations that are inherent in spoken languages but not easily translated into text.  Rupal Patel, who researches information and speech science at Northeastern University, says that previous work using AI to generate audio could capture those nuances only if they were explicitly annotated in training data. In contrast, AudioLM learns those characteristics from the input data automatically, which adds to the realistic effect. “There is a lot of what we could call linguistic information that is not in the words that you pronounce, but it’s another way of communicating based on the way you say things to express a specific intention or specific emotion,” says Neil Zeghidour, a co-creator of AudioLM. For example, someone may laugh after saying something to indicate that it was a joke. “All that makes speech natural,” he says. Eventually, AI-generated music could be used to provide more natural-sounding background soundtracks for videos and slideshows. Speech generation technology that sounds more natural could help improve internet accessibility tools and bots that work in health care settings, says Patel. The team also hopes to create more sophisticated sounds, like a band with different instruments or sounds that mimic a recording of a tropical rainforest. However, the technology’s ethical implications need to be considered, Patel says. In particular, it’s important to determine whether the musicians who produce the clips used as training data will get attribution or royalties from the end product—an issue that has cropped up with text-to-image AIs. AI-generated speech that’s indistinguishable from the real thing could also become so convincing that it enables the spread of misinformation more easily. In the paper, the researchers write that they are already considering and working to mitigate these issues—for example, by developing techniques to distinguish natural sounds from sounds produced using AudioLM. Patel also suggested including audio watermarks in AI-generated products to make them easier to distinguish from natural audio. ","A new AI system can create natural-sounding speech and music after being prompted with a few seconds of audio. AudioLM, developed by Google researchers, generates audio that fits the style of the prompt, including complex sounds like piano music, or people speaking, in a way that is almost indistinguishable from the original recording. The technique shows promise for speeding up the process of training AI to generate audio, and it could eventually be used to auto-generate music to accompany videos. (You can listen to all of the examples here.) AI-generated audio is commonplace: voices on home assistants like Alexa use natural language processing. AI music systems like OpenAI’s Jukebox have already generated impressive results, but most existing techniques need people to prepare transcriptions and label text-based training data, which takes a lot of time and human labor. Jukebox, for example, uses text-based data to generate song lyrics. AudioLM, described in a non-peer-reviewed paper last month, is different: it doesn’t require transcription or labeling. Instead, sound databases are fed into the program, and machine learning is used to compress the audio files into sound snippets, called “tokens,” without losing too much information. This tokenized training data is then fed into a machine-learning model that uses natural language processing to learn the sound’s patterns. To generate the audio, a few seconds of sound are fed into AudioLM, which then predicts what comes next. The process is similar to the way language models like GPT-3 predict what sentences and words typically follow one another. The audio clips released by the team sound pretty natural. In particular, piano music generated using AudioLM sounds more fluid than piano music generated using existing AI techniques, which tends to sound chaotic. A new wave of startups are using deep learning to build synthetic voice actors for digital assistants, video-game characters, and corporate videos. Roger Dannenberg, who researches computer-generated music at Carnegie Mellon University, says AudioLM already has much better sound quality than previous music generation programs. In particular, he says, AudioLM is surprisingly good at re-creating some of the repeating patterns inherent in human-made music. To generate realistic piano music, AudioLM has to capture a lot of the subtle vibrations contained in each note when piano keys are struck. The music also has to sustain its rhythms and harmonies over a period of time. “That’s really impressive, partly because it indicates that they are learning some kinds of structure at multiple levels,” Dannenberg says. AudioLM isn’t only confined to music. Because it was trained on a library of recordings of humans speaking sentences, the system can also generate speech that continues in the accent and cadence of the original speaker—although at this point those sentences can still seem like non sequiturs that don’t make any sense. AudioLM is trained to learn what types of sound snippets occur frequently together, and it uses the process in reverse to produce sentences. It also has the advantage of being able to learn the pauses and exclamations that are inherent in spoken languages but not easily translated into text. Rupal Patel, who researches information and speech science at Northeastern University, says that previous work using AI to generate audio could capture those nuances only if they were explicitly annotated in training data. In contrast, AudioLM learns those characteristics from the input data automatically, which adds to the realistic effect. “There is a lot of what we could call linguistic information that is not in the words that you pronounce, but it’s another way of communicating based on the way you say things to express a specific intention or specific emotion,” says Neil Zeghidour, a co-creator of AudioLM. For example, someone may laugh after saying something to indicate that it was a joke. “All that makes speech natural,” he says. Eventually, AI-generated music could be used to provide more natural-sounding background soundtracks for videos and slideshows. Speech generation technology that sounds more natural could help improve internet accessibility tools and bots that work in health care settings, says Patel. The team also hopes to create more sophisticated sounds, like a band with different instruments or sounds that mimic a recording of a tropical rainforest. However, the technology’s ethical implications need to be considered, Patel says. In particular, it’s important to determine whether the musicians who produce the clips used as training data will get attribution or royalties from the end product—an issue that has cropped up with text-to-image AIs. AI-generated speech that’s indistinguishable from the real thing could also become so convincing that it enables the spread of misinformation more easily. In the paper, the researchers write that they are already considering and working to mitigate these issues—for example, by developing techniques to distinguish natural sounds from sounds produced using AudioLM. Patel also suggested including audio watermarks in AI-generated products to make them easier to distinguish from natural audio.","['new', 'ai', 'system', 'create', 'naturalsounde', 'speech', 'music', 'prompt', 'second', 'audio', 'audiolm', 'develop', 'researcher', 'generate', 'audio', 'fit', 'style', 'prompt', 'include', 'complex', 'sound', 'piano', 'music', 'people', 'speak', 'way', 'almost', 'indistinguishable', 'original', 'recording', 'technique', 'show', 'promise', 'speed', 'process', 'training', 'ai', 'generate', 'audio', 'eventually', 'use', 'autogenerate', 'music', 'accompany', 'video', 'listen', 'example', 'aigenerate', 'audio', 'commonplace', 'voice', 'home', 'assistant', 'alexa', 'use', 'natural', 'language', 'processing', 'ai', 'music', 'system', 'already', 'generate', 'impressive', 'result', 'exist', 'technique', 'need', 'people', 'prepare', 'transcription', 'label', 'textbase', 'training', 'datum', 'take', 'lot', 'time', 'human', 'labor', 'jukebox', 'example', 'use', 'textbase', 'datum', 'generate', 'song', 'lyric', 'describe', 'nonpeerreviewed', 'paper', 'last', 'month', 'different', 'require', 'transcription', 'labeling', 'instead', 'sound', 'database', 'feed', 'program', 'machine', 'learning', 'use', 'compress', 'audio', 'file', 'sound', 'snippet', 'call', 'token', 'lose', 'much', 'information', 'tokenized', 'training', 'datum', 'feed', 'machinelearning', 'model', 'use', 'natural', 'language', 'processing', 'learn', 'sound', 'pattern', 'generate', 'audio', 'second', 'sound', 'feed', 'predict', 'come', 'next', 'process', 'similar', 'way', 'language', 'model', 'gpt3', 'predict', 'sentence', 'word', 'typically', 'follow', 'one', 'audio', 'clip', 'release', 'team', 'sound', 'pretty', 'natural', 'particular', 'piano', 'music', 'generate', 'use', 'sound', 'fluid', 'piano', 'music', 'generate', 'use', 'exist', 'technique', 'tend', 'sound', 'chaotic', 'new', 'wave', 'startup', 'use', 'deep', 'learning', 'build', 'synthetic', 'voice', 'actor', 'digital', 'assistant', 'videogame', 'character', 'corporate', 'video', 'research', 'computergenerate', 'music', 'say', 'already', 'much', 'well', 'sound', 'quality', 'previous', 'music', 'generation', 'program', 'particular', 'say', 'surprisingly', 'good', 'recreate', 'repeat', 'pattern', 'inherent', 'humanmade', 'music', 'generate', 'realistic', 'piano', 'music', 'capture', 'lot', 'subtle', 'vibration', 'contain', 'note', 'piano', 'key', 'strike', 'music', 'also', 'sustain', 'rhythm', 'harmony', 'period', 'time', '’', 'really', 'impressive', 'partly', 'indicate', 'learn', 'kind', 'structure', 'multiple', 'level', 'dannenberg', 'say', 'confine', 'music', 'train', 'library', 'recording', 'human', 'speak', 'sentence', 'system', 'also', 'generate', 'speech', 'continue', 'accent', 'cadence', 'original', 'speaker', 'point', 'sentence', 'still', 'seem', 'non', 'sequitur', 'make', 'sense', 'audiolm', 'train', 'learn', 'type', 'sound', 'snippet', 'occur', 'frequently', 'together', 'use', 'process', 'reverse', 'produce', 'sentence', 'also', 'advantage', 'able', 'learn', 'pause', 'exclamation', 'inherent', 'spoken', 'language', 'easily', 'translate', 'text', 'rupal', 'patel', 'research', 'information', 'speech', 'science', 'northeastern', 'say', 'previous', 'work', 'use', 'generate', 'audio', 'capture', 'nuance', 'explicitly', 'annotate', 'training', 'datum', 'contrast', 'audiolm', 'learn', 'characteristic', 'input', 'datum', 'automatically', 'add', 'realistic', 'effect', 'lot', 'call', 'linguistic', 'information', 'word', 'pronounce', '’', 'way', 'communicating', 'base', 'way', 'say', 'thing', 'express', 'specific', 'intention', 'specific', 'emotion', 'say', 'cocreator', 'example', 'laugh', 'say', 'indicate', 'joke', 'make', 'speech', 'natural', 'say', 'eventually', 'aigenerate', 'music', 'use', 'provide', 'naturalsounde', 'background', 'soundtrack', 'video', 'slideshow', 'speech', 'generation', 'technology', 'sound', 'natural', 'help', 'improve', 'internet', 'accessibility', 'tool', 'bot', 'work', 'health', 'care', 'setting', 'say', 'team', 'also', 'hope', 'create', 'sophisticated', 'sound', 'band', 'different', 'instrument', 'sound', 'mimic', 'recording', 'tropical', 'rainfor', 'however', 'technology', 'ethical', 'implication', 'need', 'consider', 'say', 'particular', '’', 'important', 'determine', 'musician', 'produce', 'clip', 'use', 'training', 'datum', 'get', 'attribution', 'royalty', 'end', 'product', 'issue', 'crop', 'texttoimage', 'aigenerate', 'speech', '’', 'indistinguishable', 'real', 'thing', 'also', 'become', 'convincing', 'enable', 'spread', 'misinformation', 'easily', 'paper', 'researcher', 'write', 'already', 'consider', 'work', 'mitigate', 'issue', 'example', 'develop', 'technique', 'distinguish', 'natural', 'sound', 'sound', 'produce', 'use', 'also', 'suggest', 'include', 'audio', 'watermark', 'aigenerated', 'product', 'make', 'easy', 'distinguish', 'natural', 'audio']"
I Was There When: AI mastered chess,https://www.technologyreview.com/2022/10/06/1060824/i-was-there-when-ai-mastered-chess/,2022-10-06,"<p>In the late ‘90s, IBM’s Deep Blue computer beat Garry Kasparov—the reigning world champion of chess. It paved the way for a revolution in automation.</p>
","I Was There When is an oral history project that’s part of the In Machines We Trust podcast. It features stories of how breakthroughs and watershed moments in artificial intelligence and computing happened, as told by the people who witnessed them. In this episode we meet one of the world's greatest chess players, Garry Kasparov. This project was produced by Jennifer Strong, Anthony Green and Emma Cillekens. It was edited by Mat Honan and mixed by Garret Lang with original music by Jacob Gorski. The art is from Eric Mongeon and Stephanie Arnett.  [TR ID] Jennifer: For as long as there’s been AI research, games have been a part of it… especially chess.  We think of people who are good at playing chess as having a certain level of intelligence … and so the game also became a way to gauge the intelligence of machines. And… fun fact? The very first chess playing program was written before a computer even existed to run it. Pioneering computer scientist Alan Turing played it in 1950...using an algorithm worked out on paper. It didn’t work very well. But people continued to advance this research for decades. And then, in 1997, IBM's Deep Blue computer beat Garry Kasparov... the reigning world champion of chess.  Commentator 2: Are we missing something on the chessboard now that Kasparov sees? He does not look.. he looks disgusted in fact.   Commentator 1: Whoah!  Commentator 2: Deep Blue! Kasparov, after the move C4, has resigned! [Applause] Jennifer: I’m Jennifer Strong, and this is I Was There When—an oral history project featuring the stories of breakthroughs and watershed moments in AI and computing, as told by those who witnessed them. This episode, we meet the man on the other side of that chess board, Garry Kasparov.  Garry Kasparov: It was inevitable that something described on the cover of Newsweek as the brain’s last stand and in books as big as the moon landing would involve a lot of mythology. I admit that I was caught up in a lot of this hype myself. It took years of reflection and examination to sort out my impressions then and the truth. I wrote about this painful process in my 2017 book, Deep Thinking: When machine intelligence ends and human creativity begins, it's easy for a chess machine, after all. They don't care if they win or lose. They don't even know they're playing chess. But as a human and world champion, I had many emotions sitting down across from a machine.  Garry Kasparov: Would it play like previous machines or would it play like God? I was used to reading my opponents body language. Not exactly helpful, sitting across from a computer engineer making moves he didn't understand for the machine he'd built. I was also used to preparing deeply for my opponents based on their previous games and their tendencies. Against Deep Blue, this was also out the window as they kept their training games secret. And of course they could upgrade its strengths and change its chess personality with a few keystrokes. If only I could. It was hard to explain my experience because I was really the first knowledge worker to have my job threatened by a machine. Garry Kasparov: Most AI and experiences before that were hoaxes, or quite primitive. For example, human elevate operators being replaced by automatic push-bat elevators was very alarming to people in the 1940s. In fact, the technology for automatic elevators had existed for decades, but people were afraid of them. Plus, the elevate operators had a strong union. Today, there are many easy comparisons. Sitting down across from Deep Blue was in one way entirely normal. I had been feeding at a chess board since I was six years old, and technically a little was different for me, and yet it was entirely different. I felt like most people will feel the first time they get into a self-driving car or get a diagnosis from an AI doctor. Garry Kasparov: These new marvels are far beyond my chest nemesis. Of course, the machine I lost to in the 1997 rematch, sometimes called Deep Blue, was as intelligent as your alarm clock—a 10 million dollar alarm clock, but nothing like what had been imagined by previous generations. This is not to downplay their achievement, which was a Mount Everest of computing—to defeat the world chess champion . There was a reason it got global attention. I only want to put into context what we mean when we say intelligent. Deep Blue did one thing very well with hundreds of specialized chiefs, but it was enough to compete at the world champion level because chess is deep but not deep enough. Deep Blue didn't have to solve chess. It only had to play better over six games and brute force analysis at fast speeds turned out to be enough. It took me a while to absorb the most important lessons of my loss, and they had nothing to do with chess and everything to do with the future of the human-machine relationship. Garry Kasparov: The period in which we compete against intelligent machines is very small, almost insignificant, yet we put so much importance on it instead of the alternative machine supremacy that follows, which is what really matters. AI automation replaces human jobs, for example, and there's a brief moment of equality in performance with humans. But that doesn't last long, and forever after machines will do it better, cheaper, and more safely. That's human progress. It makes our lives better. This isn't to be callous to those who lose their jobs, but even there, study after study shows that industries with more automation and AI do better with more jobs and higher salaries. The alternative is stagnation.  Garry Kasparov: Another key point from Deep Blue that has broad applications to AI and tech in general is that we often miss the early signs of inevitable machine dominance. My loss in the 1997 rematch was a big deal, but in fact, the most important point had been already made a year earlier in our first match in 1996 in Philadelphia, which I won. But I lost the very first game of the match, and that was the writing on the wall. That made it clear that chess was not as special as everyone had thought. It was just another closed, complex system that would inevitably be cracked by increases in computer power. That's when that little competition window started to close. Now it's funny to think about competing with chess machines. They are our tools, not our competition. We also get better cancer screening, safer roads, greater productivity and security. We don't have to work at many boring and dangerous jobs anymore. When that happens, we are free to become more creative, more strategic in our activities. Garry Kasparov: We can direct the robots, the algorithms, et cetera. Technology doing our work is the whole history of human progress. This is why I prefer to call AI or augmented intelligence, not artificial. It's a tool and makes us smarter. The way a telescope augments our vision—what matters is how we focus it. This isn't just a matter of economics. Global security also depends on it as leading AI tech in the hands of dictatorships is a serious threat. I helped design the first PC database software that made all my handwritten notebooks of advantages obsolete. I used and helped promote the chess programs that would overtake me and everyone else. I saw them as necessary tools that would make me better. Not as threats.  Garry Kasparov: In 1998, I invented what I called advanced chess, in which humans played together with a machine partner. A true model for many kinds of collaborative AI integration today. And humans still play chess against each other all over the world more than ever. Even though the phone in everyone's pocket now is stronger than Deep Blue. Are we using these powerful tools in a responsible way? The Wild West is romantic in cowboy movies, but progress means having laws upheld in society where we feel secured to take advantage of the technological marvels we have created. When I give lectures on AI, many expect me to be angry or a technophobe because of my loss to a machine 25 years ago. And I admit it, I am a sore loser. But really it was a fascinating experiment and experience. Mostly, I hope others learn from my attitudes. If you can’t beat them, join them. Don't rage against the machine if you can make it work for you and for all of us. Jennifer: Do you have a story to tell? Know someone who does? Drop us an email at podcasts at technology review dot com. You can find links to our reporting in the show notes... and you can support our journalism by going to tech review dot com slash subscribe. [MIDROLL] Jennifer: This project was produced by me with Anthony Green and Emma Cillekens. We’re edited by Mat Honan and our mix engineer is Garret Lang. Thanks for Listening. I'm Jennifer Strong.","I Was There When is an oral history project that’s part of the In Machines We Trust podcast. It features stories of how breakthroughs and watershed moments in artificial intelligence and computing happened, as told by the people who witnessed them. In this episode we meet one of the world's greatest chess players, Garry Kasparov. This project was produced by Jennifer Strong, Anthony Green and Emma Cillekens. It was edited by Mat Honan and mixed by Garret Lang with original music by Jacob Gorski. The art is from Eric Mongeon and Stephanie Arnett. [TR ID] Jennifer: For as long as there’s been AI research, games have been a part of it… especially chess. We think of people who are good at playing chess as having a certain level of intelligence … and so the game also became a way to gauge the intelligence of machines. And… fun fact? The very first chess playing program was written before a computer even existed to run it. Pioneering computer scientist Alan Turing played it in 1950...using an algorithm worked out on paper. It didn’t work very well. But people continued to advance this research for decades. And then, in 1997, IBM's Deep Blue computer beat Garry Kasparov... the reigning world champion of chess. Commentator 2: Are we missing something on the chessboard now that Kasparov sees? He does not look.. he looks disgusted in fact. Commentator 1: Whoah! Commentator 2: Deep Blue! Kasparov, after the move C4, has resigned! [Applause] Jennifer: I’m Jennifer Strong, and this is I Was There When—an oral history project featuring the stories of breakthroughs and watershed moments in AI and computing, as told by those who witnessed them. This episode, we meet the man on the other side of that chess board, Garry Kasparov. Garry Kasparov: It was inevitable that something described on the cover of Newsweek as the brain’s last stand and in books as big as the moon landing would involve a lot of mythology. I admit that I was caught up in a lot of this hype myself. It took years of reflection and examination to sort out my impressions then and the truth. I wrote about this painful process in my 2017 book, Deep Thinking: When machine intelligence ends and human creativity begins, it's easy for a chess machine, after all. They don't care if they win or lose. They don't even know they're playing chess. But as a human and world champion, I had many emotions sitting down across from a machine. Garry Kasparov: Would it play like previous machines or would it play like God? I was used to reading my opponents body language. Not exactly helpful, sitting across from a computer engineer making moves he didn't understand for the machine he'd built. I was also used to preparing deeply for my opponents based on their previous games and their tendencies. Against Deep Blue, this was also out the window as they kept their training games secret. And of course they could upgrade its strengths and change its chess personality with a few keystrokes. If only I could. It was hard to explain my experience because I was really the first knowledge worker to have my job threatened by a machine. Garry Kasparov: Most AI and experiences before that were hoaxes, or quite primitive. For example, human elevate operators being replaced by automatic push-bat elevators was very alarming to people in the 1940s. In fact, the technology for automatic elevators had existed for decades, but people were afraid of them. Plus, the elevate operators had a strong union. Today, there are many easy comparisons. Sitting down across from Deep Blue was in one way entirely normal. I had been feeding at a chess board since I was six years old, and technically a little was different for me, and yet it was entirely different. I felt like most people will feel the first time they get into a self-driving car or get a diagnosis from an AI doctor. Garry Kasparov: These new marvels are far beyond my chest nemesis. Of course, the machine I lost to in the 1997 rematch, sometimes called Deep Blue, was as intelligent as your alarm clock—a 10 million dollar alarm clock, but nothing like what had been imagined by previous generations. This is not to downplay their achievement, which was a Mount Everest of computing—to defeat the world chess champion . There was a reason it got global attention. I only want to put into context what we mean when we say intelligent. Deep Blue did one thing very well with hundreds of specialized chiefs, but it was enough to compete at the world champion level because chess is deep but not deep enough. Deep Blue didn't have to solve chess. It only had to play better over six games and brute force analysis at fast speeds turned out to be enough. It took me a while to absorb the most important lessons of my loss, and they had nothing to do with chess and everything to do with the future of the human-machine relationship. Garry Kasparov: The period in which we compete against intelligent machines is very small, almost insignificant, yet we put so much importance on it instead of the alternative machine supremacy that follows, which is what really matters. AI automation replaces human jobs, for example, and there's a brief moment of equality in performance with humans. But that doesn't last long, and forever after machines will do it better, cheaper, and more safely. That's human progress. It makes our lives better. This isn't to be callous to those who lose their jobs, but even there, study after study shows that industries with more automation and AI do better with more jobs and higher salaries. The alternative is stagnation. Garry Kasparov: Another key point from Deep Blue that has broad applications to AI and tech in general is that we often miss the early signs of inevitable machine dominance. My loss in the 1997 rematch was a big deal, but in fact, the most important point had been already made a year earlier in our first match in 1996 in Philadelphia, which I won. But I lost the very first game of the match, and that was the writing on the wall. That made it clear that chess was not as special as everyone had thought. It was just another closed, complex system that would inevitably be cracked by increases in computer power. That's when that little competition window started to close. Now it's funny to think about competing with chess machines. They are our tools, not our competition. We also get better cancer screening, safer roads, greater productivity and security. We don't have to work at many boring and dangerous jobs anymore. When that happens, we are free to become more creative, more strategic in our activities. Garry Kasparov: We can direct the robots, the algorithms, et cetera. Technology doing our work is the whole history of human progress. This is why I prefer to call AI or augmented intelligence, not artificial. It's a tool and makes us smarter. The way a telescope augments our vision—what matters is how we focus it. This isn't just a matter of economics. Global security also depends on it as leading AI tech in the hands of dictatorships is a serious threat. I helped design the first PC database software that made all my handwritten notebooks of advantages obsolete. I used and helped promote the chess programs that would overtake me and everyone else. I saw them as necessary tools that would make me better. Not as threats. Garry Kasparov: In 1998, I invented what I called advanced chess, in which humans played together with a machine partner. A true model for many kinds of collaborative AI integration today. And humans still play chess against each other all over the world more than ever. Even though the phone in everyone's pocket now is stronger than Deep Blue. Are we using these powerful tools in a responsible way? The Wild West is romantic in cowboy movies, but progress means having laws upheld in society where we feel secured to take advantage of the technological marvels we have created. When I give lectures on AI, many expect me to be angry or a technophobe because of my loss to a machine 25 years ago. And I admit it, I am a sore loser. But really it was a fascinating experiment and experience. Mostly, I hope others learn from my attitudes. If you can’t beat them, join them. Don't rage against the machine if you can make it work for you and for all of us. Jennifer: Do you have a story to tell? Know someone who does? Drop us an email at podcasts at technology review dot com. You can find links to our reporting in the show notes... and you can support our journalism by going to tech review dot com slash subscribe. [MIDROLL] Jennifer: This project was produced by me with Anthony Green and Emma Cillekens. We’re edited by Mat Honan and our mix engineer is Garret Lang. Thanks for Listening. I'm Jennifer Strong.","['oral', 'history', 'project', '’s', 'part', 'machine', 'trust', 'podcast', 'feature', 'story', 'breakthrough', 'watershed', 'moment', 'artificial', 'intelligence', 'computing', 'happen', 'tell', 'people', 'witness', 'episode', 'meet', 'world', 'great', 'chess', 'player', 'project', 'produce', 'cilleken', 'edit', 'mix', 'original', 'music', 'art', 'tr', 'jennifer', 'long', 'research', 'game', 'part', 'especially', 'chess', 'think', 'people', 'good', 'play', 'chess', 'certain', 'level', 'intelligence', 'game', 'also', 'become', 'way', 'gauge', 'intelligence', 'machine', 'fun', 'fact', 'first', 'chess', 'playing', 'program', 'write', 'computer', 'even', 'exist', 'run', 'pioneer', 'computer', 'scientist', 'ture', 'play', '1950use', 'work', 'paper', 'work', 'well', 'people', 'continue', 'advance', 'research', 'decade', 'ibms', 'deep', 'blue', 'computer', 'beat', 'reign', 'world', 'champion', 'chess', 'commentator', 'miss', 'chessboard', 'see', 'look', 'look', 'disgusted', 'fact', 'commentator', 'whoah', 'commentator', 'deep', 'blue', 'kasparov', 'move', 'c4', 'resign', 'applause', 'jennifer', '’m', 'jennifer', 'strong', 'oral', 'history', 'project', 'feature', 'story', 'breakthrough', 'watershed', 'moment', 'ai', 'computing', 'tell', 'witness', 'episode', 'meet', 'man', 'side', 'chess', 'board', 'inevitable', 'describe', 'cover', 'newsweek', 'brain', 'last', 'stand', 'book', 'big', 'moon', 'landing', 'involve', 'lot', 'mythology', 'admit', 'catch', 'lot', 'hype', 'take', 'year', 'reflection', 'examination', 'sort', 'impression', 'truth', 'write', 'painful', 'process', 'book', 'deep', 'thinking', 'machine', 'intelligence', 'end', 'human', 'creativity', 'begin', 'easy', 'chess', 'machine', 'care', 'win', 'lose', 'even', 'know', 'play', 'chess', 'human', 'world', 'champion', 'many', 'emotion', 'sit', 'machine', 'garry', 'play', 'previous', 'machine', 'play', 'use', 'read', 'opponent', 'body', 'language', 'exactly', 'helpful', 'sit', 'computer', 'engineer', 'make', 'move', 'understand', 'machine', 'build', 'also', 'use', 'prepare', 'deeply', 'opponent', 'base', 'previous', 'game', 'tendency', 'deep', 'blue', 'also', 'window', 'keep', 'training', 'game', 'secret', 'course', 'upgrade', 'strength', 'change', 'chess', 'personality', 'keystroke', 'hard', 'explain', 'experience', 'really', 'first', 'knowledge', 'worker', 'job', 'threaten', 'machine', 'ai', 'experience', 'hoax', 'quite', 'primitive', 'example', 'human', 'elevate', 'operator', 'replace', 'automatic', 'pushbat', 'elevator', 'alarming', 'people', '1940', 'fact', 'technology', 'automatic', 'elevator', 'exist', 'decade', 'people', 'afraid', 'elevate', 'operator', 'strong', 'union', 'today', 'many', 'easy', 'comparison', 'sit', 'deep', 'blue', 'way', 'entirely', 'normal', 'feed', 'chess', 'board', 'year', 'old', 'technically', 'little', 'different', 'yet', 'entirely', 'different', 'feel', 'people', 'feel', 'first', 'time', 'get', 'selfdriving', 'car', 'get', 'diagnosis', 'new', 'marvel', 'far', 'chest', 'nemesis', 'course', 'machine', 'lose', 'rematch', 'sometimes', 'call', 'deep', 'blue', 'intelligent', 'alarm', 'clock', 'dollar', 'alarm', 'clock', 'imagine', 'previous', 'generation', 'downplay', 'achievement', 'mount', 'everest', 'computing', 'defeat', 'world', 'chess', 'champion', 'reason', 'get', 'global', 'attention', 'want', 'put', 'context', 'mean', 'say', 'intelligent', 'deep', 'blue', 'thing', 'well', 'hundred', 'specialize', 'chief', 'enough', 'compete', 'world', 'champion', 'level', 'chess', 'deep', 'deep', 'enough', 'deep', 'blue', 'solve', 'chess', 'play', 'well', 'game', 'brute', 'force', 'analysis', 'fast', 'speed', 'turn', 'enough', 'take', 'absorb', 'important', 'lesson', 'loss', 'chess', 'future', 'relationship', 'period', 'compete', 'intelligent', 'machine', 'small', 'almost', 'insignificant', 'yet', 'put', 'much', 'importance', 'instead', 'alternative', 'machine', 'supremacy', 'follow', 'really', 'matter', 'ai', 'automation', 'replace', 'human', 'job', 'example', 'brief', 'moment', 'equality', 'performance', 'human', 'last', 'long', 'forever', 'machine', 'well', 'cheap', 'safely', 'human', 'progress', 'make', 'life', 'well', 'callous', 'lose', 'job', 'even', 'study', 'study', 'show', 'industry', 'automation', 'well', 'job', 'high', 'salary', 'alternative', 'stagnation', 'key', 'point', 'deep', 'blue', 'broad', 'application', 'ai', 'tech', 'general', 'often', 'miss', 'early', 'sign', 'inevitable', 'machine', 'dominance', 'loss', 'rematch', 'big', 'deal', 'fact', 'important', 'point', 'already', 'make', 'year', 'early', 'first', 'match', 'philadelphia', 'win', 'lose', 'first', 'game', 'match', 'writing', 'wall', 'make', 'clear', 'chess', 'special', 'think', 'closed', 'complex', 'system', 'inevitably', 'crack', 'increase', 'computer', 'power', 'little', 'competition', 'window', 'start', 'close', 'funny', 'think', 'compete', 'chess', 'machine', 'tool', 'competition', 'also', 'get', 'well', 'cancer', 'screen', 'safe', 'road', 'great', 'productivity', 'security', 'work', 'many', 'boring', 'dangerous', 'job', 'anymore', 'happen', 'free', 'become', 'creative', 'strategic', 'activity', 'direct', 'robot', 'algorithm', 'et', 'cetera', 'technology', 'work', 'whole', 'history', 'human', 'progress', 'prefer', 'call', 'ai', 'augmented', 'intelligence', 'artificial', 'tool', 'make', 'smart', 'way', 'telescope', 'augment', 'vision', 'matter', 'focus', 'matter', 'economics', 'global', 'security', 'also', 'depend', 'lead', 'tech', 'hand', 'dictatorship', 'serious', 'threat', 'help', 'design', 'first', 'database', 'software', 'make', 'handwritten', 'notebook', 'advantage', 'obsolete', 'use', 'help', 'promote', 'chess', 'program', 'overtake', 'else', 'see', 'necessary', 'tool', 'make', 'well', 'threat', 'invent', 'call', 'advanced', 'chess', 'human', 'play', 'together', 'machine', 'partner', 'true', 'model', 'many', 'kind', 'collaborative', 'integration', 'today', 'human', 'still', 'play', 'chess', 'world', 'ever', 'even', 'phone', 'everyone', 'pocket', 'strong', 'deep', 'blue', 'use', 'powerful', 'tool', 'responsible', 'way', 'wild', 'west', 'romantic', 'cowboy', 'movie', 'progress', 'mean', 'law', 'uphold', 'society', 'feel', 'secured', 'take', 'advantage', 'technological', 'marvel', 'create', 'give', 'lecture', 'many', 'expect', 'angry', 'technophobe', 'loss', 'machine', 'year', 'ago', 'admit', 'sore', 'loser', 'really', 'fascinating', 'experiment', 'experience', 'mostly', 'hope', 'learn', 'attitude', 'beat', 'join', 'rage', 'machine', 'make', 'work', 'jennifer', 'story', 'tell', 'know', 'drop', 'email', 'podcast', 'technology', 'review', 'dot', 'com', 'find', 'link', 'reporting', 'show', 'note', 'support', 'journalism', 'go', 'tech', 'review', 'dot', 'com', 'slash', 'midroll', 'project', 'produce', 'anthony', 'cilleken', 'edit', 'mix', 'engineer', 'garret', 'thank', 'listen', 'jennifer', 'strong']"
This obscure shopping app is now America’s most downloaded,https://www.technologyreview.com/2022/10/25/1062142/temu-shopping-app-most-downloaded/,2022-10-25,"<p>Temu shot up to the top spot in app store charts, but it has a long way to go before it can replicate the e-commerce success it’s seen in China.</p>
","China Report is MIT Technology Review’s newsletter about what's happening in China. Sign up to receive it in your inbox every Tuesday. Take a deep breath. The Chinese Communist Party Congress news cycle is (basically) over.  There are many significant things from the high-level political assembly to talk about, mostly around understanding what the new party leadership means for China’s future, but I’ll point you to political reporters who are real experts in all this down below.  Instead, I want to talk about something big you probably missed last week: There’s a new Chinese e-commerce app that is quietly but quickly growing. It’s called Temu. And on October 17, it became the most downloaded shopping app in the United States. It’s a pretty big deal for Temu to beat Amazon, Walmart, and its Chinese competitor Shein, especially because your immediate response is probably What? I’ve never even heard of Temu!  Well, you are in good company. The app remains obscure among most people, though it marks another high-profile attempt by yet another Chinese tech giant—after Alibaba, Shein, and ByteDance—to try its luck in the American e-commerce market.  Temu (btw, there’s no official guidance on how to pronounce the name, but I’ve been saying tee-moo) is a global version of Chinese e-commerce company Pinduoduo. Founded in 2015, it entered a market that had been dominated by Alibaba for over a decade, yet it managed to rise through the competition and, in 2020, replaced Alibaba as the company with the most e-commerce customers in China. Today, Pinduoduo has over 730 million monthly active users—more than two times the US population!—and is known for both extremely cheap prices and innovative gimmicks that keep users hooked. Still, Pinduoduo has remained an unfamiliar name outside the country. So how did Temu rise to the top of the iOS App Store’s shopping chart?  “I believe it’s driven almost exclusively by ads,” says Juozas Kaziukėnas, who founded the e-commerce analyst firm Marketplace Pulse, “because I’m seeing relatively no mentions of Temu on social media. That makes me believe that there’s very little organic recognition of the brand yet.” I know from my personal experience that at least this first part is true—I’ve been seeing Temu’s ads everywhere. Perhaps because they are targeting Chinese readers (I saw ads in Chinese), or perhaps because I’ve made the mistake of Googling its name (for work and this newsletter in particular), the ads have popped up all over for me, including in my Gmail inbox. (I didn’t even realize there were ad slots in Gmail.) According to Meta, Temu has run over 1,000 ads on its platforms since September, with posts in English and Chinese. (For comparison: Similar Chinese apps like Shein and AliExpress have run only dozens of ads.) When it comes to app stores, Temu’s iOS ads are mostly targeting consumers in the US and Canada, while its Android ads are also in seven other countries, according to the app-store advertising database App Growing. So what are Temu’s offerings like? It has everything from clothing to kitchen products, from car parts to electronics. Otherwise, the defining feature is probably just that they’re cheap. Dirt cheap. Just a quick browse on Monday morning told me you could get 60-cent earrings, $4 home security cameras, $4 wireless earphones, and $6 sneakers. Eighty percent of the orders would be delivered within 10 days, says the website, which is slower than Amazon but on par with Shein. I admit I’m drawn by how cheap these products are. But price is only one thing people consider when they shop. Is that enough to get US consumers to use Temu?  Ring Nation wants to lure you in with funny content—and push you to buy a Ring camera to make your own. People often point to Shein, the Chinese online fast-fashion retailer, as an example of how cheap made-in-China goods can succeed in the US despite the decades-long stigma associated with them. Indeed, Shein is taking Gen Z’s closets by storm. But you also need to look at other platforms offering cheap Chinese goods that failed to reach Shein’s level of influence. AliExpress, the overseas version of Alibaba, which has been around since 2010, never managed to really break through in the US even though it also prices products extremely low. Shein did some things right that AliExpress didn’t—namely, marketing and presentation. By paying influencers to try out its clothes and produce glossy YouTube and TikTok videos, Shein is spreading the idea that, first and foremost, its products are fun and trendy. The fact that they’re made in China is secondary.  The difference in their brand images is clear. Most people would go to AliExpress (or Wish, which is a comparable app from Russia) only when they know they want something inexpensive. But people go to Shein to check out the latest fashion trend and to get it at an affordable price. So will Temu be more like Shein or more like AliExpress? My sense is that so far, Temu is looking more like the latter, with its only real advantage being the price points.   “This model of relying on ads to drive every transaction does have an expiration date, and that’s what unfortunately caused the demise of Wish,” says Kaziukėnas. At one point, ads will become too expensive and too inefficient to justify the costs.  To go further, Temu needs to really differentiate itself from other Chinese and American shopping platforms. This is actually something Pinduoduo has done effectively in China. It’s known for an addictive, at times manipulative, app that incentivizes people to share what they are buying on social platforms to get even steeper discounts. In the past two years, the idea of “social e-commerce” that Pinduoduo pioneered has been seen as one of the most successful innovations in China’s consumer tech sector.  But it’s also not clear how that idea would land in the US. The American shopping industry has been reluctant to accept Chinese trends. I used to believe that livestream shopping, which is extremely popular in China, would be accepted around the world and fundamentally change e-commerce. But years later, it still hasn’t happened, and it’s starting to feel like waiting for Godot.  “You see some small attempts to do these sorts of experiments, but if you zoom out and look at what has actually changed over the last 10 years? Not that much. Amazon looks exactly the same,” says Kaziukėnas. “Perhaps [it] suggests that the West is just a much more established environment, economically and also technologically, so it’s unlikely to see these kinds of massive disruptions as you saw in China.” So good luck, Temu! In the meantime, you’ll probably be hearing this name again soon, and I’ll keep resisting the urge to click on those ubiquitous ads.  Would you use Temu? Let me know at zeyi@technologyreview.com. 1. The US Department of Justice unsealed three separate criminal cases on Monday. In one, Chinese intelligence officers were allegedly found to be interfering in the investigations on Huawei; in another, they were apparently faking academic credentials to obtain sensitive information; and in the last, they were reportedly forcing US citizens to return to China. (Politico)   2. The key thing to understand about the new top leadership of the Chinese Communist Party: It shows the concentration of power by Xi Jinping. (The New York Times $) 3. Want to know what topics Xi Jinping mentioned more than his predecessors in his party congress speech? What did he miss? There are already several quick analyses of Xi’s speech by researcher Vicky Xu, law professor Taisu Zhang, and political science researcher Mike Thompson-Brusstar. 4. For the first time in 25 years, there’s not a single woman in the Chinese Communist Party’s Politburo. (The Wall Street Journal $) 5. “Birth tourism” is still alive and well for Chinese families looking to give birth or use a surrogate in the United States, but the process has become much more difficult because of China’s border controls. (NPR) 6. The New Yorker’s Evan Osnos profiled Guo Wengui, the controversial Chinese tycoon who was once close to the country’s political elites but has reinvented himself as a darling of Trump Republicans. (The New Yorker $) 7. Two Chinese filmmakers produced Diagnosia, an animated virtual-reality film that shows the physical and mental abuses that happen in China’s infamous internet addiction clinics. (Sixth Tone) 8. Meta developed the first artificial-intelligence tool to translate Hokkien in real time. The language has no written script but is spoken by over 46 million people in China, Taiwan, Malaysia, and other countries. (Mashable) This was a summer overheated by Chinese electric blankets.  As Europeans braced for a cold winter amid the energy crisis, Chinese electric blanket factories suddenly found themselves in hot demand (yes, pun intended). As Chinese publication White Night Studio reported, in the three months from July to September, factories in southern China got massive orders from Europe to produce tens of thousands of electric blankets, a product that had been slowly disappearing in recent years. In the summer of 2022, exports of electric blankets to Europe increased 150%. Established factory owners were getting 300 calls a day asking for more supply, while rookies blindly entered the industry, opening new production lines.  However, the trend came and went quickly. By October, the orders had slowed down as the market demand was being met—and anyway, it’s now too late for the blankets to be made, shipped to Europe, and sold before the chill sets in.  Come on, we all butcher pronunciations at times. Maybe our friends make fun of us, maybe they let it go. But would you dare correct the Chinese president who was giving a highly anticipated speech in front of the whole Chinese population? In that case, the misspeak might just become the new norm. This week, Singaporean law professor Henry Gao caught a Chinese official (who majored in Chinese language studies, btw) changing his pronunciation of a word in real time during a press conference for the 20th Party Congress—likely because Xi Jinping misspoke the word just a few days before. Why? Because he realised that the 3rd pronunciation was Xiâ€™s pronunciation when he gave the 20th Congress Report! Jiang is currently the Director of the CPCCC Policy Research Office. He must know the correct pronunciation because his first degree is in Chinese language (78çº§) pic.twitter.com/CSk1SkRNak See you next week! Zeyi ","China Report is MIT Technology Review’s newsletter about what's happening in China. Sign up to receive it in your inbox every Tuesday. Take a deep breath. The Chinese Communist Party Congress news cycle is (basically) over. There are many significant things from the high-level political assembly to talk about, mostly around understanding what the new party leadership means for China’s future, but I’ll point you to political reporters who are real experts in all this down below. Instead, I want to talk about something big you probably missed last week: There’s a new Chinese e-commerce app that is quietly but quickly growing. It’s called Temu. And on October 17, it became the most downloaded shopping app in the United States. It’s a pretty big deal for Temu to beat Amazon, Walmart, and its Chinese competitor Shein, especially because your immediate response is probably What? I’ve never even heard of Temu! Well, you are in good company. The app remains obscure among most people, though it marks another high-profile attempt by yet another Chinese tech giant—after Alibaba, Shein, and ByteDance—to try its luck in the American e-commerce market. Temu (btw, there’s no official guidance on how to pronounce the name, but I’ve been saying tee-moo) is a global version of Chinese e-commerce company Pinduoduo. Founded in 2015, it entered a market that had been dominated by Alibaba for over a decade, yet it managed to rise through the competition and, in 2020, replaced Alibaba as the company with the most e-commerce customers in China. Today, Pinduoduo has over 730 million monthly active users—more than two times the US population!—and is known for both extremely cheap prices and innovative gimmicks that keep users hooked. Still, Pinduoduo has remained an unfamiliar name outside the country. So how did Temu rise to the top of the iOS App Store’s shopping chart? “I believe it’s driven almost exclusively by ads,” says Juozas Kaziukėnas, who founded the e-commerce analyst firm Marketplace Pulse, “because I’m seeing relatively no mentions of Temu on social media. That makes me believe that there’s very little organic recognition of the brand yet.” I know from my personal experience that at least this first part is true—I’ve been seeing Temu’s ads everywhere. Perhaps because they are targeting Chinese readers (I saw ads in Chinese), or perhaps because I’ve made the mistake of Googling its name (for work and this newsletter in particular), the ads have popped up all over for me, including in my Gmail inbox. (I didn’t even realize there were ad slots in Gmail.) According to Meta, Temu has run over 1,000 ads on its platforms since September, with posts in English and Chinese. (For comparison: Similar Chinese apps like Shein and AliExpress have run only dozens of ads.) When it comes to app stores, Temu’s iOS ads are mostly targeting consumers in the US and Canada, while its Android ads are also in seven other countries, according to the app-store advertising database App Growing. So what are Temu’s offerings like? It has everything from clothing to kitchen products, from car parts to electronics. Otherwise, the defining feature is probably just that they’re cheap. Dirt cheap. Just a quick browse on Monday morning told me you could get 60-cent earrings, $4 home security cameras, $4 wireless earphones, and $6 sneakers. Eighty percent of the orders would be delivered within 10 days, says the website, which is slower than Amazon but on par with Shein. I admit I’m drawn by how cheap these products are. But price is only one thing people consider when they shop. Is that enough to get US consumers to use Temu? Ring Nation wants to lure you in with funny content—and push you to buy a Ring camera to make your own. People often point to Shein, the Chinese online fast-fashion retailer, as an example of how cheap made-in-China goods can succeed in the US despite the decades-long stigma associated with them. Indeed, Shein is taking Gen Z’s closets by storm. But you also need to look at other platforms offering cheap Chinese goods that failed to reach Shein’s level of influence. AliExpress, the overseas version of Alibaba, which has been around since 2010, never managed to really break through in the US even though it also prices products extremely low. Shein did some things right that AliExpress didn’t—namely, marketing and presentation. By paying influencers to try out its clothes and produce glossy YouTube and TikTok videos, Shein is spreading the idea that, first and foremost, its products are fun and trendy. The fact that they’re made in China is secondary. The difference in their brand images is clear. Most people would go to AliExpress (or Wish, which is a comparable app from Russia) only when they know they want something inexpensive. But people go to Shein to check out the latest fashion trend and to get it at an affordable price. So will Temu be more like Shein or more like AliExpress? My sense is that so far, Temu is looking more like the latter, with its only real advantage being the price points. “This model of relying on ads to drive every transaction does have an expiration date, and that’s what unfortunately caused the demise of Wish,” says Kaziukėnas. At one point, ads will become too expensive and too inefficient to justify the costs. To go further, Temu needs to really differentiate itself from other Chinese and American shopping platforms. This is actually something Pinduoduo has done effectively in China. It’s known for an addictive, at times manipulative, app that incentivizes people to share what they are buying on social platforms to get even steeper discounts. In the past two years, the idea of “social e-commerce” that Pinduoduo pioneered has been seen as one of the most successful innovations in China’s consumer tech sector. But it’s also not clear how that idea would land in the US. The American shopping industry has been reluctant to accept Chinese trends. I used to believe that livestream shopping, which is extremely popular in China, would be accepted around the world and fundamentally change e-commerce. But years later, it still hasn’t happened, and it’s starting to feel like waiting for Godot. “You see some small attempts to do these sorts of experiments, but if you zoom out and look at what has actually changed over the last 10 years? Not that much. Amazon looks exactly the same,” says Kaziukėnas. “Perhaps [it] suggests that the West is just a much more established environment, economically and also technologically, so it’s unlikely to see these kinds of massive disruptions as you saw in China.” So good luck, Temu! In the meantime, you’ll probably be hearing this name again soon, and I’ll keep resisting the urge to click on those ubiquitous ads. Would you use Temu? Let me know at zeyi@technologyreview.com. 1. The US Department of Justice unsealed three separate criminal cases on Monday. In one, Chinese intelligence officers were allegedly found to be interfering in the investigations on Huawei; in another, they were apparently faking academic credentials to obtain sensitive information; and in the last, they were reportedly forcing US citizens to return to China. (Politico) 2. The key thing to understand about the new top leadership of the Chinese Communist Party: It shows the concentration of power by Xi Jinping. (The New York Times $) 3. Want to know what topics Xi Jinping mentioned more than his predecessors in his party congress speech? What did he miss? There are already several quick analyses of Xi’s speech by researcher Vicky Xu, law professor Taisu Zhang, and political science researcher Mike Thompson-Brusstar. 4. For the first time in 25 years, there’s not a single woman in the Chinese Communist Party’s Politburo. (The Wall Street Journal $) 5. “Birth tourism” is still alive and well for Chinese families looking to give birth or use a surrogate in the United States, but the process has become much more difficult because of China’s border controls. (NPR) 6. The New Yorker’s Evan Osnos profiled Guo Wengui, the controversial Chinese tycoon who was once close to the country’s political elites but has reinvented himself as a darling of Trump Republicans. (The New Yorker $) 7. Two Chinese filmmakers produced Diagnosia, an animated virtual-reality film that shows the physical and mental abuses that happen in China’s infamous internet addiction clinics. (Sixth Tone) 8. Meta developed the first artificial-intelligence tool to translate Hokkien in real time. The language has no written script but is spoken by over 46 million people in China, Taiwan, Malaysia, and other countries. (Mashable) This was a summer overheated by Chinese electric blankets. As Europeans braced for a cold winter amid the energy crisis, Chinese electric blanket factories suddenly found themselves in hot demand (yes, pun intended). As Chinese publication White Night Studio reported, in the three months from July to September, factories in southern China got massive orders from Europe to produce tens of thousands of electric blankets, a product that had been slowly disappearing in recent years. In the summer of 2022, exports of electric blankets to Europe increased 150%. Established factory owners were getting 300 calls a day asking for more supply, while rookies blindly entered the industry, opening new production lines. However, the trend came and went quickly. By October, the orders had slowed down as the market demand was being met—and anyway, it’s now too late for the blankets to be made, shipped to Europe, and sold before the chill sets in. Come on, we all butcher pronunciations at times. Maybe our friends make fun of us, maybe they let it go. But would you dare correct the Chinese president who was giving a highly anticipated speech in front of the whole Chinese population? In that case, the misspeak might just become the new norm. This week, Singaporean law professor Henry Gao caught a Chinese official (who majored in Chinese language studies, btw) changing his pronunciation of a word in real time during a press conference for the 20th Party Congress—likely because Xi Jinping misspoke the word just a few days before. Why? Because he realised that the 3rd pronunciation was Xiâ€™s pronunciation when he gave the 20th Congress Report! Jiang is currently the Director of the CPCCC Policy Research Office. He must know the correct pronunciation because his first degree is in Chinese language (78çº§) pic.twitter.com/CSk1SkRNak See you next week! Zeyi","['mit', 'technology', 'review', 'newsletter', 'happen', 'sign', 'receive', 'inbox', 'take', 'deep', 'breath', 'chinese', 'news', 'cycle', 'basically', 'many', 'significant', 'thing', 'highlevel', 'political', 'assembly', 'talk', 'mostly', 'around', 'understand', 'new', 'party', 'leadership', 'mean', 'future', 'point', 'political', 'reporter', 'real', 'expert', 'instead', 'want', 'talk', 'big', 'probably', 'miss', 'last', 'week', '’', 'new', 'chinese', 'quietly', 'quickly', 'grow', 'call', 'become', 'download', 'shopping', 'app', '’', 'pretty', 'big', 'deal', 'beat', 'chinese', 'competitor', 'shein', 'especially', 'immediate', 'response', 'probably', 'never', 'even', 'hear', 'temu', 'good', 'company', 'app', 'remain', 'obscure', 'people', 'mark', 'highprofile', 'attempt', 'yet', 'chinese', 'tech', 'giant', 'bytedance', 'try', 'luck', 'market', 'temu', 'btw', '’', 'official', 'guidance', 'pronounce', 'name', 'say', 'teemoo', 'global', 'version', 'chinese', 'ecommerce', 'company', 'pinduoduo', 'found', 'enter', 'market', 'dominate', 'alibaba', 'decade', 'yet', 'manage', 'rise', 'competition', 'replace', 'alibaba', 'company', 'ecommerce', 'customer', 'today', 'pinduoduo', 'monthly', 'active', 'user', 'time', 'population', 'know', 'extremely', 'cheap', 'price', 'innovative', 'gimmick', 'keep', 'user', 'hook', 'still', 'pinduoduo', 'remain', 'unfamiliar', 'name', 'country', 'temu', 'rise', 'top', 'io', 'store', 'shopping', 'chart', 'believe', 'drive', 'almost', 'exclusively', 'ad', 'say', 'found', 'ecommerce', 'analyst', 'pulse', 'see', 'relatively', 'mention', 'temu', 'social', 'medium', 'make', 'believe', '’', 'little', 'organic', 'recognition', 'brand', 'yet', 'know', 'personal', 'experience', 'least', 'first', 'part', 'true', 'see', 'ad', 'everywhere', 'perhaps', 'target', 'chinese', 'reader', 'see', 'ad', 'chinese', 'perhaps', 'make', 'mistake', 'google', 'name', 'work', 'newsletter', 'particular', 'ad', 'pop', 'include', 'gmail', 'inbox', 'even', 'realize', 'ad', 'slot', 'gmail', 'accord', 'meta', 'run', 'ad', 'platform', 'post', 'comparison', 'similar', 'chinese', 'app', 'shein', 'aliexpress', 'run', 'dozen', 'ad', 'come', 'store', 'temu', 'io', 'ad', 'mostly', 'target', 'consumer', 'android', 'ad', 'also', 'country', 'accord', 'appstore', 'advertising', 'database', 'app', 'grow', 'temu', 'offering', 'clothing', 'kitchen', 'product', 'car', 'part', 'electronic', 'otherwise', 'defining', 'feature', 'probably', '’re', 'cheap', 'dirt', 'cheap', 'quick', 'browse', 'morning', 'tell', 'get', 'earring', 'home', 'security', 'camera', 'wireless', 'earphone', 'sneaker', 'percent', 'order', 'deliver', 'day', 'say', 'website', 'slow', 'amazon', 'par', 'shein', 'admit', 'draw', 'cheap', 'product', 'price', 'thing', 'people', 'consider', 'shop', 'enough', 'get', 'consumer', 'use', 'ring', 'nation', 'want', 'lure', 'funny', 'content', 'push', 'buy', 'ring', 'camera', 'make', 'people', 'often', 'point', 'shein', 'chinese', 'online', 'fastfashion', 'retailer', 'example', 'cheap', 'madeinchina', 'good', 'succeed', 'decadeslong', 'stigma', 'associate', 'indeed', 'take', 'closet', 'storm', 'also', 'need', 'look', 'platform', 'offer', 'cheap', 'chinese', 'good', 'fail', 'reach', 'level', 'influence', 'aliexpress', 'overseas', 'version', 'alibaba', 'around', 'never', 'manage', 'really', 'break', 'even', 'also', 'price', 'product', 'extremely', 'low', 'shein', 'thing', 'right', 'aliexpress', 'didn’t', 'namely', 'market', 'presentation', 'pay', 'influencer', 'try', 'clothe', 'produce', 'glossy', 'youtube', 'tiktok', 'video', 'shein', 'spread', 'idea', 'first', 'foremost', 'product', 'fun', 'trendy', 'fact', 'make', 'secondary', 'difference', 'brand', 'image', 'clear', 'people', 'go', 'aliexpress', 'wish', 'comparable', 'app', 'know', 'want', 'inexpensive', 'people', 'go', 'shein', 'check', 'late', 'fashion', 'trend', 'get', 'affordable', 'price', 'temu', 'shein', 'aliexpress', 'sense', 'far', 'temu', 'look', 'latter', 'real', 'advantage', 'price', 'point', 'model', 'rely', 'ad', 'drive', 'transaction', 'expiration', 'date', '’', 'unfortunately', 'cause', 'demise', 'say', 'point', 'ad', 'become', 'expensive', 'inefficient', 'justify', 'cost', 'go', 'far', 'temu', 'need', 'really', 'differentiate', 'chinese', 'american', 'shopping', 'platform', 'actually', 'pinduoduo', 'effectively', 'know', 'addictive', 'time', 'manipulative', 'app', 'incentivize', 'people', 'share', 'buy', 'social', 'platform', 'get', 'even', 'steep', 'discount', 'past', 'year', 'idea', 'social', 'ecommerce', 'pinduoduo', 'pioneer', 'see', 'successful', 'innovation', 'consumer', 'tech', 'sector', '’', 'also', 'clear', 'idea', 'land', 'shopping', 'industry', 'reluctant', 'accept', 'chinese', 'trend', 'use', 'believe', 'livestream', 'shopping', 'extremely', 'popular', 'accept', 'world', 'fundamentally', 'change', 'ecommerce', 'year', 'later', 'still', 'happen', 'start', 'feel', 'wait', 'godot', 'see', 'small', 'attempt', 'sort', 'experiment', 'zoom', 'look', 'actually', 'change', 'last', 'year', 'much', 'amazon', 'look', 'exactly', 'say', 'perhaps', 'suggest', 'west', 'much', 'established', 'environment', 'economically', 'also', 'technologically', '’', 'unlikely', 'see', 'kind', 'massive', 'disruption', 'see', 'good', 'luck', 'temu', 'meantime', 'probably', 'hear', 'name', 'soon', 'keep', 'resist', 'urge', 'click', 'ubiquitous', 'ad', 'use', 'let', 'know', 'unseal', 'separate', 'criminal', 'case', 'chinese', 'intelligence', 'officer', 'allegedly', 'find', 'interfere', 'investigation', 'huawei', 'apparently', 'fake', 'academic', 'credential', 'obtain', 'sensitive', 'information', 'last', 'reportedly', 'force', 'citizen', 'return', 'key', 'thing', 'understand', 'new', 'top', 'leadership', 'party', 'show', 'concentration', 'power', 'jinpe', 'want', 'know', 'topic', 'jinping', 'mention', 'predecessor', 'party', 'congress', 'speech', 'miss', 'already', 'several', 'quick', 'analysis', 'speech', 'professor', 'taisu', 'political', 'science', 'researcher', 'first', 'time', 'year', '’', 'single', 'woman', 'birth', 'tourism', 'still', 'alive', 'well', 'chinese', 'family', 'look', 'give', 'birth', 'use', 'surrogate', 'process', 'become', 'much', 'difficult', 'border', 'control', 'osno', 'profile', 'guo', 'wengui', 'controversial', 'chinese', 'tycoon', 'close', 'country', 'political', 'elite', 'reinvent', 'darling', 'new', 'chinese', 'filmmaker', 'produce', 'animate', 'virtualreality', 'film', 'show', 'physical', 'mental', 'abuse', 'happen', 'infamous', 'internet', 'addiction', 'clinic', 'sixth', 'tone', 'meta', 'develop', 'first', 'artificialintelligence', 'tool', 'translate', 'hokkien', 'real', 'time', 'language', 'write', 'script', 'speak', 'people', 'country', 'mashable', 'summer', 'overheat', 'chinese', 'electric', 'blanket', 'european', 'brace', 'cold', 'winter', 'energy', 'crisis', 'chinese', 'electric', 'blanket', 'factory', 'suddenly', 'find', 'hot', 'demand', 'pun', 'intend', 'chinese', 'publication', 'white', 'night', 'studio', 'report', 'month', 'factory', 'southern', 'get', 'massive', 'order', 'produce', 'ten', 'thousand', 'electric', 'blanket', 'product', 'slowly', 'disappear', 'recent', 'year', 'summer', 'export', 'electric', 'blanket', 'increase', 'establish', 'factory', 'owner', 'get', 'call', 'day', 'ask', 'supply', 'rookie', 'blindly', 'enter', 'industry', 'open', 'new', 'production', 'line', 'however', 'trend', 'come', 'go', 'quickly', 'order', 'slow', 'market', 'demand', 'meet', '’', 'late', 'blanket', 'make', 'ship', 'sell', 'chill', 'set', 'come', 'butcher', 'pronunciation', 'time', 'maybe', 'friend', 'make', 'fun', 'maybe', 'let', 'go', 'dare', 'correct', 'chinese', 'president', 'give', 'highly', 'anticipate', 'speech', 'front', 'whole', 'chinese', 'population', 'case', 'misspeak', 'become', 'new', 'norm', 'week', 'catch', 'chinese', 'official', 'major', 'chinese', 'language', 'study', 'btw', 'change', 'pronunciation', 'word', 'real', 'time', 'press', 'conference', '20th', 'party', 'likely', 'misspoke', 'word', 'day', 'realise', '3rd', 'pronunciation', 'xiâ€', '™', 'pronunciation', 'give', '20th', 'currently', 'director', 'policy', 'research', 'office', 'know', 'correct', 'pronunciation', 'first', 'degree', 'chinese', 'language', 'pictwittercomcsk1skrnak', 'see', 'next', 'week', 'zeyi']"
We used to get excited about technology. What happened?,https://www.technologyreview.com/2022/10/21/1061260/innovation-technology-what-happened/,2022-10-21,"<p>Innovation that truly serves us all is in scarce supply. That’s a problem.</p>
","This piece is from our forthcoming mortality-themed issue, available from 26 October. If you want to read it when it comes out, you can subscribe to MIT Technology Review for as little as $80 a year. On a recent evening, I sat at home scrolling through my Twitter feed, which—since I’m a philosopher who studies AI and data—is always filled with the latest tech news. After a while, I noticed a heaviness growing in the pit of my stomach, that telltale sign that you are not having a good time. But why? I wasn’t reading news about politics, or the climate crisis, or the pandemic—the usual sources of doomscrolling ennui. I stopped and reflected for a moment. What had I just been looking at?  I had blinked at the aesthetic poverty of the most recent pitch for Meta’s Horizon Worlds VR game, featuring Mark Zuckerberg’s dead-eyed cartoon avatar against a visual background that one Twitter wag charitably compared to “the painted walls of an abandoned day-care center.” I had let out a quiet sigh at the news of Ring Nation, an Amazon-produced TV show featuring “lighthearted viral content” captured from the Ring surveillance empire. I had clenched my jaw at a screenshot of the Stable Diffusion text-to-image model offering up AI artworks in the styles of dozens of unpaid human artists, whose collective labor had been poured into the model’s training data, ground up, and spit back out. I recognized the feeling and I knew its name. It was resignation—that feeling of being stuck in a place you don’t want to be but can’t leave. I was struck by the irony that I studied technology my whole life in order to avoid this kind of feeling. Tech used to be my happy place.  Naturally, I poured my emotion into a tweetstorm: I struck a nerve. As my notifications started blowing up and thousands of replies and retweets started pouring in, the initial dopamine reward for virality gave way to a deeper sadness. A lot of people were sitting with that same heavy feeling in their stomach. Still, there was catharsis in reading so many others give voice to it.  Something is missing from our lives, and from our technology. Its absence is feeding a growing unease being voiced by many who work in tech or study it. It’s what drives the new generation of PhD and postdoctoral researchers I work with at the University of Edinburgh, who are drawing together knowledge from across the technical arts, sciences, and humanistic disciplines to try to figure out what’s gone awry with our tech ecosystem and how to fix it. To do that, we have to understand how and why the priorities in that ecosystem have changed.  The goal of consumer tech development used to be pretty simple: design and build something of value to people, giving them a reason to buy it. A new refrigerator is shiny, cuts down on my energy bills, makes cool-looking ice cubes. So I buy it. Done. A Roomba promises to vacuum the cat hair from under my sofa while I take a nap. Sold! But this vision of tech is increasingly outdated. It’s not enough for a refrigerator to keep food cold; today’s version offers cameras and sensors that can monitor how and what I’m eating, while the Roomba can now send a map of my house to Amazon. The issue here goes far beyond the obvious privacy risks. It’s a sea change in the entire model for innovation and the incentives that drive it. Why settle for a single profit-taking transaction for the company when you can instead design a product that will extract a monetizable data stream from every buyer, returning revenue to the company for years? Once you’ve captured that data stream, you’ll protect it, even to the disadvantage of your customer. After all, if you buy up enough of the market, you can well afford to endure your customers’ anger and frustration. Just ask Mark Zuckerberg. It’s not just consumer tech and social media platforms that have made this shift. The large ag-tech brand John Deere, for example, formerly beloved by its customers, is fighting a “right to repair” movement driven by farmers angry at being forbidden to fix their own machines, lest they disturb the proprietary software sending high-value data on the farmers’ land and crops back to the manufacturer. As more than one commenter on my Twitter thread noted, today in tech we are the product, not the prime beneficiary. The mechanical devices that used to be the product are increasingly just the middlemen. There’s also a shift in who tech innovations today are for. Several respondents objected to my thread by drawing attention to today’s vibrant market in new tech for “geeks” and “nerds”—Raspberry Pis, open-source software tools, programmable robots. As great as many of these are for those with the time, skills, and interest to put them to use, they are tools made for a narrow audience. The thrill of seeing genuine innovation in biomedical technology, such as mRNA vaccines, is likewise dampened when we see the benefits concentrated in the wealthiest countries—the ones already best served by tech. Of course, new technology remains a source of joy and excitement in many places that have historically been denied an equitable share of its comforts. But innovation used to promise us much more than new devices and apps. Engineering and inventing were once professions primarily oriented toward creating more livable infrastructure, rather than disposable stuff.  Technologists’ apparent loss of interest in humane innovation is depleting our collective faith in our own powers of invention.  Vital technologies like roads, power grids, sewers, and transit systems used to be a central part of the engineering enterprise in the US. Nowadays, we treat them as taxpayer burdens, and our best minds and resources are funneled instead into data-hungry consumer devices and apps. If the US is any indicator of the trajectory of global technology development, then deep trouble lies ahead for us all, because we have clearly lost the plot.  The fact is, the visible focus of tech culture is no longer on expanding the frontiers of humane innovation—innovation that serves us all. Even space travel has lost its humanistic vision; today’s frontier is luxury space tourism and billionaires selling credulous investors on fantasies of escape to Mars. With 8 billion people teetering on the precipice of global environmental destruction, we can’t afford a world where the core mission of new tech appears to be “Take the money and run.”  If we continue to turn away from humane applications of tech, we risk feeding a runaway feedback loop that drains our collective will to reinvest in their expansion. The danger is not only that today’s technology fails to be directed to our most urgent civilizational needs. It’s that technologists’ apparent loss of interest in humane innovation is depleting our collective faith in our own powers of invention.  When it stays true to its deepest roots, technology is still driven by a moral impulse: the impulse to construct places, tools, and techniques that can help humans not only survive but flourish together. Of course, that impulse is easily joined to, or pushed aside by, others: the impulses to dominate, exterminate, immiserate, surveil, and control. But those darker motivations aren’t at the heart of our technological capacity as a species. And we can’t let them define the modern technological order. Because if technology loses its association with shared joy and comfort, we risk becoming alienated from one of the most fundamental ways we care for the world and one another. Shannon Vallor is the Baillie Gifford Professor of Ethics of Data and Artificial Intelligence at the University of Edinburgh and director of the Centre for Technomoral Futures in the Edinburgh Futures Institute. ","This piece is from our forthcoming mortality-themed issue, available from 26 October. If you want to read it when it comes out, you can subscribe to MIT Technology Review for as little as $80 a year. On a recent evening, I sat at home scrolling through my Twitter feed, which—since I’m a philosopher who studies AI and data—is always filled with the latest tech news. After a while, I noticed a heaviness growing in the pit of my stomach, that telltale sign that you are not having a good time. But why? I wasn’t reading news about politics, or the climate crisis, or the pandemic—the usual sources of doomscrolling ennui. I stopped and reflected for a moment. What had I just been looking at? I had blinked at the aesthetic poverty of the most recent pitch for Meta’s Horizon Worlds VR game, featuring Mark Zuckerberg’s dead-eyed cartoon avatar against a visual background that one Twitter wag charitably compared to “the painted walls of an abandoned day-care center.” I had let out a quiet sigh at the news of Ring Nation, an Amazon-produced TV show featuring “lighthearted viral content” captured from the Ring surveillance empire. I had clenched my jaw at a screenshot of the Stable Diffusion text-to-image model offering up AI artworks in the styles of dozens of unpaid human artists, whose collective labor had been poured into the model’s training data, ground up, and spit back out. I recognized the feeling and I knew its name. It was resignation—that feeling of being stuck in a place you don’t want to be but can’t leave. I was struck by the irony that I studied technology my whole life in order to avoid this kind of feeling. Tech used to be my happy place. Naturally, I poured my emotion into a tweetstorm: I struck a nerve. As my notifications started blowing up and thousands of replies and retweets started pouring in, the initial dopamine reward for virality gave way to a deeper sadness. A lot of people were sitting with that same heavy feeling in their stomach. Still, there was catharsis in reading so many others give voice to it. Something is missing from our lives, and from our technology. Its absence is feeding a growing unease being voiced by many who work in tech or study it. It’s what drives the new generation of PhD and postdoctoral researchers I work with at the University of Edinburgh, who are drawing together knowledge from across the technical arts, sciences, and humanistic disciplines to try to figure out what’s gone awry with our tech ecosystem and how to fix it. To do that, we have to understand how and why the priorities in that ecosystem have changed. The goal of consumer tech development used to be pretty simple: design and build something of value to people, giving them a reason to buy it. A new refrigerator is shiny, cuts down on my energy bills, makes cool-looking ice cubes. So I buy it. Done. A Roomba promises to vacuum the cat hair from under my sofa while I take a nap. Sold! But this vision of tech is increasingly outdated. It’s not enough for a refrigerator to keep food cold; today’s version offers cameras and sensors that can monitor how and what I’m eating, while the Roomba can now send a map of my house to Amazon. The issue here goes far beyond the obvious privacy risks. It’s a sea change in the entire model for innovation and the incentives that drive it. Why settle for a single profit-taking transaction for the company when you can instead design a product that will extract a monetizable data stream from every buyer, returning revenue to the company for years? Once you’ve captured that data stream, you’ll protect it, even to the disadvantage of your customer. After all, if you buy up enough of the market, you can well afford to endure your customers’ anger and frustration. Just ask Mark Zuckerberg. It’s not just consumer tech and social media platforms that have made this shift. The large ag-tech brand John Deere, for example, formerly beloved by its customers, is fighting a “right to repair” movement driven by farmers angry at being forbidden to fix their own machines, lest they disturb the proprietary software sending high-value data on the farmers’ land and crops back to the manufacturer. As more than one commenter on my Twitter thread noted, today in tech we are the product, not the prime beneficiary. The mechanical devices that used to be the product are increasingly just the middlemen. There’s also a shift in who tech innovations today are for. Several respondents objected to my thread by drawing attention to today’s vibrant market in new tech for “geeks” and “nerds”—Raspberry Pis, open-source software tools, programmable robots. As great as many of these are for those with the time, skills, and interest to put them to use, they are tools made for a narrow audience. The thrill of seeing genuine innovation in biomedical technology, such as mRNA vaccines, is likewise dampened when we see the benefits concentrated in the wealthiest countries—the ones already best served by tech. Of course, new technology remains a source of joy and excitement in many places that have historically been denied an equitable share of its comforts. But innovation used to promise us much more than new devices and apps. Engineering and inventing were once professions primarily oriented toward creating more livable infrastructure, rather than disposable stuff. Technologists’ apparent loss of interest in humane innovation is depleting our collective faith in our own powers of invention. Vital technologies like roads, power grids, sewers, and transit systems used to be a central part of the engineering enterprise in the US. Nowadays, we treat them as taxpayer burdens, and our best minds and resources are funneled instead into data-hungry consumer devices and apps. If the US is any indicator of the trajectory of global technology development, then deep trouble lies ahead for us all, because we have clearly lost the plot. The fact is, the visible focus of tech culture is no longer on expanding the frontiers of humane innovation—innovation that serves us all. Even space travel has lost its humanistic vision; today’s frontier is luxury space tourism and billionaires selling credulous investors on fantasies of escape to Mars. With 8 billion people teetering on the precipice of global environmental destruction, we can’t afford a world where the core mission of new tech appears to be “Take the money and run.” If we continue to turn away from humane applications of tech, we risk feeding a runaway feedback loop that drains our collective will to reinvest in their expansion. The danger is not only that today’s technology fails to be directed to our most urgent civilizational needs. It’s that technologists’ apparent loss of interest in humane innovation is depleting our collective faith in our own powers of invention. When it stays true to its deepest roots, technology is still driven by a moral impulse: the impulse to construct places, tools, and techniques that can help humans not only survive but flourish together. Of course, that impulse is easily joined to, or pushed aside by, others: the impulses to dominate, exterminate, immiserate, surveil, and control. But those darker motivations aren’t at the heart of our technological capacity as a species. And we can’t let them define the modern technological order. Because if technology loses its association with shared joy and comfort, we risk becoming alienated from one of the most fundamental ways we care for the world and one another. Shannon Vallor is the Baillie Gifford Professor of Ethics of Data and Artificial Intelligence at the University of Edinburgh and director of the Centre for Technomoral Futures in the Edinburgh Futures Institute.","['piece', 'forthcoming', 'mortalitytheme', 'issue', 'available', 'want', 'read', 'come', 'subscribe', 'mit', 'technology', 'review', 'little', 'year', 'recent', 'evening', 'sit', 'home', 'scroll', 'twitter', 'feed', '’m', 'philosopher', 'study', 'ai', 'datum', 'always', 'fill', 'late', 'tech', 'news', 'notice', 'heaviness', 'grow', 'pit', 'stomach', 'telltale', 'sign', 'good', 'time', 'read', 'news', 'politic', 'climate', 'crisis', 'pandemic', 'usual', 'source', 'doomscrolle', 'ennui', 'stop', 'reflect', 'moment', 'look', 'blink', 'aesthetic', 'poverty', 'recent', 'pitch', 'world', 'vr', 'game', 'feature', 'deadeye', 'cartoon', 'avatar', 'visual', 'background', 'twitter', 'wag', 'charitably', 'compare', 'paint', 'wall', 'abandon', 'daycare', 'center', 'let', 'quiet', 'sigh', 'news', 'ring', 'amazonproduce', 'tv', 'show', 'feature', 'lighthearted', 'viral', 'content', 'capture', 'ring', 'surveillance', 'empire', 'clench', 'jaw', 'screenshot', 'stable', 'diffusion', 'texttoimage', 'model', 'offer', 'ai', 'artwork', 'style', 'dozen', 'unpaid', 'human', 'artist', 'collective', 'labor', 'pour', 'model', 'training', 'datum', 'grind', 'spit', 'back', 'recognize', 'feeling', 'know', 'name', 'resignation', 'feeling', 'stick', 'place', 'want', 'leave', 'strike', 'irony', 'study', 'technology', 'whole', 'life', 'order', 'avoid', 'kind', 'feel', 'tech', 'use', 'happy', 'place', 'naturally', 'pour', 'emotion', 'tweetstorm', 'strike', 'nerve', 'notification', 'start', 'blow', 'thousand', 'reply', 'retweet', 'start', 'pour', 'initial', 'dopamine', 'reward', 'virality', 'give', 'way', 'deep', 'sadness', 'lot', 'people', 'sit', 'heavy', 'feeling', 'stomach', 'still', 'catharsis', 'read', 'many', 'give', 'voice', 'miss', 'life', 'technology', 'absence', 'feed', 'grow', 'unease', 'voice', 'many', 'work', 'tech', 'study', '’', 'drive', 'new', 'generation', 'postdoctoral', 'researcher', 'work', 'draw', 'together', 'knowledge', 'technical', 'art', 'science', 'humanistic', 'discipline', 'try', 'figure', 'go', 'awry', 'tech', 'ecosystem', 'fix', 'understand', 'priority', 'ecosystem', 'change', 'goal', 'consumer', 'tech', 'development', 'use', 'pretty', 'simple', 'design', 'build', 'value', 'people', 'give', 'reason', 'buy', 'new', 'refrigerator', 'shiny', 'cut', 'energy', 'bill', 'make', 'coollooking', 'ice', 'cube', 'buy', 'roomba', 'promise', 'vacuum', 'cat', 'hair', 'sofa', 'take', 'nap', 'sell', 'vision', 'tech', 'increasingly', 'outdate', '’', 'enough', 'refrigerator', 'keep', 'food', 'cold', 'today', 'version', 'offer', 'camera', 'sensor', 'monitor', 'eat', 'roomba', 'send', 'map', 'house', 'amazon', 'issue', 'go', 'far', 'obvious', 'privacy', 'risk', '’', 'sea', 'change', 'entire', 'model', 'innovation', 'incentive', 'drive', 'settle', 'single', 'profittake', 'transaction', 'company', 'instead', 'design', 'product', 'extract', 'monetizable', 'data', 'stream', 'buyer', 'return', 'revenue', 'company', 'year', 'capture', 'datum', 'stream', 'protect', 'even', 'disadvantage', 'customer', 'buy', 'enough', 'market', 'well', 'afford', 'endure', 'customer', 'anger', 'frustration', 'ask', '’', 'consumer', 'tech', 'social', 'medium', 'platform', 'make', 'shift', 'large', 'agtech', 'brand', 'example', 'formerly', 'belove', 'customer', 'fight', 'right', 'repair', 'movement', 'drive', 'farmer', 'angry', 'forbid', 'fix', 'machine', 'disturb', 'proprietary', 'software', 'send', 'highvalue', 'datum', 'farmer', 'land', 'crop', 'back', 'manufacturer', 'commenter', 'twitter', 'thread', 'note', 'today', 'tech', 'product', 'prime', 'beneficiary', 'mechanical', 'device', 'use', 'product', 'increasingly', 'middleman', '’', 'also', 'shift', 'tech', 'innovation', 'today', 'several', 'respondent', 'object', 'thread', 'draw', 'attention', 'today', 'vibrant', 'market', 'new', 'tech', 'geek', 'nerd', 'raspberry', 'pis', 'opensource', 'software', 'tool', 'programmable', 'robot', 'great', 'many', 'time', 'skill', 'interest', 'put', 'use', 'tool', 'make', 'narrow', 'audience', 'thrill', 'see', 'genuine', 'innovation', 'biomedical', 'technology', 'mrna', 'vaccine', 'likewise', 'dampen', 'see', 'benefit', 'concentrate', 'wealthy', 'country', 'one', 'already', 'well', 'serve', 'tech', 'course', 'new', 'technology', 'remain', 'source', 'joy', 'excitement', 'many', 'place', 'historically', 'deny', 'equitable', 'share', 'comfort', 'innovation', 'use', 'promise', 'much', 'new', 'device', 'app', 'engineering', 'inventing', 'profession', 'primarily', 'orient', 'create', 'livable', 'infrastructure', 'rather', 'disposable', 'stuff', 'technologist', 'apparent', 'loss', 'interest', 'humane', 'innovation', 'deplete', 'collective', 'faith', 'power', 'invention', 'vital', 'technology', 'road', 'power', 'grid', 'sewer', 'transit', 'system', 'use', 'central', 'part', 'engineering', 'enterprise', 'nowadays', 'treat', 'taxpayer', 'burden', 'good', 'mind', 'resource', 'funnel', 'instead', 'datahungry', 'consumer', 'device', 'app', 'indicator', 'trajectory', 'global', 'technology', 'development', 'deep', 'trouble', 'lie', 'ahead', 'clearly', 'lose', 'plot', 'fact', 'visible', 'focus', 'tech', 'culture', 'long', 'expand', 'frontier', 'humane', 'innovation', 'innovation', 'serve', 'even', 'space', 'travel', 'lose', 'humanistic', 'vision', 'today', 'frontier', 'luxury', 'space', 'tourism', 'billionaire', 'sell', 'credulous', 'investor', 'fantasy', 'escape', 'mar', 'people', 'teeter', 'precipice', 'global', 'environmental', 'destruction', 'afford', 'world', 'core', 'mission', 'new', 'tech', 'appear', 'take', 'money', 'run', 'continue', 'turn', 'away', 'humane', 'application', 'tech', 'risk', 'feed', 'runaway', 'feedback', 'loop', 'drain', 'collective', 'reinvest', 'expansion', 'danger', 'today', 'technology', 'fail', 'direct', 'urgent', 'civilizational', 'need', '’', 'technologist', 'apparent', 'loss', 'interest', 'humane', 'innovation', 'deplete', 'collective', 'faith', 'power', 'invention', 'stay', 'true', 'deep', 'root', 'technology', 'still', 'drive', 'moral', 'impulse', 'impulse', 'construct', 'place', 'tool', 'technique', 'help', 'human', 'survive', 'flourish', 'together', 'course', 'impulse', 'easily', 'join', 'push', 'aside', 'impulse', 'dominate', 'exterminate', 'immiserate', 'surveil', 'control', 'dark', 'motivation', 'heart', 'technological', 'capacity', 'specie', 'let', 'define', 'modern', 'technological', 'order', 'technology', 'lose', 'association', 'share', 'joy', 'comfort', 'risk', 'alienate', 'fundamental', 'way', 'care', 'world', 'vallor', 'baillie', 'professor', 'ethic', 'datum', 'artificial', 'intelligence', 'director', 'centre', 'technomoral', 'future']"
The dark side of a super app like WeChat,https://www.technologyreview.com/2022/10/18/1061899/dark-side-super-app-wechat/,2022-10-18,"<p>When one app gives you everything, losing it becomes unbearable.</p>
","China Report is MIT Technology Review’s newsletter about what's happening in China. Sign up to receive it in your inbox every Tuesday. Welcome back to China Report!  I know this is going to be a long week for all of you China watchers. New stories seem to be coming out every minute about the 20th Party Congress that started on Sunday. It’s probably why news of the banner protest in Beijing, which happened only five days ago, already feels antiquated at this point. Over the weekend, I wrote about the digital aftermath of that protest: People—some who shared photos of the protest, others who didn’t know what they did wrong—found their accounts banned from WeChat. They were desperate—publicly begging Tencent, which owns the super app, to restore their accounts and apologizing for talking about the protest at all. If you want to know more about these “confession letters” and hear from users who got banned from WeChat, you can read my story here. While I was writing it, though, I realized that one idea I take for granted might not be so intuitive for people outside China. Is a WeChat account really that valuable? Why is it so devastating when you can’t use one app?  The short answer: In China, your WeChat account forms almost the entirety of your social and digital lives.  One reason is that there simply aren’t many alternatives. Messenger, WhatsApp, Telegram, and Signal are all blocked. SMS messages are inundated with spam and service notifications. iMessages reach a small crowd, because only about 20% of smartphones in China are iPhones (compared with over 50% in the US). And email is basically nonexistent among the general population. No matter whether you are talking to a family member, a schoolmate, or a colleague, WeChat is the only way to go. While it started out dominating one-on-one messaging and group chats, over time WeChat incorporated all the services you would want from the internet: digital payment, shopping, streaming, networking, ride-hailing … you name it, it’s probably there. In 2017, WeChat even launched in-app “mini programs,” which basically allow you to access non-Tencent services—like Airbnb, Weibo, and office tools—without ever leaving the platform. It’s a whole operating system within an app. Sounds quite convenient, no? But it means you are never leaving the app, period. So losing a WeChat account means losing all of the above. As I wrote, it’s not easy to get your WeChat account back; it’s actually easier to regain access to these other services individually. But even then, you’re stuck rebuilding the social network you may have created over a decade on the app. “When I was adding contacts back, I was questioned if I was a scammer,” one banned user told me. Fixing these connections is arguably the hardest part.  But the impact of WeChat is not just personal. WeChat is so popular and so ubiquitous that it has influenced Chinese society as a whole.  Yiqin Fu, who studies political science at Stanford, tells me WeChat’s quest for a monopoly on content consumption has even shaped how knowledge creation in China works. Because people spend so many hours on WeChat every day, they often get the majority of their information from articles published in the app. But these articles are not indexed by Google-like search engines (a product decision by WeChat), meaning people are discouraged from searching for content outside the app and instead just passively consume what shows up on their timelines.  This also makes it hard to find articles published not even that long ago. To use Fu’s example, she could write a blog post in English and publish it on a website, where it would receive new views years after its publication, many via search. If the same content were published in Chinese and on WeChat, it would disappear from public attention after a few days. As a result, creators, including intellectuals, are incentivized to focus exclusively on content to be consumed at the moment—short, fragmental, surface-level takes. The closed and comprehensive nature of the WeChat system is part of its secret sauce for commercial success. By keeping users trapped in a single app, WeChat makes it harder for challengers to threaten its own dominance. But this has also transformed WeChat into a dangerous tool to be wielded by those in power. The bans of users who talked about the protest in Beijing are a great example. By driving alternative communication platforms out of existence, WeChat made it easier for the government to police people’s speech through one central hub. Could the same thing happen in the US? I think it would be difficult. WeChat emerged back in 2011, before norms were set for much of the internet in China. In the US today, it would take significantly more for an app, even one as well known as Twitter or Facebook, to successfully penetrate the many different markets WeChat did.  But that won’t stop companies from trying. Tech moguls like Elon Musk (surprise, surprise) often point to WeChat as a desirable vision for super apps. Yes, this kind of platform can make digital experiences more convenient for a lot of users. But the concentration of power can have many unintended, and often negative, consequences—at least for users. This is not a thought experiment; we are already witnessing it with WeChat. Proponents of the super app fantasy may say that things will be different when it’s in a democratic country. Sorry—I have to be more pessimistic than that. How would you feel about using more super apps? Let me know at zeyi@technologyreview.com. 1. When activists in China talk about #MeToo, they say “🍚🐰” or #米兔 (which translates to “rice rabbit” but sounds like “me too”) to bypass online censors. That’s just one of many clever or funny puns used for evasive purposes. (Rest of World) 2. The first casualties of Biden’s new chip export control have emerged: the American citizens and permanent residents who work for Chinese chip companies. (Nikkei Asia $)  3. Chinese state researchers have suggested forming a pan-Asian digital currency to reduce the region’s dependence on the US dollar. (South China Morning Post $) 4. How a Chinese-American gangster made money-laundering “cheap, fast, and efficient” for Mexican drug cartels. (ProPublica)  5. Despite China’s crackdown on cryptocurrencies, the domestic crypto industry persists. There was even a 400-person web3 conference in August, with events dispersed in bars and restaurants all over the city of Dali. (Bloomberg $) 6. No more human influencers: Chinese brands are now paying virtual influencers for advertising. Apparently, they’re both ageless and more controllable. (Financial Times $) 7. Syrian refugees are asking for donations on TikTok livestreams, but the platform takes a big cut of the cash gifts—as much as 70%! (BBC) 8. China is delaying the release of its third-quarter GDP data as the country’s economic growth is expected to miss its annual target (5.5%). (Quartz) “Remote internships” in China are not what they sound like. As the Chinese publication Connecting reports, Chinese college students are paying as much as $20,000 to get fake internships, where they “work” as remote, unofficial assistants to employees of top companies, just to make their résumés look better. The whole industry is built on lies: the “supervisors” are often entry-level employees who aren’t allowed to have interns or share corporate documents, and the so-called interns are given made-up tasks that can’t actually improve their skills. But as the job market gets increasingly competitive in China, these students believe that just the name of a top company on their résumés could be a game-changer to secure better jobs. And they are willing to pay a hefty fee for it. As Chinese president Xi Jinping was making his two-hour-long speech on Sunday to commence the 20th Party Congress, so many WeChat users started sharing the speech’s livestream link to their timelines that WeChat was flooded with the same red rectangular previews on repeat. Other users, less enthusiastic about the event, created a different red rectangle—adapting a popular meme where an elderly man is squinting at his phone, looking disgusted.  See you next week (after the Party Congress)! Zeyi ","China Report is MIT Technology Review’s newsletter about what's happening in China. Sign up to receive it in your inbox every Tuesday. Welcome back to China Report! I know this is going to be a long week for all of you China watchers. New stories seem to be coming out every minute about the 20th Party Congress that started on Sunday. It’s probably why news of the banner protest in Beijing, which happened only five days ago, already feels antiquated at this point. Over the weekend, I wrote about the digital aftermath of that protest: People—some who shared photos of the protest, others who didn’t know what they did wrong—found their accounts banned from WeChat. They were desperate—publicly begging Tencent, which owns the super app, to restore their accounts and apologizing for talking about the protest at all. If you want to know more about these “confession letters” and hear from users who got banned from WeChat, you can read my story here. While I was writing it, though, I realized that one idea I take for granted might not be so intuitive for people outside China. Is a WeChat account really that valuable? Why is it so devastating when you can’t use one app? The short answer: In China, your WeChat account forms almost the entirety of your social and digital lives. One reason is that there simply aren’t many alternatives. Messenger, WhatsApp, Telegram, and Signal are all blocked. SMS messages are inundated with spam and service notifications. iMessages reach a small crowd, because only about 20% of smartphones in China are iPhones (compared with over 50% in the US). And email is basically nonexistent among the general population. No matter whether you are talking to a family member, a schoolmate, or a colleague, WeChat is the only way to go. While it started out dominating one-on-one messaging and group chats, over time WeChat incorporated all the services you would want from the internet: digital payment, shopping, streaming, networking, ride-hailing … you name it, it’s probably there. In 2017, WeChat even launched in-app “mini programs,” which basically allow you to access non-Tencent services—like Airbnb, Weibo, and office tools—without ever leaving the platform. It’s a whole operating system within an app. Sounds quite convenient, no? But it means you are never leaving the app, period. So losing a WeChat account means losing all of the above. As I wrote, it’s not easy to get your WeChat account back; it’s actually easier to regain access to these other services individually. But even then, you’re stuck rebuilding the social network you may have created over a decade on the app. “When I was adding contacts back, I was questioned if I was a scammer,” one banned user told me. Fixing these connections is arguably the hardest part. But the impact of WeChat is not just personal. WeChat is so popular and so ubiquitous that it has influenced Chinese society as a whole. Yiqin Fu, who studies political science at Stanford, tells me WeChat’s quest for a monopoly on content consumption has even shaped how knowledge creation in China works. Because people spend so many hours on WeChat every day, they often get the majority of their information from articles published in the app. But these articles are not indexed by Google-like search engines (a product decision by WeChat), meaning people are discouraged from searching for content outside the app and instead just passively consume what shows up on their timelines. This also makes it hard to find articles published not even that long ago. To use Fu’s example, she could write a blog post in English and publish it on a website, where it would receive new views years after its publication, many via search. If the same content were published in Chinese and on WeChat, it would disappear from public attention after a few days. As a result, creators, including intellectuals, are incentivized to focus exclusively on content to be consumed at the moment—short, fragmental, surface-level takes. The closed and comprehensive nature of the WeChat system is part of its secret sauce for commercial success. By keeping users trapped in a single app, WeChat makes it harder for challengers to threaten its own dominance. But this has also transformed WeChat into a dangerous tool to be wielded by those in power. The bans of users who talked about the protest in Beijing are a great example. By driving alternative communication platforms out of existence, WeChat made it easier for the government to police people’s speech through one central hub. Could the same thing happen in the US? I think it would be difficult. WeChat emerged back in 2011, before norms were set for much of the internet in China. In the US today, it would take significantly more for an app, even one as well known as Twitter or Facebook, to successfully penetrate the many different markets WeChat did. But that won’t stop companies from trying. Tech moguls like Elon Musk (surprise, surprise) often point to WeChat as a desirable vision for super apps. Yes, this kind of platform can make digital experiences more convenient for a lot of users. But the concentration of power can have many unintended, and often negative, consequences—at least for users. This is not a thought experiment; we are already witnessing it with WeChat. Proponents of the super app fantasy may say that things will be different when it’s in a democratic country. Sorry—I have to be more pessimistic than that. How would you feel about using more super apps? Let me know at zeyi@technologyreview.com. 1. When activists in China talk about #MeToo, they say “🍚🐰” or #米兔 (which translates to “rice rabbit” but sounds like “me too”) to bypass online censors. That’s just one of many clever or funny puns used for evasive purposes. (Rest of World) 2. The first casualties of Biden’s new chip export control have emerged: the American citizens and permanent residents who work for Chinese chip companies. (Nikkei Asia $) 3. Chinese state researchers have suggested forming a pan-Asian digital currency to reduce the region’s dependence on the US dollar. (South China Morning Post $) 4. How a Chinese-American gangster made money-laundering “cheap, fast, and efficient” for Mexican drug cartels. (ProPublica) 5. Despite China’s crackdown on cryptocurrencies, the domestic crypto industry persists. There was even a 400-person web3 conference in August, with events dispersed in bars and restaurants all over the city of Dali. (Bloomberg $) 6. No more human influencers: Chinese brands are now paying virtual influencers for advertising. Apparently, they’re both ageless and more controllable. (Financial Times $) 7. Syrian refugees are asking for donations on TikTok livestreams, but the platform takes a big cut of the cash gifts—as much as 70%! (BBC) 8. China is delaying the release of its third-quarter GDP data as the country’s economic growth is expected to miss its annual target (5.5%). (Quartz) “Remote internships” in China are not what they sound like. As the Chinese publication Connecting reports, Chinese college students are paying as much as $20,000 to get fake internships, where they “work” as remote, unofficial assistants to employees of top companies, just to make their résumés look better. The whole industry is built on lies: the “supervisors” are often entry-level employees who aren’t allowed to have interns or share corporate documents, and the so-called interns are given made-up tasks that can’t actually improve their skills. But as the job market gets increasingly competitive in China, these students believe that just the name of a top company on their résumés could be a game-changer to secure better jobs. And they are willing to pay a hefty fee for it. As Chinese president Xi Jinping was making his two-hour-long speech on Sunday to commence the 20th Party Congress, so many WeChat users started sharing the speech’s livestream link to their timelines that WeChat was flooded with the same red rectangular previews on repeat. Other users, less enthusiastic about the event, created a different red rectangle—adapting a popular meme where an elderly man is squinting at his phone, looking disgusted. See you next week (after the Party Congress)! Zeyi","['mit', 'technology', 'review', 'newsletter', 'happen', 'sign', 'receive', 'inbox', 'welcome', 'know', 'go', 'long', 'week', 'watcher', 'new', 'story', 'seem', 'come', 'minute', '20th', 'party', 'start', '’', 'probably', 'news', 'banner', 'protest', 'happen', 'day', 'ago', 'already', 'feel', 'antiquated', 'point', 'weekend', 'write', 'digital', 'aftermath', 'protest', 'people', 'share', 'photo', 'protest', 'know', 'wrong', 'find', 'account', 'ban', 'desperate', 'publicly', 'beg', 'tencent', 'super', 'app', 'restore', 'account', 'apologize', 'talk', 'protest', 'want', 'know', 'confession', 'letter', 'hear', 'user', 'ban', 'read', 'story', 'write', 'realize', 'idea', 'take', 'grant', 'intuitive', 'people', 'wechat', 'account', 'really', 'valuable', 'devastating', 'use', 'app', 'short', 'answer', 'wechat', 'account', 'form', 'almost', 'entirety', 'social', 'digital', 'live', 'reason', 'simply', 'many', 'alternative', 'messenger', 'whatsapp', 'signal', 'block', 'sm', 'message', 'inundate', 'spam', 'service', 'notification', 'imessage', 'reach', 'small', 'crowd', 'smartphone', 'iphone', 'compare', 'email', 'basically', 'nonexistent', 'general', 'population', 'matter', 'talk', 'family', 'member', 'schoolmate', 'colleague', 'wechat', 'way', 'go', 'start', 'dominate', 'oneonone', 'messaging', 'group', 'chat', 'time', 'incorporate', 'service', 'want', 'internet', 'digital', 'payment', 'shopping', 'streaming', 'network', 'ridehaile', 'name', '’', 'probably', 'even', 'launch', 'inapp', 'mini', 'program', 'basically', 'allow', 'access', 'nontencent', 'service', 'airbnb', 'weibo', 'office', 'tool', 'ever', 'leave', 'platform', '’', 'whole', 'operating', 'system', 'app', 'sound', 'quite', 'convenient', 'mean', 'never', 'leave', 'period', 'lose', 'wechat', 'account', 'mean', 'lose', 'write', '’', 'easy', 'get', 'wechat', 'account', 'back', '’', 'actually', 'easy', 'regain', 'access', 'service', 'individually', 'even', '’re', 'stick', 'rebuild', 'social', 'network', 'create', 'decade', 'app', 'add', 'contact', 'back', 'question', 'scammer', 'ban', 'user', 'tell', 'fix', 'connection', 'arguably', 'hard', 'part', 'impact', 'wechat', 'personal', 'wechat', 'popular', 'ubiquitous', 'influence', 'chinese', 'society', 'whole', 'yiqin', 'fu', 'study', 'political', 'science', 'tell', 'quest', 'monopoly', 'content', 'consumption', 'even', 'shape', 'knowledge', 'creation', 'work', 'people', 'spend', 'many', 'hour', 'day', 'often', 'get', 'majority', 'information', 'article', 'publish', 'app', 'article', 'index', 'googlelike', 'search', 'engine', 'product', 'decision', 'meaning', 'people', 'discourage', 'search', 'content', 'app', 'instead', 'passively', 'consume', 'show', 'timeline', 'also', 'make', 'hard', 'find', 'article', 'publish', 'even', 'long', 'ago', 'use', '’s', 'example', 'write', 'blog', 'post', 'publish', 'website', 'receive', 'new', 'view', 'year', 'publication', 'many', 'search', 'content', 'publish', 'disappear', 'public', 'attention', 'day', 'result', 'creator', 'include', 'intellectual', 'incentivize', 'focus', 'exclusively', 'content', 'consume', 'moment', 'short', 'fragmental', 'surfacelevel', 'take', 'closed', 'comprehensive', 'nature', 'wechat', 'system', 'part', 'secret', 'sauce', 'commercial', 'success', 'keep', 'user', 'trap', 'single', 'app', 'make', 'hard', 'challenger', 'threaten', 'dominance', 'also', 'transform', 'dangerous', 'tool', 'wield', 'power', 'ban', 'user', 'talk', 'protest', 'great', 'example', 'drive', 'alternative', 'communication', 'platform', 'existence', 'make', 'easy', 'government', 'police', 'people', 'speech', 'central', 'hub', 'thing', 'happen', 'think', 'difficult', 'wechat', 'emerge', 'back', 'norm', 'set', 'much', 'internet', 'today', 'take', 'significantly', 'app', 'even', 'well', 'know', 'twitter', 'facebook', 'successfully', 'penetrate', 'many', 'different', 'market', 'stop', 'company', 'try', 'tech', 'mogul', 'elon', 'musk', 'surprise', 'surprise', 'often', 'point', 'desirable', 'vision', 'super', 'app', 'kind', 'platform', 'make', 'digital', 'experience', 'convenient', 'lot', 'user', 'concentration', 'power', 'many', 'unintended', 'often', 'negative', 'consequence', 'least', 'user', 'thought', 'experiment', 'already', 'witness', 'proponent', 'super', 'app', 'fantasy', 'say', 'thing', 'different', '’', 'democratic', 'country', 'sorry', 'pessimistic', 'feel', 'use', 'super', 'app', 'let', 'know', 'activist', 'talk', 'metoo', 'say', '🍚', '🐰', 'translate', 'rice', 'rabbit', 'sound', 'bypass', 'online', 'censor', '’', 'many', 'clever', 'funny', 'pun', 'use', 'evasive', 'purpose', 'rest', 'world', 'first', 'casualty', 'new', 'chip', 'export', 'control', 'emerge', 'american', 'citizen', 'permanent', 'resident', 'work', 'chinese', 'chip', 'company', 'chinese', 'state', 'researcher', 'suggest', 'form', 'panasian', 'digital', 'currency', 'reduce', 'region', 'dependence', 'gangster', 'make', 'moneylaundere', 'cheap', 'fast', 'efficient', 'mexican', 'drug', 'cartel', 'crackdown', 'cryptocurrencie', 'domestic', 'crypto', 'industry', 'persist', 'even', 'web3', 'conference', 'event', 'disperse', 'bar', 'restaurant', 'city', 'human', 'influencer', 'chinese', 'brand', 'pay', 'virtual', 'influencer', 'advertising', 'apparently', '’re', 'ageless', 'controllable', 'financial', 'time', 'syrian', 'refugee', 'ask', 'donation', 'tiktok', 'livestream', 'platform', 'take', 'big', 'cut', 'cash', 'gift', 'much', 'delay', 'release', 'thirdquarter', 'gdp', 'datum', 'country', 'economic', 'growth', 'expect', 'miss', 'annual', 'target', 'quartz', 'remote', 'internship', 'sound', 'chinese', 'publication', 'connect', 'report', 'chinese', 'college', 'student', 'pay', 'much', 'get', 'fake', 'internship', 'work', 'remote', 'unofficial', 'assistant', 'employee', 'top', 'company', 'make', 'résumés', 'look', 'well', 'whole', 'industry', 'build', 'lie', 'supervisor', 'often', 'entrylevel', 'employee', 'allow', 'intern', 'share', 'corporate', 'document', 'socalle', 'intern', 'give', 'madeup', 'task', 'actually', 'improve', 'skill', 'job', 'market', 'get', 'increasingly', 'competitive', 'student', 'believe', 'name', 'top', 'company', 'résumés', 'gamechanger', 'secure', 'well', 'job', 'willing', 'pay', 'hefty', 'fee', 'chinese', 'make', 'twohourlong', 'speech', 'commence', '20th', 'party', 'many', 'user', 'start', 'share', 'speech', 'livestream', 'link', 'timeline', 'flood', 'red', 'rectangular', 'preview', 'repeat', 'user', 'less', 'enthusiastic', 'event', 'create', 'different', 'red', 'rectangle', 'adapt', 'popular', 'meme', 'elderly', 'man', 'squint', 'phone', 'look', 'disgusted', 'see', 'next', 'week', 'party', 'zeyi']"
Technology that lets us “speak” to our dead relatives has arrived. Are we ready?,https://www.technologyreview.com/2022/10/18/1061320/digital-clones-of-dead-people/,2022-10-18,"<p>Digital clones of the people we love could forever change how we grieve.</p>
","My parents don’t know that I spoke to them last night.  At first, they sounded distant and tinny, as if they were huddled around a phone in a prison cell. But as we chatted, they slowly started to sound more like themselves. They told me personal stories that I’d never heard. I learned about the first (and certainly not last) time my dad got drunk. Mum talked about getting in trouble for staying out late. They gave me life advice and told me things about their childhoods, as well as my own. It was mesmerizing.  “What’s the worst thing about you?” I asked Dad, since he was clearly in such a candid mood. “My worst quality is that I am a perfectionist. I can’t stand messiness and untidiness, and that always presents a challenge, especially with being married to Jane.”  Then he laughed—and for a moment I forgot I wasn’t really speaking to my parents at all, but to their digital replicas.  This Mum and Dad live inside an app on my phone, as voice assistants constructed by the California-based company HereAfter AI and powered by more than four hours of conversations they each had with an interviewer about their lives and memories. (For the record, Mum isn’t that untidy.) The company’s goal is to let the living communicate with the dead. I wanted to test out what it might be like. Technology like this, which lets you “talk” to people who’ve died, has been a mainstay of science fiction for decades. It’s an idea that’s been peddled by charlatans and spiritualists for centuries. But now it’s becoming a reality—and an increasingly accessible one, thanks to advances in AI and voice technology.  My real, flesh-and-blood parents are still alive and well; their virtual versions were just made to help me understand the technology. But their avatars offer a glimpse at a world where it’s possible to converse with loved ones—or simulacra of them—long after they’re gone.  From what I could glean over a dozen conversations with my virtually deceased parents, this really will make it easier to keep close the people we love. It’s not hard to see the appeal. People might turn to digital replicas for comfort, or to mark special milestones like anniversaries.  At the same time, the technology and the world it’s enabling are, unsurprisingly, imperfect, and the ethics of creating a virtual version of someone are complex, especially if that person hasn’t been able to provide consent.  For some, this tech may even be alarming, or downright creepy. I spoke to one man who’d created a virtual version of his mother, which he booted up and talked to at her own funeral. Some people argue that conversing with digital versions of lost loved ones could prolong your grief or loosen your grip on reality. And when I talked to friends about this article, some of them physically recoiled. There’s a common, deeply held belief that we mess with death at our peril.  I understand these concerns. I found speaking to a virtual version of my parents uncomfortable, especially at first. Even now, it still feels slightly transgressive to speak to an artificial version of someone—especially when that someone is in your own family.  But I’m only human, and those worries end up being washed away by the even scarier prospect of losing the people I love—dead and gone without a trace. If technology might help me hang onto them, is it so wrong to try? There’s something deeply human about the desire to remember the people we love who’ve passed away. We urge our loved ones to write down their memories before it’s too late. After they’re gone, we put up their photos on our walls. We visit their graves on their birthdays. We speak to them as if they were there. But the conversation has always been one-way. The idea that technology might be able to change the situation has been widely explored in ultra-dark sci-fi shows like Black Mirror—which, startups in this sector complain, everyone inevitably brings up. In one 2013 episode, a woman who loses her partner re-creates a digital version of him—initially as a chatbot, then as an almost totally convincing voice assistant, and eventually as a physical robot. Even as she builds more expansive versions of him, she becomes frustrated and disillusioned by the gaps between her memory of her partner and the shonky, flawed reality of the technology used to simulate him. If technology might help me hang onto the people I love, is it so wrong to try? “You aren’t you, are you? You’re just a few ripples of you. There’s no history to you. You’re just a performance of stuff that he performed without thinking, and it’s not enough,” she says before she consigns the robot to her attic—an embarrassing relic of her boyfriend that she’d rather not think about.  Back in the real world, the technology has evolved even in the past several years to a somewhat startling degree. Rapid advances in AI have driven progress across multiple areas. Chatbots and voice assistants, like Siri and Alexa, have gone from high-tech novelties to a part of daily life for millions of people over the past decade. We have become very comfortable with the idea of talking to our devices about everything from the weather forecast to the meaning of life. Now, AI large language models (LLMs), which can ingest a few “prompt” sentences and spit out convincing text in response, promise to unlock even more powerful ways for humans to communicate with machines. LLMs have become so convincing that some (erroneously) have argued that they must be sentient. What’s more, it’s possible to tweak LLM software like OpenAI’s GPT-3 or Google’s LaMDA to make it sound more like a specific person by feeding it lots of things that person said. In one example of this, journalist Jason Fagone wrote a story for the San Francisco Chronicle last year about a thirtysomething man who uploaded old texts and Facebook messages from his deceased fiancée to create a simulated chatbot version of her, using software known as Project December that was built on GPT-3.  By almost any measure, it was a success: he sought, and found, comfort in the bot. He’d been plagued with guilt and sadness in the years since she died, but as Fagone writes, “he felt like the chatbot had given him permission to move on with his life in small ways.” The man even shared snippets of his chatbot conversations on Reddit, hoping, he said, to bring attention to the tool and “help depressed survivors find some closure.” The lab trained a chatbot to learn from human feedback and search the internet for information to support its claims. At the same time, AI has progressed in its ability to mimic specific physical voices, a practice called voice cloning. It has also been getting better at injecting digital personas—whether cloned from a real person or completely artificial—with more of the qualities that make a voice sound “human.” In a poignant demonstration of how rapidly the field is progressing, Amazon shared a clip in June of a little boy listening to a passage from The Wizard of Oz read by his recently deceased grandmother. Her voice was artificially re-created using a clip of her speaking that lasted for less than a minute.  As Rohit Prasad, Alexa’s senior vice president and head scientist, promised: “While AI can’t eliminate that pain of loss, it can definitely make the memories last.” My own experience with talking to the dead started thanks to pure serendipity.  At the end of 2019, I saw that James Vlahos, the cofounder of HereAfter AI, would be speaking at an online conference about “virtual beings.” His company is one of a handful of startups working in the field I’ve dubbed “grief tech.” They differ in their approaches but share the same promise: to enable you to talk by video chat, text, phone, or voice assistant with a digital version of someone who is no longer alive.  Intrigued by what he was promising, I wrangled an introduction and eventually persuaded Vlahos and his colleagues to let me experiment with their software on my very-much-alive parents.  Initially, I thought it would be just a fun project to see what was technologically possible. Then the pandemic added some urgency to the proceedings. Images of people on ventilators, photos of rows of coffins and freshly dug graves, were splashed all over the news. I worried about my parents. I was terrified that they might die, and that with the strict restrictions on hospital visits in force at the time in the UK, I might never have the chance to say goodbye.  The first step was an interview. As it turns out, to create a digital replica of someone with a good chance of seeming like a convincingly authentic representation, you need data—and lots of it. HereAfter, whose work starts with subjects when they are still alive, asks them questions for hours—about everything from their earliest memories to their first date to what they believe will happen after they die. (My parents were interviewed by a real live human, but in yet another sign of just how quickly technology is progressing, almost two years later interviews are now typically automated and handled by a bot.) As my sister and I rifled through pages of suggested questions for our parents, we were able to edit them to be more personal or pointed, and we could add some of our own: What books did they like? How did our mum muscle her way into the UK’s overwhelmingly male, privileged legal sector in the 1970s? What inspired Dad to invent the silly games he used to play with us when we were small?  Whether through pandemic-induced malaise or a weary willingness to humor their younger daughter, my parents put up zero resistance. In December 2020, HereAfter’s interviewer, a friendly woman named Meredith, spoke to each of them for several hours. The company then took those responses and started stitching them together to create the voice assistants.  A couple of months later, a note popped into my inbox from Vlahos. My virtual parents were ready. On one occasion, my husband mistook my testing for an actual phone call. When he realized it wasn’t, he rolled his eyes, as if I were completely deranged. This Mum and Dad arrived via email attachment. I could communicate with them through the Alexa app on a phone or an Amazon Echo device. I was eager to hear them—but I had to wait several days, because I’d promised MIT Technology Review’s podcast team that I’d record my reaction as I spoke to my parents’ avatars for the first time. When I finally opened the file, with my colleagues watching and listening on Zoom, my hands were shaking. London was in a long, cold, depressing lockdown, and I hadn’t seen my actual, real parents for six months.  “Alexa, open HereAfter,” I directed. “Would you rather speak with Paul or with Jane?” a voice asked. After a bit of quick mental deliberation, I opted for my mum. A voice that was hers, but weirdly stiff and cold, spoke.  “Hello, this is Jane Jee and I’m happy to tell you about my life. How are you today?” I laughed, nervously.  “I’m well, thanks, Mum. How are you?” Long pause. “Good. At my end, I’m doing well.” “You sound kind of unnatural,” I said. She ignored me and carried on speaking. “Before we start, here are a few pointers. My listening skills aren’t the best, unfortunately, so you have to wait until I’ve finished talking and ask you a question before you say something back. When it’s your turn to speak, please keep your answers fairly short. A few words, a simple sentence—that type of thing,” she explained. After a bit more introduction, she concluded: “Okay, let’s get started. There’s so much to talk about. My childhood, career, and my interests. Which of those sounds best?” Scripted bits like this sounded stilted and strange, but as we moved on, with my mother recounting memories and speaking in her own words, “she” sounded far more relaxed and natural.  Still, this conversation and the ones that followed were limited—when I tried asking my mum’s bot about her favorite jewelry, for instance, I got: “Sorry, I didn’t understand that. You can try asking another way, or move onto another topic.” There were also mistakes that were jarring to the point of hilarity. One day, Dad’s bot asked me how I was. I replied, “I’m feeling sad today.” He responded with a cheery, upbeat “Good!” The overall experience was undeniably weird. Every time I spoke to their virtual versions, it struck me that I could have been talking to my real parents instead. On one occasion, my husband mistook my testing out the bots for an actual phone call. When he realized it wasn’t, he rolled his eyes, tutted, and shook his head, as if I were completely deranged.  Earlier this year, I got a demo of a similar technology from a five-year-old startup called StoryFile, which promises to take things to the next level. Its Life service records responses on video rather than just voice alone.  You can pick from hundreds of questions for the subject. Then you record the person answering the questions; this can be done on any device with a camera and a microphone, including a smartphone, though the higher-quality the recording, the better the outcome. After uploading the files, the company turns them into a digital version of the person you can see and speak to. It can only answer the questions it’s been programmed to answer—much like HereAfter, just with video. StoryFile’s CEO, Stephen Smith, demonstrated the technology on a video call, where we were joined by his mother. She died earlier this year, but here she was on the call, sitting in a comfortable chair in her living room. For a brief time, I could only see her, shared via Smith’s screen. She was soft-spoken, with wispy hair and friendly eyes. She dispensed life advice. She seemed wise.  Smith told me that his mother “attended” her own funeral: “At the end she said, ‘I guess that’s it from me … goodbye!’ and everyone burst into tears.” He told me her digital participation was well received by family and friends. And, arguably most important of all, Smith said he’s deeply comforted by the fact that he managed to capture his mother on camera before she passed away.   The video technology itself looked relatively slick and professional—though the result still fell vaguely within the uncanny valley, especially in the facial expressions. At points, much as with my own parents, I had to remind myself that she wasn’t really there. Both HereAfter and StoryFile aim to preserve someone’s life story rather than allowing you to have a full, new conversation with the bot each time. This is one of the major limitations of many current offerings in grief tech: they’re generic. These replicas may sound like someone you love, but they know nothing about you. Anyone can talk to them, and they’ll reply in the same tone. And the replies to a given question are the same every time you ask.   “The biggest issue with the [existing] technology is the idea you can generate a single universal person,” says Justin Harrison, founder of a soon-to-launch service called You, Only Virtual. “But the way we experience people is unique to us.”  Language models are mindless mimics that do not understand what they are saying—so why do we pretend they’re experts? You, Only Virtual and a few other startups want to go further, arguing that recounting memories won’t capture the fundamental essence of a relationship between two people. Harrison wants to create a personalized bot that’s for you and you alone.  The first incarnation of the service, which is set to launch in early 2023, will allow people to build a bot by uploading someone’s text messages, emails, and voice conversations. Ultimately, Harrison hopes, people will feed it data as they go; the company is currently building a communication platform that customers will be able to use to message and talk with loved ones while they’re still alive. That way, all the data will be readily available to be turned into a bot once they’re not.  That is exactly what Harrison has done with his mother, Melodi, who has stage 4 cancer: “I built it by hand using five years of my messages with her. It took 12 hours to export, and it runs to thousands of pages,” he says of his chatbot. Harrison says the interactions he has with the bot are more meaningful to him than if it were simply regurgitating memories. Bot Melodi uses the phrases his mother uses and replies to him in the way she’d reply—calling him “honey,” using the emojis she’d use and the same quirks of spelling. He won’t be able to ask Melodi’s avatar questions about her life, but that doesn’t bother him. The point, for him, is to capture the way someone communicates. “Just recounting memories has little to do with the essence of a relationship,” he says. Avatars that people feel a deep personal connection with can have staying power. In 2016, entrepreneur Eugenia Kuyda built what is thought to be the first bot of this kind after her friend Roman died, using her text conversations with him. (She later founded a startup called Replika, which creates virtual companions not based on real people.)  She found it a hugely helpful way to process her grief, and she still speaks to Roman’s bot today, she says, especially around his birthday and the anniversary of his passing. But she warns that users need to be careful not to think this technology is re-creating or even preserving people. “I didn’t want to bring back his clone, but his memory,” she says. The intention was to “create a digital monument where you can interact with that person, not in order to pretend they’re alive, but to hear about them, remember how they were, and be inspired by them again.” Some people find that hearing the voices of their loved ones after they’ve gone helps with the grieving process. It’s not uncommon for people to listen to voicemails from someone who has died, for example, says Erin Thompson, a clinical psychologist who specializes in grief. A virtual avatar that you can have more of a conversation with could be a valuable, healthy way to stay connected to someone you loved and lost, she says.   But Thompson and others echo Kuyda’s warning: it’s possible to put too much weight on the technology. A grieving person needs to remember that these bots can only ever capture a small sliver of someone. They are not sentient, and they will not replace healthy, functional human relationships.  People may find any reminders of the deceased person triggering: “In the acute phase of grief, you can get a strong sense of unreality, not being able to accept they’re gone.” “Your parents are not really there. You’re talking to them, but it’s not really them,” says Erica Stonestreet, an associate professor of philosophy at the College of Saint Benedict & Saint John’s University, who studies personhood and identity.  Particularly in the first weeks and months after a loved one dies, people struggle to accept the loss and may find any reminders of the person triggering. “In the acute phase of grief, you can get a strong sense of unreality, not being able to accept they’re gone,” Thompson says. There’s a risk that this sort of intense grief could intersect with, or even cause, mental illness, especially if it’s constantly being fueled and prolonged by reminders of the person who’s passed away.  Arguably, this risk might be small today given these technologies’ flaws. Even though sometimes I fell for the illusion, it was clear my parent bots were not in fact the real deal. But the risk that people might fall too deeply for the phantom of personhood will surely grow as the technology improves.  And there are still other risks. Any service that allows you to create a digital replica of someone without their participation raises some complex ethical issues regarding consent and privacy. While some might argue that permission is less important with someone no longer alive, can’t you also argue that the person who generated the other side of the conversation should have a say too?  And what if that person is not, in fact, dead? There’s little to stop people from using grief tech to create virtual versions of living people without their consent—for example, an ex. Companies that sell services powered by past messages are aware of this possibility and say they will delete a person’s data if that individual requests it. But companies are not obliged to do any checks to make sure their technology is being limited to people who have consented or died. There’s no law to stop anyone from creating avatars of other people, and good luck explaining it to your local police department. Imagine how you’d feel if you learned there was a virtual version of you out there, somewhere, under somebody else’s control.  If digital replicas become mainstream, there will inevitably need to be new processes and norms around the legacies we leave behind online. And if we’ve learned anything from the history of technological development, we’ll be better off if we grapple with the possibility of these replicas’ misuse before, not after, they reach mass adoption. Will that ever happen, though? You, Only Virtual uses the tagline “Never Have to Say Goodbye”—but it’s not actually clear how many people want or are ready for a world like that. Grieving for those who’ve passed away is, for most people, one of the few aspects of life still largely untouched by modern technology.  On a more mundane level, the costs could be a drawback. Although some of these services have free versions, they can easily run into the hundreds if not thousands of dollars.  HereAfter’s top-tier unlimited version lets you record as many conversations with the subject as you like, and it costs $8.99 a month. That may sound cheaper than StoryFile’s one-off $499 payment to access its premium, unlimited package of services. However, at $108 per year, HereAfter services could quickly add up if you do some ghoulish back-of-the-envelope math on lifetime costs. It’s a similar situation with You, Only Virtual, which is slated to cost somewhere between $9.99 and $19.99 a month when it launches.  Creating an avatar or chatbot of someone also requires time and effort, not least of which is just building up the energy and motivation to get started. This is true both for the user and for the subject, who may be nearing death and whose active participation may be required. Fundamentally, people don’t like grappling with the fact they are going to die, says Marius Ursache, who launched a company called Eternime in 2014. Its idea was to create a sort of Tamagotchi that people could train while they were alive to preserve a digital version of themselves. It received a huge surge of interest from people around the world, but few went on to adopt it. The company shuttered in 2018 after failing to pick up enough users. “It’s something you can put off until next week, next month, next year,” he says. “People assume that AI is the key to breaking this. But really, it’s human behavior.” Kuyda agrees: “People are extremely scared of death. They don’t want to talk about it or touch it. When you take a stick and start poking, it freaks them out. They’d rather pretend it doesn’t exist.”  Ursache tried a low-tech approach on his own parents, giving them a notebook and pens on his birthday and asking them to write down their memories and life stories. His mother wrote two pages, but his father said he’d been too busy. In the end, he asked if he could record some conversations with them, but they never managed to get around to it. “My dad passed away last year, and I never did those recordings, and now I feel like an idiot,” he says. Personally, I have mixed feelings about my experiment. I’m glad to have these virtual, audio versions of my mum and dad, even if they’re imperfect. They’ve enabled me to learn new things about my parents, and it’s comforting to think that those bots will be there even when they aren’t. I’m already thinking about who else I might want to capture digitally—my husband (who will probably roll his eyes again), my sister, maybe even my friends.  On the other hand, like a lot of people, I don’t want to think about what will happen when the people I love die. It’s uncomfortable, and many people reflexively flinch when I mention my morbid project. And I can’t help but find it sad that it took a stranger Zoom-interviewing my parents from another continent for me to properly appreciate the multifaceted, complex people they are. But I feel lucky to have had the chance to grasp that—and to still have the precious opportunity to spend more time with them, and learn more about them, face to face, no technology involved. ","My parents don’t know that I spoke to them last night. At first, they sounded distant and tinny, as if they were huddled around a phone in a prison cell. But as we chatted, they slowly started to sound more like themselves. They told me personal stories that I’d never heard. I learned about the first (and certainly not last) time my dad got drunk. Mum talked about getting in trouble for staying out late. They gave me life advice and told me things about their childhoods, as well as my own. It was mesmerizing. “What’s the worst thing about you?” I asked Dad, since he was clearly in such a candid mood. “My worst quality is that I am a perfectionist. I can’t stand messiness and untidiness, and that always presents a challenge, especially with being married to Jane.” Then he laughed—and for a moment I forgot I wasn’t really speaking to my parents at all, but to their digital replicas. This Mum and Dad live inside an app on my phone, as voice assistants constructed by the California-based company HereAfter AI and powered by more than four hours of conversations they each had with an interviewer about their lives and memories. (For the record, Mum isn’t that untidy.) The company’s goal is to let the living communicate with the dead. I wanted to test out what it might be like. Technology like this, which lets you “talk” to people who’ve died, has been a mainstay of science fiction for decades. It’s an idea that’s been peddled by charlatans and spiritualists for centuries. But now it’s becoming a reality—and an increasingly accessible one, thanks to advances in AI and voice technology. My real, flesh-and-blood parents are still alive and well; their virtual versions were just made to help me understand the technology. But their avatars offer a glimpse at a world where it’s possible to converse with loved ones—or simulacra of them—long after they’re gone. From what I could glean over a dozen conversations with my virtually deceased parents, this really will make it easier to keep close the people we love. It’s not hard to see the appeal. People might turn to digital replicas for comfort, or to mark special milestones like anniversaries. At the same time, the technology and the world it’s enabling are, unsurprisingly, imperfect, and the ethics of creating a virtual version of someone are complex, especially if that person hasn’t been able to provide consent. For some, this tech may even be alarming, or downright creepy. I spoke to one man who’d created a virtual version of his mother, which he booted up and talked to at her own funeral. Some people argue that conversing with digital versions of lost loved ones could prolong your grief or loosen your grip on reality. And when I talked to friends about this article, some of them physically recoiled. There’s a common, deeply held belief that we mess with death at our peril. I understand these concerns. I found speaking to a virtual version of my parents uncomfortable, especially at first. Even now, it still feels slightly transgressive to speak to an artificial version of someone—especially when that someone is in your own family. But I’m only human, and those worries end up being washed away by the even scarier prospect of losing the people I love—dead and gone without a trace. If technology might help me hang onto them, is it so wrong to try? There’s something deeply human about the desire to remember the people we love who’ve passed away. We urge our loved ones to write down their memories before it’s too late. After they’re gone, we put up their photos on our walls. We visit their graves on their birthdays. We speak to them as if they were there. But the conversation has always been one-way. The idea that technology might be able to change the situation has been widely explored in ultra-dark sci-fi shows like Black Mirror—which, startups in this sector complain, everyone inevitably brings up. In one 2013 episode, a woman who loses her partner re-creates a digital version of him—initially as a chatbot, then as an almost totally convincing voice assistant, and eventually as a physical robot. Even as she builds more expansive versions of him, she becomes frustrated and disillusioned by the gaps between her memory of her partner and the shonky, flawed reality of the technology used to simulate him. If technology might help me hang onto the people I love, is it so wrong to try? “You aren’t you, are you? You’re just a few ripples of you. There’s no history to you. You’re just a performance of stuff that he performed without thinking, and it’s not enough,” she says before she consigns the robot to her attic—an embarrassing relic of her boyfriend that she’d rather not think about. Back in the real world, the technology has evolved even in the past several years to a somewhat startling degree. Rapid advances in AI have driven progress across multiple areas. Chatbots and voice assistants, like Siri and Alexa, have gone from high-tech novelties to a part of daily life for millions of people over the past decade. We have become very comfortable with the idea of talking to our devices about everything from the weather forecast to the meaning of life. Now, AI large language models (LLMs), which can ingest a few “prompt” sentences and spit out convincing text in response, promise to unlock even more powerful ways for humans to communicate with machines. LLMs have become so convincing that some (erroneously) have argued that they must be sentient. What’s more, it’s possible to tweak LLM software like OpenAI’s GPT-3 or Google’s LaMDA to make it sound more like a specific person by feeding it lots of things that person said. In one example of this, journalist Jason Fagone wrote a story for the San Francisco Chronicle last year about a thirtysomething man who uploaded old texts and Facebook messages from his deceased fiancée to create a simulated chatbot version of her, using software known as Project December that was built on GPT-3. By almost any measure, it was a success: he sought, and found, comfort in the bot. He’d been plagued with guilt and sadness in the years since she died, but as Fagone writes, “he felt like the chatbot had given him permission to move on with his life in small ways.” The man even shared snippets of his chatbot conversations on Reddit, hoping, he said, to bring attention to the tool and “help depressed survivors find some closure.” The lab trained a chatbot to learn from human feedback and search the internet for information to support its claims. At the same time, AI has progressed in its ability to mimic specific physical voices, a practice called voice cloning. It has also been getting better at injecting digital personas—whether cloned from a real person or completely artificial—with more of the qualities that make a voice sound “human.” In a poignant demonstration of how rapidly the field is progressing, Amazon shared a clip in June of a little boy listening to a passage from The Wizard of Oz read by his recently deceased grandmother. Her voice was artificially re-created using a clip of her speaking that lasted for less than a minute. As Rohit Prasad, Alexa’s senior vice president and head scientist, promised: “While AI can’t eliminate that pain of loss, it can definitely make the memories last.” My own experience with talking to the dead started thanks to pure serendipity. At the end of 2019, I saw that James Vlahos, the cofounder of HereAfter AI, would be speaking at an online conference about “virtual beings.” His company is one of a handful of startups working in the field I’ve dubbed “grief tech.” They differ in their approaches but share the same promise: to enable you to talk by video chat, text, phone, or voice assistant with a digital version of someone who is no longer alive. Intrigued by what he was promising, I wrangled an introduction and eventually persuaded Vlahos and his colleagues to let me experiment with their software on my very-much-alive parents. Initially, I thought it would be just a fun project to see what was technologically possible. Then the pandemic added some urgency to the proceedings. Images of people on ventilators, photos of rows of coffins and freshly dug graves, were splashed all over the news. I worried about my parents. I was terrified that they might die, and that with the strict restrictions on hospital visits in force at the time in the UK, I might never have the chance to say goodbye. The first step was an interview. As it turns out, to create a digital replica of someone with a good chance of seeming like a convincingly authentic representation, you need data—and lots of it. HereAfter, whose work starts with subjects when they are still alive, asks them questions for hours—about everything from their earliest memories to their first date to what they believe will happen after they die. (My parents were interviewed by a real live human, but in yet another sign of just how quickly technology is progressing, almost two years later interviews are now typically automated and handled by a bot.) As my sister and I rifled through pages of suggested questions for our parents, we were able to edit them to be more personal or pointed, and we could add some of our own: What books did they like? How did our mum muscle her way into the UK’s overwhelmingly male, privileged legal sector in the 1970s? What inspired Dad to invent the silly games he used to play with us when we were small? Whether through pandemic-induced malaise or a weary willingness to humor their younger daughter, my parents put up zero resistance. In December 2020, HereAfter’s interviewer, a friendly woman named Meredith, spoke to each of them for several hours. The company then took those responses and started stitching them together to create the voice assistants. A couple of months later, a note popped into my inbox from Vlahos. My virtual parents were ready. On one occasion, my husband mistook my testing for an actual phone call. When he realized it wasn’t, he rolled his eyes, as if I were completely deranged. This Mum and Dad arrived via email attachment. I could communicate with them through the Alexa app on a phone or an Amazon Echo device. I was eager to hear them—but I had to wait several days, because I’d promised MIT Technology Review’s podcast team that I’d record my reaction as I spoke to my parents’ avatars for the first time. When I finally opened the file, with my colleagues watching and listening on Zoom, my hands were shaking. London was in a long, cold, depressing lockdown, and I hadn’t seen my actual, real parents for six months. “Alexa, open HereAfter,” I directed. “Would you rather speak with Paul or with Jane?” a voice asked. After a bit of quick mental deliberation, I opted for my mum. A voice that was hers, but weirdly stiff and cold, spoke. “Hello, this is Jane Jee and I’m happy to tell you about my life. How are you today?” I laughed, nervously. “I’m well, thanks, Mum. How are you?” Long pause. “Good. At my end, I’m doing well.” “You sound kind of unnatural,” I said. She ignored me and carried on speaking. “Before we start, here are a few pointers. My listening skills aren’t the best, unfortunately, so you have to wait until I’ve finished talking and ask you a question before you say something back. When it’s your turn to speak, please keep your answers fairly short. A few words, a simple sentence—that type of thing,” she explained. After a bit more introduction, she concluded: “Okay, let’s get started. There’s so much to talk about. My childhood, career, and my interests. Which of those sounds best?” Scripted bits like this sounded stilted and strange, but as we moved on, with my mother recounting memories and speaking in her own words, “she” sounded far more relaxed and natural. Still, this conversation and the ones that followed were limited—when I tried asking my mum’s bot about her favorite jewelry, for instance, I got: “Sorry, I didn’t understand that. You can try asking another way, or move onto another topic.” There were also mistakes that were jarring to the point of hilarity. One day, Dad’s bot asked me how I was. I replied, “I’m feeling sad today.” He responded with a cheery, upbeat “Good!” The overall experience was undeniably weird. Every time I spoke to their virtual versions, it struck me that I could have been talking to my real parents instead. On one occasion, my husband mistook my testing out the bots for an actual phone call. When he realized it wasn’t, he rolled his eyes, tutted, and shook his head, as if I were completely deranged. Earlier this year, I got a demo of a similar technology from a five-year-old startup called StoryFile, which promises to take things to the next level. Its Life service records responses on video rather than just voice alone. You can pick from hundreds of questions for the subject. Then you record the person answering the questions; this can be done on any device with a camera and a microphone, including a smartphone, though the higher-quality the recording, the better the outcome. After uploading the files, the company turns them into a digital version of the person you can see and speak to. It can only answer the questions it’s been programmed to answer—much like HereAfter, just with video. StoryFile’s CEO, Stephen Smith, demonstrated the technology on a video call, where we were joined by his mother. She died earlier this year, but here she was on the call, sitting in a comfortable chair in her living room. For a brief time, I could only see her, shared via Smith’s screen. She was soft-spoken, with wispy hair and friendly eyes. She dispensed life advice. She seemed wise. Smith told me that his mother “attended” her own funeral: “At the end she said, ‘I guess that’s it from me … goodbye!’ and everyone burst into tears.” He told me her digital participation was well received by family and friends. And, arguably most important of all, Smith said he’s deeply comforted by the fact that he managed to capture his mother on camera before she passed away. The video technology itself looked relatively slick and professional—though the result still fell vaguely within the uncanny valley, especially in the facial expressions. At points, much as with my own parents, I had to remind myself that she wasn’t really there. Both HereAfter and StoryFile aim to preserve someone’s life story rather than allowing you to have a full, new conversation with the bot each time. This is one of the major limitations of many current offerings in grief tech: they’re generic. These replicas may sound like someone you love, but they know nothing about you. Anyone can talk to them, and they’ll reply in the same tone. And the replies to a given question are the same every time you ask. “The biggest issue with the [existing] technology is the idea you can generate a single universal person,” says Justin Harrison, founder of a soon-to-launch service called You, Only Virtual. “But the way we experience people is unique to us.” Language models are mindless mimics that do not understand what they are saying—so why do we pretend they’re experts? You, Only Virtual and a few other startups want to go further, arguing that recounting memories won’t capture the fundamental essence of a relationship between two people. Harrison wants to create a personalized bot that’s for you and you alone. The first incarnation of the service, which is set to launch in early 2023, will allow people to build a bot by uploading someone’s text messages, emails, and voice conversations. Ultimately, Harrison hopes, people will feed it data as they go; the company is currently building a communication platform that customers will be able to use to message and talk with loved ones while they’re still alive. That way, all the data will be readily available to be turned into a bot once they’re not. That is exactly what Harrison has done with his mother, Melodi, who has stage 4 cancer: “I built it by hand using five years of my messages with her. It took 12 hours to export, and it runs to thousands of pages,” he says of his chatbot. Harrison says the interactions he has with the bot are more meaningful to him than if it were simply regurgitating memories. Bot Melodi uses the phrases his mother uses and replies to him in the way she’d reply—calling him “honey,” using the emojis she’d use and the same quirks of spelling. He won’t be able to ask Melodi’s avatar questions about her life, but that doesn’t bother him. The point, for him, is to capture the way someone communicates. “Just recounting memories has little to do with the essence of a relationship,” he says. Avatars that people feel a deep personal connection with can have staying power. In 2016, entrepreneur Eugenia Kuyda built what is thought to be the first bot of this kind after her friend Roman died, using her text conversations with him. (She later founded a startup called Replika, which creates virtual companions not based on real people.) She found it a hugely helpful way to process her grief, and she still speaks to Roman’s bot today, she says, especially around his birthday and the anniversary of his passing. But she warns that users need to be careful not to think this technology is re-creating or even preserving people. “I didn’t want to bring back his clone, but his memory,” she says. The intention was to “create a digital monument where you can interact with that person, not in order to pretend they’re alive, but to hear about them, remember how they were, and be inspired by them again.” Some people find that hearing the voices of their loved ones after they’ve gone helps with the grieving process. It’s not uncommon for people to listen to voicemails from someone who has died, for example, says Erin Thompson, a clinical psychologist who specializes in grief. A virtual avatar that you can have more of a conversation with could be a valuable, healthy way to stay connected to someone you loved and lost, she says. But Thompson and others echo Kuyda’s warning: it’s possible to put too much weight on the technology. A grieving person needs to remember that these bots can only ever capture a small sliver of someone. They are not sentient, and they will not replace healthy, functional human relationships. People may find any reminders of the deceased person triggering: “In the acute phase of grief, you can get a strong sense of unreality, not being able to accept they’re gone.” “Your parents are not really there. You’re talking to them, but it’s not really them,” says Erica Stonestreet, an associate professor of philosophy at the College of Saint Benedict & Saint John’s University, who studies personhood and identity. Particularly in the first weeks and months after a loved one dies, people struggle to accept the loss and may find any reminders of the person triggering. “In the acute phase of grief, you can get a strong sense of unreality, not being able to accept they’re gone,” Thompson says. There’s a risk that this sort of intense grief could intersect with, or even cause, mental illness, especially if it’s constantly being fueled and prolonged by reminders of the person who’s passed away. Arguably, this risk might be small today given these technologies’ flaws. Even though sometimes I fell for the illusion, it was clear my parent bots were not in fact the real deal. But the risk that people might fall too deeply for the phantom of personhood will surely grow as the technology improves. And there are still other risks. Any service that allows you to create a digital replica of someone without their participation raises some complex ethical issues regarding consent and privacy. While some might argue that permission is less important with someone no longer alive, can’t you also argue that the person who generated the other side of the conversation should have a say too? And what if that person is not, in fact, dead? There’s little to stop people from using grief tech to create virtual versions of living people without their consent—for example, an ex. Companies that sell services powered by past messages are aware of this possibility and say they will delete a person’s data if that individual requests it. But companies are not obliged to do any checks to make sure their technology is being limited to people who have consented or died. There’s no law to stop anyone from creating avatars of other people, and good luck explaining it to your local police department. Imagine how you’d feel if you learned there was a virtual version of you out there, somewhere, under somebody else’s control. If digital replicas become mainstream, there will inevitably need to be new processes and norms around the legacies we leave behind online. And if we’ve learned anything from the history of technological development, we’ll be better off if we grapple with the possibility of these replicas’ misuse before, not after, they reach mass adoption. Will that ever happen, though? You, Only Virtual uses the tagline “Never Have to Say Goodbye”—but it’s not actually clear how many people want or are ready for a world like that. Grieving for those who’ve passed away is, for most people, one of the few aspects of life still largely untouched by modern technology. On a more mundane level, the costs could be a drawback. Although some of these services have free versions, they can easily run into the hundreds if not thousands of dollars. HereAfter’s top-tier unlimited version lets you record as many conversations with the subject as you like, and it costs $8.99 a month. That may sound cheaper than StoryFile’s one-off $499 payment to access its premium, unlimited package of services. However, at $108 per year, HereAfter services could quickly add up if you do some ghoulish back-of-the-envelope math on lifetime costs. It’s a similar situation with You, Only Virtual, which is slated to cost somewhere between $9.99 and $19.99 a month when it launches. Creating an avatar or chatbot of someone also requires time and effort, not least of which is just building up the energy and motivation to get started. This is true both for the user and for the subject, who may be nearing death and whose active participation may be required. Fundamentally, people don’t like grappling with the fact they are going to die, says Marius Ursache, who launched a company called Eternime in 2014. Its idea was to create a sort of Tamagotchi that people could train while they were alive to preserve a digital version of themselves. It received a huge surge of interest from people around the world, but few went on to adopt it. The company shuttered in 2018 after failing to pick up enough users. “It’s something you can put off until next week, next month, next year,” he says. “People assume that AI is the key to breaking this. But really, it’s human behavior.” Kuyda agrees: “People are extremely scared of death. They don’t want to talk about it or touch it. When you take a stick and start poking, it freaks them out. They’d rather pretend it doesn’t exist.” Ursache tried a low-tech approach on his own parents, giving them a notebook and pens on his birthday and asking them to write down their memories and life stories. His mother wrote two pages, but his father said he’d been too busy. In the end, he asked if he could record some conversations with them, but they never managed to get around to it. “My dad passed away last year, and I never did those recordings, and now I feel like an idiot,” he says. Personally, I have mixed feelings about my experiment. I’m glad to have these virtual, audio versions of my mum and dad, even if they’re imperfect. They’ve enabled me to learn new things about my parents, and it’s comforting to think that those bots will be there even when they aren’t. I’m already thinking about who else I might want to capture digitally—my husband (who will probably roll his eyes again), my sister, maybe even my friends. On the other hand, like a lot of people, I don’t want to think about what will happen when the people I love die. It’s uncomfortable, and many people reflexively flinch when I mention my morbid project. And I can’t help but find it sad that it took a stranger Zoom-interviewing my parents from another continent for me to properly appreciate the multifaceted, complex people they are. But I feel lucky to have had the chance to grasp that—and to still have the precious opportunity to spend more time with them, and learn more about them, face to face, no technology involved.","['parent', 'know', 'speak', 'last', 'night', 'first', 'sound', 'distant', 'tinny', 'huddle', 'phone', 'prison', 'cell', 'chat', 'slowly', 'start', 'sound', 'tell', 'personal', 'story', '’d', 'never', 'hear', 'learn', 'first', 'certainly', 'last', 'time', 'dad', 'get', 'drunk', 'mum', 'talk', 'get', 'trouble', 'stay', 'late', 'give', 'life', 'advice', 'tell', 'thing', 'childhood', 'well', 'mesmerize', '’', 'bad', 'thing', 'ask', 'dad', 'clearly', 'candid', 'mood', 'bad', 'quality', 'perfectionist', 'stand', 'messiness', 'untidiness', 'always', 'present', 'challenge', 'especially', 'marry', 'jane', 'laugh', 'moment', 'forget', 'really', 'speak', 'parent', 'digital', 'replica', 'mum', 'dad', 'live', 'app', 'phone', 'voice', 'assistant', 'construct', 'californiabase', 'company', 'hereafter', 'ai', 'power', 'hour', 'conversation', 'interviewer', 'life', 'memory', 'record', 'mum', 'untidy', 'company', 'goal', 'let', 'living', 'communicate', 'dead', 'want', 'test', 'technology', 'let', 'talk', 'people', '’ve', 'die', 'mainstay', 'science', 'fiction', 'decade', '’', 'idea', 'peddle', 'charlatan', 'spiritualist', 'century', 'become', 'reality', 'increasingly', 'accessible', 'thank', 'advance', 'ai', 'voice', 'technology', 'real', 'fleshandblood', 'parent', 'still', 'alive', 'virtual', 'version', 'make', 'help', 'understand', 'technology', 'avatar', 'offer', 'glimpse', 'world', '’', 'possible', 'converse', 'loved', 'one', 'long', 'go', 'glean', 'dozen', 'conversation', 'virtually', 'deceased', 'parent', 'really', 'make', 'easy', 'keep', 'close', 'people', 'love', '’', 'hard', 'see', 'appeal', 'people', 'turn', 'digital', 'replica', 'comfort', 'mark', 'special', 'milestone', 'anniversary', 'time', 'technology', 'world', 'enable', 'unsurprisingly', 'imperfect', 'ethic', 'create', 'virtual', 'version', 'complex', 'especially', 'person', 'able', 'provide', 'consent', 'tech', 'even', 'alarming', 'downright', 'speak', 'man', '’d', 'create', 'virtual', 'version', 'mother', 'boot', 'talk', 'funeral', 'people', 'argue', 'converse', 'digital', 'version', 'lost', 'love', 'one', 'prolong', 'grief', 'loosen', 'grip', 'reality', 'talk', 'friend', 'article', 'physically', 'recoil', '’', 'common', 'deeply', 'hold', 'belief', 'mess', 'death', 'peril', 'understand', 'concern', 'find', 'speak', 'virtual', 'version', 'parent', 'uncomfortable', 'especially', 'first', 'even', 'still', 'feel', 'slightly', 'transgressive', 'speak', 'artificial', 'version', 'especially', 'family', '’m', 'human', 'worry', 'end', 'wash', 'away', 'even', 'scary', 'prospect', 'lose', 'people', 'love', 'dead', 'go', 'trace', 'technology', 'help', 'hang', 'wrong', 'try', '’', 'deeply', 'human', 'desire', 'remember', 'people', 'love', '’ve', 'pass', 'away', 'urge', 'love', 'one', 'write', 'memory', '’', 'late', 'go', 'put', 'photo', 'wall', 'visit', 'grave', 'birthday', 'speak', 'conversation', 'always', 'oneway', 'idea', 'technology', 'able', 'change', 'situation', 'widely', 'explore', 'ultradark', 'scifi', 'show', 'black', 'mirror', 'startup', 'sector', 'complain', 'inevitably', 'bring', 'episode', 'woman', 'lose', 'partner', 'recreate', 'digital', 'version', 'initially', 'chatbot', 'almost', 'totally', 'convincing', 'voice', 'assistant', 'eventually', 'physical', 'robot', 'even', 'build', 'expansive', 'version', 'become', 'frustrated', 'disillusion', 'gap', 'memory', 'partner', 'shonky', 'flawed', 'reality', 'technology', 'use', 'simulate', 'technology', 'help', 'hang', 'people', 'love', 'wrong', 'try', '’re', 'ripple', '’', 'history', '’re', 'performance', 'stuff', 'perform', 'think', '’', 'enough', 'say', 'consign', 'robot', 'attic', 'embarrassing', 'relic', 'boyfriend', '’d', 'rather', 'think', 'back', 'real', 'world', 'technology', 'evolve', 'even', 'past', 'several', 'year', 'somewhat', 'startling', 'degree', 'rapid', 'advance', 'drive', 'progress', 'multiple', 'area', 'chatbot', 'voice', 'assistant', 'siri', 'alexa', 'go', 'hightech', 'novelty', 'part', 'daily', 'life', 'million', 'people', 'past', 'decade', 'become', 'comfortable', 'idea', 'talk', 'device', 'weather', 'forecast', 'meaning', 'life', 'ai', 'large', 'language', 'model', 'llm', 'ingest', 'prompt', 'sentence', 'spit', 'convincing', 'text', 'response', 'promise', 'unlock', 'even', 'powerful', 'way', 'human', 'communicate', 'machine', 'llm', 'become', 'convincing', 'erroneously', 'argue', 'sentient', '’', '’', 'possible', 'tweak', 'llm', 'software', 'lamda', 'make', 'sound', 'specific', 'person', 'feed', 'lot', 'thing', 'person', 'say', 'example', 'journalist', 'write', 'story', 'chronicle', 'last', 'year', 'thirtysomething', 'man', 'upload', 'old', 'text', 'facebook', 'message', 'deceased', 'fiancée', 'create', 'simulated', 'chatbot', 'version', 'use', 'software', 'know', 'project', 'build', 'gpt3', 'almost', 'measure', 'success', 'seek', 'find', 'comfort', 'bot', '’d', 'plague', 'guilt', 'sadness', 'year', 'die', 'fagone', 'write', 'feel', 'chatbot', 'give', 'permission', 'move', 'life', 'small', 'way', 'man', 'even', 'share', 'snippet', 'chatbot', 'conversation', 'reddit', 'hope', 'say', 'bring', 'attention', 'tool', 'help', 'depressed', 'survivor', 'find', 'closure', 'lab', 'train', 'chatbot', 'learn', 'human', 'feedback', 'search', 'internet', 'information', 'support', 'claim', 'time', 'ai', 'progress', 'ability', 'mimic', 'specific', 'physical', 'voice', 'practice', 'call', 'voice', 'clone', 'also', 'get', 'well', 'inject', 'digital', 'persona', 'clone', 'real', 'person', 'completely', 'artificial', 'quality', 'make', 'voice', 'sound', 'human', 'poignant', 'demonstration', 'rapidly', 'field', 'progress', 'amazon', 'share', 'clip', 'little', 'boy', 'listen', 'passage', 'wizard', 'read', 'recently', 'deceased', 'grandmother', 'voice', 'artificially', 'recreate', 'use', 'clip', 'speak', 'last', 'less', 'minute', 'rohit', 'senior', 'vice', 'president', 'head', 'scientist', 'promise', 'eliminate', 'pain', 'loss', 'definitely', 'make', 'memory', 'last', 'experience', 'talk', 'dead', 'start', 'thank', 'pure', 'serendipity', 'end', 'see', 'vlahos', 'cofounder', 'hereafter', 'ai', 'speak', 'online', 'conference', 'virtual', 'company', 'handful', 'startup', 'work', 'field', 'dub', 'grief', 'tech', 'differ', 'approach', 'share', 'promise', 'enable', 'talk', 'video', 'chat', 'text', 'phone', 'voice', 'assistant', 'digital', 'version', 'long', 'alive', 'intrigue', 'promise', 'wrangle', 'introduction', 'eventually', 'persuade', 'vlahos', 'colleague', 'let', 'experiment', 'software', 'verymuchalive', 'parent', 'initially', 'think', 'fun', 'project', 'see', 'technologically', 'possible', 'pandemic', 'add', 'urgency', 'proceeding', 'image', 'people', 'ventilator', 'photo', 'row', 'coffin', 'freshly', 'dig', 'grave', 'splash', 'news', 'worry', 'parent', 'terrified', 'die', 'strict', 'restriction', 'hospital', 'visit', 'force', 'time', 'never', 'chance', 'say', 'first', 'step', 'interview', 'turn', 'create', 'digital', 'replica', 'good', 'chance', 'seem', 'convincingly', 'authentic', 'representation', 'need', 'datum', 'lot', 'hereafter', 'work', 'start', 'subject', 'still', 'alive', 'ask', 'question', 'hour', 'early', 'memory', 'first', 'date', 'believe', 'happen', 'die', 'parent', 'interview', 'real', 'live', 'human', 'yet', 'sign', 'quickly', 'technology', 'progress', 'almost', 'year', 'later', 'interview', 'typically', 'automate', 'handle', 'bot', 'sister', 'rifle', 'page', 'suggest', 'question', 'parent', 'able', 'edit', 'personal', 'pointed', 'add', 'book', 'like', 'mum', 'muscle', 'way', 'overwhelmingly', 'male', 'privileged', 'legal', 'sector', '1970', 'inspire', 'dad', 'invent', 'silly', 'game', 'use', 'play', 'small', 'pandemicinduce', 'malaise', 'weary', 'willingness', 'humor', 'young', 'daughter', 'parent', 'put', 'resistance', 'interviewer', 'friendly', 'woman', 'name', 'meredith', 'speak', 'several', 'hour', 'company', 'take', 'response', 'start', 'stitch', 'together', 'create', 'voice', 'assistant', 'couple', 'month', 'later', 'note', 'pop', 'inbox', 'vlahos', 'virtual', 'parent', 'ready', 'occasion', 'husband', 'mistook', 'testing', 'actual', 'phone', 'call', 'realize', 'roll', 'eye', 'completely', 'derange', 'mum', 'dad', 'arrive', 'email', 'attachment', 'communicate', 'alexa', 'app', 'phone', 'amazon', 'echo', 'device', 'eager', 'hear', 'wait', 'several', 'day', '’d', 'promise', 'mit', 'technology', 'review', 'podcast', 'team', '’d', 'record', 'reaction', 'speak', 'parent', 'avatar', 'first', 'time', 'finally', 'open', 'file', 'colleague', 'watch', 'listen', 'zoom', 'hand', 'shake', 'long', 'cold', 'depressing', 'lockdown', 'see', 'actual', 'real', 'parent', 'month', 'hereafter', 'direct', 'rather', 'speak', 'jane', 'voice', 'ask', 'bit', 'quick', 'mental', 'deliberation', 'opt', 'mum', 'voice', 'weirdly', 'stiff', 'cold', 'speak', '’m', 'happy', 'tell', 'life', 'today', 'laugh', 'nervously', '’m', 'thank', 'mum', 'long', 'pause', 'good', 'end', 'well', 'sound', 'kind', 'unnatural', 'say', 'ignore', 'carry', 'speak', 'start', 'pointer', 'listening', 'skill', 'good', 'unfortunately', 'wait', 'finish', 'talk', 'ask', 'question', 'say', 'back', '’', 'turn', 'speak', 'keep', 'answer', 'fairly', 'short', 'word', 'simple', 'sentence', 'type', 'thing', 'explain', 'bit', 'introduction', 'conclude', 'let', 'start', '’', 'much', 'talk', 'childhood', 'career', 'interest', 'sound', 'well', 'script', 'bit', 'stilte', 'strange', 'move', 'mother', 'recounting', 'memory', 'speak', 'word', 'sound', 'far', 'relaxed', 'natural', 'still', 'conversation', 'one', 'follow', 'limit', 'try', 'ask', 'mum', '’s', 'bot', 'favorite', 'jewelry', 'instance', 'get', 'sorry', 'understand', 'try', 'ask', 'way', 'move', 'topic', 'also', 'mistake', 'jar', 'point', 'hilarity', 'day', 'dad', 'ask', 'reply', 'feel', 'sad', 'today', 'respond', 'cheery', 'upbeat', 'good', 'overall', 'experience', 'undeniably', 'weird', 'time', 'speak', 'virtual', 'version', 'strike', 'talk', 'real', 'parent', 'instead', 'occasion', 'husband', 'mistook', 'testing', 'bot', 'actual', 'phone', 'call', 'realize', 'roll', 'eye', 'tutte', 'shake', 'head', 'completely', 'derange', 'early', 'year', 'get', 'demo', 'similar', 'technology', 'fiveyearold', 'startup', 'call', 'storyfile', 'promise', 'take', 'thing', 'next', 'level', 'life', 'service', 'record', 'response', 'video', 'rather', 'voice', 'alone', 'pick', 'hundred', 'question', 'subject', 'record', 'person', 'answer', 'question', 'device', 'camera', 'microphone', 'include', 'smartphone', 'higherquality', 'recording', 'well', 'outcome', 'upload', 'file', 'company', 'turn', 'digital', 'version', 'person', 'see', 'speak', 'answer', 'question', 'program', 'answer', 'much', 'hereafter', 'video', 'storyfile', 'demonstrate', 'technology', 'video', 'call', 'join', 'mother', 'die', 'early', 'year', 'call', 'sit', 'comfortable', 'chair', 'living', 'room', 'brief', 'time', 'see', 'share', 'screen', 'softspoken', 'hair', 'friendly', 'eye', 'dispense', 'life', 'advice', 'seem', 'tell', 'mother', 'attend', 'funeral', 'end', 'say', 'guess', '’', 'goodbye', 'burst', 'tear', 'tell', 'digital', 'participation', 'well', 'receive', 'family', 'friend', 'arguably', 'important', 'say', 'deeply', 'comfort', 'fact', 'manage', 'capture', 'mother', 'camera', 'pass', 'video', 'technology', 'look', 'relatively', 'slick', 'professional', 'result', 'still', 'fall', 'vaguely', 'uncanny', 'valley', 'especially', 'facial', 'expression', 'point', 'much', 'parent', 'remind', 'really', 'hereafter', 'storyfile', 'aim', 'preserve', 'life', 'story', 'rather', 'allow', 'full', 'new', 'conversation', 'bot', 'time', 'major', 'limitation', 'many', 'current', 'offering', 'grief', 'tech', '’re', 'generic', 'replica', 'sound', 'love', 'know', 'talk', 'reply', 'tone', 'reply', 'give', 'question', 'time', 'ask', 'big', 'issue', 'exist', 'technology', 'idea', 'generate', 'single', 'universal', 'person', 'say', 'founder', 'soontolaunch', 'service', 'call', 'virtual', 'way', 'experience', 'people', 'unique', 'language', 'model', 'mindless', 'mimic', 'understand', 'say', 'pretend', '’re', 'expert', 'virtual', 'startup', 'want', 'go', 'far', 'argue', 'recounting', 'memory', 'capture', 'fundamental', 'essence', 'relationship', 'people', 'harrison', 'want', 'create', 'personalized', 'bot', '’', 'alone', 'first', 'incarnation', 'service', 'set', 'launch', 'early', 'allow', 'people', 'build', 'bot', 'upload', '’s', 'text', 'message', 'email', 'voice', 'conversation', 'ultimately', 'harrison', 'hope', 'people', 'feed', 'datum', 'go', 'company', 'currently', 'build', 'communication', 'platform', 'customer', 'able', 'use', 'message', 'talk', 'love', 'one', '’re', 'still', 'alive', 'datum', 'readily', 'available', 'turn', 'bot', '’re', 'exactly', 'harrison', 'mother', 'melodi', 'stage', 'cancer', 'build', 'hand', 'use', 'year', 'message', 'take', 'hour', 'export', 'run', 'thousand', 'page', 'say', 'chatbot', 'say', 'interaction', 'bot', 'meaningful', 'simply', 'regurgitate', 'memory', 'bot', 'melodi', 'use', 'phrase', 'mother', 'use', 'reply', 'way', '’d', 'reply', 'call', 'honey', 'use', 'emoji', '’d', 'use', 'quirk', 'spelling', 'able', 'ask', 'question', 'life', 'bother', 'point', 'capture', 'way', 'communicate', 'recount', 'memory', 'little', 'essence', 'relationship', 'say', 'avatar', 'people', 'feel', 'deep', 'personal', 'connection', 'stay', 'power', 'entrepreneur', 'eugenia', 'kuyda', 'build', 'think', 'first', 'bot', 'kind', 'friend', 'roman', 'die', 'use', 'text', 'conversation', 'later', 'found', 'startup', 'call', 'create', 'virtual', 'companion', 'base', 'real', 'people', 'find', 'hugely', 'helpful', 'way', 'process', 'grief', 'still', 'speak', 'bot', 'today', 'say', 'especially', 'birthday', 'anniversary', 'passing', 'warn', 'user', 'need', 'careful', 'think', 'technology', 'recreate', 'even', 'preserve', 'people', 'want', 'bring', 'back', 'clone', 'memory', 'say', 'intention', 'create', 'digital', 'monument', 'interact', 'person', 'order', 'pretend', '’re', 'alive', 'hear', 'remember', 'inspire', 'people', 'find', 'hear', 'voice', 'love', 'one', 'go', 'help', 'grieving', 'process', '’', 'uncommon', 'people', 'listen', 'voicemail', 'die', 'example', 'say', 'clinical', 'psychologist', 'specialize', 'grief', 'virtual', 'avatar', 'conversation', 'valuable', 'healthy', 'way', 'stay', 'connected', 'love', 'lose', 'say', 'warn', '’', 'possible', 'put', 'much', 'weight', 'technology', 'grieve', 'person', 'need', 'remember', 'bot', 'ever', 'capture', 'small', 'sliver', 'sentient', 'replace', 'healthy', 'functional', 'human', 'relationship', 'people', 'find', 'reminder', 'deceased', 'person', 'trigger', 'acute', 'phase', 'grief', 'get', 'strong', 'sense', 'unreality', 'able', 'accept', 'go', 'parent', 'really', 'talk', '’', 'really', 'say', 'associate', 'professor', 'philosophy', 'college', 'study', 'personhood', 'identity', 'particularly', 'first', 'week', 'month', 'love', 'one', 'die', 'people', 'struggle', 'accept', 'loss', 'find', 'reminder', 'person', 'trigger', 'acute', 'phase', 'grief', 'get', 'strong', 'sense', 'unreality', 'able', 'accept', 'go', 'say', '’', 'risk', 'sort', 'intense', 'grief', 'intersect', 'even', 'cause', 'mental', 'illness', 'especially', 'constantly', 'fuel', 'prolong', 'reminder', 'person', 'pass', 'arguably', 'risk', 'small', 'today', 'give', 'technology', 'flaw', 'even', 'sometimes', 'fall', 'illusion', 'clear', 'parent', 'bot', 'fact', 'real', 'deal', 'risk', 'people', 'fall', 'deeply', 'phantom', 'personhood', 'surely', 'grow', 'technology', 'improve', 'still', 'risk', 'service', 'allow', 'create', 'digital', 'replica', 'participation', 'raise', 'complex', 'ethical', 'issue', 'regard', 'consent', 'privacy', 'argue', 'permission', 'less', 'important', 'long', 'alive', 'also', 'argue', 'person', 'generate', 'side', 'conversation', 'say', 'person', 'fact', 'dead', '’', 'little', 'stop', 'people', 'use', 'grief', 'tech', 'create', 'virtual', 'version', 'live', 'people', 'consent', 'example', 'company', 'sell', 'service', 'power', 'past', 'message', 'aware', 'possibility', 'say', 'delete', 'person', 'datum', 'individual', 'request', 'company', 'oblige', 'check', 'make', 'sure', 'technology', 'limit', 'people', 'consent', 'die', '’', 'law', 'stop', 'create', 'avatar', 'people', 'good', 'luck', 'explain', 'local', 'police', 'department', 'imagine', '’d', 'feel', 'learn', 'virtual', 'version', 'somewhere', 'else', 'control', 'digital', 'replica', 'become', 'mainstream', 'inevitably', 'need', 'new', 'process', 'norm', 'legacy', 'leave', 'behind', 'online', 'learn', 'history', 'technological', 'development', 'well', 'grapple', 'possibility', 'misuse', 'reach', 'mass', 'adoption', 'ever', 'happen', 'virtual', 'use', 'tagline', 'never', 'say', 'goodbye', '’', 'actually', 'clear', 'many', 'people', 'want', 'ready', 'world', 'grieve', '’ve', 'pass', 'people', 'aspect', 'life', 'still', 'largely', 'untouched', 'modern', 'technology', 'mundane', 'level', 'cost', 'drawback', 'service', 'free', 'version', 'easily', 'run', 'hundred', 'thousand', 'dollar', 'hereafter', 'toptier', 'unlimited', 'version', 'let', 'record', 'many', 'conversation', 'subject', 'like', 'cost', 'month', 'sound', 'cheap', 'oneoff', 'payment', 'access', 'premium', 'unlimited', 'package', 'service', 'however', 'year', 'hereafter', 'service', 'quickly', 'add', 'ghoulish', 'backoftheenvelope', 'math', 'lifetime', 'cost', '’', 'similar', 'situation', 'virtual', 'slate', 'cost', 'somewhere', 'month', 'launch', 'create', 'avatar', 'chatbot', 'also', 'require', 'time', 'effort', 'least', 'build', 'energy', 'motivation', 'start', 'true', 'user', 'subject', 'near', 'death', 'active', 'participation', 'require', 'fundamentally', 'people', 'like', 'grapple', 'fact', 'go', 'die', 'say', 'ursache', 'launch', 'company', 'call', 'eternime', 'idea', 'create', 'sort', 'tamagotchi', 'people', 'train', 'alive', 'preserve', 'digital', 'version', 'receive', 'huge', 'surge', 'interest', 'people', 'world', 'go', 'adopt', 'company', 'shutter', 'fail', 'pick', 'enough', 'user', '’', 'put', 'next', 'week', 'next', 'month', 'next', 'year', 'say', 'people', 'assume', 'ai', 'key', 'break', 'really', '’', 'human', 'behavior', 'kuyda', 'agree', 'people', 'extremely', 'scared', 'death', 'want', 'talk', 'touch', 'take', 'stick', 'start', 'poke', 'freak', 'rather', 'pretend', 'exist', 'ursache', 'try', 'lowtech', 'approach', 'parent', 'give', 'notebook', 'pen', 'birthday', 'ask', 'write', 'memory', 'life', 'story', 'mother', 'write', 'page', 'father', 'say', '’d', 'busy', 'end', 'ask', 'record', 'conversation', 'never', 'manage', 'get', 'dad', 'pass', 'last', 'year', 'never', 'recording', 'feel', 'idiot', 'say', 'personally', 'mixed', 'feeling', 'experiment', '’m', 'glad', 'virtual', 'audio', 'version', 'mum', 'dad', 'even', '’re', 'imperfect', 'enable', 'learn', 'new', 'thing', 'parent', '’', 'comfort', 'think', 'bot', 'even', 'already', 'think', 'else', 'want', 'capture', 'digitally', 'husband', 'probably', 'roll', 'eye', 'sister', 'maybe', 'even', 'friend', 'hand', 'lot', 'people', 'want', 'think', 'happen', 'people', 'love', 'die', '’', 'uncomfortable', 'many', 'people', 'reflexively', 'flinch', 'mention', 'morbid', 'project', 'help', 'find', 'sad', 'take', 'stranger', 'zoominterviewe', 'parent', 'continent', 'properly', 'appreciate', 'multifaceted', 'complex', 'people', 'feel', 'lucky', 'chance', 'grasp', 'still', 'precious', 'opportunity', 'spend', 'time', 'learn', 'face', 'face', 'technology', 'involve']"
WeChat users are begging Tencent to give their accounts back after talking about a Beijing protest,https://www.technologyreview.com/2022/10/16/1061713/wechat-accounts-begging-tencent-beijing-protest/,2022-10-16,"<p>The super app banned users who shared images of a rare pro-democracy demonstration. Now they’re posting “confession letters” in a desperate hope to regain access.</p>
","On Weibo, the popular Chinese social media platform, hundreds of desperate users were writing “confession letters” this past week.  “I have been in a terrible mental state due to the massive pressure from recent pandemic prevention measures. I lost my control, and sent sensitive statements in a group chat with six people,” one user wrote. “I have profoundly realized my mistake. I hope Tencent can give me a chance to start with a clean slate. I won’t let down the party and the country.” The message was posted with a special hashtag for “Tencent Customer Service.” Messages like this, which surged on Thursday, vary in substance but share urgent pleas from users who have been banned from the Tencent-owned super app WeChat—begging company representatives to restore their social accounts on a service that has become an almost indispensable part of life in China. While the hashtags themselves aren’t new, they were flooded late in the week after WeChat reportedly banned a large number of users. Those affected believe it was because they had discussed a rare political protest in Beijing.  It all started on the afternoon of October 13, two days before the high-profile 20th Communist Party Congress, when a protester hung banners on an overpass in the capital city that called for removing pandemic control measures and instating democratic reforms. “Say no to Covid test, yes to food. No to lockdown, yes to freedom,” part of one banner reads. “Go on strike, remove the dictator and national traitor Xi Jinping,” reads another. The timing right before the party congress—as well as the highly sensitive act of mentioning the name of the Chinese president, who is expected to clinch an unprecedented third term at the meeting—has made discussion of the event tightly censored on Chinese social media.  On Weibo, any user content that includes words like “Beijing,” “bridge,” and “brave” is restricted from being searched. Apple Music’s Chinese version removed a song named “Sitong Bridge,” presumably only because the name refers to the place where the protest happened.  This censorship extends to WeChat, the dominant messaging app with over 1.2 billion global users, the majority of whom live in China. Users soon realized that just posting a picture of the event, even in a private group chat, could cause their accounts to be permanently banned.  Chen, a Beijing resident who asked to be identified only by his last name, says he sent a photo of the protest to a group chat at 1:11 p.m Beijing time on Thursday, and his account was permanently banned at 5:35 p.m. The decision was made “according to the relevant Internet policies as well as laws and regulations,” the boilerplate notification from WeChat reads.  Another member of the group chat also tried to send the photo; his account was also banned, Chen later learned. “We knew it would cause a suspension, but we didn’t expect it to be permanent. I thought at the time I would only be banned for a few days,” he says.  Though there’s no official number on how many accounts were banned that day, there are numerous reports across Weibo and other social media platforms of WeChat users’ losing their accounts since the protest, some not knowing what they did wrong. Tencent didn’t respond to a request for comment from MIT Technology Review. Being banned from WeChat isn’t exactly a trivial matter. It has a significant practical impact on individuals, as they are now blocked from using the many digital services tied to their accounts, from health QR codes to online subscriptions. It takes days, if not weeks, to reestablish their digital connections with a new account.  The mass suspension also has an effect on society as a whole: the latest example of how swiftly China’s censorship machine works to silence dissent will only further chill these voices in the future. Protests like the latest one are already rare in China today, and many people won’t ever learn it happened. In China, the government holds social media platforms responsible for closely screening user-generated content. A 2017 regulation from China’s Cyberspace Administration targets online group chats and prohibits both platforms and users from “spreading content forbidden by laws and relevant regulations.” In 2021, popular social media platforms Douban and Weibo were publicly fined millions of yuan for allowing “illegal” content to be seen on their platforms. WeChat’s terms and conditions has a lengthy section on what content is banned, but it’s only specific when illustrating examples involving scams, spam, rumors, gambling, or pornography. It doesn’t give any examples of the politically sensitive content it censors. After a writer was locked out of her novel for including illegal content, Chinese web users are asking questions about just how far the state’s censorship reaches. Still, it’s well known that sending politically sensitive content on WeChat, even in private exchanges, can result in account suspension. Similar waves of mass suspension also happened during other online protests, such as when people were criticizing the inept government response to omicron flare-ups in Shanghai in April. In 2019, the Toronto-based research group Citizen Lab found that WeChat imposes real-time automatic censorship of chat images through a mix of text recognition, visual recognition, and tools for detecting duplicate files. One of the results is that once the system identifies an image as subject to restriction, it can immediately block all users from sending that image. This has sometimes driven users to get creative, using puns, distorted images, or hard-to-understand languages to mask what they want to share. The real-time censorship system seems to have been applied to images from Sitong Bridge. Tina, a 38-year-old Beijing resident, sent a photo of the protest to a small group chat on Thursday, though she suspects the image didn’t even reach the other members. She later checked with her boyfriend, who is also in the group, and confirmed that he couldn’t see any photo of the protest. Nevertheless, Tina’s WeChat account was permanently banned hours later. (Tina asked to be identified by her English name to protect her identity.)  Once a WeChat account is permanently banned, there aren’t many ways to appeal the decision. Calling the designated customer service hotline usually just gets you hours of wait time; the in-app appeals process returns a generic response concluding that “the restrictions cannot be removed.”  So over the past few years, users who are desperate to get their accounts back have turned to other social media platforms where Tencent has corporate accounts. On Weibo, there were two “super topics,” a Weibo community feature that builds on a specific hashtag: “腾讯客服 (Tencent customer service)” and “腾讯人工客服 (Tencent human customer service).” Together, the two topics had over 130,000 posts where users asked, begged, or condemned Tencent in hopes it would give their accounts back.  These posts dated back to 2017, the year after Weibo introduced the super topic feature, but more than half were published in 2022. There was one account that had persistently written to Tencent almost every day since July 26. Use of the super topics spiked before Weibo removed both topics on the morning of October 14, just a day after the protest. MIT Technology Review examined and archived some of the posts before they were taken down. Weibo didn’t respond to a request for comment. After Weibo removed the two super topics, some users moved to a different super topic, “Tencent,” or resorted to simply tagging Tencent’s corporate accounts.  The surge of posts on Thursday attracted attention from other Weibo users, who named the missives “cyber confessionals,” since users often lay out what they think they did wrong in order to ask Tencent for a second chance; WeChat users are usually not given a detailed explanation for their ban.  But some of the users knew, or suspected, that their account ban was triggered by posting politically sensitive content. “I called the customer service phone number but they didn’t tell me what violated the rules. After self-examination, I found it was because I reposted improper photos,” reads one of the posts on Weibo. Others were less clear about what happened, yet ready to admit mistakes anyway. “I personally don’t think I’ve sent any harmful information, but if it really was because I did, I’m very sorry and will be cautious with my words and actions in the future,” reads another. Not all people who posted under these hashtags were banned for political censorship. Some say they spammed too many people or promoted counterfeit products; others had no clue about what happened.  What most of the posts share is a sense of desperation. Since WeChat has come to be used in almost all aspects of life, having your primary account banned can be devastating. The Weibo posts describe how having their WeChat accounts banned made it difficult for people to get messages from colleagues, potential employers, or family members. Some write they are now on the brink of depression. Meanwhile, Tencent’s customer service Weibo accounts only posted robotic responses under these posts asking them to provide more information. Two Weibo users told MIT Technology Review that posting under the hashtag didn’t help their appeals process at all.  Being banned from WeChat turns you into a ghost on the ubiquitous platform. “After losing WeChat, it feels like you lost connection to the world,” says Chen. “Even though you can still log into your WeChat account, read the messages others sent you and the group messages, and make digital payments, you can’t interact with them or reply to them.”  WeChat started allowing banned users to export their contacts in 2020, so if they choose to register a new account and start over, they can add their friends back one by one. But for most WeChat users who have had the app for over a decade, this means adding thousands of contacts manually and explaining to them what they did to trigger the ban. Chen used his old account for 11 years and had over 1,400 contacts. It took him several hours to add back 500 contacts from his back-up account. “When I was adding contacts back, I was questioned if I was a scammer and the person called me to confirm. If I don’t have this person’s number or other confirmation methods, maybe they will straightaway refuse to befriend me,” Chen says. Then there are the subscriptions, the bookmarked content, the public accounts he follows, and all other information tied to his WeChat account. He needs to migrate all that too. On Friday, after the discussion of the protest had ebbed, many WeChat users were discovering who among their friends were banned or helping their friends spread their new WeChat handles. A 2020 article that offered a helpful checklist on what to do after being banned by WeChat gained at least 70,000 views overnight.  News of the suspensions obviously had a chilling effect too, as people weighed whether to talk about the protest when it was now clear it could get their accounts banned. By holding people’s access to digital services hostage, the government was able to obstruct the spread of information and increase its control.  Not everyone is willing to become a hostage. While Tina has heard about the posts on Weibo begging Tencent for help, that’s not what she wants to do. She understands the severity of political censorship and doesn't believe posting will help.  So far, she has only told her close contacts about what happened and plans to try living her life without a WeChat account, at least for a little while. She has always felt she spent too much time on social media apps anyway; maybe this forced leave could be a detox experience.  “Many people were registering their second accounts yesterday. But I told them I won’t. I want to give it a try. If, let’s say, I can still live my life normally without WeChat, I think I can choose not to register another account,” she says. “I don’t think an individual should be bound so close with [WeChat] together.” ","On Weibo, the popular Chinese social media platform, hundreds of desperate users were writing “confession letters” this past week. “I have been in a terrible mental state due to the massive pressure from recent pandemic prevention measures. I lost my control, and sent sensitive statements in a group chat with six people,” one user wrote. “I have profoundly realized my mistake. I hope Tencent can give me a chance to start with a clean slate. I won’t let down the party and the country.” The message was posted with a special hashtag for “Tencent Customer Service.” Messages like this, which surged on Thursday, vary in substance but share urgent pleas from users who have been banned from the Tencent-owned super app WeChat—begging company representatives to restore their social accounts on a service that has become an almost indispensable part of life in China. While the hashtags themselves aren’t new, they were flooded late in the week after WeChat reportedly banned a large number of users. Those affected believe it was because they had discussed a rare political protest in Beijing. It all started on the afternoon of October 13, two days before the high-profile 20th Communist Party Congress, when a protester hung banners on an overpass in the capital city that called for removing pandemic control measures and instating democratic reforms. “Say no to Covid test, yes to food. No to lockdown, yes to freedom,” part of one banner reads. “Go on strike, remove the dictator and national traitor Xi Jinping,” reads another. The timing right before the party congress—as well as the highly sensitive act of mentioning the name of the Chinese president, who is expected to clinch an unprecedented third term at the meeting—has made discussion of the event tightly censored on Chinese social media. On Weibo, any user content that includes words like “Beijing,” “bridge,” and “brave” is restricted from being searched. Apple Music’s Chinese version removed a song named “Sitong Bridge,” presumably only because the name refers to the place where the protest happened. This censorship extends to WeChat, the dominant messaging app with over 1.2 billion global users, the majority of whom live in China. Users soon realized that just posting a picture of the event, even in a private group chat, could cause their accounts to be permanently banned. Chen, a Beijing resident who asked to be identified only by his last name, says he sent a photo of the protest to a group chat at 1:11 p.m Beijing time on Thursday, and his account was permanently banned at 5:35 p.m. The decision was made “according to the relevant Internet policies as well as laws and regulations,” the boilerplate notification from WeChat reads. Another member of the group chat also tried to send the photo; his account was also banned, Chen later learned. “We knew it would cause a suspension, but we didn’t expect it to be permanent. I thought at the time I would only be banned for a few days,” he says. Though there’s no official number on how many accounts were banned that day, there are numerous reports across Weibo and other social media platforms of WeChat users’ losing their accounts since the protest, some not knowing what they did wrong. Tencent didn’t respond to a request for comment from MIT Technology Review. Being banned from WeChat isn’t exactly a trivial matter. It has a significant practical impact on individuals, as they are now blocked from using the many digital services tied to their accounts, from health QR codes to online subscriptions. It takes days, if not weeks, to reestablish their digital connections with a new account. The mass suspension also has an effect on society as a whole: the latest example of how swiftly China’s censorship machine works to silence dissent will only further chill these voices in the future. Protests like the latest one are already rare in China today, and many people won’t ever learn it happened. In China, the government holds social media platforms responsible for closely screening user-generated content. A 2017 regulation from China’s Cyberspace Administration targets online group chats and prohibits both platforms and users from “spreading content forbidden by laws and relevant regulations.” In 2021, popular social media platforms Douban and Weibo were publicly fined millions of yuan for allowing “illegal” content to be seen on their platforms. WeChat’s terms and conditions has a lengthy section on what content is banned, but it’s only specific when illustrating examples involving scams, spam, rumors, gambling, or pornography. It doesn’t give any examples of the politically sensitive content it censors. After a writer was locked out of her novel for including illegal content, Chinese web users are asking questions about just how far the state’s censorship reaches. Still, it’s well known that sending politically sensitive content on WeChat, even in private exchanges, can result in account suspension. Similar waves of mass suspension also happened during other online protests, such as when people were criticizing the inept government response to omicron flare-ups in Shanghai in April. In 2019, the Toronto-based research group Citizen Lab found that WeChat imposes real-time automatic censorship of chat images through a mix of text recognition, visual recognition, and tools for detecting duplicate files. One of the results is that once the system identifies an image as subject to restriction, it can immediately block all users from sending that image. This has sometimes driven users to get creative, using puns, distorted images, or hard-to-understand languages to mask what they want to share. The real-time censorship system seems to have been applied to images from Sitong Bridge. Tina, a 38-year-old Beijing resident, sent a photo of the protest to a small group chat on Thursday, though she suspects the image didn’t even reach the other members. She later checked with her boyfriend, who is also in the group, and confirmed that he couldn’t see any photo of the protest. Nevertheless, Tina’s WeChat account was permanently banned hours later. (Tina asked to be identified by her English name to protect her identity.) Once a WeChat account is permanently banned, there aren’t many ways to appeal the decision. Calling the designated customer service hotline usually just gets you hours of wait time; the in-app appeals process returns a generic response concluding that “the restrictions cannot be removed.” So over the past few years, users who are desperate to get their accounts back have turned to other social media platforms where Tencent has corporate accounts. On Weibo, there were two “super topics,” a Weibo community feature that builds on a specific hashtag: “腾讯客服 (Tencent customer service)” and “腾讯人工客服 (Tencent human customer service).” Together, the two topics had over 130,000 posts where users asked, begged, or condemned Tencent in hopes it would give their accounts back. These posts dated back to 2017, the year after Weibo introduced the super topic feature, but more than half were published in 2022. There was one account that had persistently written to Tencent almost every day since July 26. Use of the super topics spiked before Weibo removed both topics on the morning of October 14, just a day after the protest. MIT Technology Review examined and archived some of the posts before they were taken down. Weibo didn’t respond to a request for comment. After Weibo removed the two super topics, some users moved to a different super topic, “Tencent,” or resorted to simply tagging Tencent’s corporate accounts. The surge of posts on Thursday attracted attention from other Weibo users, who named the missives “cyber confessionals,” since users often lay out what they think they did wrong in order to ask Tencent for a second chance; WeChat users are usually not given a detailed explanation for their ban. But some of the users knew, or suspected, that their account ban was triggered by posting politically sensitive content. “I called the customer service phone number but they didn’t tell me what violated the rules. After self-examination, I found it was because I reposted improper photos,” reads one of the posts on Weibo. Others were less clear about what happened, yet ready to admit mistakes anyway. “I personally don’t think I’ve sent any harmful information, but if it really was because I did, I’m very sorry and will be cautious with my words and actions in the future,” reads another. Not all people who posted under these hashtags were banned for political censorship. Some say they spammed too many people or promoted counterfeit products; others had no clue about what happened. What most of the posts share is a sense of desperation. Since WeChat has come to be used in almost all aspects of life, having your primary account banned can be devastating. The Weibo posts describe how having their WeChat accounts banned made it difficult for people to get messages from colleagues, potential employers, or family members. Some write they are now on the brink of depression. Meanwhile, Tencent’s customer service Weibo accounts only posted robotic responses under these posts asking them to provide more information. Two Weibo users told MIT Technology Review that posting under the hashtag didn’t help their appeals process at all. Being banned from WeChat turns you into a ghost on the ubiquitous platform. “After losing WeChat, it feels like you lost connection to the world,” says Chen. “Even though you can still log into your WeChat account, read the messages others sent you and the group messages, and make digital payments, you can’t interact with them or reply to them.” WeChat started allowing banned users to export their contacts in 2020, so if they choose to register a new account and start over, they can add their friends back one by one. But for most WeChat users who have had the app for over a decade, this means adding thousands of contacts manually and explaining to them what they did to trigger the ban. Chen used his old account for 11 years and had over 1,400 contacts. It took him several hours to add back 500 contacts from his back-up account. “When I was adding contacts back, I was questioned if I was a scammer and the person called me to confirm. If I don’t have this person’s number or other confirmation methods, maybe they will straightaway refuse to befriend me,” Chen says. Then there are the subscriptions, the bookmarked content, the public accounts he follows, and all other information tied to his WeChat account. He needs to migrate all that too. On Friday, after the discussion of the protest had ebbed, many WeChat users were discovering who among their friends were banned or helping their friends spread their new WeChat handles. A 2020 article that offered a helpful checklist on what to do after being banned by WeChat gained at least 70,000 views overnight. News of the suspensions obviously had a chilling effect too, as people weighed whether to talk about the protest when it was now clear it could get their accounts banned. By holding people’s access to digital services hostage, the government was able to obstruct the spread of information and increase its control. Not everyone is willing to become a hostage. While Tina has heard about the posts on Weibo begging Tencent for help, that’s not what she wants to do. She understands the severity of political censorship and doesn't believe posting will help. So far, she has only told her close contacts about what happened and plans to try living her life without a WeChat account, at least for a little while. She has always felt she spent too much time on social media apps anyway; maybe this forced leave could be a detox experience. “Many people were registering their second accounts yesterday. But I told them I won’t. I want to give it a try. If, let’s say, I can still live my life normally without WeChat, I think I can choose not to register another account,” she says. “I don’t think an individual should be bound so close with [WeChat] together.”","['weibo', 'popular', 'chinese', 'social', 'medium', 'platform', 'hundred', 'desperate', 'user', 'write', 'confession', 'letter', 'past', 'week', 'terrible', 'mental', 'state', 'massive', 'pressure', 'recent', 'pandemic', 'prevention', 'measure', 'lose', 'control', 'send', 'sensitive', 'statement', 'group', 'chat', 'people', 'user', 'write', 'profoundly', 'realize', 'mistake', 'hope', 'tencent', 'give', 'chance', 'start', 'clean', 'slate', 'let', 'party', 'country', 'message', 'post', 'special', 'hashtag', 'tencent', 'customer', 'service', 'message', 'surge', 'vary', 'substance', 'share', 'urgent', 'plea', 'user', 'ban', 'tencentowne', 'super', 'app', 'wechat', 'beg', 'company', 'representative', 'restore', 'social', 'account', 'service', 'become', 'almost', 'indispensable', 'part', 'life', 'hashtag', 'new', 'flood', 'late', 'week', 'reportedly', 'ban', 'large', 'number', 'user', 'affect', 'believe', 'discuss', 'rare', 'political', 'protest', 'start', 'afternoon', 'day', '20th', 'protester', 'hang', 'banner', 'overpass', 'capital', 'city', 'call', 'remove', 'pandemic', 'control', 'measure', 'instate', 'democratic', 'reform', 'say', 'covid', 'test', 'food', 'lockdown', 'freedom', 'part', 'banner', 'read', 'go', 'strike', 'remove', 'dictator', 'national', 'traitor', 'jinping', 'read', 'timing', 'right', 'party', 'congress', 'well', 'highly', 'sensitive', 'act', 'mention', 'name', 'chinese', 'president', 'expect', 'clinch', 'unprecedented', 'third', 'term', 'meeting', 'make', 'discussion', 'event', 'tightly', 'censor', 'chinese', 'social', 'medium', 'weibo', 'user', 'content', 'include', 'word', 'restrict', 'search', 'apple', 'music', 'chinese', 'version', 'remove', 'song', 'name', 'bridge', 'presumably', 'name', 'refer', 'place', 'protest', 'happen', 'censorship', 'extend', 'wechat', 'dominant', 'message', 'app', 'global', 'user', 'majority', 'live', 'user', 'soon', 'realize', 'post', 'picture', 'event', 'even', 'private', 'group', 'chat', 'cause', 'account', 'permanently', 'ban', 'resident', 'ask', 'identify', 'last', 'name', 'say', 'send', 'photo', 'protest', 'group', 'chat', 'pm', 'time', 'account', 'permanently', 'ban', 'pm', 'decision', 'make', 'accord', 'relevant', 'internet', 'policy', 'well', 'law', 'regulation', 'boilerplate', 'notification', 'read', 'member', 'group', 'chat', 'also', 'try', 'send', 'photo', 'account', 'also', 'ban', 'later', 'learn', 'know', 'cause', 'suspension', 'expect', 'permanent', 'think', 'time', 'ban', 'day', 'say', '’', 'official', 'number', 'many', 'account', 'ban', 'day', 'numerous', 'report', 'weibo', 'social', 'medium', 'platform', 'user', 'lose', 'account', 'protest', 'know', 'wrong', 'tencent', 'respond', 'request', 'comment', 'mit', 'technology', 'review', 'ban', 'exactly', 'trivial', 'matter', 'significant', 'practical', 'impact', 'individual', 'block', 'use', 'many', 'digital', 'service', 'tie', 'account', 'health', 'qr', 'code', 'online', 'subscription', 'take', 'day', 'week', 'reestablish', 'digital', 'connection', 'new', 'account', 'mass', 'suspension', 'also', 'effect', 'society', 'whole', 'late', 'example', 'swiftly', 'machine', 'work', 'silence', 'dissent', 'far', 'chill', 'voice', 'future', 'protest', 'late', 'already', 'rare', 'today', 'many', 'people', 'ever', 'learn', 'happen', 'government', 'hold', 'social', 'medium', 'platform', 'responsible', 'closely', 'screen', 'usergenerated', 'content', 'regulation', 'administration', 'target', 'online', 'group', 'chat', 'prohibit', 'platform', 'user', 'spread', 'content', 'forbid', 'law', 'relevant', 'regulation', 'popular', 'social', 'medium', 'platform', 'douban', 'weibo', 'publicly', 'fine', 'million', 'yuan', 'allow', 'illegal', 'content', 'see', 'platform', 'term', 'condition', 'lengthy', 'section', 'content', 'ban', '’', 'specific', 'illustrate', 'example', 'involve', 'scam', 'spam', 'rumor', 'gambling', 'pornography', 'give', 'example', 'politically', 'sensitive', 'content', 'censor', 'writer', 'lock', 'novel', 'include', 'illegal', 'content', 'chinese', 'web', 'user', 'ask', 'question', 'far', 'state', '’s', 'censorship', 'reach', 'still', '’', 'well', 'known', 'send', 'politically', 'sensitive', 'content', 'even', 'private', 'exchange', 'result', 'account', 'suspension', 'similar', 'wave', 'mass', 'suspension', 'also', 'happen', 'online', 'protest', 'people', 'criticize', 'inept', 'government', 'response', 'omicron', 'flareup', 'torontobase', 'research', 'group', 'citizen', 'lab', 'find', 'impose', 'realtime', 'automatic', 'censorship', 'chat', 'image', 'mix', 'text', 'recognition', 'visual', 'recognition', 'tool', 'detect', 'duplicate', 'file', 'result', 'system', 'identify', 'image', 'subject', 'restriction', 'immediately', 'block', 'user', 'send', 'image', 'sometimes', 'drive', 'user', 'get', 'creative', 'use', 'pun', 'distort', 'image', 'hardtounderstand', 'language', 'mask', 'want', 'share', 'realtime', 'censorship', 'system', 'seem', 'apply', 'image', 'resident', 'send', 'photo', 'protest', 'small', 'group', 'chat', 'suspect', 'image', 'even', 'reach', 'member', 'later', 'check', 'boyfriend', 'also', 'group', 'confirm', 'see', 'photo', 'protest', 'nevertheless', 'account', 'permanently', 'ban', 'hour', 'later', 'ask', 'identify', 'english', 'name', 'protect', 'identity', 'wechat', 'account', 'permanently', 'ban', 'many', 'way', 'appeal', 'decision', 'call', 'designate', 'customer', 'service', 'hotline', 'usually', 'get', 'hour', 'wait', 'time', 'inapp', 'appeal', 'process', 'return', 'generic', 'response', 'conclude', 'restriction', 'remove', 'past', 'year', 'user', 'desperate', 'get', 'account', 'back', 'turn', 'social', 'medium', 'platform', 'tencent', 'corporate', 'account', 'weibo', 'super', 'topic', 'weibo', 'community', 'feature', 'build', 'specific', 'hashtag', '腾讯客服', 'tencent', 'customer', 'service', '腾讯人工客服', 'tencent', 'human', 'customer', 'service', 'together', 'topic', 'post', 'user', 'ask', 'begged', 'condemn', 'tencent', 'hope', 'give', 'account', 'post', 'date', 'back', 'year', 'weibo', 'introduce', 'super', 'topic', 'feature', 'half', 'publish', 'account', 'persistently', 'write', 'tencent', 'almost', 'day', 'use', 'super', 'topic', 'spike', 'weibo', 'remove', 'topic', 'morning', 'day', 'protest', 'mit', 'technology', 'review', 'examine', 'archive', 'post', 'take', 'weibo', 'respond', 'request', 'comment', 'weibo', 'remove', 'super', 'topic', 'user', 'move', 'different', 'super', 'topic', 'tencent', 'resort', 'simply', 'tag', 'tencent', 'corporate', 'account', 'surge', 'post', 'attract', 'attention', 'weibo', 'user', 'name', 'missive', 'cyber', 'confessional', 'user', 'often', 'lay', 'think', 'wrong', 'order', 'ask', 'tencent', 'second', 'chance', 'user', 'usually', 'give', 'detailed', 'explanation', 'ban', 'user', 'know', 'suspect', 'account', 'ban', 'trigger', 'post', 'politically', 'sensitive', 'content', 'call', 'customer', 'service', 'phone', 'number', 'tell', 'violate', 'rule', 'selfexamination', 'find', 'reposte', 'improper', 'photo', 'read', 'post', 'weibo', 'less', 'clear', 'happen', 'yet', 'ready', 'admit', 'mistake', 'personally', 'think', 'send', 'harmful', 'information', 'really', '’m', 'sorry', 'cautious', 'word', 'action', 'future', 'read', 'people', 'post', 'hashtag', 'ban', 'political', 'censorship', 'say', 'spamme', 'many', 'people', 'promote', 'counterfeit', 'product', 'clue', 'happen', 'post', 'share', 'sense', 'desperation', 'come', 'use', 'almost', 'aspect', 'life', 'primary', 'account', 'ban', 'devastate', 'weibo', 'post', 'describe', 'wechat', 'account', 'ban', 'make', 'difficult', 'people', 'get', 'message', 'colleague', 'potential', 'employer', 'family', 'member', 'write', 'brink', 'depression', 'meanwhile', 'tencent', 'customer', 'service', 'weibo', 'account', 'post', 'robotic', 'response', 'post', 'ask', 'provide', 'information', 'weibo', 'user', 'tell', 'mit', 'technology', 'review', 'post', 'hashtag', 'help', 'appeal', 'process', 'ban', 'turn', 'ghost', 'ubiquitous', 'platform', 'lose', 'feel', 'lose', 'connection', 'world', 'say', 'even', 'still', 'log', 'wechat', 'account', 'read', 'message', 'send', 'group', 'message', 'make', 'digital', 'payment', 'interact', 'reply', 'start', 'allow', 'ban', 'user', 'export', 'contact', 'choose', 'register', 'new', 'account', 'start', 'add', 'friend', 'back', 'wechat', 'user', 'app', 'decade', 'mean', 'add', 'thousand', 'contact', 'manually', 'explain', 'trigger', 'ban', 'use', 'old', 'account', 'year', 'contact', 'take', 'several', 'hour', 'add', 'back', 'contact', 'backup', 'account', 'add', 'contact', 'back', 'question', 'scammer', 'person', 'call', 'confirm', 'person', 'number', 'confirmation', 'method', 'maybe', 'straightaway', 'refuse', 'befriend', 'say', 'subscription', 'bookmarke', 'content', 'public', 'account', 'follow', 'information', 'tie', 'wechat', 'account', 'need', 'migrate', 'discussion', 'protest', 'ebb', 'many', 'user', 'discover', 'friend', 'ban', 'help', 'friend', 'spread', 'new', 'wechat', 'handle', 'article', 'offer', 'helpful', 'checklist', 'ban', 'gain', 'least', 'view', 'overnight', 'news', 'suspension', 'obviously', 'chilling', 'effect', 'people', 'weigh', 'talk', 'protest', 'clear', 'get', 'account', 'ban', 'hold', 'people', 'access', 'digital', 'service', 'hostage', 'government', 'able', 'obstruct', 'spread', 'information', 'increase', 'control', 'willing', 'become', 'hostage', 'hear', 'post', 'weibo', 'beg', 'tencent', 'help', '’', 'want', 'understand', 'severity', 'political', 'censorship', 'believe', 'post', 'help', 'far', 'tell', 'close', 'contact', 'happen', 'plan', 'try', 'live', 'life', 'wechat', 'account', 'least', 'little', 'always', 'feel', 'spend', 'much', 'time', 'social', 'medium', 'app', 'anyway', 'maybe', 'force', 'leave', 'detox', 'experience', 'many', 'people', 'register', 'second', 'account', 'yesterday', 'tell', 'want', 'give', 'try', 'let', 'say', 'still', 'live', 'life', 'normally', 'think', 'choose', 'register', 'account', 'say', 'think', 'individual', 'bind', 'close', 'together']"
Meta is desperately trying to make the metaverse happen,https://www.technologyreview.com/2022/10/11/1061144/metaverse-announcements-meta-connect-legs/,2022-10-11,"<p>Will web access and avatar legs be enough?</p>
","The star of Tuesday’s Meta Connect, the so-called “state of the union” for the company formerly known as Facebook, was Meta Quest Pro. Meta’s newest virtual-reality headset clocks in at a whopping $1,499.99. That’s a significant price jump from its previous iteration, Meta Quest 2, which could be yours for $399.99—not exactly cheap, but still in triple-digit territory. That price hike, coupled with Meta’s insistence throughout the virtual event that the company envisioned the metaverse as a “next-generation social platform” accessible to everyone, sort of feels like a blatant contradiction. Even if you are among the lucky few who can shell out a grand and a half for a virtual-reality headset, would you really want to? That’s the question Meta seems to be grappling with. While the headset price jumped, nearly all the company’s other big moves are aimed at a common and simple baseline: making the metaverse something people actually want to use.  Meta’s metaverse hasn’t exactly had a smooth year. Less than a year ago, founder Mark Zuckerberg rebranded what was then Facebook in an effort to show that the company was pivoting to what he believed was the future of our digital lives. Since then, Meta has been saddled with hiccups and gaffes, including a much-ballyhooed avatar of Zuckerberg that got memed to oblivion, a report suggesting that the company’s employees were less than enthused about the metaverse, and allegations of virtual sexual assault. A woman was sexually harassed on Meta’s VR social media platform. She’s not the first—and won’t be the last. So its current strategy seems to be to release a string of updates to see what might get people interested—a “throw spaghetti at the wall and see what sticks” approach, if you will.  Besides the Meta Quest Pro, the company also announced at the event that it was going to open up Horizon Worlds, the social media platform within Meta’s metaverse, to mobile and desktop users, so people without a headset will be able to access the virtual world. That’s a notable step: it’s a tacit admission that VR headsets aren’t taking off as quickly as the company would like. Without a critical mass of people who understand what the metaverse feels like or even is, Meta can’t hope to have its products adopted. Opening its virtual worlds to the formats consumers are comfortable with (their text messages, their browsers, the company’s beleaguered Instagram platform) gives people who aren’t open to shelling out $399.99—much less $1,499.99—a way to experience the new world. What’s also made the metaverse a hard sell is the disorienting experience of being a floating, legless torso, and Meta announced that it won’t be that way anymore. Previously, Andrew Bosworth, Meta’s CTO, said in an Instagram AMA that full-body avatars were difficult to implement, particularly because VR tracking usually comes from someone’s real-life eyes and hands. “Tracking your own legs accurately is super hard and basically not workable just from a physics standpoint with existing headsets,” he said in February. ""legs are hard"" says Meta's Mark Zuckerberg of avatars... But they're on the case... pic.twitter.com/mwSDagmrGm But Zuckerberg (or, rather, his leggy avatar) announced at the event that the company was going to use artificial intelligence to map out legs in the metaverse, allowing avatars the ability not only to walk and run but also to wear digital clothing for their legs (a marketplace that Zuckerberg has said he is eager to participate in; Roblox, a gaming platform I’ve written about before, currently has a comfortable share of the market). This would be a huge step to improving how users think about movement in the metaverse and how they decide to represent themselves there. But even with legs, and even with the ability to roam the metaverse without a headset strapped to your face, the key question remains: Is Meta’s metaverse something people will actually buy into? It’s worth noting that even employees at Meta are skeptical about the company’s vision, with one going so far as to say the amount spent on these projects to date made him “sick to [his] stomach.” A free, shareable version of the metaverse accessible via weblink will open the previously closed world up to people who may not have hundreds of dollars to burn, and it’s a huge move toward democratizing the space. It might lead people to buy Meta’s claim that talking to a cartoon version of your boss is totally cool—and, more broadly, that the metaverse really is the next digital plane on which we’ll conduct our lives.  But it might also do the opposite: people might hop on the link and find that even in its now full-bodied state, the metaverse, er, doesn’t have legs. ","The star of Tuesday’s Meta Connect, the so-called “state of the union” for the company formerly known as Facebook, was Meta Quest Pro. Meta’s newest virtual-reality headset clocks in at a whopping $1,499.99. That’s a significant price jump from its previous iteration, Meta Quest 2, which could be yours for $399.99—not exactly cheap, but still in triple-digit territory. That price hike, coupled with Meta’s insistence throughout the virtual event that the company envisioned the metaverse as a “next-generation social platform” accessible to everyone, sort of feels like a blatant contradiction. Even if you are among the lucky few who can shell out a grand and a half for a virtual-reality headset, would you really want to? That’s the question Meta seems to be grappling with. While the headset price jumped, nearly all the company’s other big moves are aimed at a common and simple baseline: making the metaverse something people actually want to use. Meta’s metaverse hasn’t exactly had a smooth year. Less than a year ago, founder Mark Zuckerberg rebranded what was then Facebook in an effort to show that the company was pivoting to what he believed was the future of our digital lives. Since then, Meta has been saddled with hiccups and gaffes, including a much-ballyhooed avatar of Zuckerberg that got memed to oblivion, a report suggesting that the company’s employees were less than enthused about the metaverse, and allegations of virtual sexual assault. A woman was sexually harassed on Meta’s VR social media platform. She’s not the first—and won’t be the last. So its current strategy seems to be to release a string of updates to see what might get people interested—a “throw spaghetti at the wall and see what sticks” approach, if you will. Besides the Meta Quest Pro, the company also announced at the event that it was going to open up Horizon Worlds, the social media platform within Meta’s metaverse, to mobile and desktop users, so people without a headset will be able to access the virtual world. That’s a notable step: it’s a tacit admission that VR headsets aren’t taking off as quickly as the company would like. Without a critical mass of people who understand what the metaverse feels like or even is, Meta can’t hope to have its products adopted. Opening its virtual worlds to the formats consumers are comfortable with (their text messages, their browsers, the company’s beleaguered Instagram platform) gives people who aren’t open to shelling out $399.99—much less $1,499.99—a way to experience the new world. What’s also made the metaverse a hard sell is the disorienting experience of being a floating, legless torso, and Meta announced that it won’t be that way anymore. Previously, Andrew Bosworth, Meta’s CTO, said in an Instagram AMA that full-body avatars were difficult to implement, particularly because VR tracking usually comes from someone’s real-life eyes and hands. “Tracking your own legs accurately is super hard and basically not workable just from a physics standpoint with existing headsets,” he said in February. ""legs are hard"" says Meta's Mark Zuckerberg of avatars... But they're on the case... pic.twitter.com/mwSDagmrGm But Zuckerberg (or, rather, his leggy avatar) announced at the event that the company was going to use artificial intelligence to map out legs in the metaverse, allowing avatars the ability not only to walk and run but also to wear digital clothing for their legs (a marketplace that Zuckerberg has said he is eager to participate in; Roblox, a gaming platform I’ve written about before, currently has a comfortable share of the market). This would be a huge step to improving how users think about movement in the metaverse and how they decide to represent themselves there. But even with legs, and even with the ability to roam the metaverse without a headset strapped to your face, the key question remains: Is Meta’s metaverse something people will actually buy into? It’s worth noting that even employees at Meta are skeptical about the company’s vision, with one going so far as to say the amount spent on these projects to date made him “sick to [his] stomach.” A free, shareable version of the metaverse accessible via weblink will open the previously closed world up to people who may not have hundreds of dollars to burn, and it’s a huge move toward democratizing the space. It might lead people to buy Meta’s claim that talking to a cartoon version of your boss is totally cool—and, more broadly, that the metaverse really is the next digital plane on which we’ll conduct our lives. But it might also do the opposite: people might hop on the link and find that even in its now full-bodied state, the metaverse, er, doesn’t have legs.","['star', 'meta', 'connect', 'socalled', 'state', 'union', 'company', 'formerly', 'know', 'meta', 'quest', 'meta', 'new', 'virtualreality', 'headset', 'clock', 'whopping', '’', 'significant', 'price', 'jump', 'previous', 'iteration', 'meta', 'quest', 'exactly', 'cheap', 'still', 'tripledigit', 'territory', 'price', 'hike', 'couple', 'insistence', 'virtual', 'event', 'company', 'envision', 'metaverse', 'nextgeneration', 'social', 'platform', 'accessible', 'sort', 'feel', 'blatant', 'contradiction', 'even', 'lucky', 'shell', 'grand', 'half', 'virtualreality', 'headset', 'really', 'want', '’s', 'question', 'meta', 'seem', 'grapple', 'headset', 'price', 'jump', 'company', 'big', 'move', 'aim', 'common', 'simple', 'baseline', 'make', 'metaverse', 'people', 'actually', 'want', 'use', 'metaverse', 'exactly', 'smooth', 'year', 'less', 'year', 'ago', 'rebrande', 'facebook', 'effort', 'show', 'company', 'pivot', 'believe', 'future', 'digital', 'life', 'meta', 'saddle', 'hiccup', 'gaffe', 'include', 'muchballyhooed', 'avatar', 'meme', 'oblivion', 'report', 'suggest', 'company', 'employee', 'less', 'enthuse', 'metaverse', 'allegation', 'virtual', 'sexual', 'assault', 'woman', 'sexually', 'harass', 'social', 'medium', 'platform', '’', 'first', 'last', 'current', 'strategy', 'seem', 'release', 'string', 'update', 'see', 'get', 'people', 'interested', 'throw', 'spaghetti', 'wall', 'see', 'stick', 'approach', 'meta', 'quest', 'company', 'also', 'announce', 'event', 'go', 'open', 'horizon', 'world', 'social', 'medium', 'platform', 'metaverse', 'mobile', 'desktop', 'user', 'people', 'headset', 'able', 'access', 'virtual', 'world', '’', 'notable', 'step', '’', 'tacit', 'admission', 'vr', 'headset', 'take', 'quickly', 'company', 'like', 'critical', 'mass', 'people', 'understand', 'metaverse', 'feel', 'even', 'meta', 'hope', 'product', 'adopt', 'open', 'virtual', 'world', 'format', 'consumer', 'comfortable', 'text', 'message', 'browser', 'company', 'beleaguered', 'instagram', 'platform', 'give', 'people', 'open', 'shell', 'much', 'less', 'way', 'experience', 'new', 'world', '’', 'also', 'make', 'metaverse', 'hard', 'sell', 'disorient', 'experience', 'float', 'legless', 'torso', 'announce', 'way', 'anymore', 'previously', 'say', 'instagram', 'ama', 'fullbody', 'avatar', 'difficult', 'implement', 'particularly', 'tracking', 'usually', 'come', 'reallife', 'eye', 'hand', 'track', 'leg', 'accurately', 'super', 'hard', 'basically', 'workable', 'physics', 'standpoint', 'exist', 'headset', 'say', 'leg', 'hard', 'say', 'avatar', 'case', 'pictwittercommwsdagmrgm', 'rather', 'leggy', 'avatar', 'announce', 'event', 'company', 'go', 'use', 'artificial', 'intelligence', 'map', 'leg', 'metaverse', 'allow', 'avatar', 'ability', 'walk', 'run', 'also', 'wear', 'digital', 'clothing', 'leg', 'marketplace', 'say', 'eager', 'participate', 'roblox', 'gaming', 'platform', 'write', 'currently', 'comfortable', 'share', 'market', 'huge', 'step', 'improve', 'user', 'think', 'movement', 'metaverse', 'decide', 'represent', 'even', 'leg', 'even', 'ability', 'roam', 'metaverse', 'headset', 'strapped', 'face', 'key', 'question', 'remain', 'meta', 'metaverse', 'people', 'actually', 'buy', '’s', 'worth', 'note', 'even', 'employee', 'meta', 'skeptical', 'company', 'vision', 'go', 'far', 'say', 'amount', 'spend', 'project', 'date', 'make', 'sick', 'stomach', 'free', 'shareable', 'version', 'metaverse', 'accessible', 'weblink', 'open', 'previously', 'close', 'world', 'people', 'hundred', 'dollar', 'burn', '’', 'huge', 'move', 'democratize', 'space', 'lead', 'people', 'buy', 'claim', 'talk', 'cartoon', 'version', 'boss', 'totally', 'cool', 'broadly', 'metaverse', 'really', 'next', 'digital', 'plane', 'conduct', 'life', 'also', 'opposite', 'people', 'hop', 'link', 'find', 'even', 'fullbodie', 'state', 'metaverse', 'leg']"
The mothers of Mexico’s missing use social media to search for mass graves,https://www.technologyreview.com/2022/10/11/1061028/the-mothers-of-mexicos-missing-use-social-media-to-search-for-mass-graves/,2022-10-11,"<p>Large numbers of people still disappear each year in Mexico. Families have turned to social media to hunt for them.</p>
","“Attention Jalisco. Do you know the location of a clandestine grave of corpses?” The question, aimed at people in the populous Mexican state, was posed on Twitter in February by Madres Buscadoras de Sonora, an organization of mothers searching for their missing loved ones. Dozens of people responded. Neighbors who had witnessed clandestine burials came forward, annotating Google Maps to point toward graves beneath vacant houses. Messages also came from “los arrepentidos,” the penitents—people who said they’d been involved in the burials and were moved to confess. Carrying picks and shovels, women from Madres Buscadoras arrived in the Chulavista neighborhood in the Jalisco municipality of Tlajomulco de Zúñiga. They began to dig.  Mexico has long struggled with a history of kidnapping. As of October 5, there were 105,984 people officially listed as disappeared in Mexico. More than a third have vanished in the past few years, during the current government of President Andrés Manuel López Obrador, commonly known as AMLO. Many of those missing are thought to have been kidnapped or forcibly recruited by criminal organizations. Most are likely dead, their remains buried in clandestine graves in rural areas, neighborhoods, and farmlands or scattered in the vast unoccupied terrain near the US-Mexico border. Some may be among the more than 52,000 unidentified bodies lying in morgues, common graves, and universities. Around a quarter are women and girls, most likely victims of sexual exploitation, human trafficking, or femicide.  In a departure from previous administrations, AMLO’s government has publicly recognized the scale of the crisis and strengthened search and identification efforts. In March 2019, it  inaugurated the National Search System, a mechanism that seeks to coordinate efforts among government agencies in the search for the disappeared. When the system launched, Karla Quintana, the head of the National Search Commission, recognized the work families have been doing on the ground, “virtually alone for years.” She promised: “Never again alone.” But authorities are still hesitant to get involved in the search for the missing. And so the task continues to fall on families. Much of the work they do now happens over social media, where people widely distribute photographs of missing relatives, coordinate search efforts, and raise awareness of the problem. Through WhatsApp, Twitter, and Facebook, Madres Buscadoras has created a platform to engage citizens and work to accelerate the search for the disappeared. Every day, the group receives information about missing people and the location of possible graves—so many that they do not have the resources to investigate them all. The work is not without challenges. When Madres Buscadoras began searching for bodies in Chulavista, they were closely watched—and photographed—by local authorities. After the collective met with the governor of Jalisco, local police joined the search the following day. Ultimately, Madres Buscadoras uncovered 221 jumbo trash bags of body parts. By April, the prosecutor’s office said the official tally was up to 44 bodies, with bags still to process. Families who conduct their own investigations can face opposition and threats both from organized crime and from government officials, who may collude with organized crime groups and may not like the optics of a hunt for missing people in their region. Under the country’s landmark General Law of Forced Disappearance, which was approved in 2017 after pressure from families, authorities must take immediate steps to search for a missing person and investigate the crime, yet this is still not the reality for thousands of families. “Although things have changed a little, it has always been the same situation on the part of the authorities. They shake things off, saying ‘It’s not up to us, it’s up to others,’” says Martín Villalobos, a member of the National Citizen Council, a consultative body of the National Search System.  But other parts of Mexican society are now responding to the plight of the families. “Social networks work very well here. People have been supporting us a lot even though they don’t have disappeared relatives,” says Araceli Hernández, who used to be a member of the main Madres Buscadoras group but recently formed a new collective. “The simple fact of listening to the pain of a mother, an aunt, makes them support us with tools, groceries, water, Gatorades, and tons of information. That makes us hold on tighter.” Gathering together On October 30, 2015, Ceci Flores’s then 21-year-old son, Alejandro Guadalupe, disappeared without a trace in the city of Los Mochis in northern Sinaloa. Less than four years later, on May 4, 2019, hit men kidnapped her other two sons—Marco Antonio and Jesús Adrián—in her home state of Sonora. Flores approached the authorities. But when she didn’t see an immediate response, she launched her own search, broadcasting live on social media. Six days later, she received a call saying her sons would be freed at a specific location. When she arrived, only her youngest, Jesús Adrián, was there. To date, Flores hasn’t heard from Marco Antonio.  The same day she recovered Jesús Adrián, Flores created a Twitter account and began to share photos of her still-missing sons. That was the genesis of Madres Buscadoras. Since then, more than 2,000 mothers and relatives of missing people have joined. “I didn’t have the support of the authorities in the search for my children. So I started these searches, inviting families. Every day more families joined me, because there were many disappeared,” she says.  The effort is not without danger. In July last year, 28-year-old buscadora Aranza Ramos was abducted from her home and fatally shot. Ramos had been searching for her husband, Brayan Omar Celaya Alvarado, since he went missing in December 2020. Flores received death threats after Ramos was killed, forcing her to leave her hometown in Sonora. Madres Buscadoras has issued a public plea to organized crime groups to allow them to do their work. But there is a general climate of hostility around the search for the missing, says Vladimir Cortés, digital rights program officer at the Mexico and Central America office of Article 19, a nonprofit advocacy group defending freedom of expression. “We are facing a government that denies that there are human rights violations, that denies that there are abuses against those who defend human rights,” says Cortés. “This generates a permissiveness to attack those who are defending human rights —relatives of disappeared persons—and try to cancel the work they do.” To report or not to report  When psychology student Mónica Alejandrina Ramírez Alvarado disappeared, months before she was due to graduate from the National Autonomous University of Mexico in 2004, social media wasn’t as pervasive as it is today. There was still no national movement for the disappeared, nor a General Law of Forced Disappearance.  But families of the disappeared still face some of the same challenges, explains Villalobos, who is Mónica Alejandrina’s brother-in-law. “Most of the complaints have to be made at the local level, and the local level is always co-opted or is part of organized crime,” Villalobos says.  “When filing a report, families are defenseless against the attacks of both criminals and authorities, and are also isolated from their own family—who, for fear of being related to the threats or revenge, move away from them.”  María de la Luz López Castruita remembers seeing mothers pasting missing person posters with their daughter’s faces in public places in the northern city of Torreón in the late 2000s, never thinking it would happen to her. “Obviously there were no social networks back then, but there were other ways to support,” López says. She could have helped paste posters or joined the search. “But no,” she says. “We stayed with our arms crossed waiting for it to happen to us, and it did happen to us.” After the disappearance of her then 17-year-old daughter, Irma Claribel, in 2008, López and her husband, Jesús Lamas, began to paste Irma’s photo on every possible lamppost, hoping that someone would give them information. They got two types of response: calls asking for money, from people claiming to know Irma’s whereabouts, and misogynistic swear words scratched on the posters.  Educators who stand up to conservative activists are being harassed and called “groomers” online, turning them into potential targets for real-world violence. Taking to social media was a logical next step for families of the missing. There was a marked rise in that activity after the onset of the pandemic, Villalobos says, when authorities declared it too risky to do fieldwork. “Many of us who belong to generations that perhaps were not very familiar with technology and social media have seen the opportunity to make visible our realities using our own voices,” he says.  But in some ways technology hasn’t made things easier, Villalobos notes; users are trolled by bots, fake accounts, and AMLO supporters. He says government supporters often accuse families of receiving financial support from opposition parties or foreign institutions such as the US Agency for International Development and the National Endowment for Democracy, groups that have a long history of funding nongovernmental organizations in Mexico.  There should be more training on social media safety, Cortés says—and a clear mechanism for legal recourse when people are threatened online. At the moment, it is a felony under federal law to threaten a person online, but Cortés says authorities often fail to investigate and prosecute such cases.  Off the radar Around noon on Sunday, April 10, López received a phone call. A man told her he’d found human remains a few months back, while pulling up candelilla plants in the desert. López and her husband were exhausted. They were on the bus, riding back to their home in Torreón after spending two weeks leading a search brigade of more than 150 relatives of missing people in the nearby city of Monterrey. But they couldn’t afford to say no. Any piece of information could be a lead in their search for their daughter Irma Claribel. They called their son Jesús and asked him to pick them up in a town near the highway.  They hopped in Jesús’s truck, picked up the guide, and began a one-and-a-half-hour journey toward desert too rugged for the truck to traverse. Soon it was just López and Lamas following the guide on foot, hoping they would find human remains. “Even if it’s not my daughter, it can be someone else,” says López. Authorities don’t want the media attention, she explains. They often step in to help search only after a massive discovery of human remains, one that would look bad for them to ignore.  After five hours of walking, it was starting to get dark and the place where the remains were supposedly found still looked distant. A recent leg injury started to slow down Lamas, who is 66. They realized they wouldn’t make it to the site. The walk back to the truck took until midnight. López and Lamas were scared. They arrived at their house around three in the morning, feeling deflated and exhausted.    Searches like this one, away from the media and authorities, are common. Bureaucracy and the extensiveness of the territory have forced mothers like López to carry out their own searches without security or resources.  “I have to be filling out papers and papers to make the authorities do the work,” López says. “But I don't want them to make the process long. So when I find something, I talk to them and tell them: Here! Here it is.”  López says that she still does not know how to make a case, or search brigade, go viral. Authorities don’t want the media attention, she explains. They often step in to help search only after a massive discovery of human remains, one that would look bad for them to ignore.  The internet has allowed families to bypass the filters of the government and the media. “That is why social media is very useful for us: to make visible what we are experiencing,” says Flores. “This is not fiction—it’s a reality we live every day. Every day dead people appear. Every day people disappear. Every day we mothers are left without children.”  Chantal Flores is a freelance journalist based in Monterrey, Mexico.  ","“Attention Jalisco. Do you know the location of a clandestine grave of corpses?” The question, aimed at people in the populous Mexican state, was posed on Twitter in February by Madres Buscadoras de Sonora, an organization of mothers searching for their missing loved ones. Dozens of people responded. Neighbors who had witnessed clandestine burials came forward, annotating Google Maps to point toward graves beneath vacant houses. Messages also came from “los arrepentidos,” the penitents—people who said they’d been involved in the burials and were moved to confess. Carrying picks and shovels, women from Madres Buscadoras arrived in the Chulavista neighborhood in the Jalisco municipality of Tlajomulco de Zúñiga. They began to dig. Mexico has long struggled with a history of kidnapping. As of October 5, there were 105,984 people officially listed as disappeared in Mexico. More than a third have vanished in the past few years, during the current government of President Andrés Manuel López Obrador, commonly known as AMLO. Many of those missing are thought to have been kidnapped or forcibly recruited by criminal organizations. Most are likely dead, their remains buried in clandestine graves in rural areas, neighborhoods, and farmlands or scattered in the vast unoccupied terrain near the US-Mexico border. Some may be among the more than 52,000 unidentified bodies lying in morgues, common graves, and universities. Around a quarter are women and girls, most likely victims of sexual exploitation, human trafficking, or femicide. In a departure from previous administrations, AMLO’s government has publicly recognized the scale of the crisis and strengthened search and identification efforts. In March 2019, it inaugurated the National Search System, a mechanism that seeks to coordinate efforts among government agencies in the search for the disappeared. When the system launched, Karla Quintana, the head of the National Search Commission, recognized the work families have been doing on the ground, “virtually alone for years.” She promised: “Never again alone.” But authorities are still hesitant to get involved in the search for the missing. And so the task continues to fall on families. Much of the work they do now happens over social media, where people widely distribute photographs of missing relatives, coordinate search efforts, and raise awareness of the problem. Through WhatsApp, Twitter, and Facebook, Madres Buscadoras has created a platform to engage citizens and work to accelerate the search for the disappeared. Every day, the group receives information about missing people and the location of possible graves—so many that they do not have the resources to investigate them all. The work is not without challenges. When Madres Buscadoras began searching for bodies in Chulavista, they were closely watched—and photographed—by local authorities. After the collective met with the governor of Jalisco, local police joined the search the following day. Ultimately, Madres Buscadoras uncovered 221 jumbo trash bags of body parts. By April, the prosecutor’s office said the official tally was up to 44 bodies, with bags still to process. Families who conduct their own investigations can face opposition and threats both from organized crime and from government officials, who may collude with organized crime groups and may not like the optics of a hunt for missing people in their region. Under the country’s landmark General Law of Forced Disappearance, which was approved in 2017 after pressure from families, authorities must take immediate steps to search for a missing person and investigate the crime, yet this is still not the reality for thousands of families. “Although things have changed a little, it has always been the same situation on the part of the authorities. They shake things off, saying ‘It’s not up to us, it’s up to others,’” says Martín Villalobos, a member of the National Citizen Council, a consultative body of the National Search System. But other parts of Mexican society are now responding to the plight of the families. “Social networks work very well here. People have been supporting us a lot even though they don’t have disappeared relatives,” says Araceli Hernández, who used to be a member of the main Madres Buscadoras group but recently formed a new collective. “The simple fact of listening to the pain of a mother, an aunt, makes them support us with tools, groceries, water, Gatorades, and tons of information. That makes us hold on tighter.” Gathering together On October 30, 2015, Ceci Flores’s then 21-year-old son, Alejandro Guadalupe, disappeared without a trace in the city of Los Mochis in northern Sinaloa. Less than four years later, on May 4, 2019, hit men kidnapped her other two sons—Marco Antonio and Jesús Adrián—in her home state of Sonora. Flores approached the authorities. But when she didn’t see an immediate response, she launched her own search, broadcasting live on social media. Six days later, she received a call saying her sons would be freed at a specific location. When she arrived, only her youngest, Jesús Adrián, was there. To date, Flores hasn’t heard from Marco Antonio. The same day she recovered Jesús Adrián, Flores created a Twitter account and began to share photos of her still-missing sons. That was the genesis of Madres Buscadoras. Since then, more than 2,000 mothers and relatives of missing people have joined. “I didn’t have the support of the authorities in the search for my children. So I started these searches, inviting families. Every day more families joined me, because there were many disappeared,” she says. The effort is not without danger. In July last year, 28-year-old buscadora Aranza Ramos was abducted from her home and fatally shot. Ramos had been searching for her husband, Brayan Omar Celaya Alvarado, since he went missing in December 2020. Flores received death threats after Ramos was killed, forcing her to leave her hometown in Sonora. Madres Buscadoras has issued a public plea to organized crime groups to allow them to do their work. But there is a general climate of hostility around the search for the missing, says Vladimir Cortés, digital rights program officer at the Mexico and Central America office of Article 19, a nonprofit advocacy group defending freedom of expression. “We are facing a government that denies that there are human rights violations, that denies that there are abuses against those who defend human rights,” says Cortés. “This generates a permissiveness to attack those who are defending human rights —relatives of disappeared persons—and try to cancel the work they do.” To report or not to report When psychology student Mónica Alejandrina Ramírez Alvarado disappeared, months before she was due to graduate from the National Autonomous University of Mexico in 2004, social media wasn’t as pervasive as it is today. There was still no national movement for the disappeared, nor a General Law of Forced Disappearance. But families of the disappeared still face some of the same challenges, explains Villalobos, who is Mónica Alejandrina’s brother-in-law. “Most of the complaints have to be made at the local level, and the local level is always co-opted or is part of organized crime,” Villalobos says. “When filing a report, families are defenseless against the attacks of both criminals and authorities, and are also isolated from their own family—who, for fear of being related to the threats or revenge, move away from them.” María de la Luz López Castruita remembers seeing mothers pasting missing person posters with their daughter’s faces in public places in the northern city of Torreón in the late 2000s, never thinking it would happen to her. “Obviously there were no social networks back then, but there were other ways to support,” López says. She could have helped paste posters or joined the search. “But no,” she says. “We stayed with our arms crossed waiting for it to happen to us, and it did happen to us.” After the disappearance of her then 17-year-old daughter, Irma Claribel, in 2008, López and her husband, Jesús Lamas, began to paste Irma’s photo on every possible lamppost, hoping that someone would give them information. They got two types of response: calls asking for money, from people claiming to know Irma’s whereabouts, and misogynistic swear words scratched on the posters. Educators who stand up to conservative activists are being harassed and called “groomers” online, turning them into potential targets for real-world violence. Taking to social media was a logical next step for families of the missing. There was a marked rise in that activity after the onset of the pandemic, Villalobos says, when authorities declared it too risky to do fieldwork. “Many of us who belong to generations that perhaps were not very familiar with technology and social media have seen the opportunity to make visible our realities using our own voices,” he says. But in some ways technology hasn’t made things easier, Villalobos notes; users are trolled by bots, fake accounts, and AMLO supporters. He says government supporters often accuse families of receiving financial support from opposition parties or foreign institutions such as the US Agency for International Development and the National Endowment for Democracy, groups that have a long history of funding nongovernmental organizations in Mexico. There should be more training on social media safety, Cortés says—and a clear mechanism for legal recourse when people are threatened online. At the moment, it is a felony under federal law to threaten a person online, but Cortés says authorities often fail to investigate and prosecute such cases. Off the radar Around noon on Sunday, April 10, López received a phone call. A man told her he’d found human remains a few months back, while pulling up candelilla plants in the desert. López and her husband were exhausted. They were on the bus, riding back to their home in Torreón after spending two weeks leading a search brigade of more than 150 relatives of missing people in the nearby city of Monterrey. But they couldn’t afford to say no. Any piece of information could be a lead in their search for their daughter Irma Claribel. They called their son Jesús and asked him to pick them up in a town near the highway. They hopped in Jesús’s truck, picked up the guide, and began a one-and-a-half-hour journey toward desert too rugged for the truck to traverse. Soon it was just López and Lamas following the guide on foot, hoping they would find human remains. “Even if it’s not my daughter, it can be someone else,” says López. Authorities don’t want the media attention, she explains. They often step in to help search only after a massive discovery of human remains, one that would look bad for them to ignore. After five hours of walking, it was starting to get dark and the place where the remains were supposedly found still looked distant. A recent leg injury started to slow down Lamas, who is 66. They realized they wouldn’t make it to the site. The walk back to the truck took until midnight. López and Lamas were scared. They arrived at their house around three in the morning, feeling deflated and exhausted. Searches like this one, away from the media and authorities, are common. Bureaucracy and the extensiveness of the territory have forced mothers like López to carry out their own searches without security or resources. “I have to be filling out papers and papers to make the authorities do the work,” López says. “But I don't want them to make the process long. So when I find something, I talk to them and tell them: Here! Here it is.” López says that she still does not know how to make a case, or search brigade, go viral. Authorities don’t want the media attention, she explains. They often step in to help search only after a massive discovery of human remains, one that would look bad for them to ignore. The internet has allowed families to bypass the filters of the government and the media. “That is why social media is very useful for us: to make visible what we are experiencing,” says Flores. “This is not fiction—it’s a reality we live every day. Every day dead people appear. Every day people disappear. Every day we mothers are left without children.” Chantal Flores is a freelance journalist based in Monterrey, Mexico.","['attention', 'know', 'location', 'clandestine', 'grave', 'corpse', 'question', 'aim', 'people', 'populous', 'mexican', 'state', 'pose', 'twitter', 'organization', 'mother', 'search', 'missing', 'love', 'one', 'dozen', 'people', 'respond', 'neighbor', 'witness', 'clandestine', 'burial', 'come', 'forward', 'annotate', 'map', 'point', 'grave', 'vacant', 'house', 'message', 'also', 'come', 'penitent', 'people', 'say', '’d', 'involve', 'burial', 'move', 'confess', 'carry', 'pick', 'shovel', 'woman', 'madre', 'buscadora', 'arrive', 'chulavista', 'neighborhood', 'municipality', 'begin', 'long', 'struggle', 'history', 'kidnapping', 'people', 'officially', 'list', 'disappear', 'third', 'vanish', 'past', 'year', 'current', 'government', 'president', 'andrés', 'obrador', 'commonly', 'know', 'amlo', 'many', 'miss', 'think', 'kidnap', 'forcibly', 'recruit', 'criminal', 'organization', 'likely', 'dead', 'remain', 'bury', 'clandestine', 'grave', 'rural', 'area', 'neighborhood', 'farmland', 'scatter', 'vast', 'unoccupied', 'terrain', 'border', 'unidentified', 'body', 'lie', 'morgue', 'common', 'grave', 'university', 'quarter', 'woman', 'girl', 'likely', 'victim', 'sexual', 'exploitation', 'human', 'trafficking', 'femicide', 'departure', 'previous', 'administration', 'amlo', '’s', 'government', 'publicly', 'recognize', 'scale', 'crisis', 'strengthen', 'search', 'identification', 'effort', 'inaugurate', 'national', 'search', 'system', 'mechanism', 'seek', 'coordinate', 'effort', 'government', 'agency', 'search', 'disappeared', 'system', 'launch', 'quintana', 'head', 'commission', 'recognize', 'work', 'family', 'ground', 'virtually', 'alone', 'year', 'promise', 'never', 'alone', 'authority', 'still', 'hesitant', 'involve', 'search', 'missing', 'task', 'continue', 'fall', 'family', 'much', 'work', 'happen', 'social', 'medium', 'people', 'widely', 'distribute', 'photograph', 'miss', 'relative', 'coordinate', 'search', 'effort', 'raise', 'awareness', 'problem', 'whatsapp', 'twitter', 'facebook', 'madre', 'create', 'platform', 'engage', 'citizen', 'work', 'accelerate', 'search', 'disappear', 'day', 'group', 'receive', 'information', 'miss', 'people', 'location', 'possible', 'grave', 'many', 'resource', 'investigate', 'work', 'challenge', 'madre', 'buscadora', 'begin', 'search', 'body', 'chulavista', 'closely', 'watch', 'photograph', 'local', 'authority', 'collective', 'meet', 'governor', 'local', 'police', 'join', 'search', 'following', 'day', 'ultimately', 'madre', 'buscadora', 'uncover', 'jumbo', 'trash', 'bag', 'body', 'part', 'prosecutor', 'say', 'official', 'tally', 'body', 'bag', 'still', 'process', 'family', 'conduct', 'investigation', 'face', 'opposition', 'threat', 'organized', 'crime', 'government', 'official', 'collude', 'organized', 'crime', 'group', 'like', 'optic', 'hunt', 'miss', 'people', 'region', 'country', 'force', 'disappearance', 'approve', 'pressure', 'family', 'authority', 'take', 'immediate', 'step', 'search', 'miss', 'person', 'investigate', 'crime', 'still', 'reality', 'thousand', 'family', 'thing', 'change', 'little', 'always', 'situation', 'part', 'authority', 'shake', 'thing', 'say', '’', '’', 'say', 'martín', 'villalobo', 'member', 'consultative', 'body', 'national', 'search', 'system', 'part', 'mexican', 'society', 'respond', 'plight', 'family', 'social', 'network', 'work', 'well', 'people', 'support', 'lot', 'even', 'disappear', 'relative', 'say', 'araceli', 'hernández', 'use', 'member', 'main', 'madre', 'group', 'recently', 'form', 'new', 'collective', 'simple', 'fact', 'listen', 'pain', 'mother', 'aunt', 'make', 'support', 'tool', 'grocery', 'water', 'gatorade', 'ton', 'information', 'make', 'hold', 'tight', 'gathering', 'together', 'ceci', 'flore', 'alejandro', 'disappear', 'trace', 'city', 'northern', 'less', 'year', 'later', 'hit', 'man', 'kidnap', 'son', 'home', 'state', 'flore', 'approach', 'authority', 'see', 'immediate', 'response', 'launch', 'search', 'broadcasting', 'live', 'social', 'medium', 'day', 'later', 'receive', 'call', 'say', 'son', 'free', 'specific', 'location', 'arrive', 'young', 'adrián', 'date', 'flore', 'hear', 'day', 'recover', 'flore', 'create', 'twitter', 'account', 'begin', 'share', 'photo', 'stillmisse', 'son', 'genesis', 'madre', 'buscadora', 'mother', 'relative', 'miss', 'people', 'join', 'support', 'authority', 'search', 'child', 'start', 'search', 'invite', 'family', 'day', 'family', 'join', 'many', 'disappear', 'say', 'effort', 'danger', 'last', 'year', 'abduct', 'home', 'fatally', 'shoot', 'search', 'husband', 'go', 'miss', 'flore', 'receive', 'death', 'threat', 'ramos', 'kill', 'force', 'leave', 'hometown', 'issue', 'public', 'plea', 'organize', 'crime', 'group', 'allow', 'work', 'general', 'climate', 'hostility', 'search', 'missing', 'say', 'program', 'officer', 'nonprofit', 'advocacy', 'group', 'defend', 'freedom', 'expression', 'face', 'government', 'deny', 'human', 'right', 'violation', 'deny', 'abuse', 'defend', 'human', 'right', 'say', 'generate', 'permissiveness', 'attack', 'defend', 'human', 'right', 'relative', 'disappear', 'person', 'try', 'cancel', 'work', 'report', 'report', 'psychology', 'student', 'disappear', 'month', 'due', 'graduate', 'social', 'medium', 'pervasive', 'today', 'still', 'national', 'movement', 'disappear', 'general', 'law', 'force', 'disappearance', 'family', 'disappear', 'still', 'face', 'challenge', 'explain', 'villalobo', 'complaint', 'make', 'local', 'level', 'local', 'level', 'always', 'coopte', 'part', 'organize', 'crime', 'villalobo', 'say', 'file', 'report', 'family', 'defenseless', 'attack', 'criminal', 'authority', 'also', 'isolate', 'family', 'fear', 'relate', 'threat', 'revenge', 'move', 'away', 'remember', 'see', 'mother', 'paste', 'miss', 'person', 'poster', 'daughter', 'face', 'public', 'place', 'northern', 'city', 'torreón', 'late', '2000', 'never', 'think', 'happen', 'obviously', 'social', 'network', 'back', 'way', 'support', 'lópez', 'say', 'help', 'paste', 'poster', 'join', 'search', 'say', 'stay', 'arm', 'cross', 'wait', 'happen', 'happen', 'disappearance', 'daughter', 'lópez', 'husband', 'jesús', 'begin', 'paste', 'photo', 'possible', 'lamppost', 'hoping', 'give', 'information', 'get', 'type', 'response', 'call', 'ask', 'money', 'people', 'claim', 'know', 'whereabouts', 'misogynistic', 'swear', 'word', 'scratch', 'poster', 'educator', 'stand', 'conservative', 'activist', 'harass', 'call', 'groomer', 'online', 'turn', 'potential', 'target', 'violence', 'take', 'social', 'medium', 'logical', 'next', 'step', 'family', 'missing', 'marked', 'rise', 'activity', 'onset', 'pandemic', 'villalobo', 'say', 'authority', 'declare', 'risky', 'fieldwork', 'many', 'belong', 'generation', 'perhaps', 'familiar', 'technology', 'social', 'medium', 'see', 'opportunity', 'make', 'visible', 'reality', 'use', 'voice', 'say', 'way', 'technology', 'make', 'thing', 'easy', 'villalobo', 'note', 'user', 'troll', 'bot', 'fake', 'account', 'amlo', 'supporter', 'say', 'government', 'supporter', 'often', 'accuse', 'family', 'receive', 'financial', 'support', 'opposition', 'party', 'foreign', 'institution', 'agency', 'international', 'development', 'national', 'endowment', 'democracy', 'group', 'long', 'history', 'fund', 'nongovernmental', 'organization', 'mexico', 'training', 'social', 'medium', 'safety', 'cortés', 'say', 'clear', 'mechanism', 'legal', 'recourse', 'people', 'threaten', 'online', 'moment', 'felony', 'federal', 'law', 'threaten', 'person', 'online', 'cortés', 'say', 'authority', 'often', 'fail', 'investigate', 'prosecute', 'case', 'radar', 'noon', 'lópez', 'receive', 'phone', 'call', 'man', 'tell', '’d', 'find', 'human', 'remain', 'month', 'back', 'pull', 'candelilla', 'plant', 'desert', 'lópez', 'husband', 'exhaust', 'bus', 'ride', 'back', 'home', 'torreón', 'spend', 'week', 'lead', 'search', 'brigade', 'relative', 'miss', 'people', 'nearby', 'city', 'monterrey', 'afford', 'say', 'piece', 'information', 'lead', 'search', 'daughter', 'call', 'son', 'ask', 'pick', 'town', 'highway', 'hop', 'truck', 'pick', 'guide', 'begin', 'oneandahalfhour', 'journey', 'desert', 'rugged', 'truck', 'traverse', 'soon', 'lópez', 'lama', 'follow', 'guide', 'foot', 'hope', 'find', 'human', 'remain', 'even', '’', 'daughter', 'else', 'say', 'lópez', 'authority', 'want', 'medium', 'attention', 'explain', 'often', 'step', 'help', 'search', 'massive', 'discovery', 'human', 'remain', 'one', 'look', 'bad', 'ignore', 'hour', 'walk', 'start', 'get', 'dark', 'place', 'remain', 'supposedly', 'find', 'still', 'look', 'distant', 'recent', 'leg', 'injury', 'start', 'slow', 'lama', 'realize', 'make', 'site', 'walk', 'back', 'truck', 'take', 'midnight', 'lópez', 'lama', 'scared', 'arrive', 'house', 'morning', 'feeling', 'deflated', 'exhausted', 'search', 'away', 'medium', 'authority', 'common', 'bureaucracy', 'extensiveness', 'territory', 'force', 'mother', 'lópez', 'carry', 'search', 'security', 'resource', 'fill', 'paper', 'paper', 'make', 'authority', 'work', 'lópez', 'say', 'want', 'make', 'process', 'long', 'find', 'talk', 'tell', 'lópez', 'say', 'still', 'know', 'make', 'case', 'search', 'brigade', 'go', 'viral', 'authority', 'want', 'medium', 'attention', 'explain', 'often', 'step', 'help', 'search', 'massive', 'discovery', 'human', 'remain', 'one', 'look', 'bad', 'ignore', 'internet', 'allow', 'family', 'bypass', 'filter', 'government', 'medium', 'social', 'medium', 'useful', 'make', 'visible', 'experience', 'say', 'flore', 'fiction', '’', 'reality', 'live', 'day', 'day', 'dead', 'people', 'appear', 'day', 'people', 'disappear', 'day', 'mother', 'leave', 'child', 'chantal', 'flore', 'freelance', 'journalist', 'base']"
The porcelain challenge didn’t need to be real to get views,https://www.technologyreview.com/2022/10/05/1060746/porcelain-challenge-fake-views-moral-panic/,2022-10-05,"<p>Sebastian Durfee created a fake teen challenge—and got banned from TikTok. It kind of proved his point about online moral panics.</p>
","Despite what you may have heard, the teens are not stealing their family’s fine dinnerware, tossing it in a blender, and snorting the resulting dust for the “porcelain challenge.” That’s just what Sebastian Durfee, a 23-year-old actor and TikTok creator, hoped you might believe when he spread the word on social media of the latest dangerous teen challenge.  Never mind that it was all fake from the start. On Saturday, Durfee posted a call to action to his followers: to work together to get “boomers to freak out about a fake TikTok challenge.” He chose the porcelain challenge—which, once again, is just a thing Durfee made up—because it seemed like something that would be plausibly dangerous, but not something “the average person could go off and do very easily,” he told me this week. Besides, it’s a catchy name. His original video quickly passed half a million views, and TikTok slapped a warning on it for promoting dangerous acts.  Meanwhile on TikTok, Facebook, and Twitter, #PorcelainChallenge videos created by those in on the joke started asking people to spread warnings and share stories of (fake) injuries and deaths from those who tried it. One particularly clever video takes the bit to the next level, with the creator claiming that videos of people trying the challenge are being removed by TikTok moderators immediately—a way to explain why there’s no available video of any person actually doing this.  The platform announced it’ll share revenue with makers of short-form videos. It wouldn’t tell us what portion of ad revenue is up for grabs. Shortly after we spoke on Monday, Durfee sent me an update: TikTok had permanently banned his account (which had 150,000 followers), apparently as a result of this experiment. The company didn’t give him a reason for the permanent removal, but he said that they did take down two videos for “promoting dangerous behavior”: one in which he told viewers to post warnings about the porcelain challenge in local Facebook groups, and another in which he shared a screenshot of some early media coverage of his work.  TikTok confirmed on Wednesday that it had banned Durfee’s account, and said that it viewed any content, including hoaxes, that promotes dangerous behavior as a violation of their community guidelines.  “It goes without saying that neither these videos nor any other ones I created glorified, endorsed, or depicted performing the challenge,” he emailed me on Wednesday. “The fact that they reacted to the challenge as if it was real by banning me entirely is the sort of knee-jerk widespread panic the challenge was meant to critique in the first place; the irony here is not lost on me.” Durfee’s goal was to get views, which he got in spades before his account was banned. It was also to examine how attention and outrage work online. If a content creator performs all the parts of a moral panic, will the fact that the challenge itself is a complete fiction actually change anything about its spread?   I’ve reported on moral panics about The Children many times over the years. Right now, it’s the season when people annually freak out about the possibility of THC-laced candies in their kid’s trick-or-treat stash. This fear, along with the many other warnings that deadly candies might be handed to kids by the sadist next door, have thrived every fall for decades merely on possibilities and what-ifs: dig into the “proof” cited by those pushing these warnings and you’ll find that it doesn’t stand up.  It doesn’t need to. Social media often works by reflex. Content that does well practically begs to be shared right away, reality be damned. And in the case of teen challenges and dangers to children, those warnings are often passed along by sources that carry some authority in their communities: the Facebook pages of local law enforcement, local media, or school officials.  “I’ve dabbled in the past with trying to make fake news that is transparent about being fake but spreads nonetheless,” Durfee said. (He once, with a surprising amount of success, got a false rumor started that longtime YouTuber Hank Green had been arrested as a teenager for trying to steal a lemur from a zoo.)  On Sunday, Durfee and his friends watched as #PorcelainChallenge gained traction, and they celebrated when it generated its first media headline (“TikTok’s porcelain challenge is not real but it’s not something to joke about either”). A steady parade of other headlines, some more credulous than others, followed.  But reflex-dependent viral content has a short life span. When Durfee and I chatted three days after he posted his first video about the porcelain challenge, he already could tell that it wasn’t going to catch as widely as he’d hoped. RIP.  Nevertheless, viral moments can be reanimated with just the slightest touch of attention, becoming an undead trend ambling through Facebook news feeds and panicked parent groups. Stripping away their original context can only make them more powerful. And dubious claims about viral teen challenges are often these sorts of zombies—sometimes giving them a second life that’s much bigger (and arguably more dangerous) than the first. For every “cinnamon challenge” (a real early-2010s viral challenge that made the YouTube rounds and put participants at risk for some nasty health complications), there are even more dumb ideas on the internet that do not trend until someone with a large audience of parents freaks out about them.  Just a couple of weeks ago, for instance, the US Food and Drug Administration issued a warning about boiling chicken in NyQuil, prompting a panic over a craze that would endanger Gen Z lives in the name of views. Instead, as Buzzfeed News reported, the warning itself was the most viral thing about NyQuil chicken, spiking interest in a “trend” that was not trending.  And in 2018, there was the “condom challenge,” which gained widespread media coverage as the latest life-threatening thing teens were doing online for attention—“uncovered” because a local news station sat in on a presentation at a Texas school on the dangers teens face. In reality, the condom challenge had a few minor blips of interest online in 2007 and 2013, but videos of people actually trying to snort a condom up their nose were sparse. In each case, the fear of teens flocking en masse to take part in a dangerous challenge did more to amplify it to a much larger audience than the challenge was able to do on its own.  The porcelain challenge has all the elements of future zombie content. Its catchy name stands out like a bite on the arm. The posts and videos seeded across social media by Durfee’s followers—and the secondary audience coming across the work of those Durfee deputized—are plausible and context-free.  Figuring out social media platforms’ hidden rules is hard work—and it falls more heavily on creators from marginalized backgrounds. But in a new twist, it is Durfee’s attempt to now mess with the people who are in on the joke that may return to chase the living.  When Durfee realized that he’d found a large audience of people who were really enthusiastic about dunking on boomers by helping to spread the porcelain challenge, he thought it was time to shift tactics a bit. “I decided, what if I get all these people who think they’re in on the joke to actually be the punchline of the next part of it?” he said.  So he posted a video on TikTok that appeared to show a Fox News headline about the porcelain challenge, along with a video clip of someone who appeared to be on the conservative channel ranting about the decline of morality. The headline, of course, was fake, the clip taken from its original context. But Durfee’s video, which featured him pointing at the headline as if he couldn’t believe how well his prank was working, ended up on Reddit’s r/facepalm subreddit. The post has more than 16,000 upvotes. The headline makes no nod to the fact that the Fox News segment is faked: “this guy made up a fake ‘TikTok challenge’ and FOX news made an article about it in three days.”  Just before we spoke, Durfee followed up with another faked video, purportedly showing the porcelain challenge on CNN. This, too, was fictional. And many viewers of his TikToks were fooled by this one as well.  “I was getting many, many comments from people saying stuff like ‘Oh, does no one check sources anymore? This is so embarrassing that they would post something without fact checking,’” he said. “And the irony is that the thing they were watching and commenting on was entirely fictional.”  No one in this fake challenge, it turns out, was immune to the impulse to share. Durfee’s followers were enticed by the excitement of dunking on boomers, and that promise became a lure, the faked Fox News clip as shareable as a warning about NyQuil chicken. I checked in with Durfee on Wednesday morning. He said his account was still banned. But many of the videos, Facebook posts, and tweets about the dangers of the challenge he made up remain online. Unlike Durfee’s content, many of these videos and posts provide absolutely no indication that the challenge itself is fiction. So there they sit, awaiting the end of the porcelain challenge’s online life span. The perfect candidates for reanimation.  ","Despite what you may have heard, the teens are not stealing their family’s fine dinnerware, tossing it in a blender, and snorting the resulting dust for the “porcelain challenge.” That’s just what Sebastian Durfee, a 23-year-old actor and TikTok creator, hoped you might believe when he spread the word on social media of the latest dangerous teen challenge. Never mind that it was all fake from the start. On Saturday, Durfee posted a call to action to his followers: to work together to get “boomers to freak out about a fake TikTok challenge.” He chose the porcelain challenge—which, once again, is just a thing Durfee made up—because it seemed like something that would be plausibly dangerous, but not something “the average person could go off and do very easily,” he told me this week. Besides, it’s a catchy name. His original video quickly passed half a million views, and TikTok slapped a warning on it for promoting dangerous acts. Meanwhile on TikTok, Facebook, and Twitter, #PorcelainChallenge videos created by those in on the joke started asking people to spread warnings and share stories of (fake) injuries and deaths from those who tried it. One particularly clever video takes the bit to the next level, with the creator claiming that videos of people trying the challenge are being removed by TikTok moderators immediately—a way to explain why there’s no available video of any person actually doing this. The platform announced it’ll share revenue with makers of short-form videos. It wouldn’t tell us what portion of ad revenue is up for grabs. Shortly after we spoke on Monday, Durfee sent me an update: TikTok had permanently banned his account (which had 150,000 followers), apparently as a result of this experiment. The company didn’t give him a reason for the permanent removal, but he said that they did take down two videos for “promoting dangerous behavior”: one in which he told viewers to post warnings about the porcelain challenge in local Facebook groups, and another in which he shared a screenshot of some early media coverage of his work. TikTok confirmed on Wednesday that it had banned Durfee’s account, and said that it viewed any content, including hoaxes, that promotes dangerous behavior as a violation of their community guidelines. “It goes without saying that neither these videos nor any other ones I created glorified, endorsed, or depicted performing the challenge,” he emailed me on Wednesday. “The fact that they reacted to the challenge as if it was real by banning me entirely is the sort of knee-jerk widespread panic the challenge was meant to critique in the first place; the irony here is not lost on me.” Durfee’s goal was to get views, which he got in spades before his account was banned. It was also to examine how attention and outrage work online. If a content creator performs all the parts of a moral panic, will the fact that the challenge itself is a complete fiction actually change anything about its spread? I’ve reported on moral panics about The Children many times over the years. Right now, it’s the season when people annually freak out about the possibility of THC-laced candies in their kid’s trick-or-treat stash. This fear, along with the many other warnings that deadly candies might be handed to kids by the sadist next door, have thrived every fall for decades merely on possibilities and what-ifs: dig into the “proof” cited by those pushing these warnings and you’ll find that it doesn’t stand up. It doesn’t need to. Social media often works by reflex. Content that does well practically begs to be shared right away, reality be damned. And in the case of teen challenges and dangers to children, those warnings are often passed along by sources that carry some authority in their communities: the Facebook pages of local law enforcement, local media, or school officials. “I’ve dabbled in the past with trying to make fake news that is transparent about being fake but spreads nonetheless,” Durfee said. (He once, with a surprising amount of success, got a false rumor started that longtime YouTuber Hank Green had been arrested as a teenager for trying to steal a lemur from a zoo.) On Sunday, Durfee and his friends watched as #PorcelainChallenge gained traction, and they celebrated when it generated its first media headline (“TikTok’s porcelain challenge is not real but it’s not something to joke about either”). A steady parade of other headlines, some more credulous than others, followed. But reflex-dependent viral content has a short life span. When Durfee and I chatted three days after he posted his first video about the porcelain challenge, he already could tell that it wasn’t going to catch as widely as he’d hoped. RIP. Nevertheless, viral moments can be reanimated with just the slightest touch of attention, becoming an undead trend ambling through Facebook news feeds and panicked parent groups. Stripping away their original context can only make them more powerful. And dubious claims about viral teen challenges are often these sorts of zombies—sometimes giving them a second life that’s much bigger (and arguably more dangerous) than the first. For every “cinnamon challenge” (a real early-2010s viral challenge that made the YouTube rounds and put participants at risk for some nasty health complications), there are even more dumb ideas on the internet that do not trend until someone with a large audience of parents freaks out about them. Just a couple of weeks ago, for instance, the US Food and Drug Administration issued a warning about boiling chicken in NyQuil, prompting a panic over a craze that would endanger Gen Z lives in the name of views. Instead, as Buzzfeed News reported, the warning itself was the most viral thing about NyQuil chicken, spiking interest in a “trend” that was not trending. And in 2018, there was the “condom challenge,” which gained widespread media coverage as the latest life-threatening thing teens were doing online for attention—“uncovered” because a local news station sat in on a presentation at a Texas school on the dangers teens face. In reality, the condom challenge had a few minor blips of interest online in 2007 and 2013, but videos of people actually trying to snort a condom up their nose were sparse. In each case, the fear of teens flocking en masse to take part in a dangerous challenge did more to amplify it to a much larger audience than the challenge was able to do on its own. The porcelain challenge has all the elements of future zombie content. Its catchy name stands out like a bite on the arm. The posts and videos seeded across social media by Durfee’s followers—and the secondary audience coming across the work of those Durfee deputized—are plausible and context-free. Figuring out social media platforms’ hidden rules is hard work—and it falls more heavily on creators from marginalized backgrounds. But in a new twist, it is Durfee’s attempt to now mess with the people who are in on the joke that may return to chase the living. When Durfee realized that he’d found a large audience of people who were really enthusiastic about dunking on boomers by helping to spread the porcelain challenge, he thought it was time to shift tactics a bit. “I decided, what if I get all these people who think they’re in on the joke to actually be the punchline of the next part of it?” he said. So he posted a video on TikTok that appeared to show a Fox News headline about the porcelain challenge, along with a video clip of someone who appeared to be on the conservative channel ranting about the decline of morality. The headline, of course, was fake, the clip taken from its original context. But Durfee’s video, which featured him pointing at the headline as if he couldn’t believe how well his prank was working, ended up on Reddit’s r/facepalm subreddit. The post has more than 16,000 upvotes. The headline makes no nod to the fact that the Fox News segment is faked: “this guy made up a fake ‘TikTok challenge’ and FOX news made an article about it in three days.” Just before we spoke, Durfee followed up with another faked video, purportedly showing the porcelain challenge on CNN. This, too, was fictional. And many viewers of his TikToks were fooled by this one as well. “I was getting many, many comments from people saying stuff like ‘Oh, does no one check sources anymore? This is so embarrassing that they would post something without fact checking,’” he said. “And the irony is that the thing they were watching and commenting on was entirely fictional.” No one in this fake challenge, it turns out, was immune to the impulse to share. Durfee’s followers were enticed by the excitement of dunking on boomers, and that promise became a lure, the faked Fox News clip as shareable as a warning about NyQuil chicken. I checked in with Durfee on Wednesday morning. He said his account was still banned. But many of the videos, Facebook posts, and tweets about the dangers of the challenge he made up remain online. Unlike Durfee’s content, many of these videos and posts provide absolutely no indication that the challenge itself is fiction. So there they sit, awaiting the end of the porcelain challenge’s online life span. The perfect candidates for reanimation.","['hear', 'teen', 'steal', 'family', 'fine', 'dinnerware', 'toss', 'blender', 'snort', 'result', 'dust', 'porcelain', 'challenge', '’', 'sebastian', 'durfee', 'actor', 'tiktok', 'creator', 'hope', 'believe', 'spread', 'word', 'social', 'medium', 'late', 'dangerous', 'teen', 'challenge', 'never', 'mind', 'fake', 'start', 'post', 'call', 'action', 'follower', 'work', 'together', 'get', 'boomer', 'freak', 'fake', 'tiktok', 'challenge', 'choose', 'porcelain', 'challenge', 'thing', 'durfee', 'make', 'seem', 'plausibly', 'dangerous', 'average', 'person', 'go', 'easily', 'tell', 'week', '’', 'catchy', 'name', 'original', 'video', 'quickly', 'pass', 'view', 'tiktok', 'slap', 'warning', 'promote', 'dangerous', 'act', 'meanwhile', 'tiktok', 'facebook', 'twitter', 'porcelainchallenge', 'video', 'create', 'joke', 'start', 'ask', 'people', 'spread', 'warning', 'share', 'story', 'fake', 'injury', 'death', 'try', 'particularly', 'clever', 'video', 'take', 'bit', 'next', 'level', 'creator', 'claim', 'video', 'people', 'try', 'challenge', 'remove', 'tiktok', 'moderator', 'immediately', 'way', 'explain', '’', 'available', 'video', 'person', 'actually', 'platform', 'announce', 'share', 'revenue', 'maker', 'shortform', 'video', 'tell', 'portion', 'ad', 'revenue', 'grab', 'shortly', 'speak', 'durfee', 'send', 'update', 'tiktok', 'permanently', 'ban', 'account', 'follower', 'apparently', 'result', 'experiment', 'company', 'give', 'reason', 'permanent', 'removal', 'say', 'take', 'video', 'promote', 'dangerous', 'behavior', 'tell', 'viewer', 'post', 'warning', 'porcelain', 'challenge', 'local', 'facebook', 'group', 'share', 'screenshot', 'early', 'medium', 'coverage', 'work', 'tiktok', 'confirm', 'ban', 'account', 'say', 'view', 'content', 'include', 'hoax', 'promote', 'dangerous', 'behavior', 'violation', 'community', 'guideline', 'go', 'say', 'video', 'one', 'create', 'glorify', 'endorse', 'depict', 'perform', 'challenge', 'email', 'fact', 'react', 'challenge', 'real', 'ban', 'entirely', 'sort', 'widespread', 'panic', 'challenge', 'mean', 'critique', 'first', 'place', 'irony', 'lose', 'durfee', 'goal', 'get', 'view', 'get', 'spade', 'account', 'ban', 'also', 'examine', 'attention', 'outrage', 'work', 'online', 'content', 'creator', 'perform', 'part', 'moral', 'panic', 'fact', 'challenge', 'complete', 'fiction', 'actually', 'change', 'spread', 'report', 'moral', 'panic', 'child', 'many', 'time', 'year', 'right', '’', 'season', 'people', 'annually', 'freak', 'possibility', 'thclaced', 'candy', 'kid', 'trickortreat', 'stash', 'fear', 'many', 'warning', 'deadly', 'candy', 'hand', 'kid', 'sadist', 'next', 'door', 'thrive', 'fall', 'decade', 'merely', 'possibility', 'whatifs', 'dig', 'proof', 'cite', 'push', 'warning', 'find', 'stand', 'need', 'social', 'medium', 'often', 'work', 'reflex', 'content', 'well', 'practically', 'beg', 'share', 'right', 'away', 'reality', 'damn', 'case', 'teen', 'challenge', 'danger', 'child', 'warning', 'often', 'pass', 'source', 'carry', 'authority', 'community', 'facebook', 'page', 'local', 'law', 'enforcement', 'local', 'medium', 'school', 'official', 'dabble', 'past', 'try', 'make', 'fake', 'news', 'transparent', 'fake', 'spread', 'nonetheless', 'durfee', 'say', 'surprising', 'amount', 'success', 'get', 'false', 'rumor', 'start', 'arrest', 'teenager', 'try', 'steal', 'lemur', 'zoo', 'durfee', 'friend', 'watch', 'porcelainchallenge', 'gain', 'traction', 'celebrate', 'generate', 'first', 'medium', 'headline', 'tiktok', 'porcelain', 'challenge', 'real', '’', 'joke', 'steady', 'parade', 'headline', 'credulous', 'follow', 'reflexdependent', 'viral', 'content', 'short', 'life', 'span', 'chat', 'day', 'post', 'first', 'video', 'porcelain', 'challenge', 'already', 'tell', 'go', 'catch', 'widely', '’d', 'hope', 'rip', 'nevertheless', 'viral', 'moment', 'reanimate', 'slight', 'touch', 'attention', 'become', 'undead', 'trend', 'amble', 'facebook', 'news', 'feed', 'panic', 'parent', 'group', 'strip', 'away', 'original', 'context', 'make', 'powerful', 'dubious', 'claim', 'viral', 'teen', 'challenge', 'often', 'sort', 'zombie', 'sometimes', 'give', 'second', 'life', '’', 'much', 'big', 'arguably', 'dangerous', 'first', 'cinnamon', 'challenge', 'real', 'early2010s', 'viral', 'challenge', 'make', 'youtube', 'round', 'put', 'participant', 'risk', 'nasty', 'health', 'complication', 'even', 'dumb', 'idea', 'internet', 'trend', 'large', 'audience', 'parent', 'freak', 'couple', 'week', 'ago', 'instance', 'food', 'issue', 'warning', 'boil', 'chicken', 'nyquil', 'prompt', 'panic', 'craze', 'endanger', 'live', 'name', 'view', 'instead', 'news', 'report', 'warning', 'viral', 'thing', 'chicken', 'spike', 'interest', 'trend', 'trend', 'condom', 'challenge', 'gain', 'widespread', 'medium', 'coverage', 'late', 'lifethreatening', 'thing', 'teen', 'online', 'attention', 'uncover', 'local', 'news', 'station', 'sit', 'presentation', 'school', 'danger', 'teen', 'face', 'reality', 'condom', 'challenge', 'minor', 'blip', 'interest', 'online', 'video', 'people', 'actually', 'try', 'snort', 'condom', 'nose', 'sparse', 'case', 'fear', 'teen', 'flock', 'masse', 'take', 'part', 'dangerous', 'challenge', 'amplify', 'much', 'large', 'audience', 'challenge', 'able', 'porcelain', 'challenge', 'element', 'future', 'zombie', 'content', 'catchy', 'name', 'stand', 'bite', 'arm', 'post', 'video', 'seed', 'social', 'medium', 'follower', 'secondary', 'audience', 'come', 'work', 'durfee', 'deputize', 'plausible', 'contextfree', 'figure', 'social', 'medium', 'platform', 'hidden', 'rule', 'hard', 'work', 'fall', 'heavily', 'creator', 'marginalized', 'background', 'new', 'twist', 'attempt', 'mess', 'people', 'joke', 'return', 'chase', 'living', 'durfee', 'realize', '’d', 'find', 'large', 'audience', 'people', 'really', 'enthusiastic', 'dunk', 'boomer', 'help', 'spread', 'porcelain', 'challenge', 'think', 'time', 'shift', 'tactic', 'bit', 'decide', 'get', 'people', 'think', '’re', 'joke', 'actually', 'punchline', 'next', 'part', 'say', 'post', 'video', 'tiktok', 'appear', 'show', 'news', 'headline', 'porcelain', 'challenge', 'video', 'clip', 'appear', 'conservative', 'channel', 'rant', 'decline', 'morality', 'headline', 'course', 'fake', 'clip', 'take', 'original', 'context', 'video', 'feature', 'point', 'headline', 'believe', 'well', 'prank', 'work', 'end', 'reddit', 'rfacepalm', 'subreddit', 'post', 'upvote', 'headline', 'make', 'nod', 'fact', 'news', 'segment', 'fake', 'guy', 'make', 'fake', 'tiktok', 'challenge', 'make', 'article', 'day', 'speak', 'durfee', 'follow', 'faked', 'video', 'purportedly', 'show', 'porcelain', 'challenge', 'fictional', 'many', 'viewer', 'tiktok', 'fool', 'one', 'well', 'get', 'many', 'many', 'comment', 'people', 'say', 'stuff', 'one', 'check', 'source', 'anymore', 'embarrassing', 'post', 'fact', 'check', 'say', 'irony', 'thing', 'watch', 'comment', 'entirely', 'fictional', 'one', 'fake', 'challenge', 'turn', 'immune', 'impulse', 'share', 'durfee', 'follower', 'entice', 'excitement', 'dunk', 'boomer', 'promise', 'become', 'lure', 'faked', 'news', 'clip', 'shareable', 'warning', 'check', 'durfee', 'morning', 'say', 'account', 'still', 'ban', 'many', 'video', 'facebook', 'post', 'tweet', 'danger', 'challenge', 'make', 'remain', 'online', 'content', 'many', 'video', 'post', 'provide', 'absolutely', 'indication', 'challenge', 'fiction', 'sit', 'await', 'end', 'porcelain', 'challenge', 'online', 'life', 'span', 'perfect', 'candidate', 'reanimation']"
How the covid pop-up window is wreaking havoc on daily life in China,https://www.technologyreview.com/2022/10/04/1060628/covid-pop-up-window-beijing/,2022-10-04,"<p>A frustrating feature in Beijing’s covid app reveals major cracks in the technocratic zero-covid system.</p>
","China Report is MIT Technology Review’s newsletter about what's happening in China. Sign up to receive it in your inbox every Tuesday. Welcome back! Hope you are not stuck in highway traffic if you are enjoying the National Day holiday in China.  Though maybe it’s still better than staying at home—after all, travel feels like such a luxury in China today. While the rest of the world drops its remaining covid-related travel restrictions, even a short trip in China is plagued by flight cancellations, mandatory quarantines, and requirements to update regular covid test results.  And for the more than 20 million people who live in or visit Beijing, the capital city, there is one additional worry: a pop-up window that can randomly show up on your phone to disrupt all your plans. Starting in 2020, China rolled out a contact tracing program that assigns a QR code to everyone in the country. It shows your covid status and allows you to enter public venues or take public transportation. Part of China’s stringent zero-covid policy, the system has persisted, and some of the once-lauded features that kept deaths comparatively low in the country now feel more burdensome than beneficial to its citizens. (Most covid apps in other countries have been suspended. We documented all of them back in 2020.) The pop-up, 弹窗, is one additional complicated layer that Beijing added to its tracing system. This window in the mobile covid app won’t go away unless the user immediately takes a PCR test. It gives broad instructions on what to do under the title “friendly reminders,” but it’s not so friendly. It masks a user’s QR code so that it can’t be scanned, thus denying people access to just about everywhere in China. In some cases, it takes only a day to get a PCR test to make the window go away; other times, people may be asked to quarantine at home for seven days or more. I have friends scattered around all parts of China, and this year I’ve seen so many of them complaining about it. “I went to take a PCR test to solve the pop-up window problem, but the testing location turned out to be a high-risk zone, so I was asked to quarantine at home for 14 days,” wrote a friend in April. The specifics may differ, but they all agree on the particular menace: no one knows why they are receiving the pop-up window or when they will get it, and there’s no way to prepare for it. Officially, the municipal government of Beijing says there are several reasons why people get a pop-up window: you have been to a city with recent covid cases; you have just been abroad; you have been in the same “time and space” with someone exposed to covid; or you didn’t get a PCR test within 72 hours of buying fever or cough medicine.  But the problem is, despite being touted as a high-tech pandemic solution, the app’s risk-identifying mechanism tends to cast a wider-than-necessary net, with zero explanation as to why the pop-up is appearing—which often leaves people confused and stuck in covid limbo.  That’s what happened to Flora Yuan, a 28-year-old Beijing resident. She received the pop-up window for the first time earlier this year when she was walking outside her office building; she was immediately blocked from reentering. “After the pop-up window, you could still walk around on the street, but you’d need a QR code to go into any place, a park, a restaurant, or a shop,” she told me recently.  Since then, she has received the pop-up window just as she was about to enter a restaurant; on the day of Chinese New Year, when all hospitals were closed and she couldn’t take a PCR test anywhere; and hours before she was supposed to take a train out of Beijing.  In none of these instances had she actually engaged in high-risk activities or had a known exposure. As best she could guess, the system perhaps thought she was elsewhere (her phone number was not registered in Beijing), or she unknowingly happened to be in the same GPS location with a covid patient, perhaps on the subway.  But whether or not she was actually exposed is sort of beside the point. Since there’s little explanation for why the windows appear, there’s no accountability. And erring on the side of caution (and over-reaching into people's lives) is a feature of the pop-up window, not a bug. For all the hype about how tech-savvy the Chinese government is, the pop-up windows reveal major cracks in the system: though often viewed outside China as a smart but dystopian use of surveillance technology, the actual covid tracing app is flawed and creates more burdens than it resolves.  The impact has been vast: When people are waiting for the pop-up to disappear, they miss out on their jobs, vacations, and sometimes urgent medical services. Thousands of people have complained on Weibo about the pop-up suddenly stranding them far from home. The pop-up also haunts the lives of the millions of non-Beijing residents who go to the city for work or to visit family and are subject to the same unpredictable restrictions.  Instead of precise prevention, the technology is more of a blunt instrument that enables the government to be as strict as possible,just like how China obsessively disinfects every surface. Does it help China reduce the number of covid deaths? Yes. But at what cost?  Increasingly, this is how the public in China feels. The measures that were considered essential in reducing covid’s spread in the first two years of the pandemic now feel performative and taxing. Ordinary people, even if they want to abide by the covid control policies, still feel they can’t control their own lives. For Yuan, the only thing she can do is to frequently check the app, sometimes once every hour, before she’s due to board a train or plane.  “Compared to all the tragedies caused by the covid prevention policies, this probably doesn’t seem significant. But when it falls on an individual, it still feels devastating,” she says.  Have you had a traumatic experience with the pop-up windows, or do you have any thoughts on them as a pandemic tool? Write to me at zeyi@technologyreview.com 1. I wrote last week about how a new fuel can help transition China’s cars away from gas—good!—but may also increase China’s dependence on coal—not so good. (MIT Technology Review) 2. Lots of news in the Chinese vaccine world:  3. From “static management” to “unnecessary food,” here are the nonsensical phrases deployed by the Chinese government to serve its zero-covid policy. (The New York Times $) 4. Richard Liu, founder and ex-CEO of China’s ecommerce giant JD, settled a 2018 sexual assault lawsuit in Minnesota. (The Wall Street Journal $) 5. Say bye to Google Translate in China, one of the last remaining services from the tech giant that was still operating in the country. (CNBC) 6. New research shows how Chinese-government-backed hackers have targeted Tibetan organizations in exile. (Bloomberg $) Home to over 90% of e-cigarette production in the world, China has implemented a much stricter regulation on vaper sales since October 1, reports the Chinese publication Sina Tech. All e-cigarettes need to have childproof locks built in, and companies can’t produce or sell fruit-flavored e-cigarettes, which are controversial for attracting children to vaping. Also, wholesalers and retail owners will have to make all transactions on a state-operated central marketplace, and only after they secure licenses from the state. Amid the rush to comply with the new rules, some retailers are hoarding fruit-flavored e-cigarettes and selling them at a 100% premium. WeChat or baijiu liquor—which one represents China’s economic future? On Friday, Kweichow Moutai, maker of China’s luxury liquor (priced at over $200 per bottle), dethroned Tencent as the most valuable publicly traded Chinese company. The latter has seen its market cap evaporate 64% since January 2021, mostly as a result of China’s moves to regulate Big Tech. It turns out tech companies come and go, but baijiu is forever. ","China Report is MIT Technology Review’s newsletter about what's happening in China. Sign up to receive it in your inbox every Tuesday. Welcome back! Hope you are not stuck in highway traffic if you are enjoying the National Day holiday in China. Though maybe it’s still better than staying at home—after all, travel feels like such a luxury in China today. While the rest of the world drops its remaining covid-related travel restrictions, even a short trip in China is plagued by flight cancellations, mandatory quarantines, and requirements to update regular covid test results. And for the more than 20 million people who live in or visit Beijing, the capital city, there is one additional worry: a pop-up window that can randomly show up on your phone to disrupt all your plans. Starting in 2020, China rolled out a contact tracing program that assigns a QR code to everyone in the country. It shows your covid status and allows you to enter public venues or take public transportation. Part of China’s stringent zero-covid policy, the system has persisted, and some of the once-lauded features that kept deaths comparatively low in the country now feel more burdensome than beneficial to its citizens. (Most covid apps in other countries have been suspended. We documented all of them back in 2020.) The pop-up, 弹窗, is one additional complicated layer that Beijing added to its tracing system. This window in the mobile covid app won’t go away unless the user immediately takes a PCR test. It gives broad instructions on what to do under the title “friendly reminders,” but it’s not so friendly. It masks a user’s QR code so that it can’t be scanned, thus denying people access to just about everywhere in China. In some cases, it takes only a day to get a PCR test to make the window go away; other times, people may be asked to quarantine at home for seven days or more. I have friends scattered around all parts of China, and this year I’ve seen so many of them complaining about it. “I went to take a PCR test to solve the pop-up window problem, but the testing location turned out to be a high-risk zone, so I was asked to quarantine at home for 14 days,” wrote a friend in April. The specifics may differ, but they all agree on the particular menace: no one knows why they are receiving the pop-up window or when they will get it, and there’s no way to prepare for it. Officially, the municipal government of Beijing says there are several reasons why people get a pop-up window: you have been to a city with recent covid cases; you have just been abroad; you have been in the same “time and space” with someone exposed to covid; or you didn’t get a PCR test within 72 hours of buying fever or cough medicine. But the problem is, despite being touted as a high-tech pandemic solution, the app’s risk-identifying mechanism tends to cast a wider-than-necessary net, with zero explanation as to why the pop-up is appearing—which often leaves people confused and stuck in covid limbo. That’s what happened to Flora Yuan, a 28-year-old Beijing resident. She received the pop-up window for the first time earlier this year when she was walking outside her office building; she was immediately blocked from reentering. “After the pop-up window, you could still walk around on the street, but you’d need a QR code to go into any place, a park, a restaurant, or a shop,” she told me recently. Since then, she has received the pop-up window just as she was about to enter a restaurant; on the day of Chinese New Year, when all hospitals were closed and she couldn’t take a PCR test anywhere; and hours before she was supposed to take a train out of Beijing. In none of these instances had she actually engaged in high-risk activities or had a known exposure. As best she could guess, the system perhaps thought she was elsewhere (her phone number was not registered in Beijing), or she unknowingly happened to be in the same GPS location with a covid patient, perhaps on the subway. But whether or not she was actually exposed is sort of beside the point. Since there’s little explanation for why the windows appear, there’s no accountability. And erring on the side of caution (and over-reaching into people's lives) is a feature of the pop-up window, not a bug. For all the hype about how tech-savvy the Chinese government is, the pop-up windows reveal major cracks in the system: though often viewed outside China as a smart but dystopian use of surveillance technology, the actual covid tracing app is flawed and creates more burdens than it resolves. The impact has been vast: When people are waiting for the pop-up to disappear, they miss out on their jobs, vacations, and sometimes urgent medical services. Thousands of people have complained on Weibo about the pop-up suddenly stranding them far from home. The pop-up also haunts the lives of the millions of non-Beijing residents who go to the city for work or to visit family and are subject to the same unpredictable restrictions. Instead of precise prevention, the technology is more of a blunt instrument that enables the government to be as strict as possible,just like how China obsessively disinfects every surface. Does it help China reduce the number of covid deaths? Yes. But at what cost? Increasingly, this is how the public in China feels. The measures that were considered essential in reducing covid’s spread in the first two years of the pandemic now feel performative and taxing. Ordinary people, even if they want to abide by the covid control policies, still feel they can’t control their own lives. For Yuan, the only thing she can do is to frequently check the app, sometimes once every hour, before she’s due to board a train or plane. “Compared to all the tragedies caused by the covid prevention policies, this probably doesn’t seem significant. But when it falls on an individual, it still feels devastating,” she says. Have you had a traumatic experience with the pop-up windows, or do you have any thoughts on them as a pandemic tool? Write to me at zeyi@technologyreview.com 1. I wrote last week about how a new fuel can help transition China’s cars away from gas—good!—but may also increase China’s dependence on coal—not so good. (MIT Technology Review) 2. Lots of news in the Chinese vaccine world: 3. From “static management” to “unnecessary food,” here are the nonsensical phrases deployed by the Chinese government to serve its zero-covid policy. (The New York Times $) 4. Richard Liu, founder and ex-CEO of China’s ecommerce giant JD, settled a 2018 sexual assault lawsuit in Minnesota. (The Wall Street Journal $) 5. Say bye to Google Translate in China, one of the last remaining services from the tech giant that was still operating in the country. (CNBC) 6. New research shows how Chinese-government-backed hackers have targeted Tibetan organizations in exile. (Bloomberg $) Home to over 90% of e-cigarette production in the world, China has implemented a much stricter regulation on vaper sales since October 1, reports the Chinese publication Sina Tech. All e-cigarettes need to have childproof locks built in, and companies can’t produce or sell fruit-flavored e-cigarettes, which are controversial for attracting children to vaping. Also, wholesalers and retail owners will have to make all transactions on a state-operated central marketplace, and only after they secure licenses from the state. Amid the rush to comply with the new rules, some retailers are hoarding fruit-flavored e-cigarettes and selling them at a 100% premium. WeChat or baijiu liquor—which one represents China’s economic future? On Friday, Kweichow Moutai, maker of China’s luxury liquor (priced at over $200 per bottle), dethroned Tencent as the most valuable publicly traded Chinese company. The latter has seen its market cap evaporate 64% since January 2021, mostly as a result of China’s moves to regulate Big Tech. It turns out tech companies come and go, but baijiu is forever.","['mit', 'technology', 'review', 'newsletter', 'happen', 'sign', 'receive', 'inbox', 'welcome', 'hope', 'stick', 'highway', 'traffic', 'enjoy', 'national', 'day', 'holiday', 'maybe', '’', 'still', 'well', 'stay', 'home', 'travel', 'feel', 'luxury', 'today', 'rest', 'world', 'drop', 'remain', 'covidrelated', 'travel', 'restriction', 'even', 'short', 'trip', 'plague', 'flight', 'cancellation', 'mandatory', 'quarantine', 'requirement', 'update', 'regular', 'covid', 'test', 'result', 'people', 'live', 'visit', 'capital', 'city', 'additional', 'worry', 'popup', 'window', 'randomly', 'show', 'phone', 'disrupt', 'plan', 'start', 'roll', 'contact', 'trace', 'program', 'assign', 'qr', 'code', 'country', 'show', 'covid', 'status', 'allow', 'enter', 'public', 'venue', 'take', 'public', 'transportation', 'part', 'stringent', 'policy', 'system', 'persist', 'oncelauded', 'feature', 'keep', 'death', 'comparatively', 'low', 'country', 'feel', 'burdensome', 'beneficial', 'citizen', 'covid', 'app', 'country', 'suspend', 'document', 'back', 'popup', 'additional', 'complicated', 'layer', 'add', 'tracing', 'system', 'window', 'mobile', 'covid', 'go', 'away', 'user', 'immediately', 'take', 'pcr', 'test', 'give', 'broad', 'instruction', 'title', 'friendly', 'reminder', '’', 'friendly', 'mask', 'user', 'qr', 'code', 'scan', 'thus', 'deny', 'people', 'access', 'everywhere', 'case', 'take', 'day', 'get', 'pcr', 'test', 'make', 'window', 'go', 'away', 'time', 'people', 'ask', 'quarantine', 'home', 'day', 'friend', 'scatter', 'part', 'year', 'see', 'many', 'complain', 'go', 'take', 'pcr', 'test', 'solve', 'popup', 'window', 'problem', 'testing', 'location', 'turn', 'highrisk', 'zone', 'ask', 'quarantine', 'home', 'day', 'write', 'friend', 'specific', 'differ', 'agree', 'particular', 'menace', 'one', 'know', 'receive', 'popup', 'window', 'get', '’', 'way', 'prepare', 'officially', 'municipal', 'government', 'say', 'several', 'reason', 'people', 'get', 'popup', 'window', 'city', 'recent', 'covid', 'case', 'abroad', 'time', 'space', 'expose', 'covid', 'get', 'pcr', 'test', 'hour', 'buy', 'fever', 'cough', 'medicine', 'problem', 'tout', 'hightech', 'pandemic', 'solution', '’s', 'riskidentifying', 'mechanism', 'tend', 'cast', 'widerthannecessary', 'net', 'explanation', 'popup', 'appear', 'often', 'leave', 'people', 'confuse', 'stick', 'covid', 'limbo', '’s', 'happen', 'resident', 'receive', 'popup', 'window', 'first', 'time', 'early', 'year', 'walk', 'office', 'building', 'immediately', 'block', 'reentere', 'popup', 'window', 'still', 'walk', 'around', 'street', '’d', 'need', 'qr', 'code', 'go', 'place', 'park', 'restaurant', 'shop', 'tell', 'recently', 'receive', 'popup', 'window', 'enter', 'restaurant', 'day', 'chinese', 'new', 'year', 'hospital', 'close', 'take', 'pcr', 'test', 'anywhere', 'hour', 'suppose', 'take', 'train', 'none', 'instance', 'actually', 'engage', 'highrisk', 'activity', 'know', 'exposure', 'well', 'guess', 'system', 'perhaps', 'think', 'elsewhere', 'phone', 'number', 'register', 'unknowingly', 'happen', 'gps', 'location', 'covid', 'patient', 'perhaps', 'subway', 'actually', 'expose', 'sort', 'point', '’', 'little', 'explanation', 'window', 'appear', '’', 'accountability', 'err', 'side', 'caution', 'overreach', 'people', 'life', 'feature', 'popup', 'window', 'bug', 'hype', 'techsavvy', 'chinese', 'government', 'popup', 'window', 'reveal', 'major', 'crack', 'system', 'though', 'often', 'view', 'smart', 'dystopian', 'use', 'surveillance', 'technology', 'actual', 'covid', 'trace', 'app', 'flawed', 'create', 'burden', 'resolve', 'impact', 'vast', 'people', 'wait', 'popup', 'disappear', 'miss', 'job', 'vacation', 'sometimes', 'urgent', 'medical', 'service', 'thousand', 'people', 'complain', 'weibo', 'popup', 'suddenly', 'strand', 'far', 'home', 'popup', 'also', 'haunt', 'life', 'million', 'nonbeije', 'resident', 'go', 'city', 'work', 'visit', 'family', 'subject', 'unpredictable', 'restriction', 'instead', 'precise', 'prevention', 'technology', 'blunt', 'instrument', 'enable', 'government', 'strict', 'possiblejust', 'obsessively', 'disinfect', 'surface', 'help', 'reduce', 'number', 'covid', 'death', 'cost', 'increasingly', 'public', 'feel', 'measure', 'consider', 'essential', 'reduce', '’s', 'spread', 'first', 'year', 'pandemic', 'feel', 'performative', 'tax', 'ordinary', 'people', 'even', 'want', 'abide', 'covid', 'control', 'policy', 'still', 'feel', 'control', 'life', 'yuan', 'thing', 'frequently', 'check', 'app', 'sometimes', 'hour', '’', 'due', 'board', 'train', 'plane', 'compare', 'tragedy', 'cause', 'covid', 'prevention', 'policy', 'probably', 'seem', 'significant', 'fall', 'individual', 'still', 'feel', 'devastating', 'say', 'traumatic', 'experience', 'popup', 'window', 'thought', 'pandemic', 'tool', 'write', 'write', 'last', 'week', 'new', 'fuel', 'help', 'transition', 'car', 'away', 'gas', 'good', 'also', 'increase', 'dependence', 'coal', 'good', 'mit', 'technology', 'review', 'lot', 'news', 'chinese', 'vaccine', 'world', 'static', 'management', 'unnecessary', 'food', 'nonsensical', 'phrase', 'deploy', 'chinese', 'government', 'serve', 'zerocovid', 'policy', 'founder', 'exceo', 'giant', 'settle', 'sexual', 'assault', 'lawsuit', 'say', 'translate', 'last', 'remain', 'service', 'tech', 'giant', 'still', 'operate', 'country', 'new', 'research', 'show', 'chinesegovernmentbacke', 'hacker', 'target', 'tibetan', 'organization', 'exile', 'bloomberg', 'home', 'ecigarette', 'production', 'world', 'implement', 'much', 'strict', 'regulation', 'vaper', 'sale', 'report', 'chinese', 'publication', 'ecigarette', 'need', 'childproof', 'lock', 'build', 'company', 'produce', 'sell', 'fruitflavored', 'ecigarette', 'controversial', 'attract', 'child', 'vape', 'also', 'wholesaler', 'retail', 'owner', 'make', 'transaction', 'stateoperate', 'central', 'marketplace', 'secure', 'license', 'state', 'rush', 'comply', 'new', 'rule', 'retailer', 'hoard', 'fruitflavored', 'ecigarette', 'sell', 'premium', 'wechat', 'baijiu', 'liquor', 'one', 'represent', 'economic', 'future', 'luxury', 'liquor', 'price', 'bottle', 'dethrone', 'tencent', 'valuable', 'publicly', 'trade', 'chinese', 'company', 'latter', 'see', 'market', 'cap', 'evaporate', 'mostly', 'result', 'move', 'regulate', 'big', 'tech', 'turn', 'tech', 'company', 'come', 'go', 'baijiu', 'forever']"
"Everything dies, including information",https://www.technologyreview.com/2022/10/26/1061308/death-of-information-digitization/,2022-10-26,"<p>Digitization can help stem the tide of entropy, but it won’t stop it.</p>
","Everything dies: people, machines, civilizations. Perhaps we can find some solace in knowing that all the meaningful things we’ve learned along the way will survive. But even knowledge has a life span. Documents fade. Art goes missing. Entire libraries and collections can face quick and unexpected destruction.  Surely, we’re at a stage technologically where we might devise ways to make knowledge available and accessible forever. After all, the density of data storage is already incomprehensibly high. In the ever-­growing museum of the internet, one can move smoothly from images from the James Webb Space Telescope through diagrams explaining Pythagoras’s philosophy on the music of the spheres to a YouTube tutorial on blues guitar soloing. What more could you want? Quite a bit, according to the experts. For one thing, what we think is permanent isn’t. Digital storage systems can become unreadable in as little as three to five years. Librarians and archivists race to copy things over to newer formats. But entropy is always there, waiting in the wings. “Our professions and our people often try to extend the normal life span as far as possible through a variety of techniques, but it’s still holding back the tide,” says Joseph Janes, an associate professor at the University of Washington Information School.  To complicate matters, archivists are now grappling with an unprecedented deluge of information. In the past, materials were scarce and storage space limited. “Now we have the opposite problem,” Janes says. “Everything is being recorded all the time.” In principle, that could right a historic wrong. For centuries, countless people didn’t have the right culture, gender, or socioeconomic class for their knowledge or work to be discovered, valued, or preserved. But the massive scale of the digital world now presents a unique challenge. According to an estimate last year from the market research firm IDC, the amount of data that companies, governments, and individuals create in the next few years will be twice the total of all the digital data generated previously since the start of the computing age. Entire schools within some universities are laboring to find better approaches to saving the data under their umbrella. The Data and Service Center for Humanities at the University of Basel, for example, has been developing a software platform called Knora to not just archive the many types of data from humanities work but ensure that people in the future can read and use them. And yet the process is fraught.  “We can’t save everything ... but that’s no reason to not do what we can.” “You make educated guesses and hope for the best, but there are data sets that are lost because nobody knew they’d be useful,” says Andrea Ogier, assistant dean and director of data services at the University Libraries of Virginia Tech.  There are never enough people or money to do all the necessary work—and formats are changing and multiplying all the time. “How do we best allocate resources to preserve things? Because budgets are only so large,” Janes says. “In some cases, that means stuff gets saved or stored but just sits there, uncatalogued and unprocessed, and thus next to impossible to find or access.” In some cases, archivists ultimately turn away new collections. The formats used to store data are themselves impermanent. NASA socked away 170 or so tapes of data on lunar dust, collected during the Apollo era. When researchers set out to use the tapes in the mid-2000s, they couldn’t find anyone with the 1960s-era IBM 729 Mark 5 machine needed to read them. With help, the team ultimately tracked down one in rough shape at the warehouse of the Australian Computer Museum. Volunteers helped refurbish the machine.   Software also has a shelf life. Ogier recalls trying to examine an old Quattro Pro spreadsheet file only to find there was no readily available software that could read it. There have been attempts to future-proof programs. One project that got a lot of fanfare in 2015 is the Open Library of Images for Virtualized Execution (Olive) archive, which runs old software like Chaste 3.1, a 2013 biology and physiology research program, and the 1990 Mac version of the computer game The Oregon Trail on a set of virtual machines. The project is still active, says Mahadev Satyanarayanan, a professor of computer science at Carnegie Mellon University. But there have been challenges in expanding Olive’s offerings, he says: even unused software has to be licensed from the companies that own it, and there is often no easy way to enter new data into the archive’s research applications. Other efforts to help advance the longevity of knowledge have also had mixed results. The Internet Archive, home of the Wayback Machine, has a large collection of digitized materials, including software, music, and videos; as of the summer of 2022 it was fighting a copyright infringement lawsuit brought by multiple publishers. On the more hopeful side, the Text Encoding Initiative has maintained international standards for encoding machine-­readable texts since the 1990s. A decade ago, the US Office of Science and Technology Policy stipulated that applications for federally supported research have to provide a data management plan so the data can be used by researchers or the public in the future. “We’re getting to the point where almost every grant-funded research project has to put its data somewhere,” Ogier says. But there are no overarching requirements about who must store the data or how long it must be saved.  Unavoidably, ideas, knowledge, and human creations will continue to be lost. “We can’t save everything. We can’t provide access to everything. We can’t retrieve everything,” Ogier says. “But that’s no reason to not do what we can.” Erik Sherman is a freelance journalist based in Ashfield, Mass. ","Everything dies: people, machines, civilizations. Perhaps we can find some solace in knowing that all the meaningful things we’ve learned along the way will survive. But even knowledge has a life span. Documents fade. Art goes missing. Entire libraries and collections can face quick and unexpected destruction. Surely, we’re at a stage technologically where we might devise ways to make knowledge available and accessible forever. After all, the density of data storage is already incomprehensibly high. In the ever-­growing museum of the internet, one can move smoothly from images from the James Webb Space Telescope through diagrams explaining Pythagoras’s philosophy on the music of the spheres to a YouTube tutorial on blues guitar soloing. What more could you want? Quite a bit, according to the experts. For one thing, what we think is permanent isn’t. Digital storage systems can become unreadable in as little as three to five years. Librarians and archivists race to copy things over to newer formats. But entropy is always there, waiting in the wings. “Our professions and our people often try to extend the normal life span as far as possible through a variety of techniques, but it’s still holding back the tide,” says Joseph Janes, an associate professor at the University of Washington Information School. To complicate matters, archivists are now grappling with an unprecedented deluge of information. In the past, materials were scarce and storage space limited. “Now we have the opposite problem,” Janes says. “Everything is being recorded all the time.” In principle, that could right a historic wrong. For centuries, countless people didn’t have the right culture, gender, or socioeconomic class for their knowledge or work to be discovered, valued, or preserved. But the massive scale of the digital world now presents a unique challenge. According to an estimate last year from the market research firm IDC, the amount of data that companies, governments, and individuals create in the next few years will be twice the total of all the digital data generated previously since the start of the computing age. Entire schools within some universities are laboring to find better approaches to saving the data under their umbrella. The Data and Service Center for Humanities at the University of Basel, for example, has been developing a software platform called Knora to not just archive the many types of data from humanities work but ensure that people in the future can read and use them. And yet the process is fraught. “We can’t save everything ... but that’s no reason to not do what we can.” “You make educated guesses and hope for the best, but there are data sets that are lost because nobody knew they’d be useful,” says Andrea Ogier, assistant dean and director of data services at the University Libraries of Virginia Tech. There are never enough people or money to do all the necessary work—and formats are changing and multiplying all the time. “How do we best allocate resources to preserve things? Because budgets are only so large,” Janes says. “In some cases, that means stuff gets saved or stored but just sits there, uncatalogued and unprocessed, and thus next to impossible to find or access.” In some cases, archivists ultimately turn away new collections. The formats used to store data are themselves impermanent. NASA socked away 170 or so tapes of data on lunar dust, collected during the Apollo era. When researchers set out to use the tapes in the mid-2000s, they couldn’t find anyone with the 1960s-era IBM 729 Mark 5 machine needed to read them. With help, the team ultimately tracked down one in rough shape at the warehouse of the Australian Computer Museum. Volunteers helped refurbish the machine. Software also has a shelf life. Ogier recalls trying to examine an old Quattro Pro spreadsheet file only to find there was no readily available software that could read it. There have been attempts to future-proof programs. One project that got a lot of fanfare in 2015 is the Open Library of Images for Virtualized Execution (Olive) archive, which runs old software like Chaste 3.1, a 2013 biology and physiology research program, and the 1990 Mac version of the computer game The Oregon Trail on a set of virtual machines. The project is still active, says Mahadev Satyanarayanan, a professor of computer science at Carnegie Mellon University. But there have been challenges in expanding Olive’s offerings, he says: even unused software has to be licensed from the companies that own it, and there is often no easy way to enter new data into the archive’s research applications. Other efforts to help advance the longevity of knowledge have also had mixed results. The Internet Archive, home of the Wayback Machine, has a large collection of digitized materials, including software, music, and videos; as of the summer of 2022 it was fighting a copyright infringement lawsuit brought by multiple publishers. On the more hopeful side, the Text Encoding Initiative has maintained international standards for encoding machine-­readable texts since the 1990s. A decade ago, the US Office of Science and Technology Policy stipulated that applications for federally supported research have to provide a data management plan so the data can be used by researchers or the public in the future. “We’re getting to the point where almost every grant-funded research project has to put its data somewhere,” Ogier says. But there are no overarching requirements about who must store the data or how long it must be saved. Unavoidably, ideas, knowledge, and human creations will continue to be lost. “We can’t save everything. We can’t provide access to everything. We can’t retrieve everything,” Ogier says. “But that’s no reason to not do what we can.” Erik Sherman is a freelance journalist based in Ashfield, Mass.","['die', 'people', 'machine', 'civilization', 'perhaps', 'find', 'solace', 'know', 'meaningful', 'thing', 'learn', 'way', 'survive', 'even', 'knowledge', 'life', 'span', 'document', 'fade', 'art', 'go', 'miss', 'entire', 'library', 'collection', 'face', 'quick', 'unexpected', 'destruction', 'surely', '’re', 'stage', 'technologically', 'devise', 'way', 'make', 'knowledge', 'available', 'accessible', 'forever', 'density', 'datum', 'storage', 'already', 'incomprehensibly', 'high', 'ever\xadgrowing', 'museum', 'internet', 'move', 'smoothly', 'image', 'diagram', 'explain', 'philosophy', 'music', 'sphere', 'youtube', 'tutorial', 'blue', 'guitar', 'solo', 'want', 'bit', 'accord', 'expert', 'thing', 'think', 'permanent', 'digital', 'storage', 'system', 'become', 'unreadable', 'little', 'year', 'librarian', 'archivist', 'race', 'copy', 'thing', 'new', 'format', 'always', 'wait', 'wing', 'profession', 'people', 'often', 'try', 'extend', 'normal', 'life', 'span', 'far', 'possible', 'variety', 'technique', 'still', 'hold', 'tide', 'say', 'jane', 'associate', 'professor', 'information', 'school', 'complicate', 'matter', 'archivist', 'grapple', 'unprecedented', 'deluge', 'information', 'past', 'material', 'scarce', 'storage', 'space', 'limit', 'opposite', 'problem', 'jane', 'say', 'record', 'time', 'principle', 'right', 'historic', 'wrong', 'century', 'countless', 'people', 'right', 'culture', 'gender', 'socioeconomic', 'class', 'knowledge', 'work', 'discover', 'value', 'preserve', 'massive', 'scale', 'digital', 'world', 'present', 'unique', 'challenge', 'accord', 'estimate', 'last', 'year', 'market', 'research', 'firm', 'amount', 'datum', 'company', 'government', 'individual', 'create', 'next', 'year', 'total', 'digital', 'datum', 'generate', 'previously', 'start', 'compute', 'age', 'entire', 'school', 'university', 'labor', 'find', 'well', 'approach', 'save', 'datum', 'umbrella', 'datum', 'service', 'center', 'humanity', 'example', 'develop', 'software', 'platform', 'call', 'knora', 'archive', 'many', 'type', 'datum', 'humanity', 'work', 'ensure', 'people', 'future', 'read', 'use', 'yet', 'process', 'fraught', 'save', '’', 'reason', 'make', 'educated', 'guess', 'hope', 'good', 'datum', 'set', 'lose', 'know', 'useful', 'say', 'director', 'datum', 'service', 'university', 'library', 'never', 'enough', 'people', 'money', 'necessary', 'work', 'format', 'change', 'time', 'well', 'allocate', 'resource', 'preserve', 'thing', 'budget', 'large', 'jane', 'say', 'case', 'mean', 'stuff', 'save', 'store', 'sit', 'uncatalogued', 'unprocessed', 'thus', 'next', 'impossible', 'find', 'access', 'case', 'archivist', 'ultimately', 'turn', 'away', 'new', 'collection', 'format', 'use', 'store', 'datum', 'impermanent', 'sock', 'away', 'tape', 'datum', 'lunar', 'dust', 'collect', 'apollo', 'era', 'researcher', 'set', 'use', 'tape', 'mid2000s', 'find', 'mark', 'machine', 'need', 'read', 'help', 'team', 'ultimately', 'track', 'rough', 'shape', 'warehouse', 'australian', 'computer', 'museum', 'volunteer', 'help', 'refurbish', 'machine', 'software', 'also', 'shelf', 'life', 'ogier', 'recall', 'try', 'examine', 'old', 'pro', 'spreadsheet', 'file', 'find', 'readily', 'available', 'software', 'read', 'attempt', 'futureproof', 'program', 'project', 'get', 'lot', 'fanfare', 'open', 'library', 'image', 'virtualized', 'execution', 'olive', 'archive', 'run', 'old', 'software', 'biology', 'physiology', 'research', 'program', 'version', 'computer', 'game', 'trail', 'set', 'virtual', 'machine', 'project', 'still', 'active', 'say', 'professor', 'computer', 'science', 'mellon', 'challenge', 'expand', 'olive', '’s', 'offering', 'say', 'even', 'unused', 'software', 'license', 'company', 'often', 'easy', 'way', 'enter', 'new', 'datum', 'archive', 'research', 'application', 'effort', 'help', 'advance', 'longevity', 'knowledge', 'also', 'mixed', 'result', 'internet', 'archive', 'home', 'wayback', 'machine', 'large', 'collection', 'digitize', 'material', 'include', 'software', 'music', 'video', 'summer', 'fight', 'copyright', 'infringement', 'lawsuit', 'bring', 'multiple', 'publisher', 'hopeful', 'side', 'text', 'encoding', 'initiative', 'maintain', 'international', 'standard', 'encode', 'machine\xadreadable', 'text', '1990', 'decade', 'ago', 'office', 'science', 'technology', 'policy', 'stipulate', 'application', 'federally', 'support', 'research', 'provide', 'datum', 'management', 'plan', 'datum', 'use', 'researcher', 'public', 'future', 'get', 'point', 'almost', 'grantfunde', 'research', 'project', 'put', 'datum', 'somewhere', 'ogi', 'say', 'overarching', 'requirement', 'store', 'datum', 'long', 'save', 'unavoidably', 'idea', 'knowledge', 'human', 'creation', 'continue', 'lose', 'save', 'provide', 'access', 'retrieve', 'ogi', 'say', '’', 'reason', 'erik', 'freelance', 'journalist', 'base']"
Cyber resilience melds data security and protection,https://www.technologyreview.com/2022/10/12/1059904/cyber-resilience-melds-data-security-and-protection/,2022-10-12,"Ransomware attacks—malware intrusions that block an organization’s access to its own data until a ransom is paid—are taking on alarming new aspects. As people’s work habits, daily routines, geographic locations, and trust in institutions have changed against a backdrop of global political shifts and the covid-19 pandemic, ransomware attacks have taken advantage of the opportunity…","In association withHitachi Ransomware attacks—malware intrusions that block an organization’s access to its own data until a ransom is paid—are taking on alarming new aspects. As people’s work habits, daily routines, geographic locations, and trust in institutions have changed against a backdrop of global political shifts and the covid-19 pandemic, ransomware attacks have taken advantage of the opportunity to grow more sophisticated and pervasive.  Though the basic tools of ransomware remain the same, attackers are using global uncertainty as cover to evolve techniques that make extortion attempts more effective. In a “double extortion” attack, for example, bad actors both block the organization’s access to data and threaten to release or sell that data.  “Triple extortion” or “quadruple extortion” attacks, which additionally incorporate distributed denial of service (DDoS) attacks or threats to third parties, are now also part of the modern risk landscape, according to Alexander Applegate of cybersecurity firm ZeroFox.  Meanwhile, attempted attacks have also grown so prevalent as to be virtually guaranteed. According to a 2022 Sophos survey, 66% of companies experienced a ransomware attack in the last year, nearly double the 2020 figure. A 2022 report by Enterprise Strategy Group (ESG) put the figure at 79% of organizations affected in the last year. ESG practice director and senior analyst Christophe Bertrand inserts this troubling addition: “I question the 21% who say they did not experience an attack, because I think the ransomware virus is probably dormant in their systems.” Ransomware threats have become more damaging in several dimensions: attacks are on the rise, cybercriminals are demanding more ransom, successful intrusions are being leveraged to compromise multiple data streams, and attacks are spreading beyond IT systems into critical infrastructure essential to business functioning. A 2022 Sophos report identified a new trend: a franchise business model (“ransomware-as-a-service”) in which gangs sell ransomware kits to other cybercriminals, who launch the attacks and then return a portion of the proceeds back to the gang. “When ransomware started, it was a small business picking on users who weren’t sophisticated and who would probably pay a couple of hundred dollars to get their data back,” says Hu Yoshida, chief technology officer at Hitachi Vantara. “But now the game has changed dramatically.” The utility industry has become an enticing target, as disrupting power, water, or critical infrastructure can be detrimental to the public. The 2021 ransomware attack against Colonial Pipeline, for example, spurred gas shortages in the northeastern United States. And though Colonial Pipeline paid the $4.4 million ransom, the decryption tool provided by the hackers was so ineffective that the company ended up using its own business continuity systems to slowly get back up and running.  Governments and public services also have become ransomware targets. A U.S. Senate committee report noted more than 2300 known ransomware attacks on local governments, schools, and healthcare providers in the U.S. in 2021. In April and May 2022, a series of ransomware attacks crippled dozens of Costa Rican government agencies, including the Ministry of Finance and the social security system, spurring the president to declare a national emergency. Download the full report. This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. ","In association withHitachi Ransomware attacks—malware intrusions that block an organization’s access to its own data until a ransom is paid—are taking on alarming new aspects. As people’s work habits, daily routines, geographic locations, and trust in institutions have changed against a backdrop of global political shifts and the covid-19 pandemic, ransomware attacks have taken advantage of the opportunity to grow more sophisticated and pervasive. Though the basic tools of ransomware remain the same, attackers are using global uncertainty as cover to evolve techniques that make extortion attempts more effective. In a “double extortion” attack, for example, bad actors both block the organization’s access to data and threaten to release or sell that data. “Triple extortion” or “quadruple extortion” attacks, which additionally incorporate distributed denial of service (DDoS) attacks or threats to third parties, are now also part of the modern risk landscape, according to Alexander Applegate of cybersecurity firm ZeroFox. Meanwhile, attempted attacks have also grown so prevalent as to be virtually guaranteed. According to a 2022 Sophos survey, 66% of companies experienced a ransomware attack in the last year, nearly double the 2020 figure. A 2022 report by Enterprise Strategy Group (ESG) put the figure at 79% of organizations affected in the last year. ESG practice director and senior analyst Christophe Bertrand inserts this troubling addition: “I question the 21% who say they did not experience an attack, because I think the ransomware virus is probably dormant in their systems.” Ransomware threats have become more damaging in several dimensions: attacks are on the rise, cybercriminals are demanding more ransom, successful intrusions are being leveraged to compromise multiple data streams, and attacks are spreading beyond IT systems into critical infrastructure essential to business functioning. A 2022 Sophos report identified a new trend: a franchise business model (“ransomware-as-a-service”) in which gangs sell ransomware kits to other cybercriminals, who launch the attacks and then return a portion of the proceeds back to the gang. “When ransomware started, it was a small business picking on users who weren’t sophisticated and who would probably pay a couple of hundred dollars to get their data back,” says Hu Yoshida, chief technology officer at Hitachi Vantara. “But now the game has changed dramatically.” The utility industry has become an enticing target, as disrupting power, water, or critical infrastructure can be detrimental to the public. The 2021 ransomware attack against Colonial Pipeline, for example, spurred gas shortages in the northeastern United States. And though Colonial Pipeline paid the $4.4 million ransom, the decryption tool provided by the hackers was so ineffective that the company ended up using its own business continuity systems to slowly get back up and running. Governments and public services also have become ransomware targets. A U.S. Senate committee report noted more than 2300 known ransomware attacks on local governments, schools, and healthcare providers in the U.S. in 2021. In April and May 2022, a series of ransomware attacks crippled dozens of Costa Rican government agencies, including the Ministry of Finance and the social security system, spurring the president to declare a national emergency. Download the full report. This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.","['association', 'withhitachi', 'attack', 'malware', 'intrusion', 'block', 'organization', 'access', 'datum', 'ransom', 'pay', 'take', 'alarm', 'new', 'aspect', 'people', 'work', 'habit', 'daily', 'geographic', 'location', 'trust', 'institution', 'change', 'backdrop', 'global', 'political', 'shift', 'covid19', 'pandemic', 'ransomware', 'attack', 'take', 'advantage', 'opportunity', 'grow', 'sophisticated', 'pervasive', 'basic', 'tool', 'remain', 'attacker', 'use', 'global', 'uncertainty', 'cover', 'evolve', 'technique', 'make', 'extortion', 'attempt', 'effective', 'double', 'extortion', 'attack', 'example', 'bad', 'actor', 'block', 'organization', 'access', 'datum', 'threaten', 'release', 'sell', 'datum', 'triple', 'extortion', 'quadruple', 'extortion', 'attack', 'additionally', 'incorporate', 'distribute', 'denial', 'service', 'ddo', 'attack', 'threat', 'third', 'party', 'also', 'part', 'modern', 'risk', 'landscape', 'accord', 'applegate', 'cybersecurity', 'firm', 'meanwhile', 'attempt', 'attack', 'also', 'grow', 'prevalent', 'virtually', 'guarantee', 'accord', 'sophos', 'survey', 'company', 'experience', 'ransomware', 'attack', 'last', 'year', 'nearly', 'figure', 'report', 'enterprise', 'strategy', 'group', 'esg', 'put', 'figure', 'organization', 'affect', 'last', 'year', 'esg', 'practice', 'director', 'senior', 'analyst', 'christophe', 'bertrand', 'insert', 'troubling', 'addition', 'question', 'say', 'experience', 'attack', 'think', 'ransomware', 'virus', 'probably', 'dormant', 'system', 'ransomware', 'threat', 'become', 'damaging', 'several', 'dimension', 'attack', 'rise', 'cybercriminal', 'demand', 'ransom', 'successful', 'intrusion', 'leveraged', 'compromise', 'multiple', 'datum', 'stream', 'attack', 'spread', 'system', 'critical', 'infrastructure', 'essential', 'business', 'function', 'sophos', 'report', 'identify', 'new', 'trend', 'franchise', 'business', 'model', 'ransomwareasaservice', 'gang', 'sell', 'ransomware', 'kit', 'cybercriminal', 'launch', 'attack', 'return', 'portion', 'proceed', 'back', 'gang', 'start', 'small', 'business', 'pick', 'user', 'sophisticated', 'probably', 'pay', 'couple', 'dollar', 'get', 'datum', 'back', 'say', 'chief', 'technology', 'officer', 'game', 'change', 'dramatically', 'utility', 'industry', 'become', 'enticing', 'target', 'disrupt', 'power', 'water', 'critical', 'infrastructure', 'detrimental', 'public', 'ransomware', 'attack', 'colonial', 'pipeline', 'example', 'spur', 'gas', 'shortage', 'northeastern', 'colonial', 'pipeline', 'pay', 'ransom', 'decryption', 'tool', 'provide', 'hacker', 'ineffective', 'company', 'end', 'use', 'business', 'continuity', 'system', 'slowly', 'get', 'back', 'run', 'government', 'public', 'service', 'also', 'become', 'ransomware', 'target', 'note', 'know', 'ransomware', 'attack', 'local', 'government', 'school', 'healthcare', 'provider', 'series', 'ransomware', 'attack', 'cripple', 'dozen', 'costa', 'rican', 'government', 'agency', 'include', 'finance', 'social', 'security', 'system', 'spur', 'president', 'declare', 'national', 'emergency', 'download', 'full', 'report', 'content', 'produce', 'insight', 'custom', 'content', 'arm', 'mit', 'technology', 'review', 'write', 'mit', 'technology', 'review', 'editorial', 'staff']"
Moving money in a digital world,https://www.technologyreview.com/2022/10/06/1060665/moving-money-in-a-digital-world/,2022-10-06,"The rising adoption of digital financial services—mobile banking, online purchasing, and peer-to-peer payments—means that these days, money most often passes not through human hands but from computer to computer. No cash, no plastic cards, no paper bills or checks or envelopes or stamps. Digital is no longer just another way to move money. Every organization…","In association withVisa The rising adoption of digital financial services—mobile banking, online purchasing, and peer-to-peer payments—means that these days, money most often passes not through human hands but from computer to computer. No cash, no plastic cards, no paper bills or checks or envelopes or stamps. Digital is no longer just another way to move money. Every organization that moves money must meet users via computers, smartphones, and other devices, and offer rapid, secure payment services. The covid-19 pandemic gave a boost to digital money movement, from online purchases to contactless payments and smartphone wallets, as consumers worldwide sought to shop without touching anything or going anywhere.  “The common denominator across almost all post-pandemic behavioral shifts is the growing importance of digital payments,” says Paul Fabara, executive vice president and chief risk officer at Visa, whose worldwide networks handled an estimated $13 trillion worth of transactions last year. “Covid forced a market that was already growing to greatly accelerate,” says Fabara. As of 2021, 76% of adults globally have an account with a financial institution or mobile money provider, up from 68% in 2017 and 51% in 2011, according to the World Bank’s Global Findex Database. That number includes 71% of adults in developing countries. In high-income economies, nearly 95% of adults either made or received digital payments in 2021. In India, 80 million adults made their first digital payment during the pandemic; in China, 100 million. Fraudsters famously go where the money is, and their online activities are expanding right along with the growth in digital transactions. Annual losses from cybercrime in the U.S. nearly doubled between 2019 and 2021, from $3.5 billion to $6.9 billion, according to the FBI’s Internet Crime Report for 2021. Fortifying cyberspace against theft and fraud has always been urgent, and the post-pandemic boom in transactions intensified matters. Business-to-business customers are beginning to insist on the same seamless real-time transactions they expect as consumers, says Aaron Press, research director of worldwide payment strategies at IDC, who tracks the development and adoption of real-time payments. “If you think about the way you shop online for personal things or pay your friends using a mobile-to-mobile app, those expectations are finding their way into the business environment,” he says. End-to-end digital transactions are here to stay. An MIT Technology Review Insights survey of global business leaders found high interest in digital payment technologies across all types and sizes of businesses. Although 36% of respondents are just getting started with digital payments, 43% expect to expand their offerings over the next 18 months, and many are venturing into cross-border transactions (37%) and cryptocurrency (18%). What’s driving businesses to all-digital payments? The largest share of survey replies, 70%, indicate businesses prioritize improving customer experience by offering multiple payment options and saving customers time. Respondents want the benefits of operational improvements (48%) and reductions in processing costs (37%). Many want expanded options for securing payments (36%) and personalized offers to customers (35%). ""Digital payments are more efficient and dramatically reduce errors,” says Press. “You’re much less likely to fill out something the wrong way, because there are checks and balances within the system.” Download the full report. This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. ","In association withVisa The rising adoption of digital financial services—mobile banking, online purchasing, and peer-to-peer payments—means that these days, money most often passes not through human hands but from computer to computer. No cash, no plastic cards, no paper bills or checks or envelopes or stamps. Digital is no longer just another way to move money. Every organization that moves money must meet users via computers, smartphones, and other devices, and offer rapid, secure payment services. The covid-19 pandemic gave a boost to digital money movement, from online purchases to contactless payments and smartphone wallets, as consumers worldwide sought to shop without touching anything or going anywhere. “The common denominator across almost all post-pandemic behavioral shifts is the growing importance of digital payments,” says Paul Fabara, executive vice president and chief risk officer at Visa, whose worldwide networks handled an estimated $13 trillion worth of transactions last year. “Covid forced a market that was already growing to greatly accelerate,” says Fabara. As of 2021, 76% of adults globally have an account with a financial institution or mobile money provider, up from 68% in 2017 and 51% in 2011, according to the World Bank’s Global Findex Database. That number includes 71% of adults in developing countries. In high-income economies, nearly 95% of adults either made or received digital payments in 2021. In India, 80 million adults made their first digital payment during the pandemic; in China, 100 million. Fraudsters famously go where the money is, and their online activities are expanding right along with the growth in digital transactions. Annual losses from cybercrime in the U.S. nearly doubled between 2019 and 2021, from $3.5 billion to $6.9 billion, according to the FBI’s Internet Crime Report for 2021. Fortifying cyberspace against theft and fraud has always been urgent, and the post-pandemic boom in transactions intensified matters. Business-to-business customers are beginning to insist on the same seamless real-time transactions they expect as consumers, says Aaron Press, research director of worldwide payment strategies at IDC, who tracks the development and adoption of real-time payments. “If you think about the way you shop online for personal things or pay your friends using a mobile-to-mobile app, those expectations are finding their way into the business environment,” he says. End-to-end digital transactions are here to stay. An MIT Technology Review Insights survey of global business leaders found high interest in digital payment technologies across all types and sizes of businesses. Although 36% of respondents are just getting started with digital payments, 43% expect to expand their offerings over the next 18 months, and many are venturing into cross-border transactions (37%) and cryptocurrency (18%). What’s driving businesses to all-digital payments? The largest share of survey replies, 70%, indicate businesses prioritize improving customer experience by offering multiple payment options and saving customers time. Respondents want the benefits of operational improvements (48%) and reductions in processing costs (37%). Many want expanded options for securing payments (36%) and personalized offers to customers (35%). ""Digital payments are more efficient and dramatically reduce errors,” says Press. “You’re much less likely to fill out something the wrong way, because there are checks and balances within the system.” Download the full report. This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.","['association', 'withvisa', 'rise', 'adoption', 'digital', 'financial', 'service', 'mobile', 'banking', 'online', 'purchasing', 'peertopeer', 'payment', 'mean', 'day', 'money', 'often', 'pass', 'human', 'hand', 'computer', 'computer', 'cash', 'plastic', 'card', 'paper', 'bill', 'check', 'envelope', 'stamp', 'long', 'way', 'move', 'money', 'organization', 'move', 'money', 'meet', 'user', 'computer', 'smartphone', 'device', 'offer', 'rapid', 'secure', 'payment', 'service', 'covid19', 'pandemic', 'give', 'boost', 'digital', 'money', 'movement', 'online', 'purchase', 'contactless', 'payment', 'smartphone', 'wallet', 'consumer', 'worldwide', 'seek', 'shop', 'touch', 'go', 'anywhere', 'common', 'denominator', 'almost', 'postpandemic', 'behavioral', 'shift', 'grow', 'importance', 'digital', 'payment', 'say', 'vice', 'president', 'chief', 'risk', 'officer', 'visa', 'worldwide', 'network', 'handle', 'estimate', 'worth', 'transaction', 'last', 'year', 'force', 'market', 'already', 'grow', 'greatly', 'accelerate', 'say', 'fabara', 'adult', 'globally', 'account', 'financial', 'institution', 'mobile', 'money', 'provider', 'accord', 'global', 'findex', 'database', 'number', 'include', 'adult', 'develop', 'country', 'highincome', 'economy', 'nearly', 'adult', 'make', 'receive', 'digital', 'payment', 'adult', 'make', 'first', 'digital', 'payment', 'pandemic', 'fraudster', 'famously', 'go', 'money', 'online', 'activity', 'expand', 'right', 'growth', 'digital', 'transaction', 'annual', 'loss', 'cybercrime', 'nearly', 'double', 'accord', 'internet', 'crime', 'report', 'fortifying', 'cyberspace', 'theft', 'fraud', 'always', 'urgent', 'postpandemic', 'boom', 'transaction', 'intensify', 'matter', 'businesstobusiness', 'customer', 'begin', 'insist', 'seamless', 'realtime', 'transaction', 'expect', 'consumer', 'say', 'research', 'director', 'worldwide', 'payment', 'strategy', 'idc', 'track', 'development', 'adoption', 'realtime', 'payment', 'think', 'way', 'shop', 'online', 'personal', 'thing', 'pay', 'friend', 'use', 'mobiletomobile', 'app', 'expectation', 'find', 'way', 'business', 'environment', 'say', 'endtoend', 'digital', 'transaction', 'stay', 'mit', 'technology', 'review', 'insight', 'survey', 'global', 'business', 'leader', 'find', 'high', 'interest', 'digital', 'payment', 'technology', 'type', 'size', 'business', 'respondent', 'start', 'digital', 'payment', 'expect', 'expand', 'offering', 'next', 'month', 'many', 'venture', 'crossborder', 'transaction', 'cryptocurrency', 'drive', 'business', 'alldigital', 'payment', 'large', 'share', 'survey', 'reply', 'indicate', 'business', 'improve', 'customer', 'experience', 'offer', 'multiple', 'payment', 'option', 'save', 'customer', 'time', 'respondent', 'want', 'benefit', 'operational', 'improvement', 'reduction', 'processing', 'cost', 'many', 'want', 'expand', 'option', 'secure', 'payment', 'personalize', 'offer', 'customer', 'digital', 'payment', 'efficient', 'dramatically', 'reduce', 'error', 'say', 'press', '’re', 'much', 'less', 'likely', 'fill', 'wrong', 'way', 'check', 'balance', 'system', 'download', 'full', 'report', 'content', 'produce', 'insight', 'custom', 'content', 'arm', 'mit', 'technology', 'review', 'write', 'mit', 'technology', 'review', 'editorial', 'staff']"
