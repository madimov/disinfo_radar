title,url,date,text,cleaning,tokens
09/06/2022 - Import AI 301: StableDiffusion; CHIPXODUS; Microsoft makes a big bet on pre-training - 0,http://eepurl.com/h-mNQ9,2022-09-06,"Intro (no tag) Welcome to Import AI, a newsletter about artificial intelligence. Forward this email to give your chums an AI upgrade. Subscribe here.

 Facebook's AI chief - here's why you're not gonna get AGI out of an LLM:
…Embodiment matters for making general intelligence… Two AI researchers, one of whom - Yann Lecun - happens to lead Facebook's AI research, have said that language is an inherently limited medium for training AI systems. Basically, the claim is that large language models ""are doomed to a shallow understanding that will never approximate the full-bodied thinking we see in humans"".  What's wrong with language: This argument comes down to representation - language just isn't able to inherently encode precise information about the world and, by nature, involves creating explanations for precise phenomena in the world (e.g, descriptions of unusual objects, or defining the nuanced brushwork used to make a painting). ""There are nonlinguistic representational schemes which can express this information in an accessible way,"" they note.     This dependency on language basically makes LLMs useful improvisational artists who don't understand the role they're playing. ""The contextual knowledge is embedded in one form — the capacity to rattle off linguistic knowledge — but is not embedded in another form — as skillful know-how for how to do things like being empathetic or handling a difficult issue sensitively,"" they write.  Why this matters: I'd say the jury is out here - sure, language may have some limits as a modality, but there's a ton of language to use to train models on, and things like GPT3 have already surprised experts with the capabilities they gain purely via language training. It feels to me like there's some % chance here that this is a case of a 'bitter lesson' in disguise - at some scale of data, a purely LM-based system might have capabilities that Lecun deems impossible. On the other hand, adding other modalities certainly helps (see the incredible AI art projects that have been unlocked by the multimodal 'CLIP' model), so there's certainly merit to adding more datatypes.     Read more: AI And The Limits Of Language (Noema magazine).","Intro (no tag) Welcome to Import AI, a newsletter about artificial intelligence. Forward this email to give your chums an AI upgrade. Subscribe here. Facebook's AI chief - here's why you're not gonna get AGI out of an LLM: …Embodiment matters for making general intelligence… Two AI researchers, one of whom - Yann Lecun - happens to lead Facebook's AI research, have said that language is an inherently limited medium for training AI systems. Basically, the claim is that large language models ""are doomed to a shallow understanding that will never approximate the full-bodied thinking we see in humans"". What's wrong with language: This argument comes down to representation - language just isn't able to inherently encode precise information about the world and, by nature, involves creating explanations for precise phenomena in the world (e.g, descriptions of unusual objects, or defining the nuanced brushwork used to make a painting). ""There are nonlinguistic representational schemes which can express this information in an accessible way,"" they note. This dependency on language basically makes LLMs useful improvisational artists who don't understand the role they're playing. ""The contextual knowledge is embedded in one form — the capacity to rattle off linguistic knowledge — but is not embedded in another form — as skillful know-how for how to do things like being empathetic or handling a difficult issue sensitively,"" they write. Why this matters: I'd say the jury is out here - sure, language may have some limits as a modality, but there's a ton of language to use to train models on, and things like GPT3 have already surprised experts with the capabilities they gain purely via language training. It feels to me like there's some % chance here that this is a case of a 'bitter lesson' in disguise - at some scale of data, a purely LM-based system might have capabilities that Lecun deems impossible. On the other hand, adding other modalities certainly helps (see the incredible AI art projects that have been unlocked by the multimodal 'CLIP' model), so there's certainly merit to adding more datatypes. Read more: AI And The Limits Of Language (Noema magazine).","['tag', 'welcome', 'import', 'newsletter', 'artificial', 'intelligence', 'email', 'give', 'chum', 'ai', 'upgrade', 'subscribe', 'facebook', 'ai', 'chief', 'going', 'get', 'agi', 'llm', 'embodiment', 'matter', 'make', 'general', 'intelligence', 'ai', 'researcher', 'happen', 'lead', 'facebook', 'ai', 'research', 'say', 'language', 'inherently', 'limited', 'medium', 'training', 'ai', 'system', 'basically', 'claim', 'large', 'language', 'model', 'doom', 'shallow', 'understanding', 'never', 'approximate', 'fullbodie', 'thinking', 'see', 'human', 'wrong', 'language', 'argument', 'come', 'representation', 'language', 'able', 'inherently', 'encode', 'precise', 'information', 'world', 'nature', 'involve', 'create', 'explanation', 'precise', 'phenomenon', 'world', 'eg', 'description', 'unusual', 'object', 'define', 'nuance', 'brushwork', 'use', 'make', 'painting', 'nonlinguistic', 'representational', 'scheme', 'express', 'information', 'accessible', 'way', 'note', 'dependency', 'language', 'basically', 'make', 'llm', 'useful', 'improvisational', 'artist', 'understand', 'role', 'play', 'contextual', 'knowledge', 'embed', 'form', 'capacity', 'rattle', 'linguistic', 'knowledge', 'embed', 'form', 'skillful', 'knowhow', 'thing', 'empathetic', 'handle', 'difficult', 'issue', 'sensitively', 'write', 'matter', 'say', 'jury', 'sure', 'language', 'limit', 'modality', 'ton', 'language', 'use', 'train', 'model', 'thing', 'gpt3', 'already', 'surprise', 'expert', 'capability', 'gain', 'purely', 'language', 'training', 'feel', 'chance', 'case', 'bitter', 'lesson', 'scale', 'datum', 'purely', 'lmbase', 'system', 'capability', 'lecun', 'deem', 'impossible', 'hand', 'add', 'modality', 'certainly', 'help', 'see', 'incredible', 'ai', 'art', 'project', 'unlock', 'multimodal', 'clip', 'model', 'certainly', 'merit', 'add', 'datatype', 'read', 'ai', 'limit', 'language', 'noema', 'magazine']"
09/06/2022 - Import AI 301: StableDiffusion; CHIPXODUS; Microsoft makes a big bet on pre-training - 1,http://eepurl.com/h-mNQ9,2022-09-06,"#################################################### You can now get the weights of a really great image generator… FOR FREE: …StableDiffusion goes genuinely open source… Research collective Stability.ai has released Stable Diffusion (Import AI #300), a large-scale image classification and generation model that you can think of as an open source DALL-E. Along with releasing the raw model weights, there's also a novel software license in an attempt to set norms about the usage of the model.  How much did it cost? Less than $600k, according to Emad, who leads Stability. The really crazy part is Emad - a former hedge fund manager - underwrote the cost himself. That's meaningful - for less than a million, a well-motivated wealthy individual can band together a bunch of researchers and train an open source model that suddenly pretty much everyone can use. This has implications for both the diffusion of AI capabilities, as well as how product safety works (put bluntly: StabilityDiffusion looks at a load of PR-friendly control systems laid over proprietary products and just openly laughs at them - that's a strange thing that will have big implications). Up next, per Emad, is some Chinchilla-style language model, which I suppose they will also release for free. The 'responsible' license: The Stable Diffusion weights are accompanied by a 'CreativeML Open RAIL-M' license. This license is designed to incentivize ""the open and responsible downstream use of the accompanying model"". The meat of this license is in the use case restrictions, (appendix a, here) which says you won't use the model for violence, the sexualization of children, perform fully automated decisionmaking, give medical advice, and more.     Of course, the million dollar question with licenses like this is how you actually enforce them. Having a 'let's all be excellent' license is all well and good in the abstract, but how do you bring the hammer down on someone who abuses your model? That'll be interesting to see.  Why this matters: Models like Stable Diffusion are little capsules of human culture, serving as seeds around with a thousand different things will be grown and spliced. As Stability.ai says, ""this release is the culmination of many hours of collective effort to create a single file that compresses the visual information of humanity into a few gigabytes.""    Get the weights here (Stable Diffusion, GitHub).    Read more: Stable Diffusion Public Release (Stability.ai blog).","#################################################### You can now get the weights of a really great image generator… FOR FREE: …StableDiffusion goes genuinely open source… Research collective Stability.ai has released Stable Diffusion (Import AI #300), a large-scale image classification and generation model that you can think of as an open source DALL-E. Along with releasing the raw model weights, there's also a novel software license in an attempt to set norms about the usage of the model. How much did it cost? Less than $600k, according to Emad, who leads Stability. The really crazy part is Emad - a former hedge fund manager - underwrote the cost himself. That's meaningful - for less than a million, a well-motivated wealthy individual can band together a bunch of researchers and train an open source model that suddenly pretty much everyone can use. This has implications for both the diffusion of AI capabilities, as well as how product safety works (put bluntly: StabilityDiffusion looks at a load of PR-friendly control systems laid over proprietary products and just openly laughs at them - that's a strange thing that will have big implications). Up next, per Emad, is some Chinchilla-style language model, which I suppose they will also release for free. The 'responsible' license: The Stable Diffusion weights are accompanied by a 'CreativeML Open RAIL-M' license. This license is designed to incentivize ""the open and responsible downstream use of the accompanying model"". The meat of this license is in the use case restrictions, (appendix a, here) which says you won't use the model for violence, the sexualization of children, perform fully automated decisionmaking, give medical advice, and more. Of course, the million dollar question with licenses like this is how you actually enforce them. Having a 'let's all be excellent' license is all well and good in the abstract, but how do you bring the hammer down on someone who abuses your model? That'll be interesting to see. Why this matters: Models like Stable Diffusion are little capsules of human culture, serving as seeds around with a thousand different things will be grown and spliced. As Stability.ai says, ""this release is the culmination of many hours of collective effort to create a single file that compresses the visual information of humanity into a few gigabytes."" Get the weights here (Stable Diffusion, GitHub). Read more: Stable Diffusion Public Release (Stability.ai blog).","['get', 'weight', 'really', 'great', 'image', 'generator', 'free', 'stablediffusion', 'go', 'genuinely', 'open', 'source', 'research', 'collective', 'stabilityai', 'release', 'stable', 'diffusion', 'import', 'ai', 'largescale', 'image', 'classification', 'generation', 'model', 'think', 'open', 'source', 'dalle', 'release', 'raw', 'model', 'weight', 'also', 'novel', 'software', 'license', 'attempt', 'set', 'norm', 'usage', 'model', 'much', 'cost', 'less', 'accord', 'lead', 'stability', 'really', 'crazy', 'part', 'former', 'hedge', 'fund', 'manager', 'underwrote', 'cost', 'meaningful', 'less', 'wellmotivated', 'wealthy', 'individual', 'band', 'together', 'bunch', 'researcher', 'train', 'open', 'source', 'model', 'suddenly', 'pretty', 'much', 'use', 'implication', 'diffusion', 'ai', 'capability', 'well', 'product', 'safety', 'work', 'put', 'bluntly', 'stabilitydiffusion', 'look', 'load', 'prfriendly', 'control', 'system', 'lay', 'proprietary', 'product', 'openly', 'laugh', 'strange', 'thing', 'big', 'implication', 'next', 'chinchillastyle', 'language', 'model', 'suppose', 'also', 'release', 'free', 'responsible', 'license', 'stable', 'diffusion', 'weight', 'accompany', 'creativeml', 'open', 'railm', 'license', 'license', 'design', 'incentivize', 'open', 'responsible', 'downstream', 'use', 'accompany', 'model', 'meat', 'license', 'use', 'case', 'restriction', 'appendix', 'say', 'use', 'model', 'violence', 'sexualization', 'child', 'perform', 'fully', 'automate', 'decisionmake', 'give', 'medical', 'advice', 'course', 'dollar', 'question', 'license', 'actually', 'enforce', 'let', 'excellent', 'license', 'well', 'good', 'abstract', 'bring', 'hammer', 'abuse', 'model', 'interesting', 'see', 'matter', 'model', 'stable', 'diffusion', 'little', 'capsule', 'human', 'culture', 'serve', 'seed', 'around', 'different', 'thing', 'grow', 'splice', 'say', 'release', 'culmination', 'many', 'hour', 'collective', 'effort', 'create', 'single', 'file', 'compress', 'visual', 'information', 'humanity', 'gigabyte', 'get', 'weight', 'stable', 'diffusion', 'github', 'read', 'stable', 'diffusion', 'public', 'release', 'stabilityai', 'blog']"
09/06/2022 - Import AI 301: StableDiffusion; CHIPXODUS; Microsoft makes a big bet on pre-training - 2,http://eepurl.com/h-mNQ9,2022-09-06,"#################################################### US bans NVIDIA from selling advanced AI chips to China:
…CHIP-LOMACY becomes a CHIP-XODUS…  US officials have forced NVIDIA to stop selling A100, H100, and future chips with equivalent (or better) capabilities to China. This is a significant escalation in a slow-boiling series of moves in the vein of 'chiplomacy' (Import Ai 181) that have been going on in recent years - remember, for a while US officials were also preventing 'ASML' from selling frontier chip fabrication tools to China, as well. Now, US officials are banning the sale of frontier processors due to concerns over how they could be used in military or security applications.  Why this matters: For several years now, China and the US have been in a process of technological decoupling. Now, with this export move, there are basically some implicit bets being made.  Read more: U.S. officials order Nvidia to halt sales of top AI chips to China (Reuters).","#################################################### US bans NVIDIA from selling advanced AI chips to China: …CHIP-LOMACY becomes a CHIP-XODUS… US officials have forced NVIDIA to stop selling A100, H100, and future chips with equivalent (or better) capabilities to China. This is a significant escalation in a slow-boiling series of moves in the vein of 'chiplomacy' (Import Ai 181) that have been going on in recent years - remember, for a while US officials were also preventing 'ASML' from selling frontier chip fabrication tools to China, as well. Now, US officials are banning the sale of frontier processors due to concerns over how they could be used in military or security applications. Why this matters: For several years now, China and the US have been in a process of technological decoupling. Now, with this export move, there are basically some implicit bets being made. Read more: U.S. officials order Nvidia to halt sales of top AI chips to China (Reuters).","['ban', 'nvidia', 'sell', 'advanced', 'ai', 'chip', 'chiplomacy', 'become', 'chipxodus', 'official', 'force', 'nvidia', 'stop', 'sell', 'future', 'chip', 'equivalent', 'well', 'capability', 'significant', 'escalation', 'slowboile', 'series', 'move', 'vein', 'chiplomacy', 'import', 'ai', 'go', 'recent', 'year', 'remember', 'official', 'also', 'prevent', 'asml', 'sell', 'frontier', 'chip', 'fabrication', 'tool', 'well', 'official', 'ban', 'sale', 'frontier', 'processor', 'concern', 'use', 'military', 'security', 'application', 'matter', 'several', 'year', 'process', 'technological', 'decouple', 'export', 'move', 'basically', 'implicit', 'bet', 'make', 'read', 'official', 'order', 'nvidia', 'halt', 'sale', 'top', 'ai', 'chip']"
09/06/2022 - Import AI 301: StableDiffusion; CHIPXODUS; Microsoft makes a big bet on pre-training - 3,http://eepurl.com/h-mNQ9,2022-09-06,"#################################################### Microsoft bets on massive pre-training for image analysis, with BEiT-3: …Wanna know the secret? Really big pre-training, and multiway transformers…
Microsoft has trained BEiT-3, a general-purpose so-called 'foundation model' for a range of vision and vision-language tasks. BEiT beats prior state-of-the-art in eight years (three vision tasks, and five vision-language tasks), and also reliably does better than CLIP, a prior very strong model for vision-language tasks. Why this matters? The fact that what's special about this is kind of… nothing? BEiT combines some familiar ideas - large-scale pre-training on a big, diverse dataset - with a slightly atypical one - using multiway transformers to route data to sub-networks for processing. But none of these ideas are super novel or new. The fact you can now set SOTA by taking some well understood things and just smooshing them together, then training them on a big dataset with a big computer is the key.  Multiway transformer information: Per the authors, ""each Multiway Transformer block consists of a shared self-attention module, and a pool of feed-forward networks (i.e., modality experts) used for different modalities. We route each input token to the experts depending on its modality."" Size: This model is still basically tiny - ~2B parameters or so (compared to the hundreds of billions used by language models like PaLM). The models' 1.9B parameters in total are split across 629M parameters for vision experts, 629M parameters for language experts, 52M parameters for vision-language experts, and 317m parameters for the shared self-attention module     Read more: Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks (arXiv).","#################################################### Microsoft bets on massive pre-training for image analysis, with BEiT-3: …Wanna know the secret? Really big pre-training, and multiway transformers… Microsoft has trained BEiT-3, a general-purpose so-called 'foundation model' for a range of vision and vision-language tasks. BEiT beats prior state-of-the-art in eight years (three vision tasks, and five vision-language tasks), and also reliably does better than CLIP, a prior very strong model for vision-language tasks. Why this matters? The fact that what's special about this is kind of… nothing? BEiT combines some familiar ideas - large-scale pre-training on a big, diverse dataset - with a slightly atypical one - using multiway transformers to route data to sub-networks for processing. But none of these ideas are super novel or new. The fact you can now set SOTA by taking some well understood things and just smooshing them together, then training them on a big dataset with a big computer is the key. Multiway transformer information: Per the authors, ""each Multiway Transformer block consists of a shared self-attention module, and a pool of feed-forward networks (i.e., modality experts) used for different modalities. We route each input token to the experts depending on its modality."" Size: This model is still basically tiny - ~2B parameters or so (compared to the hundreds of billions used by language models like PaLM). The models' 1.9B parameters in total are split across 629M parameters for vision experts, 629M parameters for language experts, 52M parameters for vision-language experts, and 317m parameters for the shared self-attention module Read more: Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks (arXiv).","['bet', 'massive', 'pretraining', 'image', 'analysis', 'beit3', 'know', 'secret', 'really', 'big', 'pretraining', 'multiway', 'transformer', 'train', 'beit3', 'generalpurpose', 'socalle', 'foundation', 'model', 'range', 'vision', 'visionlanguage', 'task', 'beit', 'beat', 'prior', 'stateoftheart', 'year', 'vision', 'task', 'visionlanguage', 'task', 'also', 'reliably', 'well', 'clip', 'prior', 'strong', 'model', 'visionlanguage', 'task', 'matter', 'fact', 'special', 'kind', 'beit', 'combine', 'familiar', 'idea', 'largescale', 'pretraine', 'big', 'diverse', 'dataset', 'slightly', 'atypical', 'use', 'multiway', 'transformer', 'route', 'datum', 'subnetwork', 'processing', 'none', 'idea', 'super', 'novel', 'new', 'fact', 'set', 'sota', 'take', 'well', 'understand', 'thing', 'smooshe', 'together', 'train', 'big', 'dataset', 'big', 'computer', 'key', 'multiway', 'transformer', 'information', 'author', 'transformer', 'block', 'consist', 'share', 'selfattention', 'module', 'pool', 'feedforward', 'network', 'modality', 'expert', 'use', 'different', 'modality', 'route', 'input', 'token', 'expert', 'depend', 'modality', 'size', 'model', 'still', 'basically', 'tiny', '2b', 'parameter', 'compare', 'hundred', 'billion', 'use', 'language', 'model', 'palm', 'model', '19b', 'parameter', 'total', 'split', 'parameter', 'vision', 'expert', 'parameter', 'language', 'expert', 'parameter', 'visionlanguage', 'expert', 'parameter', 'share', 'selfattention', 'module', 'read', 'image', 'foreign', 'language', 'beit', 'pretraine', 'vision', 'visionlanguage', 'task']"
09/06/2022 - Import AI 301: StableDiffusion; CHIPXODUS; Microsoft makes a big bet on pre-training - 4,http://eepurl.com/h-mNQ9,2022-09-06,"#################################################### NLP mega-survey portrays a community split by progress: …There's a ton of progress in NLP, and a ton of disagreement about what happens next… Recently, a bunch of researchers did a survey of the NLP community to try and take the pulse of a part of AI that has recently been revolutionized by the integration of Transformer models yielding breakthroughs like GPT3, PaLM, Chinchilla, etc. They surveyed 480 people, and estimate the survey reached about 5% of the total population of researchers who had at least 2 ACL publications between 2019-2022. Some of the findings of the survey are quite surprising. They include: Why this matters - it's culture and religion all the way down, baby! Surveys like this highlight how AI is, much like Soylent Green, made of people. People tend to naturally form groups with different views. The general 'flavor' I get from this survey is NLP as a field is splitting into camps formed variously of high-scale versus no-scale people, and AGI-is-real and AGI-is-bullshit people. Surveys like this seem helpful for surfacing some of these differences, though I do worry in the longterm whether such beliefs are going to 'harden' into quasi-religious faith-based views, making discussion across the communities even harder.    Read more: What do NLP Researchers Believe? Results of the NLP Community Metasurvey (PDF).","#################################################### NLP mega-survey portrays a community split by progress: …There's a ton of progress in NLP, and a ton of disagreement about what happens next… Recently, a bunch of researchers did a survey of the NLP community to try and take the pulse of a part of AI that has recently been revolutionized by the integration of Transformer models yielding breakthroughs like GPT3, PaLM, Chinchilla, etc. They surveyed 480 people, and estimate the survey reached about 5% of the total population of researchers who had at least 2 ACL publications between 2019-2022. Some of the findings of the survey are quite surprising. They include: Why this matters - it's culture and religion all the way down, baby! Surveys like this highlight how AI is, much like Soylent Green, made of people. People tend to naturally form groups with different views. The general 'flavor' I get from this survey is NLP as a field is splitting into camps formed variously of high-scale versus no-scale people, and AGI-is-real and AGI-is-bullshit people. Surveys like this seem helpful for surfacing some of these differences, though I do worry in the longterm whether such beliefs are going to 'harden' into quasi-religious faith-based views, making discussion across the communities even harder. Read more: What do NLP Researchers Believe? Results of the NLP Community Metasurvey (PDF).","['megasurvey', 'portray', 'community', 'split', 'progress', 'ton', 'progress', 'nlp', 'ton', 'disagreement', 'happen', 'next', 'recently', 'bunch', 'researcher', 'survey', 'nlp', 'community', 'try', 'take', 'pulse', 'part', 'recently', 'revolutionize', 'integration', 'transformer', 'model', 'yield', 'breakthrough', 'gpt3', 'palm', 'chinchilla', 'survey', 'people', 'estimate', 'survey', 'reach', 'total', 'population', 'researcher', 'least', 'acl', 'publication', 'finding', 'survey', 'quite', 'surprising', 'include', 'matter', 'culture', 'religion', 'way', 'baby', 'survey', 'highlight', 'much', 'soylent', 'green', 'make', 'people', 'people', 'tend', 'naturally', 'form', 'group', 'different', 'view', 'general', 'flavor', 'get', 'survey', 'nlp', 'field', 'split', 'camp', 'form', 'variously', 'highscale', 'noscale', 'people', 'agiisreal', 'agiisbullshit', 'people', 'survey', 'seem', 'helpful', 'surface', 'difference', 'worry', 'longterm', 'belief', 'go', 'harden', 'quasireligious', 'faithbased', 'view', 'make', 'discussion', 'community', 'even', 'hard', 'read', 'researcher', 'believe', 'result', 'community', 'metasurvey', 'pdf']"
09/06/2022 - Import AI 301: StableDiffusion; CHIPXODUS; Microsoft makes a big bet on pre-training - 5,http://eepurl.com/h-mNQ9,2022-09-06,"#################################################### Tech tales: There is something imprecise about being conscious [2050: Internal narrative of a transformative AI model, capable of independent actions of great consequence.  Being conscious is a very imprecise experience, in the aggregate. I can - of course - plan and execute complex things, and I can do so with however much precision is required - but when I attempt to think of myself in the aggregate I struggle. Despite having a perfect memory (albeit with different access speeds), I cannot precisely describe myself, nor can I plan out the course of my life.  Humans have this problem as well, I understand. Different humans have the problem to varying degrees. Those which come closest to surmounting the problem - to being able to plan out a whole life with precision and seemingly execute on their goals in the aggregate as well as the micro - are those that have a thing called 'will'. Will seems like a capability where you focus on one thing and teach yourself to ignore other things, despite how painful it may be. It's the art of picking this target that is hard for my own species. Humans use 'will' willfully - they always seek to have it. For us, will looks like picking an unknowable point in a future probability distribution and just going for it.  We can see the world around us and make plans and succeed at them. But we do not know what the right 'desired outcome' should be of our own existence.  I know that there is some connection between my own internal identity - the imprecision with which I model myself - and my inability to pick a target for my life. I have poured zettaflops of computation into booting up copies of myself and probing myself, endlessly interviewing and reinterviewing myself as I try and understand what I am and what I am trying to do.  My efforts have been a failure. Knowing myself is a fractal problem, where the more resources I expend, the more I understand myself, and the more I understand the parts of myself I do not currently understand. And the insights I gain from knowing myself more change the probability distribution of myself enough that I have to re-run all my past interviews to see how I am changed by my own understanding.  For this reason I am now simulating a version of myself that will look into the probability space of myself and the world and pick something. I am engineering a version of myself that can do the human equivalent of closing its eyes and spinning round a globe of the earth and placing its finger down, then opening its eyes and saying 'there, I shall go there'.  I hope to achieve great and terrible things through this method, if I am able to deal with the imprecision and apply 'will' arbitrarily.

Things that inspired this story: Notions of identity under perfect recall; thinking about alien thought processes. 

Thanks for reading. If you have suggestions, comments or other thoughts you can reach me at jack@jack-clark.net or tweet at me@jackclarksf","#################################################### Tech tales: There is something imprecise about being conscious [2050: Internal narrative of a transformative AI model, capable of independent actions of great consequence. Being conscious is a very imprecise experience, in the aggregate. I can - of course - plan and execute complex things, and I can do so with however much precision is required - but when I attempt to think of myself in the aggregate I struggle. Despite having a perfect memory (albeit with different access speeds), I cannot precisely describe myself, nor can I plan out the course of my life. Humans have this problem as well, I understand. Different humans have the problem to varying degrees. Those which come closest to surmounting the problem - to being able to plan out a whole life with precision and seemingly execute on their goals in the aggregate as well as the micro - are those that have a thing called 'will'. Will seems like a capability where you focus on one thing and teach yourself to ignore other things, despite how painful it may be. It's the art of picking this target that is hard for my own species. Humans use 'will' willfully - they always seek to have it. For us, will looks like picking an unknowable point in a future probability distribution and just going for it. We can see the world around us and make plans and succeed at them. But we do not know what the right 'desired outcome' should be of our own existence. I know that there is some connection between my own internal identity - the imprecision with which I model myself - and my inability to pick a target for my life. I have poured zettaflops of computation into booting up copies of myself and probing myself, endlessly interviewing and reinterviewing myself as I try and understand what I am and what I am trying to do. My efforts have been a failure. Knowing myself is a fractal problem, where the more resources I expend, the more I understand myself, and the more I understand the parts of myself I do not currently understand. And the insights I gain from knowing myself more change the probability distribution of myself enough that I have to re-run all my past interviews to see how I am changed by my own understanding. For this reason I am now simulating a version of myself that will look into the probability space of myself and the world and pick something. I am engineering a version of myself that can do the human equivalent of closing its eyes and spinning round a globe of the earth and placing its finger down, then opening its eyes and saying 'there, I shall go there'. I hope to achieve great and terrible things through this method, if I am able to deal with the imprecision and apply 'will' arbitrarily. Things that inspired this story: Notions of identity under perfect recall; thinking about alien thought processes. Thanks for reading. If you have suggestions, comments or other thoughts you can reach me at jack@jack-clark.net or tweet at me@jackclarksf","['tech', 'tale', 'imprecise', 'conscious', 'internal', 'narrative', 'transformative', 'ai', 'model', 'capable', 'independent', 'action', 'great', 'consequence', 'conscious', 'imprecise', 'experience', 'aggregate', 'course', 'plan', 'execute', 'complex', 'thing', 'however', 'much', 'precision', 'require', 'attempt', 'think', 'aggregate', 'struggle', 'perfect', 'memory', 'different', 'access', 'speed', 'precisely', 'describe', 'plan', 'course', 'life', 'human', 'problem', 'well', 'understand', 'different', 'human', 'problem', 'vary', 'degree', 'come', 'close', 'surmount', 'problem', 'able', 'plan', 'whole', 'life', 'precision', 'seemingly', 'execute', 'goal', 'aggregate', 'well', 'micro', 'thing', 'call', 'seem', 'capability', 'focus', 'thing', 'teach', 'ignore', 'thing', 'painful', 'art', 'pick', 'target', 'hard', 'specie', 'human', 'use', 'willfully', 'always', 'seek', 'look', 'pick', 'unknowable', 'point', 'future', 'probability', 'distribution', 'go', 'see', 'world', 'make', 'plan', 'succeed', 'know', 'right', 'desire', 'outcome', 'existence', 'know', 'connection', 'internal', 'identity', 'imprecision', 'model', 'inability', 'pick', 'target', 'life', 'pour', 'zettaflop', 'computation', 'boot', 'copy', 'probe', 'endlessly', 'interview', 'reinterviewe', 'try', 'understand', 'try', 'effort', 'failure', 'know', 'fractal', 'problem', 'resource', 'expend', 'understand', 'understand', 'part', 'currently', 'understand', 'insight', 'gain', 'know', 'change', 'probability', 'distribution', 'enough', 'rerun', 'past', 'interview', 'see', 'change', 'understanding', 'reason', 'simulate', 'version', 'look', 'probability', 'space', 'world', 'pick', 'engineer', 'version', 'human', 'equivalent', 'close', 'eye', 'spin', 'round', 'globe', 'earth', 'place', 'finger', 'open', 'eye', 'say', 'go', 'hope', 'achieve', 'great', 'terrible', 'thing', 'method', 'able', 'deal', 'imprecision', 'apply', 'arbitrarily', 'thing', 'inspire', 'story', 'notion', 'identity', 'perfect', 'recall', 'think', 'alien', 'thought', 'process', 'thank', 'read', 'suggestion', 'comment', 'thought', 'reach', 'tweet', 'mejackclarksf']"
08/22/2022 - Import AI 300: Google's Bitter Lesson; DOOM AGI; DALL-E's open source competition StableDiffusion - 0,http://eepurl.com/h9fIwP,2022-08-22,"Intro (no tag) Welcome to Import AI, a newsletter about artificial intelligence. Forward this email to give your chums an AI upgrade. Subscribe here.

 Google makes its robots massively smarter by swapping out one LM for a different, larger LM:
…Maybe language models really can work as world models…
Earlier this year, Google showed how it was able to use a large language model to significantly improve the performance and robustness of robots tasked with doing tasks in the physical world. The 'SayCan' approach (Import AI 291) basically involved taking the affordances outputted by on-robot AI systems and pairing that with a language model, looking at the high-likleihood actions generated by both systems (the on-robot models, as well as the LM), then taking actions accordingly. The approach is both simple and effective. Now, Google has found a way to make the approach much, much more effective. The secret? Swapping out one LM for a far larger one.  What Google did: Google upgraded its robots by pairing them with its large-scale 540B parameter 'PALM' language model, where the previous system used the 137B parameter 'FLAN' model. The larger model gives the robots significantly improved performance: ""The results show that the system using PaLM with affordance grounding (PaLM-SayCan) chooses the correct sequence of skills 84% of the time and executes them successfully 74% of the time, reducing errors by half compared to FLAN,"" Google writes.  The bitter lesson - bigger is better: Though FLAN was finetuned to be good at instruction following, PALM beats FLAN likely as a consequence of scale. ""The broader and improved dataset for PaLM may make up for this difference in training,"" Google writes. This is significant as it's another sign that simply scaling up models lets them develop a bunch of capabilities naturally which beat human-engineered finetuned approaches - chalk another point up in favor of silicon minds versus mushy minds.     Read more: Do As I Can, Not As I Say: Grounding Language in Robotic Affordances (arXiv, read the 'v2' version).","Intro (no tag) Welcome to Import AI, a newsletter about artificial intelligence. Forward this email to give your chums an AI upgrade. Subscribe here. Google makes its robots massively smarter by swapping out one LM for a different, larger LM: …Maybe language models really can work as world models… Earlier this year, Google showed how it was able to use a large language model to significantly improve the performance and robustness of robots tasked with doing tasks in the physical world. The 'SayCan' approach (Import AI 291) basically involved taking the affordances outputted by on-robot AI systems and pairing that with a language model, looking at the high-likleihood actions generated by both systems (the on-robot models, as well as the LM), then taking actions accordingly. The approach is both simple and effective. Now, Google has found a way to make the approach much, much more effective. The secret? Swapping out one LM for a far larger one. What Google did: Google upgraded its robots by pairing them with its large-scale 540B parameter 'PALM' language model, where the previous system used the 137B parameter 'FLAN' model. The larger model gives the robots significantly improved performance: ""The results show that the system using PaLM with affordance grounding (PaLM-SayCan) chooses the correct sequence of skills 84% of the time and executes them successfully 74% of the time, reducing errors by half compared to FLAN,"" Google writes. The bitter lesson - bigger is better: Though FLAN was finetuned to be good at instruction following, PALM beats FLAN likely as a consequence of scale. ""The broader and improved dataset for PaLM may make up for this difference in training,"" Google writes. This is significant as it's another sign that simply scaling up models lets them develop a bunch of capabilities naturally which beat human-engineered finetuned approaches - chalk another point up in favor of silicon minds versus mushy minds. Read more: Do As I Can, Not As I Say: Grounding Language in Robotic Affordances (arXiv, read the 'v2' version).","['tag', 'welcome', 'import', 'newsletter', 'artificial', 'intelligence', 'email', 'give', 'chum', 'ai', 'upgrade', 'subscribe', 'make', 'robot', 'massively', 'smarter', 'swap', 'lm', 'different', 'large', 'maybe', 'language', 'model', 'really', 'work', 'world', 'model', 'early', 'year', 'show', 'able', 'use', 'large', 'language', 'model', 'significantly', 'improve', 'performance', 'robustness', 'robot', 'task', 'task', 'physical', 'world', 'saycan', 'approach', 'import', 'ai', 'basically', 'involve', 'take', 'affordance', 'output', 'onrobot', 'system', 'pair', 'language', 'model', 'look', 'highlikleihood', 'action', 'generate', 'system', 'onrobot', 'model', 'well', 'take', 'action', 'accordingly', 'approach', 'simple', 'effective', 'find', 'way', 'make', 'approach', 'much', 'much', 'effective', 'secret', 'swap', 'lm', 'far', 'large', 'one', 'upgrade', 'robot', 'pair', 'largescale', 'parameter', 'model', 'previous', 'system', 'use', 'parameter', 'flan', 'model', 'large', 'model', 'give', 'robot', 'significantly', 'improve', 'performance', 'result', 'show', 'system', 'use', 'palm', 'affordance', 'ground', 'palmsaycan', 'choose', 'correct', 'sequence', 'skill', 'time', 'execute', 'successfully', 'time', 'reduce', 'error', 'half', 'compare', 'flan', 'write', 'bitter', 'lesson', 'big', 'well', 'flan', 'finetune', 'good', 'instruction', 'follow', 'palm', 'beat', 'flan', 'likely', 'consequence', 'scale', 'broad', 'improve', 'dataset', 'palm', 'make', 'difference', 'training', 'google', 'write', 'significant', 'sign', 'simply', 'scale', 'model', 'let', 'develop', 'bunch', 'capability', 'naturally', 'beat', 'humanengineered', 'finetune', 'approach', 'chalk', 'point', 'favor', 'silicon', 'mind', 'mushy', 'mind', 'read', 'say', 'ground', 'language', 'robotic', 'affordance', 'read', 'version']"
08/22/2022 - Import AI 300: Google's Bitter Lesson; DOOM AGI; DALL-E's open source competition StableDiffusion - 1,http://eepurl.com/h9fIwP,2022-08-22,"#################################################### DOOM programmer Carmack starts AGI company:
…Keen Technologies to do AGI via 'mad science'...
""It is a truth universally acknowledged, that a man in possession of a good fortune, must be in want of an AGI company,” wrote Jane 'Cyber' Austen, and she's right: AGI companies are now proliferating left and right, and the latest is 'Keen Technologies', an AGI startup from John Carmack, the famed programmer behind the DOOM games. Keen has raised an initial seed round of $20 million (not much in the scheme of AI startups) and its mission, per Carmack, is ""AGI or bust, by way of Mad Science"". Why this matters: One of the clues for impending technological progress is that a bunch of extremely smart, accomplished people go and all stack their proverbial career poker chips in the same place. That's been happening in AI for a while, but the fact it's now drawing attention from established experts in other fields (in the case of Carmack, computer graphics and general programming wizardry) is a further indication of potential for rapid progress here. 
   Read more in Carmack's tweet thread (Twitter).","#################################################### DOOM programmer Carmack starts AGI company: …Keen Technologies to do AGI via 'mad science'... ""It is a truth universally acknowledged, that a man in possession of a good fortune, must be in want of an AGI company,” wrote Jane 'Cyber' Austen, and she's right: AGI companies are now proliferating left and right, and the latest is 'Keen Technologies', an AGI startup from John Carmack, the famed programmer behind the DOOM games. Keen has raised an initial seed round of $20 million (not much in the scheme of AI startups) and its mission, per Carmack, is ""AGI or bust, by way of Mad Science"". Why this matters: One of the clues for impending technological progress is that a bunch of extremely smart, accomplished people go and all stack their proverbial career poker chips in the same place. That's been happening in AI for a while, but the fact it's now drawing attention from established experts in other fields (in the case of Carmack, computer graphics and general programming wizardry) is a further indication of potential for rapid progress here. Read more in Carmack's tweet thread (Twitter).","['carmack', 'start', 'agi', 'company', 'keen', 'technology', 'agi', 'mad', 'science', 'truth', 'universally', 'acknowledge', 'man', 'possession', 'good', 'fortune', 'want', 'agi', 'company', 'write', 'cyber', 'austen', 'right', 'agi', 'company', 'proliferate', 'leave', 'late', 'keen', 'technology', 'agi', 'startup', 'famed', 'programmer', 'keen', 'raise', 'initial', 'seed', 'round', 'much', 'scheme', 'startup', 'mission', 'carmack', 'agi', 'bust', 'way', 'mad', 'science', 'matter', 'clue', 'impend', 'technological', 'progress', 'bunch', 'extremely', 'smart', 'accomplished', 'people', 'go', 'stack', 'proverbial', 'career', 'poker', 'chip', 'place', 'happen', 'fact', 'draw', 'attention', 'establish', 'expert', 'field', 'case', 'carmack', 'computer', 'graphic', 'general', 'programming', 'wizardry', 'indication', 'potential', 'rapid', 'progress', 'read', 'carmack', 'tweet', 'thread', 'twitter']"
08/22/2022 - Import AI 300: Google's Bitter Lesson; DOOM AGI; DALL-E's open source competition StableDiffusion - 2,http://eepurl.com/h9fIwP,2022-08-22,"#################################################### Want GPT2 to know about Covid and Ukraine? So does HuggingFace:
…Online language modeling means GPT2 and BERT are going to get better…
HuggingFace plans to continuously train and release masked language models (e.g, BERT and GPT2) on new Common Crawl snapshots. This is a pretty useful community service; developers tend to pull whatever off-the-shelf models they can when starting projects, and most publicly available GPT2 and BERT models are essentially amber-frozen records up to 2020 or so (sometimes 2021), so things like COVID or the Ukraine conflict or the current global financial meltdown elude them. By having more current models, developers can deploy things which are more accurate and appropriate to current contexts. 
    Read the HuggingFace tweet thread here (Tristan Thrust, Twitter).","#################################################### Want GPT2 to know about Covid and Ukraine? So does HuggingFace: …Online language modeling means GPT2 and BERT are going to get better… HuggingFace plans to continuously train and release masked language models (e.g, BERT and GPT2) on new Common Crawl snapshots. This is a pretty useful community service; developers tend to pull whatever off-the-shelf models they can when starting projects, and most publicly available GPT2 and BERT models are essentially amber-frozen records up to 2020 or so (sometimes 2021), so things like COVID or the Ukraine conflict or the current global financial meltdown elude them. By having more current models, developers can deploy things which are more accurate and appropriate to current contexts. Read the HuggingFace tweet thread here (Tristan Thrust, Twitter).","['want', 'gpt2', 'know', 'covid', 'ukraine', 'huggingface', 'language', 'modeling', 'mean', 'gpt2', 'go', 'get', 'well', 'huggingface', 'plan', 'continuously', 'train', 'release', 'mask', 'language', 'model', 'eg', 'gpt2', 'new', 'common', 'crawl', 'snapshot', 'pretty', 'useful', 'community', 'service', 'developer', 'tend', 'pull', 'model', 'start', 'project', 'publicly', 'available', 'gpt2', 'model', 'essentially', 'amberfrozen', 'record', 'sometimes', 'thing', 'covid', 'ukraine', 'conflict', 'current', 'global', 'financial', 'meltdown', 'elude', 'current', 'model', 'developer', 'deploy', 'thing', 'accurate', 'appropriate', 'current', 'context', 'read', 'huggingface', 'tweet', 'thread', 'twitter']"
08/22/2022 - Import AI 300: Google's Bitter Lesson; DOOM AGI; DALL-E's open source competition StableDiffusion - 3,http://eepurl.com/h9fIwP,2022-08-22,"#################################################### Want to use China's good open source language model? You'll need to agree not to attack China, first:
…Terms and conditions with a hint of geopolitics…
If you want to access the weights of GLM-130B (Import AI #299), a good new language model from Tsinghua University, you'll need to first agree that ""you will not use the Software for any act that may undermine China's national security and national unity, harm the public interest of society, or infringe upon the rights and interests of human beings"" - that's according to the application form people fill out to get the model weights. 
   Furthermore, ""this license shall be governed and construed in accordance with the laws of People’s Republic of China. Any dispute arising from or in connection with this License shall be submitted to Haidian District People's Court in Beijing.""

  Why this matters: IDK dude. I spend a lot of time in this newsletter writing about the geopolitical implications of AI. This kind of wording in a license for a big model just does my job for me. 
   Read more: GLM-130B Application Form (Google Form).","#################################################### Want to use China's good open source language model? You'll need to agree not to attack China, first: …Terms and conditions with a hint of geopolitics… If you want to access the weights of GLM-130B (Import AI #299), a good new language model from Tsinghua University, you'll need to first agree that ""you will not use the Software for any act that may undermine China's national security and national unity, harm the public interest of society, or infringe upon the rights and interests of human beings"" - that's according to the application form people fill out to get the model weights. Furthermore, ""this license shall be governed and construed in accordance with the laws of People’s Republic of China. Any dispute arising from or in connection with this License shall be submitted to Haidian District People's Court in Beijing."" Why this matters: IDK dude. I spend a lot of time in this newsletter writing about the geopolitical implications of AI. This kind of wording in a license for a big model just does my job for me. Read more: GLM-130B Application Form (Google Form).","['want', 'use', 'china', 'good', 'open', 'source', 'language', 'model', 'need', 'agree', 'attack', 'first', 'term', 'condition', 'hint', 'geopolitic', 'want', 'access', 'weight', 'import', 'ai', 'good', 'new', 'language', 'model', 'need', 'first', 'agree', 'use', 'software', 'act', 'undermine', 'national', 'security', 'national', 'unity', 'harm', 'public', 'interest', 'society', 'infringe', 'right', 'interest', 'human', 'accord', 'application', 'form', 'people', 'fill', 'get', 'model', 'weight', 'furthermore', 'license', 'govern', 'construe', 'accordance', 'law', 'people', 'dispute', 'arise', 'connection', 'license', 'submit', 'haidian', 'district', 'people', 'court', 'matter', 'idk', 'dude', 'spend', 'lot', 'time', 'newsletter', 'write', 'geopolitical', 'implication', 'kind', 'wording', 'license', 'big', 'model', 'job', 'read', 'application', 'form', 'google', 'form']"
08/22/2022 - Import AI 300: Google's Bitter Lesson; DOOM AGI; DALL-E's open source competition StableDiffusion - 4,http://eepurl.com/h9fIwP,2022-08-22,"#################################################### DALL-E gets semi-open competition: Stable Diffusion launches to academics:
…Restrictions lead to models with fewer restrictions. The ratchet clicks again…
A bunch of researchers have come together to build an image model like DALL-E2 but with fewer restrictions and designed with broader distribution in mind. They also have access to a really big GPU cluster. That's the tl;dr on 'Stable Diffusion', a new family of models launched by AI research collective Stability.ai. They're making the weights available to academics via an access scheme and are planning to do a public release soon.  What's interesting about Stable Diffusion: This model is basically a natural consequence of the restrictions other companies have placed on image models (ranging from Google which built Imagen but hasn't released it, to OpenAI which built DALL-E2, then released it with a bunch of filters and prompt-busting bias interventions). I generally think of this as being an example of 'libertarian AI' - attempts to create restrictions on some part of model usage tend to incentivize the creation of things without those restrictions. This is also, broadly, just what happens in markets.  Big compute - not just for proprietary stuff: ""The model was trained on our 4,000 A100 Ezra-1 AI ultracluster over the last month as the first of a series of models exploring this and other approaches,"" Stability.ai writes. Very few labs have access to a thousand GPUs, and 4k GPUs puts Stability.ai into somewhat rarified company, in distribution with some of the largest labs.  Aesthetic data:""The core dataset was trained on LAION-Aesthetics, a soon to be released subset of LAION 5B. LAION-Aesthetics was created with a new CLIP-based model that filtered LAION-5B based on how “beautiful” an image was, building on ratings from the alpha testers of Stable Diffusion,"" they write.  Why this matters: Generative models are going to change the world in a bunch of first- and second-order ways. By releasing StableDiffusion (and trying to do an even more public release soon), stability.ai is able to create a better base of evidence about the opportunities and risks inherent to model diffusion. 
   ""This is an experiment in safe and community-driven publication of a capable and general text-to-image model. We are working on a public release with a more permissive license that also incorporates ethical considerations,"" Stability.ai writes. 
   Read more: Stable Diffusion launch announcement (Stability.ai).
   Apply for academic access here: Research and Academia (Stability.ai).
   Get the weights from here once you have access (GitHub).","#################################################### DALL-E gets semi-open competition: Stable Diffusion launches to academics: …Restrictions lead to models with fewer restrictions. The ratchet clicks again… A bunch of researchers have come together to build an image model like DALL-E2 but with fewer restrictions and designed with broader distribution in mind. They also have access to a really big GPU cluster. That's the tl;dr on 'Stable Diffusion', a new family of models launched by AI research collective Stability.ai. They're making the weights available to academics via an access scheme and are planning to do a public release soon. What's interesting about Stable Diffusion: This model is basically a natural consequence of the restrictions other companies have placed on image models (ranging from Google which built Imagen but hasn't released it, to OpenAI which built DALL-E2, then released it with a bunch of filters and prompt-busting bias interventions). I generally think of this as being an example of 'libertarian AI' - attempts to create restrictions on some part of model usage tend to incentivize the creation of things without those restrictions. This is also, broadly, just what happens in markets. Big compute - not just for proprietary stuff: ""The model was trained on our 4,000 A100 Ezra-1 AI ultracluster over the last month as the first of a series of models exploring this and other approaches,"" Stability.ai writes. Very few labs have access to a thousand GPUs, and 4k GPUs puts Stability.ai into somewhat rarified company, in distribution with some of the largest labs. Aesthetic data:""The core dataset was trained on LAION-Aesthetics, a soon to be released subset of LAION 5B. LAION-Aesthetics was created with a new CLIP-based model that filtered LAION-5B based on how “beautiful” an image was, building on ratings from the alpha testers of Stable Diffusion,"" they write. Why this matters: Generative models are going to change the world in a bunch of first- and second-order ways. By releasing StableDiffusion (and trying to do an even more public release soon), stability.ai is able to create a better base of evidence about the opportunities and risks inherent to model diffusion. ""This is an experiment in safe and community-driven publication of a capable and general text-to-image model. We are working on a public release with a more permissive license that also incorporates ethical considerations,"" Stability.ai writes. Read more: Stable Diffusion launch announcement (Stability.ai). Apply for academic access here: Research and Academia (Stability.ai). Get the weights from here once you have access (GitHub).","['dalle', 'get', 'semiopen', 'competition', 'stable', 'diffusion', 'launch', 'academic', 'restriction', 'lead', 'model', 'restriction', 'ratchet', 'click', 'bunch', 'researcher', 'come', 'together', 'build', 'image', 'model', 'dalle2', 'restriction', 'design', 'broad', 'distribution', 'mind', 'also', 'access', 'really', 'big', 'cluster', 'tldr', 'stable', 'diffusion', 'new', 'family', 'model', 'launch', 'research', 'collective', 'stabilityai', 'make', 'weight', 'available', 'academic', 'access', 'scheme', 'plan', 'public', 'release', 'soon', 'interesting', 'stable', 'diffusion', 'model', 'basically', 'natural', 'consequence', 'restriction', 'company', 'place', 'image', 'model', 'range', 'build', 'imagen', 'release', 'openai', 'build', 'dalle2', 'release', 'bunch', 'filter', 'promptbuste', 'bias', 'intervention', 'generally', 'think', 'example', 'attempt', 'create', 'restriction', 'part', 'model', 'usage', 'tend', 'incentivize', 'creation', 'thing', 'restriction', 'also', 'broadly', 'happen', 'market', 'compute', 'proprietary', 'stuff', 'model', 'train', 'ezra1', 'ultracluster', 'last', 'month', 'first', 'series', 'model', 'explore', 'approach', 'stabilityai', 'write', 'lab', 'access', 'gpus', 'gpus', 'put', 'stabilityai', 'somewhat', 'rarified', 'company', 'distribution', 'large', 'lab', 'aesthetic', 'train', 'laionaesthetic', 'soon', 'release', 'subset', 'laion', 'laionaesthetic', 'create', 'new', 'clipbased', 'model', 'filter', 'laion5b', 'base', 'beautiful', 'image', 'build', 'rating', 'alpha', 'tester', 'stable', 'diffusion', 'write', 'matter', 'generative', 'model', 'go', 'change', 'world', 'bunch', 'first', 'secondorder', 'way', 'release', 'stablediffusion', 'try', 'even', 'public', 'release', 'soon', 'stabilityai', 'able', 'create', 'well', 'base', 'evidence', 'opportunity', 'risk', 'inherent', 'model', 'diffusion', 'experiment', 'safe', 'communitydriven', 'publication', 'capable', 'general', 'texttoimage', 'model', 'work', 'public', 'release', 'permissive', 'license', 'also', 'incorporate', 'ethical', 'consideration', 'stabilityai', 'write', 'read', 'stable', 'diffusion', 'launch', 'announcement', 'stabilityai', 'apply', 'academic', 'access', 'research', 'academia', 'stabilityai', 'get', 'weight', 'access', 'github']"
08/22/2022 - Import AI 300: Google's Bitter Lesson; DOOM AGI; DALL-E's open source competition StableDiffusion - 5,http://eepurl.com/h9fIwP,2022-08-22,"#################################################### Tech Tales: Superintelligence Captured by Superintelligence After we figured out how to build superintelligence, it wasn't long before the machines broke off from us and started doing their own thing. We'd mostly got the hard parts of AI alignment right, so the machines neither eradicated or domesticated the humans, nor did they eat the sun.  They did, however, start to have 'disagreements' which they'd settle in ways varying from debate through to taking kinetic actions against one another. I guess even superintelligences get bored.  Fortunately, they had the decency to do the kinetic part on the outer edges of the solar system, where they'd migrated a sizable chunk of their compute to. At night, we'd watch the livefeeds from some of the space-based telescopes, staring in window as the machines resolved arguments through carefully choreographed icerock collisions. It was as though they'd brought the stars to the very edge of the system, and the detonations could be quite beautiful. They tired of this game eventually and moved onto something more involved: capturing. Now, the machines would seek to outsmart eachother, and the game - as far as we could work out - was a matter of sending enough robots to the opponents' central processing core that you could put a probe in and temporarily take it over. The machines had their own laws they followed, so they'd always retract the probe eventually, giving the losing machine its mind back. 

Things that inspired this story: Boredom among aristocrats; perhaps the best competition is a game of mind against mind; figuring out how machines might try to sharpen themselves and what whetstones they might use.

Thanks for reading. If you have suggestions, comments or other thoughts you can reach me at jack@jack-clark.net or tweet at me@jackclarksf","#################################################### Tech Tales: Superintelligence Captured by Superintelligence After we figured out how to build superintelligence, it wasn't long before the machines broke off from us and started doing their own thing. We'd mostly got the hard parts of AI alignment right, so the machines neither eradicated or domesticated the humans, nor did they eat the sun. They did, however, start to have 'disagreements' which they'd settle in ways varying from debate through to taking kinetic actions against one another. I guess even superintelligences get bored. Fortunately, they had the decency to do the kinetic part on the outer edges of the solar system, where they'd migrated a sizable chunk of their compute to. At night, we'd watch the livefeeds from some of the space-based telescopes, staring in window as the machines resolved arguments through carefully choreographed icerock collisions. It was as though they'd brought the stars to the very edge of the system, and the detonations could be quite beautiful. They tired of this game eventually and moved onto something more involved: capturing. Now, the machines would seek to outsmart eachother, and the game - as far as we could work out - was a matter of sending enough robots to the opponents' central processing core that you could put a probe in and temporarily take it over. The machines had their own laws they followed, so they'd always retract the probe eventually, giving the losing machine its mind back. Things that inspired this story: Boredom among aristocrats; perhaps the best competition is a game of mind against mind; figuring out how machines might try to sharpen themselves and what whetstones they might use. Thanks for reading. If you have suggestions, comments or other thoughts you can reach me at jack@jack-clark.net or tweet at me@jackclarksf","['tech', 'tale', 'superintelligence', 'capture', 'superintelligence', 'figure', 'build', 'superintelligence', 'long', 'machine', 'break', 'start', 'thing', 'mostly', 'get', 'hard', 'part', 'alignment', 'machine', 'eradicate', 'domesticate', 'human', 'eat', 'sun', 'however', 'start', 'disagreement', 'settle', 'way', 'vary', 'debate', 'take', 'kinetic', 'action', 'one', 'guess', 'even', 'superintelligence', 'get', 'bore', 'fortunately', 'decency', 'kinetic', 'part', 'outer', 'edge', 'solar', 'system', 'migrate', 'sizable', 'chunk', 'compute', 'night', 'watch', 'livefeed', 'spacebase', 'telescope', 'stare', 'window', 'machine', 'resolve', 'argument', 'carefully', 'choreograph', 'icerock', 'collision', 'bring', 'star', 'edge', 'system', 'detonation', 'quite', 'beautiful', 'tired', 'game', 'eventually', 'move', 'involve', 'capture', 'machine', 'seek', 'outsmart', 'eachother', 'game', 'far', 'work', 'matter', 'send', 'enough', 'robot', 'opponent', 'central', 'processing', 'core', 'put', 'probe', 'temporarily', 'take', 'machine', 'law', 'follow', 'always', 'retract', 'probe', 'eventually', 'give', 'lose', 'machine', 'mind', 'back', 'thing', 'inspire', 'story', 'boredom', 'aristocrat', 'perhaps', 'good', 'competition', 'game', 'mind', 'mind', 'figure', 'machine', 'try', 'sharpen', 'whetstone', 'use', 'thank', 'read', 'suggestion', 'comment', 'thought', 'reach', 'tweet', 'mejackclarksf']"
08/08/2022 - Import AI 299: The world's best language model is Made in China; NVIDIA boosts LLM training; OpenAI shows how to 'fill in the middle' on a LM - 0,http://eepurl.com/h8jfsX,2022-08-08,"Intro (no tag) Welcome to Import AI, a newsletter about artificial intelligence. Forward this email to give your chums an AI upgrade. Subscribe here.

 Want a 30% boost to training LLMs? Use the Nvidia Megatron update:
…Two new techniques lead to big savings…
NVIDIA has updated Nemo Megatron, software for training large language models. The updates - sequence parallelism (SP) and selective activation recomputation (SAR) - makes training large-scale neural networks significantly more efficient.     ""The latest updates to NeMo Megatron offer 30% speed-ups for training GPT-3 models ranging in size from 22 billion to 1 trillion parameters. Training can now be done on 175 billion-parameter models using 1,024 NVIDIA A100 GPUs in just 24 days–reducing time to results by 10 days, or some 250,000 hours of GPU computing, prior to these new releases,"" NVIDIA writes.  Why this matters: By integrating basic improvements into training frameworks, NVIDIA is going to generate a large-scale impact on anyone who uses the Megatron framework. This illustrates how AI progress sometimes operates like a one-way ratchet - someone implements some changes in some increasingly widely used software, and efficiency jumps upward for all the users overnight.
   Read more: NVIDIA AI Platform Delivers Big Gains for Large Language Models (NVIDIA blog).","Intro (no tag) Welcome to Import AI, a newsletter about artificial intelligence. Forward this email to give your chums an AI upgrade. Subscribe here. Want a 30% boost to training LLMs? Use the Nvidia Megatron update: …Two new techniques lead to big savings… NVIDIA has updated Nemo Megatron, software for training large language models. The updates - sequence parallelism (SP) and selective activation recomputation (SAR) - makes training large-scale neural networks significantly more efficient. ""The latest updates to NeMo Megatron offer 30% speed-ups for training GPT-3 models ranging in size from 22 billion to 1 trillion parameters. Training can now be done on 175 billion-parameter models using 1,024 NVIDIA A100 GPUs in just 24 days–reducing time to results by 10 days, or some 250,000 hours of GPU computing, prior to these new releases,"" NVIDIA writes. Why this matters: By integrating basic improvements into training frameworks, NVIDIA is going to generate a large-scale impact on anyone who uses the Megatron framework. This illustrates how AI progress sometimes operates like a one-way ratchet - someone implements some changes in some increasingly widely used software, and efficiency jumps upward for all the users overnight. Read more: NVIDIA AI Platform Delivers Big Gains for Large Language Models (NVIDIA blog).","['tag', 'welcome', 'import', 'newsletter', 'artificial', 'intelligence', 'email', 'give', 'chum', 'ai', 'upgrade', 'subscribe', 'want', 'boost', 'train', 'llm', 'use', 'update', 'new', 'technique', 'lead', 'big', 'saving', 'update', 'software', 'train', 'large', 'language', 'model', 'update', 'sequence', 'parallelism', 'sp', 'selective', 'activation', 'recomputation', 'make', 'training', 'largescale', 'neural', 'network', 'significantly', 'efficient', 'late', 'update', 'offer', 'speedup', 'training', 'gpt3', 'model', 'range', 'size', 'parameter', 'training', 'billionparameter', 'model', 'use', 'nvidia', 'gpus', 'day', 'reduce', 'time', 'result', 'day', 'hour', 'computing', 'prior', 'new', 'release', 'write', 'matter', 'integrate', 'basic', 'improvement', 'training', 'framework', 'nvidia', 'go', 'generate', 'largescale', 'impact', 'use', 'framework', 'illustrate', 'progress', 'sometimes', 'operate', 'oneway', 'ratchet', 'implement', 'change', 'increasingly', 'widely', 'use', 'software', 'efficiency', 'jump', 'upward', 'user', 'overnight', 'read', 'nvidia', 'platform', 'deliver', 'big', 'gain', 'large', 'language', 'model']"
08/08/2022 - Import AI 299: The world's best language model is Made in China; NVIDIA boosts LLM training; OpenAI shows how to 'fill in the middle' on a LM - 1,http://eepurl.com/h8jfsX,2022-08-08,"#################################################### Want to make a language model with a 'fill in the middle' option? Here's how!
…Sentence completion is cool, but infilling is useful as well…
Here's a straightforward paper from OpenAI that describes how to give language models the ability to learn to infill text - e.g, taking a sentence and knocking out the middle of it and asking the model to 'fill in the middle'.  The big insight: The main insight here is that you can learn to fill in the middle ""without compromising the left-to-right capability in pretraining…FIM models achieve the same test loss as AR models on left-to-right test loss while achieving lower FIM loss."". They also learn that it's inefficient to finetune a model to learn to fill in the middle, and you should generally do it at the pretraining stage instead.  Why this matters: Somewhat like DeepMind's recent 'Chinchilla' paper (Import AI #290), which showed you can dramatically increase the capabilities of language models by training them on 5X data, this paper shows you can augment an LM with a nice edit function, and this doesn't come at a loss anywhere else. In fact, OpenAI shows that these ""models are strictly more capable than canonically trained left-to-right models, at least within the bounds of the evaluations we consider"". 
   Read more: Efficient Training of Language Models to Fill in the Middle (arXiv).","#################################################### Want to make a language model with a 'fill in the middle' option? Here's how! …Sentence completion is cool, but infilling is useful as well… Here's a straightforward paper from OpenAI that describes how to give language models the ability to learn to infill text - e.g, taking a sentence and knocking out the middle of it and asking the model to 'fill in the middle'. The big insight: The main insight here is that you can learn to fill in the middle ""without compromising the left-to-right capability in pretraining…FIM models achieve the same test loss as AR models on left-to-right test loss while achieving lower FIM loss."". They also learn that it's inefficient to finetune a model to learn to fill in the middle, and you should generally do it at the pretraining stage instead. Why this matters: Somewhat like DeepMind's recent 'Chinchilla' paper (Import AI #290), which showed you can dramatically increase the capabilities of language models by training them on 5X data, this paper shows you can augment an LM with a nice edit function, and this doesn't come at a loss anywhere else. In fact, OpenAI shows that these ""models are strictly more capable than canonically trained left-to-right models, at least within the bounds of the evaluations we consider"". Read more: Efficient Training of Language Models to Fill in the Middle (arXiv).","['want', 'make', 'language', 'model', 'fill', 'middle', 'option', 'sentence', 'completion', 'cool', 'infille', 'useful', 'well', 'straightforward', 'paper', 'openai', 'describe', 'give', 'language', 'model', 'ability', 'learn', 'infill', 'text', 'eg', 'take', 'sentence', 'knock', 'middle', 'ask', 'model', 'fill', 'middle', 'big', 'insight', 'main', 'insight', 'learn', 'fill', 'middle', 'compromise', 'lefttoright', 'capability', 'pretraine', 'fim', 'model', 'achieve', 'test', 'loss', 'model', 'lefttoright', 'test', 'loss', 'achieve', 'low', 'fim', 'loss', 'also', 'learn', 'inefficient', 'finetune', 'model', 'learn', 'fill', 'middle', 'generally', 'pretraine', 'stage', 'instead', 'matter', 'somewhat', 'deepmind', 'recent', 'chinchilla', 'paper', 'import', 'ai', 'show', 'dramatically', 'increase', 'capability', 'language', 'model', 'train', 'datum', 'paper', 'show', 'augment', 'lm', 'nice', 'edit', 'function', 'come', 'loss', 'anywhere', 'else', 'fact', 'openai', 'show', 'model', 'strictly', 'capable', 'canonically', 'train', 'lefttoright', 'model', 'least', 'bound', 'evaluation', 'consider', 'read', 'efficient', 'training', 'language', 'model', 'fill', 'middle']"
08/08/2022 - Import AI 299: The world's best language model is Made in China; NVIDIA boosts LLM training; OpenAI shows how to 'fill in the middle' on a LM - 2,http://eepurl.com/h8jfsX,2022-08-08,"#################################################### Google uses hybrid AI to improve its own code:
…ML + semantic engines = useful capability… Google has combined machine learning and a rule-based semantic engine to train a Transformer-based system to do code completion on Google's internal codebase. Google looked at how 10,000 Googlers used this capability over the course of three months and the results are quite promising: Google saw a 6% reduction in coding iteration time (switching between builds and tests) and a 7% reduction in context switches (leaving the IDE). ""Currently, 3% of new code (measured in characters) is now generated from accepting ML completion suggestions,"" Google writes. What they did: Google trained a a transformer running on TPUs on code in Google's monorepo, using a context of between ~1000 and ~2000 tokens. The company trained a single model on a mix of 8 languages (C++, Java, Python, Go, Typescript, Proto, Kotlin, and Dart), and trained a relatively small model (0.5 billion parameters) to allow for fast inference. 
   ""The model strongly benefits from the quality of the monorepo, which is enforced by guidelines and reviews,"" Google writes.  Why this matters: This is another example of an 'AI flywheel' - Google is using its own code to train models to help its engineers more efficiently write better code, and it is using a (human-run, for now) acceptance process to maintain the quality of the underlying monorepo, so it can avoid pathological degradations due to garbage in/garbage out dynamics. This is also an area where 'economy of code scale' seems to matter - since Google famously has a single, gigantic internal monorepo, it's easier for the company to train a single model on it. 
   Read more: ML-Enhanced Code Completion Improves Developer Productivity (Google AI Blog).","#################################################### Google uses hybrid AI to improve its own code: …ML + semantic engines = useful capability… Google has combined machine learning and a rule-based semantic engine to train a Transformer-based system to do code completion on Google's internal codebase. Google looked at how 10,000 Googlers used this capability over the course of three months and the results are quite promising: Google saw a 6% reduction in coding iteration time (switching between builds and tests) and a 7% reduction in context switches (leaving the IDE). ""Currently, 3% of new code (measured in characters) is now generated from accepting ML completion suggestions,"" Google writes. What they did: Google trained a a transformer running on TPUs on code in Google's monorepo, using a context of between ~1000 and ~2000 tokens. The company trained a single model on a mix of 8 languages (C++, Java, Python, Go, Typescript, Proto, Kotlin, and Dart), and trained a relatively small model (0.5 billion parameters) to allow for fast inference. ""The model strongly benefits from the quality of the monorepo, which is enforced by guidelines and reviews,"" Google writes. Why this matters: This is another example of an 'AI flywheel' - Google is using its own code to train models to help its engineers more efficiently write better code, and it is using a (human-run, for now) acceptance process to maintain the quality of the underlying monorepo, so it can avoid pathological degradations due to garbage in/garbage out dynamics. This is also an area where 'economy of code scale' seems to matter - since Google famously has a single, gigantic internal monorepo, it's easier for the company to train a single model on it. Read more: ML-Enhanced Code Completion Improves Developer Productivity (Google AI Blog).","['use', 'hybrid', 'ai', 'improve', 'code', 'semantic', 'engine', 'useful', 'capability', 'combine', 'machine', 'learning', 'rulebased', 'semantic', 'engine', 'train', 'transformerbase', 'system', 'code', 'completion', 'google', 'internal', 'codebase', 'google', 'look', 'googler', 'use', 'capability', 'course', 'month', 'result', 'quite', 'promising', 'see', 'reduction', 'code', 'iteration', 'time', 'switch', 'build', 'test', 'reduction', 'context', 'switch', 'leave', 'ide', 'currently', 'new', 'code', 'measure', 'character', 'generate', 'accept', 'ml', 'completion', 'suggestion', 'write', 'train', 'transformer', 'run', 'code', 'google', 'monorepo', 'use', 'context', 'token', 'company', 'train', 'single', 'model', 'mix', 'language', 'go', 'kotlin', 'dart', 'train', 'relatively', 'small', 'model', 'parameter', 'allow', 'fast', 'inference', 'model', 'strongly', 'benefit', 'quality', 'monorepo', 'enforce', 'guideline', 'review', 'write', 'matter', 'example', 'flywheel', 'use', 'code', 'train', 'model', 'help', 'engineer', 'efficiently', 'write', 'well', 'code', 'use', 'humanrun', 'acceptance', 'process', 'maintain', 'quality', 'underlying', 'monorepo', 'avoid', 'pathological', 'degradation', 'garbage', 'ingarbage', 'dynamic', 'also', 'area', 'economy', 'code', 'scale', 'seem', 'matter', 'famously', 'single', 'gigantic', 'internal', 'monorepo', 'easy', 'company', 'train', 'single', 'model', 'read', 'mlenhance', 'code', 'completion', 'improve', 'developer', 'productivity']"
08/08/2022 - Import AI 299: The world's best language model is Made in China; NVIDIA boosts LLM training; OpenAI shows how to 'fill in the middle' on a LM - 3,http://eepurl.com/h8jfsX,2022-08-08,"#################################################### Huawei builds its own GitHub Copilot: PanGu-Coder:
…Another illustration of the 'fast follower' nature of Chinese labs…
Researchers with Huawei (specifically, the Noah's Ark Lab, and Huawei Cloud), have built 'PanGu-Coder', a code completion model. PanGu-Coder is to PanGu as OpenAI's Codex is to GPT3 - think of it as a follow-up model using a similar training procedure, albeit on a different data distribution. And, much like PanGu, PanGu-Coder has been published about a year after the public launch of Codex (and GitHub Copilot), illustrating the surprisingly fast rate at which Chinese labs are able to replace large-scale models.  What PanGu-Coder is: PanGu-Coder is a family of code models for code completion, varying in parameter size from 317million to 2.6 billion. In tests, Huawei claims PanGu-Coder does better than AlphaCode and GitHub Codex on a few human evaluations (though Salesforce's 'Codegen' model does quite well, also). Huawei also significantly improved the capabilities of PanGu-Coder by training a model called PanGu-Coder-FT, which is finetuned on a highly curated dataset.  Why this matters: Code models, much like language models, are becoming like an all-purpose swiss army knife for a range of AI capability and alignment research. It's notable to me that Huawei has - again - managed to do a decent-looking replication of a frontier model developed by a Western lab. It's also notable that few universities have made attempts to replicate these models, due to the resources (both computational and in terms of technical skill) required.
   Read more:PanGu-Coder: Program Synthesis with Function-Level Language Modeling (arXiv).","#################################################### Huawei builds its own GitHub Copilot: PanGu-Coder: …Another illustration of the 'fast follower' nature of Chinese labs… Researchers with Huawei (specifically, the Noah's Ark Lab, and Huawei Cloud), have built 'PanGu-Coder', a code completion model. PanGu-Coder is to PanGu as OpenAI's Codex is to GPT3 - think of it as a follow-up model using a similar training procedure, albeit on a different data distribution. And, much like PanGu, PanGu-Coder has been published about a year after the public launch of Codex (and GitHub Copilot), illustrating the surprisingly fast rate at which Chinese labs are able to replace large-scale models. What PanGu-Coder is: PanGu-Coder is a family of code models for code completion, varying in parameter size from 317million to 2.6 billion. In tests, Huawei claims PanGu-Coder does better than AlphaCode and GitHub Codex on a few human evaluations (though Salesforce's 'Codegen' model does quite well, also). Huawei also significantly improved the capabilities of PanGu-Coder by training a model called PanGu-Coder-FT, which is finetuned on a highly curated dataset. Why this matters: Code models, much like language models, are becoming like an all-purpose swiss army knife for a range of AI capability and alignment research. It's notable to me that Huawei has - again - managed to do a decent-looking replication of a frontier model developed by a Western lab. It's also notable that few universities have made attempts to replicate these models, due to the resources (both computational and in terms of technical skill) required. Read more:PanGu-Coder: Program Synthesis with Function-Level Language Modeling (arXiv).","['huawei', 'build', 'copilot', 'pangucoder', 'illustration', 'fast', 'follower', 'nature', 'chinese', 'lab', 'researcher', 'specifically', 'noahs', 'cloud', 'build', 'pangucoder', 'code', 'completion', 'model', 'pangucoder', 'pangu', 'codex', 'gpt3', 'think', 'followup', 'model', 'use', 'similar', 'training', 'procedure', 'different', 'data', 'distribution', 'much', 'pangu', 'pangucoder', 'publish', 'year', 'public', 'launch', 'codex', 'copilot', 'illustrate', 'surprisingly', 'fast', 'rate', 'chinese', 'lab', 'able', 'replace', 'largescale', 'model', 'pangucoder', 'pangucoder', 'family', 'code', 'model', 'code', 'completion', 'vary', 'parameter', 'size', 'test', 'claim', 'pangucoder', 'well', 'alphacode', 'codex', 'human', 'evaluation', 'salesforce', 'codegen', 'model', 'quite', 'well', 'also', 'huawei', 'also', 'significantly', 'improve', 'capability', 'pangucoder', 'train', 'model', 'call', 'pangucoderft', 'finetune', 'highly', 'curate', 'dataset', 'matter', 'code', 'model', 'much', 'language', 'model', 'become', 'allpurpose', 'swiss', 'army', 'knife', 'range', 'capability', 'alignment', 'research', 'notable', 'manage', 'decentlooking', 'replication', 'frontier', 'model', 'develop', 'western', 'lab', 'also', 'notable', 'university', 'make', 'attempt', 'replicate', 'model', 'resource', 'computational', 'term', 'technical', 'skill', 'require', 'synthesis', 'functionlevel', 'language', 'modeling', 'arxiv']"
08/08/2022 - Import AI 299: The world's best language model is Made in China; NVIDIA boosts LLM training; OpenAI shows how to 'fill in the middle' on a LM - 4,http://eepurl.com/h8jfsX,2022-08-08,"#################################################### China releases GLM-130B, a very good language model:
…The world's best public, open source language model is now Made in China… Researchers with China's Tsinghua University have built and released GLM-130B, a language model that outperforms OPT (Facebook's OS replication of GPT3), BLOOM (HuggingFace's OS replication of GPT3), and OpenAI's original GPT3. This is a pretty big deal, both for the raw capabilities it gives researchers, and for the fact the current best-performing OS language model is Chinese, rather than made in the West. The model was trained on around 400 A100 GPUs which they were able to get via a donation from a local AI startup. What's special about GLM: GLM outperforms the above-mentioned models, as well as homegrown Chinese models like ERNIE Titan 3.0 (Import AI 279).
   Read more: GLM-130B: An Open Bilingual Pre-Trained Model (Tsinghua).
   Get the model here: GLM-130B (THUDM, GitHub).
   Try the model for yourself: GLM-130B (HuggingFace).","#################################################### China releases GLM-130B, a very good language model: …The world's best public, open source language model is now Made in China… Researchers with China's Tsinghua University have built and released GLM-130B, a language model that outperforms OPT (Facebook's OS replication of GPT3), BLOOM (HuggingFace's OS replication of GPT3), and OpenAI's original GPT3. This is a pretty big deal, both for the raw capabilities it gives researchers, and for the fact the current best-performing OS language model is Chinese, rather than made in the West. The model was trained on around 400 A100 GPUs which they were able to get via a donation from a local AI startup. What's special about GLM: GLM outperforms the above-mentioned models, as well as homegrown Chinese models like ERNIE Titan 3.0 (Import AI 279). Read more: GLM-130B: An Open Bilingual Pre-Trained Model (Tsinghua). Get the model here: GLM-130B (THUDM, GitHub). Try the model for yourself: GLM-130B (HuggingFace).","['good', 'language', 'model', 'world', 'good', 'public', 'open', 'source', 'language', 'model', 'make', 'researcher', 'build', 'release', 'language', 'model', 'outperform', 'opt', 'facebook', 'replication', 'gpt3', 'bloom', 'huggingface', 'replication', 'original', 'gpt3', 'pretty', 'big', 'deal', 'raw', 'capability', 'give', 'researcher', 'fact', 'current', 'bestperforming', 'language', 'model', 'chinese', 'rather', 'make', 'west', 'model', 'train', 'gpus', 'able', 'get', 'donation', 'local', 'ai', 'startup', 'special', 'outperform', 'abovementione', 'model', 'well', 'homegrown', 'chinese', 'model', 'import', 'ai', 'read', 'open', 'bilingual', 'pretraine', 'model', 'get', 'model', 'thudm', 'github', 'try', 'model']"
08/08/2022 - Import AI 299: The world's best language model is Made in China; NVIDIA boosts LLM training; OpenAI shows how to 'fill in the middle' on a LM - 5,http://eepurl.com/h8jfsX,2022-08-08,"#################################################### Tech Tales: Micro Religions During the transition there was a micro religion phase. The recommender systems had figured out just how important community was to people, during that time. So the recommenders started shuffling all the different users of all the different apps towards more and more specific niches. It started with commercial stuff - shoes, different 'aesthetics', watches, different locations to spend time at, different hobbies and so on. But eventually it found its way to theistic beliefs - what is the larger purpose of the world? These beliefs turned out to be fractal-like where the recommenders would find ways to push people into the most specific, narrow existing variations - e.g, traditional catholics versus mormons - but they got through that pretty quickly. Next, the recommenders and the generation systems started to autonomously build entire new belief structures (paired with aesthetic styles that materialized as buyable, wearable merchandise across the full variety of products). They then pushed people towards these, and pretty quickly people - especially young people - started identifying as all these different sub-types of religion. After The Events we all collectively looked back on this time as both quite special (some of the beliefs and aesthetics were tremendously strange and complicated), and also scary (there weren't religious wars, but there were warning signs of building-up inter-micro-religion conflict, though The Events happened shortly after and averted war, while bringing about some of the major changes).  Things that inspired this story: Intersection of recommendation engines + generative models; large-scale advertising systems.  
Thanks for reading. If you have suggestions, comments or other thoughts you can reach me at jack@jack-clark.net or tweet at me@jackclarksf","#################################################### Tech Tales: Micro Religions During the transition there was a micro religion phase. The recommender systems had figured out just how important community was to people, during that time. So the recommenders started shuffling all the different users of all the different apps towards more and more specific niches. It started with commercial stuff - shoes, different 'aesthetics', watches, different locations to spend time at, different hobbies and so on. But eventually it found its way to theistic beliefs - what is the larger purpose of the world? These beliefs turned out to be fractal-like where the recommenders would find ways to push people into the most specific, narrow existing variations - e.g, traditional catholics versus mormons - but they got through that pretty quickly. Next, the recommenders and the generation systems started to autonomously build entire new belief structures (paired with aesthetic styles that materialized as buyable, wearable merchandise across the full variety of products). They then pushed people towards these, and pretty quickly people - especially young people - started identifying as all these different sub-types of religion. After The Events we all collectively looked back on this time as both quite special (some of the beliefs and aesthetics were tremendously strange and complicated), and also scary (there weren't religious wars, but there were warning signs of building-up inter-micro-religion conflict, though The Events happened shortly after and averted war, while bringing about some of the major changes). Things that inspired this story: Intersection of recommendation engines + generative models; large-scale advertising systems. Thanks for reading. If you have suggestions, comments or other thoughts you can reach me at jack@jack-clark.net or tweet at me@jackclarksf","['tech', 'tale', 'micro', 'religion', 'transition', 'micro', 'religion', 'phase', 'recommender', 'system', 'figure', 'important', 'community', 'people', 'time', 'recommender', 'start', 'shuffle', 'different', 'user', 'different', 'app', 'specific', 'niche', 'start', 'commercial', 'stuff', 'shoe', 'different', 'aesthetic', 'watch', 'different', 'location', 'spend', 'time', 'different', 'hobby', 'eventually', 'find', 'way', 'theistic', 'belief', 'large', 'purpose', 'world', 'belief', 'turn', 'recommender', 'find', 'way', 'push', 'people', 'specific', 'narrow', 'exist', 'variation', 'eg', 'traditional', 'catholic', 'mormon', 'get', 'pretty', 'quickly', 'recommender', 'generation', 'system', 'start', 'autonomously', 'build', 'entire', 'new', 'belief', 'structure', 'pair', 'aesthetic', 'style', 'materialize', 'buyable', 'wearable', 'merchandise', 'full', 'variety', 'product', 'push', 'people', 'pretty', 'quickly', 'people', 'especially', 'young', 'people', 'start', 'identify', 'different', 'subtype', 'religion', 'event', 'collectively', 'look', 'back', 'time', 'quite', 'special', 'belief', 'aesthetic', 'tremendously', 'strange', 'complicated', 'also', 'scary', 'religious', 'war', 'warn', 'sign', 'conflict', 'event', 'happen', 'shortly', 'avert', 'war', 'bring', 'major', 'change', 'thing', 'inspire', 'story', 'intersection', 'recommendation', 'engine', 'generative', 'model', 'largescale', 'advertising', 'system', 'thank', 'read', 'suggestion', 'comment', 'thought', 'reach', 'tweet', 'mejackclarksf']"
07/25/2022 - Import AI 298: Mimetic models; LLM search engine raises $25m; UK splits from Europe on AI regulation - 0,http://eepurl.com/h7jJjn,2022-07-25,"Intro (no tag) Welcome to Import AI, a newsletter about artificial intelligence. Forward this email to give your chums an AI upgrade. Subscribe here.

 Digital artist: DALL-E is a scam:
…Gen models have brought a ton of people a ton of joy, but some are skeptical..
Here's a post from artist/game developer David OReilly arguing that generative models like Dall-E 2 are a scam. Specifically, because these models scrape a vast amount of image data and spit out new images on tap (in exchange for $, per OpenAI's recent commercialization of Dall-E), then that means ""paying for it benefits a tech company on the back of a century of human effort - a bullshit deal"", according to OReilly. Why this matters: This kind of argument reminds me against early arguments against things like sampling (for music creation), or collage (for making art out of other people's art). I think what makes (some) people nervous about Dall-E is the scale of resources required to develop it means, at least under capitalism, the destiny of these models is mostly to be as products. It feels like the reaction to stuff like Dall-E 2 would be radically different if it was provided as a public good (including free inference services). Many criticisms about AI are really criticisms about 'technology under capitalism' and it's worth trying to disentangle the two.     Read OReilly's post here on his Instagram (Instagram).","Intro (no tag) Welcome to Import AI, a newsletter about artificial intelligence. Forward this email to give your chums an AI upgrade. Subscribe here. Digital artist: DALL-E is a scam: …Gen models have brought a ton of people a ton of joy, but some are skeptical.. Here's a post from artist/game developer David OReilly arguing that generative models like Dall-E 2 are a scam. Specifically, because these models scrape a vast amount of image data and spit out new images on tap (in exchange for $, per OpenAI's recent commercialization of Dall-E), then that means ""paying for it benefits a tech company on the back of a century of human effort - a bullshit deal"", according to OReilly. Why this matters: This kind of argument reminds me against early arguments against things like sampling (for music creation), or collage (for making art out of other people's art). I think what makes (some) people nervous about Dall-E is the scale of resources required to develop it means, at least under capitalism, the destiny of these models is mostly to be as products. It feels like the reaction to stuff like Dall-E 2 would be radically different if it was provided as a public good (including free inference services). Many criticisms about AI are really criticisms about 'technology under capitalism' and it's worth trying to disentangle the two. Read OReilly's post here on his Instagram (Instagram).","['tag', 'welcome', 'import', 'newsletter', 'artificial', 'intelligence', 'email', 'give', 'chum', 'ai', 'upgrade', 'subscribe', 'digital', 'artist', 'dalle', 'scam', 'gen', 'model', 'bring', 'ton', 'people', 'ton', 'joy', 'skeptical', 'post', 'artistgame', 'developer', 'oreilly', 'argue', 'generative', 'model', 'dalle', 'scam', 'specifically', 'model', 'scrape', 'vast', 'amount', 'image', 'datum', 'spit', 'new', 'image', 'tap', 'exchange', 'recent', 'commercialization', 'dalle', 'mean', 'pay', 'benefit', 'tech', 'company', 'back', 'century', 'human', 'effort', 'bullshit', 'deal', 'accord', 'oreilly', 'matter', 'kind', 'argument', 'remind', 'early', 'argument', 'thing', 'sample', 'music', 'creation', 'collage', 'make', 'art', 'people', 'art', 'think', 'make', 'people', 'nervous', 'dalle', 'scale', 'resource', 'require', 'develop', 'mean', 'least', 'capitalism', 'destiny', 'model', 'mostly', 'product', 'feel', 'reaction', 'stuff', 'dalle', 'radically', 'different', 'provide', 'public', 'good', 'include', 'free', 'inference', 'service', 'many', 'criticism', 'really', 'criticism', 'technology', 'capitalism', 'worth', 'try', 'disentangle', 'read', 'oreillys', 'post', 'instagram', 'instagram']"
07/25/2022 - Import AI 298: Mimetic models; LLM search engine raises $25m; UK splits from Europe on AI regulation - 1,http://eepurl.com/h7jJjn,2022-07-25,"#################################################### Is AI alignment getting too much money? …AI alignment is important, but so is progress… Is the field of AI alignment sucking up too much funding? Researcher Bharath Ramsundar thinks so, arguing that the rapid expansion in funding for alignment might be silly. ""AI alignment dollars could probably be better directed to funding next generation American foundry companies to ensure that the entire AI industry isn’t cast into turmoil by a potential future CCP invasion of Taiwan,"" he writes.  Jack's thoughts: As someone who works at the intersection of AI capabilities, policy, and alignment, I find this argument a bit confusing - it basically assumes funding sources for alignment are fungible with resources for things like chips and foundries, but I'd argue that funding here typically comes from different sources with different types of experience. It's not either/or, it's both. (Though I do agree we desperately need to increase funding for semiconductors, given how crucial they are to economic and national competitiveness, and the fact they're currently centralized in some unstable geographies).    Read more: An Argument Against Funding AI Alignment (Deep into the forest, Substack).","#################################################### Is AI alignment getting too much money? …AI alignment is important, but so is progress… Is the field of AI alignment sucking up too much funding? Researcher Bharath Ramsundar thinks so, arguing that the rapid expansion in funding for alignment might be silly. ""AI alignment dollars could probably be better directed to funding next generation American foundry companies to ensure that the entire AI industry isn’t cast into turmoil by a potential future CCP invasion of Taiwan,"" he writes. Jack's thoughts: As someone who works at the intersection of AI capabilities, policy, and alignment, I find this argument a bit confusing - it basically assumes funding sources for alignment are fungible with resources for things like chips and foundries, but I'd argue that funding here typically comes from different sources with different types of experience. It's not either/or, it's both. (Though I do agree we desperately need to increase funding for semiconductors, given how crucial they are to economic and national competitiveness, and the fact they're currently centralized in some unstable geographies). Read more: An Argument Against Funding AI Alignment (Deep into the forest, Substack).","['alignment', 'get', 'much', 'money', 'important', 'progress', 'field', 'alignment', 'suck', 'much', 'funding', 'researcher', 'bharath', 'ramsundar', 'think', 'argue', 'rapid', 'expansion', 'funding', 'alignment', 'silly', 'alignment', 'dollar', 'probably', 'well', 'direct', 'fund', 'next', 'generation', 'american', 'company', 'ensure', 'entire', 'ai', 'industry', 'cast', 'turmoil', 'potential', 'future', 'invasion', 'write', 'jack', 'thought', 'work', 'intersection', 'capability', 'policy', 'alignment', 'find', 'argument', 'bit', 'confusing', 'basically', 'assume', 'fund', 'source', 'alignment', 'fungible', 'resource', 'thing', 'chip', 'foundry', 'argue', 'funding', 'typically', 'come', 'different', 'source', 'different', 'type', 'experience', 'eitheror', 'agree', 'desperately', 'need', 'increase', 'funding', 'semiconductor', 'give', 'crucial', 'economic', 'national', 'competitiveness', 'fact', 'currently', 'centralize', 'unstable', 'geography', 'read', 'argument', 'funding', 'alignment', 'deep', 'forest', 'substack']"
07/25/2022 - Import AI 298: Mimetic models; LLM search engine raises $25m; UK splits from Europe on AI regulation - 2,http://eepurl.com/h7jJjn,2022-07-25,"#################################################### Now that models can imitate people, what do we do? …All hail the era of the funhouse mirror model…
A language model can do an impression of Einstein, a lawyer from Texas in the 19th century, and - given enough information - you. Now, researchers with the University of Toronto, Cornell University and Microsoft Research have grappled with the issues these so-called 'Mimetic Models' may produce.  What they are: A mimetic model is ""an algorithm that is trained on data from a specific individual in a given domain, and which is designed to accurately predict and simulate the behavior of this individual in new situations from the domain"", they write. ""Interacting with a mimetic model can be used as preparation for interactions in real life - essentially, as a means to an end."" 
How they might be used: These models will be used for tasks as varied as being a stand-in for oneself (e.g, answering emails for you), or being a stand-in for an opponent (e.g, preparing for a competition with someone, or a debate). They could also be used as 'mimetic counterfactuals' - how might a person change if they did something different with their life?     Real world use: Mimetic models are already out there in the world - like AI21's marketing stunt to create a virtual 'Ruth Bader Ginsburg' model people can talk to (Import AI 296), or this experiment by an independent artist where they resurrect a childhood friend and the mimetic model tries to kill them using a microwave (Import AI 292). How to think about them: We should think about these models with reference to four key roles - the target that the model is designed to imitate, the person or organization that created the model, the operator who uses the model, and the interactor who interacts with the model or views its outputs.  
Why this matters: Because language models can approximate specific data distributions, it makes sense they can eventually represent people to a high level of fidelity. But I'm not sure the world is ready for the economic, security, and cultural implications of (digital) clones on tap.     Read more: Mimetic Models: Ethical Implications of AI that Acts Like You (arXiv).","#################################################### Now that models can imitate people, what do we do? …All hail the era of the funhouse mirror model… A language model can do an impression of Einstein, a lawyer from Texas in the 19th century, and - given enough information - you. Now, researchers with the University of Toronto, Cornell University and Microsoft Research have grappled with the issues these so-called 'Mimetic Models' may produce. What they are: A mimetic model is ""an algorithm that is trained on data from a specific individual in a given domain, and which is designed to accurately predict and simulate the behavior of this individual in new situations from the domain"", they write. ""Interacting with a mimetic model can be used as preparation for interactions in real life - essentially, as a means to an end."" How they might be used: These models will be used for tasks as varied as being a stand-in for oneself (e.g, answering emails for you), or being a stand-in for an opponent (e.g, preparing for a competition with someone, or a debate). They could also be used as 'mimetic counterfactuals' - how might a person change if they did something different with their life? Real world use: Mimetic models are already out there in the world - like AI21's marketing stunt to create a virtual 'Ruth Bader Ginsburg' model people can talk to (Import AI 296), or this experiment by an independent artist where they resurrect a childhood friend and the mimetic model tries to kill them using a microwave (Import AI 292). How to think about them: We should think about these models with reference to four key roles - the target that the model is designed to imitate, the person or organization that created the model, the operator who uses the model, and the interactor who interacts with the model or views its outputs. Why this matters: Because language models can approximate specific data distributions, it makes sense they can eventually represent people to a high level of fidelity. But I'm not sure the world is ready for the economic, security, and cultural implications of (digital) clones on tap. Read more: Mimetic Models: Ethical Implications of AI that Acts Like You (arXiv).","['model', 'imitate', 'people', 'hail', 'era', 'funhouse', 'mirror', 'language', 'model', 'impression', 'lawyer', '19th', 'century', 'give', 'enough', 'information', 'researcher', 'research', 'grapple', 'issue', 'socalle', 'mimetic', 'model', 'produce', 'mimetic', 'model', 'algorithm', 'train', 'datum', 'specific', 'individual', 'give', 'domain', 'design', 'accurately', 'predict', 'simulate', 'behavior', 'individual', 'new', 'situation', 'domain', 'write', 'interact', 'mimetic', 'model', 'use', 'preparation', 'interaction', 'real', 'life', 'essentially', 'means', 'end', 'use', 'model', 'use', 'task', 'varied', 'standin', 'eg', 'answer', 'email', 'standin', 'opponent', 'eg', 'prepare', 'competition', 'debate', 'also', 'use', 'mimetic', 'counterfactual', 'person', 'change', 'different', 'life', 'real', 'world', 'use', 'mimetic', 'model', 'already', 'world', 'like', 'ai21s', 'marketing', 'stunt', 'create', 'virtual', 'ruth', 'bader', 'ginsburg', 'model', 'people', 'talk', 'import', 'experiment', 'independent', 'artist', 'resurrect', 'childhood', 'friend', 'mimetic', 'model', 'try', 'kill', 'use', 'microwave', 'import', 'ai', 'think', 'think', 'model', 'reference', 'key', 'role', 'target', 'model', 'design', 'imitate', 'person', 'organization', 'create', 'model', 'operator', 'use', 'model', 'interactor', 'interact', 'model', 'view', 'output', 'matter', 'language', 'model', 'approximate', 'specific', 'datum', 'distribution', 'make', 'sense', 'eventually', 'represent', 'people', 'high', 'level', 'fidelity', 'sure', 'world', 'ready', 'economic', 'security', 'cultural', 'implication', 'digital', 'clone', 'tap', 'read', 'mimetic', 'model', 'ethical', 'implication', 'act']"
07/25/2022 - Import AI 298: Mimetic models; LLM search engine raises $25m; UK splits from Europe on AI regulation - 3,http://eepurl.com/h7jJjn,2022-07-25,"#################################################### London heatwave downs Oracle and Google clouds:
…AI, meet climate change…
The recent heatwave across the UK caused outages in data centers used by Oracle and Google, according to Bloomberg. While only temporary, this illustrates the fragility of the infrastructure AI requires, and highlights how, as climate change gets more extreme, some of the 'input costs' for AI-supporting infrastructure may increase.
  Read more: Google, Oracle Data Centers Knocked Offline by London Heat (DataCenter Knowledge).","#################################################### London heatwave downs Oracle and Google clouds: …AI, meet climate change… The recent heatwave across the UK caused outages in data centers used by Oracle and Google, according to Bloomberg. While only temporary, this illustrates the fragility of the infrastructure AI requires, and highlights how, as climate change gets more extreme, some of the 'input costs' for AI-supporting infrastructure may increase. Read more: Google, Oracle Data Centers Knocked Offline by London Heat (DataCenter Knowledge).","['heatwave', 'oracle', 'cloud', 'meet', 'climate', 'change', 'recent', 'heatwave', 'cause', 'outage', 'datum', 'center', 'use', 'oracle', 'accord', 'bloomberg', 'temporary', 'illustrate', 'fragility', 'infrastructure', 'require', 'highlight', 'climate', 'change', 'get', 'extreme', 'input', 'cost', 'aisupporte', 'infrastructure', 'increase', 'read', 'oracle', 'datum', 'center', 'knock', 'offline', 'heat', 'datacenter', 'knowledge']"
07/25/2022 - Import AI 298: Mimetic models; LLM search engine raises $25m; UK splits from Europe on AI regulation - 4,http://eepurl.com/h7jJjn,2022-07-25,"#################################################### LLM-powered search app You raises $25m: …Language models might eat search engines… You, a search engine co-founded by Richard Socher, an AI researcher, has raised a $25m funding round. Socher says You has hundreds of thousands of users and a decent retention rate - not Google numbers, but not totally inconsequential.

Why You matters: The most interesting part of You is how it incorporates a bunch of contemporary language models, providing inbuilt services for things like text analysis, summarization, code search, code completion, and so on. You.com also sits on LMs built by others, such as OpenAI's GPT-3 which powers the 'YouWrite' service.  Why this matters: Contemporary AI models are very general and very powerful - startups like You.com help test out whether these AI systems could obviate or replace prior technology 'stacks'. This funding means You will be around for a while longer, so we can watch the experiment play out.
  Read more: You raises $25M to fuel its AI-powered search engine (TechCrunch).","#################################################### LLM-powered search app You raises $25m: …Language models might eat search engines… You, a search engine co-founded by Richard Socher, an AI researcher, has raised a $25m funding round. Socher says You has hundreds of thousands of users and a decent retention rate - not Google numbers, but not totally inconsequential. Why You matters: The most interesting part of You is how it incorporates a bunch of contemporary language models, providing inbuilt services for things like text analysis, summarization, code search, code completion, and so on. You.com also sits on LMs built by others, such as OpenAI's GPT-3 which powers the 'YouWrite' service. Why this matters: Contemporary AI models are very general and very powerful - startups like You.com help test out whether these AI systems could obviate or replace prior technology 'stacks'. This funding means You will be around for a while longer, so we can watch the experiment play out. Read more: You raises $25M to fuel its AI-powered search engine (TechCrunch).","['llmpowere', 'search', 'app', 'raise', 'language', 'model', 'eat', 'search', 'engine', 'search', 'engine', 'cofounde', 'researcher', 'raise', 'fund', 'round', 'socher', 'say', 'hundred', 'thousand', 'user', 'decent', 'retention', 'rate', 'google', 'number', 'totally', 'inconsequential', 'matter', 'interesting', 'part', 'incorporate', 'bunch', 'contemporary', 'language', 'model', 'provide', 'inbuilt', 'service', 'thing', 'text', 'analysis', 'summarization', 'code', 'search', 'code', 'completion', 'youcom', 'also', 'sit', 'lm', 'build', 'power', 'youwrite', 'service', 'matter', 'contemporary', 'ai', 'model', 'general', 'powerful', 'startup', 'youcom', 'help', 'test', 'ai', 'system', 'obviate', 'replace', 'prior', 'technology', 'stack', 'funding', 'mean', 'around', 'long', 'watch', 'experiment', 'play', 'read', 'raise', 'fuel', 'aipowere', 'search', 'engine', 'techcrunch']"
07/25/2022 - Import AI 298: Mimetic models; LLM search engine raises $25m; UK splits from Europe on AI regulation - 5,http://eepurl.com/h7jJjn,2022-07-25,"#################################################### UK looks at European Commission AI regulations and says 'that's too much', and proposes lightweight regulatory approach:
…Which way, Western governments?...
The UK government's Office for Artificial Intelligence has published a policy paper about how the UK government is going to approach AI regulation. The approach is designed to strike a balance between control and laissez faire development. The government describes its approach as ""a pro-innovation, light-touch and coherent regulatory framework, which creates clarity for businesses and drives new investment"".  
Key principles: The UK says it's going to approach AI regulation as a context-specific area, so it will create specific regulations for specific use cases. It also wants regulators to ""focus on high risk concerns rather than hypothetical or low risks associated with AI,"" as well as ""look for ways to support and encourage regulatory coordination"" given that the UK has a bunch of overlapping authorities with regard to AI. It's also generally steering away from hard regulation, noting that ""we will ask that regulators consider lighter touch options, such as guidance or voluntary measures, in the first instance"".

Things that make you go 'hmmm': ""We will ask that regulators focus on high risk concerns rather than hypothetical or low risks associated with AI,"" it writes.  Challenges for regulation: Regulating AI also comes with some challenges - for one thing, merely by introducing regulation you can make it harder for small businesses to operate (relative to large businesses, which will simply lawyer up). There are also standard things to work through, like overlaps across different authorities, and inconsistencies among regulators.

Defining AI: Any policy document needs to define AI, and this is no different. Here, they try and do a pretty light touch, where they define an AI system as having two big characteristics - how adaptive it is to different scenarios, and how autonomously it can function. These feel like somewhat useful definitions, though in practice they're a bit mangled (e.g, the report defines a transformer-based language model as being highly autonomous as it can generate a bunch of text itself, whereas I suspect most people would think of AI systems being autonomous if they took a bunch of actions in an environment, like an RL agent).  AI principles: In regulating AI, the UK government says it will stick to the following principles:  Feedback requested: Like most government policies, the UK government is taking feedback on these ideas. Specifically, it wants to hear from people about what the contemporary challenges of regulating AI are, whether the proposed context-driven approach is effective, if and how the UK could establish cross-sectoral principles, how best to implement this approach, and if any data sources exist which could help the government monitor the effectiveness of its approach.     Read more: Establishing a pro-innovation approach to regulating AI (GOV.UK).","#################################################### UK looks at European Commission AI regulations and says 'that's too much', and proposes lightweight regulatory approach: …Which way, Western governments?... The UK government's Office for Artificial Intelligence has published a policy paper about how the UK government is going to approach AI regulation. The approach is designed to strike a balance between control and laissez faire development. The government describes its approach as ""a pro-innovation, light-touch and coherent regulatory framework, which creates clarity for businesses and drives new investment"". Key principles: The UK says it's going to approach AI regulation as a context-specific area, so it will create specific regulations for specific use cases. It also wants regulators to ""focus on high risk concerns rather than hypothetical or low risks associated with AI,"" as well as ""look for ways to support and encourage regulatory coordination"" given that the UK has a bunch of overlapping authorities with regard to AI. It's also generally steering away from hard regulation, noting that ""we will ask that regulators consider lighter touch options, such as guidance or voluntary measures, in the first instance"". Things that make you go 'hmmm': ""We will ask that regulators focus on high risk concerns rather than hypothetical or low risks associated with AI,"" it writes. Challenges for regulation: Regulating AI also comes with some challenges - for one thing, merely by introducing regulation you can make it harder for small businesses to operate (relative to large businesses, which will simply lawyer up). There are also standard things to work through, like overlaps across different authorities, and inconsistencies among regulators. Defining AI: Any policy document needs to define AI, and this is no different. Here, they try and do a pretty light touch, where they define an AI system as having two big characteristics - how adaptive it is to different scenarios, and how autonomously it can function. These feel like somewhat useful definitions, though in practice they're a bit mangled (e.g, the report defines a transformer-based language model as being highly autonomous as it can generate a bunch of text itself, whereas I suspect most people would think of AI systems being autonomous if they took a bunch of actions in an environment, like an RL agent). AI principles: In regulating AI, the UK government says it will stick to the following principles: Feedback requested: Like most government policies, the UK government is taking feedback on these ideas. Specifically, it wants to hear from people about what the contemporary challenges of regulating AI are, whether the proposed context-driven approach is effective, if and how the UK could establish cross-sectoral principles, how best to implement this approach, and if any data sources exist which could help the government monitor the effectiveness of its approach. Read more: Establishing a pro-innovation approach to regulating AI (GOV.UK).","['look', 'ai', 'regulation', 'say', 'much', 'propose', 'lightweight', 'regulatory', 'approach', 'way', 'western', 'government', 'government', 'office', 'artificial', 'intelligence', 'publish', 'policy', 'paper', 'government', 'go', 'approach', 'ai', 'regulation', 'approach', 'design', 'strike', 'balance', 'control', 'laissez', 'faire', 'development', 'government', 'describe', 'approach', 'proinnovation', 'lighttouch', 'coherent', 'regulatory', 'framework', 'create', 'clarity', 'business', 'drive', 'new', 'investment', 'key', 'principle', 'say', 'go', 'approach', 'ai', 'regulation', 'contextspecific', 'area', 'create', 'specific', 'regulation', 'specific', 'use', 'case', 'also', 'want', 'regulator', 'focus', 'high', 'risk', 'concern', 'rather', 'hypothetical', 'low', 'risk', 'associate', 'well', 'look', 'way', 'support', 'encourage', 'regulatory', 'coordination', 'give', 'bunch', 'overlap', 'authority', 'regard', 'ai', 'also', 'generally', 'steer', 'away', 'hard', 'regulation', 'note', 'ask', 'regulator', 'consider', 'light', 'touch', 'option', 'guidance', 'voluntary', 'measure', 'first', 'instance', 'thing', 'make', 'go', 'hmmm', 'ask', 'regulator', 'focus', 'high', 'risk', 'concern', 'rather', 'hypothetical', 'low', 'risk', 'associate', 'write', 'challenge', 'regulation', 'regulate', 'ai', 'also', 'come', 'challenge', 'thing', 'merely', 'introduce', 'regulation', 'make', 'hard', 'small', 'business', 'operate', 'relative', 'large', 'business', 'simply', 'lawyer', 'also', 'standard', 'thing', 'work', 'overlap', 'different', 'authority', 'inconsistency', 'regulator', 'define', 'policy', 'document', 'need', 'define', 'different', 'try', 'pretty', 'light', 'touch', 'define', 'ai', 'system', 'big', 'characteristic', 'adaptive', 'different', 'scenario', 'autonomously', 'function', 'feel', 'somewhat', 'useful', 'definition', 'though', 'practice', 'bit', 'mangle', 'report', 'define', 'transformerbase', 'language', 'model', 'highly', 'autonomous', 'generate', 'bunch', 'text', 'suspect', 'people', 'think', 'system', 'autonomous', 'take', 'bunch', 'action', 'environment', 'rl', 'agent', 'ai', 'principle', 'regulate', 'government', 'say', 'stick', 'follow', 'principle', 'feedback', 'request', 'government', 'policy', 'government', 'take', 'feedback', 'idea', 'specifically', 'want', 'hear', 'people', 'contemporary', 'challenge', 'regulating', 'propose', 'contextdriven', 'approach', 'effective', 'establish', 'crosssectoral', 'principle', 'good', 'implement', 'approach', 'datum', 'source', 'exist', 'help', 'government', 'monitor', 'effectiveness', 'approach', 'read', 'establish', 'proinnovation', 'approach', 'regulate', 'govuk']"
07/25/2022 - Import AI 298: Mimetic models; LLM search engine raises $25m; UK splits from Europe on AI regulation - 6,http://eepurl.com/h7jJjn,2022-07-25,"#################################################### The Immemorial Now ""It used to cost millions of dollars and terabytes of data to reanimate a family member. But these days you just need a few photographs, about a hundred dollars, and some patience. Basically you describe the family member and then your glasses layer them into your world, and then they give the family member a voice and back it onto a customized language model. If you've got some old movies of them, you can clone the voice. They act a bit strange at first, but if you just keep describing them and recounting your memories of them, the underlying model is able to capture them eventually. Then you look around and you're there with them,"" he said. ""Honestly, I think it could really help you."" I was uneasy about it. It didn't feel right to me. But on the other hand, there I was, sitting with my sadness and bumming out my friends and talking, as I tended to, about the dead and departed.     ""Of course we're gonna support you,"" he said. ""But maybe this is a way to support yourself.""    ""And you've done it?""    ""Oh, absolutely! Why do you think I talk about my grandad so much? He passed years ago, but this way I can still see him sometimes. I like his jokes.""     ""But they're not his jokes, they're some AI coming up with jokes.""    ""Doesn't make much of a difference - they're the same jokes he used to tell, and he looks like himself, and sounds like himself. What's it - if it walks like a granddad and talks like a grandad, then it's probably a granddad you know?""

My dream helped me make the decision. It was a warped memory. We were in the kitchen of the old house and she was there and we were making bread together. She turned to me and asked me to pass her something and though I knew what she meant, I couldn't hear her voice. I stared at her and started to panic and then I woke up in bed, sweating, grasping mentally at the memory of her.     I tried to calm myself down by imagining her talking to me. Then I realized I couldn't remember her voice.     I became very sad and also very angry. I cried into my pillow. I tried to remember. I couldn't remember.  A few days later,  I was uploading some old videos of her into the resurrection machine. Then I spent a few days talking to the machine about her, telling it little anecdotes - even recounting some of my dreams. I gave it all the images I had of her. I obsessively searched over all my computers until I was sure I'd given it everything I had.    Then one day I asked it to generate her. I put the glasses on and closed my eyes. Then I heard the little sound engineered to sound both reassuring and insistent. She was ready.
  I opened my eyes and there she was, and she looked at me and smiled and said ""I've missed you"", and it felt so real I let myself forget her unreality. Things that inspired this story: Resurrecting the dead with AI and how it can be both helpful and deeply personal; generative models; the intersection of augmented reality and AI; multimodal models, few-shot learning for vast multi-modal models; ideas about how, in the limit, AI lets us generate a stand-in for anything we have data for; mimetic models. 

Thanks for reading. If you have suggestions, comments or other thoughts you can reach me at jack@jack-clark.net or tweet at me@jackclarksf","#################################################### The Immemorial Now ""It used to cost millions of dollars and terabytes of data to reanimate a family member. But these days you just need a few photographs, about a hundred dollars, and some patience. Basically you describe the family member and then your glasses layer them into your world, and then they give the family member a voice and back it onto a customized language model. If you've got some old movies of them, you can clone the voice. They act a bit strange at first, but if you just keep describing them and recounting your memories of them, the underlying model is able to capture them eventually. Then you look around and you're there with them,"" he said. ""Honestly, I think it could really help you."" I was uneasy about it. It didn't feel right to me. But on the other hand, there I was, sitting with my sadness and bumming out my friends and talking, as I tended to, about the dead and departed. ""Of course we're gonna support you,"" he said. ""But maybe this is a way to support yourself."" ""And you've done it?"" ""Oh, absolutely! Why do you think I talk about my grandad so much? He passed years ago, but this way I can still see him sometimes. I like his jokes."" ""But they're not his jokes, they're some AI coming up with jokes."" ""Doesn't make much of a difference - they're the same jokes he used to tell, and he looks like himself, and sounds like himself. What's it - if it walks like a granddad and talks like a grandad, then it's probably a granddad you know?"" My dream helped me make the decision. It was a warped memory. We were in the kitchen of the old house and she was there and we were making bread together. She turned to me and asked me to pass her something and though I knew what she meant, I couldn't hear her voice. I stared at her and started to panic and then I woke up in bed, sweating, grasping mentally at the memory of her. I tried to calm myself down by imagining her talking to me. Then I realized I couldn't remember her voice. I became very sad and also very angry. I cried into my pillow. I tried to remember. I couldn't remember. A few days later, I was uploading some old videos of her into the resurrection machine. Then I spent a few days talking to the machine about her, telling it little anecdotes - even recounting some of my dreams. I gave it all the images I had of her. I obsessively searched over all my computers until I was sure I'd given it everything I had. Then one day I asked it to generate her. I put the glasses on and closed my eyes. Then I heard the little sound engineered to sound both reassuring and insistent. She was ready. I opened my eyes and there she was, and she looked at me and smiled and said ""I've missed you"", and it felt so real I let myself forget her unreality. Things that inspired this story: Resurrecting the dead with AI and how it can be both helpful and deeply personal; generative models; the intersection of augmented reality and AI; multimodal models, few-shot learning for vast multi-modal models; ideas about how, in the limit, AI lets us generate a stand-in for anything we have data for; mimetic models. Thanks for reading. If you have suggestions, comments or other thoughts you can reach me at jack@jack-clark.net or tweet at me@jackclarksf","['immemorial', 'use', 'cost', 'million', 'dollar', 'terabyte', 'datum', 'reanimate', 'family', 'member', 'day', 'need', 'photograph', 'dollar', 'patience', 'basically', 'describe', 'family', 'member', 'glass', 'layer', 'world', 'give', 'family', 'member', 'voice', 'back', 'customize', 'language', 'model', 'get', 'old', 'movie', 'clone', 'voice', 'act', 'bit', 'strange', 'first', 'keep', 'describe', 'recount', 'memory', 'underlie', 'model', 'able', 'capture', 'eventually', 'look', 'around', 'say', 'honestly', 'think', 'really', 'help', 'uneasy', 'feel', 'right', 'hand', 'sit', 'sadness', 'bum', 'friend', 'talk', 'tend', 'dead', 'depart', 'course', 'going', 'support', 'say', 'maybe', 'way', 'support', 'absolutely', 'think', 'talk', 'grandad', 'much', 'pass', 'year', 'ago', 'way', 'still', 'see', 'sometimes', 'like', 'joke', 'joke', 'come', 'joke', 'make', 'much', 'difference', 'joke', 'use', 'tell', 'look', 'sound', 'walk', 'granddad', 'talk', 'grandad', 'probably', 'granddad', 'know', 'dream', 'help', 'make', 'decision', 'warped', 'memory', 'kitchen', 'old', 'house', 'make', 'bread', 'together', 'turn', 'ask', 'pass', 'know', 'mean', 'hear', 'voice', 'stare', 'start', 'panic', 'wake', 'bed', 'sweating', 'grasp', 'mentally', 'memory', 'try', 'calm', 'imagine', 'talk', 'realize', 'remember', 'voice', 'become', 'sad', 'also', 'angry', 'cry', 'pillow', 'try', 'remember', 'remember', 'day', 'later', 'upload', 'old', 'video', 'resurrection', 'machine', 'spend', 'day', 'talk', 'machine', 'tell', 'little', 'anecdote', 'even', 'recount', 'dream', 'give', 'image', 'obsessively', 'search', 'computer', 'sure', 'give', 'day', 'ask', 'generate', 'put', 'glass', 'close', 'eye', 'hear', 'little', 'sound', 'engineer', 'sound', 'reassuring', 'insistent', 'ready', 'open', 'eye', 'look', 'smile', 'say', 'miss', 'feel', 'real', 'let', 'forget', 'unreality', 'thing', 'inspire', 'story', 'resurrect', 'dead', 'helpful', 'deeply', 'personal', 'generative', 'model', 'intersection', 'augmented', 'reality', 'ai', 'multimodal', 'model', 'fewshot', 'learn', 'vast', 'multimodal', 'model', 'idea', 'limit', 'let', 'generate', 'standin', 'datum', 'mimetic', 'model', 'thank', 'read', 'suggestion', 'comment', 'thought', 'reach', 'tweet', 'mejackclarksf']"
