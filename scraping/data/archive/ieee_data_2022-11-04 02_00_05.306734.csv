title,url,date,text,cleaning,tokens
"
        How Can We Make Sure Autonomous Weapons Are Used Responsibly?
    ",https://spectrum.ieee.org/autonomous-weapons-trust,2022-11-03 15:00:16.944040,"Technical challenges of AI are exacerbated in autonomous weapons systems 
This article is part of our Autonomous Weapons Challenges series. The IEEE Standards Association is looking for your feedback on this topic, and has invites you to answer these questions.
 
	International discussions about autonomous weapons systems (AWS) often focus on a fundamental question: Is it legal for a machine to make the decision to take a human life? But woven into this question is another fundamental issue: Can an automated weapons system be trusted to do what it’s expected to do?
 
	If the technical challenges of developing and using AWS can’t be addressed, then the answer to both questions is likely “no.”
 
	Many of the known issues with AI and machine learning become even more problematic when associated with weapons. For example, AI systems could help process data from images far faster than human analysts can, and the majority of the results would be accurate. But the algorithms used for this functionality are known to introduce or exacerbate issues of bias and discrimination, targeting certain demographics more than others. Given that, is it reasonable to use image-recognition software to help humans identify potential targets?
 
	But concerns about the technical abilities of AWS extend beyond object recognition and algorithmic bias. Autonomy in weapons systems requires a slew of technologies, including sensors, communications, and onboard computing power, each of which poses its own challenges for developers. These components are often designed and programmed by different organizations, and it can be hard to predict how the components will function together within the system, as well as how they’ll react to a variety of real-world situations and adversaries.
 
	It’s also not at all clear how militaries can test these systems to ensure the AWS will do what’s expected and comply with International Humanitarian Law. And yet militaries typically want weapons to be tested and proven to act consistently, legally, and without harming their own soldiers before the systems are deployed. If commanders don’t trust a weapons system, they likely won’t use it. But standardized testing is especially complicated for an AI program that can learn from its interactions in the field—in fact, such standardized testing for AWS simply doesn’t exist.
 
	We know how software updates can alter how a system behaves and may introduce bugs that cause a system to behave erratically. But an automated weapons system powered by AI may also update its behavior based on real-world experience, and changes to the AWS behavior could be much harder for users to track. New information that the system accesses in the field could even trigger it to start to shift away from its original goals.
 
	Similarly, cyberattacks and adversarial attacks pose a known threat, which developers try to guard against. But if an attack is successful, what would testing look like to identify that the system has been hacked, and how would a user know to implement such tests?
 
	Though recent advancements in artificial intelligence have led to greater concern about the use of AWS, the technical challenges of autonomy in weapons systems extends beyond AI. Physical challenges already exist for conventional weapons and for nonweaponized autonomous systems, but these same problems are further exacerbated and complicated in AWS.
 
	For example, many autonomous systems are getting smaller, even as their computational needs grow, including navigation, data acquisition and analysis, and decision making—and potentially all while out of communication with commanders. Can the automated weapons system maintain the necessary and legal functionality throughout the mission, even if communication is lost? How is data protected if the system falls into enemy hands?
 
	Issues similar to these may also arise with other autonomous systems, but the consequences of failure are magnified with AWS, and extra features will likely be necessary to ensure that, for example, a weaponized autonomous vehicle in the battlefield doesn’t violate International Humanitarian Law or mistake a friendly vehicle for an enemy target. Because these problems are so new, weapons developers and lawmakers will need to work with and learn from experts in the robotics space to be able to solve the technical challenges and create useful policy.
 
	There are many technical advances that will contribute to various types of weapons systems. Some will prove far more difficult to develop than expected, while others will likely be developed faster. That means AWS development won’t be a leap from conventional weapons systems to full autonomy, but will instead make incremental steps as new autonomous capabilities are developed. This could lead to a slippery slope where it’s unclear if a line has been crossed from acceptable use of technology to unacceptable. Perhaps the solution is to look at specific robotic and autonomous technologies as they’re developed and ask ourselves whether society would want a weapons system with this capability, or if action should be taken to prevent that from happening.
 
	We want your feedback! To help bring clarity to these AWS discussions, the 
		IEEE Standards Association convened an expert group in 2020, to consider the ethical and technical challenges of translating AWS principles into practice and what that might mean for future development and governance. Last year, the expert group published its findings in a report entitled “Ethical and Technical Challenges in the Development, Use, and Governance of Autonomous Weapons Systems.” Many of the AWS challenges are similar to those arising in other fields that are developing autonomous systems. We expect and hope that IEEE members and readers of IEEE Spectrum will have insights from their own fields that can inform the discussion around AWS technologies.
	 Ariel Conn is Head of the IEEE SA Research Group on Issues of AI and Autonomy in Defense Systems. The prosthetics industry is too focused on high-tech limbs that are complicated, costly, and often impractical The author, Britt Young, holding her Ottobock bebionic bionic arm. 
In Jules Verne’s 1865 novel From the Earth to the Moon, members of the fictitious Baltimore Gun Club, all disabled Civil War veterans, restlessly search for a new enemy to conquer. They had spent the war innovating new, deadlier weaponry. By the war’s end, with “not quite one arm between four persons, and exactly two legs between six,” these self-taught amputee-weaponsmiths decide to repurpose their skills toward a new projectile: a rocket ship.
 
	The story of the Baltimore Gun Club propelling themselves to the moon is about the extraordinary masculine power of the veteran, who doesn’t simply “overcome” his disability; he derives power and ambition from it. Their “crutches, wooden legs, artificial arms, steel hooks, caoutchouc [rubber] jaws, silver craniums [and] platinum noses” don’t play leading roles in their personalities—they are merely tools on their bodies. These piecemeal men are unlikely crusaders of invention with an even more unlikely mission. And yet who better to design the next great leap in technology than men remade by technology themselves?
                                 ","Technical challenges of AI are exacerbated in autonomous weapons systems This article is part of our Autonomous Weapons Challenges series . The IEEE Standards Association is looking for your feedback on this topic , and has invites you to answer these questions . International discussions about autonomous weapons systems ( AWS ) often focus on a fundamental question : Is it legal for a machine to make the decision to take a human life ? But woven into this question is another fundamental issue : Can an automated weapons system be trusted to do what it ’ s expected to do ? If the technical challenges of developing and using AWS can ’ t be addressed , then the answer to both questions is likely “ no. ” Many of the known issues with AI and machine learning become even more problematic when associated with weapons . For example , AI systems could help process data from images far faster than human analysts can , and the majority of the results would be accurate . But the algorithms used for this functionality are known to introduce or exacerbate issues of bias and discrimination , targeting certain demographics more than others . Given that , is it reasonable to use image-recognition software to help humans identify potential targets ? But concerns about the technical abilities of AWS extend beyond object recognition and algorithmic bias . Autonomy in weapons systems requires a slew of technologies , including sensors , communications , and onboard computing power , each of which poses its own challenges for developers . These components are often designed and programmed by different organizations , and it can be hard to predict how the components will function together within the system , as well as how they ’ ll react to a variety of real-world situations and adversaries . It ’ s also not at all clear how militaries can test these systems to ensure the AWS will do what ’ s expected and comply with International Humanitarian Law . And yet militaries typically want weapons to be tested and proven to act consistently , legally , and without harming their own soldiers before the systems are deployed . If commanders don ’ t trust a weapons system , they likely won ’ t use it . But standardized testing is especially complicated for an AI program that can learn from its interactions in the field—in fact , such standardized testing for AWS simply doesn ’ t exist . We know how software updates can alter how a system behaves and may introduce bugs that cause a system to behave erratically . But an automated weapons system powered by AI may also update its behavior based on real-world experience , and changes to the AWS behavior could be much harder for users to track . New information that the system accesses in the field could even trigger it to start to shift away from its original goals . Similarly , cyberattacks and adversarial attacks pose a known threat , which developers try to guard against . But if an attack is successful , what would testing look like to identify that the system has been hacked , and how would a user know to implement such tests ? Though recent advancements in artificial intelligence have led to greater concern about the use of AWS , the technical challenges of autonomy in weapons systems extends beyond AI . Physical challenges already exist for conventional weapons and for nonweaponized autonomous systems , but these same problems are further exacerbated and complicated in AWS . For example , many autonomous systems are getting smaller , even as their computational needs grow , including navigation , data acquisition and analysis , and decision making—and potentially all while out of communication with commanders . Can the automated weapons system maintain the necessary and legal functionality throughout the mission , even if communication is lost ? How is data protected if the system falls into enemy hands ? Issues similar to these may also arise with other autonomous systems , but the consequences of failure are magnified with AWS , and extra features will likely be necessary to ensure that , for example , a weaponized autonomous vehicle in the battlefield doesn ’ t violate International Humanitarian Law or mistake a friendly vehicle for an enemy target . Because these problems are so new , weapons developers and lawmakers will need to work with and learn from experts in the robotics space to be able to solve the technical challenges and create useful policy . There are many technical advances that will contribute to various types of weapons systems . Some will prove far more difficult to develop than expected , while others will likely be developed faster . That means AWS development won ’ t be a leap from conventional weapons systems to full autonomy , but will instead make incremental steps as new autonomous capabilities are developed . This could lead to a slippery slope where it ’ s unclear if a line has been crossed from acceptable use of technology to unacceptable . Perhaps the solution is to look at specific robotic and autonomous technologies as they ’ re developed and ask ourselves whether society would want a weapons system with this capability , or if action should be taken to prevent that from happening . We want your feedback ! To help bring clarity to these AWS discussions , the IEEE Standards Association convened an expert group in 2020 , to consider the ethical and technical challenges of translating AWS principles into practice and what that might mean for future development and governance . Last year , the expert group published its findings in a report entitled “ Ethical and Technical Challenges in the Development , Use , and Governance of Autonomous Weapons Systems. ” Many of the AWS challenges are similar to those arising in other fields that are developing autonomous systems . We expect and hope that IEEE members and readers of IEEE Spectrum will have insights from their own fields that can inform the discussion around AWS technologies . Ariel Conn is Head of the IEEE SA Research Group on Issues of AI and Autonomy in Defense Systems . The prosthetics industry is too focused on high-tech limbs that are complicated , costly , and often impractical The author , Britt Young , holding her Ottobock bebionic bionic arm . In Jules Verne ’ s 1865 novel From the Earth to the Moon , members of the fictitious Baltimore Gun Club , all disabled Civil War veterans , restlessly search for a new enemy to conquer . They had spent the war innovating new , deadlier weaponry . By the war ’ s end , with “ not quite one arm between four persons , and exactly two legs between six , ” these self-taught amputee-weaponsmiths decide to repurpose their skills toward a new projectile : a rocket ship . The story of the Baltimore Gun Club propelling themselves to the moon is about the extraordinary masculine power of the veteran , who doesn ’ t simply “ overcome ” his disability ; he derives power and ambition from it . Their “ crutches , wooden legs , artificial arms , steel hooks , caoutchouc [ rubber ] jaws , silver craniums [ and ] platinum noses ” don ’ t play leading roles in their personalities—they are merely tools on their bodies . These piecemeal men are unlikely crusaders of invention with an even more unlikely mission . And yet who better to design the next great leap in technology than men remade by technology themselves ?","['technical', 'challenge', 'exacerbate', 'autonomous', 'weapon', 'system', 'article', 'part', 'autonomous', 'weapon', 'challenge', 'series', 'ieee', 'standard', 'association', 'look', 'feedback', 'topic', 'invite', 'answer', 'question', 'international', 'discussion', 'autonomous', 'weapon', 'system', 'aw', 'often', 'focus', 'fundamental', 'question', 'legal', 'machine', 'make', 'decision', 'take', 'human', 'life', 'weave', 'question', 'fundamental', 'issue', 'automate', 'weapon', 'system', 'trust', 'expect', 'technical', 'challenge', 'develop', 'use', 'aw', 'address', 'answer', 'question', 'likely', 'many', 'know', 'issue', 'ai', 'machine', 'learning', 'become', 'even', 'problematic', 'associate', 'weapon', 'example', 'ai', 'system', 'help', 'process', 'datum', 'image', 'far', 'fast', 'human', 'analyst', 'majority', 'result', 'accurate', 'algorithm', 'use', 'functionality', 'know', 'introduce', 'exacerbate', 'issue', 'bias', 'discrimination', 'target', 'certain', 'demographic', 'give', 'reasonable', 'use', 'imagerecognition', 'software', 'help', 'human', 'identify', 'potential', 'target', 'concern', 'technical', 'ability', 'aw', 'extend', 'object', 'recognition', 'algorithmic', 'bias', 'autonomy', 'weapon', 'system', 'require', 'slew', 'technology', 'include', 'sensor', 'communication', 'compute', 'power', 'pose', 'challenge', 'developer', 'component', 'often', 'design', 'program', 'different', 'organization', 'hard', 'predict', 'component', 'function', 'together', 'system', 'well', 'react', 'variety', 'realworld', 'situation', 'adversarie', 'also', 'clear', 'military', 'test', 'system', 'ensure', 'aw', 'expect', 'comply', 'international', 'humanitarian', 'law', 'yet', 'military', 'typically', 'want', 'weapon', 'test', 'prove', 'act', 'consistently', 'legally', 'harm', 'soldier', 'system', 'deploy', 'commander', 'trust', 'weapon', 'system', 'likely', 'win', 'use', 'standardized', 'testing', 'especially', 'complicate', 'ai', 'program', 'learn', 'interaction', 'field', 'fact', 'standardized', 'testing', 'aw', 'simply', 'exist', 'know', 'software', 'update', 'alter', 'system', 'behave', 'introduce', 'bug', 'cause', 'system', 'behave', 'erratically', 'automate', 'weapon', 'system', 'power', 'also', 'update', 'behavior', 'base', 'experience', 'change', 'aw', 'behavior', 'much', 'hard', 'user', 'track', 'new', 'information', 'system', 'access', 'field', 'even', 'trigger', 'start', 'shift', 'away', 'original', 'goal', 'similarly', 'cyberattack', 'adversarial', 'attack', 'pose', 'know', 'threat', 'developer', 'try', 'guard', 'attack', 'successful', 'test', 'look', 'identify', 'system', 'hack', 'user', 'know', 'implement', 'test', 'recent', 'advancement', 'artificial', 'intelligence', 'lead', 'great', 'concern', 'use', 'aw', 'technical', 'challenge', 'autonomy', 'weapon', 'system', 'extend', 'physical', 'challenge', 'already', 'exist', 'conventional', 'weapon', 'nonweaponized', 'autonomous', 'system', 'problem', 'far', 'exacerbate', 'complicate', 'aw', 'example', 'many', 'autonomous', 'system', 'get', 'small', 'even', 'computational', 'need', 'grow', 'include', 'navigation', 'data', 'acquisition', 'analysis', 'decision', 'making', 'communication', 'commander', 'automate', 'weapon', 'system', 'maintain', 'necessary', 'legal', 'functionality', 'mission', 'even', 'communication', 'lose', 'datum', 'protect', 'system', 'fall', 'enemy', 'hand', 'issue', 'similar', 'also', 'arise', 'autonomous', 'system', 'consequence', 'failure', 'magnify', 'aw', 'extra', 'feature', 'likely', 'necessary', 'ensure', 'example', 'weaponized', 'autonomous', 'vehicle', 'battlefield', 'violate', 'international', 'humanitarian', 'law', 'mistake', 'friendly', 'vehicle', 'enemy', 'target', 'problem', 'new', 'weapon', 'developer', 'lawmaker', 'need', 'work', 'learn', 'expert', 'robotic', 'space', 'able', 'solve', 'technical', 'challenge', 'create', 'useful', 'policy', 'many', 'technical', 'advance', 'contribute', 'various', 'type', 'weapon', 'system', 'prove', 'far', 'difficult', 'develop', 'expect', 'likely', 'develop', 'fast', 'mean', 'aw', 'development', 'win', 'leap', 'conventional', 'weapon', 'system', 'full', 'autonomy', 'instead', 'make', 'incremental', 'step', 'new', 'autonomous', 'capability', 'develop', 'lead', 'slippery', 'slope', 'unclear', 'line', 'cross', 'acceptable', 'use', 'technology', 'unacceptable', 'perhaps', 'solution', 'look', 'specific', 'robotic', 'autonomous', 'technology', 'develop', 'ask', 'society', 'want', 'weapon', 'system', 'capability', 'action', 'take', 'prevent', 'happen', 'want', 'feedback', 'help', 'bring', 'clarity', 'aw', 'discussion', 'ieee', 'standard', 'convene', 'expert', 'group', 'consider', 'ethical', 'technical', 'challenge', 'translate', 'aw', 'principle', 'practice', 'mean', 'future', 'development', 'governance', 'last', 'year', 'expert', 'group', 'publish', 'finding', 'report', 'entitle', 'ethical', 'technical', 'challenge', 'development', 'use', 'governance', 'autonomous', 'weapon', 'system', 'many', 'aw', 'challenge', 'similar', 'arise', 'field', 'develop', 'autonomous', 'system', 'expect', 'hope', 'ieee', 'member', 'reader', 'ieee', 'spectrum', 'insight', 'field', 'inform', 'discussion', 'aw', 'technology', 'head', 'ieee', 'research', 'group', 'issue', 'ai', 'autonomy', 'defense', 'system', 'prosthetic', 'industry', 'focused', 'hightech', 'limb', 'complicated', 'costly', 'often', 'impractical', 'author', 'young', 'hold', 'ottobock', 'bebionic', 'bionic', 'arm', 'jule', 'verne', 'novel', 'earth', 'moon', 'member', 'fictitious', 'gun', 'club', 'disabled', 'civil', 'war', 'veteran', 'restlessly', 'search', 'new', 'enemy', 'conquer', 'spend', 'war', 'innovate', 'new', 'deadly', 'weaponry', 'war', 'end', 'quite', 'arm', 'person', 'exactly', 'leg', 'selftaught', 'amputeeweaponsmith', 'decide', 'repurpose', 'skill', 'new', 'projectile', 'rocket', 'ship', 'story', 'gun', 'club', 'propel', 'moon', 'extraordinary', 'masculine', 'power', 'veteran', 'simply', 'overcome', 'disability', 'derive', 'power', 'ambition', 'crutch', 'wooden', 'leg', 'artificial', 'arm', 'steel', 'hook', 'caoutchouc', 'rubber', 'jaw', 'silver', 'cranium', 'platinum', 'nose', 'play', 'lead', 'role', 'personality', 'merely', 'tool', 'body', 'piecemeal', 'man', 'unlikely', 'crusader', 'invention', 'even', 'unlikely', 'mission', 'yet', 'well', 'design', 'next', 'great', 'leap', 'technology', 'man', 'remade', 'technology']"
"
        How Can We Talk About Autonomous Weapons?
    ",https://spectrum.ieee.org/autonomous-weapons-challenges,2022-11-03 15:00:16.944185,"Experts convened by the IEEE Standards Association seek your help 
This article is part of our Autonomous Weapons Challenges series. The IEEE Standards Association is looking for your feedback on this topic, and has invites you to answer these questions. 
	Lethal autonomous weapons systems can sound terrifying, but autonomy in weapons systems is far more nuanced and complicated than a simple debate between “good or bad” and “ethical or unethical.” In order to address the legal and ethical issues that an autonomous weapons system (AWS) can raise, it’s important to look at the many technical challenges that arise along the full spectrum of autonomy. A group of experts convened by 
	the IEEE Standards Association is working on this, but they need your help.
 
	Weapons systems can be built with a range of autonomous capabilities. They might be self-driving tanks, surveillance drones with AI-enabled image recognition, unmanned underwater vehicles that operate in swarms, loitering munitions with advanced target recognition—the list goes on. Some autonomous capabilities are less controversial, while others trigger intense debate over the legality and ethics of the capability. Some capabilities have existed for decades, while others are still hypothetical and may never be developed.
 
	All of this can make autonomous weapons systems difficult to talk about, and doing so has proven to be incredibly challenging over the years. Answering even the most seemingly straightforward questions, such as whether an AWS is lethal or not, can get surprisingly complicated.
 
	To date, international discussions have largely focused on the legal, ethical, and moral issues that arise with the prospect of lethal AWS, with limited consideration of the technical challenges. At the United Nations, these discussions have taken place within the
	 Convention on Certain Conventional Weapons. After nearly a decade, though, the U.N. has yet to come up with a new treaty or regulations to cover AWS. In early discussions at the CCW and other international forums, participants often talked past each other: One person might consider a “fully autonomous weapons system” to include capabilities that are only slightly more advanced than today’s drones, while another might use the term as a synonym for the Terminator.
 
	Discussions advanced to the point that in 2019, member states at the CCW agreed on a set of 
	11 guiding principles regarding lethal AWS. But these principles are nonbinding, and it’s unclear how the technical community can implement them. At the most recent meeting of the CCW in July, delegates repeatedly pushed for more nuanced discussions and understanding of the various technical issues that arise throughout the life cycle of an AWS.
 
	To help bring clarity to these and other discussions, the 
	IEEE Standards Association convened an expert group in 2020, to consider the ethical and technical challenges of translating AWS principles into practice and what that might mean for future development and governance.
 
	Last year, the expert group, which I lead, published its findings in a report entitled “Ethical and Technical Challenges in the Development, Use, and Governance of Autonomous Weapons Systems.” In the document, we identified over 60 challenges of autonomous weapons systems, organized into 10 categories:
 
	It’s not surprising that “establishing common language” is the first category. As mentioned, when the debates around AWS first began, the focus was on 
	lethal autonomous weapons systems, and that’s often still where people focus. Yet determining whether or not an AWS is lethal turns out to be harder than one might expect.
 
	Consider a drone that does autonomous surveillance and carries a remote-controlled weapon. It uses artificial intelligence to navigate to and identify targets, while a human makes the final decision about whether or not to launch an attack. Just the fact that the weapon and autonomous capabilities are within the same system suggests this could be considered a lethal AWS.
 
	Additionally, a human may not be capable of monitoring all of the data the drone is collecting in real time in order to identify and verify the target, or the human may over-trust the system (a 
	common problem when humans work with machines). Even if the human makes the decision to launch an attack against the target that the AWS has identified, it’s not clear how much “meaningful control” the human truly has. (“Meaningful human control” is another phrase that has been hotly debated.)
 
	This problem of definitions isn’t just an issue that comes up when policymakers at the U.N. discuss AWS. AI developers also have different definitions for commonly used concepts, including “bias,” “transparency,” “trust,” “autonomy,” and “artificial intelligence.” In many instances, the ultimate question may not be, Can we establish technical definitions for these terms? but rather, How do we address the fact that there may never be consistent definitions and agreement on these terms? Because, of course, one of the most important questions for all of the AWS challenges is not whether we technically 
	can address this, but even if there is a technical solution, should we build and deploy the system?
 
	Identifying the challenges was just the first stage of the work for the IEEE-SA expert group. We also concluded that there are three critical perspectives from which a new group of experts will be considering these challenges in more depth:
 
	This is where we want your feedback! Many of the AWS challenges are similar to those arising in other fields that are developing autonomous systems. We expect and hope that IEEE members and readers of 
		IEEE Spectrum will have insights from their own fields that can inform the discussion around AWS technologies.
	 
	We’ve put together a 
		series of questions in the Challenges document that we hope you’ll answer, to help us better understand how people in other fields are addressing these issues. Autonomous capabilities will increasingly be applied to weapons systems, much as they are being applied in other realms, and we hope that by looking at the challenges in more detail, we can help establish effective technical solutions, while contributing to discussions about what can and should be legally acceptable. Your feedback will help us move toward this ultimate goal. Public comments will be open through 7 December 2022.
	 
The independent group of experts who authored the report for the IEEE Standards Associate includes Emmanuel Bloch, Ariel Conn, Denise Garcia, Amandeep Gill, Ashley Llorens, Mart Noorma, and Heather Roff.
 Ariel Conn is Head of the IEEE SA Research Group on Issues of AI and Autonomy in Defense Systems. The prosthetics industry is too focused on high-tech limbs that are complicated, costly, and often impractical The author, Britt Young, holding her Ottobock bebionic bionic arm. 
In Jules Verne’s 1865 novel From the Earth to the Moon, members of the fictitious Baltimore Gun Club, all disabled Civil War veterans, restlessly search for a new enemy to conquer. They had spent the war innovating new, deadlier weaponry. By the war’s end, with “not quite one arm between four persons, and exactly two legs between six,” these self-taught amputee-weaponsmiths decide to repurpose their skills toward a new projectile: a rocket ship.
 
	The story of the Baltimore Gun Club propelling themselves to the moon is about the extraordinary masculine power of the veteran, who doesn’t simply “overcome” his disability; he derives power and ambition from it. Their “crutches, wooden legs, artificial arms, steel hooks, caoutchouc [rubber] jaws, silver craniums [and] platinum noses” don’t play leading roles in their personalities—they are merely tools on their bodies. These piecemeal men are unlikely crusaders of invention with an even more unlikely mission. And yet who better to design the next great leap in technology than men remade by technology themselves?
                                 ","Experts convened by the IEEE Standards Association seek your help This article is part of our Autonomous Weapons Challenges series . The IEEE Standards Association is looking for your feedback on this topic , and has invites you to answer these questions . Lethal autonomous weapons systems can sound terrifying , but autonomy in weapons systems is far more nuanced and complicated than a simple debate between “ good or bad ” and “ ethical or unethical. ” In order to address the legal and ethical issues that an autonomous weapons system ( AWS ) can raise , it ’ s important to look at the many technical challenges that arise along the full spectrum of autonomy . A group of experts convened by the IEEE Standards Association is working on this , but they need your help . Weapons systems can be built with a range of autonomous capabilities . They might be self-driving tanks , surveillance drones with AI-enabled image recognition , unmanned underwater vehicles that operate in swarms , loitering munitions with advanced target recognition—the list goes on . Some autonomous capabilities are less controversial , while others trigger intense debate over the legality and ethics of the capability . Some capabilities have existed for decades , while others are still hypothetical and may never be developed . All of this can make autonomous weapons systems difficult to talk about , and doing so has proven to be incredibly challenging over the years . Answering even the most seemingly straightforward questions , such as whether an AWS is lethal or not , can get surprisingly complicated . To date , international discussions have largely focused on the legal , ethical , and moral issues that arise with the prospect of lethal AWS , with limited consideration of the technical challenges . At the United Nations , these discussions have taken place within the Convention on Certain Conventional Weapons . After nearly a decade , though , the U.N. has yet to come up with a new treaty or regulations to cover AWS . In early discussions at the CCW and other international forums , participants often talked past each other : One person might consider a “ fully autonomous weapons system ” to include capabilities that are only slightly more advanced than today ’ s drones , while another might use the term as a synonym for the Terminator . Discussions advanced to the point that in 2019 , member states at the CCW agreed on a set of 11 guiding principles regarding lethal AWS . But these principles are nonbinding , and it ’ s unclear how the technical community can implement them . At the most recent meeting of the CCW in July , delegates repeatedly pushed for more nuanced discussions and understanding of the various technical issues that arise throughout the life cycle of an AWS . To help bring clarity to these and other discussions , the IEEE Standards Association convened an expert group in 2020 , to consider the ethical and technical challenges of translating AWS principles into practice and what that might mean for future development and governance . Last year , the expert group , which I lead , published its findings in a report entitled “ Ethical and Technical Challenges in the Development , Use , and Governance of Autonomous Weapons Systems. ” In the document , we identified over 60 challenges of autonomous weapons systems , organized into 10 categories : It ’ s not surprising that “ establishing common language ” is the first category . As mentioned , when the debates around AWS first began , the focus was on lethal autonomous weapons systems , and that ’ s often still where people focus . Yet determining whether or not an AWS is lethal turns out to be harder than one might expect . Consider a drone that does autonomous surveillance and carries a remote-controlled weapon . It uses artificial intelligence to navigate to and identify targets , while a human makes the final decision about whether or not to launch an attack . Just the fact that the weapon and autonomous capabilities are within the same system suggests this could be considered a lethal AWS . Additionally , a human may not be capable of monitoring all of the data the drone is collecting in real time in order to identify and verify the target , or the human may over-trust the system ( a common problem when humans work with machines ) . Even if the human makes the decision to launch an attack against the target that the AWS has identified , it ’ s not clear how much “ meaningful control ” the human truly has . ( “ Meaningful human control ” is another phrase that has been hotly debated . ) This problem of definitions isn ’ t just an issue that comes up when policymakers at the U.N. discuss AWS . AI developers also have different definitions for commonly used concepts , including “ bias , ” “ transparency , ” “ trust , ” “ autonomy , ” and “ artificial intelligence. ” In many instances , the ultimate question may not be , Can we establish technical definitions for these terms ? but rather , How do we address the fact that there may never be consistent definitions and agreement on these terms ? Because , of course , one of the most important questions for all of the AWS challenges is not whether we technically can address this , but even if there is a technical solution , should we build and deploy the system ? Identifying the challenges was just the first stage of the work for the IEEE-SA expert group . We also concluded that there are three critical perspectives from which a new group of experts will be considering these challenges in more depth : This is where we want your feedback ! Many of the AWS challenges are similar to those arising in other fields that are developing autonomous systems . We expect and hope that IEEE members and readers of IEEE Spectrum will have insights from their own fields that can inform the discussion around AWS technologies . We ’ ve put together a series of questions in the Challenges document that we hope you ’ ll answer , to help us better understand how people in other fields are addressing these issues . Autonomous capabilities will increasingly be applied to weapons systems , much as they are being applied in other realms , and we hope that by looking at the challenges in more detail , we can help establish effective technical solutions , while contributing to discussions about what can and should be legally acceptable . Your feedback will help us move toward this ultimate goal . Public comments will be open through 7 December 2022 . The independent group of experts who authored the report for the IEEE Standards Associate includes Emmanuel Bloch , Ariel Conn , Denise Garcia , Amandeep Gill , Ashley Llorens , Mart Noorma , and Heather Roff . Ariel Conn is Head of the IEEE SA Research Group on Issues of AI and Autonomy in Defense Systems . The prosthetics industry is too focused on high-tech limbs that are complicated , costly , and often impractical The author , Britt Young , holding her Ottobock bebionic bionic arm . In Jules Verne ’ s 1865 novel From the Earth to the Moon , members of the fictitious Baltimore Gun Club , all disabled Civil War veterans , restlessly search for a new enemy to conquer . They had spent the war innovating new , deadlier weaponry . By the war ’ s end , with “ not quite one arm between four persons , and exactly two legs between six , ” these self-taught amputee-weaponsmiths decide to repurpose their skills toward a new projectile : a rocket ship . The story of the Baltimore Gun Club propelling themselves to the moon is about the extraordinary masculine power of the veteran , who doesn ’ t simply “ overcome ” his disability ; he derives power and ambition from it . Their “ crutches , wooden legs , artificial arms , steel hooks , caoutchouc [ rubber ] jaws , silver craniums [ and ] platinum noses ” don ’ t play leading roles in their personalities—they are merely tools on their bodies . These piecemeal men are unlikely crusaders of invention with an even more unlikely mission . And yet who better to design the next great leap in technology than men remade by technology themselves ?","['expert', 'convene', 'ieee', 'standard', 'association', 'seek', 'help', 'article', 'part', 'autonomous', 'weapon', 'challenge', 'series', 'ieee', 'standard', 'association', 'look', 'feedback', 'topic', 'invite', 'answer', 'question', 'lethal', 'autonomous', 'weapon', 'system', 'sound', 'terrify', 'autonomy', 'weapon', 'system', 'far', 'nuanced', 'complicated', 'simple', 'debate', 'good', 'bad', 'ethical', 'unethical', 'order', 'address', 'legal', 'ethical', 'issue', 'autonomous', 'weapon', 'system', 'aw', 'raise', 'important', 'look', 'many', 'technical', 'challenge', 'arise', 'full', 'spectrum', 'group', 'expert', 'convene', 'ieee', 'standard', 'work', 'need', 'help', 'weapon', 'system', 'build', 'range', 'autonomous', 'capability', 'selfdrive', 'tank', 'surveillance', 'drone', 'aienabled', 'image', 'recognition', 'unmanned', 'underwater', 'vehicle', 'operate', 'swarm', 'loitering', 'munition', 'advanced', 'target', 'recognition', 'list', 'go', 'autonomous', 'capability', 'less', 'controversial', 'trigger', 'intense', 'debate', 'legality', 'ethic', 'capability', 'capability', 'exist', 'decade', 'still', 'hypothetical', 'never', 'develop', 'make', 'autonomous', 'weapon', 'system', 'difficult', 'talk', 'prove', 'incredibly', 'challenge', 'year', 'answer', 'even', 'seemingly', 'straightforward', 'question', 'aws', 'lethal', 'get', 'surprisingly', 'complicate', 'date', 'international', 'discussion', 'largely', 'focus', 'legal', 'ethical', 'moral', 'issue', 'arise', 'prospect', 'lethal', 'aw', 'limited', 'consideration', 'technical', 'challenge', 'discussion', 'take', 'place', 'convention', 'certain', 'conventional', 'weapon', 'nearly', 'decade', 'yet', 'come', 'new', 'treaty', 'regulation', 'cover', 'aw', 'early', 'discussion', 'ccw', 'international', 'forum', 'participant', 'often', 'talk', 'person', 'consider', 'fully', 'autonomous', 'weapon', 'system', 'include', 'capability', 'slightly', 'advanced', 'today', 'drone', 'use', 'term', 'synonym', 'terminator', 'discussion', 'advance', 'point', 'member', 'state', 'ccw', 'agree', 'set', 'guide', 'principle', 'regard', 'lethal', 'aw', 'principle', 'nonbinde', 'unclear', 'technical', 'community', 'implement', 'recent', 'meeting', 'ccw', 'delegate', 'repeatedly', 'push', 'nuanced', 'discussion', 'understanding', 'various', 'technical', 'issue', 'arise', 'life', 'cycle', 'aw', 'help', 'bring', 'clarity', 'discussion', 'ieee', 'standard', 'convene', 'expert', 'group', 'consider', 'ethical', 'technical', 'challenge', 'translate', 'aw', 'principle', 'practice', 'mean', 'future', 'development', 'governance', 'last', 'year', 'expert', 'group', 'lead', 'publish', 'finding', 'report', 'entitle', 'ethical', 'technical', 'challenge', 'development', 'use', 'governance', 'autonomous', 'weapon', 'system', 'document', 'identify', 'challenge', 'autonomous', 'weapon', 'system', 'organize', 'category', 'surprising', 'establish', 'common', 'language', 'first', 'category', 'mention', 'debate', 'aw', 'first', 'begin', 'focus', 'lethal', 'autonomous', 'weapon', 'system', 'often', 'still', 'people', 'focus', 'yet', 'determine', 'aws', 'lethal', 'turn', 'hard', 'expect', 'consider', 'drone', 'autonomous', 'surveillance', 'carry', 'remotecontrolle', 'weapon', 'use', 'artificial', 'intelligence', 'navigate', 'identify', 'target', 'human', 'make', 'final', 'decision', 'launch', 'attack', 'fact', 'weapon', 'autonomous', 'capability', 'system', 'suggest', 'consider', 'lethal', 'aw', 'additionally', 'human', 'capable', 'monitor', 'datum', 'drone', 'collect', 'real', 'time', 'order', 'identify', 'verify', 'target', 'human', 'overtrust', 'system', 'common', 'problem', 'human', 'work', 'machine', 'even', 'human', 'make', 'decision', 'launch', 'attack', 'target', 'aw', 'identify', 'clear', 'much', 'meaningful', 'control', 'human', 'truly', 'meaningful', 'human', 'control', 'phrase', 'hotly', 'debate', 'problem', 'definition', 'issue', 'come', 'policymaker', 'aw', 'ai', 'developer', 'also', 'different', 'definition', 'commonly', 'use', 'concept', 'include', 'bias', 'artificial', 'intelligence', 'many', 'instance', 'ultimate', 'question', 'establish', 'technical', 'definition', 'term', 'rather', 'address', 'fact', 'never', 'consistent', 'definition', 'agreement', 'term', 'course', 'important', 'question', 'aw', 'challenge', 'technically', 'address', 'even', 'technical', 'solution', 'build', 'deploy', 'system', 'identify', 'challenge', 'first', 'stage', 'work', 'also', 'conclude', 'critical', 'perspective', 'new', 'group', 'expert', 'consider', 'challenge', 'depth', 'want', 'feedback', 'many', 'aw', 'challenge', 'similar', 'arise', 'field', 'develop', 'autonomous', 'system', 'expect', 'hope', 'ieee', 'member', 'reader', 'ieee', 'spectrum', 'insight', 'field', 'inform', 'discussion', 'aw', 'technology', 'put', 'together', 'series', 'question', 'challenge', 'document', 'hope', 'answer', 'help', 'well', 'understand', 'people', 'field', 'address', 'issue', 'autonomous', 'capability', 'increasingly', 'apply', 'weapon', 'system', 'much', 'apply', 'realm', 'hope', 'look', 'challenge', 'detail', 'help', 'establish', 'effective', 'technical', 'solution', 'contribute', 'discussion', 'legally', 'acceptable', 'feedback', 'help', 'move', 'ultimate', 'goal', 'public', 'comment', 'open', 'independent', 'group', 'expert', 'author', 'report', 'ieee', 'standard', 'associate', 'include', 'heather', 'head', 'ieee', 'research', 'group', 'issue', 'ai', 'autonomy', 'defense', 'system', 'prosthetic', 'industry', 'focused', 'hightech', 'limb', 'complicated', 'costly', 'often', 'impractical', 'author', 'young', 'hold', 'ottobock', 'bebionic', 'bionic', 'arm', 'jule', 'verne', 'novel', 'earth', 'moon', 'member', 'fictitious', 'gun', 'club', 'disabled', 'civil', 'war', 'veteran', 'restlessly', 'search', 'new', 'enemy', 'conquer', 'spend', 'war', 'innovate', 'new', 'deadly', 'weaponry', 'war', 'end', 'quite', 'arm', 'person', 'exactly', 'leg', 'selftaught', 'amputeeweaponsmith', 'decide', 'repurpose', 'skill', 'new', 'projectile', 'rocket', 'ship', 'story', 'gun', 'club', 'propel', 'moon', 'extraordinary', 'masculine', 'power', 'veteran', 'simply', 'overcome', 'disability', 'derive', 'power', 'ambition', 'crutch', 'wooden', 'leg', 'artificial', 'arm', 'steel', 'hook', 'caoutchouc', 'rubber', 'jaw', 'silver', 'cranium', 'platinum', 'nose', 'play', 'lead', 'role', 'personality', 'merely', 'tool', 'body', 'piecemeal', 'man', 'unlikely', 'crusader', 'invention', 'even', 'unlikely', 'mission', 'yet', 'well', 'design', 'next', 'great', 'leap', 'technology', 'man', 'remade', 'technology']"
