title,url,date,text,cleaning,tokens
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels,"[{'href': 'http://arxiv.org/abs/2207.00986v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2207.00986v1', 'rel': 'related', 'type': 'application/pdf'}]",2022-07-03 08:52:40,"University of New Mexico 
University of New Mexico 
UNM Digital Repository 
UNM Digital Repository 

Electrical and Computer Engineering ETDs 

Engineering ETDs 

Spring 5-2022 

Speaker Diarization and Identification from Single-Channel 
Speaker Diarization and Identification from Single-Channel 

Classroom Audio Recording Using Virtual Microphones 
Classroom Audio Recording Using Virtual Microphones 

Antonio Gomez 

Follow this and additional works at: https://digitalrepository.unm.edu/ece_etds 

 Part of the Bilingual, Multilingual, and Multicultural Education Commons, Computational Engineering 

Commons, Educational Methods Commons, Educational Technology Commons, Science and 

Mathematics Education Commons, and the Signal Processing Commons 

     Antonio Gomez 
       Candidate  

     Electrical and Computer Engineering 
     Department 

     This dissertation is approved, and it is acceptable in quality and form for publication: 

     Approved by the Dissertation Committee: 

     Dr. Marios Pattichis                                                                                                                     Chairperson 

     Dr. Ramiro Jordan 

     Dr. Sylvia Pattichis 

     Dr. Kim Linder 

     Dr. Manel Martinez-Ramon 

i 

 
 
    
 
      
 
 
 
        
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
      
 
 
       
 
 
       
 
 
       
 
 
Speaker Diarization and Identification  
from Single-Channel Classroom Audio Recording  
Using Virtual Microphones 

by 

ANTONIO GOMEZ 

BS, Electrical Engineering, Florida International University, 1986 
MS, Engineering Management, Florida International University, 1997 

DISSERTATION 

Submitted in Partial Fulfillment of the 
Requirements for the Degree of 

Doctor of Philosophy 
Engineering 

The University of New Mexico 
Albuquerque, New Mexico 

May 2022 

ii 

 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
DEDICATION 

I would like to dedicate this dissertation to a very special person in my life, my wife 

Grace, for her support during this long journey. For all the hours, days, months, years she 

spent giving me the breath to move on, and for all the times she told me it is time to finish 

as well. For her, my eternal gratitude. 

I would like also to dedicate this work to my children, Daniel, and Carolina, for 

understanding why sometimes I was not there with them. I hope this work would serve as 

an inspiration to them. 

iii 

 
 
 
 
 
 
ACKNOWLEDGEMENTS 

I  would  like  to  sincerely  acknowledge  the  labor  of  my  advisor  and  dissertation 

chair, Dr. Marios Pattichis, for his continued support during all these years. Thank you for 

believing in me, Marios. I would have never done this without you on my side. 

I would like also to thank my committee members, for taking the time to review 

and advise my work. Thank you, Dr. Kim Linder, for being always there as a friend. 

Finally, I would like to say thank you to my managers at Honeywell and Sandia 

National Labs for their support and understanding. 

iv 

 
 
 
 
 
Speaker Diarization and Identification  

from Single-Channel Classroom Audio Recording  

Using Virtual Microphones 

By 

ANTONIO GOMEZ 

BS, Electrical Engineering, Florida International University, 1986 

MS, Engineering Management, Florida International University, 1997 

Ph.D. Engineering, University of New Mexico, 2022 

ABSTRACT 

Speaker  identification  in  noisy  audio  recordings,  specifically  those  from 

collaborative  learning  environments,  can  be  extremely  challenging.  There  is  a  need  to 

identify individual students talking in small groups from other students talking at the same 

time. To solve the problem, we assume the use of a single microphone per student group 

without any access to previous large datasets for training. 

This  dissertation  proposes  a  method  of  speaker  identification  using  cross-

correlation  patterns  associated  to  an  array  of  virtual  microphones,  centered  around  the 

physical microphone. The virtual microphones are simulated by using approximate speaker 

geometry observed from a video recording. The patterns are constructed based on estimates 

v 

 
 
 
 
 
 
 
of the room impulse responses for each virtual microphone.  The correlation patterns are 

then used to identify the speakers. The proposed method is validated with classroom audios 

and shown to substantially outperform diarization services provided by Google Cloud and 

Amazon AWS. 

vi 

 
 
 
 
TABLE OF CONTENTS 

LIST OF FIGURES…………………………………………………………………...…xii  

LIST OF TABLES……………………………………………………………….…...…xvi  

CHAPTER 1. INTRODUCTION ....................................................................................... 1 

1.1  MOTIVATION ........................................................................................................ 4 

1.2 

RELATED RESEARCH ............................................................................................ 6 

1.3 

THESIS STATEMENT ........................................................................................... 12 

1.4 

CONTRIBUTIONS ................................................................................................ 12 

1.5 

DISSERTATION OVERVIEW ................................................................................. 13 

CHAPTER 2. BACKGROUND ....................................................................................... 15 

2.1 

ACOUSTICS PRINCIPLES ..................................................................................... 15 

2.1.1  Sound Propagation: Near and Far Fields ...................................................... 16 

2.1.2  Sound Propagation: Direct Path, Reflections, and Reverberation ................ 18 

2.2  MICROPHONES AND MICROPHONE ARRAYS ....................................................... 22 

2.2.1  Classification of Microphones ...................................................................... 22 

2.2.2  Microphone Arrays ....................................................................................... 24 

2.2.2.1  Microphone Arrays Configurations ...................................................... 26 

2.2.2.2  Spatial Aliasing ..................................................................................... 30 

2.2.2.3  TDOA and Cross-Correlation ............................................................... 31 

vii 

 
 
 
2.2.2.4  Beamforming and Spatial Filters .......................................................... 33 

2.3  MODELING OF ROOM ACOUSTICS ...................................................................... 34 

2.3.1  Ray Tracing Method ..................................................................................... 35 

2.3.2 

Image Source Method ................................................................................... 36 

2.4 

CHARACTERISTICS OF THE HUMAN SPEECH ....................................................... 38 

2.5 

SPEAKER DIARIZATION AND IDENTIFICATION .................................................... 40 

2.5.1  Methods for Diarization and Identification ................................................... 40 

2.5.1.1  Classical Methods for Diarization and Identification ........................... 40 

2.5.1.2  Deep Neural Networks .......................................................................... 43 

2.5.1.2.1  Stage-wise diarization ..................................................................... 44 

2.5.1.2.2  Multimodal Speaker Diarization ..................................................... 46 

2.5.2  Current State-of-the-Art Methods for Diarization and Identification ........... 47 

CHAPTER 3. PROPOSED METHOD ............................................................................. 50 

3.1  METHODOLOGY ................................................................................................. 50 

3.2 

BLOCK DIAGRAM OF THE PROPOSED SYSTEM .................................................... 68 

CHAPTER 4. EXPERIMENTAL IMPLEMENTATION ................................................ 72 

4.1 

SOFTWARE AND HARDWARE TOOLS .................................................................. 72 

4.1.1  Open-Source Code for Room Geometry, RIR Calculation, and Microphone 

Simulation ................................................................................................................. 73 

4.1.1.1  Pyroomacoustics Implementation ......................................................... 76 

4.1.2  Audio Segmentation...................................................................................... 78 

viii 

 
 
4.1.2.1  Fixed Length Segmentation .................................................................. 78 

4.1.2.2  Voice Activity Detection ...................................................................... 79 

4.1.3 

Implementation Using the LabVIEW Graphical Programming ................... 81 

4.1.3.1  LabVIEW Implementation.................................................................... 83 

4.1.3.1.1  Function VIs .................................................................................... 83 

4.1.3.1.2  Operational Sub-VIs ........................................................................ 87 

4.1.3.2  Audio Laboratory .................................................................................. 91 

4.2 

THE AOLME ENVIRONMENT ............................................................................ 94 

4.2.1  Characteristics of the AOLME Environment ............................................... 95 

4.2.2  Preparation of the Experimental Models ...................................................... 96 

4.2.2.1  Approximating the Models Using Video Observations ........................ 97 

CHAPTER 5. RESULTS ................................................................................................ 104 

5.1 

EVALUATION OF PYROOMACOUSTICS .............................................................. 104 

5.1.1  Microphone Calibration .............................................................................. 104 

5.1.2  Audio Lab Setup and Model Configuration................................................ 108 

5.1.3  Experimental Execution .............................................................................. 110 

5.1.4  Results ......................................................................................................... 111 

5.2 

CONTROLLED ENVIRONMENT EXPERIMENTS ................................................... 112 

5.2.1  Methodology ............................................................................................... 112 

5.2.1.1  Audio Lab and Model Preparation ...................................................... 113 

5.2.1.2  Evaluation Criteria .............................................................................. 115 

ix 

 
 
5.2.2  “HAL 9000” Experiments........................................................................... 116 

5.2.2.1  Source Preparation and Editing .......................................................... 118 

5.2.2.2  Ground Truth Recording ..................................................................... 120 

5.2.2.3  Training and Segmentation ................................................................. 120 

5.2.2.4  Testing and Results ............................................................................. 123 

5.2.3  Multi-Speaker Identification Experiments .................................................. 124 

5.2.3.1  Source Preparation and Editing .......................................................... 124 

5.2.3.2  Ground Truth Recording ..................................................................... 126 

5.2.3.3  Training and Segmentation ................................................................. 127 

5.2.3.4  Testing and Results ............................................................................. 127 

5.3 

AOLME EXPERIMENTS ................................................................................... 128 

5.3.1  Evaluation and Selection of AOLME Videos ............................................. 128 

5.3.2  Model Preparation ....................................................................................... 129 

5.3.3  Training and Segmentation ......................................................................... 131 

5.3.4  Testing and Results ..................................................................................... 132 

5.4 

COMPARISON WITH OTHER METHODS ............................................................. 134 

5.4.1  Methodology for Comparison ..................................................................... 134 

5.4.2  Selection, Preparation, and Ground Truth Measurements of Videos for 

Analysis................................................................................................................... 135 

5.4.3  Training and Segmentation ......................................................................... 136 

5.4.4  Testing and Analysis ................................................................................... 136 

x 

 
 
5.4.5  Results ......................................................................................................... 136 

CHAPTER 6. SUMMARY, CONCLUSIONS, AND FUTURE WORK ...................... 140 

APPENDIX A: 

PYROOMACOUSTICS SCRIPTS ................................................ 143 

APPENDIX B: 

LABVIEW SUB-VIS...................................................................... 146 

APPENDIX C: 

AUDIO LAB EQUIPMENT SPECIFICATIONS .......................... 158 

REFERENCES ............................................................................................................... 162 

xi 

 
 
LIST OF FIGURES 

Figure 1: Propagation of Sound Waves. (a) Free Field. (b) Directional. .......................... 17 

Figure 2: Near and Far-Field Areas. ................................................................................. 18 

Figure 3: Direct and Reflected Paths for Sound Propagation in a Diffuse Field. ............. 19 

Figure 4: Representation of the Room Impulse Response and its Components. .............. 21 

Figure 5: Polar Pattern Plot of Directivity of Two Types of Microphones: (a) 

Omnidirectional. (b) Cardioid. .................................................................................. 24 

Figure 6: Linear Microphone Array. (a) Geometry. (b) 3D Directionality Pattern. ......... 27 

Figure 7: Cross-Linear Array and Azimuth Directivity Pattern. ...................................... 28 

Figure 8: Circular Microphone Array and Directivity Pattern.......................................... 29 

Figure 9: Volumetric Microphone Array and 3D Directivity Pattern............................... 30 

Figure 10: Location of Source and Microphones for Time Difference of Arrival. .......... 32 

Figure 11: Simulation Methods. (a) Ray Tracing. (b) Image Source Method. ................. 36 

Figure 12: Source Image Map. .......................................................................................... 37 

Figure 13: Directionality of Human Head. ....................................................................... 39 

Figure 14: Block Diagram of a Typical Speaker Diarization System. ............................. 41 

Figure 15: GMM/i-vector Framework. ............................................................................. 45 

Figure 16: DNN/i-vector Implementation. ....................................................................... 45 

Figure 17: Collaborative Environment (a) with 2D Model (b). ........................................ 51 

xii 

 
 
 
Figure 18: 2D Model of Fig. 12(b) with Microphone Array. ........................................... 52 

Figure 19: Possible 2D Model for Fig. 17. ....................................................................... 56 

Figure 20: Estimation of the Sources. ............................................................................... 60 

Figure 21: Estimation of Virtual Microphones. ................................................................ 60 

Figure 22: Training Samples from Each Speaker and Noise. ........................................... 64 

Figure 23: Audio Segmentation using a VAD. ................................................................. 67 

Figure 24: Block Diagram of the Proposed System.......................................................... 69 

Figure 25: Pyroomacoustics Models. (a) 2D. (b) 3D. (c) 3D With Images. ..................... 75 

Figure 26: LabVIEW Sub VI for Cross-Correlation Calculation. .................................... 82 

Figure 27: LabVIEW Convolution VI. ............................................................................. 84 

Figure 28: LabVIEW Deconvolution VI. ......................................................................... 85 

Figure 29: LabVIEW Correlation VI. ............................................................................... 86 

Figure 30: LabVIEW Cross-Correlation VI. .................................................................... 87 

Figure 31: Audio Lab Components................................................................................... 93 

Figure 32: Audio Lab Setup .............................................................................................. 94 

Figure 33: Common AOLME Environment Setup. .......................................................... 95 

Figure 34: Relative Positions of AOLME Participants..................................................... 97 

Figure 35: Location of Speakers and Real Microphone. ................................................ 100 

Figure 36: 3D Model of the Virtual Room ..................................................................... 101 

Figure 37: Final 2D Model for AOLME Example. ........................................................ 103 

Figure 38: Block Diagram of a Microphone Calibration Setup. ..................................... 105 

xiii 

 
 
Figure 39: (a) Microphone Calibration Jig. (b) Location to Loudspeaker. ..................... 106 

Figure 40: Audio Lab Set-Up for Pyroomacoustics Evaluation. .................................... 108 

Figure 41: Final 2D Model of Audio Lab Setup. ............................................................ 110 

Figure 42: 2D Model for Controlled Experiments. ......................................................... 115 

Figure 43: Video Clips of Dave (Clip1), and HAL (Clip2). ........................................... 117 

Figure 44: Sources and Noise for HAL 9000 Experiment .............................................. 119 

Figure 45: Ground Truth Sets A and B for HAL 9000 Experiment. .............................. 121 

Figure 46: Training Segments for HAL and Dave. ......................................................... 122 

Figure 47:Video Clips for AOLME Experiments. .......................................................... 129 

Figure 48: 2D Model for AOLME Experiments............................................................. 130 

Figure 49: Room Parameters Reader Inputs and Outputs ............................................... 146 

Figure 50: Room Parameters Reader Front Panel. .......................................................... 146 

Figure 51: Room Parameters Reader Block Diagram..................................................... 147 

Figure 52: Room Model Generator Icon. ........................................................................ 148 

Figure 53: Room Model Generator Front Panel. ............................................................ 148 

Figure 54: Room Model Generator Block Diagram. ...................................................... 149 

Figure 55: Source Estimator Icon. .................................................................................. 150 

Figure 56: Source Estimator Front Panel. ....................................................................... 150 

Figure 57: Source Estimator Simplified Block Diagram. ............................................... 151 

Figure 58: Cross-Correlation Model Calculator Icon. .................................................... 151 

Figure 59: Cross-Correlation Model Calculator Front Panel. ......................................... 152 

xiv 

 
 
Figure 60: Cross-Correlation Model Calculator Block Diagram. ................................... 153 

Figure 61: Cross-Correlation Model Calculator. Cross-Correlator Sub-VI.................... 154 

Figure 62: Model Classifier Icon with Inputs and Outputs............................................. 154 

Figure 63: Model Classifier Front Panel. ........................................................................ 155 

Figure 64: Multi-Function Convolution and Correlator Visualizer Front Panel. ........... 156 

Figure 65: Multi-Function Convolution and Correlator Visualizer Diagram. ................ 157 

xv 

 
 
 
 
LIST OF TABLES 

Table I: Template Cross-Correlation Table for Source 1. ................................................ 64 

Table II: Template Cross-Correlation Table for Source 2. ............................................... 65 

Table III: Template Cross-Correlation Table for Source 2. .............................................. 65 

Table IV: Example Cross-Correlation Table Output from Model Calculator .................. 90 

Table V: Cross-Correlation Tables for Classification ...................................................... 90 

Table VI: Cross-Correlation Table for Microphone Calibration. ................................... 107 

Table VII: Dimensions of Virtual Room and Location of Sources (in m). .................... 109 

Table VIII: Experimental Results for Simulation Software Evaluation. ........................ 111 

Table IX: Distribution of Microphones and Sources for Controlled Experiments. ........ 114 

Table X: DER Results for HAL 9000 Experiments. ....................................................... 124 

Table XI: Multi-Speaker Experiment Sequence Table ................................................... 126 

Table XII: Controlled Environment Experiments Diarization Error Rate Results ......... 127 

Table XIII: Location of Speakers and Microphones for AOLME Experiments. ........... 131 

Table XIV: Speaker Assignment for AOLME Experiments. ......................................... 132 

Table XV: CC Tables for AOLME Experiment. ............................................................ 133 

Table XVI: Classification Results for AOLME Experiments. ....................................... 134 

Table XVII: Experimental Comparison Between Methods. ........................................... 137 

Table XVIII: % Average Error for All Three Methods. ................................................. 138 

xvi 

 
 
 
Chapter 1. Introduction 

The  field  of  speech  processing,  which  includes  speech  recognition,  separation, 

transcription, and enhancement, has undergone several transformational changes. Despite 

significant progress, speaker identification  in  crowded rooms  continues  to  be a  difficult 

problem.  Crosstalk  and  large  amounts  of  background  noise  make  these  environments 

particularly challenging.  Most speaker identification and diarization systems rely on the 

use of Deep Learning methods that require pre-training on large datasets. Speech features 

such as formant frequencies, pitch contours, and coarticulation are extracted from the test 

samples  and  are  eventually  matched  against  a  database  of  training  samples  [1].  The 

databases need to contain as many training examples as possible and should be updated 

periodically to maintain a proper performance level [2]. The accuracy of the identification 

depends on the size of the database: the bigger the database, the better the accuracy, but 

the longer the training times [3]. In addition to long training times, databases are prone to 

bias concerning spoken language and accent [4]. This biasing is usually unintentional and 

unconscious, and it is the product of the environment where the speech recognition system 

is developed [5]. 

The  limitations  of  speech  processing  systems  are  more  evident  in  challenging 

situations such as collaborative environments, meetings, or large-scale educational settings 

in general. These environments commonly  consist  of  multiple  speakers  sitting  around a 

table located inside a room. The speakers can take turns to speak, but it is not unusual to 

1 

 
 
 
have two or more speakers talking at the same time. The environment can also be very 

noisy if we have numerous participants or groups inside the same room. These types of 

environments are too difficult for most speech processing systems, requiring in many cases 

heavy manual analysis. Manual diarization of meetings is a tedious and time-consuming 

task that requires many hours of processing, and it is subject to many interpretation errors.  

There  is  a  need  in  many  educational  research  activities  to  understand  how  the 

classroom material engages the students. To understand how students interact, classroom 

sessions are recorded and transcribed. An important problem here is to determine which 

participant is speaking at a particular moment, what she or he has said, and for how long 

the participant spoke. Automated methods usually require multi-channel audio recordings 

and are prone to errors due to noise and crosstalk. Also, these systems have limitations in 

the number of speakers they can process, as well as the length of the audio segments. While 

diarization  systems  do  not  require  enrollment  of  the  speakers,  they  can  only  generate 

abstract labels of the speaker that is active in an audio segment. On the other hand, speaker 

identification  systems  can  provide  non-abstract  labels  by  enrolling  the  participating 

speakers. The enrollment process  consists  of each  speaker  providing  several  seconds of 

noise-free speech without crosstalk. This requirement cannot be met when the data consists 

of  audio  recordings  of  busy  meetings  with  noisy  backgrounds.  It  is  thus  important  to 

develop speech identification and diarization methods that do not impose any requirement 

to pre-enroll the speakers.   

2 

 
 
This  dissertation  aims  to  provide  the  foundations  of  a  new  approach  to  speaker 

identification  and  diarization  using  virtual  microphones  and  spatial  information. 

Simulations  are  never  perfect,  but  this  work  shows  that  it  is  possible  to  use  an 

approximation  of  a  real  room  geometry  to  obtain  the  acoustic  parameters  necessary  to 

simulate reception in a virtual array of microphones and use these simulated signals for 

speaker diarization and  identification.  The simulation is  based  on  a physical  model that 

requires no databases, it is independent of the spoken language or accent of the participants, 

it does not require prior speaker enrollment, and it presents high immunity to noise. 

The proposed approach relies on the fact that discriminant information about the 

3D geometry of each speaker is embedded in the recorded audio from a single microphone. 

The  basic  idea  is  to  recognize  speakers  using  acoustical  simulation.  As  part  of  the 

simulation process, the proposed method computes the Room Impulse Response (RIR) for 

each of the microphones and the speakers and simulates the reception on each of the virtual 

microphones. The accuracy of the process of computing RIRs is verified through real-life 

measurements of the correlation patterns. Based on the simulated reception over the virtual 

microphones, the method computes correlation patterns  among the virtual microphones. 

The  recorded  audio  is then also  used to  generate  different  correlation  patterns  based on 

hypothesized speaker locations. A classifier is applied to the generated correlation patterns 

to select the most likely speaker location.  

This approach has several advantages.  First, we do not require databases of speech. 

Our  system  is based on  physical models  that  are  unique  to  the scene  we are analyzing. 

3 

 
 
Because we do not have databases to train the model, our system requires capturing only 

about  1  to  2  seconds  of  audio  from  each  speaker  for  both  training  and  recognition.  In 

contrast,  state-of-the-art  systems require tens  of seconds of  clean  audio  for  training and 

several  seconds  of  identification.  Second,  our  system  has  been  conceived  to  operate  in 

noisy  environments  where  microphone  arrays  and  cross-correlation  analysis  have  been 

proven  to  be  efficient  methods  for  speaker  discrimination  [6],[7].  Third,  the  simulation 

does not require multi-channel audio, but it uses a single channel recording as a reference 

for the simulation. Finally, our system can run on simple computers without the need to 

access remote computer clusters or databases.  

1.1  Motivation 

This work is motivated by the need for a reliable non-manual method of assessing 

the  level  of  engagement  of  the  students  participating  in  the  Advancing  Out-of-school 

Learning in Mathematics and Engineering (AOLME) program at the University of New 

Mexico (UNM) [8]. AOLME is a collaborative learning environment where students are 

introduced  to  STEM  subjects  such  as  integrating  computer  programming  and  middle 

school mathematics. It forms part of the educational research activities performed at the 

University  of  New  Mexico’s  Image  and  Video  Processing  and  Communications  Lab 

(ivPCL) [9].  AOLME sessions are video recorded for later analysis that includes students’ 

participation and overall level of attention, as well as the facilitator’s interaction with the 

students. The analysis consists of evaluating the activities of the participants such as hands 

4 

 
 
 
or head movement, use of keyboard and mouse, lip movement, etc., and transcription of 

the sessions to determine the time when a participant is speaking and for how long. Detailed 

participation  statistics  for  each  participant  are  currently  not  available  because  manually 

measuring talking times is time-consuming and plagued with errors. AOLME organizers 

have tried several transcriptions systems currently available in the market or open-source 

code, all without much success. The AOLME environment is extremely challenging for 

any speech recognition and transcription system due to multiple groups talking at the same 

time and the presence of background noise and echo. Hence, there is a need for a robust 

system  that  can  overcome  the  limitations  of  the  current  state-of-the-art  methods  and 

complements  the  ivPCL  methods,  with  the  application  to  process  hundreds  of  hours  of 

video recordings. 

AOLME  video  analysis  presents  other  challenges  in  addition  to  the  presence  of 

multiple speakers and noise. First, these videos  were taken with  a  simple  video  camera 

using  a  single  microphone  located  at  the  meeting  table.  Budget  limitations  restrict  the 

purchasing  and  use  of  more  advanced  equipment  with  multi-channel  audio  recording 

capabilities.  Second,  there are  already  hundreds  of hours  of  these  video  recordings  that 

need to be analyzed. There was no previous speaker enrollment that could be used to train 

a  speaker  identification  system.  Furthermore,  most  participants  only  speak  for  several 

seconds at a time, which makes the identification process more difficult. Even if for future 

sessions  it  is  possible  to record multichannel  audio  and enroll  the speakers,  there  is the 

need to process the existing videos, therefore the need for a flexible method that can handle 

5 

 
 
new and existing recordings. 

1.2 

Related Research 

Assessing  the  level  of  engagement  of  participants  in  collaborative  educational 

sessions requires the application of tools to extract relevant information from audio and 

video data. This information is then interpreted and translated into statistical data for the 

researchers. For this end, these tools can either identify activities in a video scene that are 

related  to  attention  behaviors  (e.g.,  typing  and  writing),  or  they  can  identify  the  active 

speaker or speakers in an audio segment. Related work to this dissertation includes both 

types of tools. 

In  the  area  of  activity  tracking,  it  is  important  to  mention  the  work  by  UNM’s 

ivPCL lab in direct connection with the AOLME program.  Darsey [10], analyzes video 

using  color  and  optical  flow  for  tracking  hand  movement.  Teeparthi  et  al.  [11],  [12], 

presents fast methods of video analysis for hand and object tracking as well. Jacoby et al. 

[13] works in human activity detection using context-sensitive approaches, while Jatla et 

al [14] uses 3D Convolutional Nets. Eiliar et al. [15] provides a maintainable open-source 

activity system.  Detection of attention traits is investigated by Shi et al. [16], using AM-

FM models to detect head direction and group interactions.  

Research on speech processing covers a vast area containing different topics. Under 

the  umbrella  of  speech  processing,  we  find  speech  identification,  speech  enhancement, 

speaker  verification,  speaker  diarization,  and  speaker  identification,  among  others.  This 

6 

 
 
 
dissertation focus on speaker identification and diarization as part of the research labor of 

the ivPCL lab and AOLME programs. 

 Speaker  identification  is  the process  of  recognizing  the  identity  of  a  speaker  or 

several speakers present in a speech segment. Speaker diarization is the process in which 

an audio recording that contains several speakers is dissected into segments that contain 

only one speaker at a time [17]. Speaker Diarization is often defined as “who said what, 

and when”, and for “how long”. Both Speaker Identification and Speaker Diarization are 

important mechanisms in many audio-processing tasks.  

Most  of  the  research  on  speech  processing  nowadays  is  focused  on  the  use  of 

Artificial Neural Networks and Deep Learning. Deep Belief Networks (DBN) are widely 

used in speech recognition [18], [19].  X-vectors  are  considered  today  state  of the art in 

speaker  recognition  [20].  X-vector  methods  outperform  classic  i-vector  methods  in  the 

order  of 9.23%,  and  they  have been  tested  with  datasets  such  as  VoxCeleb,  NIST  SRE 

2016, and SWBD [21]. 

The research in this dissertation focuses on the use of spatial information and virtual 

microphone arrays for speaker identification and diarization. There is no attempt to cover 

methods  that  do  not  use  spatial  information  or  virtual  microphone  arrays  for  speaker 

identification and diarization. Although not as extensive as the neural network and deep 

learning  research,  it  was  possible  to  find  numerous  works  that  demonstrated  the  use of 

spatial  information  for  speaker  identification  and  diarization,  as  well  as  applications  of 

7 

 
 
virtual microphone arrays for acoustic signal enhancement  and meeting diarization. The 

references to these works are presented in the next sections. 

Most  literature  regarding  the  application  of  microphone  arrays  (multichannel 

audio) and beamforming is related to the implementation of spatial filters to improve the 

signal-to-noise  ratio  (SNR).  Nevertheless,  several  researchers  found  ways to exploit the 

operational principles of microphone arrays and apply them to speaker identification and 

diarization. Xavier Anguera et al. [22] propose the use of beamforming algorithms as the 

forefront of a speaker diarization system. These beamforming algorithms take advantage 

of the environment commonly encountered in meetings, such as multiple microphones, to 

enhance a single signal of interest. Anguera et al. optimize a conventional delay and sum 

beamforming array to operate under the constraints of an unknown number of speakers, 

unknown location of both speaker and microphones, and microphone mismatching. The 

Time  Differential  of  Arrivals  (TDOAs)  of  the  microphones  are  calculated  by  cross-

correlation. Diarization is accomplished by agglomerative clustering where each cluster is 

modeled via a Gaussian Mixture Model (GMM). A separate set of GMMs is used to model 

the TDOA features.  

In  a  similar  manner  as  Anguera,  Mitianoudis  et  al.  [23]  propose  the  use  of 

beamforming  in  parallel  with  Independent  Component  Analysis  (ICA)  for  audio  source 

separation.  The  ICA  for  source  separation  requires  knowledge  of  the  parameters  of the 

mixing matrix. If these parameters are not known, then the separation problem becomes a 

Blind  Source  Separation  problem  (BSS),  which  is  an  ill-posed  problem  (multiple 

8 

 
 
solutions). Mitianoudis et al. propose the use of the directivity pattern of beamforming (use 

of phase information) to select signals among different possible permutations.  

Both  previous  authors  exploit  the  phase  information  of  signals  captured  by 

microphone arrays. In my research, I also exploit the phase information (TDOA between 

microphones) as a means of determining the relative position of the active speaker and thus 

the identity.  The previous work shows the use of cross-correlation to calculate the TDOA. 

Klein  et  al.  [24]  study  the  performance  of  the  multi-channel  cross-correlation  (MCCC) 

coefficient  method  as  a  robust  solution  to  calculations  of  TDOA  under  noisy  and 

reverberant  environments.  Padois  [25]  studies 

the  performance  of  time-domain 

beamformers  based  on  the  generalized  cross-correlation  functions.  Padois  generates  a 

sound source map by interpolating the cross-correlation function between microphones, to 

generate a two-dimensional hyperbola of the spatial likelihood function. The number of 

hyperbolas  corresponds  to  the  number  of  microphones  used  in  the  array.  The  source 

position can be determined by averaging the hyperbolas and determining their maximum 

value as the intersecting point for the location. In general, the experimental results show 

that  resolution  improves  with  the  number  of  microphones,  up  to  a  number  where  the 

performance seems to plateau.  

Pasha et al. [26] present work that is closely related to our research on RIR and 

room geometry for TDOA estimation. Pasha et al. propose a method of source localization 

that utilizes RIRs amplitudes to fit a TDOA surface and an amplitude surface across a room 

of  known  geometry.  The  RIR  is  obtained  from  a  set  of  microphones  of  an  unknown 

9 

 
 
location.  The RIR  amplitudes  of  the  direct  path  impulses  are  higher  and  have  a  shorter 

relative time of arrival for the signals that are closer to the receiving microphone. The area 

with the maximum amplitude and minimum delay is considered the estimated source area. 

The center of these  areas is the  estimated source location. Similar work  was  previously 

presented  by  Tervo  et  al  [27],  but,  instead  of  source  location,  this  work  focuses  on 

localization of acoustic reflections using the combined TOA and the TDOA information 

contained in the RIR.    

All the work presented so far takes advantage of the properties of beamformers, 

TDOA,  TOA,  DOA,  and  cross-correlation,  but  also  requires  an  array  of  physical 

microphones. In this dissertation, the method depends only on the information captured by 

a single microphone. Research material on single microphone acoustic separation based on 

spatial information is more limited, as well as work on virtual microphone arrays for the 

same purpose. Nevertheless, there is interesting work that provided useful information for 

my work. Perhaps the closest work to my research that I found is presented by Hu et al. 

[28]. Hu et al. propose a method to utilize the reverberant information, known as the Direct-

to-Reverberant Ration (DRR), from a single channel recording for Speaker Diarization. Hu 

et al. estimate the DRR using the algorithm from Peso Parada et al. [29] and combine it 

with  a  Mel-Frequency  Cepstral  Coefficient  (MFCC)  diarization  method  proposed  by 

Vijayasenan  et  al.  [30].  The  principle  is  to  use  both  MFCC  and  DRR  features  in 

combination  so  a  trained  system  can  perform  a  clustering  type  of  classification.  The 

estimates  for  the  DRRs  are  computed  using  features  such  as  Signal-to-Noise  ratios, 

10 

 
 
MFCCs, power spectrum, and zero-crossing rates. It is important to notice that this work 

was  tested  only  using  simulated  meeting  recordings  and  assumes  that  the  speakers  are 

stationary. 

Because  the  research  work  in  this  dissertation  proposed  virtual  microphone 

simulations, it is necessary to present some relevant work in this area. Yoshioka et al [31] 

describe a way of linking several recording devices, such as laptops or mobile phones, to 

create a virtual microphone array. Once the link has been established, the multi-channel 

audio  can  be  used  for  speaker  diarization.  Yoshioka  et  al.  claim  to  achieve  a  13.6% 

diarization rate when 10% of the speech duration contains more than one speaker.   

The Yoshioka et al. approach is very innovative but requires the presence of several 

recording devices in the meeting room. More aligned with this dissertation is the work of 

Katahira et al. [32], Del Galdo et al. [33], and Izquierdo [34]. Here the authors propose 

methods  to  simulate  arrays  of  microphones  by  interpolating  the  signal  received  by  two 

physical microphones. The authors demonstrate that the virtual microphone arrays improve 

the  SNR  in  reverberant  environments,  hence  their  potential  application  for  speech 

processing  devices.  Even  though  these  methods  succeed  in  emulating  a  set  of  virtual 

microphones,  they  need  at  least  two  physical  microphones  as  “seed”,  which  are  not 

available for the method presented in this dissertation. 

Finally, Tapia et al. [35] presented a bilingual speech recognition method inspired 

in the research presented in this dissertation. Tapia utilizes still video frames to estimate 

the approximate geometry of the speakers and simulate the center microphone reception 

11 

 
 
using Pyroomacoustics. The simulated audio is used along with ALOME transcriptions to 

generate the training sets for a convolutional neural network.  

1.3 

Thesis Statement 

The main objective of this dissertation is to develop a method that applies spatial 

information and virtual microphone arrays to identify multiple speakers in a single channel 

audio recording of a collaborative environment and provide activity statistics of each of the 

participants. 

This method is aimed to succeed in challenging environments with multiple active 

speakers and background noise, conditions that make the current state-of-the-art methods 

perform poorly. For this purpose, the work in this dissertation presents the implementation 

of  an  acoustic  model  based  on  a  virtual  room  of  rough  similar  geometry  to  the  actual 

acoustic scene being analyzed, and then the simulation of the signals received by a virtual 

microphone array located in the virtual  scenario.  The signal delay  between each  virtual 

microphone represents the relative physical position of the active source that in this case is 

each  speaker.  The  research  goal  is  to  find  a suitable  way  to  extract  the  spatial  location 

embedded into a single channel recording to implement the model and subsequent virtual 

microphone array. 

1.4 

Contributions 

 The contributions expected from this work include: 

12 

 
 
 
 
  A method to identify speakers in a collaborative environment by extracting spatial 

information from a single channel audio recording utilizing an acoustic simulation 

and virtual microphones.  

  A  solution  for  the  limitations  of  current  state-of-the-art  speaker  identification 

methods concerning: 

o  Multiple speakers 

o  Speaker gender or accent 

o  Background Noise and reverberation. 

  Development of speaker identification framework that is based on an explainable 

model developed in terms of the physical characteristics of the problem, and hence 

does not require large datasets to train many parameters. 

  The basis for a tool for quantitative analysis of video recordings for assessing the 

level of interaction of participants in collaborative environments. 

1.5 

Dissertation Overview 

This dissertation is divided into 6 chapters that cover background theory and other 

related work, a description of our method, experiments, and results, and conclusion and 

recommendations for future work. The dissertation is presented as follows: 

  Chapter 2 gives a background of audio spatial theory and its applications in speaker 

diarization and identification, and how they functionally compare with other state-

of-the-art methods. 

13 

 
 
 
  Chapter  3  presents  the  foundations  on  which  the  proposed  method  in  this 

Dissertation is based and a block diagram of its implementation. 

  Chapter  4  describes  the  practical  implementation,  including  software,  model 

implementation, simulation ions, video analysis, and audio segmentation. 

  Chapter 5 presents the experimental results obtained when analyzing audio under 

controlled and uncontrolled environments, and the experimental comparison of our 

method against current Google and Amazon speaker diarization methods. 

  Chapter 6 presents a summary of this dissertation and possible future work. 

  Appendix A contains the scripts and pseudo-code for the Python implementation 

of Pyroomacoustics. 

  Appendix B presents the most important LabVIEW Sub-VIs front panels and block 

diagrams. 

  Appendix  C  contains  the  specifications  of  the  equipment  used  in  the  audio 

laboratory. 

14 

 
 
 
 
 
 
Chapter 2. Background 

This  chapter  introduces  the  principles  that  form  the  foundations  that  define  the 

method  described  in  this  dissertation.  The  section  begins  with  basic  acoustic  theory, 

concepts,  and  definitions,  and  continues  with  a  presentation  on  microphones  and 

microphone arrays. It finalizes with an introduction to methods for speaker diarization and 

identification, covering both classic methods and Deep Learning methods. 

2.1 

Acoustics Principles 

The perception of sound by a sound capturing device (e.g., a microphone or human 

ear), not only depends on the characteristics of the sound source, but it also depends on the 

medium where the sound propagates, the physical environment where the sound source is 

located, and the relative locations of the capturing devices and the source. This dissertation, 

considers all these factors to create models that represent the environment where the sound 

sources, i.e., the speakers, are active. 

Chapter  1  presented  a  brief  introduction  to  the  AOLME  program.  The  AOLME 

video recordings were taken inside rooms where the participants gather in groups sitting 

around  tables.  The  exact  geometry  of  the  room  is  unknown,  but  the  video  recording 

provides  clues  about  the  location  of  the  speakers,  the  separation  between  them,  their 

physical height, and the location of the recording microphone. These clues can be used for 

modeling a virtual room which can be defined as a three-dimensional enclosed space where 

15 

 
 
 
 
the acoustic event takes place. This virtual room may not be necessarily the whole space 

where all the AOLME participants are, but it can be the space surrounding the participants 

in a single table. The approximate geometrical and physical characteristics of the virtual 

room allow us to emulate the reception on arrays of virtual microphones.  

2.1.1 

Sound Propagation: Near and Far Fields 

Consider an acoustic source such as a person speaking, a stereo system playing a 

song,  or  a  running  ventilation  fan.  Sound  from  these  sources  propagates  in  the  form  of 

circular air pressure waves, away from the source. They can propagate in all directions if 

the source is in an open field (Fig. 1a), or directionally if the source is in proximity to a 

non-conducting medium such as a wall (Fig.1b). In acoustic theory, the relative location of 

a source to a point in space determines its field location. A source is in the near field if its 

distance to a point is less than one wavelength of the acoustic signal it is emitting. Sources 

that are located at distances greater than one wavelength are located at the far-field. The 

field location of a source plays an important factor when modeling the perception of sounds 

wave at a point in space. 

16 

 
 
 
Figure 1: Propagation of Sound Waves. (a) Free Field. (b) Directional. 

Fig. 2 shows a representation of the near field, the transition zone, and the far-field. 

In  the  near  field,  the  sound  waves  behave  turbulently,  with  more  circulation  than 

propagation. At about a distance of one wavelength from the source, the sound waves begin 

transitioning  into  propagation.  At  more  than  one  wavelength,  sound  waves  mostly 

propagate into the infinite. A point located at the near field perceives the sound waves as 

circular while one located at the far-field will consider these waves planar [36]. 

17 

 
 
 
 
 
Figure 2: Near and Far-Field Areas. 

2.1.2 

Sound Propagation: Direct Path, Reflections, and Reverberation 

The perception of sounds varies depending on whether the listener is located inside 

a theater room, small dormitory, or an open field. These differences in perception are the 

result  of  the  behavior  of  the  sound  waves  when  they  propagate  across  a  medium.  To 

visualize this phenomenon, consider for example a room where there is one acoustic source 

S (a person speaking) and one microphone M, as represented in Fig. 3. 

18 

 
 
 
 
 
Figure 3: Direct and Reflected Paths for Sound Propagation in a Diffuse Field. 

In Fig. 1(a) and Fig. 1(b), sound from the source will reach an observer or receiver 

directly, from one direction without reflections. In this case, the source is said to be in an 

acoustic  free  field.  Fig.  3,  in  contrast,  represents  a  diffuse  field.  In  this  case,  the  sound 

reaches the microphone  from more than  one direction due  to  reflections.  As in  the free 

field, the direct signal received at the microphone is characterized by the distance from the 

source to the microphone. This distance determines the sound pressure at the microphone, 

and the time it takes from the sound wave to reach the microphone. This time is known as 

the Time of Arrival (TOA), and it is a function of the speed of the sound in the room and 

the  Euclidian  distance  from  the  source  to  the  microphone.  Each  reflection  contributes 

similarly. 

The signal received at a microphone can be expressed in mathematical terms. If we 

consider a signal s(t) from an acoustic source located in the far-field, this signal is captured 

19 

 
 
 
 
 
by a microphone as a signal x(t) that is the convolution of the Room Impulse Response 

(RIR) h(t) with additive noise w(t) as given by: 

𝑥(𝑡) = 𝑠(𝑡) ∗ ℎ(𝑡) + 𝑤(𝑡)              (2.0). 

The RIR is unique for every two points in the room and depends on the geometry 

of the room, the absorption of the materials in the room, and the frequency of the sources 

[37].  The RIR  consists  of  three  parts:  the  direct  path,  the  early  reflections,  and  the  late 

reverberations. The direct path component is determined by the Euclidian distance of the 

source to the microphone, and it is a function of the Time of Arrival (TOA) or the time it 

takes for the signal to travel from the source to the microphone. The other two components 

of the RIR are related to the reflections of the sound waves at the walls and objects in the 

room. The early reflections usually arrive 5 ms after the direct path. The late reverberations 

arrive 20 or 30 ms after the early reflections begin. 

 The RIR can then be expressed as the summation of each of the impulse responses 

corresponding to the direct path and the reflections: 

(cid:3012)

ℎ(𝑡) = (cid:3533) ℎ(cid:3038)(𝑡) + 𝑚(𝑡)
(cid:3038)(cid:2880)(cid:2869)

              (2.1), 

where K is the number of reflections, k is the index number of the reflection, and m is the 

measurement noise. The RIR lasts until the reverberation energy decays to 60 dB on what 

20 

 
 
 
 
 
 
is known as the T60 time. The T60 was calculated empirically by Sabine in 1890 and can be 

expressed as: 

𝑇(cid:2874)(cid:2868) =

55.25 ∙ 𝑉
𝑐 ∙ 𝑆 ∙ 𝑎

                               (2.2), 

where V is the total volume of the room, c is the speed of sound, S is the total surface of 

the room, and a is the absorption coefficient of the room (0 to 1). The reverberations are 

characterized by the frequency of the sources but, in the case of the early reflections, this 

influence  is  minimum  [27].    Fig.  4  depicts  a  representation  of  a  RIR  with  its  three 

components.  

Figure 4: Representation of the Room Impulse Response and its Components. 

21 

 
 
 
 
 
 
 
The path of the reflections from the walls can be represented as direct paths coming 

from  imaginary  sources  called  Images.  The  signal  at  any  microphone  would  be  then 

represented by the number of contributing sources plus their image reflections. All acoustic 

reflections are subject to a TOA that depends on the distance of the path of the reflection. 

Section 2.3 presents more detail on the concept of acoustic images and their role in room 

simulation. 

2.2 

 Microphones and Microphone Arrays 

The  previous  section  introduced  microphones  as  devices  capable  of  capturing 

sound. In general terms, microphones are sensing devices that detect changes in air pressure 

and  convert  these  changes  into  electrical  signals.  Microphones  are  categorized  by  their 

electrical conversion type and their directionality pattern. Deep technical details for each 

type  of  conversion  and  directionality  pattern  microphone  are  out  of  the  scope  of  this 

dissertation. The dissertation will only consider the type of microphones used during the 

research. 

2.2.1  Classification of Microphones 

This research used two types of physical microphones: Condenser omnidirectional, 

and condenser cardioid. The condenser term refers to the type of electrical conversion of 

the  sound,  and  the  terms  omnidirectional  and  cardioid  refer  to  the  directionality  of  the 

microphone.   

22 

 
 
 
 
Condenser microphones work by utilizing a variable condenser that detects the air 

pressure changes. The change in pressure translates into a movement of the plates of the 

condenser thus changing its capacitance.  The changes in capacitance are measured by the 

changes in the charging current in a circuit. Condenser microphones are also known by the 

name of electret. They are the most popular type of microphones today. 

The directivity pattern of a microphone determines its gain or sensitivity according 

to the direction of the incoming sound. Omnidirectional microphones are equally sensitive 

to  incoming  sound  from  any  direction.  These  microphones  are  simple  pressure  sensing 

devices or acoustic monopoles. Cardioid microphones are also known as pressure gradient 

microphones,  and  they  are  characterized  for  a  directionality  pattern  that  is  like  a  heart 

(hence their name cardioid, from the Greek “heart”). Fig. 5 shows the typical directivity 

pattern for omnidirectional (a) and cardioid (b) microphones [38]. All AOLME videos were 

recorded using Audio-Technica ATR3350 condenser omnidirectional microphones.  

23 

 
 
Figure 5: Polar Pattern Plot of Directivity of Two Types of Microphones: (a) 

Omnidirectional. (b) Cardioid. 

Regardless of their type., all microphones generate noise. The conversion of sound 

pressure  waves  into  electrical  signals  carries  electrical  noise,  which  has  a flat  spectrum 

[39]. Manufacturers usually indicate the electrical noise of their microphones in a Signal 

to noise ratio (SNR) number at a certain sound level. Appendix C contains the technical 

specifications of the microphones used for this research. 

2.2.2  Microphone Arrays 

When two or more microphones are arranged into a geometric pattern, they become 

a microphone array. Microphone arrays have important functional properties that are of 

24 

 
 
 
 
 
 
interest when capturing sound in noisy environments, or when directionality is needed to 

discriminate between sound  sources. An  important  part  of  the  results  of  our research is 

based on the functional characteristics of microphone arrays. 

Microphone arrays allow for the incorporation of spatial dimensionality to sound 

capturing. The difference between the signals captured by any two microphones separated 

a distance d provides information that can be used for source localization, tracking, and 

general noise reduction. 

Microphone arrays can be expressed mathematically by (2.3) 

                                            𝒙 = 𝑠𝒅 + 𝒗                                  (2.3), 

where x represents the vector of all microphone signals, s is the source audio signal, d is 

the propagation vector represented in (2.4), and v is the additive noise [40]. The vector d is 

expressed by (2.4) 

𝒅(𝑓) = [𝑎(cid:2869)𝑒(cid:2879)(cid:2870)(cid:3095)(cid:3033)(cid:3099)(cid:3117) … . 𝑎(cid:3041)𝑒(cid:2879)(cid:2870)(cid:3095)(cid:3033)(cid:3099)(cid:3289) … . 𝑎(cid:3015)𝑒(cid:2879)(cid:2870)(cid:3095)(cid:3033)(cid:3099)(cid:3263)](cid:3021)          (2.4), 

where an represents the attenuation factor  1

(cid:3415) (𝑛) , 𝜏𝑛 is the channel delay  𝑑(cid:3046) 𝑐(cid:3415) (𝑛) and  
𝑑(cid:3046)

𝑑(cid:3046)(𝑛) is the distance between the source and a microphone n, with c the speed of sound. 

The fine details of the theory behind microphone arrays are out of the scope of this 

dissertation. Nevertheless, it is important to have a basic knowledge of the properties of 

25 

 
 
 
 
 
 
microphone  arrays  due  to  their  applications  in  source  localization,  spatial  filtering,  and 

source separation. All of these are applications related to this research and will be discussed 

later in this section. 

2.2.2.1  Microphone Arrays Configurations 

The  possible  geometries  of  microphone  arrays  are  infinite.  These  different 

geometries are guided by the number of microphones that can practically be allocated to 

an  array,  and  the  type  of  acoustic  scenario  the  array  is  intended  to  operate.  The  most 

common types are linear, circular, and volumetric (3D) [41]. 

a)  Linear Microphone Arrays: 

In this type of array, the microphones are linearly arranged. Fig. 6(a) represents a 

five-microphone  array  with  a  separation  of  0.05  m  between  microphones.  This  array 

configuration is very popular, and it is designed to capture the sound that is in front of it. 

This type of array cannot distinguish from sounds that are coming from the same angle to 

the axis of the array, as the sound waves will arrive at the microphones with the same time 

delay.  Fig.  6(b)  shows  the  directivity  pattern  of  the  microphone  array  of  Fig.  6(a), 

calculated at 450 Hz with the speed of sound c = 343 m/s. 

26 

 
 
 
Figure 6: Linear Microphone Array. (a) Geometry. (b) 3D Directionality Pattern. 

A  variant  of  this  type  of  array  is  a  cross-linear  array,  also  known  as  a  planar 

microphone array. This type of array consists of two linear arrays perpendicular to each 

other,  as  shown  in  Fig.7.  This  is  the  type  of  array  used  in  this  dissertation  for  virtual 

microphone simulations. 

27 

 
 
 
 
 
Figure 7: Cross-Linear Array and Azimuth Directivity Pattern. 

b) Circular Microphone Array: 

This microphone array has its elements positioned circularly. They can consist of 

one circle, or several concentric circles, as shown in Fig. 8. This type of array is commonly 

found in conference equipment that is in the center of a meeting table.  

28 

 
 
 
 
 
Figure 8: Circular Microphone Array and Directivity Pattern. 

c) Volumetric (3D) Array: 

This type of array forms a lattice with its elements, as shown in Fig. 9. They can 

capture sound from any direction, for as long as they are “suspended in the air” with no 

other interference. Their shape can vary as cubes, spheres, or cylinders. 

29 

 
 
 
 
 
Figure 9: Volumetric Microphone Array and 3D Directivity Pattern. 

2.2.2.2  Spatial Aliasing 

Signal aliasing occurs when the sampling frequency is less than twice the largest 

signal frequency component. When the bandwidth of the signal is greater than half of the 

sampling frequency, spectral overlapping happens.  

Spatial  aliasing  occurs  similarly.  To  reconstruct  a  spatial  signal  from  a  set  of 

samples, it is necessary to have a spatial sampling period that is less than half of the signal 

wavelength  [42].  In  microphone  arrays,  the  phase  difference  between  two  microphones 

should be less than π  to avoid  spatial aliasing [43].    This  constraint  means  that  given a 

signal of frequency f, there is maximum distance 𝑑 between microphones before spatial 

aliasing occurs, and vice versa. For an audio signal of wavelength λ, this distance is half of 

the wavelength:  

30 

 
 
 
 
 
𝑑  ≤

𝜆(cid:3040)(cid:3036)(cid:3041)
2

                               (2.5), 

which translates to a maximum frequency of   

𝑓(cid:3040)(cid:3028)(cid:3051) ≤  

𝑐
2𝑑

                              (2.6), 

where 𝑐 is the speed of sound. 

2.2.2.3  TDOA and Cross-Correlation 

A very important property of microphone arrays is the Time Difference of Arrival 

(TDOA) between microphones. The TDOA is defined as the difference in time a signal 

takes to reach two points separated by a certain distance  𝑑. To understand this concept, 

assume there are two microphones 𝑀𝑖 and 𝑀𝑗 separated by a distance d, and sound source 

S located at distances 𝐷𝑖 and 𝐷𝑗 from microphones 𝑀𝑖 and 𝑀𝑗 , respectively, as shown in 

Fig. 10:  

31 

 
 
 
 
 
 
Figure 10: Location of Source and Microphones for Time Difference of Arrival. 

The difference in the distance ∆𝑫 between 𝐷𝑖 and 𝐷𝑗 is defined as:  

                          ∆𝑫 = 𝑐 ∗ (∆𝑡)                                  (2.7), 

where 𝑐 is the speed of sound and ∆𝑡 is the TDOA between 𝑀𝑖 and 𝑀𝑗. Conversely, if d 

and ∆𝑡 are known, it is possible to determine 𝐷𝑖 or 𝐷𝑗 if one of them is known. From (2.7), 

it is also possible to infer the proximity of the source to either microphone by the sign of 

∆𝑫. Because ∆𝑡 = 𝑡(cid:3036) − 𝑡(cid:3037), a positive ∆𝑡 indicates that 𝑀𝑖  is closer to the sound source than 

𝑀𝐽, whereas a negative ∆𝑡 indicates the opposite.  

The signal delay between microphones 𝑀𝑖 and 𝑀𝑗 can be also expressed in terms of 

their  cross-correlation  (CC).    Let  𝑟(cid:3036),(cid:3037)(𝑡) = 𝑥(cid:3036)(𝑡) ⊛ 𝑥(cid:3037)(𝑡)  denote  the  cross-correlation 

32 

 
 
 
 
 
 
 
between microphone signals 𝑥(cid:3036)(𝑡), 𝑥(cid:3037)(𝑡) corresponding to the microphones 𝑀𝑖 and 𝑀𝑗. The 

CC 𝑟(cid:3036),(cid:3037)(𝑡) between these two signals is defined as: 

               𝑟(cid:3036),(cid:3037)(𝑡) ≜ E(cid:3427)𝑥(cid:3036)(𝑡)𝑥(cid:3115)(cid:3365) (𝑡)(cid:3431)                                  (2.8). 

The normalized cross-correlation is defined by: 

𝑅(cid:3036),(cid:3037)(𝑡) =

(cid:2869)

(cid:3028)∙(cid:3029)

 𝑟(cid:3036),(cid:3037)(𝑡)                                  (2.9), 

where the 𝑎, 𝑏 are defined using 𝑎 =   (cid:3495)∑ 𝑥(cid:3036)

(cid:3047)

(cid:2870)(𝑡)

  and  𝑏 =   (cid:3495)∑ 𝑥(cid:3037)

(cid:3047)

(cid:2870)(𝑡)

. 

2.2.2.4  Beamforming and Spatial Filters 

The process of filtering each of the outputs of the microphones of an array into a 

single output is known as beamforming. Beamforming steers the array’s directivity pattern 

into a particular direction using beamforming filters [40]. The combination of the signals 

from each microphone is governed by: 

𝑦 = 𝒘𝑯𝒙                                            (2.10), 

33 

 
 
 
 
 
 
 
 
 
where  w  represents  the  beamforming  filters  and  𝒘𝑯 is  the  conjugate  transpose.  The 

beamforming filters can be estimated as a function of a propagation vector d and a noise 

correlation matrix Q using: 

                              𝒘 =

𝑸(cid:2879)(cid:2869)𝑑
𝒅(cid:3009)𝑸(cid:2879)(cid:2869)𝒅

                                         (2.11).                                   

The  filter  described  in  equation  (2.11)  is  known  as  the  Minimum  Variance 

Distortionless Response (MVDR), and it is one of the most popular types of beamforming 

filter. Refer to [31] for a full explanation of beamforming filters. 

If the location of the sound sources d is known, it is possible to construct a spatial 

filter for each of the sources. This approach is used to minimize crosstalk between channels 

and  for  noise  reduction.  The  details  of  Spatial  Filtering  are  outside  the  scope  of  this 

dissertation. Nevertheless, a brief introduction is presented because future work proposed 

in this dissertation includes a possible combination of the proposed method with spatial 

filtering and beamforming for speaker separation. 

2.3  Modeling of Room Acoustics 

The proposed research requires the modeling of room acoustics. The simulation of 

microphones and sources are all based on physical models that predict the effects of the 

acoustic reflections given the geometry of the room and the location of the speakers. To 

this  end,  simulations  calculate  RIRs  to  the  target  points.  The  methods  to  model  room 

34 

 
 
 
 
 
acoustics are dived into two categories: geometrical acoustics-based and wave acoustic-

based  [44].  Geometrical  acoustics-based  methods  work  by  capitalizing  the  reflection 

properties of sound, i.e., sounds reflect into smooth surfaces in the same way light does, 

following Snell’s law. These methods are relatively easy to implement but do not take into 

consideration the roughness of the reflective surface. On the other hand, wave acoustic-

based methods take into consideration the characteristics of the sound wave, providing a 

more  accurate  simulation.  In  contrast  with  geometry  methods,  wave  methods  are  more 

computationally intensive and are limited to  low-frequency  ranges  [45].  The simulation 

package used for this research is geometry acoustic-based; wave acoustic-based methods 

are not considered in this dissertation. 

The two more common geometry acoustic-based methods of modeling are the Ray 

Tracing  Method  and  the  Image  Source  Method.  This  dissertation  focus  on  the  Image 

Method as this method is the one used by the simulation package. 

2.3.1  Ray Tracing Method 

The Ray Tracing Method assumes that sound radiates from the source as several 

rays [44] whose energy is the total energy of the source divided by the number of rays. 

These rays propagate at the speed of sound and, when they reach a boundary surface, some 

of the energy is reflected in an angle 𝛼′ equal to the incidence angle 𝛼, as it is shown in 

Fig. 11 (a). The perceived sound at any point is represented by an echogram that contains 

the history of all the ray reflections [45] plus the direct ray. The Ray Tracing Method was 

35 

 
 
 
introduced in the late 1960s and was widely used until the 1980s. Ray Tracing is a relatively 

straightforward method, but its resolution is limited [45]. 

2.3.2 

Image Source Method 

The  Image  Source  Method  (ISM,  also  known  as  Mirror  Image  Source  Method 

MISM), is perhaps the most popular modeling method in use [46]. Image methods are used 

to solve physics problems, and in the late 1970s, Allen and Berkley [46], [47] introduced 

an algorithm to RIR related applications. 

In the Image Source Method, a virtual image or specular reflection of the source is 

created perpendicularly to the source, as shown in Fig. 11 (b). The sound received by the 

sensor 𝑀 is the summation of the sound from the source 𝑆 and the image source 𝑆′. 

Figure 11: Simulation Methods. (a) Ray Tracing. (b) Image Source Method. 

36 

 
 
 
 
 
The ISM needs the amplitude and delay of the image sources to calculate the RIR. 

Because  there  are  infinite  possible  reflection  paths,  the  ISM  creates  a  map  of  mirrored 

rooms with the position of the number of desired images, as shown in Fig. 12. 

Figure 12: Source Image Map. 

The  coordinates  of  each  of  the  images  are  calculated  using  the  map  with  the 

corresponding room size and the position of the source. Once the position of the images is 

calculated, the Euclidian distance 𝑑(cid:3041) from the image 𝑛 to the source is used to calculate 

the delay 𝜏(cid:3041) =

(cid:3031)(cid:3289)
(cid:3030)

 , where 𝑐 is the speed of sound inside the room. 

Finally, the amplitude 𝐴(cid:3041) of each of the signals from the images is calculated by 

the reflection coefficient 𝛽(cid:3041) of each of the walls crossed by the path from the image to the 

sensor, using (2.12) [46]: 

37 

 
 
 
 
 
 
 
𝐴(cid:3041) =

𝛽(cid:3041)
4𝜋. 𝑑(cid:3041)

.                                                   (2.12). 

The RIR ℎ(𝑡) is calculated using the amplitude and the delay for the images: 

ℎ(𝑡) = (cid:3533) 𝐴(cid:3041) ⋅ 𝛿(𝑡 − 𝜏(cid:3041))                             (2.13),

(cid:3041)∈ℕ

where ℕ represents the image sources and 𝛿 is the impulse function. 

2.4 

Characteristics of the Human Speech 

The performance of the method described in this dissertation will improve if the 

acoustic models are tailored to human speech. Human speech has some characteristics that 

can be exploited and used to compensate for some of the deficiencies encountered with the 

approximation of the geometry of the room and the limitations of the modeling software.  

 Two  characteristics  of human  speech:  fundamental  frequency  and  directionality 

are  of  particular  importance.  Speech  is  a  non-stationary  signal,  or  rather  said,  a  non-

stationary process, meaning that its frequency content is not unique in any given interval 

of time. The fundamental frequency of the human voice varies from 85 Hz to 180 Hz, with 

women  going  up  to  255  Hz,  and  children  to  300  Hz  and  even  higher  [48].  The  whole 

spectrum of the human voice contains frequencies that go up to 8kHz. Much of the energy 

38 

 
 
 
 
 
 
 
 
is found in frequencies that are below 500 Hz for males and 800Hz for females [49]. As a 

curiosity note, the frequency sensitivity of the human  ear is very close to the frequency 

spectrum of the human voice. This research work focus on the fundamental frequency to 

develop the acoustic models. More detail is presented in the Experimental Implementation 

section of this dissertation. 

The  other  important  characteristic  of  human  speech  is  its  directionality.  Speech 

does not propagate equally in all directions, but rather has directionality due to the location 

of the mouth and the shadow cast by the head and the torso [50]. Fig. 13(a) depicts the 

propagation of sound in the horizontal direction, while Fig. 13(b) presents the propagation 

in the vertical axis. Lower frequencies propagate farther from the back of the head than 

higher frequencies. Most propagation occurs at the front of the head. This directionality 

property is utilized for positioning the speakers in the simulation models. 

Figure 13: Directionality of Human Head [50]. 

39 

 
 
 
 
 
2.5 

Speaker Diarization and Identification 

Section 1.2 presented a background on several methods for speaker diarization and 

identification  that  relate  to  this  research.  To  understand  the  differences  between  these 

methods  and  the  method  proposed  in  this  research,  this  next  section  reviews  the 

fundamentals on which some of these methods are based on. Reviewing in detail all the 

methods  presented  in  section  1.2  requires  an  effort  that  goes  beyond  the  scope  of  this 

dissertation. For this reason, this dissertation only focuses on the most recent and common 

methods of speaker diarization and identification.  

2.5.1  Methods for Diarization and Identification 

Speaker  diarization  can  be  summarized  as  “who  said  what,  and  when”,  and  for 

“how long”. The task of determining for how long one speaker has been active in a multi-

participant  conversation  requires  speaker  diarization  and  subsequent  identification  with 

non-abstract  labels.  Speaker  identification  should  not  be  confused  with  speaker 

verification. A system that accepts or rejects the  identity  claim by a speaker is  called  a 

speaker verification system. This dissertation divided these methods into two categories: 

Classic methods and Deep Learning methods.  

2.5.1.1  Classical Methods for Diarization and Identification 

Anyone  conducting  a  web  search  for  “speaker  diarization  and  identification 

methods” will find thousands and even millions of documents that somehow relate to the 

40 

 
 
 
 
subject (by the time of this dissertation, “speaker diarization methods” gave 66,400 hits, 

“speaker  identification  methods”  about  48,000,00  hits,  and  “speaker  diarization  and 

identification methods” some 121,000). Nevertheless, until researchers started using Deep 

Learning  and  Neural  Network  methods,  most  speaker  diarization  and  identification 

methods consisted of four basic modules or steps: A feature extraction module, a speech 

or  voice  activity  detector  (SAD  or  VAD,  respectively),  a  segmenter  or  speaker  change 

module, and finally, a clustering mechanism [51], [52]. Fig. 14 shows a block diagram of 

the four modules.  

Figure 14: Block Diagram of a Typical Speaker Diarization System. 

The feature extraction module generally uses Mel-Frequency Cepstral Coefficients 

(MFCC) as features. Not as popular as MFCCs, Linear Frequency Cepstral Coefficients 

(LFCC), and Perceptual Linear Predictive are also used as features [52].  

The purpose of the speech activity module (SAD), also known as the voice activity 

module (VAD), is to detect the presence of speech. SADs or VADs (hereon referred to as 

41 

 
 
 
 
 
 
VAD) eliminate audio segments that contain no necessary information, such as noise or 

music, thus improving the performance of the segmenting and clustering modules. There 

are  several  different  algorithms  for  these  detectors,  that  vary  from  just  energy  level 

detection  to  binary classifiers  based on  pre-trained  speech  models.  This research  uses  a 

custom-made VAD to segment the audio into frames, as it will be shown in later chapters. 

The  next  module  to  follow  is  the  segmenter  or  speaker  change  detector.  The 

segmenter  detects  when  there  is  a  speaker  change  in  the  audio  and  creates  frames  that 

ideally  only  contain  one  speaker.  This  is  a  necessary  step  before  clustering,  where  the 

grouping  of  the  clusters  is  done  without  previous  information.  A  common  method  of 

segmentation is to measure the distance between two segments. Segments that belong to 

the same speaker are usually closer in distance than those coming from a different speaker. 

The  models  are  usually  Ergodic  Hidden  Markov  Models  (HMMs),  where  each  state 

represents  a  speaker,  and  the  probabilities  are  modeled  by  Gaussian  Mixture  Models 

(GMMs).  Bayesian Information Criterion (BIC) is used to determine the nearest clusters, 

merging the clusters that generate the highest BIC, stopping the process when the values 

of the BIC are no longer positive. This algorithm was introduced by Chen et al. [53] and it 

is defined as (2.14) for a parametric Gaussian Mixture Model (GMM) with clusters 𝐶 with 

features [51] 

𝐵𝐼𝐶(𝑀) = log ℒ (𝑋|𝑀) −

𝜆
2

#(𝑀) log(𝑁)                    (2.14), 

42 

 
 
 
 
where 𝑁 is the number of samples, #(𝑀) is the number of parameters of the model, and 𝜆 

is a tunable parameter. 

The final clustering step groups together segments that belong to the same speaker. 

In  most  speaker  diarization  and  identification  approaches,  clustering  is  achieved  by 

agglomerative  hierarchical  clustering  (AHC).  Using  the  same  distance  concept,  each 

segment is its cluster at the beginning of the process, and parts of clusters are merged until 

the stopping criterion is met. This criterion is ideally to get the number of clusters equal to 

the number of speakers. In practical terms, the stopping criterion is a threshold that is preset 

at the beginning of the process. 

2.5.1.2  Deep Neural Networks 

The  applications  of  Deep  Neural  Networks  (DNNs)  to  speaker  diarization  have 

gained a lot of momentum in recent years. It is difficult to keep pace with the amount of 

research that is done on an almost monthly basis in this field. It is therefore of importance 

to  have  a  basic  understanding  of  how  DNNs  are  applied  to  the  problem  of  speaker 

diarization. 

In general terms, DNN speaker diarization/identification methods are divided into 

four groups [54]: Stage-wise, end to end, online, and multimodal. From these groups, this 

dissertation  will  address  stage-wise  and  multimodal  groups  as  they  relate  more  to  the 

research work. 

43 

 
 
 
 
2.5.1.2.1  Stage-wise diarization 

Stage-wise diarization methods are based on the same blocks or stages as the GMM 

methods covered in the previous section, but they rely on DNNs that employ a universal 

background model (UBM), rather than GMMs for feature extraction and clustering. For 

GMMs  to  be  computationally  efficient  for  feature  extraction,  each  sequence  of  feature 

vectors is converted into a fixed-length vector, or supervector [55]. Because this approach 

makes  GMMs  susceptible  to  speaker  and  channel  variations  of  utterances  [56],  it  is 

desirable  to  reduce  the  dimensionality  of  the  supervectors.  These  lower-dimensional 

vectors are called  i-vectors (the i-vectors were previously  referenced in  the background 

section).  The  representation  of  i-vectors  assumes  that  speaker  and  channel-dependent 

variabilities  reside  in  a  lower-dimensional  space  [57],  which  is  represented  by  a  total 

variability matrix T. For GMMs this conversion can be expressed as: 

𝑠 = 𝑠(cid:4593) + 𝑇𝑤                                              (2.15), 

where  𝑠′  is the speaker  and  channel  supervector and  𝑤  is  the i-vector.  Fig.  15  shows a 

GMM/i-vector framework [56]. 

44 

 
 
 
 
 
Figure 15: GMM/i-vector Framework. 

At this point, the effort moved to replace the GMM generated i-vectors for DNN 

generated  i-vectors.  The  idea  behind  this  approach  is  to  replace  the  GMM  generated 

posteriors for the feature vectors and take a DNN trained acoustic model using senones to 

generate these posteriors. Fig. 16 represents this approach [54]. 

Figure 16: DNN/i-vector Implementation. 

Although the performance of DNN based acoustic models has been proven [56], 

they require a large set of training data and more computational cost as well. 

45 

 
 
 
 
 
 
 
 
 
 In addition to i-vectors, other DNN approaches include the use of d-vectors and x-

vectors embedding. D-vectors were introduced by Variani et al. (2014), and they are based 

on  assigning  the  ground  truth  training  utterance  to  labels  of  the  training  frames  to  the 

corresponding utterance in the training stage, converting the problem into a classification 

one. For a more detailed description of d-vectors, refer to [54],[56]. 

X-vectors  are  derived  from  d-vectors.  Instead  of  using  frame-by-frame  speaker 

labels, they use utterance-level speaker labels by aggregation. As was referred to in the 

background section, x-vectors outperform most i-vector and d-vector approaches. Refer to 

[54], [56], for details on x-vectors. 

Deep  Learning  clustering  techniques  are  also  applied  in  replacement  of 

conventional distance and similarity methods. Clustering is treated as either a supervised 

or unsupervised problem, by employing recurrent neural networks (RNN) or discriminative 

sequence-to-sequence neural networks. References to these methods can be found in [54]. 

2.5.1.2.2  Multimodal Speaker Diarization 

Related to our  approach  of exploiting video  clues  and  spatial information, Deep 

Learning is applied to the analysis of not only visual clues, such as movement of lips [58], 

but also to the content of the speech of the participants [59], [60]. In this sense, multimodal 

methods  train  the  networks  based  on  the  patterns  that  most  likely  belong  to  a  genre  of 

participants. For example, in a collaborative environment with students, the facilitator is 

more likely to have a calm voice, in contrast with the students. In recent publications, W. 

46 

 
 
 
Kang  et  al.  [61],  have  presented  speaker  diarization  based  on  d-vectors  combined  with 

spatial information provided by microphone arrays.   

2.5.2  Current State-of-the-Art Methods for Diarization and Identification 

State-of-the-art methods cover the speaker diarization and transcription that major 

technology players are offering. They keep their technologies a secret, as they compete to 

have  the  most  reliable  service  available,  thus  the  difficulty  in  obtaining  detailed 

information on how their methods work. It is expected that they somehow use the speaker 

diarization approaches reviewed in the previous sections.     

IBM, Google, Amazon, and Microsoft offer cloud computing that includes speech 

processing services based on algorithms that use Deep Learning and Machine Learning. 

Amazon’s, Google’s, and Microsoft’s are all closed-source cloud services that provide an 

API  for  speech-to-text  processing  and  speaker  diarization.  This  dissertation  reviewed 

Amazon’s  Transcribe  (AWS)  [62],  Google’s  Cloud  [63],  and  Microsoft  Azure  Speech 

Services [64], and experimentally compared Amazon’s and Google’s against our proposed 

system. 

Amazon’s Transcribe accepts either audio files or streaming data, single-channel, 

and outputs text files with speaker diarization if this option is selected, and the number of 

speakers  is  specified.  Amazon’s  Transcribe  works  better  with  2-5  speakers,  and  it  is 

language-dependent,  limited  to  120  minutes  of  audio.  Amazon’s  Transcribe  stores  the 

voice data to train the models [65] unless the users select the option to delete this data. 

47 

 
 
 
Amazon offers a highly trained set of models called Amazon Transcribe Medical which is 

aimed at medical transcriptions. Users can also customize the vocabulary to better fit their 

needs. Amazon functionality can be accessed via REST and SOAP protocol over HTTP 

[66]. 

Google’s Cloud works similarly, with an interface for long speech, single-channel 

input for transcription purposes [65]. The optimum number of speakers is set at a maximum 

of 5. As with Amazon Transcribe, Google offers the option of privacy that prevents data 

logging  that  could  be  used  to  improve  the  models.  Google’s  models  are  optimized  for 

phone conversations or videos, accepting 16 kHz or 8 kHz audio, respectively, depending 

on  the  application  [67].  It  also  offers  vocabulary  customization.  Google  offers  good 

scalability, infrastructure, and payment  schemes  that  are  considered  the  best  among the 

technology giants [66].  

 Microsoft offers speaker diarization utilizing its Cognitive Services. Microsoft’s 

Diarization system ranked first at the VoxSRC challenge 2020 by achieving a Diarization 

Error (DER) of 3.71% in development and 6.23% in evaluation testing [68]. The datasets 

consisted of audio collected from YouTube recordings. For the challenge, the network was 

trained with 1500 hours of simulated mixed training audio. Microsoft Speaker Recognition 

[69]  offers  text-independent  speaker  recognition/verification.  The  speakers  need  to  be 

enrolled to create a signature, which is later compared with the audio to be analyzed. The 

minimum requirements are 20 seconds of speech for training, and 4 seconds of speech for 

identification,  with  unlimited  speaker  enrollment,  with  only  one speaker  present.  In  the 

48 

 
 
case  of  diarization,  Microsoft  can  only  recognize  up  to  two  speakers.  Microsoft 

Transcription  requires  multi-channel  audio  for  diarization  and  the  signature  of  the 

participating  speakers  for  identification,  labeling  each  speech  segment  with  its 

correspondent speaker. Microsoft does not collect users’ voice tracks to train its models. 

Users can customize their vocabulary and the environment they are expecting to operate, 

meaning that  customization  must include noise,  indoor  or outdoor  environments,  multi-

gender speech, etc. [64]. 

49 

 
 
 
 
Chapter 3. Proposed Method 

The  previous  chapter  discussed  the  principles  of  acoustics,  speech,  and  speaker 

diarization  that  served  as  the  foundations  for  this  research.  This  chapter  will  cover  the 

mathematical models that are used to estimate the virtual microphones, and how they are 

implemented into a working system. Finally, it will present a block diagram detailing the 

function of each of the elements of the proposed system and its operation. 

3.1  Methodology 

The goal of this dissertation is the identification of speakers from single-channel 

recordings  using  virtual  microphones.  This  statement  includes  the  objective  (identify 

speakers), the data source (single  channel  recording),  and  the  means  to  accomplish this 

objective (using virtual microphones). This section will begin by identifying the physical 

and mathematical elements of the models needed for the virtual microphone simulation. 

Let us consider a collaborative environment such as the one represented in Fig. 17 

(a),  where  we  have  three  speakers  sitting  around  a  table  with  a  central  recording 

microphone. Such an environment can be represented as a simple 2D model shown in Fig. 

17(b) that shows the relative location of the speakers and the recording microphone. 

50 

 
 
 
 
Figure 17: Collaborative Environment (a) with 2D Model (b). 

To  capitalize  on  the  properties  of  microphone  arrays,  it  is  necessary  to  find  a 

method to simulate several virtual microphones based on the information contained in the 

signal captured by the central microphone. From the discussion on microphone arrays in 

chapter 2, it is possible to implement several different virtual array configurations.  Let us 

consider a cross-linear array with four microphones and one central recording microphone, 

as shown in Fig. 18.  

51 

 
 
 
 
 
Figure 18: 2D Model of Fig. 12(b) with Microphone Array. 

If  Fig.  18  is  an  ideal  representation,  where  there  are  no  reflections  or  room 

absorption, then for each unique active speaker there will be a set of pairs of microphones 

with unique TDOAs that correspond  to  the  active speaker. For  example,  if speaker 3 is 

active, then the TDOA between M5 and M3 and the TDOA between M2 and M3 will be 

unique for speaker 3. Having this concept in mind, we recall from Chapter 2 that the cross-

correlation from any pair of microphones  represents  the signal delay between  them. To 

uniquely identify each of the speakers, we are interested in the location of the peak of the 

cross-correlation function defined by: 

𝑇(cid:3036),(cid:3037) = argmax 𝑅(cid:3036),(cid:3037)(𝑡)                        (3.0), 

52 

 
 
 
 
 
 
 
where 𝑅(cid:3036),(cid:3037)(𝑡) denotes the cross-correlation between two microphone signals 𝑥(cid:3036)(𝑡), 𝑥(cid:3037)(𝑡). 

If a source signal propagates to microphones 𝑖, 𝑗, 𝑇(cid:3036),(cid:3037) represents the time lag that it 

takes for the signal to reach  𝑗 after reaching 𝑖. Thus, 𝑇(cid:3036),(cid:3037) > 0 implies that the signal arrived 

at  microphone  𝑖  before  𝑗.  On  the  other  hand,  𝑇(cid:3036),(cid:3037) < 0  implies  that  the  signal  arrived  at 

microphone 𝑗 before 𝑖. The cross-correlation matrix of all possible values 𝑇(cid:3036),(cid:3037) will be used 

for determining the locations of the speakers. 

Now we move to the problem of simulating the virtual microphones. From equation 

(2.0) from Chapter 2, it is possible to extend this model for the case of multiple sources 

and microphones. Suppose that we have 𝐽 possible sources: 𝑠(cid:2869)(𝑡), … , 𝑠(cid:3011)(𝑡) and 𝑁 possible 

microphone signals: 𝑥(cid:2869)(𝑡), . . . , 𝑥(cid:3015)(𝑡). Next, let ℎ(cid:3037),(cid:3038)(𝑡) denote the RIR that describes the 

propagation  from  the  𝑗-th  source  to  the  𝑘-th  microphone.  At  the  𝑘-th  microphone,  we 

receive signals from all sources as expressed by: 

(cid:3011)

𝑥(cid:3038)(𝑡) = (cid:3533) 𝑠(cid:3037)(𝑡) ∗ ℎ(cid:3037),(cid:3038)(𝑡) + 𝑛(𝑡)

                         (3.1), 

(cid:3037)(cid:2880)(cid:2869)

where  𝑛(𝑡) represents additive white noise. For the model in (3.1), we need to estimate 

ℎ(cid:3037),(cid:3038)(𝑡). If ℎ(cid:3037),(cid:3038)(𝑡) is known, it is possible, at least in theory, to estimate the signal source 

by deconvolving the signal 𝑥(cid:3038)(𝑡) with ℎ(cid:3037),(cid:3038)(𝑡) (i.e., ℎ(cid:3037),(cid:3038)

(cid:2879)(cid:2869)(𝑡)). Once the sources have been 

estimated, each virtual microphone can be emulated by just convolving the emulated source 

with each of the RIRs of the virtual microphones.  

53 

 
 
 
 
Some important factors need to be considered to develop a model for this approach. 

First, ℎ(cid:3037),(cid:3038)

(cid:2879)(cid:2869)(𝑡) may not exist [70], and it may be necessary to construct virtual microphone 

approximations to ℎ(cid:3037),(cid:3038)(𝑡). Second, the speaker feature correlation matrix defined by 𝑇(cid:3040) is 

estimated under the assumption that speaker 𝑚 is talking while all other speakers remain 

quiet:  𝑠(cid:3038)(𝑡) = 0, 𝑘 ≠ 𝑚. Third, for each audio segment, we need to compute 𝑇, the cross-

correlation matrix of the actual signal. Finally, we need to estimate the active speaker by 

solving  

  match(𝑇, 𝑇(cid:3040))                         (3.2), 

max
(cid:3040)

where match(. , . ) is a function of the similarity between 𝑇, 𝑇(cid:3040).  

We  now  can  turn  our  attention  to  estimating  the  RIRs.  As  it  was  presented  in 

Chapter 2, the RIR is a function of the geometry of the room, the relative location of the 

sources and microphones, and the physics of the room (i.e., the absorption of the room, 

which  characterizes  the  reverberation).  This  information  will  be  very  difficult  if  not 

impossible to obtain from just the audio from the recording microphone, but we could use 

information  from  the  video  recording  to  estimate  some  of  the  parameters  needed  to 

calculate  the  RIR.  From  the  video  recording,  it  would  be  possible  to  approximate  the 

location of the speakers and the virtual microphones to each other. This information, along 

with an empirical approximation of the absorption of the room, is all that is necessary to 

calculate the RIR.  

54 

 
 
 
 
Calculating the RIR can be a very tedious task. The number of calculations required 

is a factor in the degree of accuracy desired in the model. If we recall the concept of images 

from  Chapter  2,  the  reception  at  a  microphone  is  the  result  of  the  sum  of  the  images; 

therefore,  the  fidelity  will  depend  on  the  number  of  images  added  as  part  of  the  RIR 

function.  The  next  chapter  will  present  an  open-source  software  package  that  performs 

these calculations thus saving some programming time. 

So far, this dissertation has presented the fundamentals of the simulation on which 

the proposed method is based. By using the approximate geometry of the room to calculate 

the  RIR  and  to  simulate  the  microphones,  we  should  be  able  to  calculate  the  cross-

correlation between microphones and determine the active speaker. The proposed method 

then can be summarized in 5 steps: 1) Evaluating the room geometry and location of the 

speakers of the acoustic scene, 2) Estimating a generic RIR model for this geometry, 3) 

Training the model with known speaker samples, 4) Estimation of the sources that will fit 

the model for each of the possible active speakers given an unknown audio sample, and 5) 

Conducting  a  Cross-Correlation  Analysis  and  classification.  The  following  section 

explains each of the steps in more detail. 

1)  Evaluation of room geometry and location of speakers and microphones 

As it was described before, the RIR is a unique transfer function between two points 

in space. To calculate the RIR between a source and a microphone, it is necessary to know 

their spatial locations inside a physical room of known acoustic characteristics. In Fig. 17, 

55 

 
 
 
it  is  possible  to  appreciate  the  relative  location  of  the  three  speakers  and  the  recording 

microphone. This video frame can be used as a reference for the location of the sources 

and virtual microphones in the model, e.g., from this image we can approximate that the 

table is about 1.5 meters long by 1 meter wide, that the speakers are separated about 0.7 

meters from each other, and the speaker’s mouths are about 0.24 to 0.25 m from the table. 

It is also possible to locate the reference microphone in coordinates that are relative to each 

of the speakers. These are just approximations to create a generic model from where to 

calculate the RIRs. Fig. 19 shows a possible 2D model for these approximations. 

Figure 19: Possible 2D Model for Fig. 17. 

The location and separation of the virtual microphones can be arbitrary for as long 

as  they  do  not  violate  the  rules  of  spatial  anti-aliasing.  As  presented  in  Chapter  2,  the 

56 

 
 
 
 
 
fundamental frequency of human speech varies from 85 Hz to 180 Hz approximately, with 

some extreme cases going up to 255-300 Hz (children). If it is assumed a max frequency 

average of 180 Hz using (2.6) and (2.7), the maximum separation 𝑑 for each microphone 

would be ≤

(cid:2871)(cid:2872)(cid:2871)

(cid:3288)
(cid:3294)

(cid:2870)((cid:2869)(cid:2876)(cid:2868) (cid:3009)(cid:3053))

= 0.95 𝑚.  

2)  Estimation of the generic RIR model 

The approximation of the geometry of the room provides the basis to implement a 

generic  model  to  calculate  a set  of  RIRs  to  estimate  the  virtual  microphone  array.  This 

model, as it was mentioned before, is based on an approximate geometry of the room, the 

location  of  the  speakers,  and  the  number  of  reflections.  It  is  desirable  to  reduce  the 

influence of reflections and reverberation in the simulation as they add complexity to the 

RIR.  One way  this  can  be  achieved  is  by  an  overall  reduction  of  the  length  of  the  T60. 

Recalling  equation  (2.2),  we  can  minimize  the  volume  of  the  room  and  maximize  its 

absorption  as  a  means  of  reducing  the  length  of  T60.  These  two  parameters  are  easy  to 

control and implement in the simulation. The number of images to calculate can be set to 

an acceptable value that compromises the simulation fidelity and the computational burden. 

Some trial and error may be necessary to optimize the number of reflections.  

Another point to consider is the directionality of the human voice. The human voice 

propagates mostly in one direction to the front of the head; therefore, our model must take 

this propagation inequality when simulating the audio reception at any point of the room. 

57 

 
 
 
One solution implemented in this research consisted of locating the speakers close to the 

end of the virtual room, so the reflections from the back of the speaker are minimized. 

With the approximate physical and acoustical characteristics of the room, it is then 

possible  to  calculate  the  RIRs  between  the  virtual  microphones  of  the  array  and  the 

speakers. It was indicated in the previous section that it could be possible to implement any 

arbitrary array of microphones for as long as we follow the rules of spatial anti-aliasing. 

The calculated value of the distance d is well fitted between the boundaries of the proposed 

model,  but  it  would  be  beneficial  for  the  performance  of  the  model  to  optimize  the 

microphone array for maximum cross-correlation information. This can be accomplished 

by  asymmetric  microphone  arrays,  i.e.,  arranging  the  microphones  at  locations  that  are 

offset from equidistant points to the speakers. Also, the microphone arrays should have as 

many microphones as possible, for as long as the required computational resources remain 

manageable. 

3)  Estimation of sources and virtual microphones 

The  next  step  is  to  apply  our  generic  model  to  estimate  the  signal  at  the  virtual 

microphone array based on the recorded signal at the reference microphone. To do so, it is 

necessary first to estimate the sources that would fit the model, i.e., estimate a set of sources 

that, when convolved with the model’s RIRs, will represent the signal at each microphone 

of the array, including the reference microphone. One way to estimate the sources is to 

deconvolve the reference signal with the RIR that corresponds to the source we want to 

58 

 
 
 
estimate. For example,  assume that our model  has  three  sources  𝑠(cid:2869)(𝑡), 𝑠(cid:2870)(𝑡) and 𝑠(cid:2871)(𝑡), 

three microphones M1, M2, and M3, with M3 as the reference microphone. If 𝑥(cid:2871),(cid:3037)(𝑡) is the 

signal  received  at  M3  with 𝑗 = 1,2,3    for  the  respective  sources  𝑠(cid:2869),  𝑠(cid:2870),  and 𝑠(cid:2871),  then  to 

estimate 𝑠(cid:2869)(𝑡), 𝑠(cid:2870)(𝑡), and 𝑠(cid:2871)(𝑡) given 𝑥(cid:2871),(cid:3041)(𝑡) 

𝑠̃(cid:2869)(𝑡) = 𝑥(cid:2871),(cid:2869)(𝑡) ∗ ℎ(cid:2871),(cid:2869)

(cid:2879)(cid:2869)(𝑡)                                    (3.3), 

𝑠̃(cid:2870)(𝑡) = 𝑥(cid:2871),(cid:2870)(𝑡) ∗ ℎ(cid:2871),(cid:2870)

(cid:2879)(cid:2869)(𝑡)                                    (3.4), 

𝑠̃(cid:2871)(𝑡) = 𝑥(cid:2871),(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2871)

(cid:2879)(cid:2869)(𝑡)                                    (3.5), 

with ℎ(cid:2871),(cid:2869)

(cid:2879)(cid:2869)(𝑡) the inverse of ℎ(cid:2871),(cid:2869)(𝑡) (RIR from M3 to 𝑠(cid:2869)),  ℎ(cid:2871),(cid:2870)

(cid:2879)(cid:2869)(𝑡) the inverse of ℎ(cid:2871),(cid:2869)(𝑡) (RIR 

from M3 to 𝑠(cid:2870)), and ℎ(cid:2871),(cid:2871)

(cid:2879)(cid:2869)(𝑡) the inverse of ℎ(cid:2871),(cid:2871)(𝑡) (RIR from M3 to 𝑠(cid:2871)). Fig. 20 shows how 

the sources can be estimated for the example of Fig. 17 and the model of Fig. 19. Once the 

sources have been estimated, they can be convolved with the remaining RIRs to obtain the 

simulated reception on each of the microphones of the array. Fig. 21 shows an example of 

how microphones M1, M2, and M3 are estimated using 𝑠(cid:2870)(𝑡).  The process is extensive to 

the other sources as well. We can use an estimation or the ground truth for microphone M3. 

59 

 
 
Figure 20: Estimation of the Sources. 

Figure 21: Estimation of Virtual Microphones. 

60 

 
 
 
 
 
 
 
 
It may be noticed at this point that the solution presented above will only work if 

we know which  n source is active at  𝑥(cid:2871),(cid:3041)(𝑡), and which ℎ(cid:2871),(cid:3041)(𝑡) we need to deconvolve 

with. To solve this problem, our method simulates each possible source by deconvolving 

the signal at M3 with each RIR of the model and then simulates the signal at each of the 

virtual  microphones.  The  result  is  a  set  of  virtual  arrays  that  correspond  to  each  of  the 

possible active sources. In the three source examples, if 𝑥(cid:2871)(𝑡) is defined as the unknown 

signal  at  M3,  the  estimate  of  both  possible  sources  𝑠̃(cid:2869)(t),  𝑠̃(cid:2870)(t)  and  𝑠̃(cid:2871)(t)  is  obtained  by 

deconvolving 𝑥(cid:2871)(𝑡) with ℎ(cid:2871),(cid:2869)(𝑡), ℎ(cid:2871),(cid:2870)(𝑡) and ℎ(cid:2871),(cid:2871)(𝑡):  

𝑠̃(cid:2869)(𝑡) = 𝑥(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2869)

(cid:2879)(cid:2869)(𝑡)                     (3.6), 

𝑠̃(cid:2870)(𝑡) = 𝑥(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2870)

(cid:2879)(cid:2869)(𝑡)                      (3.7), 

𝑠̃(cid:2871)(𝑡) = 𝑥(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2871)

(cid:2879)(cid:2869)(𝑡)                      (3.8), 

and  then  emulating  two  sets  of  virtual  microphones.  Each  set  of  the  microphones  is 

represented  as  𝑥(cid:3028),(cid:3029),  where  a  is  the index  of the virtual  set,  b  is  the index  of  the  virtual 

microphone of the set, and ℎ(cid:3030),(cid:3031) is the RIR from source c to microphone d.  

For set 1: 

𝑥(cid:2869),(cid:2869)(𝑡) = 𝑠̃(cid:2869)(𝑡) ∗ ℎ(cid:2869),(cid:2869)(𝑡),                    (3.9), 

61 

 
 
For set 2: 

For set 3: 

 𝑥(cid:2869),(cid:2870)(𝑡) = 𝑠̃(cid:2869)(𝑡) ∗ ℎ(cid:2869),(cid:2870)(𝑡),                   (3.10), 

 𝑥(cid:2869),(cid:2871)(𝑡) = 𝑠̃(cid:2869)(𝑡) ∗ ℎ(cid:2869),(cid:2871)(𝑡).                   (3.11). 

𝑥(cid:2870),(cid:2869)(𝑡) = 𝑠̃(cid:2870)(𝑡) ∗ ℎ(cid:2870),(cid:2869)(𝑡),                     (3.12), 

𝑥(cid:2870),(cid:2870)(𝑡) = 𝑠̃(cid:2870)(𝑡) ∗ ℎ(cid:2870),(cid:2870)(𝑡),                    (3.13), 

𝑥(cid:2870),(cid:2871)(𝑡) = 𝑠̃(cid:2870)(𝑡) ∗ ℎ(cid:2870),(cid:2871)(𝑡).                    (3.14). 

𝑥(cid:2871),(cid:2869)(𝑡) = 𝑠̃(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2869)(𝑡),                    (3.9), 

 𝑥(cid:2871),(cid:2870)(𝑡) = 𝑠̃(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2870)(𝑡),                   (3.10), 

 𝑥(cid:2871),(cid:2871)(𝑡) = 𝑠̃(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2871)(𝑡).                   (3.11). 

62 

 
 
 
4)  Cross-Correlation and Model training 

The  three  sets  of  virtual  microphones  give  us  enough  information  for  cross-

correlation analysis and model training. To train the model, we take a small audio sample 

that contains only one active source (e.g., see Fig. 22), and we then use this information to 

generate a cross-correlation table that contains all combinations of possible sources  and 

microphone pairs for that source. For the training, we include the background noise, as is 

shown in Fig. 22. Training the model for noise is explained later in the implementation 

section. These tables are templates for the classification of each of the active sources. For 

our example of three sources and three microphones, we calculate three cross-correlation 

tables for each known sample processed with filters for s1, s2, and s3, as shown in Table I, 

Table II, and Table III.  

63 

 
 
Figure 22: Training Samples from Each Speaker and Noise. 

Table I: Template Cross-Correlation Table for Source 1. 

r1-2 
V1 
V4 
V7 

𝑠̃(cid:2869),(cid:2869) 
 𝑠̃(cid:2869),(cid:2870) 
 𝑠̃(cid:2869),(cid:2871) 

r1-3 
V2 
V5 
V8 

r2-3 
V3 
V6 
V9 

64 

 
 
 
 
 
 
 
 
 
Table II: Template Cross-Correlation Table for Source 2. 

r1-2 
V10 
V13 
V16 

𝑠̃(cid:2870),(cid:2869) 
𝑠̃(cid:2870),(cid:2870) 
𝑠̃(cid:2870),(cid:2871) 

r1-3 
V11 
V14 
V17 

r2-3 
V12 
V15 
V18 

Table III: Template Cross-Correlation Table for Source 2. 

r1-2 
V19 
V22 
V25 

𝑠̃(cid:2871),(cid:2869) 
𝑠̃(cid:2871),(cid:2870) 
𝑠̃(cid:2871),(cid:2871) 

r1-3 
V20 
V23 
V26 

r2-3 
V21 
V24 
V27 

where   𝑉(cid:2869) … 𝑉(cid:3041) are the values of the cross-correlations 𝑟(cid:2869),(cid:2870), 𝑟(cid:2869),(cid:2871), and 𝑟(cid:2870),(cid:2871) corresponding to 

the microphones M1-M2, M1-M3, and M2-M3 respectively, for each known sample source 

of 𝑠(cid:2869), 𝑠(cid:2870) and 𝑠(cid:2871). Table I will contain the results for the sample 𝑠(cid:2869), Table II for the sample 

𝑠(cid:2870), and Table III for the sample 𝑠(cid:2871). Training needs to be done just once. 

5)  Analysis and Classification 

Cross-correlation  analysis  of  multi-speaker  audio  is  not  possible  unless  this  is 

divided into segments. Proper segmentation of the audio is important to the performance 

of  the  proposed  method.  Because  the  audio  from  collaborative  environments  contains 

multiple  speakers,  it  is  possible  at  any  time  to  have  more  than  one  simultaneous  active 

speaker. Also, it is possible to have periods of noise (there are no periods of silence) or 

65 

 
 
 
 
 
 
 
overlapping  speech  when  one  speaker  finishes  and  another  one  begins  speaking.  For 

optimal  cross-correlation  location  identification,  each  segment  should  only  contain  one 

active speaker at a time. If the audio contains overlapping speech or mixes of speakers, the 

location of the peak value of the cross-correlation between microphones will depend on the 

amount of information from each of the speakers that are contained in the audio segment, 

making the classification more difficult. 

One solution to maximize the probabilities of having only one active speaker in a 

segment is by minimizing its length: the shorter the segment is, the most likely it is to have 

content from only one speaker. There is, however, a limit on the minimum length of the 

segments. The minimum length of the segments is subject to the performance of the cross-

correlation  algorithm.  This  means  the  segments  need  to  be  long  enough  to  contain 

sufficient  information  for  the  algorithm  to  calculate  a  meaningful  cross-correlation.  In 

addition, the total analysis time is affected by the number of segments that need to be cross-

correlated and analyzed, hence the desire of reducing the number of segments. There is 

then a need for optimizing the length of the segments for a balance between the maximum 

information  content  and  the  minimum  overlapping  between  speakers.  Recalling  from 

Chapter 2, the best way to segment the audio is to incorporate a VAD. Ideally, a VAD will 

detect speech content and the change of speakers based on a certain pre-determined energy 

threshold, as shown in Fig. 23. If the energy threshold is properly adjusted, a VAD can be 

effective in producing segments of audio that contain only one speaker at the time, and 

segments that contain mixes of speakers or noise, maximizing their information content. 

66 

 
 
Because  VADs  are  not  perfect,  there  will  be  always  segments  that  could  contain 

overlapping, mixes of speakers, or simply being misclassified. To minimize the number of 

misclassifications, the length of the segments can be limited to a maximum that provides 

an acceptable number of misclassifications. It was found during this research that segments 

that are more than 1.5 s long are prone to misclassifications, while segments of less than 

500 ms are difficult to cross-correlate. 

Figure 23: Audio Segmentation using a VAD. 

Each audio segment will generate a single cross-correlation table that corresponds 

to each of the possible locations of the speakers, as it is done for training. The classifier 

will  then  use  the  cross-correlation  template  tables  from  training  to  compare  with  the 

analysis results and determine the most probable source match. Alternatively, it is possible 

67 

 
 
 
 
 
 
to cluster the cross-correlation results for later classification. Chapter 4 covers the analysis 

and classification methods of this research in more detail. 

3.2 

Block Diagram of the Proposed System 

Fig. 24 presents the block diagram of the proposed method. Chapter 4 covers the 

experimental  implementation  of  each  of  the  modules  in  this  diagram,  except  for  the 

clustering module, which was not implemented for this research.  

68 

 
 
 
 
Figure 24: Block Diagram of the Proposed System. 

The proposed system is divided into 4 subsystems described below: 

1)  Room Geometry and RIR Generator: 

The  first  subsystem  of  the  block  diagram  is  The  Room  Geometry  and  RIR 

Generator (RGRG). This subsystem accepts the room geometry parameters (geometry of 

the room, absorption, location of the speakers and microphones) and calculates the RIRs 

using synthetic speech sources. The RGRG consists of two modules: The Room Parameter 

69 

 
 
 
 
 
Generator (A) and the Room Model Generator (B). The Room Parameter Generator creates 

the  vectors  that  contain  the  geometry  of  the  room  and  the  location  of  the  speakers  and 

microphones  (virtual  and  real).  The  Room  Model  Generator  gets  the  room  geometry 

vectors and calculates the RIRs between the sources and the microphones.  

2)  Audio Pre-Processor: 

The second subsystem is the Audio Pre-Processor (APP). The function of the APP 

is to prepare the single-channel raw  audio for analysis. It consists of two modules: The 

Training Sample Audio (C), and the Segmenter (D). The Training Sample Audio module 

contains  the  training  samples  of  each  of  the  speakers  participating  in  the  audio  to  be 

analyzed plus a sample of ambient noise. These samples are saved as .wav files and labeled 

independently. 

The Segmenter module uses a VAD to create segments of the audio to be analyzed. 

Each segment of audio is saved as a .wav file of variable duration, with a minimum and a 

maximum  length  threshold.  The segments  that  are  less  than  a  predetermined  length  are 

discarded. 

3)  Analysis Subsystem: 

The function of the Analysis Subsystem (AS) is to calculate the cross-correlation 

between  the  emulated  microphones.  The  AS  consists  of  three  modules:  The  Source 

Estimator (E), the Room Model Estimator (F), and the Cross-Correlator (G). The source 

Estimator gets the audio from the APP and deconvolves it with the RIR from the RGRG to 

estimate each possible source. The deconvolution is done to both the audio training samples 

70 

 
 
and  the  segments  for  analysis.  The  Room  Model  Estimator  then  emulates  each  of  the 

microphones  by  convolving  the  estimated  sources  with  each  of  the  corresponding  RIR 

calculated using the model room geometry. Again, this is done for both the training samples 

and  the  analysis  segments.  Finally,  The  Cross-Correlator  module  calculates  the  cross-

correlation between the microphones for each of the possible source combinations, for both 

training and testing.   

4)  Classifier: 

The output of the AS subsystem is  then handled  to  the Classifier.  The  classifier 

creates the cross-correlation sets of tables for training and testing. During training, only 

one table is created for each of the training audio samples. For testing, there is a cross-

correlation table for each possible source for  each of the segments, as  was described in 

section 3.1. There are two possible paths  of  action  once the  cross-correlation  tables are 

available. One path is to just run a clustering algorithm to group each segment in similar 

clusters  or  run  a  classifier  that  selects  the  best  source  that  matches  the  training  cross-

correlation table. This research follows the classifier option, which will be discussed in the 

next section. 

The final component of the Classifier subsystem is the Speaker Metric module. The 

function of this module is to calculate the statistics of each of the participants, e.g., for how 

long they have been active, and when they have been active. In this research, our metrics 

only focus on measuring the total time each participant has been active. 

71 

 
 
 
Chapter 4. Experimental Implementation 

This chapter presents the software and hardware implementation of the proposed 

method presented in Chapter 3. It begins by presenting the software tools for simulation, 

deconvolution, and data handling, and continue with the software implementation based 

on  the  AOLME  environment.  This  implementation  will  be  used  in  the  experiments  of 

Chapter 5 to evaluate the performance of the proposed method.  

4.1 

Software and Hardware Tools 

The  block  diagram  of  Fig.  24  shows  the  need  of  developing  several  software 

modules to simulate the acoustics characteristics of the room, including RIRs and source 

image  calculations,  deconvolution  for  source  estimation,  cross-correlation,  and 

classification.  In  summary,  it  is  necessary  to  have  code  that  performs  the  following 

operations: 

1)  Simulation of the geometry of a room 

2)  Calculation of all the RIRs based on the geometry of the room 

3)  Extraction of audio track from video recording 

4)  Segmentation of audio recording 

5)  Deconvolution of audio for source simulation 

6)  Simulation of microphone array 

7)  Microphone cross-correlation calculation 

8)  Analysis of microphone cross-correlation to identify the active speaker 

72 

 
 
 
 
9)  Calculation of the metrics for each participating speaker. 

Developing code for the above modules is a time-consuming task due to the large 

number  of  mathematical  algorithms  and  calculations  needed.  Fortunately,  there  are 

software packages available and code libraries that simplify the implementation of these 

modules into a software framework for the experimental analysis. This dissertation have 

combined  open-source  code and commercial  software,  saving  a considerable  amount of 

time to the alternative of writing code from scratch. 

4.1.1  Open-Source Code for Room Geometry, RIR Calculation, and Microphone 

Simulation 

The  open-source  community  of  code  developers  offers  an  extensive  variety  of 

software libraries that cover a wide range of  topics,  from  machine  learning  to  financial 

market analysis, including acoustic simulations. Several acoustic simulation packages are 

available on GitHub for download. These packages are mainly designed to simulate the 

acoustics of environments for performing arts, such as theaters, stadiums, and recording 

studios. From these available packages, Pyroomacoustics was selected for RIR calculation 

and microphone simulation. 

Pyroomacoustics [71] is an open-source acoustic simulation package that calculates 

the RIRs and simulates the reception of the audio at a set of virtual microphones located 

inside a virtual room. Pyroomacoustics uses the Image Source Method (ISM) to calculate 

the RIR between a source and any point inside the virtual room. The location of the images 

73 

 
 
 
can be visualized with 2-D and 3-D representations of the geometry of the virtual room and 

the location of the sources and the virtual microphones. After simulating the location of 

the images, Pyroomacoustics calculates the RIRs to the target microphones and convolves 

the sample audio to simulate the reception at the microphones. Pyroomacoustics libraries' 

inputs are the geometry of the room, the location of the sources, the location of the virtual 

microphones,  the  absorption  of  the  room,  the  sampling  frequency,  and  the  number  of 

images to calculate. The outputs for the libraries include a set of arrays containing the RIR 

to each of the microphones and the emulated reception at each of the microphones. Figs. 

25(a) and 25(b) show examples of 2-D and 3-D visualizations from Pyroomacoustics of a 

non-rectangular  room  3  x  5  x  2  meters,  with  a  circular  microphone  array  with  6 

microphones and one source. Fig 25(c) shows the same room with the simulated images.  

These types of representations will be used to approximate the AOLME models discussed 

later. Complete documentation on  Pyroomacoustics  functions and  code  can  be found in 

[72]. 

74 

 
 
Figure 25: Pyroomacoustics Models. (a) 2D. (b) 3D. (c) 3D With Images.  

The version of Pyroomacoustics used for this research (0.4.1) has some limitations 

that needed to be considered when developing the models: 1) Microphones and sources are 

always modeled as omnidirectional. There are no options to add unidirectional sources or 

other  types  of  microphones  (e.g.,  cardioids);  2)  All  rooms  are  square,  with  no  round 

corners;  3)  There  is  no  option  to  add  objects  such  as  tables  inside  the  room,  and  4) 

Absorption is an empirical parameter that needs to be estimated by other means outside the 

software.  

75 

 
 
 
 
 
All  experiments  in  this  research  were  conducted  using  Pyroomacoustics  version 

0.4.1.  For  the  room  geometry  calculations,  Pyroomacoustics  libraries  are  called  from  a 

Jupyter Notebook under Anaconda 3. The libraries were also called from within LabVIEW 

using scripts under Python 3.  

4.1.1.1  Pyroomacoustics Implementation 

Implementation  of  Pyroomacoustics  for  virtual  microphone  simulation  is 

accomplished by four steps that include simulation of the room, placement of the sources 

and  microphones,  calculation  of  the  RIR  from  the  sources  to  the  microphones,  and 

convolution of the sources with the RIR for microphone simulation. This is done by calling 

the classes in the Pyroomacoustics libraries as follows: 

a)  Room Simulation: 

The room simulation contains the parameters of the room, such as its dimensions, 

the absorption, the number of images to be calculated, and the sampling frequency. For 

example, the following script will generate a room of dimensions 9 x 7 x 3 meters, with a 

total of 9 images, at a sampling frequency of 9600 Hz: 

pyroomacoustics.room.Room([9.0,7.0,3.0], fs=9600, max-order=9) 

b)  Sources and Microphone Placement: 

76 

 
 
 
 
 
This script adds the sources and microphones to the model. Pyroomacoustics need 

a valid audio file for source location. The following script will locate a source at X= 2 m, 

Y = 3 m, and Z = 1 m from the origin, and two microphones at X1 = 6 m, Y1 = 4, and Z1 = 

1 m for microphone 1, and X2 = 6 m, Y2 = 4.5, and Z2 = 1 m for microphone 2: 

room.add_source([2.0, 3.0, 1.0], signal=audio) 

mic_locs = np.c_[ 

    [6.0, 4.0, 1.0],  # mic 1 

    [6.0, 4.5, 1.0],  # mic 2 

] 

room.add_microphone_array(mic_locs) 

c)  RIR calculation: 

By calling room.compute_rir() the RIRs are calculated to each of the microphones, 

and the results are saved in the form of a list of lists at the rir attribute of room. 

d)  Microphone Simulation: 

The final microphone simulation is obtained by calling simulate(). This convolves 

the sources with each of the RIRs and emulates the signals in each of the microphones. The 

results of the convolutions are stored in the signals attribute of room.mic_array. 

Appendix  A  includes  some  of  the  scripts  used  in  the  actual  experimental 

implementation  of  Pyroomacoustics.  Refer  to  Pyroomacoustics  documentation  found  at 

[72] for full description of the libraries and their algorithms. 

77 

 
 
 
 
4.1.2  Audio Segmentation 

Recalling from previous discussions, the practical analysis of long audio recordings 

is not possible unless they are segmented into smaller frames. Audio segmentation plays a 

critical  role  in  the  overall  performance  of  the  proposed  method;  therefore,  careful 

consideration should be made with the algorithms for audio segmentation. As previously 

indicated,  the  audio  segments  need  to  comply  with  two  main  requirements:  1)  Contain 

audio  from  only  one  active  speaker  with  minimum  overlapping  or  mixing  between 

speakers,  and  2)  are  of  a  length  that  provides  enough  signal  information  for  cross-

correlation  analysis.  Both  requirements  are  difficult  to  achieve,  and  in  chapter  3  it  was 

introduced the concept of VADs as a segmentation method that maximizes the information 

content  of  a  single  speaker.  Two  segmentation  methods  were  considered  during  this 

research: Fixed Segmentation and Voice Activity Detection. In the end, it was opted for 

VADs due to their better performance results.  

4.1.2.1  Fixed Length Segmentation 

The simplest way to segment audio is to divide it into fixed-length segments. Fixed 

length segmentation is a relatively simple and computationally inexpensive method where 

each audio segment has the same length, independently of their content. Because there is 

no intelligence in this method, there is a probability of some of the segments containing 

overlapping speech. Also, it is very unlikely that the audio can be divided into exactly equal 

parts making the last segment of shorter duration than the others. 

78 

 
 
 
A solution to minimize overlapping is to make the segments as short as possible. 

As it was  discussed  before, if the  segments  are  too short,  they  may  not  contain  enough 

information for calculating the cross-correlation. There is therefore a balance between the 

optimum length of the segments and the desired classification error. 

One empirical way to find the length of the segments is by assessing the audio. If 

the  audio  contains  well-separated  speakers  with  little  overlapping,  the  length  of  the 

segments can be longer  than in acoustic scenes  with noise or disorganized speech. This 

research  conducted  experiments  with  segment  lengths  varying  from  250  ms  to  1.2  s, 

obtaining  different  degrees  of  success.  At  the  end,  fixed-length  segmentation  was 

abandoned  due  to  an  undesirable  number  of  errors  and  a  lower  performance  when 

compared with voice activity detection segmentation. 

4.1.2.2  Voice Activity Detection  

The VAD used in these experiments was programmed using MATLAB by a fellow 

graduate student at the University of New Mexico [73]. He used MATLAB Fast Fourier 

Transform (FFT) and Inverse Fast Fourier Transform (IFFT) functions to convert the audio 

from the time domain to the frequency domain and vice versa. First, the audio is converted 

into the frequency domain by applying the FFT, and then a 3000 Hz low pass filter and a 

1000 Hz high  pass filter  are  applied  to  remove some  of the noise. The filtered  audio is 

brought  back  to  the  time  domain  using  the  IFFT,  and  it  is  normalized  afterward.  An 

Amplitude Trigger (AT) with a threshold of 0.1 is used to determine the presence of speech 

79 

 
 
 
or noise. If the amplitude is exceeded at any time, this will be the beginning of a speech, 

and this time is marked as 𝑇(cid:2869). The level is checked 300 ms after 𝑇(cid:2869). If the AT is exceeded 

again, we mark that time as 𝑇(cid:2870), and check the AT again after another 300 ms. If the audio 

does not exceed the AT, then it is marked as the end of the audio with a time 𝑇(cid:2870) = 𝑇(cid:2869) +300 

ms; otherwise, the end of the audio will be 𝑇(cid:2869) + 𝑇(cid:2870). When the audio does not exceed the 

AT and is not in the time range of speech, it is classified as noise.  

Using  the  information  obtained  from  the  filtered  audio  and  adding  a time  offset 

(250 ms) to compensate for information missing in the filtered audio, we split the audio 

giving a maximum and a minimum time. If a noise segment is too small (under 250 ms), 

they will be combined with the audio segments since this is a pause of a person speaking. 

If there is noise or the audio is too long, it gets split into batches of a maximum time of 

1.2s, with small exceptions that can go up to 1.449s.  

It is important to notice that audio segmentation produces artifacts at the beginning 

and the end of the segment [74]. These artifacts are the familiar “clicks” we hear when 

listening to a sequence of segments. In audio processing, it is common practice to apply a 

window, a filter, and overlap of the segments [74] to allow for a smooth transition between 

them. Our method did not apply windowing or overlapping due to the possibility of altering 

the spatial  content  of the segments; therefore,  it  was  better to  accept  a  reasonable  error 

instead. 

80 

 
 
 
4.1.3 

Implementation Using the LabVIEW Graphical Programming 

This  research  work  used  LabVIEW  for  deconvolution,  array  manipulation, 

classification, metrics, and user interface. LabVIEW is very popular in engineering due to 

its wide variety of built-in functions and its simplicity to create graphical user interfaces. 

It is not an open-source language, requiring the purchasing of a license.  

LabVIEW requires additional toolkits for some advanced digital signal processing, 

statistics, and software integration. This research applied the Advanced Signal Processing 

toolkit  for  cross-correlation  analysis,  convolution,  and  deconvolution  calculations. 

Because Pyroomacoustics was used for all room simulations, it was necessary to install the 

Python Integration Toolkit provided by Enthought. This toolkit provides LabVIEW with 

the capability of calling Python code directly. LabVIEW is then used as a wrapper to call 

Pyroomacoustics Python libraries from within LabVIEW. In this way, LabVIEW provides 

the user interface for the Pyroomacoustics inputs (i.e., room geometry, number of images, 

audio files), and processes the outputs (i.e., RIRs, microphone simulations), saves the data, 

and displays the results. All documents and detailed description of LabVIEW can be found 

at the NI website [75]. 

Instead  of  scripting  code,  LabVIEW  uses  a  graphical  interface  that  contains 

functional  modules  called  VIs  (short  of  Virtual  Instruments).  The  VIs  perform  basic 

functions such as adding, subtracting, array manipulation, and logical operations, among 

others.  There  are  more  advanced  VIs  to  calculate  more  complex  operations  such  as 

convolution  and  inverse  convolution,  correlation  and  cross-correlation,  and  file 

81 

 
 
manipulation, for example. Each VI transfers data using a wired connection, and there is a 

mechanism  to  handle  and  display  execution  errors.  Fig.  26(a)  and  Fig.  26(b)  show  a 

screenshot of the internal block diagram and user interface, respectively, of the LabVIEW 

implementation used during this research for convolution, deconvolution, correlation, and 

cross-correlation  operations  between  two  files.  The  user  can  select  between  any  of  the 

operations  using  a  drop-down  selector.  The  implementation  reads  two  text  files  that 

correspond to the audio files to be analyzed or convolved and a third file that corresponds 

to the RIR for convolution operations only. There are four graphics that represent the input 

files, the RIR, and the output of the cross-correlation calculation. The results can be saved 

as text files for later conversion into audio or any other format. 

Figure 26: LabVIEW Sub VI for Cross-Correlation Calculation. 

82 

 
 
 
 
 
 
 
Despite the popularity of LabVIEW among the engineering community, LabVIEW 

is many times regarded by hard-core coders as a language for those who do not know how 

to code. Its major deficiencies lie in the fact that its built-in functions are rarely modifiable, 

the block  diagrams can  get  confusing if  they  are  not  divided  into  smaller  VIs,  and it  is 

difficult  to  document  and  comment.  The  decision  was  to  use  LabVIEW  because  of the 

time-savings advantages it has over scripted languages.  

4.1.3.1  LabVIEW Implementation 

The code written for this research used several built-in VIs available in LabVIEW 

version 2016, 32 bits. These VIs were implemented into more complex sub-VIs to run the 

calculations,  data  handling,  user  interface,  file  manipulation,  and  display  of  results. 

Although  the code  required  the  use of  dozens  of  different  VIs  for  simple  mathematical 

operations and data flow, important calculations such as convolution and deconvolution 

were handled with LabVIEW built-in functions. 

4.1.3.1.1  Function VIs 

The  three  functions  VIs  in  this  section  were  used  to  calculate  convolution, 

deconvolution,  and  cross-correlation.  They  are  part  of  LabVIEW's  built-in  library  for 

signal processing. The algorithms for these functions are explained next. 

4.1.3.1.1.1  Convolution VI 

83 

 
 
 
 
 
This VI computes the convolution of two vectors x and y. The convolution can be 

computed by selecting either a direct method or a frequency domain algorithm that uses 

the  FFT,  being  the  latter  the  one  used  for  this  research.  The  VI  that  represents  the 

convolution is shown in Fig. 27. Documentation on this VI can be found at [76]. 

Figure 27: LabVIEW Convolution VI. 

The algorithm works by padding the ends of x and y with zeros to make their lengths 

M + N – 1, as shown in (4.0) and (4.1): 

𝑥′𝑖 = (cid:3420)

𝑥𝑖,
0,

𝑖 = 0,1, … , 𝑁 − 1
𝑖 = 𝑁, … , 𝑀 + 𝑁 − 2

                  (4.0), 

𝑦′𝑖 = (cid:3420)

𝑦𝑖,
0,

𝑖 = 0,1 … , 𝑀 − 1
𝑖 = 𝑀, … , 𝑀 + 𝑁 − 2

                  (4.1), 

The convolution is computed by calculating the inverse FFT of the product of the 

FFTs of 𝑥(cid:4593) and 𝑦(cid:4593) 

𝒙(cid:4593)(𝑓) = 𝐹𝐹𝑇(𝑥(cid:4593))                                                  (4.2), 
84 

 
 
 
 
 
 
 
 
 
 
 
𝒚(cid:4593)(𝑓) = 𝐹𝐹𝑇(𝑦(cid:4593))                                                  (4.3), 

𝒙 ∗ 𝒚 = 𝐼𝐹𝐹𝑇(cid:3435)𝒙(cid:4593)(𝑓) ∙ 𝒚(cid:4593)(𝑓)(cid:3439)                             (4.4), 

where IFFT is the inverse FFT.  

4.1.3.1.1.2  Deconvolution VI 

The deconvolution VI computes the inverse convolution of two vectors x*y and y. 

It returns the value of vector x. Fig. 17 shows the symbol for this VI. Documentation on 

this VI can be found at [77]. 

Figure 28: LabVIEW Deconvolution VI. 

This VI implements the deconvolution by computing the Fourier Transform of the 

input x*y and y, then dividing them to create a new vector h. The vector x is computed by 

applying the IFFT to the sequence h. 

85 

 
 
 
 
 
 
 
 
 
 
 
4.1.3.1.1.3  Correlation VI 

The Correlation VI calculates the correlation coefficient r between two vectors x 

and y. Fig. 18 shows the icon for this VI. Documentation on this VI can be found at [78]. 

Figure 29: LabVIEW Correlation VI. 

This  VI  calculates  the  linear  correlation  coefficient,  also  known  as  Pierson’s 

correlation by (eq. number) 

𝑟 =

∑ 𝑧(cid:3051)𝑧(cid:3052)
𝑛

                                               (4.5), 

where 𝑧𝑥and 𝑧𝑦are the standardized z-values of x and y. The standardized z-values indicate 

how many standard deviations x and y are above or below the mean. 

4.1.3.1.1.4  Cross-Correlation VI 

The cross-correlation VI computes the cross-correlation between two vectors x and 

y. The inputs for this VI are the vectors  𝒙𝒕 and  𝒚𝒕, the weighting specifies the use of a 

biased or unbiased weighting in the cross-correlation calculation, being the former the one 

used in all the calculations. The maximum lag specifies the maximum value of the lag this 

86 

 
 
 
 
 
 
 
 
VI uses to compute the cross-correlation. The maximum lag used equals max (M, N) – 1, 

where M and N are the lengths of 𝒙𝒕 and 𝒚𝒕, respectively. Fig. 30 shows the icon for this 

VI. Documentation on this VI can be found at [79]. 

Figure 30: LabVIEW Cross-Correlation VI. 

This VI computes the cross-correlation values between two univariate time series 

𝑿𝒕 and 𝒀𝒕 according to the following equation: 

𝑟𝑥𝑦(𝑘 + 𝑁 − 1) =

1
𝑎 ∙ 𝑏 ∙ 𝑤(𝑘)

𝑁−1
(cid:3533) 𝑋𝑡(𝑛)𝑌𝑡
𝑛=0

(𝑛 + 𝑘),   1 − 𝑁 < 𝑘 < 𝑀          (4.6), 

where  = (cid:3493)∑

(cid:3050)(cid:2879)(cid:2869)
(cid:3041)(cid:2880)(cid:2868)

(cid:2870)(𝑛)

𝑋(cid:3047)

  ,  𝑎 = (cid:3493)∑

(cid:3014)(cid:2879)(cid:2869)
(cid:3041)(cid:2880)(cid:2868)

(cid:2870)(𝑛)

𝑌(cid:3047)

,  𝑿𝒕 has  length  N  and  𝒀𝒕 has  length  M.  The 

length of the output is N+M–1. w is the weighting factor which in our case, w(k) = 1. 

4.1.3.1.2  Operational Sub-VIs 

This section will cover the Sub-VIs that form the core of the code that performs the 

computations needed for the analysis. These Sub-VIs contain the function VIs covered in 

87 

 
 
 
 
 
 
 
 
 
the previous section. Appendix B contains the front panels and block diagrams of these 

sub-VIs. 

4.1.3.1.2.1  Room Parameters Reader 

The  Room  Parameters  Reader  Sub-VI  reads  the  source  locations,  microphone 

locations, and 2D room dimension files created by the Pyroomacoustics Room Geometry 

Generator and formats them for the Room Model Generator Sub-VI. The room absorption, 

the room extrusion, and the number of images to calculate are just a pass thru. Appendix 

B section (a) shows the front panel and blocks diagrams for this Sub-VI. 

4.1.3.1.2.2  Room Model Generator 

The Room Model Generator Sub-VI reads the room geometry parameters formatted 

by  the  Room  Parameters  Reader  Sub-VI  and  runs  the  Python  scripts  that  call  the 

Pyroomacoustics libraries that compute the RIRs for the room model. This Sub-VI also 

reads  the  synthetic  speech  or  noise  .wav  files  used  by  Pyroomacoustics  for  the  RIR 

calculations. The calculated RIRs are saved in .txt files for later retrieval by the Source 

Estimator Sub-VI. The Room Model Generator is used twice, first to calculate the room 

model RIRs for the source estimation, and again to emulate the virtual microphones using 

the  estimated  sources.  Section  Appendix  B  section  (b)  shows  the  front  panel,  block 

diagram, and inputs and outputs with more detail.  

88 

 
 
 
 
 
 
4.1.3.1.2.3  Source Estimator 

The Source Estimator takes the model RIR and estimates all the sources that will 

correspond to the audio segment that is being analyzed. For this estimation, this Sub-VI 

takes the segment of audio under analysis (corresponding to the real recording microphone) 

and deconvolves it with the RIRs for each of the source locations. The emulated sources 

are saved under .txt files for virtual microphone simulation using another instance of the 

Room  Model Generator. Appendix B section (c) shows the details of this Sub-VI and a 

simplified block diagram. 

4.1.3.1.2.4  Cross-Correlation Model Calculator 

This Sub-VI takes the results of the virtual microphone simulation from the second 

run  of  the Room  Model Generator  and  calculates  all  the  cross-correlations  between  the 

virtual microphones. The results are saved as cross-correlation tables and used for training 

and classification. Appendix B section d shows the details of this Sub-VI. 

The  output  of  this  Sub-VI  is  a  table  that  contains  all  possible  cross-correlations 

between microphones for each of the possible sources.  For the three speakers and three 

microphones example, the cross-correlation table would look like the one represented in 

Table  IV.  The  first  row  is  the  cross-correlation  microphone  combinations,  and  the  first 

column is the speakers. The numbers represent the array index where the max occurs.  

89 

 
 
 
 
Table IV: Example Cross-Correlation Table Output from Model Calculator 

1-2 
96 
-32 
5 

1-3 
5 
0 
5 

2-3 
-5 
-83 
-130 

1 
2 
3 

4.1.3.1.2.5  Model Classifier 

The  Model  Classifier  Sub-VI  takes  all  the  correlation  tables,  from  training  and 

testing, and performs the classification by comparing the testing results against the training 

templates. This is a very simple classifier that works by comparing each CC table for best 

similarity. For example, assume that the CC table IV corresponds to the training of speaker 

S1, and the analysis of an unknown audio segment produces the three CC tables shown in 

Table V(a), (b), and (c). The classifier simply counts the number of matches between each 

CC table and the training CC table. In this example, table V(a) has the greatest number of 

matches,  indicating  that  the  unknown  segment  corresponds  to  speaker  1.  Appendix  B 

section (e) shows the icon and front panel. 

Table V: Cross-Correlation Tables for Classification 

1 
2 
3 

1-3 
1-2 
96 
1 
2 
-15 
5 
1 
Total for S1 
(a) 

2-3 
-5 
-3 
-130 

Match 
2 
0 
2 
4 

90 

 
 
 
 
 
 
1 
2 
3 

1 
2 
3 

1-3 
1-2 
9 
1 
-32 
6 
2 
9 
Total for S2 
(b) 

1-3 
1-2 
6 
8 
-2 
2 
5 
5 
Total for S3 
(c) 

2-3 
-1 
-8 
-13 

2-3 
-50 
-8 
-15 

Match 
0 
1 
0 
1 

Match 
0 
1 
1 
2 

4.1.3.1.2.6  Multi-Function Convolution and Correlator Visualizer 

The  Multi-Function  Convolution  and  Correlator  Visualizer  is  a  full  stand-alone 

Sub-VI  used  to  manually  convolve  and  deconvolve  audio  files  and  for  correlation  and 

cross-correlation analysis of files. Appendix B section (f) provides more information about 

this Sub-VI. 

4.1.3.2  Audio Laboratory 

The  purpose  of  the  Audio  Laboratory  was  to  capture  real  audio  in  a  controlled 

environment. This laboratory allowed to conduct experiments knowing the position of the 

speakers  and  microphones  and  control  the  content,  duration,  and  characteristics  of  the 

analyzed  speech.  The  results  from  the  experiments  performed  at  the  audio  lab  were 

91 

 
 
 
 
 
compared  against  the  results  obtained  from  our  proposed  method  and  the  simulation 

software. 

The audio laboratory consisted of a set of microphones, an audio processing device, 

an audio amplifier, loudspeakers, and the computer running the software that captures the 

recordings. The audio laboratory was physically configured to follow the common acoustic 

scene  found  on  the  videos  analyzed  in  this  research.  This  configuration  used  a  set  of 

loudspeakers located at the approximated position of the speakers sitting around a table. A 

set of microphones captured the audio at different locations of the lab, and one microphone 

was located at the same relative position as the recording microphone at the videos.  

Fig. 31 shows a block diagram of the lab components. The set of microphones were 

the same type used in the recording of AOLME video. These microphones were connected 

to the Tascam® Audio Processor. This processor can capture simultaneous audio from all 

six microphones and send it digitally to the computer via USB. The computer processes 

the  audio  using  Tracktion  Waveform®  audio  processing  software  [80].  This  software 

processes  the  audio  from  the  microphones  and  saves  it  in  separate  .wav  files  that 

correspond to each of the microphones. 

92 

 
 
Figure 31: Audio Lab Components. 

The simulation of the speakers is accomplished using a set of four loudspeakers 

connected to a stereo audio amplifier. Speakers 1 and 2 were simulated with the left stereo 

channel, while speakers  3 and 4 were simulated  with the right  stereo channel. A switch 

allows  selecting  between  loudspeakers  1  and  3,  and  2  and  4.  The  lab  also  included  a 

Compact Disk (CD) player located at a certain distance from the table. This CD player was 

used to inject background noise during the  experiments. Fig. 32 shows the actual audio 

laboratory setup where we can appreciate the location of its components. 

93 

 
 
 
 
 
Figure 32: Audio Lab Setup 

4.2 

The AOLME Environment  

The dissertation focuses on the analysis of audio from AOLME videos to assess the 

level of engagement of the participants. The AOLME environment is characterized by the 

presence of background noise, crosstalk, and other interferences that make it challenging 

for speaker identification tasks; therefore, to improve the identification rate, the simulation 

models  must  be  optimized  to  fit  this  environment.  This  section  studies  the  AOLME 

environment to find out how to best adapt the models to the acoustic characteristics of this 

environment and implement these models for the experimental section. 

94 

 
 
 
 
 
  
4.2.1  Characteristics of the AOLME Environment 

Fig. 33 shows a screen capture from one of the AOLME videos analyzed in this 

research.  The  scene  shows  a  typical  collaboration  table  with  four  students  and  one 

instructor.  It is common to have 5 to 10 of these tables, with three to six participants each, 

distributed  in  a  room  of  approximated  dimensions  of  9  x  14  x  2.5  m.  The  camera  is 

recording the audio via a single omnidirectional microphone that is resting on the top of 

the table. In addition to normal room noise, this environment presents other elements that 

make  its  dynamics  more  complex.  For  example,  it  is  typical  to  have  the  participants 

shuffling papers, leaning over the table, eating, speaking simultaneously, and accidentally 

covering the microphone with books or other utensils. Furthermore, there are occasions 

when another staff member walks in and joins the group for a conversation. 

Figure 33: Common AOLME Environment Setup.  

95 

 
 
 
 
The first step in building the models is to approximate the location of the speakers 

and the recording microphone. By analyzing the scene in Fig. 33, it is possible to get some 

clues  that  can  be  used  to  approximate  these  locations.  From  Fig.  20,  it  is  possible  to 

estimate the relative locations of each of the speakers with respect to each other and the 

recording  microphone.  It  is  noticeable  also  that  the  position  of  the  speakers  forms  a 

rectangle  that  can  be translated into  a 3D  figure  whose  bottom  area  is  the  table  and  its 

height is defined by the tallest speaker.  

The second step is to approximate the geometry of the room. From Fig. 33, it is 

possible to recognize that there is a nearby wall behind speakers 1 and 3. The second wall 

is located behind speaker 2 at a farther distance from speaker 2 than the first wall is located 

from  speakers  1  and  3.  There  is  no  indication  of  any  other  wall  or  the  presence  of  the 

celling, which we are assuming exists. It is also assumed that there are other tables nearby, 

but these cannot be seen in Fig. 33. 

4.2.2 

Preparation of the Experimental Models 

As mentioned earlier, the models are based in part on the geometry of the room and 

the location of the speakers. Because this exact information is not available, the models 

need approximations based on the observations made from the video shot.  Also, recalling 

from section 4.1.1, our version of Pyroomacoustics does not allow us to simulate complex 

environments like the one shown in Fig. 33, where we have the participants sitting around 

96 

 
 
 
a table. Fortunately, the models do not need to be perfect, and we can make assumptions 

that will reduce their complexity.  

4.2.2.1  Approximating the Models Using Video Observations 

We are ready to make some assumptions and approximations based on observations 

from  the  video.  Fig.  34  shows  another  frame  from  the  same  AOLME  video  recording, 

where it is easy to estimate the relative distances between the participants. In Fig. 34, H1 

represents the height of speaker 2, while and H2 represents the relative height of speakers 

1, 3, 5, and 4. S represents the separation between speakers, and D represents the width of 

the table. We are assuming also in this observation that speakers 1 and 4 are separated by 

the same distance D.   

Figure 34: Relative Positions of AOLME Participants. 

97 

 
 
 
 
 
In Fig. 34, D can be approximated to the width of two standard commercial tables, 

which we can assume is 0.8 m x 2 = 1.6 m total. Speaker 2 is sitting about half of this 

distance, about 0.8 m from each edge of the table combination. Speaker 1 is close to one 

of the corners of the table, as it is speaker 4. The separation  S between speakers can be 

approximated to 0.3 m, and the recording microphone can be located at half of this distance 

at the center of the table. Finally, H1 can be approximated using as reference the average 

waist to head distance of a young female, to about 0.5m, and  H2 to the average waist to 

head distance of kids 11 years old, to approximately 0.4 m. These values are just examples 

to illustrate the principle on which we are basing the approximations. The actual model 

will not necessarily use these values. 

There  is  no  prior  knowledge  of  the  dimensions  of  the  room  that  can  be  used  to 

approximate its geometry. Observations about the location of the walls and the ceiling only 

provide a reference for the location of two walls. Nevertheless, it is possible to recognize, 

given the appearance of the scene, that the remaining walls are at a greater distance than 

the visible ones. This assumption does not provide a numeric value to the location of the 

walls or the ceiling, but it gives a clue of the behavior of the sound in the room.  

Recalling Section 2.4, the human voice propagates mostly unidirectionally to the 

front of the speaker.  Speakers 1 and 3 will project their voices toward speakers 4 and 5 

and vice versa. Most of the sound energy from speakers 1 and 3 is absorbed by speakers 4 

and 5, with some energy reflected by the table, some traveling to the ceiling of the room, 

and  some  other  amount  propagating  to  the  walls  behind.  The  walls  reflect  the  residual 

98 

 
 
sound energy to speakers 4 and 5, and the process repeats until all the energy is absorbed, 

following the 𝑇(cid:2874)(cid:2868) rule. The same process applies when speakers 4 and 5 are active. In the 

case of speaker 2, there are no reflecting surfaces directly located in front of her, and the 

computer  screen  is  located  at  a  distance  where  the  sound  reflections  from  it  can  be 

considered of minimal influence, making the table the only reflecting surface. Under this 

model,  it  is  possible  to  conclude  that  the  sound  energy  of  the  participants  is  mainly 

contained within the boundaries of the table, and the contributions of the reflections due to 

the walls can be considered in practice as negligible, given the directionality of speech, the 

absorption of the speakers, and the separation of the speakers to the wall and the ceiling of 

the room. 

The  previous  analysis  indicated  that  it  is  not  critical  that  the  models  take  into 

consideration the reflections from the walls, suggesting that the rooms can be modeled as 

to  be  of  infinite dimensions  or  to  have  an  absorbance  that  is  close  to  1.  Unfortunately, 

having a room of infinite dimensions will lead to a problem when modeling the sources. 

As discussed previously, the simulation software only allows for omnidirectional sources 

and microphones. In a wall-less room, Pyroomacoustics will create images from speech 

that equally propagates in all directions from the speaker, which we know is not accurate. 

The solution is to place the sources at very close proximity from the walls of the model and 

make the virtual room of the size of the table, thus reducing the propagation behind each 

speaker to negligible levels.   

99 

 
 
The  analysis  described  above  gives  the  basis  for  a  first  model  representing  the 

location of the speakers and the recording microphone. Recalling the 2D model of Fig. 19, 

we can set up a 2D model based on the acoustic scene of Fig. 34, representing the location 

with respect to the table of the 5 speakers and the real (recording) microphone. Note that 

this model includes a 6th “speaker” that represents the room noise. Representing the noise 

as a separate speaker allows for better discrimination between audio segments containing 

noise and those containing speech.  

Figure 35: Location of Speakers and Real Microphone. 

The Z dimension (room height) needs to be added to convert the 2D model into a 

3D model. Because the perimeter of the room is limited to the size of the table, the table 

itself can be modeled as the floor of the room. With this approach,  all locations will be 

zero-referenced with respect to the table.  

100 

 
 
 
 
 
 
The total height of the room can be approximated in a similar manner as it was done 

for  the  perimeter  of  the  room.  Because  of  the  directionality  of  the  human  voice,  it  is 

expected that there will be a little transmission of voice energy to the ceiling; therefore, the 

reflections coming from above can be neglected. The ceiling can then be located at any 

height for as long it is above the maximum height of the taller speaker. Empirically, this 

value  can  be  set,  for  example,  at  1  m  above  the  table.  The  3D  model  for  the  room 

dimensions and the speakers is shown in Fig. 36. 

Figure 36: 3D Model of the Virtual Room 

The  last  element  needed  to  complete  the  model  is  the  location  of  the  virtual 

microphones. Their location is constrained by the dimensions of the virtual room and the 

maximum anti-aliasing distance between them. Also, it is necessary to consider that the 

array of microphones consists of a set of virtual microphones plus a real microphone, which 
101 

 
 
 
 
 
 
is resting at the top of the table. At this location, the real microphone receives no sound 

reflections from the bottom; therefore, it can be assigned a Z value of zero. Because the 

real microphone is resting on the table, there are mechanical vibrations transmitted from 

the table. To simulate these vibrations, all models in this research include some value for 

the Z component of the real microphone.   

The location of the virtual microphone array can be arbitrary, and the separation 

between  microphones  is  not  critical  because  the  distance  between  two  adjacent 

microphones will never exceed the maximum for anti-aliasing.  However, it is of interest 

to have unique cross-correlation values between microphones. For this, the array should be 

in an asymmetric position with respect to the speakers in such a way that the value of the 

magnitude of the cross-correlation between microphones is different for each speaker. The 

Z value of the virtual microphones can be arbitrary, but because Pyroomacoustics can only 

simulate omnidirectional microphones, it is of advantage to locate them a certain height 

above the reference microphone.  All the models in this research have microphones located 

at approximately the height of the speakers,  allowing for simulation from all directions. 

Fig. 37 shows the complete 2D model derived from the five-speaker AOLME environment 

example.  This  type  of  model  is  used  in  all  experiments  in  this  dissertation,  with  the 

variations needed to fit the objective of the experiment. 

102 

 
 
Figure 37: Final 2D Model for AOLME Example. 

103 

 
 
 
 
 
Chapter 5. Results 

This chapter presents the experiments conducted to evaluate the capability of the 

proposed method to identify speakers in audio segments. The experiments focused on three 

objectives: 1) To determine the suitability of Pyroomacoustics as a simulation package; 2) 

to evaluate the performance of the proposed method for diarizing and identifying speakers; 

and  3)  to  compare  the  performance of  the  proposed  method  against  Amazon  AWS  and 

Google Cloud. These experiments included both real audio recordings from the audio lab 

and AOLME videos. 

5.1 

Evaluation of Pyroomacoustics 

The objective of this experiment  was  to  evaluate Pyroomacoustics as  simulation 

software.  This  experiment  compared  the  cross-correlation  measured  between  real 

microphones  and 

the  cross-correlation  between  emulated  microphones  using 

Pyroomacoustics.  This  experiment  was  performed  using  the  audio  lab,  with  a 

Pyroomacoustics simulation based on the geometry discussed in Chapter 4.  

5.1.1  Microphone Calibration 

All audio recording devices have an electronic delay that varies from equipment to 

equipment.  To  measure  the  real  cross-correlation  between  physical  microphones,  it  is 

necessary  to  measure  this  electronic  delay  for  each  of  the  microphones  and  apply  a 

calibration  factor  if  necessary.  Because  Pyroomacoustics  version  0.4.0  simulates  all 

104 

 
 
 
 
 
microphones as ideal and does not consider any delays, it is necessary to calibrate the real 

microphones to compensate for their delays before comparing them against any simulation. 

One way to calibrate the microphones is to place them in an array configuration 

and locate this array in the proximity to an audio source. Fig. 38 shows a block diagram of 

the components needed to calibrate the microphones. This calibration setup consists of an 

audio source, speaker, sound processor, and microphone array. The audio source is driven 

by  a  signal  generator,  and  the  sound  processor  can  acquire  six  audio  channels 

simultaneously. 

Figure 38: Block Diagram of a Microphone Calibration Setup. 

a)  Calibration Preparation 

   A homemade jig made of cloth pins was used to hold the six microphones for 

calibration. The configuration and separation of the microphones are shown in Fig. 39(a). 

The array of microphones was located next to one of the loudspeakers, as shown in Fig 

39(b). With this configuration, the distance of each microphone to the sound source is about 
105 

 
 
 
 
 
 
the  same  for  all  microphones,  making  the  time  differential  of  arrival  between  them 

neglectable.  

(a) 

(b) 

Figure 39: (a) Microphone Calibration Jig. (b) Location to Loudspeaker. 

106 

 
 
 
 
 
b)  Calibration Execution 

A  450 Hz signal was  applied to the loudspeaker using a signal  generator, to the 

loudspeaker, and the output of the six microphones was collected simultaneously using the 

sound processor and the computer running Tracktion Waveform® software. Each channel 

recording was saved as a separated .wav file of 2 s duration, sampled at 48 kHz. 

To measure the delay between microphones, each of the .wav files was converted 

into  .txt  files  for  cross-correlation  analysis  using  the  Multi-Function  Convolution  and 

Correlator Visualizer Sub-VI. Each combination of microphones was cross-correlated as 

shown in Table VI. The results in Table VI show that Microphones 1, 3, and 6 had zero 

cross-correlation between them. The same was observed between microphones 2, 4, and 5. 

Rather than apply a calibration factor, it is more convenient to segregate the microphones 

into groups and measure the cross-correlation between pairs that belong to the same group. 

Note that the results shown by Table VI correspond to the index of the array where the max 

cross-correlation occurs.   

Table VI: Cross-Correlation Table for Microphone Calibration. 

  1 
s
2 
e
n
o
3 
h
p
4 
o
r
c
5 
i
6 

M

1 
- 
50 
0 
49 
50 
0 

2 
-50 
- 
-50 
0 
0 
-50 

Microphones 
4 
-49 
0 
-49 
- 
0 
-49 

3 
0 
50 
- 
49 
50 
0 

107 

5 
-50 
0 
-50 
0 
- 
-50 

6 
0 
50 
0 
49 
50 
- 

 
 
 
 
 
 
  
 
 
 
 
5.1.2  Audio Lab Setup and Model Configuration 

Fig.  40  shows  the  laboratory  setup  for  this  experiment.  The  setup  follows  the 

general model configuration described in Chapter 4, but the microphones were distributed 

between  the  loudspeakers  to  maximize  the  cross-correlation  value  differences  between 

microphones. The dimension of the lab setup allows for the microphones to be within the 

anti-aliasing distance already calculated of 0.95  m. Microphone 3  was kept  in the same 

location as the recording microphone of the draft model.  

Figure 40: Audio Lab Set-Up for Pyroomacoustics Evaluation. 

The Pyroomacoustics model was set up following the configuration of the audio 

lab. Because the audio lab has only 4 loudspeakers, speakers 5 and 6 were not included in 

the model. The virtual room perimeter was set to the size of the lab table, and the height of 

108 

 
 
 
 
 
the room was set to a value of 1 m. The absorption of the model was set empirically to 0.95 

and  the  number  of  images  at  8.  The  microphone  height  was  set  to  0.025  m  for  all 

microphones,  following  the  observations  made  in  Chapter  3.  Table  VII  shows  the final 

dimensions  of  the  virtual  room  and  the  location  of  the  sources  (loudspeakers)  and 

microphones  used  to  create  the  Pyroomacoustics  model.  The  final  2D  model  geometry 

generated by Pyroomacoustics is shown in Fig. 41. 

Table VII: Dimensions of Virtual Room and Location of Sources (in m). 

Z 

0.25 

0.25 

0.25 

0.25 

--- 

--- 

0.025 

0.025 

0.025 

0.025 

0.025 

0.025 

-- 

-- 

-- 

-- 

Y 

0.79 

0.4 

0.79 

0.01 

--- 

--- 

0.79 

0.01 

0.35 

0.1 

0.7 

0.79 

0 

0.8 

0.8 

0 
1 

Sources 

Mics 

Room 

S1 

S2 

S3 

S4 

S5 

S6 

M1 

M2 

M3 

M4 

M5 

M6 

CORNER 1 

CORNER 2 

CORNER 3 

CORNER 4 
EXTRUDE 

X 

0.4 

0.01 

1 

0.4 

--- 

--- 

0.015 

0.015 

0.9 

1.39 

1.39 

0.7 

0 

0 

1.4 

1.4 

109 

 
 
 
 
 
Figure 41: Final 2D Model of Audio Lab Setup. 

5.1.3  Experimental Execution 

Both  audio  lab  and  simulation  sections  of  this  experiment  used  as  a  source  one 

anechoic male voice of 2 s of duration. The source was played sequentially on each of the 

loudspeakers corresponding to S1, S2, S3, and S4, and it was captured simultaneously into 

the  six-channel  audio  processor,  corresponding  to  each  of  the  microphones.  The  six-

channel audio then was saved as six independent audio files using Tracktion Waveform®.  

The  simulation  with  Pyroomacoustics  used  the  geometric  model  of  Fig.  41. 

Because  there  was  no  need  to  estimate  the  sources,  the  simulation  of  the  reception  at 

microphones M1, M2, M3, M4, M5, and M6 was accomplished by only running the Room 

Model Generator Sub-VI with the geometric model and playing the source at the location 

of speakers S1 to S4. The Sub-VI saved the results of each microphone simulation as a 

separate .txt file.  

110 

 
 
 
 
 
5.1.4  Results 

The  final  analysis  consisted  of  running  the  Multi-Function  Convolution  and 

Correlator  Visualizer  Sub-VI  to  calculate  the  cross-correlation  for  each  of  the  real 

microphone audio files (ground truth) and the simulated microphone audio files. The cross-

correlation was calculated between microphones of the same group as it was determined 

during calibration. There was no need for audio segmentation due to the short duration of 

the sample audio. Table VIII shows the results in ms of the offset between the ground truth 

and the simulated signals, corresponding to a sampling rate of 48 kHz.  

Table VIII: Experimental Results for Simulation Software Evaluation. 

S1 

S2 

S3 

S4 

Sim.  G.T.  Diff  Sim.  G.T.  Diff  Sim.  G.T.  Diff  Sim.  G.T.  Diff 
0.34 
-0.58 

-1.62  0.38 

-0.34  0.24 

-1.24 

0.38 

0.72 

1.56 

1.88 

0.32 

0.20 

0.80 

0.30 

0.68 

0.10 

-1.06 

-1.30  0.24 

0.12 

0.18 

0.30 

0.12 

-1.08 

-0.88  0.20 

-1.90 

-1.56  0.34 

-0.48 

-0.50  0.02 

-1.90 

-1.62  0.28 

0.58 

0.40 

0.18 

0.00 

-0.02  0.02 

1.82 

0.26 

0.48 

1.62 

1.12 

1.96 

0.06 

0.50 

1.46 

0.96 

0.14 

0.08 

0.06 

0.02 

0.20 

-0.60 

-0.32  0.28 

0.02 

-1.98 

-1.56  0.42 

0.16 

-2.58 

-2.08  0.50 

0.16 

-0.56 

-0.50  0.06 

1-3 
1-6 
3-6 
2-4 
2-5 
4-5 

Table  VIII  shows  that  the  simulation  correctly  predicts  the  sign  of  the  cross-

correlation  for  each  of  the  microphone  pairs.  The  maximun  offset  difference  is  0.5  ms 

which corresponds to a difference of 20%, and the average difference is 0.2 m, hence the 

111 

 
 
  
  
 
simulation model appears to be sufficiently accurate for differentiating speakers based on 

their positions.  

5.2 

Controlled Environment Experiments 

The objective of this next set of experiments is to evaluate the performance of our 

method to identify  speakers in  single-channel audio  segments  that  were  recorded  under 

controlled conditions at the audio lab. There were two controlled experiments: The first 

experiment demonstrated the capability of the proposed method to identify two speakers 

based only on their location. The second  experiment demonstrated  the  capability  of the 

proposed method to identify multiple speakers independently of their spoken words. 

5.2.1  Methodology 

The approach for these experiments is to physically emulate an open collaborative 

environment such as AOLME in which we record audio containing speech with a single 

microphone. Because the geometry of the acoustic scene is known, we can create a model 

that numerically follows this real scene, and then evaluate the performance of the proposed 

method using this model. Conversely, by having control over some of the parameters, such 

as the location of the sources, it is possible to experiment with different microphone arrays 

and absorptions values to evaluate the performance of different models.  

The  controlled  experiments used the same audio  lab  configuration  and  the same 

Pyroomacoustics model from the previous experiment. A change was made to the location 

112 

 
 
 
 
of the speakers to better fit the distance that will be used for the AOLME experiments.  

5.2.1.1  Audio Lab and Model Preparation 

Table  IX  represents  the  audio  lab  configuration  for  this  experiment,  with  the 

location  of  the  loudspeakers  and  the  recording  microphone  (MIC3).  The  audio  was 

recorded using the Canon video camera connected with MIC3, and the video recording was 

saved  in  the  internal  SD  card  of  the  camera,  the  same  way  it  is  done  with  AOLME 

recordings. Ambient noise was injected using the CD player with background noise from 

one of the AOLME video sessions. 

113 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
Table IX: Distribution of Microphones and Sources for Controlled Experiments. 

Sources 

Mics 

S1 

S2 

S3 

S4 

S5 

S6 

M1 

M2 

M3 

M4 

M5 

M6 

M7 

CORNER 1 

CORNER 2 

Room 

CORNER 3 

CORNER 4 

EXTRUDE 

X 

0.4 

0.16 

0.65 

0.3 

--- 

0.98 

0.6 

0.65 

0.6 

0.6 

0.6 

0.55 

0.6 

0 

0 

1 

1 

Z 

0.25 

0.25 

0.25 

0.25 

--- 

1.5 

0.025 

0.025 

0.025 

0.025 

0.025 

0.025 

0.025 

-- 

-- 

-- 

-- 

Y 

0.79 

0.5 

0.79 

0.2 

--- 

0.4 

0.6 

0.55 

0.55 

0.45 

0.5 

0.55 

0.65 

0 

0.8 

0.8 

0 

2 

The lab setup was translated into the Pyroomacoustics 2D model shown in Fig. 42. 

Noise is represented as “speaker” S6 and placed it in a relative location that resembles the 

location of the CD player. All sources and microphones kept the same Z coordinate value 

as in the previous experiment (0.25 m), except for the noise S6, which is located at Z= 1.5 

m, to better represent the location of the CD player.  

This experiment (and for all subsequent experiments in this research), used a linear 

cross-type  virtual  microphone  array  with  7  elements,  with  the  recording  microphone 

114 

 
 
 
 
located at the center  of the array. This type of microphone configuration is flexible and 

compact  and  allows  its  implementation  in  other  models  with  different  geometries.  The 

separation  between  microphones  in  the  array  was  set  to  0.05  m,  which  is  a  distance 

commonly found in commercial microphone arrays, which is around 0.025 m to 0.040 m.  

The virtual microphone array is located at an offset position to the loudspeakers, avoiding 

any symmetry with them. This location should provide more distinctive cross-correlation 

results between microphones for better differentiation. 

Figure 42: 2D Model for Controlled Experiments. 

5.2.1.2  Evaluation Criteria 

A  common  method  to  measure  the  performance  of  diarization  systems  is  the 

Diarization Error Rate (DER) [81], [82]. The DER is defined as the fraction of the time 

that is not attributed correctly to a speaker or non-speech [38]. It can be calculated as the 

115 

 
 
 
 
 
 
summation of all errors as follows: 

𝐷𝐸𝑅 =  

(cid:3007)(cid:3002)(cid:2878)(cid:3014)(cid:3036)(cid:3046)(cid:3046)(cid:2878)(cid:3016)(cid:3049)(cid:3032)(cid:3045)(cid:3039)(cid:3028)(cid:3043)(cid:2878)(cid:3004)(cid:3042)(cid:3041)(cid:3033)(cid:3048)(cid:3046)(cid:3036)(cid:3042)(cid:3041)

(cid:3019)(cid:3032)(cid:3033)(cid:3032)(cid:3045)(cid:3032)(cid:3041)(cid:3030)(cid:3032) (cid:3013)(cid:3032)(cid:3041)(cid:3034)(cid:3035)

             (5.0), 

where  FA  is  the  length  of  False  Alarms,  Miss  is  the  length  missed  speech  segments, 

Overlap  is  the  total  length  of  overlapped  speech,  Confusion  is  the  total  length  of 

misclassified segments, and the Reference Length is the total length of the audio reference. 

Overlap was not used in any of the tests. 

5.2.2 

“HAL 9000” Experiments 

The objective of this experiment is to demonstrate that the proposed method can 

identify speakers solely on the location of the speaker and independently of their speech 

characteristics. This was accomplished by using non-anechoic audio as the speech source, 

obtained from a raw video clip of a classic movie. 

Many of the software packages for speech processing found during this research 

provided some sort of test files for evaluation. One of these demos included a phrase from 

the classical 1967 movie “2001, a Space Odyssey”. In this movie, the human crew faced 

the rebellion of the spaceship’s  computer,  “HAL  9000”,  which  after  some  malfunction, 

attempts to kill the crew. The phrase “I’m sorry Dave, I’m afraid I can’t do that” is still 

very  well-known  nowadays  when  we  discuss  the  implications  of  artificial  intelligence 

taking over the control of critical missions.  

116 

 
 
 
 
 
 
 
This experiment used a clip of 128 seconds of duration where this famous phrase 

is spoken. This clip included the conversation between Dave, who is inside a space pod 

(Fig. 43, clip1), and HAL at the mothership (Fig. 43, clip2). The video scenes switched 

between the space pod and the spaceship, with voices coming from radio transmissions, or 

the inside of the spaceships, depending on the scene. There is also some background noise 

from  the  electronic  equipment  at  the  space  pod.  This  clip  can  be  downloaded  from 

YouTube at https://www.youtube.com/watch?v=Wy4EfdnMZ5g&t=11s 

Figure 43: Video Clips of Dave (Clip1), and HAL (Clip2) SOURCE: Fandango 

Movie Clips. 

Two sets of experiments were performed: Experiment 1 was aimed to determine if 

there  was  any  biasing  on  the  results  as  the  product  of  the  location  of  the  speakers. 

Experiment 2 evaluated the effects of training in the results.  

117 

 
 
 
 
 
 
   
5.2.2.1  Source Preparation and Editing 

This  experiment  played  Dave’s  and  HAL’s  voices  independently  at  the 

loudspeakers.  To  do  so,  the  YouTube  video  was  converted  into  a  single  channel  using 

Audacity ® version 2.4.2 [83] and saved as a MP4 48 kHz audio (See Fig 44 (a)). Then, 

using Audacity, the segments with voices of Dave and HAL were cut and pasted in two 

separate  channels  of  a  new  stereo  track  (Fig.  44  (b)).  The  intervals  with  noise  were 

converted into silence to allow the recording noise to come from an external source. Dave 

was placed on the right track and Hal was placed on the left track. The noise segments were 

copied and pasted into a separate audio track and burnt into a CD (Fig. 44 (c)). 

118 

 
 
 
Figure 44: Sources and Noise for HAL 9000 

Experiment

119 

 
 
 
With this configuration, it was possible to play Dave at loudspeakers 1 (S1) and 2 

(S2), and HAL at loudspeakers 3 (S3) and 4 (S4), by using the loudspeaker switch. The 

noise was played at the CD player in a continuous loop and modeled as S5 or S6. 

5.2.2.2  Ground Truth Recording  

Two sets of recordings were taken for this experiment. Set 1A consisted of playing 

the audio track using the loudspeakers 1 (Dave) and 3 (HAL). Set 1B consisted of playing 

the loudspeakers 2 (Dave) and 4 (HAL). The noise track was played in a continuous loop 

by a CD player located at the position of Source 6. The audio was recorded using the Canon 

video camera with the microphone located at the position of microphone 3 in Table IX. 

The recording was transferred to the computer for segmentation and training. Because the 

camera records audio in stereo mode and the code can only handle mono audio, the stereo 

track was converted into mono audio by removing the right channel. This conversion kept 

intact all the spatial information contained in the left channel. Using Audacity’s “convert 

to  mono”  feature  would  have  mixed  both  channels,  rendering  the  spatial  information 

useless. Fig. 45 shows the final sets 1A and 1B of audio captured by the camera. 

5.2.2.3  Training and Segmentation 

Both models for experiments 1 and 2 were trained with segments of speech from Dave and 

HAL, and a segment of noise. For experiment 1A, the model was trained with Dave as S1 

using a 1.98 s long segment, and HAL as S3 with a 1.76 long segment, as shown in Fig 46.  

120 

 
 
 
 
Figure 45: Ground Truth Sets A and B for HAL 9000 

Experiment. 

121 

 
 
 
 
 
Figure 46: Training Segments for HAL and Dave.

122 

 
 
 
Noise was trained as S6 with a 2 s long segment. S2, S4, and S5 were set to silence. For 

experiment 1B, Dave was trained as S2, and HAL was trained as S4.  S1, S3, and S5 were 

set to silence, and S6 was noise. All training segments were about the same length as in 

1A. 

For Experiment 2, the model was trained with HAL as speaker S1 and S4, and Dave 

as speaker S2 and S3. The noise was trained as S6, and S5 was set to silence. 

The recorded audio was segmented in two different ways. For experiment 1, the 

VAD was set with a maximum length segment of 5 seconds, ending with an audio of 120.39 

s after subtracting the dropped segments. For experiment 2, the length of the segments was 

limited  to  a  maximum  of  1.5  s.  Frames  of  less  than  500  ms  were  discarded  for  both 

experiments.   

5.2.2.4  Testing and Results 

Table X shows the results of experiments 1 and 2. We can appreciate that the length 

of the segments has an influence on the DER. In this experiment, the longer the segments, 

the  less  the  error.  These  results  agree  with  our  previous  discussion  on  the  amount  of 

information needed for proper cross-correlation. It is important then to optimize the length 

of the segments so they can contain as much  information as possible and maximize the 

matching probabilities with the training template. 

123 

 
 
 
 
Table X: DER Results for HAL 9000 Experiments. 

Exp 

Test 

No. 
Segments 

1 

2 

A 
B 
-- 

71 
71 
122 

Properly 
Classified 
Segments 
58 
58 
99 

False 
Alarms 
(s) 
5.68 
1.22 
11.31 

Miss (s) 

Confusion
(s) 

1.46 
3.01 
1.2 

2.88 
2.32 
10.98 

DER 

0.083 
0.054 
0.195 

5.2.3  Multi-Speaker Identification Experiments 

The objective of the experiments in this section is to measure the performance of 

the  proposed  method 

to 

identify  several  speakers 

in  single-channel  recording, 

independently  of  the  content  of  their  speech.  As  with  the  previous  experiments,  the 

geometry of the room and the location of the speakers is known, allowing for models that 

represent more accurately the actual acoustic scene under analysis. The experiments in this 

section used the same lab setup and models of the “HAL 9000” experiment.  

The experiment was divided into four separate tests, that included two speakers and 

four speakers. Three of the experiments have two independent speakers repeating the same 

phrases,  at  different  positions.  The  last  experiment  has  four  separate  speakers  at  four 

different locations.  

5.2.3.1  Source Preparation and Editing 

The speech sources for the experiments consisted of four different speakers, two 

male, and two females, sampled at a rate of 48 kHz. These sources were downloaded from 

124 

 
 
 
 
the Telecommunications and Signal Processing Laboratory of McGill University, database 

version 2 [84]. The lengths of these sources vary between 1.2 to 3 s, approximately. 

A total of four audio tracks were prepared for analysis. Tracks A, B, and C had two 

speakers, while track D had four. The sources were arranged into one stereo track, so they 

can be played at the loudspeakers LS1 and LS3, and then switched to be played at LS2 and 

LS4, as it was done with the HAL 9000 experiments. A small pause was inserted to allow 

for switching between loudspeakers. 

Table XI shows the structure of each of the audio sample. Each sequence in the 

table indicates the label of the active speaker, the loudspeaker playing the speech, and the 

label of the spoken phrase. For example, audio sample A contains two sequences, 1 and 2. 

Sequence 1 is played at loudspeaker S1 by speaker 1, speaking phrase “a”. Sequence 2 is 

played by speaker 2, loudspeaker S3, speaking phrase “b”. In samples B, C, and D, speakers 

repeat some of the phrases with the objective to demonstrate the ability of the proposed 

system to differentiate the speakers regardless of their speech content. 

125 

 
 
 
 
 
 
 
 
Table XI: Multi-Speaker Experiment Sequence Table 

Duration 
(s) 

Conditions 

1 

2 

3 

-- 

-- 

-- 

Loudspeaker 

S1 

S3 

Speaker 

Phrase 

1 

a 

2 

b 

Loudspeaker 

S2 

S4  S2 

Speaker 

Phrase 

1 

a 

2 

a 

1 

b 

Sequence 

4 

-- 

-- 

-- 

-- 

-- 

-- 

5 

-- 

-- 

-- 

-- 

-- 

-- 

6 

-- 

-- 

-- 

-- 

-- 

-- 

7 

-- 

-- 

-- 

-- 

-- 

-- 

8 

-- 

-- 

-- 

-- 

-- 

-- 

9 

-- 

-- 

-- 

-- 

-- 

-- 

A 

4.78 

B 

6.05 

Loudspeaker 

S1 

S1  S3  S1  S2  S4  S4  S4  S4 

C 

39.58 

Speaker 

Phrase 

1 

a 

1 

b 

2 

c 

1 

d 

1 

e 

2 

f 

2 

g 

2 

h 

2 

i 

10 

-- 

-- 

-- 

-- 

-- 

-- 

-- 

-- 

-- 

l

e
p
m
a
S

Loudspeaker 

S1 

S3  S1  S3  S3  S2  S2  S4  S2  S4 

D 

27.73 

Speaker 

Phrase 

1 

a 

2 

a 

1 

b 

2 

b 

2 

c 

3 

d 

3 

e 

4 

f 

3 

g 

4 

h 

5.2.3.2  Ground Truth Recording 

The audio was captured the same way as in the “HAL 9000” experiments, using 

the Canon video camera and saving the video recording in the camera’s internal SD storage. 

Ambient noise was injected by paying background noise using the CD player, as it was 

done for the “HALL 9000” experiments. The background noise was extracted from one of 

the AOLME video recordings.  

As with the “HAL 9000” experiments, the stereo recording from the video camera 

was converted into single-channel audio by removing the right channel, before the analysis. 

126 

 
 
 
 
 
5.2.3.3  Training and Segmentation 

The training was done with segments that had a maximum length of 1.5 s for each 

of the speakers, plus 1.5 s segment of noise. The custom VAD was used for segmentation. 

The number of segments produced for each of the audio tracks varied as is shown in the 

results table. 

5.2.3.4  Testing and Results 

Testing was conducted in the same manner as the “HAL 9000” experiments. The 

results for each of the segments are shown in Table XII. 

Table XII: Controlled Environment Experiments Diarization Error Rate Results 

Audio 
Sample 

No. 
Speakers 

No. 
Segments 

A 
B 
C 
D 

2 
2 
2 
4 

9 
15 
116 
37 

Properly 
Classified 
Segments 
7 
12 
98 
27 

False 
Alarms 

0 
0 
10 
2 

Miss 

Confusion 

DER 

2 
2 
0 
0 

0 
1 
8 
8 

0.19 
0.19 
0.12 
0.27 

Table V shows that the DER is not more than 0.27 in the worst case. These results 

are  comparable  or  better  than  DER  results  from  methods  using  databases  and  neural 

networks [85] 

127 

 
 
 
 
 
5.3 

AOLME Experiments 

The controlled environment experiments demonstrated that the proposed method 

could identify speakers  in single-channel recordings. These experiments  analyzed audio 

samples that featured organized speech (one speaker at a time), where the speakers are well 

separated  from  each  other  (no  overlapping  between  speakers).  The  objective  of  the 

AOLME experiments in this section is to evaluate the performance of the proposed method 

to identify speakers in single-channel audio recordings from videos of noisy multi-speaker 

collaborative environments.  

This  section  evaluates  the  process  of  selection  of  the  AOLME  videos  for  the 

experimental analysis, and discusses the models employed for the analysis. The analysis of 

the audios will follow the same approach as the previous experiments.  

5.3.1  Evaluation and Selection of AOLME Videos 

There  are  several  hundred  hours  of  AOLME  video  recordings  available  for 

analysis but, because of the experimental nature of this research work, it was necessary to 

select videos that met certain characteristics that facilitate the preparation of the models 

and the setup of the experiments. The models used in the previous experiments proved to 

perform  well,  and  for  this  reason,  it  was  necessary  to  search  for  AOLME  videos  with 

similar  geometric  characteristics  as  these  models,  i.e.,  the  participants  were  in  similar 

places as the speakers in the model from our previous experiments. The selection consisted 

of four videos with 2, 3, 4 and 5 participants from the library of videos. The videos were 

128 

 
 
 
approximately  3  minutes  long  each.    Fig.  47  shows  frames  from  these  videos  with  2 

participants (a), 3 participants (b), 4 participants (c), and 5 participants (d).  As was done 

in  the  previous  experiments,  the  stereo  audio  track  for  each  video  was  extracted  and 

converted into a 48 kHz single channel by removing the right channel. 

Figure 47:Video Clips for AOLME Experiments. 

5.3.2  Model Preparation 

The model used for this experiment followed the same geometry as the previous 

experiments, with the width of the table adjusted to 1.8 m to fit the AOLME scene more 

accurately. Instead of generating separate models for each of the videos, the model had all 

129 

 
 
 
 
 
 
three  speakers  for  all  the  experiments.  As  previously  done,  the  locations  of  the  absent 

speakers  were  turned  off  by  training  with  a  silence  segment.    Fig.  48  shows  the  2D 

Pyroomacoustics  model  and  Table  XIII  shows  the  locations  of  the  speakers  and  the 

microphones.  

Figure 48: 2D Model for AOLME Experiments. 

130 

 
 
 
 
 
 
 
Table XIII: Location of Speakers and Microphones for AOLME Experiments. 

s
r
e
k
a
e
p
S

s
c
i

M

m
o
o
R

S1 
S2 
S3 
S4 
S5 
S6 
M1 
M2 
M3 
M4 
M5 
M6 
M7 
CORNER 1 
CORNER 2 
CORNER 3 

CORNER 4 
EXTRUDE 

X 
0.40 
0.01 
1.00 
0.40 
1.20 
2.40 
0.75 
0.85 
0.80 
0.80 
0.80 
0.80 
0.80 
0.00 
0.00 
2.50 

2.50 

Y 
1.79 
0.80 
1.79 
0.01 
0.01 
1.00 
1.00 
1.00 
1.00 
1.05 
0.95 
1.10 
0.90 
0.00 
1.80 
1.80 

1.80 

2.00 

Z 
0.25 
0.25 
0.25 
0.25 
0.25 
1.50 
0.03 
0.03 
0.03 
0.03 
0.03 
0.03 
0.03 
-- 
-- 
-- 

-- 

5.3.3  Training and Segmentation 

The  same  training  and  segmentation  principles  were  used  as  in  the  previous 

experiments.  Training  used  a  1.5  to  2  s  long  sample  of  each  of  the  participants,  plus  a 

similar  length  segment  of  background  noise.  Because  the  same  model  was  used  for  all 

participants, non-active speakers were trained with a silence segment of 2 s duration. Table 

XIV shows the speaker assignment for each of the experiments.  

131 

 
 
 
 
 
 
 
 
Table XIV: Speaker Assignment for AOLME Experiments. 

Audio 
Sample 

A 

B 

C 

D 

Speaker Assignment 

S2 

S1 
 Silence 


 Silence 



S3 

Silence 

Silence 


S5 

S4 
 Silence 
 Silence 









S6 

Noise 

Noise 

Noise 

Noise 

The  Ground  Truth  for  each  audio  was  segmented  using  the  VAD,  discarding 

segments with less  than 0.5 s  duration,  and  limiting  the length of  the segments  to 1.5 s 

maximum. The total number of segments for each sample is shown in the results table. 

5.3.4  Testing and Results 

The same type of analysis was applied as in the previous experiments. Table XV 

(a) shows an example of the Cross-Correlation results of analyzing one segment of Audio 

Sample B. Tables VII (b), (c), and (d) show the training CC tables with the score of each 

possible  speaker.  Each  match  is  represented  by  a  zero  (0).  In  this  case,  the  segment 

corresponds to speaker 2.

132 

 
 
 
 
 
Table XV: CC Tables for AOLME 

Experiment. 

1-2  1-3 

1-4 

1-5 

1-6  1-7  2-3 

2-4 

2-5 

2-6  2-7 

3-4  3-5 

3-6 

3-7 

4-5 

4-6 

(a)    Microphone Cross Correlation. Unknown Segment 

-64 
-65 
11 
63 

-45 
-75 
89 
72 

-96 
-236 
137 
133 

-100 
-236 
306 
133 

12 
-75 
90 
97 

-68 
0 
-28 
0 

18 
-30 
56 
8 

-74 
-103 
203 
57 

-276 
-103 
92 
57 

71 
-11 
79 
21 

-9 
65 
-34 
-63 

-72 
-69 
-41 
42 

-41 
-69 
35 
42 

57 
19 
21 
1 

-27 
75 
-123 
-72 

14 
0 
82 
0 

1-2  1-3 
0 
91 
0 
-53 
11 
0 
4 
0 

1-2  1-3 
0 
-245 
-1 
0 
0 
0 
4 
0 

1-4 
0 
-83 
-145 
0 

1-4 
0 
21 
-145 
12 

1-5 
-14 
-83 
197 
0 

1-5 
-14 
21 
218 
12 

(b)     Microphone Cross Correlation. Training Speaker 1. Score: 25 
4-5 
-127 
0 
21 
0 

2-6  2-7 
-5 
-9 
53 
-1 
17 
-11 
0 
-1 

3-4  3-5 
8 
0 
-11 
1 

1-6  1-7  2-3 
4 
18 
5 
0 
0 
110 
1 
6 
-5 
1 
0 
12 

2-5 
-139 
0 
5 
-1 

3-7 
-4 
0 
-2 
-4 

3-6 
0 
1 
1 
-1 

2-4 
4 
0 
192 
-1 

0 
0 
2 
1 

(c)    Microphone Cross Correlation. Training Speaker 2. Score: 32 
4-5 
5 
0 
0 
0 

2-6  2-7 
-5 
-13 
0 
0 
1 
5 
0 
0 

3-4  3-5 
14 
-1 
0 
0 
3 
-11 
0 
0 

1-6  1-7  2-3 
4 
18 
5 
0 
0 
0 
1 
-9 
-5 
4 
0 
0 

2-5 
-270 
0 
5 
-1 

3-7 
-4 
1 
-11 
-4 

3-6 
0 
1 
3 
-1 

2-4 
204 
0 
419 
-1 

(d)       Microphone Cross Correlation. Training Speaker 3. Score: 21 

1-2 
13 
0 
-5 
0 

1-3 
-1 
-1 
14 
-209 

1-4 
5 
-121 
-77 
0 

1-5 
-14 
-121 
202 
0 

1-6  1-7  2-3 
-6 
13 
5 
-194 
0 
0 
0 
-5 
-5 
4 
0 
24 

2-4 
-198 
0 
182 
11 

2-5  2-6  2-7 
-5 
-9 
-72 
0 
-2 
0 
-155 
5 
5 
0 
11 
11 

3-4  3-5 
0 
7 
0 
2 

1 
7 
3 
2 

3-6 
1 
191 
3 
-3 

3-7 
3 
1 
-3 
209 

4-5 
4 
0 
6 
0 

133 

285 
98 
18 
-36 

4-6 
56 
0 
2 
1 

4-6 
394 
5 
1 
1 

4-6 
-9 
0 
-31 
1 

s
r
e
k
a
e
p
S

s
r
e
k
a
e
p
S

s
r
e
k
a
e
p
S

s
r
e
k
a
e
p
S

1 
2 
3 
6 

1 
2 
3 
6 

1 
2 
3 
6 

1 
2 
3 
6 

4-7 

-58 
236 
-94 
-133 

4-7 
-333 
83 
0 
0 

4-7 
-333 
-21 
0 
-12 

4-7 
-267 
121 
-12 
0 

5-6 

294 
98 
-8 
-36 

5-6 
206 
0 
5 
1 

5-6 
208 
5 
0 
1 

5-6 
201 
0 
5 
1 

5-7 

3 
236 
-107 
-133 

5-7 
-1 
83 
37 
0 

5-7 
0 
-21 
-202 
-12 

5-7 
-5 
121 
16 
0 

6-7 

-80 
75 
-125 
-97 

6-7 
4 
-110 
-15 
-12 

6-7 
0 
0 
0 
0 

6-7 
4 
0 
-12 
-24 

 
 
 
 
   
 
 
  
   
 
 
  
   
 
 
  
   
Table  XVI  shows  the  results  of  the  analysis  of  all  Audio  Samples,  with  the 

respective DER for each experiment. 

Table XVI: Classification Results for AOLME Experiments. 

Audio 
Sample 

Sample 
Duration 
(s) 

No. 
Speakers 

No. 
Segments 

Properly 
Classified 
Segments 

False 
Alarms 

Miss  Confusion  DER 

A 
B 
C 
D 

244 
256 
381 
257 

2 
3 
4 
5 

311 
328 
489 
339 

281 
302 
426 
284 

5 
8 
10 
12 

10 
10 
25 
15 

15 
8 
28 
28 

0.095 
0.079 
0.12 
0.16 

5.4 

Comparison with Other Methods 

The  final  set  of  experiments  focus  on  comparing  our  proposed  method  against 

Google’s and Amazon AWS. Google’s and Amazon AWS were two of the cloud-based 

speech  processing  services  introduced  in  the  background  section  of  this  dissertation. 

Microsoft  Diarization  service  was  in  the  process  of  being  updated  by  the  time  this 

dissertation was written and, therefore, it was not possible to run any experiment with it. 

5.4.1  Methodology for Comparison 

The diarization services provided by Google and Amazon differ from the proposed 

method in three aspects. First, they do not require a sample of audio for training. Second, 

the audio samples to diarize need to be of a minimum duration of 4 s, approximately.  Third, 

134 

 
 
 
 
their output does not provide a label of the active speaker, but rather a set of text transcripts 

that contain the speech segment, the abstract speaker label (e.g., speaker 0, speaker 2), the 

active time of the speaker on the transcript segment, and the confidence rate. Given these 

constraints,  the  only  fair  comparison  criteria  are  to  manually  measure  each  speaker’s 

ground truth active time manually and compare these times with the results of the analysis 

by all three methods. It was necessary to add a section of code to the proposed method to 

measure the length of each of the segments that are already classified and totalize the time 

for the same speaker plus noise.  

5.4.2 

Selection,  Preparation,  and  Ground  Truth  Measurements  of  Videos  for 

Analysis 

The  analysis  consisted  of  a  total  of  8  AOLME  videos  containing  2,  3,  4,  and  5 

speakers. The duration of each video was limited to a maximum of 3 minutes. The audio 

from each video was extracted using Audacity and downshifted to 16 kHz for upload to 

Goggle and Amazon. The audio files for our methods were sampled at a rate of 48 kHz. 

Each  speaker’s  active  time  from  the  ground  truth  audio  was  measured  using  a 

stopwatch. In some of the AOLME videos, it was difficult to assess this time due to several 

speakers being active simultaneously. In these cases, each speaker’s time was recorded by 

listening to his/her voice and watching his/her lip movement on video, even if their speech 

overlapped at any moment. 

135 

 
 
 
 
5.4.3  Training and Segmentation 

The system was trained with audio samples of about 1.8 s long from each speaker 

and noise, using a VAD with a maximum segment length of 1.2 s. All segments with a 

duration  of  less  than  0.5  s  were  dropped. There  was  no  need  for  training  on  Google or 

Amazon; these systems trained by using the uploaded audio and their databases. 

5.4.4  Testing and Analysis 

Each of the audio files from the videos was analyzed using the modified code that 

totalizes each speaker’s time, with no other additional steps. For Amazon and Google, the 

audio was uploaded to the cloud. 

Because both Amazon and Google’s methods return only abstract labels, the output 

transcriptions  of  each  of  the  speakers  were  used  to  manually  match  the  identity  of  the 

speaker on each segment, noting that both Amazon and Google label the first active speaker 

they detect as “speaker 0”.  

5.4.5  Results 

Table  XVII  shows  the  results  of  this  experiment,  with  the  percentage  error 

highlighted in light blue. The error was calculated using (5.1).  

Percent error =

estimated time − true time
true time

∗ 100          (5.1). 

136 

 
 
 
 
 
Table XVII: Experimental Comparison Between Methods. 

Audio 
Sample 

No. of 
Speakers 

Speaker 

1 

2 

3 

4 

5 

6 

7 

2 

2 

3 

3 

4 

4 

5 

8 

5 

S1 
S2 
S1 
S2 
S1 
S2 
S3 
S1 
S2 
S3 
S1 
S2 
S3 
S4 
S1 
S2 
S3 
S4 
S1 
S2 
S3 
S4 
S5 
S1 
S2 
S3 
S4 
S5 

Amazon AWS 

Google Cloud 

1.95 
45.25 
4.85 
8.24 
40.88 
47.08 
31.51 
61.41 
24.01 
3.72 
40.39 
7.53 

Time 
Error 
(s) 
% 
94.52 
19.21 
74.47 
170.60 
120.90 
12.99 
45.46 
152.14 
9.88 
64.67 
143.74 
40.21 
0.00 
100.00 
106.36 
61.79 
37.67 
36.19 
0.00 
100.00 
52.19 
84.48 
8.93 
20.05 
0.00 
100.00 
0.00 
100.00 
78.70 
221.49 
36.95 
65.84 
100.00 
0.00 
250.00  38.05  3070.83 
100.00 
0.00 
60.54 
28.30 
88.77 
6.74 
100.00 
0.00 
13.82 
39.24 
60.04 
13.31 
100.00 
0.00 
10.92 
100.00 
0.00 
31.65 
53.73 
53.13 
21.67 
100.00 
0.00 
44.00 
15.63 
17.61 
46.22 
17.52 
56.02 
42.23 

Error 
Time 
% 
(s) 
8.63 
127.10 
100.00 
0.00 
31.40 
73.40 
66.59 
269.33 
66.59  1009.83 
50.80 
10.29 
80.20 
31.39 
0.00 
0.00 
8.30 
35.00 
94.30 
53.59 
29.19 
15.29 
3.30 
5.09 
24.90 
0.00 
54.70 
46.60 
6.29 
29.59 
7.49 
11.20 
29.59 

50.45 
11.12 
22.00 
13.49 
100.00 
100.00 
25.69 
17.20 
27.71 
118.91 
31.01 
40.62 
175.00 
74.86 
64.01 
100.00 
26.86 
279.79 
55.95 
14.38 
199.60 
26.46 
37.93 

Proposed 
Method 

Ground 
Truth 
Time 
Error 
Time 
(s) 
% 
(s) 
14.54 
99.99 
117.00 
25.80 
34.62 
27.52 
5.61 
107.00  113.00 
23.44 
18.03 
30.01 
20.69  244.83 
6.00 

102.52  100.52 
13.45 
68.93 
25.38 
15.30 
41.61 
14.69 
68.23 
91.57 
25.39 
13.28 
27.69 
4.20 
7.99 
64.53 
10.71 
48.86 
10.93 
18.80 
42.05 
3.60 
22.27 
27.54 

9.26 
65.74 
27.66 
10.86 
28.29 
11.17 
42.27 
73.84 
24.48 
22.28 
25.75 
1.20 
20.25 
69.19 
9.41 
43.12 
12.27 
14.28 
34.56 
2.50 
15.23 
47.67 

137 

 
 
 
 
 
Table XVIII shows the average error for 2, 3, 4, and 5 speakers, as well as the total 

average error for each method. 

Table XVIII: % Average Error for All Three Methods. 

No. of Speakers 

2 
3 
4 
5 
Total 

Proposed 
Method 
18.99 
57.67 
58.21 
29.11 
42.10 

Amazon 
AWS 
88.74 
67.14 
470.34 
65.44 
184.82 

Google 
Cloud 
102.34 
201.15 
67.02 
87.98 
108.29 

The results presented in Tables XVII and XVIII show a substantial reduction in the 

achieved error rate. More specifically, error reduction ranges from 50% to 87%. The color 

codes used in Table XVII emphasize the results of this experiment. The red highlighting 

denotes  cases  of  failures  where  we  have  a  speaker  that  was  completely  missed,  or  the 

estimated talking time of the speaker had more than a 100% error (e.g., an over-estimating 

speaker talking time). Out of 28 possible speakers across all examples, Amazon AWS gave 

failing results for 14 cases (50%), Google cloud gave failing results for 10 cases (36%), 

while the proposed method gave failing results for 2 cases (7%). It is interesting to notice 

that the proposed method never failed to detect a speaker (0% error), while Amazon AWS 

could not detect any talking time for 10 cases (36%). Google cloud failed to detect any 

talking time for 4 cases (14%). Also, there are failure cases for all 8 samples for Amazon 

138 

 
 
 
 
AWS and Google Cloud. In contrast, for the proposed method, there are 2 samples with 

examples of over-estimation, with 6 samples being free of dramatic failures. 

Teal highlighting denotes cases where the total estimated speaking time gave 20% 

or less error. Based on this criterion, both AWS and Google Cloud gave satisfactory results 

in 5 cases (18%) versus 11 cases (39%) for the proposed method. 

139 

 
 
 
Chapter 6. Summary, Conclusions, and Future work 

This dissertation presented a method for speaker diarization and identification using 

virtual microphones and cross-correlation patterns. The proposed method identifies speakers 

in single-channel recordings taken in noisy collaborative environments, such as classrooms 

and educational workshops. The method gave an error rate that was over 50% less on average 

than other available diarization methods when subject to the same testing environments. In 

contrast  with  other  methods  that  are  considered  state-of-the-art,  the  proposed  method 

requires minimal training and no databases, making it applicable in situations where it is not 

possible to gather clean speech samples. 

The  background  section  of  this  dissertation  presented  similar  research  works  on 

speaker diarization and identification based on microphone arrays.  Although some of these 

works  included  virtual  microphone  arrays,  none  of  them  approached  a  full  virtual  array 

simulation  from  a single  microphone  recording.  Given  the  unprecedented  focus  on  Deep 

Learning methods, alternative approaches are avoided, limiting the number of researchers 

interested  in  pursuing  them.  Yet,  the  proposed  methodology  clearly  outperformed 

commercial Deep Learning methods and demonstrated some of their limitations due to their 

needs for large training datasets. 

The  method  presented  in  this  dissertation  offers  an  alternative  for  educational 

researchers  that  are  involved  with  collaborative  environments  and  depend  mostly  on  the 

140 

 
 
 
 
analysis of data provided by video recordings. The work in this dissertation showed that other 

available methods perform poorly under these environments when determining who speaks, 

when,  and  for  how  long.  The  deficiencies  presented  by  these  methods  are  even  more 

prominent when the participants are from underrepresented groups from which large training 

databases  may  not  exist.  The  proposed  method  demonstrated  a  significant  performance 

improvement by capitalizing on real video information of the environment under analysis, 

rather  than  depending  on  unrelated  training  data.  Also,  by  no  requiring  previous  speaker 

enrollment, this method opens the possibility of analysis of a wide variety of video data that 

may not have been recorded with the known intention of posteriors analysis.       

The  dissertation  method  constitutes  more  of  a  proof  of  concept  than  a  fully 

operational  method.  The  success  of  the  proposed  method  is  due  to  the  possibility  of 

simulating acoustic wave propagation, including speech. Even though this modeling can 

be complex, we have now powerful personal computers to execute the calculations required 

by the signal processing algorithms. Furthermore, the code for the simulations is available 

from  large  repositories  that  contain  open-source  libraries  ready  for  implementation; 

nevertheless,  there  is  work  that  needs  to  be  done  to  address  some  of  the  weaknesses 

observed so far, such as it is the case where participant speakers move and change their 

original locations, and when they “invade” other’s speakers’ physical location. Under this 

area,  it  is  possible  to  eventually  adapt  the methods  from  the  research  work  done  at  the 

ivPCL  lab  regarding  object  and  subject  tracking.  The  location  of  the  speakers  and  the 

general geometry of the room could be dynamically modified in the models based on the 

141 

 
 
information  from  video  data,  thus  improving  the  error  rate.  Also,  the  experiments  only 

considered one type of microphone array, leaving open the question of the performance of 

other  types  of  arrays,  such  as  circular  or  even  volumetric.  In  addition,  the  simulation 

version  available  during  the  development  of  this  dissertation  had  some  limitations  that 

impacted the accuracy of the models. Pyroomacoustics released a new version that includes 

improvements to the models’ parameters, such as physical modeling of room absorption, 

reverberation  modeling,  and  multi-pattern  microphone  simulation.  Finally,  the  method 

depends  on  proper  audio  segmentation  and  final  classification.  Most  of 

the 

misclassifications in the method were the product of improper pre-segmentation and sub-

optimal  classification.  A  more  sophisticated  classifier  using  machine  learning  or  neural 

networks  would  help  improve  the  overall  performance.  It  is  possible  also  to  apply 

clustering classification for unsupervised identification of the speakers.  

Finally,  the  method  could  be  extended  to  support  other  applications  of  speech 

processing,  as  it  can  be  incorporated  as  a  front  end  or  pre-processor.  For  example,  the 

method can be used to improve the accuracy of spatial filters for speech enhancement or 

speaker  separation  from  mixtures.  The  parameters  of  the  spatial  filters  can  be  better 

determined by estimating the location of the speaker and then optimizing the parameters 

for that location. 

142 

 
 
 
Appendix A: Pyroomacoustics Scripts 

This section describes the two Python scripts that call the Pyroomacoustics libraries 

to  generate  the  room  geometry  parameters,  calculate  the  RIRs,  and  emulate  the  virtual 

microphones. 

a)  Room Geometry Generator: 

This script accepts the room dimensions and locations of the sources and virtual 

microphones and generates the 2D and 3D geometric models. The room geometry is saved 

as  a  set  of  .txt  files  that  contains  the  geometry  arrays.  This  script  runs  under  a  Jupyter 

Notebook. 

#Location of Sources and Microphones 
Source6=[0.98,0.4] 
Source6_3D=[0.98,0.4,0.98] 

Mic_X = [0.6,0.65,0.6,0.6,0.6,0.55,0.6] 
Mic_Y = [0.6,0.55,0.55,0.45,0.5,0.55,0.65] 
Mic_Z = [0.25,0.25,0.01,0.25,0.25,0.25,0.25] 

#Add room 
room = pra.Room.from_corners(corners, fs=fs) 

#Location of Microphones Array 
R = np.array([Mic_X, Mic_Y])  # [[x], [y], [z]] 

#Add source to 2D room 

room.add_source(Source1, signal=s1) 
. 
. 
room.add_source(Source6, signal=s6) 

room.add_microphone_array(pra.MicrophoneArray(R, room.fs)) 

#Execute Location 
room = pra.Room.from_corners(corners, fs=fs) 
room.extrude(1.0) 

143 

 
 
 
 
 
 
 
 
 
 
 
R = np.array([Mic_X, Mic_Y, Mic_Z])  # [[x], [y], [z]] 
room.add_microphone_array(pra.MicrophoneArray(R, room.fs)) 
room.add_source(Source1_3D, signal=s1) 
. 
. 
room.add_source(Source4_3D, signal=s4) 

#Save Geometry 
np.savetxt(r'C:\Users\User\Desktop\PhD 
Folder\Dissertation\Experiments\Model_Estimation\Room_parameters\corner
s_array.txt',corners[:,:],delimiter=',', fmt='%f') 
. 
. 
. 
np.savetxt(r'C:\Users\User\Desktop\PhD 
Folder\Dissertation\Experiments\Model_estimation\Room_parameters\mic_ar
ray.txt',R[:,:],delimiter=',', fmt='%f') 

b)  Pyroomacoustics Virtual Microphone Simulation Script 

This script is used twice to first calculate the RIR from the model sources to the 

virtual microphones, and then again to emulate the signal at the virtual microphones using 

the estimated sources. This script is called within LabVIEW, and its outputs are saved in 

.txt files. 

#Setup Python 
import numpy as np 
import matplotlib.pyplot as plt 
from scipy.io import wavfile 
from scipy.signal import fftconvolve 
import pyroomacoustics as pra 
#Define Variables 
Abs = 0 
max_o = 0 
room_extrude = 0 
corners_array = 0 
Source1 = 0 
. 
. 
Source6 = 0 
mic_array = 0 
#Define model 
def model_generation(): 

144 

 
 
 
 
#Delimit the corners of the room 
corners = np.array(corners_array).T  # [x,y] 
room = pra.Room.from_corners(corners) 
room.extrude(room_extrude) 
#Read Sources 
fs, s1 = wavfile.read(r""C:\.....) 
. 
. 
fs, s6 = wavfile.read(r""C:\.....) 
room = pra.Room.from_corners(corners, fs=fs) 
#Add microphone array 
R = np.array(mic_array)  # [[x], [y], [z]] 
room.add_microphone_array(pra.MicrophoneArray(R, room.fs)) 
# set max_order for RIR 
room = pra.Room.from_corners(corners, fs=fs, max_order=max_o, 
absorption=Abs) 
#Set Extrusion 
room.extrude(room_extrude) 
#Add source arrays and microphones 
Source1_3D=np.array(Source1) 
#Source 1 
room.add_source(Source1_3D, signal=s1) 
room.add_microphone_array(pra.MicrophoneArray(R, room.fs)) 
#Compute image sources 
room.image_source_model(use_libroom=True) 
room.compute_rir() 
#Save Data 
np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') 
#Data Mic 
data_mic=room.mic_array.signals[0,:] 
np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f')    
data_mic=room.mic_array.signals[1,:] 
np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') 
data_mic=room.mic_array.signals[2,:] 
np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') 
data_mic=room.mic_array.signals[3,:] 
np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f')    #Data 
Mic5 
data_mic=room.mic_array.signals[4,:] 
np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f')    #Data 
Mic6 
data_mic=room.mic_array.signals[5,:] 
np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f')    
data_mic=room.mic_array.signals[6,:] 
np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') 
#Reepeat for all sources 
. 
. 
. 
return 

145 

 
 
 
Appendix B: LabVIEW Sub-Vis 

a)  Room Parameters Reader 

Figure 49: Room Parameters Reader Inputs and Outputs 

Figure 50: Room Parameters Reader Front Panel. 

146 

 
 
 
 
 
Figure 51: Room Parameters 

Reader Block Diagram.

147 

 
 
 
b)  Room Model Generator 

Figure 52: Room Model Generator Icon. 

Figure 53: Room Model Generator Front Panel. 

148 

 
 
 
 
Figure 54: Room Model 

Generator Block Diagram.

149 

 
 
 
c)  Source Estimator 

This Sub- VI is too complex to display its source block diagram. Instead, a 

simple functional block diagram is shown. 

Figure 55: Source Estimator Icon. 

Figure 56: Source Estimator Front Panel. 

150 

 
 
 
 
 
Figure 57: Source Estimator Simplified Block Diagram. 

d)  Cross-Correlation Model Calculator 

Figure 58: Cross-Correlation Model Calculator Icon. 

151 

 
 
 
 
 
 
Figure 59: Cross-Correlation Model Calculator Front Panel. 

152 

 
 
 
 
 
 
Figure 60: Cross-Correlation Model Calculator Block 

Diagram.

153 

 
 
 
Figure 61: Cross-Correlation Model Calculator. Cross-Correlator Sub-VI. 

Notes on this sub-VI: The cross-correlation results are indicated by the index 

where the max cross-correlation occur. This method makes the results independent of the 

sampling frequency. Also, this sub-VI truncates the largest input to make both input files 

the same size as the smallest one. 

e)  Model Classifier 

Figure 62: Model Classifier Icon with Inputs and Outputs. 

154 

 
 
 
 
 
Figure 63: Model Classifier Front Panel. 

155 

 
 
 
 
 
 
 
 
 
 
f)  Multi-Function Convolution and Correlator Visualizer 

Figure 64: Multi-Function Convolution and Correlator Visualizer Front Panel. 

156 

 
 
 
 
 
 
 
 
Figure 65: Multi-Function Convolution and Correlator 

Visualizer Diagram.

157 

 
 
 
Appendix C: Audio Lab Equipment Specifications 

a)  Microphone Equipment: 

Audio-Technica ATR3350xIs 
  Element: Condenser 
  Polar Pattern: Omnidirectional 
  Frequency Response: 50 – 18,000 Hz.  
  Sensitivity: -54 db. 
 
  Power Source: Battery Type: LR44. 

Impedance: 1,000 ohms 

Comica CVM-V020 

  Transducer: Back Electrets Condenser 
  Directivity: Omnidirectional  
  Frequency Range: 100Hz ~ 12KHz 
  THD: ≤1% 
  Sensitivity: 
35dB ±3dB 
  Signal/Noise Ratio: ≥60dB 
  Power Source: 48V Phantom Powered 

158 

 
 
 
 
 
 
   
 
 
 
Excelvan 700 

  Polar Pattern: Uni-directional 
  Frequency Response: 20Hz-20kHz 
  Sensitivity: 45dB±1dB 
  Output Impedance:1500Ω±30%(at 1kHz) 
  Load impedance: ≥1000 Ω 
  Equivalent Noise level: 16dBA 
  Power Source: 48V phantom power supply 

b)  Audio Processing Equipment 

TASCAM Model US-16x08 

  Frequency response: 

o  LINE OUT(BALANCED) 
o  44.1k/48k Hz  20Hz to 20kHz, ±0.3dB(JEITA) 
o  88.2k/96k Hz  20Hz to 40kHz, ±0.3dB(JEITA) 

100dB or more 
100dB or more 

  THD  0.008% or less 
  S/N ratio 
  Crosstalk 
  EIN 
  Sampling frequency  44.1k/48k/88.2k/96k Hz 
  Quantization bit rate  16/24-bit 

–125dBu or less 

159 

 
 
 
 
 
 
  
  
  Analog audio inputs:    
o  MIC IN(IN 1-8) 

  Connector 

XLR-3-31 (1: GND, 2: HOT, 3: COLD), 

2.4kΩ 

BALANCED 
 
Input impedance 
  Nominal input level 
  GAIN: MAX  –68dBu (0.0003Vrms) 
  GAIN: MIN  –12dBu (0.195Vrms) 
  Maximum input level +8dBu (1.947Vrms) 
  Gain  56dB 
o  LINE IN (IN 9-10) 
  Connector 

1/4"" (6.3mm) TRS-jack (T: HOT, R: COLD, S: 

10kΩ 

GND), BALANCED 
 
Input impedance 
  Nominal input level 
  GAIN: MAX  –41dBu (0.0069Vrms) 
  GAIN: MIN  +4dBu (1.228Vrms) 
  Maximum input level +24dBu (12.182Vrms) 
  Gain  45dB 

AIWA Stereo Audio Amplifier 

  Power output: 80 watts per channel into 8Ω (stereo) 
  Surround output: 80W (front), 80W (center), 80W (rear) 
  Frequency response: 20Hz to 20kHz 
  Total harmonic distortion: 1% 
 
  Output: 300mV (line) 

Input sensitivity: 2.5mV (MM), 300mV (line) 

160 

 
 
  
  
  
  
 
  Speaker load impedance: 8Ω (minimum) 
c)  Loudspeakers 

Polk Audio RM6751 

  Power Range: 20- 100 W 
  Frequency Response: 40 Hz – 24 kHz  
  Sensitivity: 89 @2.83Vrms dB  
 

Impedance (Ohms): 8  

161 

 
 
 
 
References 

[1] S. S. Tirumala, S. R. Shahamiri, A. S. Garhwal, R. Wang, “Speaker identification 

features extraction methods: A systematic review”. Expert Systems with 
Applications, vol. 90, pp. 250-271, 2017. doi: 0957-4174, 
https://doi.org/10.1016/j.eswa.2017.08.015. 

[2] J. Brownlee, “Impact of Dataset Size on Deep Learning Model Skill And 

Performance Estimates,” Deep Learning Performance, machinelearningmastery.com, 
para.4, Jan. 2, 2019. [Online]. Available: 
https://machinelearningmastery.com/impact-of-dataset-size-on-deep-learning-model-
skill-and-performance-estimates/. 

[3] J. Yoon and S. O. Arik “Estimating the Impact of Training Data with Reinforcement 

Learning,” Cloud AI Team Google Research, googleblog.com, para. 2, Oct. 28, 2020. 
[Online]. Available: https://ai.googleblog.com/2020/10/estimating-impact-of-
training-data-with.html. 

[4] A. Koenecke  A. Nam, E. Lake, J. Nudell, M. Quartey, Z. Mengesha, C. Toups, J.R. 
Rickford, D. Jurafsky S. Goel, “Racial disparities in automated speech recognition,” 
Proceedings of the National Academy of Sciences of the United States of America, 
April 7, 2020, 117(14):7684-7689,  [Online serial]. Available: 
https://www.pnas.org/content/117/14/7684. 

[5] J. Martin, K.Tang, “Understanding Racial Disparities in Automatic Speech 

Recognition: The Case of Habitual “be”. Presented at 21st International Conference 
on Speech Processing and Applications, Shanghai, China, 2020. 

[6] R. Gupte, S. Hawa, and R. Sonkusare, “Speech recognition using cross correlation 
and feature analysis using mel-frequency cepstral coefficients and pitch,” In Proc. 
2020 IEEE International Conference for Innovation in Technology (INOCON), 2020, 
pp. 1-5. 

[7] G. Ekim, N. Ikizler, A. Atasoy, and I. H. Cavdar, “A speaker recognition system 

using by cross correlation,” In Proc. 2008 IEEE 16th Signal Processing, 
Communication and Applications Conference, 2008, pp. 1-4. 

162 

 
 
 
 
 
 
 
 
 
 
[8] The University of New Mexico, “AOLME: Advancing Out-of-school Learning in 
Mathematics and Engineering”. [Online]. Available: https://aolme.unm.edu/. 

[9] University of New Mexico’s Image and Video Processing and Communications Lab 

(ivPCL). [Online]. Available: https://ivpcl.unm.edu/ 

[10] C. J. Darsey, “Hand Detection in Collaborative Learning Environments”. The 

University of New Mexico, 2018. 

[11] Teeparthi S., “Long-term Video Object Detection and Tracking in Collaborative 

Learning Environments,” Fall 2021 (with distinction). She was funded through NSF. 

[12] Teeparthi, S., Jatla, V., Pattichis, M.S., Celedón-Pattichis, S., and LópezLeiva, C., 

“Fast Hand Detection in Collaborative Learning Environments,” The 19th 
International Conference on Computer Analysis of Images and Patterns (CAIP), pp. 
445-454, 2021. 

[13] Jacoby A. R., “Context-Sensitive Human Activity Classification in Video Utilizing 

Object Recognition and Motion Estimation,” Spring 2018. 

[14] Jatla, V., Teeparthi, S., Pattichis, M.S., Celedón-Pattichis, S., and LópezLeiva, C., 

“Long-term Human Video Activity Quantification of Student Participation,” in 2021 
Asilomar Conference on Signals, Systems, and Computers. 

[15] Eilar, C., Jatla, V., Pattichis, M. S., Celedón-Pattichis, S., & LópezLeiva, C. A., 

“Distributed Video Analysis for the Advancing Out of School Learning in 
Mathematics and Engineering Project,” 2016 Asilomar Conference on Signals, 
Systems, and Computers, pp. 571-575, 2016. 

[16] Shi, W., Pattichis, M.S., Celedón-Pattichis, S., and LópezLeiva, C., “Dynamic 

Group Interactions in Collaborative Learning Videos,” 2018 Asilomar Conference on 
Signals, Systems, and Computers, in press, pp. 1528-1531, 2018. 

[17] X. Anguera, S. Bozonnet, N. Evans, C. Fredouille, G. Friedland, O. Vinyals, 

""Speaker diarization: A review of recent research,"" IEEE Transactions on Audio, 
Speech, and Language Processing, vol. 20, no. 2, pp. 356-370, 2012. 

[18] M. Alam, M.D. Samad, L. Vidyaratne, A. Glandon, K.M. Iftekharuddin,” Survey on 
Deep Neural Networks in Speech and Vision Systems,” Neurocomputing, Volume 
417, 2020, pp. 302-321. 

163 

 
 
 
 
 
 
 
 
 
 
 
 
 
[19] D. Sztahó, G. Szaszák, A. Beke, ‘‘Deep learning methods in speaker recognition: A 
review,’’ Periodica Polytechnica Electrical Engineering and Computer Science, vol. 
65, no. 4, pp. 310–328, Jan. 2021. [Online]. Available: 
http://arxiv.org/abs/1911.06615. 

[20] J. Villalba, N. Chen, D. Snyder, D. Garcia-Romero, A. McCree, G. Sell, J. 
Borgstrom, L. Paola García-Perera, F. Richardson, R. Dehak, P. A. Torres-
Carrasquillo, N. Dehak, “State-of-the-art speaker recognition with neural network 
embeddings in NIST SRE18 and Speakers in the Wild evaluations,” Computer 
Speech & Language, vol. 60, March, 2020.  

[21] D. Snyder, D. Garcia-Romero, G. Sell, D. Povey and S. Khudanpur, ""X-Vectors: 
Robust DNN Embeddings for Speaker Recognition,"" 2018 IEEE International 
Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018, pp. 5329-
5333. 

[22] X. A. Miró, “Robust speaker diarization for meetings,” Ph.D. thesis, Speech 

Processing Group Department of Signal Theory and Communications Universitat 
Politècnica de Catalunya, Barcelona, 2006. 

[23] N. Mitianoudis and M. E. Davies, ""Using beamforming in the audio source 

separation problem,"" Seventh International Symposium on Signal Processing and Its 
Applications, 2003. Proceedings., 2003, pp. 89-92 vol.2, doi: 
10.1109/ISSPA.2003.1224822. 

[24] U. Klein and Trình Quốc Võ, ""Direction-of-arrival estimation using a microphone 
array with the multichannel cross-correlation method,"" 2012 IEEE International 
Symposium on Signal Processing and Information Technology (ISSPIT), 2012, pp. 
000251-000256, doi: 10.1109/ISSPIT.2012.6621296. 

[25] T. Padois, “Acoustic source localization based on the generalized cross-correlation 

and the generalized mean with few microphones”. J Acoust Soc Am. 2018. 

[26] S. Pasha and C. Ritz, ""Informed source location and DOA estimation using acoustic 
room impulse response parameters,"" 2015 IEEE International Symposium on Signal 
Processing and Information Technology (ISSPIT), 2015, pp. 139-144, doi: 
10.1109/ISSPIT.2015.7394316. 

[27] S. Tervo, J. Pätynen, and T. Lokki, “Acoustic reflection localization from room 

impulse responses,” Acta Acustica united with Acustica, vol. 98, no. 3, pp. 418-440, 
2021. 

164 

 
 
 
 
 
 
 
 
 
 
 
[28] M. Hu, P.P. Parada, D. Sharma, S. Doclo, T.V Waterschoot, M. Brookes, P.A. 

Naylor, ""Single-channel speaker diarization based on spatial features,"" In Proc. IEEE 
Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), 
2015, pp. 1-5. 

[29] P. P. Parada, D. Sharma, P. A. Naylor, “Non-intrusive estimation of the level of 

reverberation in speech,” in Proc. IEEE International Conf. on Acoustics, Speech and 
Signal Processing (ICASSP), Florence, Italy, May 2014, pp. 4718–4722. 

[30] D. Vijayasenan, F. Valente, and H. Bourlard, “Multistream speaker diarization 

beyond two acoustic feature streams,” in Proc. IEEE Intl. Conf. on Acoustics, Speech 
and Signal Processing (ICASSP), Dallas, TX, USA, Mar. 2010, pp. 4950–4953. 

[31] T. Yoshioka, Z. Chen, D. Dimitriadis, W. Hinthorn, X. Huang, A. Stolcke, M. Zeng, 
“Meeting transcription using virtual microphone arrays,” Microsoft Technical Report 
MSR-TR-2019-11, July 2019. 

[32] H. Katahira, N. Ono, S. Miyabe, T. Yamada, S. Makino, “Nonlinear speech 

enhancement by virtual increase of channels and maximum SNR beamformer,” 
EURASIP Journal on Advances in Signal Processing, 2016, issue 1, article 11, pp. 1-
8, 2016. 

[33] G. Del Galdo, O. Thiergart, T. Weller and E. A. P. Habets, ""Generating virtual 

microphone signals using geometrical information gathered by distributed arrays,"" 
2011 Joint Workshop on Hands-free Speech Communication and Communication and 
Microphone Arrays, Edinburgh, pp. 185-190, 2011. 

[34] A. Izquierdo, J. Villacorta, L. del Val, L. Suárez, and D. Suárez, “Implementation of 
a Virtual Microphone Array to Obtain High Resolution Acoustic Images,” Sensors, 
vol. 18, no. 2, p. 25, Dec. 2017.  

[35] Tapia, L.S., Gomez, A., Esparza, M., Jatla, V., Pattichis, M.S., Celedón-Pattichis, S., 

and López-Leiva, C., “Bilingual Speech Recognition by Estimating Speaker 
Geometry from Video Data,” The 19th International Conference on Computer 
Analysis of Images and Patterns (CAIP), pp. 79-89, 2021. 

[36] Siemens Simcenter “Sound Fields: Free versus Diffuse Field, Near versus Far Field” 
[Online]. Available: https://community.sw.siemens.com/s/article/sound-fields-free-
versus-diffuse-field-near-versus-far-field 

[37] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West 

Sussex: John Wiley & Sons Ltd., pp 341-343, 2009. 

165 

 
 
 
 
 
 
 
 
 
 
 
[38] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West 

Sussex: John Wiley & Sons Ltd., 2009, pp 171-174, 2009. 

[39] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West 

Sussex: John Wiley & Sons Ltd., 2009, pp 74, 2009 

[40] S. Renals, H. Bourlard, J. Carletta, and A. Popescu-Belis, “Multi-Modal Signal 
Processing. Human Interactions in Meetings”, New York: Cambridge University 
Press, pp 29-35, 2012. 

[41] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West 

Sussex: John Wiley & Sons Ltd., pp 171, 2009. 

[42] I. Cohen, J. Benesty, and S. Gannot,“Speech Processing in Modern 

Communications”. W. Kellerman. Berlin: Springer-Verlag, page 212, 2010. 

[43] B. Gunel, EE2.LabB: Measurement and Processing of Room Impulse Responses”. 

University of Surrey, 2011. [Online]. Available: 
http://personal.ee.surrey.ac.uk/Personal/P.Jackson/ee2.lab/XY_rir/. 

[44] B. Xie, “Head Related Transfer Function and Virtual Auditory Display”. Second 

Edition. J. Ross Publishing, Plantation Fl., pp 352-355, 2013. 

[45] F. A. Everest, and K.C. Pohlmann, “Master Handbook of Acoustics” McGraw Hill, 

New York, pp 559-560, 2015. 

[46] D. Diaz-Guerra, A. Miguel, and A. J. Beltran, “gpuRIR: A python library for room 
impulse response simulation with GPU acceleration”. Multimed Tools Appl 80, 
5653–5671. 2021. https://doi.org/10.1007/s11042-020-09905-3. 

[47] J.B. Allen, D.A. Berkley, “Image Method for Efficiently Simulating Small-Room 

Acoustics”, The Journal of the Acoustical Society of America, 1979. DOI 
10.1121/1.382599 

[48] Wikipedia [Online]. Available: https://en.wikipedia.org/wiki/Voice_frequency 

[49] I. McLoughlin, “Speech and Audio Processing, a MATLAB-based Approach”, 

Cambridge University Press, New York, page 65, 2016. 

[50] F. A. Everest, and K.C. Pohlmann, “Master Handbook of Acoustics” McGraw Hill, 

New York, pp 75-76, 2015. 

166 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
[51] S. Renals, H. Bourlard, J. Carletta, and A. Popescu-Belis, “Multi-Modal Signal 
Processing. Human Interactions in Meetings”, New York: Cambridge University 
Press, pp 40-41, 2012. 

[52] M. de Campos Niero, A. de Lima Veiga Filho, and A. G. Adami, ""A comparison of 

distance measures for clustering in speaker diarization,"" 2014 International 
Telecommunications Symposium (ITS), 2014, pp. 1-5, doi: 
10.1109/ITS.2014.6947954. 

[53] S. Chen, and P. Gopalakrishnan,” Speaker, environment and channel change 

detection and clustering via the bayesian information criterion”, in Proceedings of 
DARPA Broadcast News Transcription and Understanding Workshop, 1998. 

[54] Z. Bai, Xiao-Lei Zhang, “Speaker recognition based on deep learning: An 

overview”, Elsevier: Journal of Neural Networks, Volume 140, 2021, pp 84-88, ISSN 
0893-6080, [Online], Available: https://doi.org/10.1016/j.neunet.2021.03.004. 

[55] O. Ghahabi, “Deep Learning for i-Vector Speaker and Language Recognition”. 

Ph.D. thesis, Speech Processing Group Department of Signal Theory and 
Communications Universitat Politècnica de Catalunya, Barcelona, 2018. 

[56] Z. Bai, and Xiao-Lei Zhang, “Speaker recognition based on deep learning: An 

overview”, Elsevier: Journal of Neural Networks, Volume 140, 2021, pp 68-72, ISSN 
0893-6080, [Online], Available: https://doi.org/10.1016/j.neunet.2021.03.004. 

[57] J. Guo, N. Xu, K. Qian, Y. Shi, K. Xu, Y. Wu, and A. Alwan., “Deep neural network 
based i-vector mapping for speaker verification using short utterances”, Computer 
Speech & Language, Volume 72, March 2022, 101317. [Online]. Available: 
https://arxiv.org/abs/2101.09624. 

[58] D. Yifan, X. Yong, Z. Shi-Xiong, C. Yauhan, and W. Liqiang. 2020. “Self-

Supervised learning for audio-visual speaker diarization”. In ICASSP 2020 - 2020 
IEEE international conference on acoustics, speech and signal processing pp. 4367–
4371, 2020. 

[59] T. J. Park, and P. Georgiou, “Multimodal speaker segmentation and diarization using 

lexical and acoustic cues via sequence to sequence neural networks”. In Proc. 
INTERSPEECH 2018 pp. 1373–1377, 2018. 

167 

 
 
 
 
 
 
 
 
 
 
 
 
[60] L. El Shafey, H. Soltau, and I. Shafran, “Joint speech recognition and speaker 

diarization via sequence transduction”. In Proc. INTERSPEECH 2019 pp. 396–400, 
2019. 

[61] W. Kang, B. Roy, and W. Chow. “Multimodal speaker diarization of real-world 
meetings using d-vectors with spatial features”. In ICASSP 2020 – 2020 IEEE 
international conference on acoustics, speech, and signal processing pp. 6509–6513, 
2020. 

[62] Amazon AWS, “Amazon Transcribe”, 2021. [Online]. Available: 

https://aws.amazon.com/transcribe/?nc=sn&loc=1. 

[63] Google’s Cloud, “Separating different speakers in an audio recording”, 2021. 

[Online]. Available: https://cloud.google.com/speech-to-text/docs/multiple-voices. 

[64] Microsoft Azure Product Documentation, “What is Speaker Recognition?” 
Microsoft, Nov. 3, 2021. [Online]. Available: https://docs.microsoft.com/en-
us/azure/cognitive-services/speech-service/speaker-recognition-overview. 

[65] D. Misal, “Google Speech Vs Amazon Transcribe: The War of Speech Technology,” 

Analytics India Magazine, Oct. 22, 2018. [Online], Available: 
https://analyticsindiamag.com/google-speech-vs-amazon-transcribe-the-war-of-
speech-technology/. 

[66] M. Saraswat and R. C. Tripathi, ""Cloud computing: comparison and analysis of 

cloud service providers-AWs, Microsoft and Google,"" In Proc. 2020 9th International 
Conference System Modeling and Advancement in Research Trends (SMART), 
2020, pp. 281-285.  

[67] A. Woollacott, “Benchmarking speech technologies,” Academia.edu, Feb. 2021. 

[Online]. Available: Academia, 
https://www.academia.edu/45165394/Benchmarking_Speech_Technologies. 

[68] X. Xiao, N. Kanda, Z. Chen, T. Zhou, T. Yoshioka, S. Chen, Y. Zhao, G. Liu, Y. 

Wu, J. Wu, S. Liu, J. Li, and Y. Gong, “Microsoft speaker diarization system for the 
VoxCeleb speaker recognition challenge 2020,” In Proc. ICASSP 2021-2021 IEEE 
International Conference on Acoustics, Speech and Signal Processing (ICASSP), 
2021, pp.5824-5828. 

[69] Microsoft speaker recognition. [Online]. Available: https://docs.microsoft.com/en-

us/azure/cognitive-services/speech-service/speaker-recognition-overview 

168 

 
 
 
 
 
 
 
 
 
 
 
 
[70] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West 

Sussex: John Wiley & Sons Ltd., pp 351, 2009. 

[71] R. Scheibler, E. Bezzam, and I. Dokmanić, “Pyroomacoustics: A Python package for 

audio room simulation and array processing algorithms,” In Proc. 2018 IEEE 
International Conference on Acoustics, Speech and Signal Processing (ICASSP), 
2018, pp. 351-355. 

[72] Pyroomacoustics documentation. [Online]. Available: 
https://pyroomacoustics.readthedocs.io/en/pypi-release/ 

[73] E. Marin. “Voice Activity Detection Using Filters”. University of New Mexico, 

Spring 2021.  eguaderrama@unm.edu. 

[74] I. McLoughlin, “Speech and Audio Processing, a MATLAB-based Approach”, 

Cambridge University Press, New York, pp 24-28, 2016. 

[75] NI LabVIEW. [Online]. Available: https://www.ni.com/en-us/shop/labview.html 

[76] NI LabVIEW Convolution. [Online]. Available:  https://zone.ni.com/reference/en-

XX/help/371361R-01/lvanls/convolution/ 

[77] NI LabVIEW Deconvolution. [Online]. Available:  https://zone.ni.com/reference/en-

XX/help/371361R-01/lvanls/deconvolution/ 

[78] NI LabVIEW Correlation. [Online]. Available:  https://zone.ni.com/reference/en-

XX/help/371361R-01/gmath/correlation_test/ 

[79] NI LabVIEW Cross-Correlation. [Online]. Available:   

https://zone.ni.com/reference/en-XX/help/371361R-01/lvanls/crosscorrelation/ 

[80] Waveform Tracktion. [Online]. Available:  

https://www.tracktion.com/products/waveform-free 

[81] O. Galibert, “Methodologies for the evaluation of speaker diarization and automatic 
speech recognition in the presence of overlapping speech,” In Proc. INTERSPEECH 
2013, 2013, pp. 1131-1134.  

[82] Q. Wang, “SimpleDER: a lightweight library to compute Diarization Error Rate 

(DER)”. [Online]. Available: https://pypi.org/project/simpleder/. 

169 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
[83] Audacity® software is copyright © 1999-2021 Audacity Team. Web site: 

https://audacityteam.org/. It is free software distributed under the terms of the GNU 
General Public License. The name Audacity® is a registered trademark. 

[84] P. Kabal, TSP Speech Database, version 2 (2018-11), Montreal, Quebec: McGill 

University Department of Electrical and Computer Engineering Telecommunications 
& Signal Processing Laboratory, 2018. [Online]. Available: http://www-
mmsp.ece.mcgill.ca/Documents/Data/. 

[85] Y. Fujita, N. Kanda, S. Horiguchi, K. Nagamatsu, and S. Watanabe, “End-to-end 

neural speaker diarization with permutation-free objectives,” In Proc. 
INTERSPEECH 2019, 2019, pp. 4300-4304. 

170 

 
 
 
 
 
 
","University of New Mexico University of New Mexico UNM Digital Repository UNM Digital Repository Electrical and Computer Engineering ETDs Engineering ETDs Spring 5-2022 Speaker Diarization and Identification from Single-Channel Speaker Diarization and Identification from Single-Channel Classroom Audio Recording Using Virtual Microphones Classroom Audio Recording Using Virtual Microphones Antonio Gomez Follow this and additional works at: https://digitalrepository.unm.edu/ece_etds Part of the Bilingual, Multilingual, and Multicultural Education Commons, Computational Engineering Commons, Educational Methods Commons, Educational Technology Commons, Science and Mathematics Education Commons, and the Signal Processing Commons Antonio Gomez Candidate Electrical and Computer Engineering Department This dissertation is approved, and it is acceptable in quality and form for publication: Approved by the Dissertation Committee: Dr. Marios Pattichis Chairperson Dr. Ramiro Jordan Dr. Sylvia Pattichis Dr. Kim Linder Dr. Manel Martinez-Ramon i Speaker Diarization and Identification from Single-Channel Classroom Audio Recording Using Virtual Microphones by ANTONIO GOMEZ BS, Electrical Engineering, Florida International University, 1986 MS, Engineering Management, Florida International University, 1997 DISSERTATION Submitted in Partial Fulfillment of the Requirements for the Degree of Doctor of Philosophy Engineering The University of New Mexico Albuquerque, New Mexico May 2022 ii DEDICATION I would like to dedicate this dissertation to a very special person in my life, my wife Grace, for her support during this long journey. For all the hours, days, months, years she spent giving me the breath to move on, and for all the times she told me it is time to finish as well. For her, my eternal gratitude. I would like also to dedicate this work to my children, Daniel, and Carolina, for understanding why sometimes I was not there with them. I hope this work would serve as an inspiration to them. iii ACKNOWLEDGEMENTS I would like to sincerely acknowledge the labor of my advisor and dissertation chair, Dr. Marios Pattichis, for his continued support during all these years. Thank you for believing in me, Marios. I would have never done this without you on my side. I would like also to thank my committee members, for taking the time to review and advise my work. Thank you, Dr. Kim Linder, for being always there as a friend. Finally, I would like to say thank you to my managers at Honeywell and Sandia National Labs for their support and understanding. iv Speaker Diarization and Identification from Single-Channel Classroom Audio Recording Using Virtual Microphones By ANTONIO GOMEZ BS, Electrical Engineering, Florida International University, 1986 MS, Engineering Management, Florida International University, 1997 Ph.D. Engineering, University of New Mexico, 2022 ABSTRACT Speaker identification in noisy audio recordings, specifically those from collaborative learning environments, can be extremely challenging. There is a need to identify individual students talking in small groups from other students talking at the same time. To solve the problem, we assume the use of a single microphone per student group without any access to previous large datasets for training. This dissertation proposes a method of speaker identification using cross- correlation patterns associated to an array of virtual microphones, centered around the physical microphone. The virtual microphones are simulated by using approximate speaker geometry observed from a video recording. The patterns are constructed based on estimates v of the room impulse responses for each virtual microphone. The correlation patterns are then used to identify the speakers. The proposed method is validated with classroom audios and shown to substantially outperform diarization services provided by Google Cloud and Amazon AWS. vi TABLE OF CONTENTS LIST OF FIGURES…………………………………………………………………...…xii LIST OF TABLES……………………………………………………………….…...…xvi CHAPTER 1. INTRODUCTION ....................................................................................... 1 1.1 MOTIVATION ........................................................................................................ 4 1.2 RELATED RESEARCH ............................................................................................ 6 1.3 THESIS STATEMENT ........................................................................................... 12 1.4 CONTRIBUTIONS ................................................................................................ 12 1.5 DISSERTATION OVERVIEW ................................................................................. 13 CHAPTER 2. BACKGROUND ....................................................................................... 15 2.1 ACOUSTICS PRINCIPLES ..................................................................................... 15 2.1.1 Sound Propagation: Near and Far Fields ...................................................... 16 2.1.2 Sound Propagation: Direct Path, Reflections, and Reverberation ................ 18 2.2 MICROPHONES AND MICROPHONE ARRAYS ....................................................... 22 2.2.1 Classification of Microphones ...................................................................... 22 2.2.2 Microphone Arrays ....................................................................................... 24 2.2.2.1 Microphone Arrays Configurations ...................................................... 26 2.2.2.2 Spatial Aliasing ..................................................................................... 30 2.2.2.3 TDOA and Cross-Correlation ............................................................... 31 vii 2.2.2.4 Beamforming and Spatial Filters .......................................................... 33 2.3 MODELING OF ROOM ACOUSTICS ...................................................................... 34 2.3.1 Ray Tracing Method ..................................................................................... 35 2.3.2 Image Source Method ................................................................................... 36 2.4 CHARACTERISTICS OF THE HUMAN SPEECH ....................................................... 38 2.5 SPEAKER DIARIZATION AND IDENTIFICATION .................................................... 40 2.5.1 Methods for Diarization and Identification ................................................... 40 2.5.1.1 Classical Methods for Diarization and Identification ........................... 40 2.5.1.2 Deep Neural Networks .......................................................................... 43 2.5.1.2.1 Stage-wise diarization ..................................................................... 44 2.5.1.2.2 Multimodal Speaker Diarization ..................................................... 46 2.5.2 Current State-of-the-Art Methods for Diarization and Identification ........... 47 CHAPTER 3. PROPOSED METHOD ............................................................................. 50 3.1 METHODOLOGY ................................................................................................. 50 3.2 BLOCK DIAGRAM OF THE PROPOSED SYSTEM .................................................... 68 CHAPTER 4. EXPERIMENTAL IMPLEMENTATION ................................................ 72 4.1 SOFTWARE AND HARDWARE TOOLS .................................................................. 72 4.1.1 Open-Source Code for Room Geometry, RIR Calculation, and Microphone Simulation ................................................................................................................. 73 4.1.1.1 Pyroomacoustics Implementation ......................................................... 76 4.1.2 Audio Segmentation...................................................................................... 78 viii 4.1.2.1 Fixed Length Segmentation .................................................................. 78 4.1.2.2 Voice Activity Detection ...................................................................... 79 4.1.3 Implementation Using the LabVIEW Graphical Programming ................... 81 4.1.3.1 LabVIEW Implementation.................................................................... 83 4.1.3.1.1 Function VIs .................................................................................... 83 4.1.3.1.2 Operational Sub-VIs ........................................................................ 87 4.1.3.2 Audio Laboratory .................................................................................. 91 4.2 THE AOLME ENVIRONMENT ............................................................................ 94 4.2.1 Characteristics of the AOLME Environment ............................................... 95 4.2.2 Preparation of the Experimental Models ...................................................... 96 4.2.2.1 Approximating the Models Using Video Observations ........................ 97 CHAPTER 5. RESULTS ................................................................................................ 104 5.1 EVALUATION OF PYROOMACOUSTICS .............................................................. 104 5.1.1 Microphone Calibration .............................................................................. 104 5.1.2 Audio Lab Setup and Model Configuration................................................ 108 5.1.3 Experimental Execution .............................................................................. 110 5.1.4 Results ......................................................................................................... 111 5.2 CONTROLLED ENVIRONMENT EXPERIMENTS ................................................... 112 5.2.1 Methodology ............................................................................................... 112 5.2.1.1 Audio Lab and Model Preparation ...................................................... 113 5.2.1.2 Evaluation Criteria .............................................................................. 115 ix 5.2.2 “HAL 9000” Experiments........................................................................... 116 5.2.2.1 Source Preparation and Editing .......................................................... 118 5.2.2.2 Ground Truth Recording ..................................................................... 120 5.2.2.3 Training and Segmentation ................................................................. 120 5.2.2.4 Testing and Results ............................................................................. 123 5.2.3 Multi-Speaker Identification Experiments .................................................. 124 5.2.3.1 Source Preparation and Editing .......................................................... 124 5.2.3.2 Ground Truth Recording ..................................................................... 126 5.2.3.3 Training and Segmentation ................................................................. 127 5.2.3.4 Testing and Results ............................................................................. 127 5.3 AOLME EXPERIMENTS ................................................................................... 128 5.3.1 Evaluation and Selection of AOLME Videos ............................................. 128 5.3.2 Model Preparation ....................................................................................... 129 5.3.3 Training and Segmentation ......................................................................... 131 5.3.4 Testing and Results ..................................................................................... 132 5.4 COMPARISON WITH OTHER METHODS ............................................................. 134 5.4.1 Methodology for Comparison ..................................................................... 134 5.4.2 Selection, Preparation, and Ground Truth Measurements of Videos for Analysis................................................................................................................... 135 5.4.3 Training and Segmentation ......................................................................... 136 5.4.4 Testing and Analysis ................................................................................... 136 x 5.4.5 Results ......................................................................................................... 136 CHAPTER 6. SUMMARY, CONCLUSIONS, AND FUTURE WORK ...................... 140 APPENDIX A: PYROOMACOUSTICS SCRIPTS ................................................ 143 APPENDIX B: LABVIEW SUB-VIS...................................................................... 146 APPENDIX C: AUDIO LAB EQUIPMENT SPECIFICATIONS .......................... 158 REFERENCES ............................................................................................................... 162 xi LIST OF FIGURES Figure 1: Propagation of Sound Waves. (a) Free Field. (b) Directional. .......................... 17 Figure 2: Near and Far-Field Areas. ................................................................................. 18 Figure 3: Direct and Reflected Paths for Sound Propagation in a Diffuse Field. ............. 19 Figure 4: Representation of the Room Impulse Response and its Components. .............. 21 Figure 5: Polar Pattern Plot of Directivity of Two Types of Microphones: (a) Omnidirectional. (b) Cardioid. .................................................................................. 24 Figure 6: Linear Microphone Array. (a) Geometry. (b) 3D Directionality Pattern. ......... 27 Figure 7: Cross-Linear Array and Azimuth Directivity Pattern. ...................................... 28 Figure 8: Circular Microphone Array and Directivity Pattern.......................................... 29 Figure 9: Volumetric Microphone Array and 3D Directivity Pattern............................... 30 Figure 10: Location of Source and Microphones for Time Difference of Arrival. .......... 32 Figure 11: Simulation Methods. (a) Ray Tracing. (b) Image Source Method. ................. 36 Figure 12: Source Image Map. .......................................................................................... 37 Figure 13: Directionality of Human Head. ....................................................................... 39 Figure 14: Block Diagram of a Typical Speaker Diarization System. ............................. 41 Figure 15: GMM/i-vector Framework. ............................................................................. 45 Figure 16: DNN/i-vector Implementation. ....................................................................... 45 Figure 17: Collaborative Environment (a) with 2D Model (b). ........................................ 51 xii Figure 18: 2D Model of Fig. 12(b) with Microphone Array. ........................................... 52 Figure 19: Possible 2D Model for Fig. 17. ....................................................................... 56 Figure 20: Estimation of the Sources. ............................................................................... 60 Figure 21: Estimation of Virtual Microphones. ................................................................ 60 Figure 22: Training Samples from Each Speaker and Noise. ........................................... 64 Figure 23: Audio Segmentation using a VAD. ................................................................. 67 Figure 24: Block Diagram of the Proposed System.......................................................... 69 Figure 25: Pyroomacoustics Models. (a) 2D. (b) 3D. (c) 3D With Images. ..................... 75 Figure 26: LabVIEW Sub VI for Cross-Correlation Calculation. .................................... 82 Figure 27: LabVIEW Convolution VI. ............................................................................. 84 Figure 28: LabVIEW Deconvolution VI. ......................................................................... 85 Figure 29: LabVIEW Correlation VI. ............................................................................... 86 Figure 30: LabVIEW Cross-Correlation VI. .................................................................... 87 Figure 31: Audio Lab Components................................................................................... 93 Figure 32: Audio Lab Setup .............................................................................................. 94 Figure 33: Common AOLME Environment Setup. .......................................................... 95 Figure 34: Relative Positions of AOLME Participants..................................................... 97 Figure 35: Location of Speakers and Real Microphone. ................................................ 100 Figure 36: 3D Model of the Virtual Room ..................................................................... 101 Figure 37: Final 2D Model for AOLME Example. ........................................................ 103 Figure 38: Block Diagram of a Microphone Calibration Setup. ..................................... 105 xiii Figure 39: (a) Microphone Calibration Jig. (b) Location to Loudspeaker. ..................... 106 Figure 40: Audio Lab Set-Up for Pyroomacoustics Evaluation. .................................... 108 Figure 41: Final 2D Model of Audio Lab Setup. ............................................................ 110 Figure 42: 2D Model for Controlled Experiments. ......................................................... 115 Figure 43: Video Clips of Dave (Clip1), and HAL (Clip2). ........................................... 117 Figure 44: Sources and Noise for HAL 9000 Experiment .............................................. 119 Figure 45: Ground Truth Sets A and B for HAL 9000 Experiment. .............................. 121 Figure 46: Training Segments for HAL and Dave. ......................................................... 122 Figure 47:Video Clips for AOLME Experiments. .......................................................... 129 Figure 48: 2D Model for AOLME Experiments............................................................. 130 Figure 49: Room Parameters Reader Inputs and Outputs ............................................... 146 Figure 50: Room Parameters Reader Front Panel. .......................................................... 146 Figure 51: Room Parameters Reader Block Diagram..................................................... 147 Figure 52: Room Model Generator Icon. ........................................................................ 148 Figure 53: Room Model Generator Front Panel. ............................................................ 148 Figure 54: Room Model Generator Block Diagram. ...................................................... 149 Figure 55: Source Estimator Icon. .................................................................................. 150 Figure 56: Source Estimator Front Panel. ....................................................................... 150 Figure 57: Source Estimator Simplified Block Diagram. ............................................... 151 Figure 58: Cross-Correlation Model Calculator Icon. .................................................... 151 Figure 59: Cross-Correlation Model Calculator Front Panel. ......................................... 152 xiv Figure 60: Cross-Correlation Model Calculator Block Diagram. ................................... 153 Figure 61: Cross-Correlation Model Calculator. Cross-Correlator Sub-VI.................... 154 Figure 62: Model Classifier Icon with Inputs and Outputs............................................. 154 Figure 63: Model Classifier Front Panel. ........................................................................ 155 Figure 64: Multi-Function Convolution and Correlator Visualizer Front Panel. ........... 156 Figure 65: Multi-Function Convolution and Correlator Visualizer Diagram. ................ 157 xv LIST OF TABLES Table I: Template Cross-Correlation Table for Source 1. ................................................ 64 Table II: Template Cross-Correlation Table for Source 2. ............................................... 65 Table III: Template Cross-Correlation Table for Source 2. .............................................. 65 Table IV: Example Cross-Correlation Table Output from Model Calculator .................. 90 Table V: Cross-Correlation Tables for Classification ...................................................... 90 Table VI: Cross-Correlation Table for Microphone Calibration. ................................... 107 Table VII: Dimensions of Virtual Room and Location of Sources (in m). .................... 109 Table VIII: Experimental Results for Simulation Software Evaluation. ........................ 111 Table IX: Distribution of Microphones and Sources for Controlled Experiments. ........ 114 Table X: DER Results for HAL 9000 Experiments. ....................................................... 124 Table XI: Multi-Speaker Experiment Sequence Table ................................................... 126 Table XII: Controlled Environment Experiments Diarization Error Rate Results ......... 127 Table XIII: Location of Speakers and Microphones for AOLME Experiments. ........... 131 Table XIV: Speaker Assignment for AOLME Experiments. ......................................... 132 Table XV: CC Tables for AOLME Experiment. ............................................................ 133 Table XVI: Classification Results for AOLME Experiments. ....................................... 134 Table XVII: Experimental Comparison Between Methods. ........................................... 137 Table XVIII: % Average Error for All Three Methods. ................................................. 138 xvi Chapter 1. Introduction The field of speech processing, which includes speech recognition, separation, transcription, and enhancement, has undergone several transformational changes. Despite significant progress, speaker identification in crowded rooms continues to be a difficult problem. Crosstalk and large amounts of background noise make these environments particularly challenging. Most speaker identification and diarization systems rely on the use of Deep Learning methods that require pre-training on large datasets. Speech features such as formant frequencies, pitch contours, and coarticulation are extracted from the test samples and are eventually matched against a database of training samples [1]. The databases need to contain as many training examples as possible and should be updated periodically to maintain a proper performance level [2]. The accuracy of the identification depends on the size of the database: the bigger the database, the better the accuracy, but the longer the training times [3]. In addition to long training times, databases are prone to bias concerning spoken language and accent [4]. This biasing is usually unintentional and unconscious, and it is the product of the environment where the speech recognition system is developed [5]. The limitations of speech processing systems are more evident in challenging situations such as collaborative environments, meetings, or large-scale educational settings in general. These environments commonly consist of multiple speakers sitting around a table located inside a room. The speakers can take turns to speak, but it is not unusual to 1 have two or more speakers talking at the same time. The environment can also be very noisy if we have numerous participants or groups inside the same room. These types of environments are too difficult for most speech processing systems, requiring in many cases heavy manual analysis. Manual diarization of meetings is a tedious and time-consuming task that requires many hours of processing, and it is subject to many interpretation errors. There is a need in many educational research activities to understand how the classroom material engages the students. To understand how students interact, classroom sessions are recorded and transcribed. An important problem here is to determine which participant is speaking at a particular moment, what she or he has said, and for how long the participant spoke. Automated methods usually require multi-channel audio recordings and are prone to errors due to noise and crosstalk. Also, these systems have limitations in the number of speakers they can process, as well as the length of the audio segments. While diarization systems do not require enrollment of the speakers, they can only generate abstract labels of the speaker that is active in an audio segment. On the other hand, speaker identification systems can provide non-abstract labels by enrolling the participating speakers. The enrollment process consists of each speaker providing several seconds of noise-free speech without crosstalk. This requirement cannot be met when the data consists of audio recordings of busy meetings with noisy backgrounds. It is thus important to develop speech identification and diarization methods that do not impose any requirement to pre-enroll the speakers. 2 This dissertation aims to provide the foundations of a new approach to speaker identification and diarization using virtual microphones and spatial information. Simulations are never perfect, but this work shows that it is possible to use an approximation of a real room geometry to obtain the acoustic parameters necessary to simulate reception in a virtual array of microphones and use these simulated signals for speaker diarization and identification. The simulation is based on a physical model that requires no databases, it is independent of the spoken language or accent of the participants, it does not require prior speaker enrollment, and it presents high immunity to noise. The proposed approach relies on the fact that discriminant information about the 3D geometry of each speaker is embedded in the recorded audio from a single microphone. The basic idea is to recognize speakers using acoustical simulation. As part of the simulation process, the proposed method computes the Room Impulse Response (RIR) for each of the microphones and the speakers and simulates the reception on each of the virtual microphones. The accuracy of the process of computing RIRs is verified through real-life measurements of the correlation patterns. Based on the simulated reception over the virtual microphones, the method computes correlation patterns among the virtual microphones. The recorded audio is then also used to generate different correlation patterns based on hypothesized speaker locations. A classifier is applied to the generated correlation patterns to select the most likely speaker location. This approach has several advantages. First, we do not require databases of speech. Our system is based on physical models that are unique to the scene we are analyzing. 3 Because we do not have databases to train the model, our system requires capturing only about 1 to 2 seconds of audio from each speaker for both training and recognition. In contrast, state-of-the-art systems require tens of seconds of clean audio for training and several seconds of identification. Second, our system has been conceived to operate in noisy environments where microphone arrays and cross-correlation analysis have been proven to be efficient methods for speaker discrimination [6],[7]. Third, the simulation does not require multi-channel audio, but it uses a single channel recording as a reference for the simulation. Finally, our system can run on simple computers without the need to access remote computer clusters or databases. 1.1 Motivation This work is motivated by the need for a reliable non-manual method of assessing the level of engagement of the students participating in the Advancing Out-of-school Learning in Mathematics and Engineering (AOLME) program at the University of New Mexico (UNM) [8]. AOLME is a collaborative learning environment where students are introduced to STEM subjects such as integrating computer programming and middle school mathematics. It forms part of the educational research activities performed at the University of New Mexico’s Image and Video Processing and Communications Lab (ivPCL) [9]. AOLME sessions are video recorded for later analysis that includes students’ participation and overall level of attention, as well as the facilitator’s interaction with the students. The analysis consists of evaluating the activities of the participants such as hands 4 or head movement, use of keyboard and mouse, lip movement, etc., and transcription of the sessions to determine the time when a participant is speaking and for how long. Detailed participation statistics for each participant are currently not available because manually measuring talking times is time-consuming and plagued with errors. AOLME organizers have tried several transcriptions systems currently available in the market or open-source code, all without much success. The AOLME environment is extremely challenging for any speech recognition and transcription system due to multiple groups talking at the same time and the presence of background noise and echo. Hence, there is a need for a robust system that can overcome the limitations of the current state-of-the-art methods and complements the ivPCL methods, with the application to process hundreds of hours of video recordings. AOLME video analysis presents other challenges in addition to the presence of multiple speakers and noise. First, these videos were taken with a simple video camera using a single microphone located at the meeting table. Budget limitations restrict the purchasing and use of more advanced equipment with multi-channel audio recording capabilities. Second, there are already hundreds of hours of these video recordings that need to be analyzed. There was no previous speaker enrollment that could be used to train a speaker identification system. Furthermore, most participants only speak for several seconds at a time, which makes the identification process more difficult. Even if for future sessions it is possible to record multichannel audio and enroll the speakers, there is the need to process the existing videos, therefore the need for a flexible method that can handle 5 new and existing recordings. 1.2 Related Research Assessing the level of engagement of participants in collaborative educational sessions requires the application of tools to extract relevant information from audio and video data. This information is then interpreted and translated into statistical data for the researchers. For this end, these tools can either identify activities in a video scene that are related to attention behaviors (e.g., typing and writing), or they can identify the active speaker or speakers in an audio segment. Related work to this dissertation includes both types of tools. In the area of activity tracking, it is important to mention the work by UNM’s ivPCL lab in direct connection with the AOLME program. Darsey [10], analyzes video using color and optical flow for tracking hand movement. Teeparthi et al. [11], [12], presents fast methods of video analysis for hand and object tracking as well. Jacoby et al. [13] works in human activity detection using context-sensitive approaches, while Jatla et al [14] uses 3D Convolutional Nets. Eiliar et al. [15] provides a maintainable open-source activity system. Detection of attention traits is investigated by Shi et al. [16], using AM- FM models to detect head direction and group interactions. Research on speech processing covers a vast area containing different topics. Under the umbrella of speech processing, we find speech identification, speech enhancement, speaker verification, speaker diarization, and speaker identification, among others. This 6 dissertation focus on speaker identification and diarization as part of the research labor of the ivPCL lab and AOLME programs. Speaker identification is the process of recognizing the identity of a speaker or several speakers present in a speech segment. Speaker diarization is the process in which an audio recording that contains several speakers is dissected into segments that contain only one speaker at a time [17]. Speaker Diarization is often defined as “who said what, and when”, and for “how long”. Both Speaker Identification and Speaker Diarization are important mechanisms in many audio-processing tasks. Most of the research on speech processing nowadays is focused on the use of Artificial Neural Networks and Deep Learning. Deep Belief Networks (DBN) are widely used in speech recognition [18], [19]. X-vectors are considered today state of the art in speaker recognition [20]. X-vector methods outperform classic i-vector methods in the order of 9.23%, and they have been tested with datasets such as VoxCeleb, NIST SRE 2016, and SWBD [21]. The research in this dissertation focuses on the use of spatial information and virtual microphone arrays for speaker identification and diarization. There is no attempt to cover methods that do not use spatial information or virtual microphone arrays for speaker identification and diarization. Although not as extensive as the neural network and deep learning research, it was possible to find numerous works that demonstrated the use of spatial information for speaker identification and diarization, as well as applications of 7 virtual microphone arrays for acoustic signal enhancement and meeting diarization. The references to these works are presented in the next sections. Most literature regarding the application of microphone arrays (multichannel audio) and beamforming is related to the implementation of spatial filters to improve the signal-to-noise ratio (SNR). Nevertheless, several researchers found ways to exploit the operational principles of microphone arrays and apply them to speaker identification and diarization. Xavier Anguera et al. [22] propose the use of beamforming algorithms as the forefront of a speaker diarization system. These beamforming algorithms take advantage of the environment commonly encountered in meetings, such as multiple microphones, to enhance a single signal of interest. Anguera et al. optimize a conventional delay and sum beamforming array to operate under the constraints of an unknown number of speakers, unknown location of both speaker and microphones, and microphone mismatching. The Time Differential of Arrivals (TDOAs) of the microphones are calculated by cross- correlation. Diarization is accomplished by agglomerative clustering where each cluster is modeled via a Gaussian Mixture Model (GMM). A separate set of GMMs is used to model the TDOA features. In a similar manner as Anguera, Mitianoudis et al. [23] propose the use of beamforming in parallel with Independent Component Analysis (ICA) for audio source separation. The ICA for source separation requires knowledge of the parameters of the mixing matrix. If these parameters are not known, then the separation problem becomes a Blind Source Separation problem (BSS), which is an ill-posed problem (multiple 8 solutions). Mitianoudis et al. propose the use of the directivity pattern of beamforming (use of phase information) to select signals among different possible permutations. Both previous authors exploit the phase information of signals captured by microphone arrays. In my research, I also exploit the phase information (TDOA between microphones) as a means of determining the relative position of the active speaker and thus the identity. The previous work shows the use of cross-correlation to calculate the TDOA. Klein et al. [24] study the performance of the multi-channel cross-correlation (MCCC) coefficient method as a robust solution to calculations of TDOA under noisy and reverberant environments. Padois [25] studies the performance of time-domain beamformers based on the generalized cross-correlation functions. Padois generates a sound source map by interpolating the cross-correlation function between microphones, to generate a two-dimensional hyperbola of the spatial likelihood function. The number of hyperbolas corresponds to the number of microphones used in the array. The source position can be determined by averaging the hyperbolas and determining their maximum value as the intersecting point for the location. In general, the experimental results show that resolution improves with the number of microphones, up to a number where the performance seems to plateau. Pasha et al. [26] present work that is closely related to our research on RIR and room geometry for TDOA estimation. Pasha et al. propose a method of source localization that utilizes RIRs amplitudes to fit a TDOA surface and an amplitude surface across a room of known geometry. The RIR is obtained from a set of microphones of an unknown 9 location. The RIR amplitudes of the direct path impulses are higher and have a shorter relative time of arrival for the signals that are closer to the receiving microphone. The area with the maximum amplitude and minimum delay is considered the estimated source area. The center of these areas is the estimated source location. Similar work was previously presented by Tervo et al [27], but, instead of source location, this work focuses on localization of acoustic reflections using the combined TOA and the TDOA information contained in the RIR. All the work presented so far takes advantage of the properties of beamformers, TDOA, TOA, DOA, and cross-correlation, but also requires an array of physical microphones. In this dissertation, the method depends only on the information captured by a single microphone. Research material on single microphone acoustic separation based on spatial information is more limited, as well as work on virtual microphone arrays for the same purpose. Nevertheless, there is interesting work that provided useful information for my work. Perhaps the closest work to my research that I found is presented by Hu et al. [28]. Hu et al. propose a method to utilize the reverberant information, known as the Direct- to-Reverberant Ration (DRR), from a single channel recording for Speaker Diarization. Hu et al. estimate the DRR using the algorithm from Peso Parada et al. [29] and combine it with a Mel-Frequency Cepstral Coefficient (MFCC) diarization method proposed by Vijayasenan et al. [30]. The principle is to use both MFCC and DRR features in combination so a trained system can perform a clustering type of classification. The estimates for the DRRs are computed using features such as Signal-to-Noise ratios, 10 MFCCs, power spectrum, and zero-crossing rates. It is important to notice that this work was tested only using simulated meeting recordings and assumes that the speakers are stationary. Because the research work in this dissertation proposed virtual microphone simulations, it is necessary to present some relevant work in this area. Yoshioka et al [31] describe a way of linking several recording devices, such as laptops or mobile phones, to create a virtual microphone array. Once the link has been established, the multi-channel audio can be used for speaker diarization. Yoshioka et al. claim to achieve a 13.6% diarization rate when 10% of the speech duration contains more than one speaker. The Yoshioka et al. approach is very innovative but requires the presence of several recording devices in the meeting room. More aligned with this dissertation is the work of Katahira et al. [32], Del Galdo et al. [33], and Izquierdo [34]. Here the authors propose methods to simulate arrays of microphones by interpolating the signal received by two physical microphones. The authors demonstrate that the virtual microphone arrays improve the SNR in reverberant environments, hence their potential application for speech processing devices. Even though these methods succeed in emulating a set of virtual microphones, they need at least two physical microphones as “seed”, which are not available for the method presented in this dissertation. Finally, Tapia et al. [35] presented a bilingual speech recognition method inspired in the research presented in this dissertation. Tapia utilizes still video frames to estimate the approximate geometry of the speakers and simulate the center microphone reception 11 using Pyroomacoustics. The simulated audio is used along with ALOME transcriptions to generate the training sets for a convolutional neural network. 1.3 Thesis Statement The main objective of this dissertation is to develop a method that applies spatial information and virtual microphone arrays to identify multiple speakers in a single channel audio recording of a collaborative environment and provide activity statistics of each of the participants. This method is aimed to succeed in challenging environments with multiple active speakers and background noise, conditions that make the current state-of-the-art methods perform poorly. For this purpose, the work in this dissertation presents the implementation of an acoustic model based on a virtual room of rough similar geometry to the actual acoustic scene being analyzed, and then the simulation of the signals received by a virtual microphone array located in the virtual scenario. The signal delay between each virtual microphone represents the relative physical position of the active source that in this case is each speaker. The research goal is to find a suitable way to extract the spatial location embedded into a single channel recording to implement the model and subsequent virtual microphone array. 1.4 Contributions The contributions expected from this work include: 12  A method to identify speakers in a collaborative environment by extracting spatial information from a single channel audio recording utilizing an acoustic simulation and virtual microphones.  A solution for the limitations of current state-of-the-art speaker identification methods concerning: o Multiple speakers o Speaker gender or accent o Background Noise and reverberation.  Development of speaker identification framework that is based on an explainable model developed in terms of the physical characteristics of the problem, and hence does not require large datasets to train many parameters.  The basis for a tool for quantitative analysis of video recordings for assessing the level of interaction of participants in collaborative environments. 1.5 Dissertation Overview This dissertation is divided into 6 chapters that cover background theory and other related work, a description of our method, experiments, and results, and conclusion and recommendations for future work. The dissertation is presented as follows:  Chapter 2 gives a background of audio spatial theory and its applications in speaker diarization and identification, and how they functionally compare with other state- of-the-art methods. 13  Chapter 3 presents the foundations on which the proposed method in this Dissertation is based and a block diagram of its implementation.  Chapter 4 describes the practical implementation, including software, model implementation, simulation ions, video analysis, and audio segmentation.  Chapter 5 presents the experimental results obtained when analyzing audio under controlled and uncontrolled environments, and the experimental comparison of our method against current Google and Amazon speaker diarization methods.  Chapter 6 presents a summary of this dissertation and possible future work.  Appendix A contains the scripts and pseudo-code for the Python implementation of Pyroomacoustics.  Appendix B presents the most important LabVIEW Sub-VIs front panels and block diagrams.  Appendix C contains the specifications of the equipment used in the audio laboratory. 14 Chapter 2. Background This chapter introduces the principles that form the foundations that define the method described in this dissertation. The section begins with basic acoustic theory, concepts, and definitions, and continues with a presentation on microphones and microphone arrays. It finalizes with an introduction to methods for speaker diarization and identification, covering both classic methods and Deep Learning methods. 2.1 Acoustics Principles The perception of sound by a sound capturing device (e.g., a microphone or human ear), not only depends on the characteristics of the sound source, but it also depends on the medium where the sound propagates, the physical environment where the sound source is located, and the relative locations of the capturing devices and the source. This dissertation, considers all these factors to create models that represent the environment where the sound sources, i.e., the speakers, are active. Chapter 1 presented a brief introduction to the AOLME program. The AOLME video recordings were taken inside rooms where the participants gather in groups sitting around tables. The exact geometry of the room is unknown, but the video recording provides clues about the location of the speakers, the separation between them, their physical height, and the location of the recording microphone. These clues can be used for modeling a virtual room which can be defined as a three-dimensional enclosed space where 15 the acoustic event takes place. This virtual room may not be necessarily the whole space where all the AOLME participants are, but it can be the space surrounding the participants in a single table. The approximate geometrical and physical characteristics of the virtual room allow us to emulate the reception on arrays of virtual microphones. 2.1.1 Sound Propagation: Near and Far Fields Consider an acoustic source such as a person speaking, a stereo system playing a song, or a running ventilation fan. Sound from these sources propagates in the form of circular air pressure waves, away from the source. They can propagate in all directions if the source is in an open field (Fig. 1a), or directionally if the source is in proximity to a non-conducting medium such as a wall (Fig.1b). In acoustic theory, the relative location of a source to a point in space determines its field location. A source is in the near field if its distance to a point is less than one wavelength of the acoustic signal it is emitting. Sources that are located at distances greater than one wavelength are located at the far-field. The field location of a source plays an important factor when modeling the perception of sounds wave at a point in space. 16 Figure 1: Propagation of Sound Waves. (a) Free Field. (b) Directional. Fig. 2 shows a representation of the near field, the transition zone, and the far-field. In the near field, the sound waves behave turbulently, with more circulation than propagation. At about a distance of one wavelength from the source, the sound waves begin transitioning into propagation. At more than one wavelength, sound waves mostly propagate into the infinite. A point located at the near field perceives the sound waves as circular while one located at the far-field will consider these waves planar [36]. 17 Figure 2: Near and Far-Field Areas. 2.1.2 Sound Propagation: Direct Path, Reflections, and Reverberation The perception of sounds varies depending on whether the listener is located inside a theater room, small dormitory, or an open field. These differences in perception are the result of the behavior of the sound waves when they propagate across a medium. To visualize this phenomenon, consider for example a room where there is one acoustic source S (a person speaking) and one microphone M, as represented in Fig. 3. 18 Figure 3: Direct and Reflected Paths for Sound Propagation in a Diffuse Field. In Fig. 1(a) and Fig. 1(b), sound from the source will reach an observer or receiver directly, from one direction without reflections. In this case, the source is said to be in an acoustic free field. Fig. 3, in contrast, represents a diffuse field. In this case, the sound reaches the microphone from more than one direction due to reflections. As in the free field, the direct signal received at the microphone is characterized by the distance from the source to the microphone. This distance determines the sound pressure at the microphone, and the time it takes from the sound wave to reach the microphone. This time is known as the Time of Arrival (TOA), and it is a function of the speed of the sound in the room and the Euclidian distance from the source to the microphone. Each reflection contributes similarly. The signal received at a microphone can be expressed in mathematical terms. If we consider a signal s(t) from an acoustic source located in the far-field, this signal is captured 19 by a microphone as a signal x(t) that is the convolution of the Room Impulse Response (RIR) h(t) with additive noise w(t) as given by: 𝑥(𝑡) = 𝑠(𝑡) ∗ ℎ(𝑡) + 𝑤(𝑡) (2.0). The RIR is unique for every two points in the room and depends on the geometry of the room, the absorption of the materials in the room, and the frequency of the sources [37]. The RIR consists of three parts: the direct path, the early reflections, and the late reverberations. The direct path component is determined by the Euclidian distance of the source to the microphone, and it is a function of the Time of Arrival (TOA) or the time it takes for the signal to travel from the source to the microphone. The other two components of the RIR are related to the reflections of the sound waves at the walls and objects in the room. The early reflections usually arrive 5 ms after the direct path. The late reverberations arrive 20 or 30 ms after the early reflections begin. The RIR can then be expressed as the summation of each of the impulse responses corresponding to the direct path and the reflections: (cid:3012) ℎ(𝑡) = (cid:3533) ℎ(cid:3038)(𝑡) + 𝑚(𝑡) (cid:3038)(cid:2880)(cid:2869) (2.1), where K is the number of reflections, k is the index number of the reflection, and m is the measurement noise. The RIR lasts until the reverberation energy decays to 60 dB on what 20 is known as the T60 time. The T60 was calculated empirically by Sabine in 1890 and can be expressed as: 𝑇(cid:2874)(cid:2868) = 55.25 ∙ 𝑉 𝑐 ∙ 𝑆 ∙ 𝑎 (2.2), where V is the total volume of the room, c is the speed of sound, S is the total surface of the room, and a is the absorption coefficient of the room (0 to 1). The reverberations are characterized by the frequency of the sources but, in the case of the early reflections, this influence is minimum [27]. Fig. 4 depicts a representation of a RIR with its three components. Figure 4: Representation of the Room Impulse Response and its Components. 21 The path of the reflections from the walls can be represented as direct paths coming from imaginary sources called Images. The signal at any microphone would be then represented by the number of contributing sources plus their image reflections. All acoustic reflections are subject to a TOA that depends on the distance of the path of the reflection. Section 2.3 presents more detail on the concept of acoustic images and their role in room simulation. 2.2 Microphones and Microphone Arrays The previous section introduced microphones as devices capable of capturing sound. In general terms, microphones are sensing devices that detect changes in air pressure and convert these changes into electrical signals. Microphones are categorized by their electrical conversion type and their directionality pattern. Deep technical details for each type of conversion and directionality pattern microphone are out of the scope of this dissertation. The dissertation will only consider the type of microphones used during the research. 2.2.1 Classification of Microphones This research used two types of physical microphones: Condenser omnidirectional, and condenser cardioid. The condenser term refers to the type of electrical conversion of the sound, and the terms omnidirectional and cardioid refer to the directionality of the microphone. 22 Condenser microphones work by utilizing a variable condenser that detects the air pressure changes. The change in pressure translates into a movement of the plates of the condenser thus changing its capacitance. The changes in capacitance are measured by the changes in the charging current in a circuit. Condenser microphones are also known by the name of electret. They are the most popular type of microphones today. The directivity pattern of a microphone determines its gain or sensitivity according to the direction of the incoming sound. Omnidirectional microphones are equally sensitive to incoming sound from any direction. These microphones are simple pressure sensing devices or acoustic monopoles. Cardioid microphones are also known as pressure gradient microphones, and they are characterized for a directionality pattern that is like a heart (hence their name cardioid, from the Greek “heart”). Fig. 5 shows the typical directivity pattern for omnidirectional (a) and cardioid (b) microphones [38]. All AOLME videos were recorded using Audio-Technica ATR3350 condenser omnidirectional microphones. 23 Figure 5: Polar Pattern Plot of Directivity of Two Types of Microphones: (a) Omnidirectional. (b) Cardioid. Regardless of their type., all microphones generate noise. The conversion of sound pressure waves into electrical signals carries electrical noise, which has a flat spectrum [39]. Manufacturers usually indicate the electrical noise of their microphones in a Signal to noise ratio (SNR) number at a certain sound level. Appendix C contains the technical specifications of the microphones used for this research. 2.2.2 Microphone Arrays When two or more microphones are arranged into a geometric pattern, they become a microphone array. Microphone arrays have important functional properties that are of 24 interest when capturing sound in noisy environments, or when directionality is needed to discriminate between sound sources. An important part of the results of our research is based on the functional characteristics of microphone arrays. Microphone arrays allow for the incorporation of spatial dimensionality to sound capturing. The difference between the signals captured by any two microphones separated a distance d provides information that can be used for source localization, tracking, and general noise reduction. Microphone arrays can be expressed mathematically by (2.3) 𝒙 = 𝑠𝒅 + 𝒗 (2.3), where x represents the vector of all microphone signals, s is the source audio signal, d is the propagation vector represented in (2.4), and v is the additive noise [40]. The vector d is expressed by (2.4) 𝒅(𝑓) = [𝑎(cid:2869)𝑒(cid:2879)(cid:2870)(cid:3095)(cid:3033)(cid:3099)(cid:3117) … . 𝑎(cid:3041)𝑒(cid:2879)(cid:2870)(cid:3095)(cid:3033)(cid:3099)(cid:3289) … . 𝑎(cid:3015)𝑒(cid:2879)(cid:2870)(cid:3095)(cid:3033)(cid:3099)(cid:3263)](cid:3021) (2.4), where an represents the attenuation factor 1 (cid:3415) (𝑛) , 𝜏𝑛 is the channel delay 𝑑(cid:3046) 𝑐(cid:3415) (𝑛) and 𝑑(cid:3046) 𝑑(cid:3046)(𝑛) is the distance between the source and a microphone n, with c the speed of sound. The fine details of the theory behind microphone arrays are out of the scope of this dissertation. Nevertheless, it is important to have a basic knowledge of the properties of 25 microphone arrays due to their applications in source localization, spatial filtering, and source separation. All of these are applications related to this research and will be discussed later in this section. 2.2.2.1 Microphone Arrays Configurations The possible geometries of microphone arrays are infinite. These different geometries are guided by the number of microphones that can practically be allocated to an array, and the type of acoustic scenario the array is intended to operate. The most common types are linear, circular, and volumetric (3D) [41]. a) Linear Microphone Arrays: In this type of array, the microphones are linearly arranged. Fig. 6(a) represents a five-microphone array with a separation of 0.05 m between microphones. This array configuration is very popular, and it is designed to capture the sound that is in front of it. This type of array cannot distinguish from sounds that are coming from the same angle to the axis of the array, as the sound waves will arrive at the microphones with the same time delay. Fig. 6(b) shows the directivity pattern of the microphone array of Fig. 6(a), calculated at 450 Hz with the speed of sound c = 343 m/s. 26 Figure 6: Linear Microphone Array. (a) Geometry. (b) 3D Directionality Pattern. A variant of this type of array is a cross-linear array, also known as a planar microphone array. This type of array consists of two linear arrays perpendicular to each other, as shown in Fig.7. This is the type of array used in this dissertation for virtual microphone simulations. 27 Figure 7: Cross-Linear Array and Azimuth Directivity Pattern. b) Circular Microphone Array: This microphone array has its elements positioned circularly. They can consist of one circle, or several concentric circles, as shown in Fig. 8. This type of array is commonly found in conference equipment that is in the center of a meeting table. 28 Figure 8: Circular Microphone Array and Directivity Pattern. c) Volumetric (3D) Array: This type of array forms a lattice with its elements, as shown in Fig. 9. They can capture sound from any direction, for as long as they are “suspended in the air” with no other interference. Their shape can vary as cubes, spheres, or cylinders. 29 Figure 9: Volumetric Microphone Array and 3D Directivity Pattern. 2.2.2.2 Spatial Aliasing Signal aliasing occurs when the sampling frequency is less than twice the largest signal frequency component. When the bandwidth of the signal is greater than half of the sampling frequency, spectral overlapping happens. Spatial aliasing occurs similarly. To reconstruct a spatial signal from a set of samples, it is necessary to have a spatial sampling period that is less than half of the signal wavelength [42]. In microphone arrays, the phase difference between two microphones should be less than π to avoid spatial aliasing [43]. This constraint means that given a signal of frequency f, there is maximum distance 𝑑 between microphones before spatial aliasing occurs, and vice versa. For an audio signal of wavelength λ, this distance is half of the wavelength: 30 𝑑 ≤ 𝜆(cid:3040)(cid:3036)(cid:3041) 2 (2.5), which translates to a maximum frequency of 𝑓(cid:3040)(cid:3028)(cid:3051) ≤ 𝑐 2𝑑 (2.6), where 𝑐 is the speed of sound. 2.2.2.3 TDOA and Cross-Correlation A very important property of microphone arrays is the Time Difference of Arrival (TDOA) between microphones. The TDOA is defined as the difference in time a signal takes to reach two points separated by a certain distance 𝑑. To understand this concept, assume there are two microphones 𝑀𝑖 and 𝑀𝑗 separated by a distance d, and sound source S located at distances 𝐷𝑖 and 𝐷𝑗 from microphones 𝑀𝑖 and 𝑀𝑗 , respectively, as shown in Fig. 10: 31 Figure 10: Location of Source and Microphones for Time Difference of Arrival. The difference in the distance ∆𝑫 between 𝐷𝑖 and 𝐷𝑗 is defined as: ∆𝑫 = 𝑐 ∗ (∆𝑡) (2.7), where 𝑐 is the speed of sound and ∆𝑡 is the TDOA between 𝑀𝑖 and 𝑀𝑗. Conversely, if d and ∆𝑡 are known, it is possible to determine 𝐷𝑖 or 𝐷𝑗 if one of them is known. From (2.7), it is also possible to infer the proximity of the source to either microphone by the sign of ∆𝑫. Because ∆𝑡 = 𝑡(cid:3036) − 𝑡(cid:3037), a positive ∆𝑡 indicates that 𝑀𝑖 is closer to the sound source than 𝑀𝐽, whereas a negative ∆𝑡 indicates the opposite. The signal delay between microphones 𝑀𝑖 and 𝑀𝑗 can be also expressed in terms of their cross-correlation (CC). Let 𝑟(cid:3036),(cid:3037)(𝑡) = 𝑥(cid:3036)(𝑡) ⊛ 𝑥(cid:3037)(𝑡) denote the cross-correlation 32 between microphone signals 𝑥(cid:3036)(𝑡), 𝑥(cid:3037)(𝑡) corresponding to the microphones 𝑀𝑖 and 𝑀𝑗. The CC 𝑟(cid:3036),(cid:3037)(𝑡) between these two signals is defined as: 𝑟(cid:3036),(cid:3037)(𝑡) ≜ E(cid:3427)𝑥(cid:3036)(𝑡)𝑥(cid:3115)(cid:3365) (𝑡)(cid:3431) (2.8). The normalized cross-correlation is defined by: 𝑅(cid:3036),(cid:3037)(𝑡) = (cid:2869) (cid:3028)∙(cid:3029) 𝑟(cid:3036),(cid:3037)(𝑡) (2.9), where the 𝑎, 𝑏 are defined using 𝑎 = (cid:3495)∑ 𝑥(cid:3036) (cid:3047) (cid:2870)(𝑡) and 𝑏 = (cid:3495)∑ 𝑥(cid:3037) (cid:3047) (cid:2870)(𝑡) . 2.2.2.4 Beamforming and Spatial Filters The process of filtering each of the outputs of the microphones of an array into a single output is known as beamforming. Beamforming steers the array’s directivity pattern into a particular direction using beamforming filters [40]. The combination of the signals from each microphone is governed by: 𝑦 = 𝒘𝑯𝒙 (2.10), 33 where w represents the beamforming filters and 𝒘𝑯 is the conjugate transpose. The beamforming filters can be estimated as a function of a propagation vector d and a noise correlation matrix Q using: 𝒘 = 𝑸(cid:2879)(cid:2869)𝑑 𝒅(cid:3009)𝑸(cid:2879)(cid:2869)𝒅 (2.11). The filter described in equation (2.11) is known as the Minimum Variance Distortionless Response (MVDR), and it is one of the most popular types of beamforming filter. Refer to [31] for a full explanation of beamforming filters. If the location of the sound sources d is known, it is possible to construct a spatial filter for each of the sources. This approach is used to minimize crosstalk between channels and for noise reduction. The details of Spatial Filtering are outside the scope of this dissertation. Nevertheless, a brief introduction is presented because future work proposed in this dissertation includes a possible combination of the proposed method with spatial filtering and beamforming for speaker separation. 2.3 Modeling of Room Acoustics The proposed research requires the modeling of room acoustics. The simulation of microphones and sources are all based on physical models that predict the effects of the acoustic reflections given the geometry of the room and the location of the speakers. To this end, simulations calculate RIRs to the target points. The methods to model room 34 acoustics are dived into two categories: geometrical acoustics-based and wave acoustic- based [44]. Geometrical acoustics-based methods work by capitalizing the reflection properties of sound, i.e., sounds reflect into smooth surfaces in the same way light does, following Snell’s law. These methods are relatively easy to implement but do not take into consideration the roughness of the reflective surface. On the other hand, wave acoustic- based methods take into consideration the characteristics of the sound wave, providing a more accurate simulation. In contrast with geometry methods, wave methods are more computationally intensive and are limited to low-frequency ranges [45]. The simulation package used for this research is geometry acoustic-based; wave acoustic-based methods are not considered in this dissertation. The two more common geometry acoustic-based methods of modeling are the Ray Tracing Method and the Image Source Method. This dissertation focus on the Image Method as this method is the one used by the simulation package. 2.3.1 Ray Tracing Method The Ray Tracing Method assumes that sound radiates from the source as several rays [44] whose energy is the total energy of the source divided by the number of rays. These rays propagate at the speed of sound and, when they reach a boundary surface, some of the energy is reflected in an angle 𝛼′ equal to the incidence angle 𝛼, as it is shown in Fig. 11 (a). The perceived sound at any point is represented by an echogram that contains the history of all the ray reflections [45] plus the direct ray. The Ray Tracing Method was 35 introduced in the late 1960s and was widely used until the 1980s. Ray Tracing is a relatively straightforward method, but its resolution is limited [45]. 2.3.2 Image Source Method The Image Source Method (ISM, also known as Mirror Image Source Method MISM), is perhaps the most popular modeling method in use [46]. Image methods are used to solve physics problems, and in the late 1970s, Allen and Berkley [46], [47] introduced an algorithm to RIR related applications. In the Image Source Method, a virtual image or specular reflection of the source is created perpendicularly to the source, as shown in Fig. 11 (b). The sound received by the sensor 𝑀 is the summation of the sound from the source 𝑆 and the image source 𝑆′. Figure 11: Simulation Methods. (a) Ray Tracing. (b) Image Source Method. 36 The ISM needs the amplitude and delay of the image sources to calculate the RIR. Because there are infinite possible reflection paths, the ISM creates a map of mirrored rooms with the position of the number of desired images, as shown in Fig. 12. Figure 12: Source Image Map. The coordinates of each of the images are calculated using the map with the corresponding room size and the position of the source. Once the position of the images is calculated, the Euclidian distance 𝑑(cid:3041) from the image 𝑛 to the source is used to calculate the delay 𝜏(cid:3041) = (cid:3031)(cid:3289) (cid:3030) , where 𝑐 is the speed of sound inside the room. Finally, the amplitude 𝐴(cid:3041) of each of the signals from the images is calculated by the reflection coefficient 𝛽(cid:3041) of each of the walls crossed by the path from the image to the sensor, using (2.12) [46]: 37 𝐴(cid:3041) = 𝛽(cid:3041) 4𝜋. 𝑑(cid:3041) . (2.12). The RIR ℎ(𝑡) is calculated using the amplitude and the delay for the images: ℎ(𝑡) = (cid:3533) 𝐴(cid:3041) ⋅ 𝛿(𝑡 − 𝜏(cid:3041)) (2.13), (cid:3041)∈ℕ where ℕ represents the image sources and 𝛿 is the impulse function. 2.4 Characteristics of the Human Speech The performance of the method described in this dissertation will improve if the acoustic models are tailored to human speech. Human speech has some characteristics that can be exploited and used to compensate for some of the deficiencies encountered with the approximation of the geometry of the room and the limitations of the modeling software. Two characteristics of human speech: fundamental frequency and directionality are of particular importance. Speech is a non-stationary signal, or rather said, a non- stationary process, meaning that its frequency content is not unique in any given interval of time. The fundamental frequency of the human voice varies from 85 Hz to 180 Hz, with women going up to 255 Hz, and children to 300 Hz and even higher [48]. The whole spectrum of the human voice contains frequencies that go up to 8kHz. Much of the energy 38 is found in frequencies that are below 500 Hz for males and 800Hz for females [49]. As a curiosity note, the frequency sensitivity of the human ear is very close to the frequency spectrum of the human voice. This research work focus on the fundamental frequency to develop the acoustic models. More detail is presented in the Experimental Implementation section of this dissertation. The other important characteristic of human speech is its directionality. Speech does not propagate equally in all directions, but rather has directionality due to the location of the mouth and the shadow cast by the head and the torso [50]. Fig. 13(a) depicts the propagation of sound in the horizontal direction, while Fig. 13(b) presents the propagation in the vertical axis. Lower frequencies propagate farther from the back of the head than higher frequencies. Most propagation occurs at the front of the head. This directionality property is utilized for positioning the speakers in the simulation models. Figure 13: Directionality of Human Head [50]. 39 2.5 Speaker Diarization and Identification Section 1.2 presented a background on several methods for speaker diarization and identification that relate to this research. To understand the differences between these methods and the method proposed in this research, this next section reviews the fundamentals on which some of these methods are based on. Reviewing in detail all the methods presented in section 1.2 requires an effort that goes beyond the scope of this dissertation. For this reason, this dissertation only focuses on the most recent and common methods of speaker diarization and identification. 2.5.1 Methods for Diarization and Identification Speaker diarization can be summarized as “who said what, and when”, and for “how long”. The task of determining for how long one speaker has been active in a multi- participant conversation requires speaker diarization and subsequent identification with non-abstract labels. Speaker identification should not be confused with speaker verification. A system that accepts or rejects the identity claim by a speaker is called a speaker verification system. This dissertation divided these methods into two categories: Classic methods and Deep Learning methods. 2.5.1.1 Classical Methods for Diarization and Identification Anyone conducting a web search for “speaker diarization and identification methods” will find thousands and even millions of documents that somehow relate to the 40 subject (by the time of this dissertation, “speaker diarization methods” gave 66,400 hits, “speaker identification methods” about 48,000,00 hits, and “speaker diarization and identification methods” some 121,000). Nevertheless, until researchers started using Deep Learning and Neural Network methods, most speaker diarization and identification methods consisted of four basic modules or steps: A feature extraction module, a speech or voice activity detector (SAD or VAD, respectively), a segmenter or speaker change module, and finally, a clustering mechanism [51], [52]. Fig. 14 shows a block diagram of the four modules. Figure 14: Block Diagram of a Typical Speaker Diarization System. The feature extraction module generally uses Mel-Frequency Cepstral Coefficients (MFCC) as features. Not as popular as MFCCs, Linear Frequency Cepstral Coefficients (LFCC), and Perceptual Linear Predictive are also used as features [52]. The purpose of the speech activity module (SAD), also known as the voice activity module (VAD), is to detect the presence of speech. SADs or VADs (hereon referred to as 41 VAD) eliminate audio segments that contain no necessary information, such as noise or music, thus improving the performance of the segmenting and clustering modules. There are several different algorithms for these detectors, that vary from just energy level detection to binary classifiers based on pre-trained speech models. This research uses a custom-made VAD to segment the audio into frames, as it will be shown in later chapters. The next module to follow is the segmenter or speaker change detector. The segmenter detects when there is a speaker change in the audio and creates frames that ideally only contain one speaker. This is a necessary step before clustering, where the grouping of the clusters is done without previous information. A common method of segmentation is to measure the distance between two segments. Segments that belong to the same speaker are usually closer in distance than those coming from a different speaker. The models are usually Ergodic Hidden Markov Models (HMMs), where each state represents a speaker, and the probabilities are modeled by Gaussian Mixture Models (GMMs). Bayesian Information Criterion (BIC) is used to determine the nearest clusters, merging the clusters that generate the highest BIC, stopping the process when the values of the BIC are no longer positive. This algorithm was introduced by Chen et al. [53] and it is defined as (2.14) for a parametric Gaussian Mixture Model (GMM) with clusters 𝐶 with features [51] 𝐵𝐼𝐶(𝑀) = log ℒ (𝑋|𝑀) − 𝜆 2 #(𝑀) log(𝑁) (2.14), 42 where 𝑁 is the number of samples, #(𝑀) is the number of parameters of the model, and 𝜆 is a tunable parameter. The final clustering step groups together segments that belong to the same speaker. In most speaker diarization and identification approaches, clustering is achieved by agglomerative hierarchical clustering (AHC). Using the same distance concept, each segment is its cluster at the beginning of the process, and parts of clusters are merged until the stopping criterion is met. This criterion is ideally to get the number of clusters equal to the number of speakers. In practical terms, the stopping criterion is a threshold that is preset at the beginning of the process. 2.5.1.2 Deep Neural Networks The applications of Deep Neural Networks (DNNs) to speaker diarization have gained a lot of momentum in recent years. It is difficult to keep pace with the amount of research that is done on an almost monthly basis in this field. It is therefore of importance to have a basic understanding of how DNNs are applied to the problem of speaker diarization. In general terms, DNN speaker diarization/identification methods are divided into four groups [54]: Stage-wise, end to end, online, and multimodal. From these groups, this dissertation will address stage-wise and multimodal groups as they relate more to the research work. 43 2.5.1.2.1 Stage-wise diarization Stage-wise diarization methods are based on the same blocks or stages as the GMM methods covered in the previous section, but they rely on DNNs that employ a universal background model (UBM), rather than GMMs for feature extraction and clustering. For GMMs to be computationally efficient for feature extraction, each sequence of feature vectors is converted into a fixed-length vector, or supervector [55]. Because this approach makes GMMs susceptible to speaker and channel variations of utterances [56], it is desirable to reduce the dimensionality of the supervectors. These lower-dimensional vectors are called i-vectors (the i-vectors were previously referenced in the background section). The representation of i-vectors assumes that speaker and channel-dependent variabilities reside in a lower-dimensional space [57], which is represented by a total variability matrix T. For GMMs this conversion can be expressed as: 𝑠 = 𝑠(cid:4593) + 𝑇𝑤 (2.15), where 𝑠′ is the speaker and channel supervector and 𝑤 is the i-vector. Fig. 15 shows a GMM/i-vector framework [56]. 44 Figure 15: GMM/i-vector Framework. At this point, the effort moved to replace the GMM generated i-vectors for DNN generated i-vectors. The idea behind this approach is to replace the GMM generated posteriors for the feature vectors and take a DNN trained acoustic model using senones to generate these posteriors. Fig. 16 represents this approach [54]. Figure 16: DNN/i-vector Implementation. Although the performance of DNN based acoustic models has been proven [56], they require a large set of training data and more computational cost as well. 45 In addition to i-vectors, other DNN approaches include the use of d-vectors and x- vectors embedding. D-vectors were introduced by Variani et al. (2014), and they are based on assigning the ground truth training utterance to labels of the training frames to the corresponding utterance in the training stage, converting the problem into a classification one. For a more detailed description of d-vectors, refer to [54],[56]. X-vectors are derived from d-vectors. Instead of using frame-by-frame speaker labels, they use utterance-level speaker labels by aggregation. As was referred to in the background section, x-vectors outperform most i-vector and d-vector approaches. Refer to [54], [56], for details on x-vectors. Deep Learning clustering techniques are also applied in replacement of conventional distance and similarity methods. Clustering is treated as either a supervised or unsupervised problem, by employing recurrent neural networks (RNN) or discriminative sequence-to-sequence neural networks. References to these methods can be found in [54]. 2.5.1.2.2 Multimodal Speaker Diarization Related to our approach of exploiting video clues and spatial information, Deep Learning is applied to the analysis of not only visual clues, such as movement of lips [58], but also to the content of the speech of the participants [59], [60]. In this sense, multimodal methods train the networks based on the patterns that most likely belong to a genre of participants. For example, in a collaborative environment with students, the facilitator is more likely to have a calm voice, in contrast with the students. In recent publications, W. 46 Kang et al. [61], have presented speaker diarization based on d-vectors combined with spatial information provided by microphone arrays. 2.5.2 Current State-of-the-Art Methods for Diarization and Identification State-of-the-art methods cover the speaker diarization and transcription that major technology players are offering. They keep their technologies a secret, as they compete to have the most reliable service available, thus the difficulty in obtaining detailed information on how their methods work. It is expected that they somehow use the speaker diarization approaches reviewed in the previous sections. IBM, Google, Amazon, and Microsoft offer cloud computing that includes speech processing services based on algorithms that use Deep Learning and Machine Learning. Amazon’s, Google’s, and Microsoft’s are all closed-source cloud services that provide an API for speech-to-text processing and speaker diarization. This dissertation reviewed Amazon’s Transcribe (AWS) [62], Google’s Cloud [63], and Microsoft Azure Speech Services [64], and experimentally compared Amazon’s and Google’s against our proposed system. Amazon’s Transcribe accepts either audio files or streaming data, single-channel, and outputs text files with speaker diarization if this option is selected, and the number of speakers is specified. Amazon’s Transcribe works better with 2-5 speakers, and it is language-dependent, limited to 120 minutes of audio. Amazon’s Transcribe stores the voice data to train the models [65] unless the users select the option to delete this data. 47 Amazon offers a highly trained set of models called Amazon Transcribe Medical which is aimed at medical transcriptions. Users can also customize the vocabulary to better fit their needs. Amazon functionality can be accessed via REST and SOAP protocol over HTTP [66]. Google’s Cloud works similarly, with an interface for long speech, single-channel input for transcription purposes [65]. The optimum number of speakers is set at a maximum of 5. As with Amazon Transcribe, Google offers the option of privacy that prevents data logging that could be used to improve the models. Google’s models are optimized for phone conversations or videos, accepting 16 kHz or 8 kHz audio, respectively, depending on the application [67]. It also offers vocabulary customization. Google offers good scalability, infrastructure, and payment schemes that are considered the best among the technology giants [66]. Microsoft offers speaker diarization utilizing its Cognitive Services. Microsoft’s Diarization system ranked first at the VoxSRC challenge 2020 by achieving a Diarization Error (DER) of 3.71% in development and 6.23% in evaluation testing [68]. The datasets consisted of audio collected from YouTube recordings. For the challenge, the network was trained with 1500 hours of simulated mixed training audio. Microsoft Speaker Recognition [69] offers text-independent speaker recognition/verification. The speakers need to be enrolled to create a signature, which is later compared with the audio to be analyzed. The minimum requirements are 20 seconds of speech for training, and 4 seconds of speech for identification, with unlimited speaker enrollment, with only one speaker present. In the 48 case of diarization, Microsoft can only recognize up to two speakers. Microsoft Transcription requires multi-channel audio for diarization and the signature of the participating speakers for identification, labeling each speech segment with its correspondent speaker. Microsoft does not collect users’ voice tracks to train its models. Users can customize their vocabulary and the environment they are expecting to operate, meaning that customization must include noise, indoor or outdoor environments, multi- gender speech, etc. [64]. 49 Chapter 3. Proposed Method The previous chapter discussed the principles of acoustics, speech, and speaker diarization that served as the foundations for this research. This chapter will cover the mathematical models that are used to estimate the virtual microphones, and how they are implemented into a working system. Finally, it will present a block diagram detailing the function of each of the elements of the proposed system and its operation. 3.1 Methodology The goal of this dissertation is the identification of speakers from single-channel recordings using virtual microphones. This statement includes the objective (identify speakers), the data source (single channel recording), and the means to accomplish this objective (using virtual microphones). This section will begin by identifying the physical and mathematical elements of the models needed for the virtual microphone simulation. Let us consider a collaborative environment such as the one represented in Fig. 17 (a), where we have three speakers sitting around a table with a central recording microphone. Such an environment can be represented as a simple 2D model shown in Fig. 17(b) that shows the relative location of the speakers and the recording microphone. 50 Figure 17: Collaborative Environment (a) with 2D Model (b). To capitalize on the properties of microphone arrays, it is necessary to find a method to simulate several virtual microphones based on the information contained in the signal captured by the central microphone. From the discussion on microphone arrays in chapter 2, it is possible to implement several different virtual array configurations. Let us consider a cross-linear array with four microphones and one central recording microphone, as shown in Fig. 18. 51 Figure 18: 2D Model of Fig. 12(b) with Microphone Array. If Fig. 18 is an ideal representation, where there are no reflections or room absorption, then for each unique active speaker there will be a set of pairs of microphones with unique TDOAs that correspond to the active speaker. For example, if speaker 3 is active, then the TDOA between M5 and M3 and the TDOA between M2 and M3 will be unique for speaker 3. Having this concept in mind, we recall from Chapter 2 that the cross- correlation from any pair of microphones represents the signal delay between them. To uniquely identify each of the speakers, we are interested in the location of the peak of the cross-correlation function defined by: 𝑇(cid:3036),(cid:3037) = argmax 𝑅(cid:3036),(cid:3037)(𝑡) (3.0), 52 where 𝑅(cid:3036),(cid:3037)(𝑡) denotes the cross-correlation between two microphone signals 𝑥(cid:3036)(𝑡), 𝑥(cid:3037)(𝑡). If a source signal propagates to microphones 𝑖, 𝑗, 𝑇(cid:3036),(cid:3037) represents the time lag that it takes for the signal to reach 𝑗 after reaching 𝑖. Thus, 𝑇(cid:3036),(cid:3037) > 0 implies that the signal arrived at microphone 𝑖 before 𝑗. On the other hand, 𝑇(cid:3036),(cid:3037) < 0 implies that the signal arrived at microphone 𝑗 before 𝑖. The cross-correlation matrix of all possible values 𝑇(cid:3036),(cid:3037) will be used for determining the locations of the speakers. Now we move to the problem of simulating the virtual microphones. From equation (2.0) from Chapter 2, it is possible to extend this model for the case of multiple sources and microphones. Suppose that we have 𝐽 possible sources: 𝑠(cid:2869)(𝑡), … , 𝑠(cid:3011)(𝑡) and 𝑁 possible microphone signals: 𝑥(cid:2869)(𝑡), . . . , 𝑥(cid:3015)(𝑡). Next, let ℎ(cid:3037),(cid:3038)(𝑡) denote the RIR that describes the propagation from the 𝑗-th source to the 𝑘-th microphone. At the 𝑘-th microphone, we receive signals from all sources as expressed by: (cid:3011) 𝑥(cid:3038)(𝑡) = (cid:3533) 𝑠(cid:3037)(𝑡) ∗ ℎ(cid:3037),(cid:3038)(𝑡) + 𝑛(𝑡) (3.1), (cid:3037)(cid:2880)(cid:2869) where 𝑛(𝑡) represents additive white noise. For the model in (3.1), we need to estimate ℎ(cid:3037),(cid:3038)(𝑡). If ℎ(cid:3037),(cid:3038)(𝑡) is known, it is possible, at least in theory, to estimate the signal source by deconvolving the signal 𝑥(cid:3038)(𝑡) with ℎ(cid:3037),(cid:3038)(𝑡) (i.e., ℎ(cid:3037),(cid:3038) (cid:2879)(cid:2869)(𝑡)). Once the sources have been estimated, each virtual microphone can be emulated by just convolving the emulated source with each of the RIRs of the virtual microphones. 53 Some important factors need to be considered to develop a model for this approach. First, ℎ(cid:3037),(cid:3038) (cid:2879)(cid:2869)(𝑡) may not exist [70], and it may be necessary to construct virtual microphone approximations to ℎ(cid:3037),(cid:3038)(𝑡). Second, the speaker feature correlation matrix defined by 𝑇(cid:3040) is estimated under the assumption that speaker 𝑚 is talking while all other speakers remain quiet: 𝑠(cid:3038)(𝑡) = 0, 𝑘 ≠ 𝑚. Third, for each audio segment, we need to compute 𝑇, the cross- correlation matrix of the actual signal. Finally, we need to estimate the active speaker by solving match(𝑇, 𝑇(cid:3040)) (3.2), max (cid:3040) where match(. , . ) is a function of the similarity between 𝑇, 𝑇(cid:3040). We now can turn our attention to estimating the RIRs. As it was presented in Chapter 2, the RIR is a function of the geometry of the room, the relative location of the sources and microphones, and the physics of the room (i.e., the absorption of the room, which characterizes the reverberation). This information will be very difficult if not impossible to obtain from just the audio from the recording microphone, but we could use information from the video recording to estimate some of the parameters needed to calculate the RIR. From the video recording, it would be possible to approximate the location of the speakers and the virtual microphones to each other. This information, along with an empirical approximation of the absorption of the room, is all that is necessary to calculate the RIR. 54 Calculating the RIR can be a very tedious task. The number of calculations required is a factor in the degree of accuracy desired in the model. If we recall the concept of images from Chapter 2, the reception at a microphone is the result of the sum of the images; therefore, the fidelity will depend on the number of images added as part of the RIR function. The next chapter will present an open-source software package that performs these calculations thus saving some programming time. So far, this dissertation has presented the fundamentals of the simulation on which the proposed method is based. By using the approximate geometry of the room to calculate the RIR and to simulate the microphones, we should be able to calculate the cross- correlation between microphones and determine the active speaker. The proposed method then can be summarized in 5 steps: 1) Evaluating the room geometry and location of the speakers of the acoustic scene, 2) Estimating a generic RIR model for this geometry, 3) Training the model with known speaker samples, 4) Estimation of the sources that will fit the model for each of the possible active speakers given an unknown audio sample, and 5) Conducting a Cross-Correlation Analysis and classification. The following section explains each of the steps in more detail. 1) Evaluation of room geometry and location of speakers and microphones As it was described before, the RIR is a unique transfer function between two points in space. To calculate the RIR between a source and a microphone, it is necessary to know their spatial locations inside a physical room of known acoustic characteristics. In Fig. 17, 55 it is possible to appreciate the relative location of the three speakers and the recording microphone. This video frame can be used as a reference for the location of the sources and virtual microphones in the model, e.g., from this image we can approximate that the table is about 1.5 meters long by 1 meter wide, that the speakers are separated about 0.7 meters from each other, and the speaker’s mouths are about 0.24 to 0.25 m from the table. It is also possible to locate the reference microphone in coordinates that are relative to each of the speakers. These are just approximations to create a generic model from where to calculate the RIRs. Fig. 19 shows a possible 2D model for these approximations. Figure 19: Possible 2D Model for Fig. 17. The location and separation of the virtual microphones can be arbitrary for as long as they do not violate the rules of spatial anti-aliasing. As presented in Chapter 2, the 56 fundamental frequency of human speech varies from 85 Hz to 180 Hz approximately, with some extreme cases going up to 255-300 Hz (children). If it is assumed a max frequency average of 180 Hz using (2.6) and (2.7), the maximum separation 𝑑 for each microphone would be ≤ (cid:2871)(cid:2872)(cid:2871) (cid:3288) (cid:3294) (cid:2870)((cid:2869)(cid:2876)(cid:2868) (cid:3009)(cid:3053)) = 0.95 𝑚. 2) Estimation of the generic RIR model The approximation of the geometry of the room provides the basis to implement a generic model to calculate a set of RIRs to estimate the virtual microphone array. This model, as it was mentioned before, is based on an approximate geometry of the room, the location of the speakers, and the number of reflections. It is desirable to reduce the influence of reflections and reverberation in the simulation as they add complexity to the RIR. One way this can be achieved is by an overall reduction of the length of the T60. Recalling equation (2.2), we can minimize the volume of the room and maximize its absorption as a means of reducing the length of T60. These two parameters are easy to control and implement in the simulation. The number of images to calculate can be set to an acceptable value that compromises the simulation fidelity and the computational burden. Some trial and error may be necessary to optimize the number of reflections. Another point to consider is the directionality of the human voice. The human voice propagates mostly in one direction to the front of the head; therefore, our model must take this propagation inequality when simulating the audio reception at any point of the room. 57 One solution implemented in this research consisted of locating the speakers close to the end of the virtual room, so the reflections from the back of the speaker are minimized. With the approximate physical and acoustical characteristics of the room, it is then possible to calculate the RIRs between the virtual microphones of the array and the speakers. It was indicated in the previous section that it could be possible to implement any arbitrary array of microphones for as long as we follow the rules of spatial anti-aliasing. The calculated value of the distance d is well fitted between the boundaries of the proposed model, but it would be beneficial for the performance of the model to optimize the microphone array for maximum cross-correlation information. This can be accomplished by asymmetric microphone arrays, i.e., arranging the microphones at locations that are offset from equidistant points to the speakers. Also, the microphone arrays should have as many microphones as possible, for as long as the required computational resources remain manageable. 3) Estimation of sources and virtual microphones The next step is to apply our generic model to estimate the signal at the virtual microphone array based on the recorded signal at the reference microphone. To do so, it is necessary first to estimate the sources that would fit the model, i.e., estimate a set of sources that, when convolved with the model’s RIRs, will represent the signal at each microphone of the array, including the reference microphone. One way to estimate the sources is to deconvolve the reference signal with the RIR that corresponds to the source we want to 58 estimate. For example, assume that our model has three sources 𝑠(cid:2869)(𝑡), 𝑠(cid:2870)(𝑡) and 𝑠(cid:2871)(𝑡), three microphones M1, M2, and M3, with M3 as the reference microphone. If 𝑥(cid:2871),(cid:3037)(𝑡) is the signal received at M3 with 𝑗 = 1,2,3 for the respective sources 𝑠(cid:2869), 𝑠(cid:2870), and 𝑠(cid:2871), then to estimate 𝑠(cid:2869)(𝑡), 𝑠(cid:2870)(𝑡), and 𝑠(cid:2871)(𝑡) given 𝑥(cid:2871),(cid:3041)(𝑡) 𝑠̃(cid:2869)(𝑡) = 𝑥(cid:2871),(cid:2869)(𝑡) ∗ ℎ(cid:2871),(cid:2869) (cid:2879)(cid:2869)(𝑡) (3.3), 𝑠̃(cid:2870)(𝑡) = 𝑥(cid:2871),(cid:2870)(𝑡) ∗ ℎ(cid:2871),(cid:2870) (cid:2879)(cid:2869)(𝑡) (3.4), 𝑠̃(cid:2871)(𝑡) = 𝑥(cid:2871),(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2871) (cid:2879)(cid:2869)(𝑡) (3.5), with ℎ(cid:2871),(cid:2869) (cid:2879)(cid:2869)(𝑡) the inverse of ℎ(cid:2871),(cid:2869)(𝑡) (RIR from M3 to 𝑠(cid:2869)), ℎ(cid:2871),(cid:2870) (cid:2879)(cid:2869)(𝑡) the inverse of ℎ(cid:2871),(cid:2869)(𝑡) (RIR from M3 to 𝑠(cid:2870)), and ℎ(cid:2871),(cid:2871) (cid:2879)(cid:2869)(𝑡) the inverse of ℎ(cid:2871),(cid:2871)(𝑡) (RIR from M3 to 𝑠(cid:2871)). Fig. 20 shows how the sources can be estimated for the example of Fig. 17 and the model of Fig. 19. Once the sources have been estimated, they can be convolved with the remaining RIRs to obtain the simulated reception on each of the microphones of the array. Fig. 21 shows an example of how microphones M1, M2, and M3 are estimated using 𝑠(cid:2870)(𝑡). The process is extensive to the other sources as well. We can use an estimation or the ground truth for microphone M3. 59 Figure 20: Estimation of the Sources. Figure 21: Estimation of Virtual Microphones. 60 It may be noticed at this point that the solution presented above will only work if we know which n source is active at 𝑥(cid:2871),(cid:3041)(𝑡), and which ℎ(cid:2871),(cid:3041)(𝑡) we need to deconvolve with. To solve this problem, our method simulates each possible source by deconvolving the signal at M3 with each RIR of the model and then simulates the signal at each of the virtual microphones. The result is a set of virtual arrays that correspond to each of the possible active sources. In the three source examples, if 𝑥(cid:2871)(𝑡) is defined as the unknown signal at M3, the estimate of both possible sources 𝑠̃(cid:2869)(t), 𝑠̃(cid:2870)(t) and 𝑠̃(cid:2871)(t) is obtained by deconvolving 𝑥(cid:2871)(𝑡) with ℎ(cid:2871),(cid:2869)(𝑡), ℎ(cid:2871),(cid:2870)(𝑡) and ℎ(cid:2871),(cid:2871)(𝑡): 𝑠̃(cid:2869)(𝑡) = 𝑥(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2869) (cid:2879)(cid:2869)(𝑡) (3.6), 𝑠̃(cid:2870)(𝑡) = 𝑥(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2870) (cid:2879)(cid:2869)(𝑡) (3.7), 𝑠̃(cid:2871)(𝑡) = 𝑥(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2871) (cid:2879)(cid:2869)(𝑡) (3.8), and then emulating two sets of virtual microphones. Each set of the microphones is represented as 𝑥(cid:3028),(cid:3029), where a is the index of the virtual set, b is the index of the virtual microphone of the set, and ℎ(cid:3030),(cid:3031) is the RIR from source c to microphone d. For set 1: 𝑥(cid:2869),(cid:2869)(𝑡) = 𝑠̃(cid:2869)(𝑡) ∗ ℎ(cid:2869),(cid:2869)(𝑡), (3.9), 61 For set 2: For set 3: 𝑥(cid:2869),(cid:2870)(𝑡) = 𝑠̃(cid:2869)(𝑡) ∗ ℎ(cid:2869),(cid:2870)(𝑡), (3.10), 𝑥(cid:2869),(cid:2871)(𝑡) = 𝑠̃(cid:2869)(𝑡) ∗ ℎ(cid:2869),(cid:2871)(𝑡). (3.11). 𝑥(cid:2870),(cid:2869)(𝑡) = 𝑠̃(cid:2870)(𝑡) ∗ ℎ(cid:2870),(cid:2869)(𝑡), (3.12), 𝑥(cid:2870),(cid:2870)(𝑡) = 𝑠̃(cid:2870)(𝑡) ∗ ℎ(cid:2870),(cid:2870)(𝑡), (3.13), 𝑥(cid:2870),(cid:2871)(𝑡) = 𝑠̃(cid:2870)(𝑡) ∗ ℎ(cid:2870),(cid:2871)(𝑡). (3.14). 𝑥(cid:2871),(cid:2869)(𝑡) = 𝑠̃(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2869)(𝑡), (3.9), 𝑥(cid:2871),(cid:2870)(𝑡) = 𝑠̃(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2870)(𝑡), (3.10), 𝑥(cid:2871),(cid:2871)(𝑡) = 𝑠̃(cid:2871)(𝑡) ∗ ℎ(cid:2871),(cid:2871)(𝑡). (3.11). 62 4) Cross-Correlation and Model training The three sets of virtual microphones give us enough information for cross- correlation analysis and model training. To train the model, we take a small audio sample that contains only one active source (e.g., see Fig. 22), and we then use this information to generate a cross-correlation table that contains all combinations of possible sources and microphone pairs for that source. For the training, we include the background noise, as is shown in Fig. 22. Training the model for noise is explained later in the implementation section. These tables are templates for the classification of each of the active sources. For our example of three sources and three microphones, we calculate three cross-correlation tables for each known sample processed with filters for s1, s2, and s3, as shown in Table I, Table II, and Table III. 63 Figure 22: Training Samples from Each Speaker and Noise. Table I: Template Cross-Correlation Table for Source 1. r1-2 V1 V4 V7 𝑠̃(cid:2869),(cid:2869) 𝑠̃(cid:2869),(cid:2870) 𝑠̃(cid:2869),(cid:2871) r1-3 V2 V5 V8 r2-3 V3 V6 V9 64 Table II: Template Cross-Correlation Table for Source 2. r1-2 V10 V13 V16 𝑠̃(cid:2870),(cid:2869) 𝑠̃(cid:2870),(cid:2870) 𝑠̃(cid:2870),(cid:2871) r1-3 V11 V14 V17 r2-3 V12 V15 V18 Table III: Template Cross-Correlation Table for Source 2. r1-2 V19 V22 V25 𝑠̃(cid:2871),(cid:2869) 𝑠̃(cid:2871),(cid:2870) 𝑠̃(cid:2871),(cid:2871) r1-3 V20 V23 V26 r2-3 V21 V24 V27 where 𝑉(cid:2869) … 𝑉(cid:3041) are the values of the cross-correlations 𝑟(cid:2869),(cid:2870), 𝑟(cid:2869),(cid:2871), and 𝑟(cid:2870),(cid:2871) corresponding to the microphones M1-M2, M1-M3, and M2-M3 respectively, for each known sample source of 𝑠(cid:2869), 𝑠(cid:2870) and 𝑠(cid:2871). Table I will contain the results for the sample 𝑠(cid:2869), Table II for the sample 𝑠(cid:2870), and Table III for the sample 𝑠(cid:2871). Training needs to be done just once. 5) Analysis and Classification Cross-correlation analysis of multi-speaker audio is not possible unless this is divided into segments. Proper segmentation of the audio is important to the performance of the proposed method. Because the audio from collaborative environments contains multiple speakers, it is possible at any time to have more than one simultaneous active speaker. Also, it is possible to have periods of noise (there are no periods of silence) or 65 overlapping speech when one speaker finishes and another one begins speaking. For optimal cross-correlation location identification, each segment should only contain one active speaker at a time. If the audio contains overlapping speech or mixes of speakers, the location of the peak value of the cross-correlation between microphones will depend on the amount of information from each of the speakers that are contained in the audio segment, making the classification more difficult. One solution to maximize the probabilities of having only one active speaker in a segment is by minimizing its length: the shorter the segment is, the most likely it is to have content from only one speaker. There is, however, a limit on the minimum length of the segments. The minimum length of the segments is subject to the performance of the cross- correlation algorithm. This means the segments need to be long enough to contain sufficient information for the algorithm to calculate a meaningful cross-correlation. In addition, the total analysis time is affected by the number of segments that need to be cross- correlated and analyzed, hence the desire of reducing the number of segments. There is then a need for optimizing the length of the segments for a balance between the maximum information content and the minimum overlapping between speakers. Recalling from Chapter 2, the best way to segment the audio is to incorporate a VAD. Ideally, a VAD will detect speech content and the change of speakers based on a certain pre-determined energy threshold, as shown in Fig. 23. If the energy threshold is properly adjusted, a VAD can be effective in producing segments of audio that contain only one speaker at the time, and segments that contain mixes of speakers or noise, maximizing their information content. 66 Because VADs are not perfect, there will be always segments that could contain overlapping, mixes of speakers, or simply being misclassified. To minimize the number of misclassifications, the length of the segments can be limited to a maximum that provides an acceptable number of misclassifications. It was found during this research that segments that are more than 1.5 s long are prone to misclassifications, while segments of less than 500 ms are difficult to cross-correlate. Figure 23: Audio Segmentation using a VAD. Each audio segment will generate a single cross-correlation table that corresponds to each of the possible locations of the speakers, as it is done for training. The classifier will then use the cross-correlation template tables from training to compare with the analysis results and determine the most probable source match. Alternatively, it is possible 67 to cluster the cross-correlation results for later classification. Chapter 4 covers the analysis and classification methods of this research in more detail. 3.2 Block Diagram of the Proposed System Fig. 24 presents the block diagram of the proposed method. Chapter 4 covers the experimental implementation of each of the modules in this diagram, except for the clustering module, which was not implemented for this research. 68 Figure 24: Block Diagram of the Proposed System. The proposed system is divided into 4 subsystems described below: 1) Room Geometry and RIR Generator: The first subsystem of the block diagram is The Room Geometry and RIR Generator (RGRG). This subsystem accepts the room geometry parameters (geometry of the room, absorption, location of the speakers and microphones) and calculates the RIRs using synthetic speech sources. The RGRG consists of two modules: The Room Parameter 69 Generator (A) and the Room Model Generator (B). The Room Parameter Generator creates the vectors that contain the geometry of the room and the location of the speakers and microphones (virtual and real). The Room Model Generator gets the room geometry vectors and calculates the RIRs between the sources and the microphones. 2) Audio Pre-Processor: The second subsystem is the Audio Pre-Processor (APP). The function of the APP is to prepare the single-channel raw audio for analysis. It consists of two modules: The Training Sample Audio (C), and the Segmenter (D). The Training Sample Audio module contains the training samples of each of the speakers participating in the audio to be analyzed plus a sample of ambient noise. These samples are saved as .wav files and labeled independently. The Segmenter module uses a VAD to create segments of the audio to be analyzed. Each segment of audio is saved as a .wav file of variable duration, with a minimum and a maximum length threshold. The segments that are less than a predetermined length are discarded. 3) Analysis Subsystem: The function of the Analysis Subsystem (AS) is to calculate the cross-correlation between the emulated microphones. The AS consists of three modules: The Source Estimator (E), the Room Model Estimator (F), and the Cross-Correlator (G). The source Estimator gets the audio from the APP and deconvolves it with the RIR from the RGRG to estimate each possible source. The deconvolution is done to both the audio training samples 70 and the segments for analysis. The Room Model Estimator then emulates each of the microphones by convolving the estimated sources with each of the corresponding RIR calculated using the model room geometry. Again, this is done for both the training samples and the analysis segments. Finally, The Cross-Correlator module calculates the cross- correlation between the microphones for each of the possible source combinations, for both training and testing. 4) Classifier: The output of the AS subsystem is then handled to the Classifier. The classifier creates the cross-correlation sets of tables for training and testing. During training, only one table is created for each of the training audio samples. For testing, there is a cross- correlation table for each possible source for each of the segments, as was described in section 3.1. There are two possible paths of action once the cross-correlation tables are available. One path is to just run a clustering algorithm to group each segment in similar clusters or run a classifier that selects the best source that matches the training cross- correlation table. This research follows the classifier option, which will be discussed in the next section. The final component of the Classifier subsystem is the Speaker Metric module. The function of this module is to calculate the statistics of each of the participants, e.g., for how long they have been active, and when they have been active. In this research, our metrics only focus on measuring the total time each participant has been active. 71 Chapter 4. Experimental Implementation This chapter presents the software and hardware implementation of the proposed method presented in Chapter 3. It begins by presenting the software tools for simulation, deconvolution, and data handling, and continue with the software implementation based on the AOLME environment. This implementation will be used in the experiments of Chapter 5 to evaluate the performance of the proposed method. 4.1 Software and Hardware Tools The block diagram of Fig. 24 shows the need of developing several software modules to simulate the acoustics characteristics of the room, including RIRs and source image calculations, deconvolution for source estimation, cross-correlation, and classification. In summary, it is necessary to have code that performs the following operations: 1) Simulation of the geometry of a room 2) Calculation of all the RIRs based on the geometry of the room 3) Extraction of audio track from video recording 4) Segmentation of audio recording 5) Deconvolution of audio for source simulation 6) Simulation of microphone array 7) Microphone cross-correlation calculation 8) Analysis of microphone cross-correlation to identify the active speaker 72 9) Calculation of the metrics for each participating speaker. Developing code for the above modules is a time-consuming task due to the large number of mathematical algorithms and calculations needed. Fortunately, there are software packages available and code libraries that simplify the implementation of these modules into a software framework for the experimental analysis. This dissertation have combined open-source code and commercial software, saving a considerable amount of time to the alternative of writing code from scratch. 4.1.1 Open-Source Code for Room Geometry, RIR Calculation, and Microphone Simulation The open-source community of code developers offers an extensive variety of software libraries that cover a wide range of topics, from machine learning to financial market analysis, including acoustic simulations. Several acoustic simulation packages are available on GitHub for download. These packages are mainly designed to simulate the acoustics of environments for performing arts, such as theaters, stadiums, and recording studios. From these available packages, Pyroomacoustics was selected for RIR calculation and microphone simulation. Pyroomacoustics [71] is an open-source acoustic simulation package that calculates the RIRs and simulates the reception of the audio at a set of virtual microphones located inside a virtual room. Pyroomacoustics uses the Image Source Method (ISM) to calculate the RIR between a source and any point inside the virtual room. The location of the images 73 can be visualized with 2-D and 3-D representations of the geometry of the virtual room and the location of the sources and the virtual microphones. After simulating the location of the images, Pyroomacoustics calculates the RIRs to the target microphones and convolves the sample audio to simulate the reception at the microphones. Pyroomacoustics libraries' inputs are the geometry of the room, the location of the sources, the location of the virtual microphones, the absorption of the room, the sampling frequency, and the number of images to calculate. The outputs for the libraries include a set of arrays containing the RIR to each of the microphones and the emulated reception at each of the microphones. Figs. 25(a) and 25(b) show examples of 2-D and 3-D visualizations from Pyroomacoustics of a non-rectangular room 3 x 5 x 2 meters, with a circular microphone array with 6 microphones and one source. Fig 25(c) shows the same room with the simulated images. These types of representations will be used to approximate the AOLME models discussed later. Complete documentation on Pyroomacoustics functions and code can be found in [72]. 74 Figure 25: Pyroomacoustics Models. (a) 2D. (b) 3D. (c) 3D With Images. The version of Pyroomacoustics used for this research (0.4.1) has some limitations that needed to be considered when developing the models: 1) Microphones and sources are always modeled as omnidirectional. There are no options to add unidirectional sources or other types of microphones (e.g., cardioids); 2) All rooms are square, with no round corners; 3) There is no option to add objects such as tables inside the room, and 4) Absorption is an empirical parameter that needs to be estimated by other means outside the software. 75 All experiments in this research were conducted using Pyroomacoustics version 0.4.1. For the room geometry calculations, Pyroomacoustics libraries are called from a Jupyter Notebook under Anaconda 3. The libraries were also called from within LabVIEW using scripts under Python 3. 4.1.1.1 Pyroomacoustics Implementation Implementation of Pyroomacoustics for virtual microphone simulation is accomplished by four steps that include simulation of the room, placement of the sources and microphones, calculation of the RIR from the sources to the microphones, and convolution of the sources with the RIR for microphone simulation. This is done by calling the classes in the Pyroomacoustics libraries as follows: a) Room Simulation: The room simulation contains the parameters of the room, such as its dimensions, the absorption, the number of images to be calculated, and the sampling frequency. For example, the following script will generate a room of dimensions 9 x 7 x 3 meters, with a total of 9 images, at a sampling frequency of 9600 Hz: pyroomacoustics.room.Room([9.0,7.0,3.0], fs=9600, max-order=9) b) Sources and Microphone Placement: 76 This script adds the sources and microphones to the model. Pyroomacoustics need a valid audio file for source location. The following script will locate a source at X= 2 m, Y = 3 m, and Z = 1 m from the origin, and two microphones at X1 = 6 m, Y1 = 4, and Z1 = 1 m for microphone 1, and X2 = 6 m, Y2 = 4.5, and Z2 = 1 m for microphone 2: room.add_source([2.0, 3.0, 1.0], signal=audio) mic_locs = np.c_[ [6.0, 4.0, 1.0], # mic 1 [6.0, 4.5, 1.0], # mic 2 ] room.add_microphone_array(mic_locs) c) RIR calculation: By calling room.compute_rir() the RIRs are calculated to each of the microphones, and the results are saved in the form of a list of lists at the rir attribute of room. d) Microphone Simulation: The final microphone simulation is obtained by calling simulate(). This convolves the sources with each of the RIRs and emulates the signals in each of the microphones. The results of the convolutions are stored in the signals attribute of room.mic_array. Appendix A includes some of the scripts used in the actual experimental implementation of Pyroomacoustics. Refer to Pyroomacoustics documentation found at [72] for full description of the libraries and their algorithms. 77 4.1.2 Audio Segmentation Recalling from previous discussions, the practical analysis of long audio recordings is not possible unless they are segmented into smaller frames. Audio segmentation plays a critical role in the overall performance of the proposed method; therefore, careful consideration should be made with the algorithms for audio segmentation. As previously indicated, the audio segments need to comply with two main requirements: 1) Contain audio from only one active speaker with minimum overlapping or mixing between speakers, and 2) are of a length that provides enough signal information for cross- correlation analysis. Both requirements are difficult to achieve, and in chapter 3 it was introduced the concept of VADs as a segmentation method that maximizes the information content of a single speaker. Two segmentation methods were considered during this research: Fixed Segmentation and Voice Activity Detection. In the end, it was opted for VADs due to their better performance results. 4.1.2.1 Fixed Length Segmentation The simplest way to segment audio is to divide it into fixed-length segments. Fixed length segmentation is a relatively simple and computationally inexpensive method where each audio segment has the same length, independently of their content. Because there is no intelligence in this method, there is a probability of some of the segments containing overlapping speech. Also, it is very unlikely that the audio can be divided into exactly equal parts making the last segment of shorter duration than the others. 78 A solution to minimize overlapping is to make the segments as short as possible. As it was discussed before, if the segments are too short, they may not contain enough information for calculating the cross-correlation. There is therefore a balance between the optimum length of the segments and the desired classification error. One empirical way to find the length of the segments is by assessing the audio. If the audio contains well-separated speakers with little overlapping, the length of the segments can be longer than in acoustic scenes with noise or disorganized speech. This research conducted experiments with segment lengths varying from 250 ms to 1.2 s, obtaining different degrees of success. At the end, fixed-length segmentation was abandoned due to an undesirable number of errors and a lower performance when compared with voice activity detection segmentation. 4.1.2.2 Voice Activity Detection The VAD used in these experiments was programmed using MATLAB by a fellow graduate student at the University of New Mexico [73]. He used MATLAB Fast Fourier Transform (FFT) and Inverse Fast Fourier Transform (IFFT) functions to convert the audio from the time domain to the frequency domain and vice versa. First, the audio is converted into the frequency domain by applying the FFT, and then a 3000 Hz low pass filter and a 1000 Hz high pass filter are applied to remove some of the noise. The filtered audio is brought back to the time domain using the IFFT, and it is normalized afterward. An Amplitude Trigger (AT) with a threshold of 0.1 is used to determine the presence of speech 79 or noise. If the amplitude is exceeded at any time, this will be the beginning of a speech, and this time is marked as 𝑇(cid:2869). The level is checked 300 ms after 𝑇(cid:2869). If the AT is exceeded again, we mark that time as 𝑇(cid:2870), and check the AT again after another 300 ms. If the audio does not exceed the AT, then it is marked as the end of the audio with a time 𝑇(cid:2870) = 𝑇(cid:2869) +300 ms; otherwise, the end of the audio will be 𝑇(cid:2869) + 𝑇(cid:2870). When the audio does not exceed the AT and is not in the time range of speech, it is classified as noise. Using the information obtained from the filtered audio and adding a time offset (250 ms) to compensate for information missing in the filtered audio, we split the audio giving a maximum and a minimum time. If a noise segment is too small (under 250 ms), they will be combined with the audio segments since this is a pause of a person speaking. If there is noise or the audio is too long, it gets split into batches of a maximum time of 1.2s, with small exceptions that can go up to 1.449s. It is important to notice that audio segmentation produces artifacts at the beginning and the end of the segment [74]. These artifacts are the familiar “clicks” we hear when listening to a sequence of segments. In audio processing, it is common practice to apply a window, a filter, and overlap of the segments [74] to allow for a smooth transition between them. Our method did not apply windowing or overlapping due to the possibility of altering the spatial content of the segments; therefore, it was better to accept a reasonable error instead. 80 4.1.3 Implementation Using the LabVIEW Graphical Programming This research work used LabVIEW for deconvolution, array manipulation, classification, metrics, and user interface. LabVIEW is very popular in engineering due to its wide variety of built-in functions and its simplicity to create graphical user interfaces. It is not an open-source language, requiring the purchasing of a license. LabVIEW requires additional toolkits for some advanced digital signal processing, statistics, and software integration. This research applied the Advanced Signal Processing toolkit for cross-correlation analysis, convolution, and deconvolution calculations. Because Pyroomacoustics was used for all room simulations, it was necessary to install the Python Integration Toolkit provided by Enthought. This toolkit provides LabVIEW with the capability of calling Python code directly. LabVIEW is then used as a wrapper to call Pyroomacoustics Python libraries from within LabVIEW. In this way, LabVIEW provides the user interface for the Pyroomacoustics inputs (i.e., room geometry, number of images, audio files), and processes the outputs (i.e., RIRs, microphone simulations), saves the data, and displays the results. All documents and detailed description of LabVIEW can be found at the NI website [75]. Instead of scripting code, LabVIEW uses a graphical interface that contains functional modules called VIs (short of Virtual Instruments). The VIs perform basic functions such as adding, subtracting, array manipulation, and logical operations, among others. There are more advanced VIs to calculate more complex operations such as convolution and inverse convolution, correlation and cross-correlation, and file 81 manipulation, for example. Each VI transfers data using a wired connection, and there is a mechanism to handle and display execution errors. Fig. 26(a) and Fig. 26(b) show a screenshot of the internal block diagram and user interface, respectively, of the LabVIEW implementation used during this research for convolution, deconvolution, correlation, and cross-correlation operations between two files. The user can select between any of the operations using a drop-down selector. The implementation reads two text files that correspond to the audio files to be analyzed or convolved and a third file that corresponds to the RIR for convolution operations only. There are four graphics that represent the input files, the RIR, and the output of the cross-correlation calculation. The results can be saved as text files for later conversion into audio or any other format. Figure 26: LabVIEW Sub VI for Cross-Correlation Calculation. 82 Despite the popularity of LabVIEW among the engineering community, LabVIEW is many times regarded by hard-core coders as a language for those who do not know how to code. Its major deficiencies lie in the fact that its built-in functions are rarely modifiable, the block diagrams can get confusing if they are not divided into smaller VIs, and it is difficult to document and comment. The decision was to use LabVIEW because of the time-savings advantages it has over scripted languages. 4.1.3.1 LabVIEW Implementation The code written for this research used several built-in VIs available in LabVIEW version 2016, 32 bits. These VIs were implemented into more complex sub-VIs to run the calculations, data handling, user interface, file manipulation, and display of results. Although the code required the use of dozens of different VIs for simple mathematical operations and data flow, important calculations such as convolution and deconvolution were handled with LabVIEW built-in functions. 4.1.3.1.1 Function VIs The three functions VIs in this section were used to calculate convolution, deconvolution, and cross-correlation. They are part of LabVIEW's built-in library for signal processing. The algorithms for these functions are explained next. 4.1.3.1.1.1 Convolution VI 83 This VI computes the convolution of two vectors x and y. The convolution can be computed by selecting either a direct method or a frequency domain algorithm that uses the FFT, being the latter the one used for this research. The VI that represents the convolution is shown in Fig. 27. Documentation on this VI can be found at [76]. Figure 27: LabVIEW Convolution VI. The algorithm works by padding the ends of x and y with zeros to make their lengths M + N – 1, as shown in (4.0) and (4.1): 𝑥′𝑖 = (cid:3420) 𝑥𝑖, 0, 𝑖 = 0,1, … , 𝑁 − 1 𝑖 = 𝑁, … , 𝑀 + 𝑁 − 2 (4.0), 𝑦′𝑖 = (cid:3420) 𝑦𝑖, 0, 𝑖 = 0,1 … , 𝑀 − 1 𝑖 = 𝑀, … , 𝑀 + 𝑁 − 2 (4.1), The convolution is computed by calculating the inverse FFT of the product of the FFTs of 𝑥(cid:4593) and 𝑦(cid:4593) 𝒙(cid:4593)(𝑓) = 𝐹𝐹𝑇(𝑥(cid:4593)) (4.2), 84 𝒚(cid:4593)(𝑓) = 𝐹𝐹𝑇(𝑦(cid:4593)) (4.3), 𝒙 ∗ 𝒚 = 𝐼𝐹𝐹𝑇(cid:3435)𝒙(cid:4593)(𝑓) ∙ 𝒚(cid:4593)(𝑓)(cid:3439) (4.4), where IFFT is the inverse FFT. 4.1.3.1.1.2 Deconvolution VI The deconvolution VI computes the inverse convolution of two vectors x*y and y. It returns the value of vector x. Fig. 17 shows the symbol for this VI. Documentation on this VI can be found at [77]. Figure 28: LabVIEW Deconvolution VI. This VI implements the deconvolution by computing the Fourier Transform of the input x*y and y, then dividing them to create a new vector h. The vector x is computed by applying the IFFT to the sequence h. 85 4.1.3.1.1.3 Correlation VI The Correlation VI calculates the correlation coefficient r between two vectors x and y. Fig. 18 shows the icon for this VI. Documentation on this VI can be found at [78]. Figure 29: LabVIEW Correlation VI. This VI calculates the linear correlation coefficient, also known as Pierson’s correlation by (eq. number) 𝑟 = ∑ 𝑧(cid:3051)𝑧(cid:3052) 𝑛 (4.5), where 𝑧𝑥and 𝑧𝑦are the standardized z-values of x and y. The standardized z-values indicate how many standard deviations x and y are above or below the mean. 4.1.3.1.1.4 Cross-Correlation VI The cross-correlation VI computes the cross-correlation between two vectors x and y. The inputs for this VI are the vectors 𝒙𝒕 and 𝒚𝒕, the weighting specifies the use of a biased or unbiased weighting in the cross-correlation calculation, being the former the one used in all the calculations. The maximum lag specifies the maximum value of the lag this 86 VI uses to compute the cross-correlation. The maximum lag used equals max (M, N) – 1, where M and N are the lengths of 𝒙𝒕 and 𝒚𝒕, respectively. Fig. 30 shows the icon for this VI. Documentation on this VI can be found at [79]. Figure 30: LabVIEW Cross-Correlation VI. This VI computes the cross-correlation values between two univariate time series 𝑿𝒕 and 𝒀𝒕 according to the following equation: 𝑟𝑥𝑦(𝑘 + 𝑁 − 1) = 1 𝑎 ∙ 𝑏 ∙ 𝑤(𝑘) 𝑁−1 (cid:3533) 𝑋𝑡(𝑛)𝑌𝑡 𝑛=0 (𝑛 + 𝑘), 1 − 𝑁 < 𝑘 < 𝑀 (4.6), where = (cid:3493)∑ (cid:3050)(cid:2879)(cid:2869) (cid:3041)(cid:2880)(cid:2868) (cid:2870)(𝑛) 𝑋(cid:3047) , 𝑎 = (cid:3493)∑ (cid:3014)(cid:2879)(cid:2869) (cid:3041)(cid:2880)(cid:2868) (cid:2870)(𝑛) 𝑌(cid:3047) , 𝑿𝒕 has length N and 𝒀𝒕 has length M. The length of the output is N+M–1. w is the weighting factor which in our case, w(k) = 1. 4.1.3.1.2 Operational Sub-VIs This section will cover the Sub-VIs that form the core of the code that performs the computations needed for the analysis. These Sub-VIs contain the function VIs covered in 87 the previous section. Appendix B contains the front panels and block diagrams of these sub-VIs. 4.1.3.1.2.1 Room Parameters Reader The Room Parameters Reader Sub-VI reads the source locations, microphone locations, and 2D room dimension files created by the Pyroomacoustics Room Geometry Generator and formats them for the Room Model Generator Sub-VI. The room absorption, the room extrusion, and the number of images to calculate are just a pass thru. Appendix B section (a) shows the front panel and blocks diagrams for this Sub-VI. 4.1.3.1.2.2 Room Model Generator The Room Model Generator Sub-VI reads the room geometry parameters formatted by the Room Parameters Reader Sub-VI and runs the Python scripts that call the Pyroomacoustics libraries that compute the RIRs for the room model. This Sub-VI also reads the synthetic speech or noise .wav files used by Pyroomacoustics for the RIR calculations. The calculated RIRs are saved in .txt files for later retrieval by the Source Estimator Sub-VI. The Room Model Generator is used twice, first to calculate the room model RIRs for the source estimation, and again to emulate the virtual microphones using the estimated sources. Section Appendix B section (b) shows the front panel, block diagram, and inputs and outputs with more detail. 88 4.1.3.1.2.3 Source Estimator The Source Estimator takes the model RIR and estimates all the sources that will correspond to the audio segment that is being analyzed. For this estimation, this Sub-VI takes the segment of audio under analysis (corresponding to the real recording microphone) and deconvolves it with the RIRs for each of the source locations. The emulated sources are saved under .txt files for virtual microphone simulation using another instance of the Room Model Generator. Appendix B section (c) shows the details of this Sub-VI and a simplified block diagram. 4.1.3.1.2.4 Cross-Correlation Model Calculator This Sub-VI takes the results of the virtual microphone simulation from the second run of the Room Model Generator and calculates all the cross-correlations between the virtual microphones. The results are saved as cross-correlation tables and used for training and classification. Appendix B section d shows the details of this Sub-VI. The output of this Sub-VI is a table that contains all possible cross-correlations between microphones for each of the possible sources. For the three speakers and three microphones example, the cross-correlation table would look like the one represented in Table IV. The first row is the cross-correlation microphone combinations, and the first column is the speakers. The numbers represent the array index where the max occurs. 89 Table IV: Example Cross-Correlation Table Output from Model Calculator 1-2 96 -32 5 1-3 5 0 5 2-3 -5 -83 -130 1 2 3 4.1.3.1.2.5 Model Classifier The Model Classifier Sub-VI takes all the correlation tables, from training and testing, and performs the classification by comparing the testing results against the training templates. This is a very simple classifier that works by comparing each CC table for best similarity. For example, assume that the CC table IV corresponds to the training of speaker S1, and the analysis of an unknown audio segment produces the three CC tables shown in Table V(a), (b), and (c). The classifier simply counts the number of matches between each CC table and the training CC table. In this example, table V(a) has the greatest number of matches, indicating that the unknown segment corresponds to speaker 1. Appendix B section (e) shows the icon and front panel. Table V: Cross-Correlation Tables for Classification 1 2 3 1-3 1-2 96 1 2 -15 5 1 Total for S1 (a) 2-3 -5 -3 -130 Match 2 0 2 4 90 1 2 3 1 2 3 1-3 1-2 9 1 -32 6 2 9 Total for S2 (b) 1-3 1-2 6 8 -2 2 5 5 Total for S3 (c) 2-3 -1 -8 -13 2-3 -50 -8 -15 Match 0 1 0 1 Match 0 1 1 2 4.1.3.1.2.6 Multi-Function Convolution and Correlator Visualizer The Multi-Function Convolution and Correlator Visualizer is a full stand-alone Sub-VI used to manually convolve and deconvolve audio files and for correlation and cross-correlation analysis of files. Appendix B section (f) provides more information about this Sub-VI. 4.1.3.2 Audio Laboratory The purpose of the Audio Laboratory was to capture real audio in a controlled environment. This laboratory allowed to conduct experiments knowing the position of the speakers and microphones and control the content, duration, and characteristics of the analyzed speech. The results from the experiments performed at the audio lab were 91 compared against the results obtained from our proposed method and the simulation software. The audio laboratory consisted of a set of microphones, an audio processing device, an audio amplifier, loudspeakers, and the computer running the software that captures the recordings. The audio laboratory was physically configured to follow the common acoustic scene found on the videos analyzed in this research. This configuration used a set of loudspeakers located at the approximated position of the speakers sitting around a table. A set of microphones captured the audio at different locations of the lab, and one microphone was located at the same relative position as the recording microphone at the videos. Fig. 31 shows a block diagram of the lab components. The set of microphones were the same type used in the recording of AOLME video. These microphones were connected to the Tascam® Audio Processor. This processor can capture simultaneous audio from all six microphones and send it digitally to the computer via USB. The computer processes the audio using Tracktion Waveform® audio processing software [80]. This software processes the audio from the microphones and saves it in separate .wav files that correspond to each of the microphones. 92 Figure 31: Audio Lab Components. The simulation of the speakers is accomplished using a set of four loudspeakers connected to a stereo audio amplifier. Speakers 1 and 2 were simulated with the left stereo channel, while speakers 3 and 4 were simulated with the right stereo channel. A switch allows selecting between loudspeakers 1 and 3, and 2 and 4. The lab also included a Compact Disk (CD) player located at a certain distance from the table. This CD player was used to inject background noise during the experiments. Fig. 32 shows the actual audio laboratory setup where we can appreciate the location of its components. 93 Figure 32: Audio Lab Setup 4.2 The AOLME Environment The dissertation focuses on the analysis of audio from AOLME videos to assess the level of engagement of the participants. The AOLME environment is characterized by the presence of background noise, crosstalk, and other interferences that make it challenging for speaker identification tasks; therefore, to improve the identification rate, the simulation models must be optimized to fit this environment. This section studies the AOLME environment to find out how to best adapt the models to the acoustic characteristics of this environment and implement these models for the experimental section. 94 4.2.1 Characteristics of the AOLME Environment Fig. 33 shows a screen capture from one of the AOLME videos analyzed in this research. The scene shows a typical collaboration table with four students and one instructor. It is common to have 5 to 10 of these tables, with three to six participants each, distributed in a room of approximated dimensions of 9 x 14 x 2.5 m. The camera is recording the audio via a single omnidirectional microphone that is resting on the top of the table. In addition to normal room noise, this environment presents other elements that make its dynamics more complex. For example, it is typical to have the participants shuffling papers, leaning over the table, eating, speaking simultaneously, and accidentally covering the microphone with books or other utensils. Furthermore, there are occasions when another staff member walks in and joins the group for a conversation. Figure 33: Common AOLME Environment Setup. 95 The first step in building the models is to approximate the location of the speakers and the recording microphone. By analyzing the scene in Fig. 33, it is possible to get some clues that can be used to approximate these locations. From Fig. 20, it is possible to estimate the relative locations of each of the speakers with respect to each other and the recording microphone. It is noticeable also that the position of the speakers forms a rectangle that can be translated into a 3D figure whose bottom area is the table and its height is defined by the tallest speaker. The second step is to approximate the geometry of the room. From Fig. 33, it is possible to recognize that there is a nearby wall behind speakers 1 and 3. The second wall is located behind speaker 2 at a farther distance from speaker 2 than the first wall is located from speakers 1 and 3. There is no indication of any other wall or the presence of the celling, which we are assuming exists. It is also assumed that there are other tables nearby, but these cannot be seen in Fig. 33. 4.2.2 Preparation of the Experimental Models As mentioned earlier, the models are based in part on the geometry of the room and the location of the speakers. Because this exact information is not available, the models need approximations based on the observations made from the video shot. Also, recalling from section 4.1.1, our version of Pyroomacoustics does not allow us to simulate complex environments like the one shown in Fig. 33, where we have the participants sitting around 96 a table. Fortunately, the models do not need to be perfect, and we can make assumptions that will reduce their complexity. 4.2.2.1 Approximating the Models Using Video Observations We are ready to make some assumptions and approximations based on observations from the video. Fig. 34 shows another frame from the same AOLME video recording, where it is easy to estimate the relative distances between the participants. In Fig. 34, H1 represents the height of speaker 2, while and H2 represents the relative height of speakers 1, 3, 5, and 4. S represents the separation between speakers, and D represents the width of the table. We are assuming also in this observation that speakers 1 and 4 are separated by the same distance D. Figure 34: Relative Positions of AOLME Participants. 97 In Fig. 34, D can be approximated to the width of two standard commercial tables, which we can assume is 0.8 m x 2 = 1.6 m total. Speaker 2 is sitting about half of this distance, about 0.8 m from each edge of the table combination. Speaker 1 is close to one of the corners of the table, as it is speaker 4. The separation S between speakers can be approximated to 0.3 m, and the recording microphone can be located at half of this distance at the center of the table. Finally, H1 can be approximated using as reference the average waist to head distance of a young female, to about 0.5m, and H2 to the average waist to head distance of kids 11 years old, to approximately 0.4 m. These values are just examples to illustrate the principle on which we are basing the approximations. The actual model will not necessarily use these values. There is no prior knowledge of the dimensions of the room that can be used to approximate its geometry. Observations about the location of the walls and the ceiling only provide a reference for the location of two walls. Nevertheless, it is possible to recognize, given the appearance of the scene, that the remaining walls are at a greater distance than the visible ones. This assumption does not provide a numeric value to the location of the walls or the ceiling, but it gives a clue of the behavior of the sound in the room. Recalling Section 2.4, the human voice propagates mostly unidirectionally to the front of the speaker. Speakers 1 and 3 will project their voices toward speakers 4 and 5 and vice versa. Most of the sound energy from speakers 1 and 3 is absorbed by speakers 4 and 5, with some energy reflected by the table, some traveling to the ceiling of the room, and some other amount propagating to the walls behind. The walls reflect the residual 98 sound energy to speakers 4 and 5, and the process repeats until all the energy is absorbed, following the 𝑇(cid:2874)(cid:2868) rule. The same process applies when speakers 4 and 5 are active. In the case of speaker 2, there are no reflecting surfaces directly located in front of her, and the computer screen is located at a distance where the sound reflections from it can be considered of minimal influence, making the table the only reflecting surface. Under this model, it is possible to conclude that the sound energy of the participants is mainly contained within the boundaries of the table, and the contributions of the reflections due to the walls can be considered in practice as negligible, given the directionality of speech, the absorption of the speakers, and the separation of the speakers to the wall and the ceiling of the room. The previous analysis indicated that it is not critical that the models take into consideration the reflections from the walls, suggesting that the rooms can be modeled as to be of infinite dimensions or to have an absorbance that is close to 1. Unfortunately, having a room of infinite dimensions will lead to a problem when modeling the sources. As discussed previously, the simulation software only allows for omnidirectional sources and microphones. In a wall-less room, Pyroomacoustics will create images from speech that equally propagates in all directions from the speaker, which we know is not accurate. The solution is to place the sources at very close proximity from the walls of the model and make the virtual room of the size of the table, thus reducing the propagation behind each speaker to negligible levels. 99 The analysis described above gives the basis for a first model representing the location of the speakers and the recording microphone. Recalling the 2D model of Fig. 19, we can set up a 2D model based on the acoustic scene of Fig. 34, representing the location with respect to the table of the 5 speakers and the real (recording) microphone. Note that this model includes a 6th “speaker” that represents the room noise. Representing the noise as a separate speaker allows for better discrimination between audio segments containing noise and those containing speech. Figure 35: Location of Speakers and Real Microphone. The Z dimension (room height) needs to be added to convert the 2D model into a 3D model. Because the perimeter of the room is limited to the size of the table, the table itself can be modeled as the floor of the room. With this approach, all locations will be zero-referenced with respect to the table. 100 The total height of the room can be approximated in a similar manner as it was done for the perimeter of the room. Because of the directionality of the human voice, it is expected that there will be a little transmission of voice energy to the ceiling; therefore, the reflections coming from above can be neglected. The ceiling can then be located at any height for as long it is above the maximum height of the taller speaker. Empirically, this value can be set, for example, at 1 m above the table. The 3D model for the room dimensions and the speakers is shown in Fig. 36. Figure 36: 3D Model of the Virtual Room The last element needed to complete the model is the location of the virtual microphones. Their location is constrained by the dimensions of the virtual room and the maximum anti-aliasing distance between them. Also, it is necessary to consider that the array of microphones consists of a set of virtual microphones plus a real microphone, which 101 is resting at the top of the table. At this location, the real microphone receives no sound reflections from the bottom; therefore, it can be assigned a Z value of zero. Because the real microphone is resting on the table, there are mechanical vibrations transmitted from the table. To simulate these vibrations, all models in this research include some value for the Z component of the real microphone. The location of the virtual microphone array can be arbitrary, and the separation between microphones is not critical because the distance between two adjacent microphones will never exceed the maximum for anti-aliasing. However, it is of interest to have unique cross-correlation values between microphones. For this, the array should be in an asymmetric position with respect to the speakers in such a way that the value of the magnitude of the cross-correlation between microphones is different for each speaker. The Z value of the virtual microphones can be arbitrary, but because Pyroomacoustics can only simulate omnidirectional microphones, it is of advantage to locate them a certain height above the reference microphone. All the models in this research have microphones located at approximately the height of the speakers, allowing for simulation from all directions. Fig. 37 shows the complete 2D model derived from the five-speaker AOLME environment example. This type of model is used in all experiments in this dissertation, with the variations needed to fit the objective of the experiment. 102 Figure 37: Final 2D Model for AOLME Example. 103 Chapter 5. Results This chapter presents the experiments conducted to evaluate the capability of the proposed method to identify speakers in audio segments. The experiments focused on three objectives: 1) To determine the suitability of Pyroomacoustics as a simulation package; 2) to evaluate the performance of the proposed method for diarizing and identifying speakers; and 3) to compare the performance of the proposed method against Amazon AWS and Google Cloud. These experiments included both real audio recordings from the audio lab and AOLME videos. 5.1 Evaluation of Pyroomacoustics The objective of this experiment was to evaluate Pyroomacoustics as simulation software. This experiment compared the cross-correlation measured between real microphones and the cross-correlation between emulated microphones using Pyroomacoustics. This experiment was performed using the audio lab, with a Pyroomacoustics simulation based on the geometry discussed in Chapter 4. 5.1.1 Microphone Calibration All audio recording devices have an electronic delay that varies from equipment to equipment. To measure the real cross-correlation between physical microphones, it is necessary to measure this electronic delay for each of the microphones and apply a calibration factor if necessary. Because Pyroomacoustics version 0.4.0 simulates all 104 microphones as ideal and does not consider any delays, it is necessary to calibrate the real microphones to compensate for their delays before comparing them against any simulation. One way to calibrate the microphones is to place them in an array configuration and locate this array in the proximity to an audio source. Fig. 38 shows a block diagram of the components needed to calibrate the microphones. This calibration setup consists of an audio source, speaker, sound processor, and microphone array. The audio source is driven by a signal generator, and the sound processor can acquire six audio channels simultaneously. Figure 38: Block Diagram of a Microphone Calibration Setup. a) Calibration Preparation A homemade jig made of cloth pins was used to hold the six microphones for calibration. The configuration and separation of the microphones are shown in Fig. 39(a). The array of microphones was located next to one of the loudspeakers, as shown in Fig 39(b). With this configuration, the distance of each microphone to the sound source is about 105 the same for all microphones, making the time differential of arrival between them neglectable. (a) (b) Figure 39: (a) Microphone Calibration Jig. (b) Location to Loudspeaker. 106 b) Calibration Execution A 450 Hz signal was applied to the loudspeaker using a signal generator, to the loudspeaker, and the output of the six microphones was collected simultaneously using the sound processor and the computer running Tracktion Waveform® software. Each channel recording was saved as a separated .wav file of 2 s duration, sampled at 48 kHz. To measure the delay between microphones, each of the .wav files was converted into .txt files for cross-correlation analysis using the Multi-Function Convolution and Correlator Visualizer Sub-VI. Each combination of microphones was cross-correlated as shown in Table VI. The results in Table VI show that Microphones 1, 3, and 6 had zero cross-correlation between them. The same was observed between microphones 2, 4, and 5. Rather than apply a calibration factor, it is more convenient to segregate the microphones into groups and measure the cross-correlation between pairs that belong to the same group. Note that the results shown by Table VI correspond to the index of the array where the max cross-correlation occurs. Table VI: Cross-Correlation Table for Microphone Calibration. 1 s 2 e n o 3 h p 4 o r c 5 i 6 M 1 - 50 0 49 50 0 2 -50 - -50 0 0 -50 Microphones 4 -49 0 -49 - 0 -49 3 0 50 - 49 50 0 107 5 -50 0 -50 0 - -50 6 0 50 0 49 50 - 5.1.2 Audio Lab Setup and Model Configuration Fig. 40 shows the laboratory setup for this experiment. The setup follows the general model configuration described in Chapter 4, but the microphones were distributed between the loudspeakers to maximize the cross-correlation value differences between microphones. The dimension of the lab setup allows for the microphones to be within the anti-aliasing distance already calculated of 0.95 m. Microphone 3 was kept in the same location as the recording microphone of the draft model. Figure 40: Audio Lab Set-Up for Pyroomacoustics Evaluation. The Pyroomacoustics model was set up following the configuration of the audio lab. Because the audio lab has only 4 loudspeakers, speakers 5 and 6 were not included in the model. The virtual room perimeter was set to the size of the lab table, and the height of 108 the room was set to a value of 1 m. The absorption of the model was set empirically to 0.95 and the number of images at 8. The microphone height was set to 0.025 m for all microphones, following the observations made in Chapter 3. Table VII shows the final dimensions of the virtual room and the location of the sources (loudspeakers) and microphones used to create the Pyroomacoustics model. The final 2D model geometry generated by Pyroomacoustics is shown in Fig. 41. Table VII: Dimensions of Virtual Room and Location of Sources (in m). Z 0.25 0.25 0.25 0.25 --- --- 0.025 0.025 0.025 0.025 0.025 0.025 -- -- -- -- Y 0.79 0.4 0.79 0.01 --- --- 0.79 0.01 0.35 0.1 0.7 0.79 0 0.8 0.8 0 1 Sources Mics Room S1 S2 S3 S4 S5 S6 M1 M2 M3 M4 M5 M6 CORNER 1 CORNER 2 CORNER 3 CORNER 4 EXTRUDE X 0.4 0.01 1 0.4 --- --- 0.015 0.015 0.9 1.39 1.39 0.7 0 0 1.4 1.4 109 Figure 41: Final 2D Model of Audio Lab Setup. 5.1.3 Experimental Execution Both audio lab and simulation sections of this experiment used as a source one anechoic male voice of 2 s of duration. The source was played sequentially on each of the loudspeakers corresponding to S1, S2, S3, and S4, and it was captured simultaneously into the six-channel audio processor, corresponding to each of the microphones. The six- channel audio then was saved as six independent audio files using Tracktion Waveform®. The simulation with Pyroomacoustics used the geometric model of Fig. 41. Because there was no need to estimate the sources, the simulation of the reception at microphones M1, M2, M3, M4, M5, and M6 was accomplished by only running the Room Model Generator Sub-VI with the geometric model and playing the source at the location of speakers S1 to S4. The Sub-VI saved the results of each microphone simulation as a separate .txt file. 110 5.1.4 Results The final analysis consisted of running the Multi-Function Convolution and Correlator Visualizer Sub-VI to calculate the cross-correlation for each of the real microphone audio files (ground truth) and the simulated microphone audio files. The cross- correlation was calculated between microphones of the same group as it was determined during calibration. There was no need for audio segmentation due to the short duration of the sample audio. Table VIII shows the results in ms of the offset between the ground truth and the simulated signals, corresponding to a sampling rate of 48 kHz. Table VIII: Experimental Results for Simulation Software Evaluation. S1 S2 S3 S4 Sim. G.T. Diff Sim. G.T. Diff Sim. G.T. Diff Sim. G.T. Diff 0.34 -0.58 -1.62 0.38 -0.34 0.24 -1.24 0.38 0.72 1.56 1.88 0.32 0.20 0.80 0.30 0.68 0.10 -1.06 -1.30 0.24 0.12 0.18 0.30 0.12 -1.08 -0.88 0.20 -1.90 -1.56 0.34 -0.48 -0.50 0.02 -1.90 -1.62 0.28 0.58 0.40 0.18 0.00 -0.02 0.02 1.82 0.26 0.48 1.62 1.12 1.96 0.06 0.50 1.46 0.96 0.14 0.08 0.06 0.02 0.20 -0.60 -0.32 0.28 0.02 -1.98 -1.56 0.42 0.16 -2.58 -2.08 0.50 0.16 -0.56 -0.50 0.06 1-3 1-6 3-6 2-4 2-5 4-5 Table VIII shows that the simulation correctly predicts the sign of the cross- correlation for each of the microphone pairs. The maximun offset difference is 0.5 ms which corresponds to a difference of 20%, and the average difference is 0.2 m, hence the 111 simulation model appears to be sufficiently accurate for differentiating speakers based on their positions. 5.2 Controlled Environment Experiments The objective of this next set of experiments is to evaluate the performance of our method to identify speakers in single-channel audio segments that were recorded under controlled conditions at the audio lab. There were two controlled experiments: The first experiment demonstrated the capability of the proposed method to identify two speakers based only on their location. The second experiment demonstrated the capability of the proposed method to identify multiple speakers independently of their spoken words. 5.2.1 Methodology The approach for these experiments is to physically emulate an open collaborative environment such as AOLME in which we record audio containing speech with a single microphone. Because the geometry of the acoustic scene is known, we can create a model that numerically follows this real scene, and then evaluate the performance of the proposed method using this model. Conversely, by having control over some of the parameters, such as the location of the sources, it is possible to experiment with different microphone arrays and absorptions values to evaluate the performance of different models. The controlled experiments used the same audio lab configuration and the same Pyroomacoustics model from the previous experiment. A change was made to the location 112 of the speakers to better fit the distance that will be used for the AOLME experiments. 5.2.1.1 Audio Lab and Model Preparation Table IX represents the audio lab configuration for this experiment, with the location of the loudspeakers and the recording microphone (MIC3). The audio was recorded using the Canon video camera connected with MIC3, and the video recording was saved in the internal SD card of the camera, the same way it is done with AOLME recordings. Ambient noise was injected using the CD player with background noise from one of the AOLME video sessions. 113 Table IX: Distribution of Microphones and Sources for Controlled Experiments. Sources Mics S1 S2 S3 S4 S5 S6 M1 M2 M3 M4 M5 M6 M7 CORNER 1 CORNER 2 Room CORNER 3 CORNER 4 EXTRUDE X 0.4 0.16 0.65 0.3 --- 0.98 0.6 0.65 0.6 0.6 0.6 0.55 0.6 0 0 1 1 Z 0.25 0.25 0.25 0.25 --- 1.5 0.025 0.025 0.025 0.025 0.025 0.025 0.025 -- -- -- -- Y 0.79 0.5 0.79 0.2 --- 0.4 0.6 0.55 0.55 0.45 0.5 0.55 0.65 0 0.8 0.8 0 2 The lab setup was translated into the Pyroomacoustics 2D model shown in Fig. 42. Noise is represented as “speaker” S6 and placed it in a relative location that resembles the location of the CD player. All sources and microphones kept the same Z coordinate value as in the previous experiment (0.25 m), except for the noise S6, which is located at Z= 1.5 m, to better represent the location of the CD player. This experiment (and for all subsequent experiments in this research), used a linear cross-type virtual microphone array with 7 elements, with the recording microphone 114 located at the center of the array. This type of microphone configuration is flexible and compact and allows its implementation in other models with different geometries. The separation between microphones in the array was set to 0.05 m, which is a distance commonly found in commercial microphone arrays, which is around 0.025 m to 0.040 m. The virtual microphone array is located at an offset position to the loudspeakers, avoiding any symmetry with them. This location should provide more distinctive cross-correlation results between microphones for better differentiation. Figure 42: 2D Model for Controlled Experiments. 5.2.1.2 Evaluation Criteria A common method to measure the performance of diarization systems is the Diarization Error Rate (DER) [81], [82]. The DER is defined as the fraction of the time that is not attributed correctly to a speaker or non-speech [38]. It can be calculated as the 115 summation of all errors as follows: 𝐷𝐸𝑅 = (cid:3007)(cid:3002)(cid:2878)(cid:3014)(cid:3036)(cid:3046)(cid:3046)(cid:2878)(cid:3016)(cid:3049)(cid:3032)(cid:3045)(cid:3039)(cid:3028)(cid:3043)(cid:2878)(cid:3004)(cid:3042)(cid:3041)(cid:3033)(cid:3048)(cid:3046)(cid:3036)(cid:3042)(cid:3041) (cid:3019)(cid:3032)(cid:3033)(cid:3032)(cid:3045)(cid:3032)(cid:3041)(cid:3030)(cid:3032) (cid:3013)(cid:3032)(cid:3041)(cid:3034)(cid:3035) (5.0), where FA is the length of False Alarms, Miss is the length missed speech segments, Overlap is the total length of overlapped speech, Confusion is the total length of misclassified segments, and the Reference Length is the total length of the audio reference. Overlap was not used in any of the tests. 5.2.2 “HAL 9000” Experiments The objective of this experiment is to demonstrate that the proposed method can identify speakers solely on the location of the speaker and independently of their speech characteristics. This was accomplished by using non-anechoic audio as the speech source, obtained from a raw video clip of a classic movie. Many of the software packages for speech processing found during this research provided some sort of test files for evaluation. One of these demos included a phrase from the classical 1967 movie “2001, a Space Odyssey”. In this movie, the human crew faced the rebellion of the spaceship’s computer, “HAL 9000”, which after some malfunction, attempts to kill the crew. The phrase “I’m sorry Dave, I’m afraid I can’t do that” is still very well-known nowadays when we discuss the implications of artificial intelligence taking over the control of critical missions. 116 This experiment used a clip of 128 seconds of duration where this famous phrase is spoken. This clip included the conversation between Dave, who is inside a space pod (Fig. 43, clip1), and HAL at the mothership (Fig. 43, clip2). The video scenes switched between the space pod and the spaceship, with voices coming from radio transmissions, or the inside of the spaceships, depending on the scene. There is also some background noise from the electronic equipment at the space pod. This clip can be downloaded from YouTube at https://www.youtube.com/watch?v=Wy4EfdnMZ5g&t=11s Figure 43: Video Clips of Dave (Clip1), and HAL (Clip2) SOURCE: Fandango Movie Clips. Two sets of experiments were performed: Experiment 1 was aimed to determine if there was any biasing on the results as the product of the location of the speakers. Experiment 2 evaluated the effects of training in the results. 117 5.2.2.1 Source Preparation and Editing This experiment played Dave’s and HAL’s voices independently at the loudspeakers. To do so, the YouTube video was converted into a single channel using Audacity ® version 2.4.2 [83] and saved as a MP4 48 kHz audio (See Fig 44 (a)). Then, using Audacity, the segments with voices of Dave and HAL were cut and pasted in two separate channels of a new stereo track (Fig. 44 (b)). The intervals with noise were converted into silence to allow the recording noise to come from an external source. Dave was placed on the right track and Hal was placed on the left track. The noise segments were copied and pasted into a separate audio track and burnt into a CD (Fig. 44 (c)). 118 Figure 44: Sources and Noise for HAL 9000 Experiment 119 With this configuration, it was possible to play Dave at loudspeakers 1 (S1) and 2 (S2), and HAL at loudspeakers 3 (S3) and 4 (S4), by using the loudspeaker switch. The noise was played at the CD player in a continuous loop and modeled as S5 or S6. 5.2.2.2 Ground Truth Recording Two sets of recordings were taken for this experiment. Set 1A consisted of playing the audio track using the loudspeakers 1 (Dave) and 3 (HAL). Set 1B consisted of playing the loudspeakers 2 (Dave) and 4 (HAL). The noise track was played in a continuous loop by a CD player located at the position of Source 6. The audio was recorded using the Canon video camera with the microphone located at the position of microphone 3 in Table IX. The recording was transferred to the computer for segmentation and training. Because the camera records audio in stereo mode and the code can only handle mono audio, the stereo track was converted into mono audio by removing the right channel. This conversion kept intact all the spatial information contained in the left channel. Using Audacity’s “convert to mono” feature would have mixed both channels, rendering the spatial information useless. Fig. 45 shows the final sets 1A and 1B of audio captured by the camera. 5.2.2.3 Training and Segmentation Both models for experiments 1 and 2 were trained with segments of speech from Dave and HAL, and a segment of noise. For experiment 1A, the model was trained with Dave as S1 using a 1.98 s long segment, and HAL as S3 with a 1.76 long segment, as shown in Fig 46. 120 Figure 45: Ground Truth Sets A and B for HAL 9000 Experiment. 121 Figure 46: Training Segments for HAL and Dave. 122 Noise was trained as S6 with a 2 s long segment. S2, S4, and S5 were set to silence. For experiment 1B, Dave was trained as S2, and HAL was trained as S4. S1, S3, and S5 were set to silence, and S6 was noise. All training segments were about the same length as in 1A. For Experiment 2, the model was trained with HAL as speaker S1 and S4, and Dave as speaker S2 and S3. The noise was trained as S6, and S5 was set to silence. The recorded audio was segmented in two different ways. For experiment 1, the VAD was set with a maximum length segment of 5 seconds, ending with an audio of 120.39 s after subtracting the dropped segments. For experiment 2, the length of the segments was limited to a maximum of 1.5 s. Frames of less than 500 ms were discarded for both experiments. 5.2.2.4 Testing and Results Table X shows the results of experiments 1 and 2. We can appreciate that the length of the segments has an influence on the DER. In this experiment, the longer the segments, the less the error. These results agree with our previous discussion on the amount of information needed for proper cross-correlation. It is important then to optimize the length of the segments so they can contain as much information as possible and maximize the matching probabilities with the training template. 123 Table X: DER Results for HAL 9000 Experiments. Exp Test No. Segments 1 2 A B -- 71 71 122 Properly Classified Segments 58 58 99 False Alarms (s) 5.68 1.22 11.31 Miss (s) Confusion (s) 1.46 3.01 1.2 2.88 2.32 10.98 DER 0.083 0.054 0.195 5.2.3 Multi-Speaker Identification Experiments The objective of the experiments in this section is to measure the performance of the proposed method to identify several speakers in single-channel recording, independently of the content of their speech. As with the previous experiments, the geometry of the room and the location of the speakers is known, allowing for models that represent more accurately the actual acoustic scene under analysis. The experiments in this section used the same lab setup and models of the “HAL 9000” experiment. The experiment was divided into four separate tests, that included two speakers and four speakers. Three of the experiments have two independent speakers repeating the same phrases, at different positions. The last experiment has four separate speakers at four different locations. 5.2.3.1 Source Preparation and Editing The speech sources for the experiments consisted of four different speakers, two male, and two females, sampled at a rate of 48 kHz. These sources were downloaded from 124 the Telecommunications and Signal Processing Laboratory of McGill University, database version 2 [84]. The lengths of these sources vary between 1.2 to 3 s, approximately. A total of four audio tracks were prepared for analysis. Tracks A, B, and C had two speakers, while track D had four. The sources were arranged into one stereo track, so they can be played at the loudspeakers LS1 and LS3, and then switched to be played at LS2 and LS4, as it was done with the HAL 9000 experiments. A small pause was inserted to allow for switching between loudspeakers. Table XI shows the structure of each of the audio sample. Each sequence in the table indicates the label of the active speaker, the loudspeaker playing the speech, and the label of the spoken phrase. For example, audio sample A contains two sequences, 1 and 2. Sequence 1 is played at loudspeaker S1 by speaker 1, speaking phrase “a”. Sequence 2 is played by speaker 2, loudspeaker S3, speaking phrase “b”. In samples B, C, and D, speakers repeat some of the phrases with the objective to demonstrate the ability of the proposed system to differentiate the speakers regardless of their speech content. 125 Table XI: Multi-Speaker Experiment Sequence Table Duration (s) Conditions 1 2 3 -- -- -- Loudspeaker S1 S3 Speaker Phrase 1 a 2 b Loudspeaker S2 S4 S2 Speaker Phrase 1 a 2 a 1 b Sequence 4 -- -- -- -- -- -- 5 -- -- -- -- -- -- 6 -- -- -- -- -- -- 7 -- -- -- -- -- -- 8 -- -- -- -- -- -- 9 -- -- -- -- -- -- A 4.78 B 6.05 Loudspeaker S1 S1 S3 S1 S2 S4 S4 S4 S4 C 39.58 Speaker Phrase 1 a 1 b 2 c 1 d 1 e 2 f 2 g 2 h 2 i 10 -- -- -- -- -- -- -- -- -- l e p m a S Loudspeaker S1 S3 S1 S3 S3 S2 S2 S4 S2 S4 D 27.73 Speaker Phrase 1 a 2 a 1 b 2 b 2 c 3 d 3 e 4 f 3 g 4 h 5.2.3.2 Ground Truth Recording The audio was captured the same way as in the “HAL 9000” experiments, using the Canon video camera and saving the video recording in the camera’s internal SD storage. Ambient noise was injected by paying background noise using the CD player, as it was done for the “HALL 9000” experiments. The background noise was extracted from one of the AOLME video recordings. As with the “HAL 9000” experiments, the stereo recording from the video camera was converted into single-channel audio by removing the right channel, before the analysis. 126 5.2.3.3 Training and Segmentation The training was done with segments that had a maximum length of 1.5 s for each of the speakers, plus 1.5 s segment of noise. The custom VAD was used for segmentation. The number of segments produced for each of the audio tracks varied as is shown in the results table. 5.2.3.4 Testing and Results Testing was conducted in the same manner as the “HAL 9000” experiments. The results for each of the segments are shown in Table XII. Table XII: Controlled Environment Experiments Diarization Error Rate Results Audio Sample No. Speakers No. Segments A B C D 2 2 2 4 9 15 116 37 Properly Classified Segments 7 12 98 27 False Alarms 0 0 10 2 Miss Confusion DER 2 2 0 0 0 1 8 8 0.19 0.19 0.12 0.27 Table V shows that the DER is not more than 0.27 in the worst case. These results are comparable or better than DER results from methods using databases and neural networks [85] 127 5.3 AOLME Experiments The controlled environment experiments demonstrated that the proposed method could identify speakers in single-channel recordings. These experiments analyzed audio samples that featured organized speech (one speaker at a time), where the speakers are well separated from each other (no overlapping between speakers). The objective of the AOLME experiments in this section is to evaluate the performance of the proposed method to identify speakers in single-channel audio recordings from videos of noisy multi-speaker collaborative environments. This section evaluates the process of selection of the AOLME videos for the experimental analysis, and discusses the models employed for the analysis. The analysis of the audios will follow the same approach as the previous experiments. 5.3.1 Evaluation and Selection of AOLME Videos There are several hundred hours of AOLME video recordings available for analysis but, because of the experimental nature of this research work, it was necessary to select videos that met certain characteristics that facilitate the preparation of the models and the setup of the experiments. The models used in the previous experiments proved to perform well, and for this reason, it was necessary to search for AOLME videos with similar geometric characteristics as these models, i.e., the participants were in similar places as the speakers in the model from our previous experiments. The selection consisted of four videos with 2, 3, 4 and 5 participants from the library of videos. The videos were 128 approximately 3 minutes long each. Fig. 47 shows frames from these videos with 2 participants (a), 3 participants (b), 4 participants (c), and 5 participants (d). As was done in the previous experiments, the stereo audio track for each video was extracted and converted into a 48 kHz single channel by removing the right channel. Figure 47:Video Clips for AOLME Experiments. 5.3.2 Model Preparation The model used for this experiment followed the same geometry as the previous experiments, with the width of the table adjusted to 1.8 m to fit the AOLME scene more accurately. Instead of generating separate models for each of the videos, the model had all 129 three speakers for all the experiments. As previously done, the locations of the absent speakers were turned off by training with a silence segment. Fig. 48 shows the 2D Pyroomacoustics model and Table XIII shows the locations of the speakers and the microphones. Figure 48: 2D Model for AOLME Experiments. 130 Table XIII: Location of Speakers and Microphones for AOLME Experiments. s r e k a e p S s c i M m o o R S1 S2 S3 S4 S5 S6 M1 M2 M3 M4 M5 M6 M7 CORNER 1 CORNER 2 CORNER 3 CORNER 4 EXTRUDE X 0.40 0.01 1.00 0.40 1.20 2.40 0.75 0.85 0.80 0.80 0.80 0.80 0.80 0.00 0.00 2.50 2.50 Y 1.79 0.80 1.79 0.01 0.01 1.00 1.00 1.00 1.00 1.05 0.95 1.10 0.90 0.00 1.80 1.80 1.80 2.00 Z 0.25 0.25 0.25 0.25 0.25 1.50 0.03 0.03 0.03 0.03 0.03 0.03 0.03 -- -- -- -- 5.3.3 Training and Segmentation The same training and segmentation principles were used as in the previous experiments. Training used a 1.5 to 2 s long sample of each of the participants, plus a similar length segment of background noise. Because the same model was used for all participants, non-active speakers were trained with a silence segment of 2 s duration. Table XIV shows the speaker assignment for each of the experiments. 131 Table XIV: Speaker Assignment for AOLME Experiments. Audio Sample A B C D Speaker Assignment S2 S1  Silence    Silence   S3 Silence Silence  S5 S4  Silence  Silence      S6 Noise Noise Noise Noise The Ground Truth for each audio was segmented using the VAD, discarding segments with less than 0.5 s duration, and limiting the length of the segments to 1.5 s maximum. The total number of segments for each sample is shown in the results table. 5.3.4 Testing and Results The same type of analysis was applied as in the previous experiments. Table XV (a) shows an example of the Cross-Correlation results of analyzing one segment of Audio Sample B. Tables VII (b), (c), and (d) show the training CC tables with the score of each possible speaker. Each match is represented by a zero (0). In this case, the segment corresponds to speaker 2. 132 Table XV: CC Tables for AOLME Experiment. 1-2 1-3 1-4 1-5 1-6 1-7 2-3 2-4 2-5 2-6 2-7 3-4 3-5 3-6 3-7 4-5 4-6 (a) Microphone Cross Correlation. Unknown Segment -64 -65 11 63 -45 -75 89 72 -96 -236 137 133 -100 -236 306 133 12 -75 90 97 -68 0 -28 0 18 -30 56 8 -74 -103 203 57 -276 -103 92 57 71 -11 79 21 -9 65 -34 -63 -72 -69 -41 42 -41 -69 35 42 57 19 21 1 -27 75 -123 -72 14 0 82 0 1-2 1-3 0 91 0 -53 11 0 4 0 1-2 1-3 0 -245 -1 0 0 0 4 0 1-4 0 -83 -145 0 1-4 0 21 -145 12 1-5 -14 -83 197 0 1-5 -14 21 218 12 (b) Microphone Cross Correlation. Training Speaker 1. Score: 25 4-5 -127 0 21 0 2-6 2-7 -5 -9 53 -1 17 -11 0 -1 3-4 3-5 8 0 -11 1 1-6 1-7 2-3 4 18 5 0 0 110 1 6 -5 1 0 12 2-5 -139 0 5 -1 3-7 -4 0 -2 -4 3-6 0 1 1 -1 2-4 4 0 192 -1 0 0 2 1 (c) Microphone Cross Correlation. Training Speaker 2. Score: 32 4-5 5 0 0 0 2-6 2-7 -5 -13 0 0 1 5 0 0 3-4 3-5 14 -1 0 0 3 -11 0 0 1-6 1-7 2-3 4 18 5 0 0 0 1 -9 -5 4 0 0 2-5 -270 0 5 -1 3-7 -4 1 -11 -4 3-6 0 1 3 -1 2-4 204 0 419 -1 (d) Microphone Cross Correlation. Training Speaker 3. Score: 21 1-2 13 0 -5 0 1-3 -1 -1 14 -209 1-4 5 -121 -77 0 1-5 -14 -121 202 0 1-6 1-7 2-3 -6 13 5 -194 0 0 0 -5 -5 4 0 24 2-4 -198 0 182 11 2-5 2-6 2-7 -5 -9 -72 0 -2 0 -155 5 5 0 11 11 3-4 3-5 0 7 0 2 1 7 3 2 3-6 1 191 3 -3 3-7 3 1 -3 209 4-5 4 0 6 0 133 285 98 18 -36 4-6 56 0 2 1 4-6 394 5 1 1 4-6 -9 0 -31 1 s r e k a e p S s r e k a e p S s r e k a e p S s r e k a e p S 1 2 3 6 1 2 3 6 1 2 3 6 1 2 3 6 4-7 -58 236 -94 -133 4-7 -333 83 0 0 4-7 -333 -21 0 -12 4-7 -267 121 -12 0 5-6 294 98 -8 -36 5-6 206 0 5 1 5-6 208 5 0 1 5-6 201 0 5 1 5-7 3 236 -107 -133 5-7 -1 83 37 0 5-7 0 -21 -202 -12 5-7 -5 121 16 0 6-7 -80 75 -125 -97 6-7 4 -110 -15 -12 6-7 0 0 0 0 6-7 4 0 -12 -24 Table XVI shows the results of the analysis of all Audio Samples, with the respective DER for each experiment. Table XVI: Classification Results for AOLME Experiments. Audio Sample Sample Duration (s) No. Speakers No. Segments Properly Classified Segments False Alarms Miss Confusion DER A B C D 244 256 381 257 2 3 4 5 311 328 489 339 281 302 426 284 5 8 10 12 10 10 25 15 15 8 28 28 0.095 0.079 0.12 0.16 5.4 Comparison with Other Methods The final set of experiments focus on comparing our proposed method against Google’s and Amazon AWS. Google’s and Amazon AWS were two of the cloud-based speech processing services introduced in the background section of this dissertation. Microsoft Diarization service was in the process of being updated by the time this dissertation was written and, therefore, it was not possible to run any experiment with it. 5.4.1 Methodology for Comparison The diarization services provided by Google and Amazon differ from the proposed method in three aspects. First, they do not require a sample of audio for training. Second, the audio samples to diarize need to be of a minimum duration of 4 s, approximately. Third, 134 their output does not provide a label of the active speaker, but rather a set of text transcripts that contain the speech segment, the abstract speaker label (e.g., speaker 0, speaker 2), the active time of the speaker on the transcript segment, and the confidence rate. Given these constraints, the only fair comparison criteria are to manually measure each speaker’s ground truth active time manually and compare these times with the results of the analysis by all three methods. It was necessary to add a section of code to the proposed method to measure the length of each of the segments that are already classified and totalize the time for the same speaker plus noise. 5.4.2 Selection, Preparation, and Ground Truth Measurements of Videos for Analysis The analysis consisted of a total of 8 AOLME videos containing 2, 3, 4, and 5 speakers. The duration of each video was limited to a maximum of 3 minutes. The audio from each video was extracted using Audacity and downshifted to 16 kHz for upload to Goggle and Amazon. The audio files for our methods were sampled at a rate of 48 kHz. Each speaker’s active time from the ground truth audio was measured using a stopwatch. In some of the AOLME videos, it was difficult to assess this time due to several speakers being active simultaneously. In these cases, each speaker’s time was recorded by listening to his/her voice and watching his/her lip movement on video, even if their speech overlapped at any moment. 135 5.4.3 Training and Segmentation The system was trained with audio samples of about 1.8 s long from each speaker and noise, using a VAD with a maximum segment length of 1.2 s. All segments with a duration of less than 0.5 s were dropped. There was no need for training on Google or Amazon; these systems trained by using the uploaded audio and their databases. 5.4.4 Testing and Analysis Each of the audio files from the videos was analyzed using the modified code that totalizes each speaker’s time, with no other additional steps. For Amazon and Google, the audio was uploaded to the cloud. Because both Amazon and Google’s methods return only abstract labels, the output transcriptions of each of the speakers were used to manually match the identity of the speaker on each segment, noting that both Amazon and Google label the first active speaker they detect as “speaker 0”. 5.4.5 Results Table XVII shows the results of this experiment, with the percentage error highlighted in light blue. The error was calculated using (5.1). Percent error = estimated time − true time true time ∗ 100 (5.1). 136 Table XVII: Experimental Comparison Between Methods. Audio Sample No. of Speakers Speaker 1 2 3 4 5 6 7 2 2 3 3 4 4 5 8 5 S1 S2 S1 S2 S1 S2 S3 S1 S2 S3 S1 S2 S3 S4 S1 S2 S3 S4 S1 S2 S3 S4 S5 S1 S2 S3 S4 S5 Amazon AWS Google Cloud 1.95 45.25 4.85 8.24 40.88 47.08 31.51 61.41 24.01 3.72 40.39 7.53 Time Error (s) % 94.52 19.21 74.47 170.60 120.90 12.99 45.46 152.14 9.88 64.67 143.74 40.21 0.00 100.00 106.36 61.79 37.67 36.19 0.00 100.00 52.19 84.48 8.93 20.05 0.00 100.00 0.00 100.00 78.70 221.49 36.95 65.84 100.00 0.00 250.00 38.05 3070.83 100.00 0.00 60.54 28.30 88.77 6.74 100.00 0.00 13.82 39.24 60.04 13.31 100.00 0.00 10.92 100.00 0.00 31.65 53.73 53.13 21.67 100.00 0.00 44.00 15.63 17.61 46.22 17.52 56.02 42.23 Error Time % (s) 8.63 127.10 100.00 0.00 31.40 73.40 66.59 269.33 66.59 1009.83 50.80 10.29 80.20 31.39 0.00 0.00 8.30 35.00 94.30 53.59 29.19 15.29 3.30 5.09 24.90 0.00 54.70 46.60 6.29 29.59 7.49 11.20 29.59 50.45 11.12 22.00 13.49 100.00 100.00 25.69 17.20 27.71 118.91 31.01 40.62 175.00 74.86 64.01 100.00 26.86 279.79 55.95 14.38 199.60 26.46 37.93 Proposed Method Ground Truth Time Error Time (s) % (s) 14.54 99.99 117.00 25.80 34.62 27.52 5.61 107.00 113.00 23.44 18.03 30.01 20.69 244.83 6.00 102.52 100.52 13.45 68.93 25.38 15.30 41.61 14.69 68.23 91.57 25.39 13.28 27.69 4.20 7.99 64.53 10.71 48.86 10.93 18.80 42.05 3.60 22.27 27.54 9.26 65.74 27.66 10.86 28.29 11.17 42.27 73.84 24.48 22.28 25.75 1.20 20.25 69.19 9.41 43.12 12.27 14.28 34.56 2.50 15.23 47.67 137 Table XVIII shows the average error for 2, 3, 4, and 5 speakers, as well as the total average error for each method. Table XVIII: % Average Error for All Three Methods. No. of Speakers 2 3 4 5 Total Proposed Method 18.99 57.67 58.21 29.11 42.10 Amazon AWS 88.74 67.14 470.34 65.44 184.82 Google Cloud 102.34 201.15 67.02 87.98 108.29 The results presented in Tables XVII and XVIII show a substantial reduction in the achieved error rate. More specifically, error reduction ranges from 50% to 87%. The color codes used in Table XVII emphasize the results of this experiment. The red highlighting denotes cases of failures where we have a speaker that was completely missed, or the estimated talking time of the speaker had more than a 100% error (e.g., an over-estimating speaker talking time). Out of 28 possible speakers across all examples, Amazon AWS gave failing results for 14 cases (50%), Google cloud gave failing results for 10 cases (36%), while the proposed method gave failing results for 2 cases (7%). It is interesting to notice that the proposed method never failed to detect a speaker (0% error), while Amazon AWS could not detect any talking time for 10 cases (36%). Google cloud failed to detect any talking time for 4 cases (14%). Also, there are failure cases for all 8 samples for Amazon 138 AWS and Google Cloud. In contrast, for the proposed method, there are 2 samples with examples of over-estimation, with 6 samples being free of dramatic failures. Teal highlighting denotes cases where the total estimated speaking time gave 20% or less error. Based on this criterion, both AWS and Google Cloud gave satisfactory results in 5 cases (18%) versus 11 cases (39%) for the proposed method. 139 Chapter 6. Summary, Conclusions, and Future work This dissertation presented a method for speaker diarization and identification using virtual microphones and cross-correlation patterns. The proposed method identifies speakers in single-channel recordings taken in noisy collaborative environments, such as classrooms and educational workshops. The method gave an error rate that was over 50% less on average than other available diarization methods when subject to the same testing environments. In contrast with other methods that are considered state-of-the-art, the proposed method requires minimal training and no databases, making it applicable in situations where it is not possible to gather clean speech samples. The background section of this dissertation presented similar research works on speaker diarization and identification based on microphone arrays. Although some of these works included virtual microphone arrays, none of them approached a full virtual array simulation from a single microphone recording. Given the unprecedented focus on Deep Learning methods, alternative approaches are avoided, limiting the number of researchers interested in pursuing them. Yet, the proposed methodology clearly outperformed commercial Deep Learning methods and demonstrated some of their limitations due to their needs for large training datasets. The method presented in this dissertation offers an alternative for educational researchers that are involved with collaborative environments and depend mostly on the 140 analysis of data provided by video recordings. The work in this dissertation showed that other available methods perform poorly under these environments when determining who speaks, when, and for how long. The deficiencies presented by these methods are even more prominent when the participants are from underrepresented groups from which large training databases may not exist. The proposed method demonstrated a significant performance improvement by capitalizing on real video information of the environment under analysis, rather than depending on unrelated training data. Also, by no requiring previous speaker enrollment, this method opens the possibility of analysis of a wide variety of video data that may not have been recorded with the known intention of posteriors analysis. The dissertation method constitutes more of a proof of concept than a fully operational method. The success of the proposed method is due to the possibility of simulating acoustic wave propagation, including speech. Even though this modeling can be complex, we have now powerful personal computers to execute the calculations required by the signal processing algorithms. Furthermore, the code for the simulations is available from large repositories that contain open-source libraries ready for implementation; nevertheless, there is work that needs to be done to address some of the weaknesses observed so far, such as it is the case where participant speakers move and change their original locations, and when they “invade” other’s speakers’ physical location. Under this area, it is possible to eventually adapt the methods from the research work done at the ivPCL lab regarding object and subject tracking. The location of the speakers and the general geometry of the room could be dynamically modified in the models based on the 141 information from video data, thus improving the error rate. Also, the experiments only considered one type of microphone array, leaving open the question of the performance of other types of arrays, such as circular or even volumetric. In addition, the simulation version available during the development of this dissertation had some limitations that impacted the accuracy of the models. Pyroomacoustics released a new version that includes improvements to the models’ parameters, such as physical modeling of room absorption, reverberation modeling, and multi-pattern microphone simulation. Finally, the method depends on proper audio segmentation and final classification. Most of the misclassifications in the method were the product of improper pre-segmentation and sub- optimal classification. A more sophisticated classifier using machine learning or neural networks would help improve the overall performance. It is possible also to apply clustering classification for unsupervised identification of the speakers. Finally, the method could be extended to support other applications of speech processing, as it can be incorporated as a front end or pre-processor. For example, the method can be used to improve the accuracy of spatial filters for speech enhancement or speaker separation from mixtures. The parameters of the spatial filters can be better determined by estimating the location of the speaker and then optimizing the parameters for that location. 142 Appendix A: Pyroomacoustics Scripts This section describes the two Python scripts that call the Pyroomacoustics libraries to generate the room geometry parameters, calculate the RIRs, and emulate the virtual microphones. a) Room Geometry Generator: This script accepts the room dimensions and locations of the sources and virtual microphones and generates the 2D and 3D geometric models. The room geometry is saved as a set of .txt files that contains the geometry arrays. This script runs under a Jupyter Notebook. #Location of Sources and Microphones Source6=[0.98,0.4] Source6_3D=[0.98,0.4,0.98] Mic_X = [0.6,0.65,0.6,0.6,0.6,0.55,0.6] Mic_Y = [0.6,0.55,0.55,0.45,0.5,0.55,0.65] Mic_Z = [0.25,0.25,0.01,0.25,0.25,0.25,0.25] #Add room room = pra.Room.from_corners(corners, fs=fs) #Location of Microphones Array R = np.array([Mic_X, Mic_Y]) # [[x], [y], [z]] #Add source to 2D room room.add_source(Source1, signal=s1) . . room.add_source(Source6, signal=s6) room.add_microphone_array(pra.MicrophoneArray(R, room.fs)) #Execute Location room = pra.Room.from_corners(corners, fs=fs) room.extrude(1.0) 143 R = np.array([Mic_X, Mic_Y, Mic_Z]) # [[x], [y], [z]] room.add_microphone_array(pra.MicrophoneArray(R, room.fs)) room.add_source(Source1_3D, signal=s1) . . room.add_source(Source4_3D, signal=s4) #Save Geometry np.savetxt(r'C:\Users\User\Desktop\PhD Folder\Dissertation\Experiments\Model_Estimation\Room_parameters\corner s_array.txt',corners[:,:],delimiter=',', fmt='%f') . . . np.savetxt(r'C:\Users\User\Desktop\PhD Folder\Dissertation\Experiments\Model_estimation\Room_parameters\mic_ar ray.txt',R[:,:],delimiter=',', fmt='%f') b) Pyroomacoustics Virtual Microphone Simulation Script This script is used twice to first calculate the RIR from the model sources to the virtual microphones, and then again to emulate the signal at the virtual microphones using the estimated sources. This script is called within LabVIEW, and its outputs are saved in .txt files. #Setup Python import numpy as np import matplotlib.pyplot as plt from scipy.io import wavfile from scipy.signal import fftconvolve import pyroomacoustics as pra #Define Variables Abs = 0 max_o = 0 room_extrude = 0 corners_array = 0 Source1 = 0 . . Source6 = 0 mic_array = 0 #Define model def model_generation(): 144 #Delimit the corners of the room corners = np.array(corners_array).T # [x,y] room = pra.Room.from_corners(corners) room.extrude(room_extrude) #Read Sources fs, s1 = wavfile.read(r""C:\.....) . . fs, s6 = wavfile.read(r""C:\.....) room = pra.Room.from_corners(corners, fs=fs) #Add microphone array R = np.array(mic_array) # [[x], [y], [z]] room.add_microphone_array(pra.MicrophoneArray(R, room.fs)) # set max_order for RIR room = pra.Room.from_corners(corners, fs=fs, max_order=max_o, absorption=Abs) #Set Extrusion room.extrude(room_extrude) #Add source arrays and microphones Source1_3D=np.array(Source1) #Source 1 room.add_source(Source1_3D, signal=s1) room.add_microphone_array(pra.MicrophoneArray(R, room.fs)) #Compute image sources room.image_source_model(use_libroom=True) room.compute_rir() #Save Data np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') #Data Mic data_mic=room.mic_array.signals[0,:] np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') data_mic=room.mic_array.signals[1,:] np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') data_mic=room.mic_array.signals[2,:] np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') data_mic=room.mic_array.signals[3,:] np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') #Data Mic5 data_mic=room.mic_array.signals[4,:] np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') #Data Mic6 data_mic=room.mic_array.signals[5,:] np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') data_mic=room.mic_array.signals[6,:] np.savetxt(r'C:\....,room.rir[0][0],delimiter=',', fmt='%f') #Reepeat for all sources . . . return 145 Appendix B: LabVIEW Sub-Vis a) Room Parameters Reader Figure 49: Room Parameters Reader Inputs and Outputs Figure 50: Room Parameters Reader Front Panel. 146 Figure 51: Room Parameters Reader Block Diagram. 147 b) Room Model Generator Figure 52: Room Model Generator Icon. Figure 53: Room Model Generator Front Panel. 148 Figure 54: Room Model Generator Block Diagram. 149 c) Source Estimator This Sub- VI is too complex to display its source block diagram. Instead, a simple functional block diagram is shown. Figure 55: Source Estimator Icon. Figure 56: Source Estimator Front Panel. 150 Figure 57: Source Estimator Simplified Block Diagram. d) Cross-Correlation Model Calculator Figure 58: Cross-Correlation Model Calculator Icon. 151 Figure 59: Cross-Correlation Model Calculator Front Panel. 152 Figure 60: Cross-Correlation Model Calculator Block Diagram. 153 Figure 61: Cross-Correlation Model Calculator. Cross-Correlator Sub-VI. Notes on this sub-VI: The cross-correlation results are indicated by the index where the max cross-correlation occur. This method makes the results independent of the sampling frequency. Also, this sub-VI truncates the largest input to make both input files the same size as the smallest one. e) Model Classifier Figure 62: Model Classifier Icon with Inputs and Outputs. 154 Figure 63: Model Classifier Front Panel. 155 f) Multi-Function Convolution and Correlator Visualizer Figure 64: Multi-Function Convolution and Correlator Visualizer Front Panel. 156 Figure 65: Multi-Function Convolution and Correlator Visualizer Diagram. 157 Appendix C: Audio Lab Equipment Specifications a) Microphone Equipment: Audio-Technica ATR3350xIs  Element: Condenser  Polar Pattern: Omnidirectional  Frequency Response: 50 – 18,000 Hz.  Sensitivity: -54 db.   Power Source: Battery Type: LR44. Impedance: 1,000 ohms Comica CVM-V020  Transducer: Back Electrets Condenser  Directivity: Omnidirectional  Frequency Range: 100Hz ~ 12KHz  THD: ≤1%  Sensitivity: 35dB ±3dB  Signal/Noise Ratio: ≥60dB  Power Source: 48V Phantom Powered 158 Excelvan 700  Polar Pattern: Uni-directional  Frequency Response: 20Hz-20kHz  Sensitivity: 45dB±1dB  Output Impedance:1500Ω±30%(at 1kHz)  Load impedance: ≥1000 Ω  Equivalent Noise level: 16dBA  Power Source: 48V phantom power supply b) Audio Processing Equipment TASCAM Model US-16x08  Frequency response: o LINE OUT(BALANCED) o 44.1k/48k Hz 20Hz to 20kHz, ±0.3dB(JEITA) o 88.2k/96k Hz 20Hz to 40kHz, ±0.3dB(JEITA) 100dB or more 100dB or more  THD 0.008% or less  S/N ratio  Crosstalk  EIN  Sampling frequency 44.1k/48k/88.2k/96k Hz  Quantization bit rate 16/24-bit –125dBu or less 159  Analog audio inputs: o MIC IN(IN 1-8)  Connector XLR-3-31 (1: GND, 2: HOT, 3: COLD), 2.4kΩ BALANCED  Input impedance  Nominal input level  GAIN: MAX –68dBu (0.0003Vrms)  GAIN: MIN –12dBu (0.195Vrms)  Maximum input level +8dBu (1.947Vrms)  Gain 56dB o LINE IN (IN 9-10)  Connector 1/4"" (6.3mm) TRS-jack (T: HOT, R: COLD, S: 10kΩ GND), BALANCED  Input impedance  Nominal input level  GAIN: MAX –41dBu (0.0069Vrms)  GAIN: MIN +4dBu (1.228Vrms)  Maximum input level +24dBu (12.182Vrms)  Gain 45dB AIWA Stereo Audio Amplifier  Power output: 80 watts per channel into 8Ω (stereo)  Surround output: 80W (front), 80W (center), 80W (rear)  Frequency response: 20Hz to 20kHz  Total harmonic distortion: 1%   Output: 300mV (line) Input sensitivity: 2.5mV (MM), 300mV (line) 160  Speaker load impedance: 8Ω (minimum) c) Loudspeakers Polk Audio RM6751  Power Range: 20- 100 W  Frequency Response: 40 Hz – 24 kHz  Sensitivity: 89 @2.83Vrms dB  Impedance (Ohms): 8 161 References [1] S. S. Tirumala, S. R. Shahamiri, A. S. Garhwal, R. Wang, “Speaker identification features extraction methods: A systematic review”. Expert Systems with Applications, vol. 90, pp. 250-271, 2017. doi: 0957-4174, https://doi.org/10.1016/j.eswa.2017.08.015. [2] J. Brownlee, “Impact of Dataset Size on Deep Learning Model Skill And Performance Estimates,” Deep Learning Performance, machinelearningmastery.com, para.4, Jan. 2, 2019. [Online]. Available: https://machinelearningmastery.com/impact-of-dataset-size-on-deep-learning-model- skill-and-performance-estimates/. [3] J. Yoon and S. O. Arik “Estimating the Impact of Training Data with Reinforcement Learning,” Cloud AI Team Google Research, googleblog.com, para. 2, Oct. 28, 2020. [Online]. Available: https://ai.googleblog.com/2020/10/estimating-impact-of- training-data-with.html. [4] A. Koenecke A. Nam, E. Lake, J. Nudell, M. Quartey, Z. Mengesha, C. Toups, J.R. Rickford, D. Jurafsky S. Goel, “Racial disparities in automated speech recognition,” Proceedings of the National Academy of Sciences of the United States of America, April 7, 2020, 117(14):7684-7689, [Online serial]. Available: https://www.pnas.org/content/117/14/7684. [5] J. Martin, K.Tang, “Understanding Racial Disparities in Automatic Speech Recognition: The Case of Habitual “be”. Presented at 21st International Conference on Speech Processing and Applications, Shanghai, China, 2020. [6] R. Gupte, S. Hawa, and R. Sonkusare, “Speech recognition using cross correlation and feature analysis using mel-frequency cepstral coefficients and pitch,” In Proc. 2020 IEEE International Conference for Innovation in Technology (INOCON), 2020, pp. 1-5. [7] G. Ekim, N. Ikizler, A. Atasoy, and I. H. Cavdar, “A speaker recognition system using by cross correlation,” In Proc. 2008 IEEE 16th Signal Processing, Communication and Applications Conference, 2008, pp. 1-4. 162 [8] The University of New Mexico, “AOLME: Advancing Out-of-school Learning in Mathematics and Engineering”. [Online]. Available: https://aolme.unm.edu/. [9] University of New Mexico’s Image and Video Processing and Communications Lab (ivPCL). [Online]. Available: https://ivpcl.unm.edu/ [10] C. J. Darsey, “Hand Detection in Collaborative Learning Environments”. The University of New Mexico, 2018. [11] Teeparthi S., “Long-term Video Object Detection and Tracking in Collaborative Learning Environments,” Fall 2021 (with distinction). She was funded through NSF. [12] Teeparthi, S., Jatla, V., Pattichis, M.S., Celedón-Pattichis, S., and LópezLeiva, C., “Fast Hand Detection in Collaborative Learning Environments,” The 19th International Conference on Computer Analysis of Images and Patterns (CAIP), pp. 445-454, 2021. [13] Jacoby A. R., “Context-Sensitive Human Activity Classification in Video Utilizing Object Recognition and Motion Estimation,” Spring 2018. [14] Jatla, V., Teeparthi, S., Pattichis, M.S., Celedón-Pattichis, S., and LópezLeiva, C., “Long-term Human Video Activity Quantification of Student Participation,” in 2021 Asilomar Conference on Signals, Systems, and Computers. [15] Eilar, C., Jatla, V., Pattichis, M. S., Celedón-Pattichis, S., & LópezLeiva, C. A., “Distributed Video Analysis for the Advancing Out of School Learning in Mathematics and Engineering Project,” 2016 Asilomar Conference on Signals, Systems, and Computers, pp. 571-575, 2016. [16] Shi, W., Pattichis, M.S., Celedón-Pattichis, S., and LópezLeiva, C., “Dynamic Group Interactions in Collaborative Learning Videos,” 2018 Asilomar Conference on Signals, Systems, and Computers, in press, pp. 1528-1531, 2018. [17] X. Anguera, S. Bozonnet, N. Evans, C. Fredouille, G. Friedland, O. Vinyals, ""Speaker diarization: A review of recent research,"" IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 2, pp. 356-370, 2012. [18] M. Alam, M.D. Samad, L. Vidyaratne, A. Glandon, K.M. Iftekharuddin,” Survey on Deep Neural Networks in Speech and Vision Systems,” Neurocomputing, Volume 417, 2020, pp. 302-321. 163 [19] D. Sztahó, G. Szaszák, A. Beke, ‘‘Deep learning methods in speaker recognition: A review,’’ Periodica Polytechnica Electrical Engineering and Computer Science, vol. 65, no. 4, pp. 310–328, Jan. 2021. [Online]. Available: http://arxiv.org/abs/1911.06615. [20] J. Villalba, N. Chen, D. Snyder, D. Garcia-Romero, A. McCree, G. Sell, J. Borgstrom, L. Paola García-Perera, F. Richardson, R. Dehak, P. A. Torres- Carrasquillo, N. Dehak, “State-of-the-art speaker recognition with neural network embeddings in NIST SRE18 and Speakers in the Wild evaluations,” Computer Speech & Language, vol. 60, March, 2020. [21] D. Snyder, D. Garcia-Romero, G. Sell, D. Povey and S. Khudanpur, ""X-Vectors: Robust DNN Embeddings for Speaker Recognition,"" 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018, pp. 5329- 5333. [22] X. A. Miró, “Robust speaker diarization for meetings,” Ph.D. thesis, Speech Processing Group Department of Signal Theory and Communications Universitat Politècnica de Catalunya, Barcelona, 2006. [23] N. Mitianoudis and M. E. Davies, ""Using beamforming in the audio source separation problem,"" Seventh International Symposium on Signal Processing and Its Applications, 2003. Proceedings., 2003, pp. 89-92 vol.2, doi: 10.1109/ISSPA.2003.1224822. [24] U. Klein and Trình Quốc Võ, ""Direction-of-arrival estimation using a microphone array with the multichannel cross-correlation method,"" 2012 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT), 2012, pp. 000251-000256, doi: 10.1109/ISSPIT.2012.6621296. [25] T. Padois, “Acoustic source localization based on the generalized cross-correlation and the generalized mean with few microphones”. J Acoust Soc Am. 2018. [26] S. Pasha and C. Ritz, ""Informed source location and DOA estimation using acoustic room impulse response parameters,"" 2015 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT), 2015, pp. 139-144, doi: 10.1109/ISSPIT.2015.7394316. [27] S. Tervo, J. Pätynen, and T. Lokki, “Acoustic reflection localization from room impulse responses,” Acta Acustica united with Acustica, vol. 98, no. 3, pp. 418-440, 2021. 164 [28] M. Hu, P.P. Parada, D. Sharma, S. Doclo, T.V Waterschoot, M. Brookes, P.A. Naylor, ""Single-channel speaker diarization based on spatial features,"" In Proc. IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), 2015, pp. 1-5. [29] P. P. Parada, D. Sharma, P. A. Naylor, “Non-intrusive estimation of the level of reverberation in speech,” in Proc. IEEE International Conf. on Acoustics, Speech and Signal Processing (ICASSP), Florence, Italy, May 2014, pp. 4718–4722. [30] D. Vijayasenan, F. Valente, and H. Bourlard, “Multistream speaker diarization beyond two acoustic feature streams,” in Proc. IEEE Intl. Conf. on Acoustics, Speech and Signal Processing (ICASSP), Dallas, TX, USA, Mar. 2010, pp. 4950–4953. [31] T. Yoshioka, Z. Chen, D. Dimitriadis, W. Hinthorn, X. Huang, A. Stolcke, M. Zeng, “Meeting transcription using virtual microphone arrays,” Microsoft Technical Report MSR-TR-2019-11, July 2019. [32] H. Katahira, N. Ono, S. Miyabe, T. Yamada, S. Makino, “Nonlinear speech enhancement by virtual increase of channels and maximum SNR beamformer,” EURASIP Journal on Advances in Signal Processing, 2016, issue 1, article 11, pp. 1- 8, 2016. [33] G. Del Galdo, O. Thiergart, T. Weller and E. A. P. Habets, ""Generating virtual microphone signals using geometrical information gathered by distributed arrays,"" 2011 Joint Workshop on Hands-free Speech Communication and Communication and Microphone Arrays, Edinburgh, pp. 185-190, 2011. [34] A. Izquierdo, J. Villacorta, L. del Val, L. Suárez, and D. Suárez, “Implementation of a Virtual Microphone Array to Obtain High Resolution Acoustic Images,” Sensors, vol. 18, no. 2, p. 25, Dec. 2017. [35] Tapia, L.S., Gomez, A., Esparza, M., Jatla, V., Pattichis, M.S., Celedón-Pattichis, S., and López-Leiva, C., “Bilingual Speech Recognition by Estimating Speaker Geometry from Video Data,” The 19th International Conference on Computer Analysis of Images and Patterns (CAIP), pp. 79-89, 2021. [36] Siemens Simcenter “Sound Fields: Free versus Diffuse Field, Near versus Far Field” [Online]. Available: https://community.sw.siemens.com/s/article/sound-fields-free- versus-diffuse-field-near-versus-far-field [37] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West Sussex: John Wiley & Sons Ltd., pp 341-343, 2009. 165 [38] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West Sussex: John Wiley & Sons Ltd., 2009, pp 171-174, 2009. [39] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West Sussex: John Wiley & Sons Ltd., 2009, pp 74, 2009 [40] S. Renals, H. Bourlard, J. Carletta, and A. Popescu-Belis, “Multi-Modal Signal Processing. Human Interactions in Meetings”, New York: Cambridge University Press, pp 29-35, 2012. [41] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West Sussex: John Wiley & Sons Ltd., pp 171, 2009. [42] I. Cohen, J. Benesty, and S. Gannot,“Speech Processing in Modern Communications”. W. Kellerman. Berlin: Springer-Verlag, page 212, 2010. [43] B. Gunel, EE2.LabB: Measurement and Processing of Room Impulse Responses”. University of Surrey, 2011. [Online]. Available: http://personal.ee.surrey.ac.uk/Personal/P.Jackson/ee2.lab/XY_rir/. [44] B. Xie, “Head Related Transfer Function and Virtual Auditory Display”. Second Edition. J. Ross Publishing, Plantation Fl., pp 352-355, 2013. [45] F. A. Everest, and K.C. Pohlmann, “Master Handbook of Acoustics” McGraw Hill, New York, pp 559-560, 2015. [46] D. Diaz-Guerra, A. Miguel, and A. J. Beltran, “gpuRIR: A python library for room impulse response simulation with GPU acceleration”. Multimed Tools Appl 80, 5653–5671. 2021. https://doi.org/10.1007/s11042-020-09905-3. [47] J.B. Allen, D.A. Berkley, “Image Method for Efficiently Simulating Small-Room Acoustics”, The Journal of the Acoustical Society of America, 1979. DOI 10.1121/1.382599 [48] Wikipedia [Online]. Available: https://en.wikipedia.org/wiki/Voice_frequency [49] I. McLoughlin, “Speech and Audio Processing, a MATLAB-based Approach”, Cambridge University Press, New York, page 65, 2016. [50] F. A. Everest, and K.C. Pohlmann, “Master Handbook of Acoustics” McGraw Hill, New York, pp 75-76, 2015. 166 [51] S. Renals, H. Bourlard, J. Carletta, and A. Popescu-Belis, “Multi-Modal Signal Processing. Human Interactions in Meetings”, New York: Cambridge University Press, pp 40-41, 2012. [52] M. de Campos Niero, A. de Lima Veiga Filho, and A. G. Adami, ""A comparison of distance measures for clustering in speaker diarization,"" 2014 International Telecommunications Symposium (ITS), 2014, pp. 1-5, doi: 10.1109/ITS.2014.6947954. [53] S. Chen, and P. Gopalakrishnan,” Speaker, environment and channel change detection and clustering via the bayesian information criterion”, in Proceedings of DARPA Broadcast News Transcription and Understanding Workshop, 1998. [54] Z. Bai, Xiao-Lei Zhang, “Speaker recognition based on deep learning: An overview”, Elsevier: Journal of Neural Networks, Volume 140, 2021, pp 84-88, ISSN 0893-6080, [Online], Available: https://doi.org/10.1016/j.neunet.2021.03.004. [55] O. Ghahabi, “Deep Learning for i-Vector Speaker and Language Recognition”. Ph.D. thesis, Speech Processing Group Department of Signal Theory and Communications Universitat Politècnica de Catalunya, Barcelona, 2018. [56] Z. Bai, and Xiao-Lei Zhang, “Speaker recognition based on deep learning: An overview”, Elsevier: Journal of Neural Networks, Volume 140, 2021, pp 68-72, ISSN 0893-6080, [Online], Available: https://doi.org/10.1016/j.neunet.2021.03.004. [57] J. Guo, N. Xu, K. Qian, Y. Shi, K. Xu, Y. Wu, and A. Alwan., “Deep neural network based i-vector mapping for speaker verification using short utterances”, Computer Speech & Language, Volume 72, March 2022, 101317. [Online]. Available: https://arxiv.org/abs/2101.09624. [58] D. Yifan, X. Yong, Z. Shi-Xiong, C. Yauhan, and W. Liqiang. 2020. “Self- Supervised learning for audio-visual speaker diarization”. In ICASSP 2020 - 2020 IEEE international conference on acoustics, speech and signal processing pp. 4367– 4371, 2020. [59] T. J. Park, and P. Georgiou, “Multimodal speaker segmentation and diarization using lexical and acoustic cues via sequence to sequence neural networks”. In Proc. INTERSPEECH 2018 pp. 1373–1377, 2018. 167 [60] L. El Shafey, H. Soltau, and I. Shafran, “Joint speech recognition and speaker diarization via sequence transduction”. In Proc. INTERSPEECH 2019 pp. 396–400, 2019. [61] W. Kang, B. Roy, and W. Chow. “Multimodal speaker diarization of real-world meetings using d-vectors with spatial features”. In ICASSP 2020 – 2020 IEEE international conference on acoustics, speech, and signal processing pp. 6509–6513, 2020. [62] Amazon AWS, “Amazon Transcribe”, 2021. [Online]. Available: https://aws.amazon.com/transcribe/?nc=sn&loc=1. [63] Google’s Cloud, “Separating different speakers in an audio recording”, 2021. [Online]. Available: https://cloud.google.com/speech-to-text/docs/multiple-voices. [64] Microsoft Azure Product Documentation, “What is Speaker Recognition?” Microsoft, Nov. 3, 2021. [Online]. Available: https://docs.microsoft.com/en- us/azure/cognitive-services/speech-service/speaker-recognition-overview. [65] D. Misal, “Google Speech Vs Amazon Transcribe: The War of Speech Technology,” Analytics India Magazine, Oct. 22, 2018. [Online], Available: https://analyticsindiamag.com/google-speech-vs-amazon-transcribe-the-war-of- speech-technology/. [66] M. Saraswat and R. C. Tripathi, ""Cloud computing: comparison and analysis of cloud service providers-AWs, Microsoft and Google,"" In Proc. 2020 9th International Conference System Modeling and Advancement in Research Trends (SMART), 2020, pp. 281-285. [67] A. Woollacott, “Benchmarking speech technologies,” Academia.edu, Feb. 2021. [Online]. Available: Academia, https://www.academia.edu/45165394/Benchmarking_Speech_Technologies. [68] X. Xiao, N. Kanda, Z. Chen, T. Zhou, T. Yoshioka, S. Chen, Y. Zhao, G. Liu, Y. Wu, J. Wu, S. Liu, J. Li, and Y. Gong, “Microsoft speaker diarization system for the VoxCeleb speaker recognition challenge 2020,” In Proc. ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021, pp.5824-5828. [69] Microsoft speaker recognition. [Online]. Available: https://docs.microsoft.com/en- us/azure/cognitive-services/speech-service/speaker-recognition-overview 168 [70] I. Tashev, “Sound Capture and Processing: Practical Approaches”. Chichester, West Sussex: John Wiley & Sons Ltd., pp 351, 2009. [71] R. Scheibler, E. Bezzam, and I. Dokmanić, “Pyroomacoustics: A Python package for audio room simulation and array processing algorithms,” In Proc. 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018, pp. 351-355. [72] Pyroomacoustics documentation. [Online]. Available: https://pyroomacoustics.readthedocs.io/en/pypi-release/ [73] E. Marin. “Voice Activity Detection Using Filters”. University of New Mexico, Spring 2021. eguaderrama@unm.edu. [74] I. McLoughlin, “Speech and Audio Processing, a MATLAB-based Approach”, Cambridge University Press, New York, pp 24-28, 2016. [75] NI LabVIEW. [Online]. Available: https://www.ni.com/en-us/shop/labview.html [76] NI LabVIEW Convolution. [Online]. Available: https://zone.ni.com/reference/en- XX/help/371361R-01/lvanls/convolution/ [77] NI LabVIEW Deconvolution. [Online]. Available: https://zone.ni.com/reference/en- XX/help/371361R-01/lvanls/deconvolution/ [78] NI LabVIEW Correlation. [Online]. Available: https://zone.ni.com/reference/en- XX/help/371361R-01/gmath/correlation_test/ [79] NI LabVIEW Cross-Correlation. [Online]. Available: https://zone.ni.com/reference/en-XX/help/371361R-01/lvanls/crosscorrelation/ [80] Waveform Tracktion. [Online]. Available: https://www.tracktion.com/products/waveform-free [81] O. Galibert, “Methodologies for the evaluation of speaker diarization and automatic speech recognition in the presence of overlapping speech,” In Proc. INTERSPEECH 2013, 2013, pp. 1131-1134. [82] Q. Wang, “SimpleDER: a lightweight library to compute Diarization Error Rate (DER)”. [Online]. Available: https://pypi.org/project/simpleder/. 169 [83] Audacity® software is copyright © 1999-2021 Audacity Team. Web site: https://audacityteam.org/. It is free software distributed under the terms of the GNU General Public License. The name Audacity® is a registered trademark. [84] P. Kabal, TSP Speech Database, version 2 (2018-11), Montreal, Quebec: McGill University Department of Electrical and Computer Engineering Telecommunications & Signal Processing Laboratory, 2018. [Online]. Available: http://www- mmsp.ece.mcgill.ca/Documents/Data/. [85] Y. Fujita, N. Kanda, S. Horiguchi, K. Nagamatsu, and S. Watanabe, “End-to-end neural speaker diarization with permutation-free objectives,” In Proc. INTERSPEECH 2019, 2019, pp. 4300-4304. 170","['digital', 'repository', 'unm', 'digital', 'repository', 'electrical', 'computer', 'engineering', 'etd', 'engineering', 'etd', 'spring', 'speaker', 'diarization', 'identification', 'speaker', 'diarization', 'identification', 'singlechannel', 'classroom', 'audio', 'recording', 'use', 'virtual', 'microphone', 'classroom', 'audio', 'recording', 'use', 'virtual', 'microphone', 'gomez', 'follow', 'additional', 'work', 'part', 'bilingual', 'multilingual', 'multicultural', 'educational', 'method', 'common', 'educational', 'technology', 'science', 'mathematic', 'common', 'gomez', 'candidate', 'electrical', 'computer', 'engineering', 'department', 'dissertation', 'approve', 'acceptable', 'quality', 'form', 'publication', 'approve', 'dissertation', 'committee', 'speaker', 'diarization', 'identification', 'singlechannel', 'classroom', 'audio', 'recording', 'use', 'virtual', 'microphone', 'electrical', 'engineering', 'engineering', 'dissertation', 'submit', 'partial', 'fulfillment', 'requirement', 'degree', 'doctor', 'philosophy', 'engineer', 'dedication', 'like', 'dedicate', 'dissertation', 'special', 'person', 'life', 'wife', 'grace', 'support', 'long', 'journey', 'hour', 'day', 'month', 'year', 'spend', 'give', 'breath', 'move', 'time', 'tell', 'time', 'finish', 'well', 'eternal', 'gratitude', 'like', 'also', 'dedicate', 'work', 'child', 'understanding', 'sometimes', 'hope', 'work', 'serve', 'inspiration', 'acknowledgement', 'like', 'sincerely', 'acknowledge', 'labor', 'advisor', 'dissertation', 'chair', 'continued', 'support', 'year', 'thank', 'believe', 'mario', 'never', 'side', 'like', 'also', 'thank', 'committee', 'member', 'take', 'time', 'review', 'advise', 'work', 'thank', 'always', 'friend', 'finally', 'like', 'say', 'thank', 'manager', 'national', 'lab', 'support', 'understand', 'speaker', 'diarization', 'identification', 'singlechannel', 'classroom', 'audio', 'recording', 'use', 'virtual', 'microphone', 'electrical', 'engineering', 'engineering', 'phd', 'abstract', 'speaker', 'identification', 'noisy', 'audio', 'recording', 'specifically', 'collaborative', 'learning', 'environment', 'extremely', 'challenging', 'need', 'identify', 'individual', 'student', 'talk', 'small', 'group', 'student', 'talk', 'time', 'solve', 'problem', 'assume', 'use', 'single', 'microphone', 'student', 'group', 'access', 'previous', 'large', 'dataset', 'train', 'dissertation', 'propose', 'method', 'speaker', 'identification', 'use', 'cross', 'correlation', 'pattern', 'associate', 'array', 'virtual', 'microphone', 'center', 'physical', 'microphone', 'virtual', 'microphone', 'simulate', 'use', 'approximate', 'speaker', 'geometry', 'observe', 'video', 'recording', 'pattern', 'construct', 'base', 'estimate', 'room', 'impulse', 'response', 'virtual', 'microphone', 'correlation', 'pattern', 'use', 'identify', 'speaker', 'propose', 'method', 'validate', 'classroom', 'audio', 'show', 'substantially', 'outperform', 'diarization', 'service', 'provide', 'amazon', 'aw', 'vi', 'table', 'content', 'list', 'figure', 'xii', 'list', 'table', 'chapter', 'introduction', 'motivation', 'relate', 'research', 'thesis', 'statement', 'contribution', 'dissertation', 'overview', 'chapter', 'background', 'acoustic', 'principle', 'sound', 'propagation', 'far', 'field', 'sound', 'propagation', 'direct', 'path', 'reflection', 'reverberation', 'microphone', 'microphone', 'array', 'classification', 'microphone', 'microphone', 'array', 'microphone', 'arrays', 'configuration', 'spatial', 'aliasing', 'tdoa', 'crosscorrelation', 'beamforming', 'spatial', 'filter', 'modeling', 'room', 'acoustic', 'ray', 'tracing', 'method', 'image', 'source', 'method', 'characteristic', 'human', 'speech', 'speaker', 'diarization', 'identification', 'method', 'diarization', 'identification', 'classical', 'method', 'diarization', 'identification', 'deep', 'neural', 'network', 'stagewise', 'diarization', 'multimodal', 'speaker', 'diarization', 'current', 'stateoftheart', 'method', 'diarization', 'identification', 'chapter', 'propose', 'method', 'methodology', 'block', 'diagram', 'propose', 'system', 'chapter', 'experimental', 'implementation', 'software', 'hardware', 'tool', 'opensource', 'code', 'room', 'geometry', 'rir', 'calculation', 'microphone', 'simulation', 'pyroomacoustics', 'implementation', 'audio', 'segmentation', 'viii', 'fix', 'length', 'segmentation', 'voice', 'activity', 'detection', 'implementation', 'use', 'labview', 'graphical', 'programming', 'labview', 'implementation', 'function', 'audio', 'laboratory', 'environment', 'characteristic', 'environment', 'preparation', 'experimental', 'model', 'approximate', 'model', 'use', 'video', 'observation', 'chapter', 'result', 'evaluation', 'microphone', 'calibration', 'audio', 'lab', 'setup', 'model', 'configuration', 'experimental', 'execution', 'result', 'control', 'environment', 'experiment', 'methodology', 'audio', 'lab', 'model', 'preparation', 'evaluation', 'criterion', 'hal', 'experiment', 'source', 'preparation', 'edit', 'ground', 'truth', 'recording', 'training', 'segmentation', 'testing', 'result', 'multispeaker', 'identification', 'experiment', 'source', 'preparation', 'edit', 'ground', 'truth', 'recording', 'training', 'segmentation', 'testing', 'result', 'aolme', 'experiment', 'evaluation', 'selection', 'model', 'preparation', 'training', 'segmentation', 'testing', 'result', 'comparison', 'method', 'methodology', 'comparison', 'selection', 'preparation', 'ground', 'truth', 'measurement', 'video', 'analysis', 'training', 'segmentation', 'testing', 'analysis', 'result', 'chapter', 'summary', 'conclusion', 'future', 'work', 'appendix', 'pyroomacoustic', 'script', '143', 'b', 'labview', 'subvis', 'audio', 'lab', 'equipment', 'specification', 'reference', 'list', 'figure', 'figure', 'propagation', 'sound', 'wave', 'free', 'field', 'directional', 'figure', 'farfield', 'area', 'figure', 'direct', 'reflect', 'path', 'sound', 'propagation', 'diffuse', 'field', 'figure', 'representation', 'room', 'impulse', 'response', 'component', 'figure', 'polar', 'pattern', 'plot', 'directivity', 'type', 'microphone', 'omnidirectional', 'b', 'cardioid', 'figure', 'linear', 'microphone', 'array', 'geometry', 'b', 'directionality', 'pattern', 'figure', 'crosslinear', 'array', 'azimuth', 'directivity', 'pattern', 'figure', 'circular', 'microphone', 'array', 'directivity', 'pattern', 'figure', 'volumetric', 'microphone', 'array', 'directivity', 'pattern', 'figure', 'location', 'source', 'microphone', 'time', 'difference', 'arrival', 'figure', 'simulation', 'method', 'ray', 'trace', 'image', 'source', 'method', 'figure', 'source', 'image', 'map', 'figure', 'directionality', 'human', 'head', 'figure', 'block', 'diagram', 'typical', 'speaker', 'diarization', 'figure', 'gmmivector', 'framework', 'figure', 'dnnivector', 'implementation', 'figure', 'collaborative', 'environment', 'model', 'xii', 'figure', 'model', 'fig', '12b', 'microphone', 'array', 'figure', 'possible', 'model', 'fig', 'figure', 'estimation', 'source', 'figure', 'estimation', 'virtual', 'microphone', 'figure', 'training', 'sample', 'speaker', 'noise', 'figure', 'audio', 'segmentation', 'use', 'figure', 'block', 'diagram', 'propose', 'system', 'figure', 'pyroomacoustic', 'model', 'b', 'c', 'image', 'figure', 'labview', 'sub', 'vi', 'crosscorrelation', 'calculation', 'figure', 'labview', 'convolution', 'figure', 'labview', 'deconvolution', 'figure', 'labview', 'correlation', 'figure', 'labview', 'crosscorrelation', 'figure', 'audio', 'lab', 'component', 'figure', 'audio', 'lab', 'setup', 'figure', 'common', 'aolme', 'environment', 'setup', 'figure', 'relative', 'position', 'aolme', 'participant', 'figure', 'location', 'speaker', 'real', 'microphone', 'figure', 'model', 'virtual', 'room', 'figure', 'final', 'model', 'example', 'figure', 'block', 'diagram', 'microphone', 'calibration', 'setup', 'figure', 'microphone', 'calibration', 'location', 'loudspeaker', 'figure', 'audio', 'lab', 'setup', 'evaluation', 'figure', 'final', 'model', 'audio', 'lab', 'setup', 'figure', 'model', 'control', 'experiment', 'figure', 'video', 'clip', 'hal', 'clip2', 'figure', 'source', 'noise', 'hal', 'experiment', 'figure', 'ground', 'truth', 'set', 'b', 'hal', 'experiment', 'figure', 'training', 'segment', 'figure', '47video', 'clip', 'aolme', 'experiment', 'figure', 'model', 'aolme', 'experiment', 'figure', 'room', 'parameter', 'reader', 'input', 'output', 'figure', 'room', 'parameter', 'reader', 'front', 'panel', 'figure', 'room', 'parameter', 'reader', 'block', 'diagram', 'figure', 'room', 'model', 'figure', 'room', 'model', 'generator', 'front', 'panel', 'figure', 'room', 'model', 'generator', 'figure', 'source', 'estimator', 'icon', 'figure', 'source', 'estimator', 'front', 'panel', 'figure', 'source', 'estimator', 'simplify', 'block', 'figure', 'crosscorrelation', 'model', 'calculator', 'figure', 'crosscorrelation', 'model', 'calculator', 'front', 'panel', 'figure', 'crosscorrelation', 'model', 'calculator', 'block', 'figure', 'crosscorrelation', 'model', 'calculator', 'crosscorrelator', 'subvi', 'figure', 'model', 'classifier', 'icon', 'input', 'output', 'figure', 'model', 'classifier', 'front', 'panel', 'figure', 'multifunction', 'convolution', 'correlator', 'visualizer', 'front', 'panel', 'figure', 'multifunction', 'convolution', 'xv', 'list', 'table', 'table', 'template', 'crosscorrelation', 'table', 'source', 'table', 'template', 'crosscorrelation', 'table', 'source', 'table', 'iii', 'template', 'crosscorrelation', 'table', 'source', 'table', 'iv', 'example', 'crosscorrelation', 'table', 'output', 'model', 'calculator', 'table', 'crosscorrelation', 'table', 'classification', 'table', 'vi', 'crosscorrelation', 'table', 'microphone', 'calibration', 'table', 'vii', 'dimension', 'virtual', 'room', 'location', 'source', 'table', 'viii', 'experimental', 'result', 'simulation', 'software', 'evaluation', 'table', 'distribution', 'microphone', 'source', 'control', 'experiment', 'table', 'x', 'der', 'result', 'hal', 'experiment', 'table', 'experiment', 'sequence', 'table', 'table', 'xii', 'control', 'environment', 'experiment', 'diarization', 'error', 'rate', 'result', 'table', 'xiii', 'location', 'speaker', 'microphone', 'aolme', 'experiment', 'table', 'speaker', 'assignment', 'experiment', 'table', 'table', 'aolme', 'experiment', 'table', 'xvi', 'classification', 'result', 'aolme', 'experiment', 'table', 'experimental', 'comparison', 'method', 'table', 'average', 'error', 'method', 'xvi', 'chapter', 'introduction', 'field', 'speech', 'processing', 'include', 'speech', 'recognition', 'separation', 'transcription', 'enhancement', 'undergo', 'several', 'transformational', 'change', 'significant', 'progress', 'speaker', 'identification', 'crowded', 'room', 'continue', 'difficult', 'problem', 'crosstalk', 'large', 'amount', 'background', 'noise', 'make', 'environment', 'particularly', 'challenge', 'speaker', 'identification', 'diarization', 'system', 'rely', 'use', 'deep', 'learning', 'method', 'require', 'pretraine', 'large', 'dataset', 'speech', 'feature', 'formant', 'frequency', 'pitch', 'contour', 'coarticulation', 'extract', 'test', 'sample', 'eventually', 'match', 'database', 'training', 'sample', 'database', 'need', 'contain', 'many', 'training', 'example', 'possible', 'update', 'periodically', 'maintain', 'proper', 'performance', 'level', 'accuracy', 'identification', 'depend', 'size', 'database', 'big', 'database', 'well', 'accuracy', 'long', 'training', 'time', 'addition', 'long', 'training', 'time', 'database', 'prone', 'bias', 'concern', 'spoken', 'language', 'accent', 'biasing', 'usually', 'unintentional', 'unconscious', 'product', 'environment', 'speech', 'recognition', 'system', 'develop', 'limitation', 'speech', 'processing', 'system', 'evident', 'challenging', 'situation', 'collaborative', 'environment', 'meeting', 'largescale', 'educational', 'setting', 'general', 'environment', 'commonly', 'consist', 'multiple', 'speaker', 'sit', 'table', 'locate', 'room', 'speaker', 'take', 'turn', 'speak', 'unusual', 'speaker', 'talk', 'time', 'environment', 'also', 'noisy', 'numerous', 'participant', 'group', 'room', 'type', 'environment', 'difficult', 'speech', 'processing', 'system', 'require', 'many', 'case', 'heavy', 'manual', 'analysis', 'manual', 'diarization', 'meeting', 'tedious', 'timeconsuming', 'task', 'require', 'many', 'hour', 'processing', 'subject', 'many', 'interpretation', 'error', 'need', 'many', 'educational', 'research', 'activity', 'understand', 'classroom', 'material', 'engage', 'student', 'understand', 'student', 'interact', 'classroom', 'session', 'record', 'transcribe', 'important', 'problem', 'determine', 'participant', 'speak', 'particular', 'moment', 'say', 'long', 'participant', 'speak', 'automate', 'method', 'usually', 'require', 'audio', 'recording', 'prone', 'error', 'noise', 'crosstalk', 'also', 'system', 'limitation', 'number', 'speaker', 'process', 'well', 'length', 'audio', 'segment', 'diarization', 'system', 'require', 'enrollment', 'speaker', 'generate', 'abstract', 'label', 'speaker', 'active', 'audio', 'segment', 'hand', 'speaker', 'identification', 'system', 'provide', 'nonabstract', 'label', 'enrol', 'participate', 'speaker', 'enrollment', 'process', 'consist', 'speaker', 'provide', 'several', 'second', 'noisefree', 'speech', 'requirement', 'meet', 'datum', 'consist', 'audio', 'recording', 'busy', 'meeting', 'noisy', 'background', 'thus', 'important', 'develop', 'speech', 'identification', 'diarization', 'method', 'impose', 'requirement', 'preenroll', 'speaker', 'dissertation', 'aim', 'provide', 'foundation', 'new', 'approach', 'speaker', 'identification', 'diarization', 'use', 'virtual', 'microphone', 'spatial', 'information', 'simulation', 'never', 'perfect', 'work', 'show', 'possible', 'use', 'approximation', 'real', 'room', 'geometry', 'obtain', 'acoustic', 'parameter', 'necessary', 'simulate', 'reception', 'virtual', 'array', 'microphone', 'use', 'simulated', 'signal', 'speaker', 'diarization', 'identification', 'simulation', 'base', 'physical', 'model', 'require', 'database', 'independent', 'spoken', 'language', 'accent', 'participant', 'require', 'prior', 'speaker', 'enrollment', 'present', 'high', 'immunity', 'noise', 'propose', 'approach', 'rely', 'fact', 'discriminant', 'information', 'geometry', 'speaker', 'embed', 'recorded', 'audio', 'single', 'microphone', 'basic', 'idea', 'recognize', 'speaker', 'use', 'acoustical', 'simulation', 'part', 'simulation', 'process', 'propose', 'method', 'compute', 'room', 'impulse', 'response', 'rir', 'microphone', 'speaker', 'simulate', 'reception', 'virtual', 'microphone', 'accuracy', 'process', 'compute', 'rir', 'verify', 'reallife', 'measurement', 'correlation', 'pattern', 'base', 'simulated', 'reception', 'virtual', 'microphone', 'method', 'compute', 'correlation', 'pattern', 'virtual', 'microphone', 'record', 'audio', 'also', 'use', 'generate', 'different', 'correlation', 'pattern', 'base', 'hypothesized', 'speaker', 'location', 'classifier', 'apply', 'generate', 'correlation', 'pattern', 'select', 'likely', 'speaker', 'location', 'approach', 'several', 'advantage', 'first', 'require', 'database', 'speech', 'system', 'base', 'physical', 'model', 'unique', 'scene', 'analyze', 'database', 'train', 'model', 'system', 'require', 'capture', 'second', 'audio', 'speaker', 'training', 'recognition', 'contrast', 'stateoftheart', 'system', 'require', 'ten', 'second', 'clean', 'audio', 'training', 'several', 'second', 'identification', 'second', 'system', 'conceive', 'operate', 'noisy', 'environment', 'microphone', 'array', 'crosscorrelation', 'analysis', 'prove', 'efficient', 'method', 'speaker', 'discrimination', 'third', 'simulation', 'require', 'audio', 'use', 'single', 'channel', 'recording', 'reference', 'simulation', 'finally', 'system', 'run', 'simple', 'computer', 'need', 'access', 'remote', 'computer', 'cluster', 'database', 'motivation', 'work', 'motivate', 'need', 'reliable', 'nonmanual', 'method', 'assess', 'level', 'engagement', 'student', 'participate', 'advance', 'outofschool', 'learn', 'mathematic', 'engineering', 'aolme', 'program', 'aolme', 'collaborative', 'learning', 'environment', 'student', 'introduce', 'stem', 'subject', 'integrate', 'computer', 'programming', 'middle', 'school', 'mathematic', 'form', 'part', 'educational', 'research', 'activity', 'perform', 'image', 'video', 'processing', 'communication', 'lab', 'ivpcl', 'aolme', 'session', 'video', 'record', 'later', 'analysis', 'include', 'student', 'participation', 'overall', 'level', 'attention', 'well', 'facilitator', 'interaction', 'student', 'analysis', 'consist', 'evaluate', 'activity', 'participant', 'hand', 'head', 'movement', 'use', 'keyboard', 'mouse', 'lip', 'movement', 'transcription', 'session', 'determine', 'time', 'participant', 'speak', 'long', 'detailed', 'participation', 'statistic', 'participant', 'currently', 'available', 'manually', 'measure', 'talking', 'time', 'timeconsuming', 'plague', 'error', 'aolme', 'organizer', 'try', 'several', 'transcription', 'system', 'currently', 'available', 'market', 'opensource', 'code', 'much', 'success', 'aolme', 'environment', 'extremely', 'challenging', 'speech', 'recognition', 'transcription', 'system', 'multiple', 'group', 'talk', 'time', 'presence', 'background', 'noise', 'echo', 'hence', 'need', 'robust', 'system', 'overcome', 'limitation', 'current', 'stateoftheart', 'method', 'complement', 'ivpcl', 'method', 'application', 'process', 'hundred', 'hour', 'video', 'recording', 'aolme', 'video', 'analysis', 'present', 'challenge', 'addition', 'presence', 'multiple', 'speaker', 'noise', 'first', 'video', 'take', 'simple', 'video', 'camera', 'use', 'single', 'microphone', 'locate', 'meeting', 'table', 'budget', 'limitation', 'restrict', 'purchasing', 'use', 'advanced', 'equipment', 'audio', 'recording', 'capability', 'second', 'already', 'hundred', 'hour', 'video', 'recording', 'need', 'analyze', 'previous', 'speaker', 'enrollment', 'use', 'train', 'speaker', 'identification', 'system', 'furthermore', 'participant', 'speak', 'several', 'second', 'time', 'make', 'identification', 'process', 'difficult', 'even', 'future', 'session', 'possible', 'record', 'audio', 'enroll', 'speaker', 'need', 'process', 'exist', 'video', 'therefore', 'need', 'flexible', 'method', 'handle', 'new', 'exist', 'recording', 'relate', 'research', 'assess', 'level', 'engagement', 'participant', 'collaborative', 'educational', 'session', 'require', 'application', 'tool', 'extract', 'relevant', 'information', 'audio', 'video', 'datum', 'information', 'interpret', 'translate', 'statistical', 'datum', 'researcher', 'end', 'tool', 'identify', 'activity', 'video', 'scene', 'relate', 'attention', 'behavior', 'eg', 'type', 'writing', 'identify', 'active', 'speaker', 'speaker', 'audio', 'segment', 'relate', 'work', 'dissertation', 'include', 'type', 'tool', 'area', 'activity', 'track', 'important', 'mention', 'work', 'ivpcl', 'lab', 'direct', 'connection', 'aolme', 'program', 'analyze', 'video', 'use', 'color', 'optical', 'flow', 'track', 'hand', 'movement', 'present', 'fast', 'method', 'video', 'analysis', 'hand', 'object', 'tracking', 'well', 'jacoby', 'work', 'human', 'activity', 'detection', 'use', 'contextsensitive', 'approach', 'use', 'convolutional', 'net', 'eiliar', 'provide', 'maintainable', 'opensource', 'activity', 'system', 'detection', 'attention', 'trait', 'investigate', 'use', 'model', 'detect', 'head', 'direction', 'group', 'interaction', 'research', 'speech', 'processing', 'cover', 'vast', 'area', 'contain', 'different', 'topic', 'umbrella', 'speech', 'processing', 'find', 'speech', 'identification', 'speech', 'enhancement', 'speaker', 'speaker', 'diarization', 'speaker', 'identification', 'dissertation', 'focus', 'speaker', 'identification', 'diarization', 'part', 'research', 'labor', 'ivpcl', 'lab', 'aolme', 'program', 'speaker', 'identification', 'process', 'recognize', 'identity', 'speaker', 'several', 'speaker', 'present', 'speech', 'segment', 'speaker', 'diarization', 'process', 'audio', 'recording', 'contain', 'several', 'speaker', 'dissect', 'segment', 'contain', 'speaker', 'time', 'speaker', 'diarization', 'often', 'define', 'say', 'long', 'speaker', 'identification', 'speaker', 'diarization', 'important', 'mechanism', 'many', 'audioprocesse', 'task', 'research', 'speech', 'processing', 'nowadays', 'focus', 'use', 'artificial', 'neural', 'network', 'deep', 'learn', 'deep', 'belief', 'network', 'dbn', 'widely', 'use', 'speech', 'recognition', 'xvector', 'consider', 'today', 'state', 'art', 'speaker', 'xvector', 'method', 'outperform', 'classic', 'ivector', 'method', 'order', 'test', 'dataset', 'voxceleb', 'nist', 'sre', 'swbd', 'research', 'dissertation', 'focus', 'use', 'spatial', 'information', 'virtual', 'microphone', 'array', 'speaker', 'identification', 'diarization', 'attempt', 'cover', 'method', 'use', 'spatial', 'information', 'virtual', 'microphone', 'array', 'speaker', 'identification', 'diarization', 'extensive', 'neural', 'network', 'deep', 'learning', 'research', 'possible', 'find', 'numerous', 'work', 'demonstrate', 'use', 'spatial', 'information', 'speaker', 'identification', 'diarization', 'well', 'application', 'virtual', 'microphone', 'array', 'acoustic', 'signal', 'enhancement', 'meeting', 'diarization', 'reference', 'work', 'present', 'next', 'section', 'literature', 'regard', 'application', 'microphone', 'array', 'beamforming', 'relate', 'implementation', 'spatial', 'filter', 'improve', 'signaltonoise', 'ratio', 'snr', 'nevertheless', 'several', 'researcher', 'find', 'way', 'exploit', 'operational', 'principle', 'microphone', 'array', 'apply', 'speaker', 'identification', 'diarization', 'xavi', 'propose', 'use', 'beamforme', 'algorithm', 'forefront', 'speaker', 'diarization', 'system', 'beamforme', 'algorithm', 'take', 'advantage', 'environment', 'commonly', 'encounter', 'meeting', 'multiple', 'microphone', 'enhance', 'single', 'signal', 'interest', 'anguera', 'conventional', 'delay', 'sum', 'beamforme', 'array', 'operate', 'constraint', 'unknown', 'number', 'speaker', 'unknown', 'location', 'speaker', 'microphone', 'microphone', 'mismatching', 'time', 'differential', 'arrival', 'tdoa', 'microphone', 'calculate', 'cross', 'correlation', 'diarization', 'accomplish', 'agglomerative', 'clustering', 'cluster', 'model', 'gaussian', 'mixture', 'model', 'separate', 'set', 'gmms', 'use', 'model', 'tdoa', 'feature', 'similar', 'manner', 'anguera', 'propose', 'use', 'beamforme', 'parallel', 'independent', 'component', 'analysis', 'audio', 'source', 'separation', 'source', 'separation', 'require', 'knowledge', 'parameter', 'mix', 'matrix', 'parameter', 'know', 'separation', 'problem', 'become', 'blind', 'source', 'separation', 'problem', 'illpose', 'problem', 'multiple', 'solution', 'mitianoudi', 'use', 'directivity', 'pattern', 'beamforming', 'use', 'phase', 'information', 'select', 'signal', 'different', 'possible', 'permutation', 'previous', 'author', 'exploit', 'phase', 'information', 'signal', 'capture', 'microphone', 'array', 'research', 'also', 'exploit', 'phase', 'information', 'tdoa', 'microphone', 'means', 'determine', 'relative', 'position', 'active', 'speaker', 'thus', 'identity', 'previous', 'work', 'show', 'use', 'crosscorrelation', 'calculate', 'study', 'performance', 'crosscorrelation', 'coefficient', 'method', 'robust', 'solution', 'calculation', 'tdoa', 'noisy', 'reverberant', 'environment', 'study', 'performance', 'timedomain', 'beamformer', 'base', 'generalized', 'crosscorrelation', 'function', 'generate', 'sound', 'source', 'map', 'interpolate', 'crosscorrelation', 'function', 'microphone', 'generate', 'twodimensional', 'hyperbola', 'spatial', 'likelihood', 'function', 'number', 'correspond', 'number', 'microphone', 'use', 'array', 'source', 'position', 'determine', 'average', 'hyperbola', 'determine', 'maximum', 'value', 'intersecting', 'point', 'location', 'general', 'experimental', 'result', 'show', 'resolution', 'improve', 'number', 'microphone', 'number', 'performance', 'seem', 'present', 'work', 'closely', 'related', 'research', 'rir', 'room', 'geometry', 'tdoa', 'estimation', 'method', 'source', 'localization', 'utilize', 'rir', 'amplitude', 'fit', 'tdoa', 'surface', 'amplitude', 'surface', 'room', 'know', 'geometry', 'rir', 'obtain', 'set', 'microphone', 'unknown', 'location', 'rir', 'amplitude', 'direct', 'path', 'impulse', 'high', 'short', 'relative', 'time', 'arrival', 'signal', 'close', 'receiving', 'microphone', 'area', 'maximum', 'amplitude', 'minimum', 'delay', 'consider', 'estimate', 'source', 'area', 'center', 'area', 'estimate', 'source', 'location', 'similar', 'work', 'previously', 'present', 'tervo', 'et', 'instead', 'source', 'location', 'work', 'focus', 'localization', 'acoustic', 'reflection', 'use', 'combined', 'toa', 'tdoa', 'information', 'contain', 'rir', 'work', 'present', 'far', 'take', 'advantage', 'property', 'beamformer', 'doa', 'crosscorrelation', 'also', 'require', 'array', 'physical', 'microphone', 'dissertation', 'method', 'depend', 'information', 'capture', 'single', 'microphone', 'research', 'material', 'single', 'microphone', 'acoustic', 'separation', 'base', 'spatial', 'information', 'limited', 'well', 'work', 'virtual', 'microphone', 'arrays', 'purpose', 'nevertheless', 'interesting', 'work', 'provide', 'useful', 'information', 'work', 'perhaps', 'close', 'work', 'research', 'find', 'present', 'method', 'utilize', 'reverberant', 'information', 'know', 'direct', 'toreverberant', 'ration', 'drr', 'single', 'channel', 'recording', 'estimate', 'drr', 'use', 'peso', 'parada', 'et', 'combine', 'melfrequency', 'cepstral', 'coefficient', 'diarization', 'method', 'propose', 'principle', 'use', 'mfcc', 'drr', 'feature', 'combination', 'train', 'system', 'perform', 'clustering', 'type', 'classification', 'estimate', 'drr', 'compute', 'use', 'feature', 'signaltonoise', 'ratio', 'mfccs', 'power', 'spectrum', 'zerocrosse', 'rate', 'important', 'notice', 'work', 'test', 'use', 'simulated', 'meeting', 'recording', 'assume', 'speaker', 'stationary', 'research', 'work', 'dissertation', 'propose', 'virtual', 'microphone', 'simulation', 'necessary', 'present', 'relevant', 'work', 'area', 'yoshioka', 'describe', 'way', 'link', 'several', 'recording', 'device', 'laptop', 'mobile', 'phone', 'create', 'virtual', 'microphone', 'array', 'link', 'establish', 'audio', 'use', 'claim', 'achieve', 'diarization', 'rate', 'speech', 'duration', 'contain', 'speaker', 'yoshioka', 'approach', 'innovative', 'require', 'presence', 'several', 'recording', 'device', 'meeting', 'room', 'align', 'dissertation', 'work', 'author', 'propose', 'method', 'simulate', 'array', 'microphone', 'interpolate', 'signal', 'receive', 'physical', 'microphone', 'author', 'demonstrate', 'virtual', 'microphone', 'array', 'improve', 'snr', 'reverberant', 'environment', 'hence', 'potential', 'application', 'speech', 'processing', 'device', 'even', 'method', 'succeed', 'emulate', 'set', 'virtual', 'microphone', 'need', 'least', 'physical', 'microphone', 'seed', 'available', 'method', 'present', 'dissertation', 'finally', 'tapia', 'present', 'bilingual', 'speech', 'recognition', 'method', 'inspire', 'research', 'present', 'dissertation', 'tapia', 'utilize', 'still', 'video', 'frame', 'estimate', 'approximate', 'geometry', 'speaker', 'simulate', 'center', 'microphone', 'reception', 'use', 'pyroomacoustic', 'simulated', 'audio', 'use', 'alome', 'transcription', 'generate', 'training', 'set', 'convolutional', 'neural', 'network', 'thesis', 'statement', 'main', 'objective', 'dissertation', 'develop', 'method', 'apply', 'spatial', 'information', 'virtual', 'microphone', 'array', 'identify', 'multiple', 'speaker', 'single', 'channel', 'audio', 'recording', 'collaborative', 'environment', 'provide', 'activity', 'statistic', 'participant', 'method', 'aim', 'succeed', 'challenge', 'environment', 'multiple', 'active', 'speaker', 'background', 'noise', 'condition', 'make', 'current', 'stateoftheart', 'method', 'perform', 'poorly', 'purpose', 'work', 'dissertation', 'present', 'implementation', 'acoustic', 'model', 'base', 'virtual', 'room', 'rough', 'similar', 'geometry', 'actual', 'acoustic', 'scene', 'analyze', 'simulation', 'signal', 'receive', 'virtual', 'microphone', 'array', 'locate', 'virtual', 'scenario', 'signal', 'delay', 'virtual', 'microphone', 'represent', 'relative', 'physical', 'position', 'active', 'source', 'case', 'speaker', 'research', 'goal', 'find', 'suitable', 'way', 'extract', 'spatial', 'location', 'embed', 'single', 'channel', 'record', 'implement', 'model', 'subsequent', 'virtual', 'microphone', 'array', 'contribution', 'contribution', 'expect', 'work', 'include', '\uf0b7', 'method', 'identify', 'speaker', 'collaborative', 'environment', 'extract', 'spatial', 'information', 'single', 'channel', 'audio', 'recording', 'utilize', 'acoustic', 'simulation', 'virtual', 'microphone', '\uf0b7', 'solution', 'limitation', 'current', 'stateoftheart', 'speaker', 'identification', 'method', 'concern', 'multiple', 'speaker', 'speaker', 'gender', 'accent', 'background', 'noise', 'reverberation', '\uf0b7', 'development', 'speaker', 'identification', 'framework', 'base', 'explainable', 'model', 'develop', 'term', 'physical', 'characteristic', 'problem', 'hence', 'require', 'large', 'dataset', 'train', 'many', 'parameter', '\uf0b7', 'basis', 'tool', 'quantitative', 'analysis', 'video', 'recording', 'assess', 'level', 'interaction', 'participant', 'collaborative', 'environment', 'dissertation', 'overview', 'dissertation', 'divide', 'chapter', 'cover', 'background', 'theory', 'related', 'work', 'description', 'method', 'experiment', 'result', 'conclusion', 'recommendation', 'future', 'work', 'dissertation', 'present', 'follow', 'chapter', 'give', 'background', 'audio', 'spatial', 'theory', 'application', 'speaker', 'diarization', 'identification', 'functionally', 'compare', 'state', 'oftheart', 'method', '\uf0b7', 'chapter', 'present', 'foundation', 'propose', 'method', 'dissertation', 'base', 'block', 'diagram', 'implementation', '\uf0b7', 'chapter', 'describe', 'practical', 'implementation', 'include', 'software', 'model', 'implementation', 'simulation', 'ion', 'video', 'analysis', 'audio', 'segmentation', '\uf0b7', 'chapter', 'present', 'experimental', 'result', 'obtain', 'analyze', 'audio', 'control', 'uncontrolled', 'environment', 'experimental', 'comparison', 'method', 'current', 'google', 'amazon', 'speaker', 'diarization', 'method', 'chapter', 'present', 'summary', 'dissertation', 'possible', 'future', 'work', 'contain', 'script', 'pseudocode', 'python', 'implementation', 'pyroomacoustic', 'present', 'important', 'labview', 'front', 'panel', 'block', 'diagram', 'contain', 'specification', 'equipment', 'use', 'audio', 'laboratory', 'chapter', 'background', 'chapter', 'introduce', 'principle', 'form', 'foundation', 'define', 'method', 'describe', 'dissertation', 'section', 'begin', 'basic', 'acoustic', 'theory', 'concept', 'definition', 'continue', 'presentation', 'microphone', 'microphone', 'array', 'finalize', 'introduction', 'method', 'speaker', 'diarization', 'identification', 'cover', 'classic', 'method', 'deep', 'learning', 'method', 'acoustic', 'principle', 'perception', 'sound', 'sound', 'capture', 'device', 'eg', 'microphone', 'human', 'ear', 'depend', 'characteristic', 'sound', 'source', 'also', 'depend', 'medium', 'sound', 'propagate', 'physical', 'environment', 'sound', 'source', 'locate', 'relative', 'location', 'capturing', 'device', 'source', 'dissertation', 'consider', 'factor', 'create', 'model', 'represent', 'environment', 'sound', 'source', 'speaker', 'active', 'chapter', 'present', 'brief', 'introduction', 'aolme', 'program', 'aolme', 'video', 'recording', 'take', 'room', 'participant', 'gather', 'group', 'sit', 'table', 'exact', 'geometry', 'room', 'unknown', 'video', 'recording', 'provide', 'clue', 'location', 'speaker', 'separation', 'physical', 'height', 'location', 'recording', 'microphone', 'clue', 'use', 'model', 'virtual', 'room', 'define', 'threedimensional', 'enclose', 'space', 'acoustic', 'event', 'take', 'place', 'virtual', 'room', 'necessarily', 'whole', 'space', 'aolme', 'participant', 'space', 'surround', 'participant', 'single', 'table', 'approximate', 'geometrical', 'physical', 'characteristic', 'virtual', 'room', 'allow', 'emulate', 'reception', 'array', 'virtual', 'microphone', 'sound', 'propagation', 'far', 'field', 'consider', 'acoustic', 'source', 'person', 'speak', 'stereo', 'system', 'play', 'song', 'run', 'ventilation', 'fan', 'sound', 'source', 'propagate', 'form', 'circular', 'air', 'pressure', 'wave', 'away', 'source', 'propagate', 'direction', 'source', 'open', 'field', 'fig', 'directionally', 'source', 'proximity', 'nonconducte', 'medium', 'wall', 'acoustic', 'theory', 'relative', 'location', 'source', 'point', 'space', 'determine', 'field', 'location', 'source', 'near', 'field', 'distance', 'point', 'less', 'wavelength', 'acoustic', 'signal', 'emit', 'source', 'locate', 'distance', 'great', 'wavelength', 'locate', 'farfield', 'field', 'location', 'source', 'play', 'important', 'factor', 'model', 'perception', 'sound', 'wave', 'point', 'space', 'figure', 'propagation', 'sound', 'wave', 'free', 'field', 'directional', 'fig', 'show', 'representation', 'near', 'field', 'transition', 'zone', 'farfield', 'near', 'field', 'sound', 'wave', 'behave', 'turbulently', 'circulation', 'propagation', 'distance', 'wavelength', 'source', 'sound', 'wave', 'begin', 'transition', 'propagation', 'wavelength', 'sound', 'wave', 'mostly', 'propagate', 'infinite', 'point', 'locate', 'near', 'field', 'perceive', 'sound', 'wave', 'circular', 'locate', 'farfield', 'consider', 'wave', 'planar', 'figure', 'farfield', 'area', 'sound', 'propagation', 'direct', 'path', 'reflection', 'reverberation', 'perception', 'sound', 'vary', 'depend', 'listener', 'locate', 'theater', 'room', 'small', 'dormitory', 'open', 'field', 'difference', 'perception', 'result', 'behavior', 'sound', 'wave', 'propagate', 'medium', 'visualize', 'phenomenon', 'consider', 'example', 'room', 'acoustic', 'source', 'person', 'speak', 'microphone', 'represent', 'fig', 'figure', 'direct', 'reflect', 'path', 'sound', 'propagation', 'diffuse', 'field', 'fig', 'fig', 'sound', 'source', 'reach', 'observer', 'receiver', 'directly', 'direction', 'reflection', 'case', 'source', 'say', 'acoustic', 'free', 'field', 'fig', 'contrast', 'represent', 'diffuse', 'field', 'case', 'sound', 'reach', 'microphone', 'direction', 'reflection', 'free', 'field', 'direct', 'signal', 'receive', 'microphone', 'characterize', 'distance', 'source', 'microphone', 'distance', 'determine', 'sound', 'pressure', 'microphone', 'time', 'take', 'sound', 'wave', 'reach', 'microphone', 'time', 'know', 'time', 'arrival', 'toa', 'function', 'speed', 'sound', 'room', 'euclidian', 'distance', 'source', 'microphone', 'reflection', 'contribute', 'similarly', 'signal', 'receive', 'microphone', 'express', 'mathematical', 'term', 'consider', 'signal', 'acoustic', 'source', 'locate', 'farfield', 'signal', 'capture', 'microphone', 'signal', 'convolution', 'room', 'impulse', 'response', 'rir', 'additive', 'noise', 'wt', 'give', '𝑤𝑡', 'rir', 'unique', 'point', 'room', 'depend', 'geometry', 'room', 'absorption', 'material', 'room', 'frequency', 'source', 'rir', 'consist', 'part', 'direct', 'path', 'early', 'reflection', 'late', 'reverberation', 'direct', 'path', 'component', 'determine', 'euclidian', 'distance', 'source', 'microphone', 'function', 'time', 'arrival', 'toa', 'time', 'take', 'signal', 'travel', 'source', 'microphone', 'component', 'rir', 'relate', 'reflection', 'sound', 'wave', 'wall', 'object', 'room', 'early', 'reflection', 'usually', 'arrive', 'ms', 'direct', 'path', 'late', 'reverberation', 'arrive', 'ms', 'early', 'reflection', 'begin', 'rir', 'express', 'summation', 'impulse', 'response', 'correspond', 'direct', 'path', 'reflection', 'number', 'reflection', 'index', 'number', 'reflection', 'measurement', 'noise', 'rir', 'last', 'reverberation', 'energy', 'decay', 'db', 'know', 't60', 'time', 't60', 'calculate', 'empirically', 'sabine', 'express', '𝑇cid2874cid2868', '𝑉', '𝑐', '∙', 'v', 'total', 'volume', 'room', 'c', 'speed', 'sound', 'total', 'surface', 'room', 'absorption', 'coefficient', 'room', 'reverberation', 'characterize', 'frequency', 'source', 'case', 'early', 'reflection', 'influence', 'minimum', 'fig', 'depict', 'representation', 'rir', 'component', 'figure', 'representation', 'room', 'impulse', 'response', 'component', 'path', 'reflection', 'wall', 'represent', 'direct', 'path', 'come', 'imaginary', 'source', 'call', 'image', 'signal', 'microphone', 'represent', 'number', 'contribute', 'source', 'image', 'reflection', 'acoustic', 'reflection', 'subject', 'toa', 'depend', 'distance', 'path', 'reflection', 'section', 'present', 'detail', 'concept', 'acoustic', 'image', 'role', 'room', 'simulation', 'microphone', 'microphone', 'array', 'previous', 'section', 'introduce', 'microphone', 'device', 'capable', 'capture', 'sound', 'general', 'term', 'microphone', 'sense', 'device', 'detect', 'change', 'air', 'pressure', 'convert', 'change', 'electrical', 'signal', 'microphone', 'categorize', 'electrical', 'conversion', 'type', 'directionality', 'pattern', 'deep', 'technical', 'detail', 'type', 'conversion', 'directionality', 'pattern', 'microphone', 'scope', 'dissertation', 'dissertation', 'consider', 'type', 'microphone', 'use', 'research', 'classification', 'microphone', 'research', 'use', 'type', 'physical', 'microphone', 'condenser', 'omnidirectional', 'condenser', 'cardioid', 'condenser', 'term', 'refer', 'type', 'electrical', 'conversion', 'sound', 'term', 'omnidirectional', 'cardioid', 'refer', 'directionality', 'microphone', 'condenser', 'microphone', 'work', 'utilize', 'variable', 'condenser', 'detect', 'air', 'pressure', 'change', 'change', 'pressure', 'translate', 'movement', 'plate', 'condenser', 'thus', 'change', 'capacitance', 'change', 'capacitance', 'measure', 'change', 'charge', 'current', 'circuit', 'condenser', 'microphone', 'also', 'know', 'name', 'electret', 'popular', 'type', 'microphone', 'today', 'directivity', 'pattern', 'microphone', 'determine', 'gain', 'sensitivity', 'accord', 'direction', 'incoming', 'sound', 'omnidirectional', 'microphone', 'equally', 'sensitive', 'incoming', 'sound', 'direction', 'microphone', 'simple', 'pressure', 'sense', 'device', 'acoustic', 'monopole', 'cardioid', 'microphone', 'also', 'know', 'pressure', 'gradient', 'microphone', 'characterize', 'directionality', 'pattern', 'heart', 'hence', 'name', 'cardioid', 'greek', 'heart', 'fig', 'show', 'typical', 'directivity', 'pattern', 'omnidirectional', 'cardioid', 'b', 'microphone', 'aolme', 'video', 'record', 'use', 'condenser', 'omnidirectional', 'microphone', 'figure', 'polar', 'pattern', 'plot', 'directivity', 'type', 'microphone', 'omnidirectional', 'b', 'cardioid', 'regardless', 'microphone', 'generate', 'noise', 'conversion', 'sound', 'pressure', 'wave', 'electrical', 'signal', 'carry', 'electrical', 'noise', 'flat', 'spectrum', 'manufacturer', 'usually', 'indicate', 'electrical', 'noise', 'microphone', 'signal', 'noise', 'ratio', 'snr', 'number', 'certain', 'sound', 'level', 'c', 'contain', 'technical', 'specification', 'microphone', 'use', 'research', 'microphone', 'array', 'microphone', 'arrange', 'geometric', 'pattern', 'become', 'microphone', 'array', 'microphone', 'array', 'important', 'functional', 'property', 'interest', 'capture', 'sound', 'noisy', 'environment', 'directionality', 'need', 'discriminate', 'sound', 'source', 'important', 'part', 'result', 'research', 'base', 'functional', 'characteristic', 'microphone', 'array', 'microphone', 'array', 'allow', 'incorporation', 'spatial', 'dimensionality', 'sound', 'capture', 'difference', 'signal', 'capture', 'microphone', 'separate', 'distance', 'provide', 'information', 'use', 'source', 'localization', 'tracking', 'general', 'noise', 'reduction', 'microphone', 'array', 'express', 'mathematically', 'x', 'represent', 'vector', 'microphone', 'signal', 'source', 'audio', 'signal', 'propagation', 'vector', 'represent', 'v', 'additive', 'noise', 'vector', 'express', '𝑎cid2869𝑒cid2879cid2870cid3095cid3033cid3099cid3117', '𝑎cid3041𝑒cid2879cid2870cid3095cid3033cid3099cid3289', '𝑎cid3015𝑒cid2879cid2870cid3095cid3033cid3099cid3263cid3021', 'represent', 'attenuation', 'factor', 'cid3415', '𝑛', '𝜏𝑛', 'channel', 'delay', '𝑑cid3046𝑛', 'distance', 'source', 'microphone', 'c', 'speed', 'sound', 'fine', 'detail', 'theory', 'microphone', 'array', 'scope', 'dissertation', 'nevertheless', 'important', 'basic', 'knowledge', 'property', 'microphone', 'array', 'application', 'source', 'localization', 'spatial', 'filtering', 'source', 'separation', 'application', 'relate', 'research', 'discuss', 'later', 'section', 'microphone', 'array', 'configuration', 'possible', 'geometry', 'microphone', 'array', 'infinite', 'different', 'geometry', 'guide', 'number', 'microphone', 'practically', 'allocate', 'array', 'type', 'acoustic', 'scenario', 'array', 'intend', 'operate', 'common', 'type', 'linear', 'circular', 'volumetric', 'linear', 'microphone', 'arrays', 'type', 'array', 'microphone', 'linearly', 'arrange', 'fig', '6a', 'represent', 'fivemicrophone', 'array', 'separation', 'microphone', 'array', 'configuration', 'popular', 'design', 'capture', 'sound', 'front', 'type', 'array', 'distinguish', 'sound', 'come', 'angle', 'axis', 'array', 'sound', 'wave', 'arrive', 'microphone', 'time', 'delay', 'fig', 'show', 'directivity', 'pattern', 'microphone', 'array', 'fig', 'calculate', 'hz', 'speed', 'sound', 'figure', 'linear', 'microphone', 'array', 'geometry', 'b', 'directionality', 'pattern', 'variant', 'type', 'array', 'crosslinear', 'array', 'also', 'know', 'planar', 'microphone', 'array', 'type', 'array', 'consist', 'linear', 'array', 'perpendicular', 'show', 'fig7', 'type', 'array', 'use', 'dissertation', 'virtual', 'microphone', 'simulation', 'figure', 'crosslinear', 'array', 'azimuth', 'directivity', 'pattern', 'circular', 'microphone', 'array', 'microphone', 'array', 'element', 'position', 'circularly', 'consist', 'circle', 'several', 'concentric', 'circle', 'show', 'fig', 'type', 'array', 'commonly', 'find', 'conference', 'equipment', 'center', 'meeting', 'table', 'figure', 'circular', 'microphone', 'array', 'directivity', 'pattern', 'c', 'volumetric', 'array', 'type', 'array', 'form', 'lattice', 'element', 'show', 'fig', 'capture', 'sound', 'direction', 'long', 'suspend', 'air', 'interference', 'shape', 'vary', 'cube', 'sphere', 'cylinder', 'figure', 'volumetric', 'microphone', 'array', 'directivity', 'pattern', 'spatial', 'aliasing', 'signal', 'aliasing', 'occur', 'sample', 'frequency', 'less', 'large', 'signal', 'frequency', 'component', 'bandwidth', 'signal', 'great', 'half', 'sample', 'frequency', 'spectral', 'overlapping', 'happen', 'spatial', 'aliasing', 'occur', 'similarly', 'reconstruct', 'spatial', 'signal', 'set', 'sample', 'necessary', 'spatial', 'sampling', 'period', 'less', 'half', 'signal', 'wavelength', 'microphone', 'array', 'phase', 'difference', 'microphone', 'less', 'avoid', 'spatial', 'aliase', 'constraint', 'mean', 'give', 'signal', 'frequency', 'maximum', 'distance', '𝑑', 'microphone', 'spatial', 'aliasing', 'occur', 'vice', 'versa', 'audio', 'signal', 'wavelength', 'distance', 'half', 'wavelength', '𝜆cid3040cid3036cid3041', 'translate', 'maximum', 'frequency', 'speed', 'sound', 'tdoa', 'crosscorrelation', 'important', 'property', 'microphone', 'array', 'time', 'difference', 'arrival', 'tdoa', 'microphone', 'tdoa', 'define', 'difference', 'time', 'signal', 'take', 'reach', 'point', 'separate', 'certain', 'distance', '𝑑', 'understand', 'concept', 'assume', 'microphone', 'separate', 'distance', 'sound', 'source', 'locate', 'distance', 'microphone', 'respectively', 'show', 'fig', 'figure', 'location', 'source', 'microphone', 'time', 'difference', 'arrival', 'difference', 'distance', 'define', '∗', 'speed', 'sound', 'tdoa', '𝑀𝑗', 'conversely', 'know', 'possible', 'determine', '𝐷𝑖', 'know', 'also', 'possible', 'infer', 'proximity', 'source', 'microphone', 'sign', 'positive', 'indicate', 'close', 'sound', 'source', 'negative', 'indicate', 'opposite', 'signal', 'delay', 'microphone', 'also', 'express', 'term', 'crosscorrelation', 'cc', 'let', 'denote', 'crosscorrelation', 'microphone', 'signal', 'correspond', 'microphone', 'signal', 'define', '𝑟cid3036cid3037𝑡', '≜', 'normalize', 'crosscorrelation', 'define', '𝑅cid3036cid3037𝑡', '𝑎', '𝑏', 'define', 'use', 'cid3495∑', 'cid3047', 'cid2870𝑡', 'cid3495∑', 'cid3047', 'beamforming', 'spatial', 'filter', 'process', 'filter', 'output', 'microphone', 'array', 'single', 'output', 'know', 'beamforme', 'beamforming', 'steer', 'array', 'directivity', 'pattern', 'particular', 'direction', 'use', 'beamforme', 'filter', 'combination', 'signal', 'microphone', 'govern', '𝒘𝑯𝒙', 'represent', 'beamforme', 'filter', '𝒘𝑯', 'conjugate', 'transpose', 'beamforme', 'filter', 'estimate', 'function', 'propagation', 'vector', 'noise', 'correlation', 'matrix', 'q', 'use', 'filter', 'describe', 'equation', 'know', 'minimum', 'variance', 'distortionless', 'response', 'mvdr', 'popular', 'type', 'beamforme', 'filter', 'refer', 'full', 'explanation', 'beamforme', 'filter', 'location', 'sound', 'source', 'know', 'possible', 'construct', 'spatial', 'filter', 'source', 'approach', 'use', 'minimize', 'crosstalk', 'channel', 'noise', 'reduction', 'detail', 'spatial', 'filtering', 'scope', 'dissertation', 'nevertheless', 'brief', 'introduction', 'present', 'future', 'work', 'propose', 'dissertation', 'include', 'possible', 'combination', 'propose', 'method', 'spatial', 'filtering', 'beamforme', 'speaker', 'separation', 'modeling', 'room', 'acoustic', 'propose', 'research', 'require', 'modeling', 'room', 'acoustic', 'simulation', 'microphone', 'source', 'base', 'physical', 'model', 'predict', 'effect', 'acoustic', 'reflection', 'give', 'geometry', 'room', 'location', 'speaker', 'end', 'simulation', 'calculate', 'rir', 'target', 'point', 'method', 'model', 'room', 'acoustic', 'dive', 'category', 'geometrical', 'acousticsbased', 'wave', 'acoustic', 'base', 'geometrical', 'acousticsbase', 'method', 'work', 'capitalize', 'reflection', 'property', 'sound', 'sound', 'reflect', 'smooth', 'surface', 'way', 'light', 'follow', 'snell', 'law', 'method', 'relatively', 'easy', 'implement', 'take', 'consideration', 'roughness', 'reflective', 'surface', 'hand', 'wave', 'acoustic', 'base', 'method', 'take', 'consideration', 'characteristic', 'sound', 'wave', 'provide', 'accurate', 'simulation', 'contrast', 'geometry', 'method', 'wave', 'method', 'computationally', 'intensive', 'limit', 'lowfrequency', 'range', 'simulation', 'package', 'use', 'research', 'geometry', 'acousticbased', 'wave', 'acousticbase', 'method', 'consider', 'dissertation', 'common', 'geometry', 'acousticbase', 'method', 'modeling', 'ray', 'trace', 'method', 'image', 'source', 'method', 'dissertation', 'focus', 'image', 'method', 'method', 'use', 'simulation', 'package', 'ray', 'tracing', 'method', 'ray', 'trace', 'method', 'assume', 'sound', 'radiate', 'source', 'several', 'ray', 'energy', 'total', 'energy', 'source', 'divide', 'number', 'ray', 'ray', 'propagate', 'speed', 'sound', 'reach', 'boundary', 'surface', 'energy', 'reflect', 'angle', '𝛼′', 'equal', 'incidence', 'angle', 'show', 'fig', 'perceive', 'sound', 'point', 'represent', 'echogram', 'contain', 'history', 'ray', 'reflection', 'direct', 'ray', 'ray', 'tracing', 'method', 'introduce', 'late', '1960', 'widely', 'use', 'ray', 'tracing', 'relatively', 'straightforward', 'method', 'resolution', 'limit', 'image', 'source', 'method', 'image', 'source', 'method', 'ism', 'also', 'know', 'mirror', 'image', 'source', 'method', 'mism', 'perhaps', 'popular', 'modeling', 'method', 'use', 'image', 'method', 'use', 'solve', 'physics', 'problem', 'late', '1970', 'introduce', 'rir', 'related', 'application', 'image', 'source', 'method', 'virtual', 'image', 'specular', 'reflection', 'source', 'create', 'perpendicularly', 'source', 'show', 'fig', 'b', 'sound', 'receive', 'sensor', 'summation', 'sound', 'source', 'image', 'source', 'figure', 'simulation', 'method', 'ray', 'trace', 'image', 'source', 'method', 'ism', 'need', 'amplitude', 'delay', 'image', 'source', 'calculate', 'rir', 'infinite', 'possible', 'reflection', 'path', 'ism', 'create', 'map', 'mirror', 'room', 'position', 'number', 'desire', 'image', 'show', 'fig', 'figure', 'source', 'image', 'map', 'coordinate', 'image', 'calculate', 'use', 'map', 'correspond', 'room', 'size', 'position', 'source', 'position', 'image', 'calculate', 'euclidian', 'distance', 'image', 'source', 'use', 'calculate', 'delay', 'speed', 'sound', 'room', 'finally', 'amplitude', '𝐴cid3041', 'signal', 'image', 'calculate', 'reflection', 'coefficient', 'wall', 'cross', 'path', 'image', 'sensor', 'use', 'rir', 'ℎ𝑡', 'calculate', 'use', 'amplitude', 'delay', 'image', 'cid3533', 'represent', 'image', 'source', '𝛿', 'function', 'characteristic', 'human', 'speech', 'performance', 'method', 'describe', 'dissertation', 'improve', 'acoustic', 'model', 'tailor', 'human', 'speech', 'human', 'speech', 'characteristic', 'exploit', 'use', 'compensate', 'deficiency', 'encounter', 'approximation', 'geometry', 'room', 'limitation', 'modeling', 'software', 'characteristic', 'human', 'speech', 'fundamental', 'frequency', 'directionality', 'particular', 'importance', 'speech', 'nonstationary', 'signal', 'rather', 'say', 'non', 'stationary', 'process', 'mean', 'frequency', 'content', 'unique', 'give', 'interval', 'time', 'fundamental', 'frequency', 'human', 'voice', 'vary', 'hz', 'hz', 'woman', 'go', 'hz', 'child', 'hz', 'even', 'high', 'whole', 'spectrum', 'human', 'voice', 'contain', 'frequency', 'go', '8khz', 'much', 'energy', 'find', 'frequency', 'hz', 'male', '800hz', 'female', 'curiosity', 'note', 'frequency', 'sensitivity', 'human', 'ear', 'close', 'frequency', 'spectrum', 'human', 'voice', 'research', 'work', 'focus', 'fundamental', 'frequency', 'develop', 'acoustic', 'model', 'detail', 'present', 'experimental', 'implementation', 'section', 'dissertation', 'important', 'characteristic', 'human', 'speech', 'directionality', 'speech', 'propagate', 'equally', 'direction', 'rather', 'directionality', 'location', 'mouth', 'shadow', 'cast', 'head', 'fig', 'depict', 'propagation', 'sound', 'horizontal', 'direction', 'present', 'propagation', 'vertical', 'axis', 'low', 'frequency', 'propagate', 'far', 'back', 'head', 'high', 'frequency', 'propagation', 'occur', 'front', 'head', 'directionality', 'property', 'utilize', 'position', 'speaker', 'simulation', 'model', 'figure', 'directionality', 'human', 'head', 'speaker', 'diarization', 'identification', 'section', 'present', 'background', 'several', 'method', 'speaker', 'diarization', 'identification', 'relate', 'research', 'understand', 'difference', 'method', 'method', 'propose', 'research', 'next', 'section', 'review', 'fundamental', 'method', 'base', 'review', 'detail', 'method', 'present', 'section', 'require', 'effort', 'go', 'scope', 'dissertation', 'reason', 'dissertation', 'focus', 'recent', 'common', 'method', 'speaker', 'diarization', 'identification', 'method', 'diarization', 'identification', 'speaker', 'diarization', 'summarize', 'say', 'long', 'task', 'determine', 'long', 'speaker', 'active', 'multi', 'participant', 'conversation', 'require', 'speaker', 'diarization', 'subsequent', 'identification', 'nonabstract', 'label', 'speaker', 'identification', 'confuse', 'speaker', 'verification', 'system', 'accept', 'reject', 'identity', 'claim', 'speaker', 'call', 'speaker', 'verification', 'system', 'dissertation', 'divide', 'method', 'category', 'classic', 'method', 'deep', 'learning', 'method', 'classical', 'method', 'diarization', 'identification', 'conduct', 'web', 'search', 'speaker', 'diarization', 'identification', 'method', 'find', 'thousand', 'even', 'million', 'document', 'somehow', 'relate', 'subject', 'time', 'dissertation', 'speaker', 'diarization', 'method', 'give', 'hit', 'speaker', 'identification', 'method', 'hit', 'speaker', 'diarization', 'identification', 'method', 'nevertheless', 'researcher', 'start', 'use', 'deep', 'learning', 'neural', 'network', 'method', 'speaker', 'diarization', 'identification', 'method', 'consist', 'basic', 'module', 'step', 'feature', 'extraction', 'module', 'speech', 'voice', 'activity', 'detector', 'sad', 'vad', 'respectively', 'segmenter', 'speaker', 'change', 'module', 'finally', 'clustering', 'mechanism', 'fig', 'show', 'block', 'diagram', 'module', 'figure', 'block', 'diagram', 'typical', 'speaker', 'diarization', 'system', 'feature', 'extraction', 'module', 'generally', 'use', 'melfrequency', 'cepstral', 'coefficient', 'mfcc', 'feature', 'popular', 'mfccs', 'linear', 'frequency', 'cepstral', 'coefficient', 'perceptual', 'predictive', 'also', 'use', 'feature', 'purpose', 'speech', 'activity', 'module', 'sad', 'also', 'know', 'voice', 'activity', 'module', 'detect', 'presence', 'speech', 'sad', 'vad', 'refer', 'vad', 'eliminate', 'audio', 'segment', 'contain', 'necessary', 'information', 'noise', 'music', 'thus', 'improve', 'performance', 'segmenting', 'cluster', 'module', 'several', 'different', 'algorithm', 'detector', 'vary', 'energy', 'level', 'detection', 'binary', 'classifier', 'base', 'pretraine', 'speech', 'model', 'research', 'use', 'custommade', 'vad', 'segment', 'audio', 'frame', 'show', 'later', 'chapter', 'next', 'module', 'follow', 'segmenter', 'speaker', 'change', 'detector', 'segmenter', 'detect', 'speaker', 'change', 'audio', 'create', 'frame', 'ideally', 'contain', 'speaker', 'necessary', 'step', 'cluster', 'grouping', 'cluster', 'previous', 'information', 'common', 'method', 'segmentation', 'measure', 'distance', 'segment', 'segment', 'belong', 'speaker', 'usually', 'close', 'distance', 'come', 'different', 'speaker', 'model', 'usually', 'ergodic', 'hide', 'markov', 'model', 'hmms', 'state', 'represent', 'speaker', 'probability', 'model', 'gaussian', 'mixture', 'model', 'gmms', 'bayesian', 'information', 'criterion', 'use', 'determine', 'near', 'cluster', 'merge', 'cluster', 'generate', 'high', 'bic', 'stop', 'process', 'value', 'bic', 'long', 'positive', 'introduce', 'define', 'parametric', 'gaussian', 'mixture', 'model', 'cluster', 'feature', '𝐵𝐼𝐶𝑀', 'log', 'ℒ', '𝜆', 'number', 'sample', 'number', 'parameter', 'model', '𝜆', 'tunable', 'parameter', 'final', 'clustering', 'step', 'group', 'together', 'segment', 'belong', 'speaker', 'speaker', 'diarization', 'identification', 'approach', 'cluster', 'achieve', 'agglomerative', 'hierarchical', 'clustering', 'ahc', 'use', 'distance', 'concept', 'segment', 'cluster', 'beginning', 'process', 'part', 'cluster', 'merge', 'stopping', 'criterion', 'meet', 'criterion', 'ideally', 'get', 'number', 'cluster', 'equal', 'number', 'speaker', 'practical', 'term', 'stopping', 'criterion', 'threshold', 'preset', 'beginning', 'process', 'deep', 'neural', 'network', 'application', 'deep', 'neural', 'network', 'dnn', 'speaker', 'diarization', 'gain', 'lot', 'momentum', 'recent', 'year', 'difficult', 'keep', 'pace', 'amount', 'research', 'almost', 'monthly', 'basis', 'field', 'therefore', 'importance', 'basic', 'understanding', 'dnn', 'apply', 'problem', 'speaker', 'diarization', 'general', 'term', 'dnn', 'speaker', 'diarizationidentification', 'method', 'divide', 'group', 'stagewise', 'end', 'end', 'online', 'multimodal', 'group', 'dissertation', 'address', 'stagewise', 'multimodal', 'group', 'relate', 'research', 'work', 'stagewise', 'diarization', 'stagewise', 'diarization', 'method', 'base', 'block', 'stage', 'gmm', 'method', 'cover', 'previous', 'section', 'rely', 'dnn', 'employ', 'universal', 'background', 'model', 'ubm', 'rather', 'gmms', 'feature', 'extraction', 'cluster', 'gmms', 'computationally', 'efficient', 'feature', 'extraction', 'sequence', 'feature', 'vector', 'convert', 'fixedlength', 'vector', 'supervector', 'approach', 'make', 'gmms', 'susceptible', 'speaker', 'channel', 'variation', 'utterance', 'desirable', 'reduce', 'dimensionality', 'supervector', 'lowerdimensional', 'vector', 'call', 'ivector', 'ivector', 'previously', 'reference', 'background', 'section', 'representation', 'ivector', 'assume', 'speaker', 'channeldependent', 'variability', 'reside', 'lowerdimensional', 'space', 'represent', 'total', 'variability', 'matrix', 'gmms', 'conversion', 'express', 'speaker', 'channel', 'supervector', 'ivector', 'fig', 'show', 'gmmivector', 'framework', 'figure', 'gmmivector', 'framework', 'point', 'effort', 'move', 'replace', 'gmm', 'generate', 'ivector', 'dnn', 'generate', 'ivector', 'idea', 'approach', 'replace', 'gmm', 'generate', 'posterior', 'feature', 'vector', 'take', 'dnn', 'train', 'acoustic', 'model', 'use', 'senone', 'generate', 'posterior', 'fig', 'represent', 'approach', 'figure', 'dnnivector', 'implementation', 'performance', 'dnn', 'base', 'acoustic', 'model', 'prove', 'require', 'large', 'set', 'training', 'datum', 'computational', 'cost', 'well', 'addition', 'ivector', 'dnn', 'approach', 'include', 'use', 'dvector', 'x', 'vector', 'embed', 'dvector', 'introduce', 'variani', 'base', 'assign', 'ground', 'truth', 'training', 'utterance', 'label', 'training', 'frame', 'corresponding', 'utterance', 'training', 'stage', 'convert', 'problem', 'classification', 'detailed', 'description', 'dvector', 'refer', 'xvector', 'derive', 'dvector', 'instead', 'use', 'framebyframe', 'speaker', 'label', 'use', 'utterancelevel', 'speaker', 'label', 'aggregation', 'refer', 'background', 'section', 'xvector', 'outperform', 'ivector', 'dvector', 'approach', 'refer', 'detail', 'xvector', 'deep', 'learn', 'clustering', 'technique', 'also', 'apply', 'replacement', 'conventional', 'distance', 'similarity', 'method', 'cluster', 'treat', 'supervised', 'unsupervised', 'problem', 'employ', 'recurrent', 'neural', 'network', 'rnn', 'discriminative', 'sequencetosequence', 'neural', 'network', 'reference', 'method', 'find', 'multimodal', 'speaker', 'diarization', 'relate', 'approach', 'exploit', 'video', 'clue', 'spatial', 'information', 'deep', 'learning', 'apply', 'analysis', 'visual', 'clue', 'movement', 'lip', 'also', 'content', 'speech', 'participant', 'sense', 'multimodal', 'method', 'train', 'network', 'base', 'pattern', 'likely', 'belong', 'genre', 'participant', 'example', 'collaborative', 'environment', 'student', 'facilitator', 'likely', 'calm', 'voice', 'contrast', 'student', 'recent', 'publication', 'kang', 'present', 'speaker', 'diarization', 'base', 'dvector', 'combine', 'spatial', 'information', 'provide', 'microphone', 'array', 'current', 'stateoftheart', 'method', 'diarization', 'identification', 'stateoftheart', 'method', 'cover', 'speaker', 'diarization', 'transcription', 'major', 'technology', 'player', 'offer', 'keep', 'technology', 'secret', 'compete', 'reliable', 'service', 'available', 'thus', 'difficulty', 'obtain', 'detailed', 'information', 'method', 'work', 'expect', 'somehow', 'use', 'speaker', 'diarization', 'approach', 'review', 'previous', 'section', 'amazon', 'offer', 'cloud', 'computing', 'include', 'speech', 'processing', 'service', 'base', 'algorithm', 'use', 'deep', 'learning', 'machine', 'learn', 'closedsource', 'cloud', 'service', 'provide', 'api', 'speechtotext', 'processing', 'speaker', 'diarization', 'dissertation', 'review', 'amazon', 'transcribe', 'aw', 'azure', 'speech', 'service', 'experimentally', 'compare', 'propose', 'system', 'amazon', 'transcribe', 'accept', 'audio', 'file', 'streaming', 'datum', 'singlechannel', 'output', 'text', 'file', 'speaker', 'diarization', 'option', 'select', 'number', 'speaker', 'specify', 'transcribe', 'work', 'well', 'speaker', 'languagedependent', 'limited', 'minute', 'audio', 'amazon', 'transcribe', 'store', 'voice', 'datum', 'train', 'model', 'user', 'select', 'option', 'delete', 'datum', 'amazon', 'offer', 'highly', 'train', 'set', 'model', 'call', 'amazon', 'transcribe', 'medical', 'aim', 'medical', 'transcription', 'user', 'also', 'customize', 'vocabulary', 'well', 'fit', 'need', 'amazon', 'functionality', 'access', 'rest', 'soap', 'protocol', 'work', 'similarly', 'interface', 'long', 'speech', 'singlechannel', 'input', 'transcription', 'purpose', 'optimum', 'number', 'speaker', 'set', 'maximum', 'amazon', 'transcribe', 'offer', 'option', 'privacy', 'prevent', 'datum', 'logging', 'use', 'improve', 'model', 'model', 'optimize', 'phone', 'conversation', 'video', 'accept', 'khz', 'khz', 'audio', 'respectively', 'depend', 'application', 'also', 'offer', 'vocabulary', 'customization', 'offer', 'good', 'scalability', 'infrastructure', 'payment', 'scheme', 'consider', 'good', 'technology', 'giant', 'offer', 'speaker', 'diarization', 'utilize', 'cognitive', 'service', 'system', 'rank', 'first', 'voxsrc', 'challenge', 'achieve', 'diarization', 'error', 'der', 'development', 'evaluation', 'testing', 'dataset', 'consist', 'audio', 'collect', 'youtube', 'recording', 'challenge', 'network', 'train', 'hour', 'simulated', 'mixed', 'training', 'audio', 'speaker', 'offer', 'textindependent', 'speaker', 'recognitionverification', 'speaker', 'need', 'enrol', 'create', 'signature', 'later', 'compare', 'audio', 'analyze', 'minimum', 'requirement', 'second', 'speech', 'training', 'second', 'speech', 'identification', 'unlimited', 'speaker', 'enrollment', 'speaker', 'present', 'case', 'diarization', 'recognize', 'speaker', 'transcription', 'require', 'diarization', 'signature', 'participate', 'speaker', 'identification', 'label', 'speech', 'segment', 'correspondent', 'speaker', 'collect', 'user', 'voice', 'track', 'train', 'model', 'user', 'customize', 'vocabulary', 'environment', 'expect', 'operate', 'mean', 'customization', 'include', 'noise', 'indoor', 'outdoor', 'environment', 'multi', 'gender', 'speech', 'chapter', 'propose', 'method', 'previous', 'chapter', 'discuss', 'principle', 'acoustic', 'speech', 'speaker', 'diarization', 'serve', 'foundation', 'research', 'chapter', 'cover', 'mathematical', 'model', 'use', 'estimate', 'virtual', 'microphone', 'implement', 'work', 'system', 'finally', 'present', 'block', 'diagram', 'detail', 'function', 'element', 'propose', 'system', 'operation', 'methodology', 'goal', 'dissertation', 'identification', 'speaker', 'singlechannel', 'recording', 'use', 'virtual', 'microphone', 'statement', 'include', 'objective', 'identify', 'speaker', 'datum', 'source', 'single', 'channel', 'recording', 'mean', 'accomplish', 'objective', 'use', 'virtual', 'microphone', 'section', 'begin', 'identify', 'physical', 'mathematical', 'element', 'model', 'need', 'virtual', 'microphone', 'simulation', 'let', 'consider', 'collaborative', 'environment', 'one', 'represent', 'fig', 'speaker', 'sit', 'table', 'central', 'recording', 'microphone', 'environment', 'represent', 'simple', 'model', 'show', 'fig', '17b', 'show', 'relative', 'location', 'speaker', 'recording', 'microphone', 'figure', 'collaborative', 'environment', 'model', 'b', 'capitalize', 'property', 'microphone', 'array', 'necessary', 'find', 'method', 'simulate', 'several', 'virtual', 'microphone', 'base', 'information', 'contain', 'signal', 'capture', 'central', 'microphone', 'discussion', 'microphone', 'arrays', 'chapter', 'possible', 'implement', 'several', 'different', 'virtual', 'array', 'configuration', 'let', 'consider', 'crosslinear', 'array', 'microphone', 'central', 'recording', 'microphone', 'show', 'fig', 'figure', 'model', 'fig', '12b', 'microphone', 'array', 'fig', 'ideal', 'representation', 'reflection', 'room', 'absorption', 'unique', 'active', 'speaker', 'set', 'pair', 'microphone', 'unique', 'correspond', 'active', 'speaker', 'example', 'speaker', 'active', 'tdoa', 'tdoa', 'unique', 'speaker', 'concept', 'mind', 'recall', 'chapter', 'cross', 'correlation', 'pair', 'microphone', 'represent', 'signal', 'delay', 'uniquely', 'identify', 'speaker', 'interested', 'location', 'peak', 'crosscorrelation', 'function', 'define', '𝑇cid3036cid3037', 'argmax', '𝑅cid3036cid3037𝑡', '𝑅cid3036cid3037𝑡', 'denote', 'crosscorrelation', 'microphone', 'signal', 'source', 'signal', 'propagate', 'microphone', '𝑖', '𝑇cid3036cid3037', 'represent', 'time', 'lag', 'take', 'signal', 'reach', '𝑗', 'reach', 'thus', '𝑇cid3036cid3037', 'imply', 'signal', 'arrive', 'microphone', '𝑗', 'hand', '𝑇cid3036cid3037', 'imply', 'signal', 'arrive', 'microphone', '𝑗', 'crosscorrelation', 'matrix', 'possible', 'value', '𝑇cid3036cid3037', 'use', 'determine', 'location', 'speaker', 'move', 'problem', 'simulate', 'virtual', 'microphone', 'equation', 'chapter', 'possible', 'extend', 'model', 'case', 'multiple', 'source', 'microphone', 'suppose', 'possible', 'source', '𝑠cid2869𝑡', 'possible', 'microphone', 'signal', '𝑥cid2869𝑡', '𝑥cid3015𝑡', 'next', 'let', 'ℎcid3037cid3038𝑡', 'denote', 'rir', 'describe', 'propagation', '𝑗th', 'source', '𝑘th', 'microphone', '𝑘th', 'microphone', 'receive', 'signal', 'source', 'express', 'cid3533', 'ℎcid3037cid3038𝑡', '𝑛𝑡', 'represent', 'additive', 'white', 'noise', 'model', 'need', 'estimate', 'ℎcid3037cid3038𝑡', 'ℎcid3037cid3038𝑡', 'know', 'possible', 'least', 'theory', 'estimate', 'signal', 'source', 'deconvolve', 'signal', 'ℎcid3037cid3038𝑡', 'cid2879cid2869𝑡', 'source', 'estimate', 'virtual', 'microphone', 'emulate', 'convolve', 'emulate', 'source', 'rir', 'virtual', 'microphone', 'important', 'factor', 'need', 'consider', 'develop', 'model', 'approach', 'first', 'exist', 'necessary', 'construct', 'virtual', 'microphone', 'approximation', 'ℎcid3037cid3038𝑡', 'second', 'speaker', 'feature', 'correlation', 'matrix', 'define', 'estimate', 'assumption', 'speaker', 'talk', 'speaker', 'remain', 'quiet', 'third', 'audio', 'segment', 'need', 'compute', 'cross', 'correlation', 'matrix', 'actual', 'signal', 'finally', 'need', 'estimate', 'active', 'speaker', 'solve', 'match𝑇', 'max', 'cid3040', 'match', 'function', 'similarity', 'turn', 'attention', 'estimate', 'rir', 'present', 'chapter', 'rir', 'function', 'geometry', 'room', 'relative', 'location', 'source', 'microphone', 'physics', 'room', 'absorption', 'room', 'characterize', 'reverberation', 'information', 'difficult', 'impossible', 'obtain', 'audio', 'recording', 'microphone', 'use', 'information', 'video', 'recording', 'estimate', 'parameter', 'need', 'calculate', 'rir', 'video', 'recording', 'possible', 'approximate', 'location', 'speaker', 'virtual', 'microphone', 'information', 'empirical', 'approximation', 'absorption', 'room', 'necessary', 'calculate', 'rir', 'calculate', 'rir', 'tedious', 'task', 'number', 'calculation', 'require', 'factor', 'degree', 'accuracy', 'desire', 'model', 'recall', 'concept', 'image', 'chapter', 'reception', 'microphone', 'result', 'sum', 'image', 'therefore', 'fidelity', 'depend', 'number', 'image', 'add', 'part', 'rir', 'function', 'next', 'chapter', 'present', 'opensource', 'software', 'package', 'perform', 'calculation', 'thus', 'save', 'programming', 'time', 'far', 'dissertation', 'present', 'fundamental', 'simulation', 'propose', 'method', 'base', 'use', 'approximate', 'geometry', 'room', 'calculate', 'rir', 'simulate', 'microphone', 'able', 'calculate', 'cross', 'correlation', 'microphone', 'determine', 'active', 'speaker', 'propose', 'method', 'summarize', 'step', 'evaluate', 'room', 'geometry', 'location', 'speaker', 'acoustic', 'scene', 'estimate', 'generic', 'rir', 'model', 'geometry', 'train', 'model', 'know', 'speaker', 'sample', 'estimation', 'source', 'fit', 'model', 'possible', 'active', 'speaker', 'give', 'unknown', 'audio', 'sample', 'conduct', 'crosscorrelation', 'analysis', 'classification', 'follow', 'section', 'explain', 'step', 'detail', 'evaluation', 'room', 'geometry', 'location', 'speaker', 'microphone', 'describe', 'rir', 'unique', 'transfer', 'function', 'point', 'space', 'calculate', 'rir', 'source', 'microphone', 'necessary', 'know', 'spatial', 'location', 'physical', 'room', 'know', 'acoustic', 'characteristic', 'fig', 'possible', 'appreciate', 'relative', 'location', 'speaker', 'recording', 'microphone', 'video', 'frame', 'use', 'reference', 'location', 'source', 'virtual', 'microphone', 'model', 'image', 'approximate', 'table', 'meter', 'long', 'meter', 'wide', 'speaker', 'separate', 'meter', 'speaker', 'mouth', 'table', 'also', 'possible', 'locate', 'reference', 'microphone', 'coordinate', 'relative', 'speaker', 'approximation', 'create', 'generic', 'model', 'calculate', 'rir', 'fig', 'show', 'possible', 'model', 'approximation', 'figure', 'possible', 'model', 'fig', 'location', 'separation', 'virtual', 'microphone', 'arbitrary', 'long', 'violate', 'rule', 'spatial', 'antialiasing', 'present', 'chapter', 'fundamental', 'frequency', 'human', 'speech', 'vary', 'hz', 'approximately', 'extreme', 'case', 'go', 'child', 'assume', 'max', 'frequency', 'average', 'hz', 'use', 'maximum', 'separation', '𝑑', 'microphone', 'cid2870cid2869cid2876cid2868', 'cid3009cid3053', 'estimation', 'generic', 'rir', 'model', 'approximation', 'geometry', 'room', 'provide', 'basis', 'implement', 'generic', 'model', 'calculate', 'set', 'rir', 'estimate', 'virtual', 'microphone', 'array', 'model', 'mention', 'base', 'approximate', 'geometry', 'room', 'location', 'speaker', 'number', 'reflection', 'desirable', 'reduce', 'influence', 'reflection', 'reverberation', 'simulation', 'add', 'complexity', 'rir', 'way', 'achieve', 'overall', 'reduction', 'length', 't60', 'recall', 'equation', 'minimize', 'volume', 'room', 'maximize', 'absorption', 'means', 'reduce', 'length', 't60', 'parameter', 'easy', 'control', 'implement', 'simulation', 'number', 'image', 'calculate', 'set', 'acceptable', 'value', 'compromise', 'simulation', 'fidelity', 'computational', 'burden', 'trial', 'error', 'necessary', 'optimize', 'number', 'reflection', 'point', 'consider', 'directionality', 'human', 'voice', 'human', 'voice', 'propagate', 'mostly', 'direction', 'front', 'head', 'therefore', 'model', 'take', 'propagation', 'inequality', 'simulate', 'audio', 'reception', 'point', 'room', 'solution', 'implement', 'research', 'consist', 'locate', 'speaker', 'close', 'end', 'virtual', 'room', 'reflection', 'back', 'speaker', 'minimize', 'approximate', 'physical', 'acoustical', 'characteristic', 'room', 'possible', 'calculate', 'rir', 'virtual', 'microphone', 'array', 'speaker', 'indicate', 'previous', 'section', 'possible', 'implement', 'arbitrary', 'array', 'microphone', 'long', 'follow', 'rule', 'spatial', 'antialiase', 'calculate', 'value', 'distance', 'well', 'fit', 'boundary', 'propose', 'model', 'beneficial', 'performance', 'model', 'optimize', 'microphone', 'array', 'maximum', 'crosscorrelation', 'information', 'accomplish', 'arrays', 'arrange', 'microphone', 'location', 'offset', 'equidistant', 'point', 'speaker', 'also', 'microphone', 'array', 'many', 'microphone', 'possible', 'long', 'required', 'computational', 'resource', 'remain', 'manageable', 'estimation', 'source', 'virtual', 'microphone', 'next', 'step', 'apply', 'generic', 'model', 'estimate', 'signal', 'virtual', 'microphone', 'array', 'base', 'recorded', 'signal', 'reference', 'microphone', 'necessary', 'first', 'estimate', 'source', 'fit', 'model', 'estimate', 'set', 'source', 'convolve', 'model', 'rir', 'represent', 'signal', 'microphone', 'array', 'include', 'reference', 'microphone', 'way', 'estimate', 'source', 'deconvolve', 'reference', 'signal', 'rir', 'correspond', 'source', 'want', 'estimate', 'example', 'assume', 'model', 'source', '𝑠cid2869𝑡', '𝑠cid2870𝑡', '𝑠cid2871𝑡', 'microphone', 'reference', 'microphone', '𝑥cid2871cid3037𝑡', 'signal', 'receive', 'respective', 'source', 'estimate', '𝑠cid2869𝑡', '𝑠cid2870𝑡', '𝑠cid2871𝑡', 'give', '𝑠̃cid2869𝑡', '𝑥cid2871cid2869𝑡', '∗', 'cid2879cid2869𝑡', '𝑥cid2871cid2870𝑡', '∗', 'ℎcid2871cid2870', 'cid2879cid2869𝑡', '𝑠̃cid2871𝑡', '𝑥cid2871cid2871𝑡', 'cid2879cid2869𝑡', 'cid2879cid2869𝑡', 'inverse', 'cid2879cid2869𝑡', 'inverse', 'cid2879cid2869𝑡', 'inverse', 'ℎcid2871cid2871𝑡', 'rir', 'fig', 'show', 'source', 'estimate', 'example', 'fig', 'model', 'fig', 'source', 'estimate', 'convolve', 'remain', 'rir', 'obtain', 'simulated', 'reception', 'microphone', 'array', 'fig', 'show', 'example', 'microphone', 'estimate', 'use', 'process', 'extensive', 'source', 'well', 'use', 'estimation', 'ground', 'truth', 'microphone', 'figure', 'estimation', 'source', 'figure', 'estimation', 'virtual', 'microphone', 'notice', 'point', 'solution', 'present', 'work', 'know', 'source', 'active', 'ℎcid2871cid3041𝑡', 'need', 'deconvolve', 'solve', 'problem', 'method', 'simulate', 'possible', 'source', 'deconvolve', 'signal', 'rir', 'model', 'simulate', 'signal', 'virtual', 'microphone', 'result', 'set', 'virtual', 'array', 'correspond', 'possible', 'active', 'source', 'source', 'example', '𝑥cid2871𝑡', 'define', 'unknown', 'signal', 'estimate', 'possible', 'source', '𝑠̃cid2870', 'obtain', 'deconvolve', '𝑥cid2871𝑡', 'ℎcid2871cid2871𝑡', '𝑠̃cid2869𝑡', '𝑥cid2871𝑡', '∗', 'cid2879cid2869𝑡', '𝑥cid2871𝑡', '∗', 'ℎcid2871cid2870', 'cid2879cid2869𝑡', '𝑠̃cid2871𝑡', '𝑥cid2871𝑡', '∗', 'cid2879cid2869𝑡', 'emulate', 'set', 'virtual', 'microphone', 'set', 'microphone', 'represent', 'index', 'virtual', 'set', 'b', 'index', 'virtual', 'microphone', 'set', 'rir', 'source', 'c', 'microphone', 'set', '𝑥cid2869cid2869𝑡', '𝑠̃cid2869𝑡', '∗', 'ℎcid2869cid2869𝑡', 'set', 'set', '𝑠̃cid2869𝑡', '∗', '𝑥cid2869cid2871𝑡', '𝑠̃cid2869𝑡', '∗', 'ℎcid2869cid2871𝑡', '𝑥cid2870cid2869𝑡', '∗', 'ℎcid2870cid2869𝑡', '∗', '𝑥cid2870cid2871𝑡', '∗', 'ℎcid2870cid2871𝑡', '𝑥cid2871cid2869𝑡', '𝑠̃cid2871𝑡', '∗', '𝑥cid2871cid2870𝑡', '𝑠̃cid2871𝑡', '∗', '𝑥cid2871cid2871𝑡', '𝑠̃cid2871𝑡', '∗', 'crosscorrelation', 'model', 'training', 'set', 'virtual', 'microphone', 'give', 'enough', 'information', 'cross', 'correlation', 'analysis', 'model', 'training', 'train', 'model', 'take', 'small', 'audio', 'sample', 'contain', 'active', 'source', 'see', 'fig', 'use', 'information', 'generate', 'crosscorrelation', 'table', 'contain', 'combination', 'possible', 'source', 'microphone', 'pair', 'source', 'training', 'include', 'background', 'noise', 'show', 'fig', 'training', 'model', 'noise', 'explain', 'later', 'implementation', 'section', 'table', 'template', 'classification', 'active', 'source', 'example', 'source', 'microphone', 'calculate', 'crosscorrelation', 'table', 'know', 'sample', 'process', 'filter', 's3', 'show', 'table', 'table', 'ii', 'table', 'iii', 'figure', 'training', 'sample', 'speaker', 'noise', 'table', 'template', 'crosscorrelation', 'table', 'source', 'r12', 'v1', '𝑠̃cid2869cid2870', 'r13', 'table', 'template', 'crosscorrelation', 'table', 'source', 'r12', 'v10', 'v13', 'v16', 'r13', 'v11', 'v12', 'table', 'iii', 'template', 'crosscorrelation', 'table', 'source', 'v19', 'v22', 'v25', 'r13', 'v20', 'r23', 'v21', 'v24', 'v27', 'value', 'crosscorrelation', 'correspond', 'microphone', 'm1m3', 'm2m3', 'respectively', 'know', 'sample', 'source', 'table', 'contain', 'result', 'sample', 'table', 'ii', 'sample', 'table', 'iii', 'sample', 'training', 'need', 'analysis', 'classification', 'crosscorrelation', 'analysis', 'audio', 'possible', 'divide', 'segment', 'proper', 'segmentation', 'audio', 'important', 'performance', 'propose', 'method', 'audio', 'collaborative', 'environment', 'contain', 'multiple', 'speaker', 'possible', 'time', 'simultaneous', 'active', 'speaker', 'also', 'possible', 'period', 'noise', 'period', 'silence', 'overlap', 'speech', 'speaker', 'finish', 'one', 'begin', 'speak', 'optimal', 'crosscorrelation', 'location', 'identification', 'segment', 'contain', 'active', 'speaker', 'time', 'audio', 'contain', 'overlap', 'speech', 'mix', 'speaker', 'location', 'peak', 'value', 'crosscorrelation', 'microphone', 'depend', 'amount', 'information', 'speaker', 'contain', 'audio', 'segment', 'make', 'classification', 'difficult', 'solution', 'maximize', 'probability', 'active', 'speaker', 'segment', 'minimize', 'length', 'short', 'segment', 'likely', 'content', 'speaker', 'however', 'limit', 'minimum', 'length', 'segment', 'minimum', 'length', 'segment', 'subject', 'performance', 'cross', 'correlation', 'mean', 'segment', 'need', 'long', 'enough', 'contain', 'sufficient', 'information', 'calculate', 'meaningful', 'crosscorrelation', 'addition', 'total', 'analysis', 'time', 'affect', 'number', 'segment', 'need', 'cross', 'correlate', 'analyze', 'hence', 'desire', 'reduce', 'number', 'segment', 'need', 'optimize', 'length', 'segment', 'balance', 'maximum', 'information', 'content', 'minimum', 'overlapping', 'speaker', 'recall', 'chapter', 'good', 'way', 'segment', 'audio', 'incorporate', 'vad', 'ideally', 'vad', 'detect', 'speech', 'content', 'change', 'speaker', 'base', 'certain', 'predetermine', 'energy', 'threshold', 'show', 'fig', 'energy', 'threshold', 'properly', 'adjust', 'vad', 'effective', 'produce', 'segment', 'audio', 'contain', 'speaker', 'time', 'segment', 'contain', 'mix', 'speaker', 'noise', 'maximize', 'information', 'content', 'vad', 'perfect', 'always', 'segment', 'contain', 'overlap', 'mix', 'speaker', 'simply', 'misclassifie', 'minimize', 'number', 'misclassification', 'length', 'segment', 'limit', 'maximum', 'provide', 'acceptable', 'number', 'misclassification', 'find', 'research', 'segment', 'long', 'prone', 'misclassification', 'segment', 'less', 'ms', 'difficult', 'crosscorrelate', 'figure', 'audio', 'segmentation', 'use', 'vad', 'audio', 'segment', 'generate', 'single', 'crosscorrelation', 'table', 'correspond', 'possible', 'location', 'speaker', 'train', 'classifier', 'use', 'crosscorrelation', 'template', 'table', 'training', 'compare', 'analysis', 'result', 'determine', 'probable', 'source', 'match', 'alternatively', 'possible', 'cluster', 'crosscorrelation', 'result', 'later', 'classification', 'chapter', 'cover', 'analysis', 'classification', 'method', 'research', 'detail', 'block', 'diagram', 'propose', 'system', 'fig', 'present', 'block', 'diagram', 'propose', 'method', 'chapter', 'cover', 'experimental', 'implementation', 'module', 'diagram', 'clustering', 'module', 'implement', 'research', 'figure', 'block', 'diagram', 'propose', 'system', 'propose', 'system', 'divide', 'subsystem', 'describe', 'room', 'geometry', 'rir', 'generator', 'first', 'subsystem', 'block', 'diagram', 'room', 'geometry', 'generator', 'rgrg', 'subsystem', 'accept', 'room', 'geometry', 'parameter', 'geometry', 'room', 'absorption', 'location', 'speaker', 'microphone', 'calculate', 'rir', 'use', 'synthetic', 'speech', 'source', 'rgrg', 'consist', 'module', 'room', 'parameter', 'generator', 'room', 'model', 'generator', 'room', 'parameter', 'generator', 'create', 'vector', 'contain', 'geometry', 'room', 'location', 'speaker', 'microphone', 'virtual', 'real', 'room', 'model', 'generator', 'get', 'room', 'geometry', 'vector', 'calculate', 'rir', 'source', 'microphone', 'audio', 'preprocessor', 'second', 'subsystem', 'preprocessor', 'function', 'app', 'prepare', 'singlechannel', 'raw', 'audio', 'analysis', 'consist', 'module', 'training', 'sample', 'audio', 'c', 'segmenter', 'training', 'sample', 'audio', 'module', 'contain', 'training', 'sample', 'speaker', 'participate', 'audio', 'analyze', 'sample', 'ambient', 'noise', 'sample', 'save', 'wav', 'file', 'label', 'independently', 'segmenter', 'module', 'use', 'vad', 'create', 'segment', 'audio', 'analyze', 'segment', 'audio', 'save', 'wav', 'file', 'variable', 'duration', 'minimum', 'maximum', 'length', 'threshold', 'segment', 'less', 'predetermine', 'length', 'discard', 'analysis', 'subsystem', 'function', 'analysis', 'subsystem', 'calculate', 'crosscorrelation', 'emulate', 'microphone', 'consist', 'module', 'source', 'estimator', 'e', 'room', 'model', 'estimator', 'crosscorrelator', 'source', 'estimator', 'get', 'audio', 'app', 'deconvolve', 'rir', 'rgrg', 'estimate', 'possible', 'source', 'deconvolution', 'audio', 'training', 'sample', 'segment', 'analysis', 'room', 'model', 'estimator', 'emulate', 'microphone', 'convolve', 'estimate', 'source', 'corresponding', 'rir', 'calculate', 'use', 'model', 'room', 'geometry', 'training', 'sample', 'analysis', 'segment', 'finally', 'crosscorrelator', 'module', 'calculate', 'cross', 'correlation', 'microphone', 'possible', 'source', 'combination', 'training', 'testing', 'classifier', 'output', 'subsystem', 'handle', 'classifier', 'classifier', 'create', 'crosscorrelation', 'set', 'table', 'training', 'testing', 'training', 'table', 'create', 'training', 'audio', 'sample', 'testing', 'cross', 'correlation', 'table', 'possible', 'source', 'segment', 'describe', 'section', 'possible', 'path', 'action', 'crosscorrelation', 'table', 'available', 'path', 'run', 'cluster', 'algorithm', 'group', 'segment', 'similar', 'cluster', 'run', 'classifier', 'select', 'good', 'source', 'match', 'training', 'cross', 'correlation', 'table', 'research', 'follow', 'classifier', 'option', 'discuss', 'next', 'section', 'final', 'component', 'classifier', 'subsystem', 'speaker', 'metric', 'module', 'function', 'module', 'calculate', 'statistic', 'participant', 'eg', 'long', 'active', 'active', 'research', 'metric', 'focus', 'measure', 'total', 'time', 'participant', 'active', 'chapter', 'experimental', 'implementation', 'chapter', 'present', 'software', 'hardware', 'implementation', 'propose', 'method', 'present', 'chapter', 'begin', 'present', 'software', 'tool', 'simulation', 'deconvolution', 'datum', 'handling', 'continue', 'software', 'implementation', 'base', 'aolme', 'environment', 'implementation', 'use', 'experiment', 'chapter', 'evaluate', 'performance', 'propose', 'method', 'software', 'hardware', 'tool', 'block', 'show', 'need', 'develop', 'several', 'software', 'module', 'simulate', 'acoustic', 'characteristic', 'room', 'include', 'rir', 'source', 'image', 'calculation', 'deconvolution', 'source', 'estimation', 'crosscorrelation', 'classification', 'summary', 'necessary', 'code', 'perform', 'follow', 'operation', 'simulation', 'geometry', 'room', 'calculation', 'rir', 'base', 'geometry', 'room', 'extraction', 'audio', 'track', 'video', 'recording', 'segmentation', 'audio', 'recording', 'deconvolution', 'audio', 'source', 'simulation', 'simulation', 'microphone', 'array', 'microphone', 'crosscorrelation', 'calculation', 'analysis', 'microphone', 'crosscorrelation', 'identify', 'active', 'speaker', 'calculation', 'metric', 'participate', 'speaker', 'develop', 'code', 'module', 'timeconsuming', 'task', 'large', 'number', 'mathematical', 'algorithm', 'calculation', 'need', 'fortunately', 'software', 'package', 'available', 'code', 'library', 'simplify', 'implementation', 'module', 'software', 'framework', 'experimental', 'analysis', 'dissertation', 'combine', 'opensource', 'code', 'commercial', 'software', 'save', 'considerable', 'amount', 'time', 'alternative', 'write', 'code', 'scratch', 'opensource', 'code', 'room', 'geometry', 'rir', 'calculation', 'microphone', 'simulation', 'opensource', 'community', 'code', 'developer', 'offer', 'extensive', 'variety', 'software', 'library', 'cover', 'wide', 'range', 'topic', 'machine', 'learning', 'financial', 'market', 'analysis', 'include', 'acoustic', 'simulation', 'several', 'acoustic', 'simulation', 'package', 'available', 'github', 'download', 'package', 'mainly', 'design', 'simulate', 'acoustic', 'environment', 'perform', 'art', 'theater', 'stadium', 'record', 'studio', 'available', 'package', 'pyroomacoustic', 'select', 'rir', 'calculation', 'microphone', 'simulation', 'pyroomacoustic', 'opensource', 'acoustic', 'simulation', 'package', 'calculate', 'rir', 'simulate', 'reception', 'audio', 'set', 'virtual', 'microphone', 'locate', 'virtual', 'room', 'pyroomacoustic', 'use', 'image', 'source', 'method', 'ism', 'calculate', 'rir', 'source', 'point', 'virtual', 'room', 'location', 'image', 'visualize', '3d', 'representation', 'geometry', 'virtual', 'room', 'location', 'source', 'virtual', 'microphone', 'simulate', 'location', 'image', 'pyroomacoustic', 'calculate', 'rir', 'target', 'microphone', 'convolve', 'sample', 'audio', 'simulate', 'reception', 'microphone', 'pyroomacoustic', 'library', 'input', 'geometry', 'room', 'location', 'source', 'location', 'virtual', 'microphone', 'absorption', 'room', 'sample', 'frequency', 'number', 'image', 'calculate', 'output', 'library', 'include', 'set', 'array', 'contain', 'rir', 'microphone', 'emulated', 'reception', 'microphone', 'fig', '25a', '25b', 'show', 'example', '3d', 'visualization', 'pyroomacoustic', 'nonrectangular', 'room', 'meter', 'circular', 'microphone', 'array', 'microphone', 'source', 'fig', '25c', 'show', 'room', 'simulated', 'image', 'type', 'representation', 'use', 'approximate', 'aolme', 'model', 'discuss', 'later', 'complete', 'documentation', 'pyroomacoustic', 'function', 'code', 'find', 'figure', 'pyroomacoustic', 'model', 'b', 'c', 'image', 'version', 'pyroomacoustic', 'use', 'research', 'limitation', 'need', 'consider', 'develop', 'model', 'microphone', 'source', 'always', 'model', 'omnidirectional', 'option', 'add', 'unidirectional', 'source', 'type', 'microphone', 'cardioid', 'room', 'square', 'round', 'corner', 'option', 'add', 'object', 'table', 'room', 'absorption', 'empirical', 'parameter', 'need', 'estimate', 'mean', 'software', 'experiment', 'research', 'conduct', 'use', 'version', 'room', 'geometry', 'calculation', 'pyroomacoustic', 'library', 'call', 'jupyter', 'notebook', 'library', 'also', 'call', 'labview', 'use', 'script', 'pyroomacoustic', 'implementation', 'implementation', 'pyroomacoustic', 'virtual', 'microphone', 'simulation', 'accomplish', 'step', 'include', 'simulation', 'room', 'placement', 'source', 'microphone', 'calculation', 'rir', 'source', 'microphone', 'convolution', 'source', 'rir', 'microphone', 'simulation', 'call', 'class', 'pyroomacoustic', 'library', 'follow', 'room', 'simulation', 'room', 'simulation', 'contain', 'parameter', 'room', 'dimension', 'absorption', 'number', 'image', 'calculate', 'sample', 'frequency', 'example', 'following', 'script', 'generate', 'room', 'dimension', 'meter', 'total', 'image', 'sample', 'frequency', 'maxorder9', 'b', 'source', 'microphone', 'placement', 'script', 'add', 'source', 'microphone', 'model', 'pyroomacoustic', 'need', 'valid', 'audio', 'file', 'source', 'location', 'following', 'script', 'locate', 'source', 'origin', 'microphone', 'microphone', 'microphone', 'roomaddsource20', 'signalaudio', 'miclocs', 'mic', 'mic', 'roomaddmicrophonearraymicloc', 'c', 'rir', 'calculation', 'call', 'roomcomputerir', 'rir', 'calculate', 'microphone', 'result', 'save', 'form', 'list', 'list', 'rir', 'attribute', 'room', 'microphone', 'simulation', 'final', 'microphone', 'simulation', 'obtain', 'call', 'simulate', 'convolve', 'source', 'rir', 'emulate', 'signal', 'microphone', 'result', 'convolution', 'store', 'signal', 'attribute', 'roommicarray', 'include', 'script', 'use', 'actual', 'experimental', 'implementation', 'pyroomacoustic', 'refer', 'pyroomacoustic', 'documentation', 'find', 'full', 'description', 'library', 'algorithm', 'audio', 'segmentation', 'recall', 'previous', 'discussion', 'practical', 'analysis', 'long', 'audio', 'recording', 'possible', 'segment', 'small', 'frame', 'audio', 'segmentation', 'play', 'critical', 'role', 'overall', 'performance', 'propose', 'method', 'therefore', 'careful', 'consideration', 'make', 'algorithm', 'audio', 'segmentation', 'previously', 'indicate', 'audio', 'segment', 'need', 'comply', 'main', 'requirement', 'contain', 'audio', 'active', 'speaker', 'minimum', 'overlapping', 'mix', 'speaker', 'length', 'provide', 'enough', 'signal', 'information', 'cross', 'correlation', 'analysis', 'requirement', 'difficult', 'achieve', 'chapter', 'introduce', 'concept', 'vad', 'segmentation', 'method', 'maximize', 'information', 'content', 'single', 'speaker', 'segmentation', 'method', 'consider', 'research', 'fix', 'segmentation', 'voice', 'activity', 'detection', 'end', 'opt', 'vad', 'well', 'performance', 'result', 'fix', 'length', 'segmentation', 'simple', 'way', 'segment', 'audio', 'divide', 'fixedlength', 'segment', 'fix', 'length', 'segmentation', 'relatively', 'simple', 'computationally', 'inexpensive', 'method', 'audio', 'segment', 'length', 'independently', 'content', 'intelligence', 'method', 'probability', 'segment', 'contain', 'overlap', 'speech', 'also', 'unlikely', 'audio', 'divide', 'exactly', 'equal', 'part', 'make', 'last', 'segment', 'short', 'duration', 'solution', 'minimize', 'overlap', 'make', 'segment', 'short', 'possible', 'discuss', 'segment', 'short', 'contain', 'enough', 'information', 'calculate', 'crosscorrelation', 'therefore', 'balance', 'optimum', 'length', 'segment', 'desire', 'classification', 'error', 'empirical', 'way', 'find', 'length', 'segment', 'assess', 'audio', 'audio', 'contain', 'wellseparated', 'speaker', 'little', 'overlap', 'length', 'segment', 'long', 'acoustic', 'scene', 'noise', 'disorganize', 'speech', 'research', 'conduct', 'experiment', 'segment', 'length', 'vary', 'ms', 'obtain', 'different', 'degree', 'success', 'end', 'fixedlength', 'segmentation', 'abandon', 'undesirable', 'number', 'error', 'low', 'performance', 'compare', 'voice', 'activity', 'detection', 'segmentation', 'voice', 'activity', 'detection', 'vad', 'use', 'experiment', 'program', 'use', 'fellow', 'graduate', 'student', 'use', 'fast', 'fouri', 'transform', 'fft', 'inverse', 'fast', 'fouri', 'transform', 'ifft', 'function', 'convert', 'audio', 'time', 'domain', 'frequency', 'domain', 'vice', 'versa', 'first', 'audio', 'convert', 'frequency', 'domain', 'apply', 'fft', 'low', 'pass', 'filter', 'high', 'pass', 'filter', 'apply', 'remove', 'noise', 'filter', 'audio', 'bring', 'back', 'time', 'domain', 'use', 'ifft', 'normalize', 'afterward', 'amplitude', 'trigger', 'threshold', 'use', 'determine', 'presence', 'speech', 'noise', 'amplitude', 'exceed', 'time', 'beginning', 'speech', 'time', 'mark', 'level', 'check', 'ms', 'exceed', 'mark', 'time', 'check', 'ms', 'audio', 'exceed', 'mark', 'end', 'audio', 'time', 'ms', 'otherwise', 'end', 'audio', 'audio', 'exceed', 'time', 'range', 'speech', 'classify', 'noise', 'use', 'information', 'obtain', 'filter', 'audio', 'add', 'time', 'offset', 'ms', 'compensate', 'information', 'miss', 'filter', 'audio', 'split', 'audio', 'give', 'maximum', 'minimum', 'time', 'noise', 'segment', 'small', 'ms', 'combine', 'audio', 'segment', 'pause', 'person', 'speak', 'noise', 'audio', 'long', 'split', 'batch', 'maximum', 'time', 'small', 'exception', 'go', 'important', 'notice', 'audio', 'segmentation', 'produce', 'artifact', 'beginning', 'end', 'segment', 'artifact', 'familiar', 'click', 'hear', 'listen', 'sequence', 'segment', 'audio', 'processing', 'common', 'practice', 'apply', 'window', 'filter', 'overlap', 'segment', 'allow', 'smooth', 'transition', 'method', 'apply', 'windowe', 'overlap', 'possibility', 'alter', 'spatial', 'content', 'segment', 'therefore', 'well', 'accept', 'reasonable', 'error', 'instead', 'implementation', 'use', 'labview', 'graphical', 'programming', 'research', 'work', 'use', 'labview', 'deconvolution', 'array', 'manipulation', 'classification', 'metric', 'user', 'interface', 'labview', 'popular', 'engineering', 'wide', 'variety', 'builtin', 'function', 'simplicity', 'create', 'graphical', 'user', 'interface', 'opensource', 'language', 'require', 'purchasing', 'license', 'labview', 'require', 'additional', 'toolkit', 'advanced', 'digital', 'signal', 'processing', 'statistic', 'software', 'integration', 'research', 'apply', 'advanced', 'signal', 'processing', 'toolkit', 'crosscorrelation', 'analysis', 'convolution', 'deconvolution', 'calculation', 'pyroomacoustic', 'use', 'room', 'simulation', 'necessary', 'install', 'python', 'integration', 'toolkit', 'provide', 'enthought', 'toolkit', 'provide', 'labview', 'capability', 'call', 'code', 'directly', 'labview', 'use', 'wrapper', 'call', 'library', 'labview', 'way', 'labview', 'provide', 'user', 'interface', 'pyroomacoustic', 'input', 'room', 'geometry', 'number', 'image', 'audio', 'file', 'process', 'output', 'rir', 'microphone', 'simulation', 'save', 'datum', 'display', 'result', 'document', 'detailed', 'description', 'labview', 'find', 'website', 'instead', 'scripting', 'code', 'labview', 'use', 'graphical', 'interface', 'contain', 'functional', 'module', 'call', 'short', 'virtual', 'instrument', 'perform', 'basic', 'function', 'add', 'subtract', 'array', 'manipulation', 'logical', 'operation', 'advanced', 'calculate', 'complex', 'operation', 'convolution', 'inverse', 'convolution', 'correlation', 'crosscorrelation', 'file', 'manipulation', 'example', 'vi', 'transfer', 'datum', 'use', 'wired', 'connection', 'mechanism', 'handle', 'display', 'execution', 'error', 'fig', '26a', 'fig', '26b', 'show', 'screenshot', 'internal', 'block', 'diagram', 'user', 'interface', 'respectively', 'labview', 'implementation', 'use', 'research', 'convolution', 'deconvolution', 'correlation', 'crosscorrelation', 'operation', 'file', 'user', 'select', 'operation', 'use', 'dropdown', 'selector', 'implementation', 'read', 'text', 'file', 'correspond', 'audio', 'file', 'analyze', 'convolve', 'third', 'file', 'correspond', 'rir', 'convolution', 'operation', 'graphic', 'represent', 'input', 'file', 'rir', 'output', 'crosscorrelation', 'calculation', 'result', 'save', 'text', 'file', 'later', 'conversion', 'audio', 'format', 'figure', 'labview', 'sub', 'vi', 'crosscorrelation', 'calculation', 'popularity', 'labview', 'engineering', 'community', 'labview', 'many', 'time', 'regard', 'hardcore', 'coder', 'language', 'know', 'code', 'major', 'deficiency', 'lie', 'fact', 'builtin', 'function', 'rarely', 'modifiable', 'block', 'diagram', 'get', 'confusing', 'divide', 'small', 'difficult', 'document', 'comment', 'decision', 'use', 'labview', 'timesaving', 'advantage', 'script', 'language', 'labview', 'implementation', 'code', 'write', 'research', 'use', 'several', 'builtin', 'available', 'labview', 'version', 'bit', 'implement', 'complex', 'subvis', 'run', 'calculation', 'datum', 'handle', 'user', 'interface', 'file', 'manipulation', 'display', 'result', 'code', 'require', 'use', 'dozen', 'different', 'simple', 'mathematical', 'operation', 'data', 'flow', 'important', 'calculation', 'convolution', 'deconvolution', 'handle', 'labview', 'builtin', 'function', 'function', 'function', 'section', 'use', 'calculate', 'convolution', 'deconvolution', 'crosscorrelation', 'part', 'signal', 'process', 'algorithm', 'function', 'explain', 'next', 'convolution', 'vi', 'compute', 'convolution', 'vector', 'convolution', 'compute', 'select', 'direct', 'method', 'frequency', 'domain', 'use', 'fft', 'latter', 'one', 'use', 'research', 'vi', 'represent', 'convolution', 'show', 'fig', 'documentation', 'vi', 'find', 'figure', 'labview', 'convolution', 'work', 'pad', 'end', 'zero', 'make', 'length', 'show', '𝑥′𝑖', '−', '𝑦′𝑖', '−', '−', 'convolution', 'compute', 'calculate', 'inverse', 'fft', 'product', 'fft', '∗', '𝒚', '𝐼𝐹𝐹𝑇cid3435𝒙cid4593𝑓', 'ifft', 'inverse', 'fft', 'deconvolution', 'deconvolution', 'vi', 'compute', 'inverse', 'convolution', 'vector', 'return', 'value', 'vector', 'fig', 'show', 'symbol', 'vi', 'documentation', 'vi', 'find', 'figure', 'labview', 'deconvolution', 'vi', 'implement', 'deconvolution', 'compute', 'fouri', 'transform', 'input', 'divide', 'create', 'new', 'vector', 'h', 'vector', 'compute', 'apply', 'ifft', 'sequence', 'h', 'correlation', 'correlation', 'vi', 'calculate', 'correlation', 'coefficient', 'r', 'vector', 'fig', 'show', 'icon', 'vi', 'documentation', 'vi', 'find', 'figure', 'labview', 'correlation', 'vi', 'calculate', 'linear', 'correlation', 'coefficient', 'also', 'know', 'correlation', 'eq', 'number', '𝑧𝑥and', '𝑧𝑦are', 'standardized', 'zvalue', 'standardized', 'zvalue', 'indicate', 'many', 'standard', 'deviation', 'mean', 'crosscorrelation', 'crosscorrelation', 'compute', 'crosscorrelation', 'vector', 'input', 'vi', 'vector', '𝒙𝒕', 'weighting', 'specifie', 'use', 'biased', 'unbiased', 'weighting', 'crosscorrelation', 'calculation', 'former', 'one', 'use', 'calculation', 'maximum', 'lag', 'specify', 'maximum', 'value', 'lag', 'vi', 'use', 'compute', 'crosscorrelation', 'maximum', 'lag', 'use', 'max', 'length', '𝒙𝒕', '𝒚𝒕', 'respectively', 'fig', 'show', 'icon', 'vi', 'documentation', 'vi', 'find', 'figure', 'labview', 'crosscorrelation', 'vi', 'compute', 'crosscorrelation', 'value', 'univariate', 'time', 'series', '𝒀𝒕', 'accord', 'follow', 'equation', '𝑟𝑥𝑦𝑘', '𝑎', '∙', '𝑏', '∙', 'cid3533', '−', '𝑁', 'cid3493∑', 'cid3050cid2879cid2869', 'cid3041cid2880cid2868', 'cid2870𝑛', 'cid3014cid2879cid2869', 'cid3041cid2880cid2868', 'cid2870𝑛', 'length', 'n', 'length', 'length', 'output', 'weighting', 'factor', 'case', 'operational', 'section', 'cover', 'subvis', 'form', 'core', 'code', 'perform', 'computation', 'need', 'analysis', 'subvis', 'contain', 'function', 'cover', 'previous', 'section', 'b', 'contain', 'front', 'panel', 'block', 'diagram', 'subvis', 'room', 'parameter', 'reader', 'room', 'parameter', 'reader', 'subvi', 'read', 'source', 'location', 'microphone', 'location', 'room', 'dimension', 'file', 'create', 'room', 'geometry', 'generator', 'format', 'room', 'model', 'generator', 'subvi', 'room', 'absorption', 'room', 'extrusion', 'number', 'image', 'calculate', 'pass', 'b', 'section', 'show', 'front', 'panel', 'block', 'diagram', 'subvi', 'room', 'model', 'generator', 'room', 'model', 'generator', 'subvi', 'read', 'room', 'geometry', 'parameter', 'format', 'room', 'parameter', 'reader', 'subvi', 'run', 'script', 'call', 'pyroomacoustic', 'library', 'compute', 'rir', 'room', 'model', 'subvi', 'also', 'read', 'synthetic', 'speech', 'noise', 'wav', 'file', 'use', 'pyroomacoustic', 'rir', 'calculation', 'calculate', 'rir', 'save', 'txt', 'file', 'later', 'retrieval', 'source', 'estimator', 'subvi', 'room', 'model', 'generator', 'use', 'twice', 'first', 'calculate', 'room', 'model', 'rir', 'source', 'estimation', 'emulate', 'virtual', 'microphone', 'use', 'estimate', 'source', 'section', 'b', 'section', 'b', 'show', 'front', 'panel', 'block', 'diagram', 'input', 'output', 'detail', 'source', 'estimator', 'source', 'estimator', 'take', 'model', 'rir', 'estimate', 'source', 'correspond', 'audio', 'segment', 'analyze', 'estimation', 'subvi', 'take', 'segment', 'audio', 'analysis', 'correspond', 'real', 'recording', 'microphone', 'deconvolve', 'rir', 'source', 'location', 'emulate', 'source', 'save', 'txt', 'file', 'virtual', 'microphone', 'simulation', 'use', 'instance', 'room', 'model', 'generator', 'section', 'show', 'detail', 'subvi', 'simplified', 'block', 'diagram', 'crosscorrelation', 'model', 'calculator', 'subvi', 'take', 'result', 'virtual', 'microphone', 'simulation', 'second', 'run', 'room', 'model', 'generator', 'calculate', 'crosscorrelation', 'virtual', 'microphone', 'result', 'save', 'crosscorrelation', 'table', 'use', 'training', 'classification', 'appendix', 'b', 'section', 'show', 'detail', 'subvi', 'output', 'subvi', 'table', 'contain', 'possible', 'crosscorrelation', 'microphone', 'possible', 'source', 'speaker', 'microphone', 'example', 'crosscorrelation', 'table', 'look', 'one', 'represent', 'table', 'iv', 'first', 'row', 'crosscorrelation', 'microphone', 'combination', 'first', 'column', 'speaker', 'number', 'represent', 'array', 'index', 'max', 'occur', 'table', 'iv', 'example', 'crosscorrelation', 'table', 'output', 'model', 'calculator', 'model', 'classifier', 'model', 'classifier', 'subvi', 'take', 'correlation', 'table', 'training', 'testing', 'perform', 'classification', 'compare', 'testing', 'result', 'training', 'template', 'simple', 'classifier', 'work', 'compare', 'table', 'good', 'similarity', 'example', 'assume', 'table', 'iv', 'correspond', 'training', 'speaker', 's1', 'analysis', 'unknown', 'audio', 'segment', 'produce', 'table', 'show', 'table', 'c', 'classifier', 'simply', 'count', 'number', 'match', 'table', 'training', 'cc', 'table', 'example', 'table', 'great', 'number', 'match', 'indicate', 'unknown', 'segment', 'correspond', 'speaker', 'b', 'section', 'e', 'show', 'icon', 'front', 'panel', 'table', 'crosscorrelation', 'table', 'classification', 'total', 'match', 'total', 'total', 'c', 'match', 'match', 'multifunction', 'convolution', 'correlator', 'visualizer', 'multifunction', 'convolution', 'correlator', 'visualizer', 'full', 'standalone', 'subvi', 'use', 'manually', 'convolve', 'deconvolve', 'audio', 'file', 'correlation', 'crosscorrelation', 'analysis', 'file', 'b', 'section', 'provide', 'information', 'subvi', 'audio', 'laboratory', 'purpose', 'audio', 'laboratory', 'capture', 'real', 'audio', 'control', 'environment', 'laboratory', 'allow', 'conduct', 'experiment', 'know', 'position', 'speaker', 'microphone', 'control', 'content', 'duration', 'characteristic', 'analyze', 'speech', 'result', 'experiment', 'perform', 'audio', 'lab', 'compare', 'result', 'obtain', 'propose', 'method', 'simulation', 'software', 'audio', 'laboratory', 'consist', 'set', 'microphone', 'audio', 'processing', 'device', 'audio', 'amplifier', 'loudspeaker', 'computer', 'run', 'software', 'capture', 'recording', 'audio', 'laboratory', 'physically', 'configure', 'follow', 'common', 'acoustic', 'scene', 'find', 'video', 'analyze', 'research', 'configuration', 'use', 'set', 'loudspeaker', 'locate', 'approximated', 'position', 'speaker', 'sit', 'table', 'set', 'microphone', 'capture', 'audio', 'different', 'location', 'lab', 'microphone', 'locate', 'relative', 'position', 'recording', 'microphone', 'video', 'fig', 'show', 'block', 'diagram', 'lab', 'component', 'set', 'microphone', 'type', 'use', 'recording', 'video', 'microphone', 'connect', 'tascam', 'processor', 'processor', 'capture', 'simultaneous', 'audio', 'microphone', 'send', 'digitally', 'computer', 'computer', 'process', 'audio', 'use', 'tracktion', 'waveform', 'audio', 'processing', 'software', 'software', 'process', 'audio', 'microphone', 'save', 'separate', 'wav', 'file', 'correspond', 'microphone', 'figure', 'audio', 'lab', 'component', 'simulation', 'speaker', 'accomplish', 'use', 'set', 'loudspeaker', 'connect', 'stereo', 'audio', 'amplifier', 'speaker', 'simulate', 'left', 'stereo', 'channel', 'speaker', 'simulate', 'right', 'stereo', 'channel', 'switch', 'allow', 'select', 'loudspeaker', 'lab', 'also', 'include', 'compact', 'disk', 'cd', 'player', 'locate', 'certain', 'distance', 'table', 'cd', 'player', 'use', 'inject', 'background', 'noise', 'experiment', 'fig', 'show', 'actual', 'audio', 'laboratory', 'setup', 'appreciate', 'location', 'component', 'figure', 'audio', 'lab', 'setup', 'aolme', 'environment', 'dissertation', 'focus', 'analysis', 'audio', 'video', 'assess', 'level', 'engagement', 'participant', 'aolme', 'environment', 'characterize', 'presence', 'background', 'noise', 'crosstalk', 'interference', 'make', 'challenge', 'speaker', 'identification', 'task', 'therefore', 'improve', 'identification', 'rate', 'simulation', 'model', 'optimize', 'fit', 'environment', 'section', 'study', 'aolme', 'environment', 'find', 'well', 'adapt', 'model', 'acoustic', 'characteristic', 'environment', 'implement', 'model', 'experimental', 'section', 'characteristic', 'environment', 'fig', 'show', 'screen', 'capture', 'aolme', 'video', 'analyze', 'research', 'scene', 'show', 'typical', 'collaboration', 'table', 'student', 'instructor', 'common', 'table', 'participant', 'distribute', 'room', 'approximated', 'dimension', 'camera', 'record', 'audio', 'single', 'omnidirectional', 'microphone', 'rest', 'top', 'table', 'addition', 'normal', 'room', 'noise', 'environment', 'present', 'element', 'make', 'dynamic', 'complex', 'example', 'typical', 'participant', 'shuffle', 'paper', 'lean', 'table', 'eat', 'speak', 'simultaneously', 'accidentally', 'cover', 'microphone', 'book', 'utensil', 'furthermore', 'occasion', 'staff', 'member', 'walk', 'join', 'group', 'conversation', 'figure', 'common', 'aolme', 'environment', 'setup', 'first', 'step', 'build', 'model', 'approximate', 'location', 'speaker', 'recording', 'microphone', 'analyze', 'scene', 'fig', 'possible', 'get', 'clue', 'use', 'approximate', 'location', 'fig', 'possible', 'estimate', 'relative', 'location', 'speaker', 'respect', 'recording', 'microphone', 'noticeable', 'also', 'position', 'speaker', 'form', 'rectangle', 'translate', 'figure', 'bottom', 'area', 'table', 'height', 'define', 'tall', 'speaker', 'second', 'step', 'approximate', 'geometry', 'room', 'fig', 'possible', 'recognize', 'nearby', 'wall', 'speaker', 'second', 'wall', 'locate', 'speaker', 'farth', 'distance', 'speaker', 'first', 'wall', 'locate', 'speaker', 'indication', 'wall', 'presence', 'celling', 'assume', 'exist', 'also', 'assume', 'table', 'nearby', 'see', 'fig', 'preparation', 'experimental', 'model', 'mention', 'early', 'model', 'base', 'part', 'geometry', 'room', 'location', 'speaker', 'exact', 'information', 'available', 'model', 'need', 'approximation', 'base', 'observation', 'make', 'video', 'shot', 'also', 'recall', 'section', 'version', 'pyroomacoustics', 'allow', 'simulate', 'complex', 'environment', 'one', 'show', 'fig', 'participant', 'sit', 'table', 'fortunately', 'model', 'need', 'perfect', 'make', 'assumption', 'reduce', 'complexity', 'approximate', 'model', 'use', 'video', 'observation', 'ready', 'make', 'assumption', 'approximation', 'base', 'observation', 'video', 'fig', 'show', 'frame', 'aolme', 'video', 'recording', 'easy', 'estimate', 'relative', 'distance', 'participant', 'fig', 'h1', 'represent', 'height', 'speaker', 'h2', 'represent', 'relative', 'height', 'speaker', 'represent', 'separation', 'speaker', 'represent', 'width', 'table', 'assume', 'also', 'observation', 'speaker', 'separate', 'distance', 'figure', 'relative', 'position', 'aolme', 'participant', 'fig', 'approximate', 'width', 'standard', 'commercial', 'table', 'assume', 'total', 'speaker', 'sit', 'half', 'distance', 'edge', 'table', 'combination', 'speaker', 'close', 'corner', 'table', 'speaker', 'separation', 'speaker', 'approximate', 'recording', 'microphone', 'locate', 'half', 'distance', 'center', 'table', 'finally', 'approximate', 'use', 'reference', 'average', 'waist', 'head', 'distance', 'young', 'female', 'h2', 'average', 'waist', 'head', 'distance', 'kid', 'year', 'old', 'approximately', 'value', 'example', 'illustrate', 'principle', 'base', 'approximation', 'actual', 'model', 'necessarily', 'use', 'value', 'prior', 'knowledge', 'dimension', 'room', 'use', 'approximate', 'geometry', 'observation', 'location', 'wall', 'ceiling', 'provide', 'reference', 'location', 'wall', 'nevertheless', 'possible', 'recognize', 'give', 'appearance', 'scene', 'remain', 'wall', 'great', 'distance', 'visible', 'one', 'assumption', 'provide', 'numeric', 'value', 'location', 'wall', 'ceiling', 'give', 'clue', 'behavior', 'sound', 'room', 'recall', 'section', 'human', 'voice', 'propagate', 'mostly', 'unidirectionally', 'front', 'speaker', 'speaker', 'project', 'voice', 'speaker', 'vice', 'versa', 'sound', 'energy', 'speaker', 'absorb', 'speaker', 'energy', 'reflect', 'table', 'travel', 'ceiling', 'room', 'amount', 'propagate', 'wall', 'wall', 'reflect', 'residual', 'sound', 'energy', 'speaker', 'process', 'repeat', 'energy', 'absorb', 'follow', '𝑇cid2874cid2868', 'rule', 'process', 'apply', 'speaker', 'active', 'case', 'speaker', 'reflect', 'surface', 'directly', 'locate', 'front', 'computer', 'screen', 'locate', 'distance', 'sound', 'reflection', 'consider', 'minimal', 'influence', 'make', 'table', 'reflect', 'surface', 'model', 'possible', 'conclude', 'sound', 'energy', 'participant', 'mainly', 'contain', 'boundary', 'table', 'contribution', 'reflection', 'wall', 'consider', 'practice', 'negligible', 'give', 'directionality', 'speech', 'absorption', 'speaker', 'separation', 'speaker', 'wall', 'ceiling', 'room', 'previous', 'analysis', 'indicate', 'critical', 'model', 'take', 'consideration', 'reflection', 'wall', 'suggest', 'room', 'model', 'infinite', 'dimension', 'absorbance', 'close', 'unfortunately', 'room', 'infinite', 'dimension', 'lead', 'problem', 'model', 'source', 'discuss', 'previously', 'simulation', 'software', 'allow', 'omnidirectional', 'source', 'microphone', 'wallless', 'room', 'pyroomacoustic', 'create', 'image', 'speech', 'equally', 'propagate', 'direction', 'speaker', 'know', 'accurate', 'solution', 'place', 'source', 'close', 'proximity', 'wall', 'model', 'make', 'virtual', 'room', 'size', 'table', 'thus', 'reduce', 'propagation', 'speaker', 'negligible', 'level', 'analysis', 'describe', 'give', 'basis', 'first', 'model', 'represent', 'location', 'speaker', 'recording', 'microphone', 'recall', 'model', 'fig', 'set', 'model', 'base', 'acoustic', 'scene', 'fig', 'represent', 'location', 'respect', 'table', 'speaker', 'real', 'recording', 'microphone', 'note', 'model', 'include', '6th', 'speaker', 'represent', 'room', 'noise', 'represent', 'noise', 'separate', 'speaker', 'allow', 'well', 'discrimination', 'audio', 'segment', 'contain', 'noise', 'contain', 'speech', 'figure', 'location', 'speaker', 'real', 'microphone', 'z', 'dimension', 'room', 'height', 'need', 'add', 'convert', 'model', 'model', 'perimeter', 'room', 'limit', 'size', 'table', 'table', 'model', 'floor', 'room', 'approach', 'location', 'zeroreference', 'respect', 'table', 'total', 'height', 'room', 'approximate', 'similar', 'manner', 'perimeter', 'room', 'directionality', 'human', 'voice', 'expect', 'little', 'transmission', 'voice', 'energy', 'ceiling', 'therefore', 'reflection', 'come', 'neglect', 'ceiling', 'locate', 'height', 'long', 'maximum', 'height', 'tall', 'speaker', 'empirically', 'value', 'set', 'example', 'table', '3d', 'model', 'room', 'dimension', 'speaker', 'show', 'fig', 'figure', 'model', 'virtual', 'room', 'last', 'element', 'need', 'complete', 'model', 'location', 'virtual', 'microphone', 'location', 'constrain', 'dimension', 'virtual', 'room', 'maximum', 'antialiasing', 'distance', 'also', 'necessary', 'consider', 'array', 'microphone', 'consist', 'set', 'virtual', 'microphone', 'real', 'microphone', 'rest', 'top', 'table', 'location', 'real', 'microphone', 'receive', 'sound', 'reflection', 'bottom', 'therefore', 'assign', 'z', 'value', 'real', 'microphone', 'rest', 'table', 'mechanical', 'vibration', 'transmit', 'table', 'simulate', 'vibration', 'model', 'research', 'include', 'value', 'component', 'real', 'microphone', 'location', 'virtual', 'microphone', 'array', 'arbitrary', 'separation', 'microphone', 'critical', 'distance', 'adjacent', 'microphone', 'never', 'exceed', 'maximum', 'antialiase', 'however', 'interest', 'unique', 'crosscorrelation', 'value', 'microphone', 'array', 'asymmetric', 'position', 'respect', 'speaker', 'way', 'value', 'magnitude', 'crosscorrelation', 'microphone', 'different', 'speaker', 'z', 'value', 'virtual', 'microphone', 'arbitrary', 'pyroomacoustic', 'simulate', 'omnidirectional', 'microphone', 'advantage', 'locate', 'certain', 'height', 'reference', 'microphone', 'model', 'research', 'microphone', 'locate', 'approximately', 'height', 'speaker', 'allow', 'simulation', 'direction', 'fig', 'show', 'complete', 'model', 'derive', 'fivespeak', 'example', 'type', 'model', 'use', 'experiment', 'dissertation', 'variation', 'need', 'fit', 'objective', 'experiment', 'figure', 'final', 'model', 'example', 'chapter', 'result', 'chapter', 'present', 'experiment', 'conduct', 'evaluate', 'capability', 'propose', 'method', 'identify', 'speaker', 'audio', 'segment', 'experiment', 'focus', 'objective', 'determine', 'suitability', 'pyroomacoustic', 'simulation', 'package', 'evaluate', 'performance', 'propose', 'method', 'diarize', 'identify', 'speaker', 'compare', 'performance', 'propose', 'method', 'amazon', 'aw', 'cloud', 'experiment', 'include', 'real', 'audio', 'recording', 'audio', 'lab', 'aolme', 'video', 'evaluation', 'pyroomacoustic', 'objective', 'experiment', 'evaluate', 'pyroomacoustic', 'simulation', 'software', 'experiment', 'compare', 'crosscorrelation', 'measure', 'real', 'microphone', 'crosscorrelation', 'emulate', 'microphone', 'use', 'pyroomacoustic', 'experiment', 'perform', 'use', 'audio', 'lab', 'pyroomacoustic', 'simulation', 'base', 'geometry', 'discuss', 'chapter', 'microphone', 'calibration', 'audio', 'recording', 'device', 'electronic', 'delay', 'vary', 'equipment', 'equipment', 'measure', 'real', 'crosscorrelation', 'physical', 'microphone', 'necessary', 'measure', 'electronic', 'delay', 'microphone', 'apply', 'calibration', 'factor', 'necessary', 'simulate', 'microphone', 'ideal', 'consider', 'delay', 'necessary', 'calibrate', 'real', 'microphone', 'compensate', 'delay', 'compare', 'simulation', 'way', 'calibrate', 'microphone', 'place', 'array', 'configuration', 'locate', 'array', 'proximity', 'audio', 'source', 'fig', 'show', 'block', 'diagram', 'component', 'need', 'calibrate', 'microphone', 'calibration', 'setup', 'consist', 'audio', 'source', 'speaker', 'sound', 'processor', 'microphone', 'array', 'audio', 'source', 'drive', 'signal', 'generator', 'sound', 'processor', 'acquire', 'audio', 'channel', 'simultaneously', 'figure', 'block', 'diagram', 'microphone', 'calibration', 'setup', 'calibration', 'preparation', 'homemade', 'jig', 'make', 'cloth', 'pin', 'use', 'hold', 'microphone', 'calibration', 'configuration', 'separation', 'microphone', 'show', 'fig', '39a', 'array', 'microphone', 'locate', 'next', 'loudspeaker', 'show', 'fig', '39b', 'configuration', 'distance', 'microphone', 'sound', 'source', 'microphone', 'make', 'time', 'differential', 'arrival', 'neglectable', 'b', 'figure', 'microphone', 'calibration', 'location', 'loudspeaker', 'calibration', 'execution', 'apply', 'loudspeaker', 'use', 'signal', 'generator', 'loudspeaker', 'output', 'microphone', 'collect', 'simultaneously', 'use', 'sound', 'processor', 'computer', 'run', 'tracktion', 'waveform', '®', 'software', 'channel', 'recording', 'save', 'separated', 'wav', 'file', 'duration', 'sample', 'khz', 'measure', 'delay', 'microphone', 'wav', 'file', 'convert', 'txt', 'file', 'crosscorrelation', 'analysis', 'use', 'multifunction', 'convolution', 'correlator', 'visualizer', 'subvi', 'combination', 'microphone', 'crosscorrelate', 'show', 'table', 'result', 'table', 'vi', 'show', 'microphone', 'crosscorrelation', 'observe', 'microphone', 'rather', 'apply', 'calibration', 'factor', 'convenient', 'segregate', 'microphone', 'group', 'measure', 'crosscorrelation', 'pair', 'belong', 'group', 'note', 'result', 'show', 'table', 'vi', 'correspond', 'index', 'array', 'max', 'crosscorrelation', 'occur', 'table', 'vi', 'crosscorrelation', 'table', 'microphone', 'calibration', 'e', 'h', 'p', 'r', 'microphone', 'audio', 'lab', 'setup', 'model', 'configuration', 'fig', 'show', 'laboratory', 'setup', 'experiment', 'setup', 'follow', 'general', 'model', 'configuration', 'describe', 'chapter', 'microphone', 'distribute', 'loudspeaker', 'maximize', 'crosscorrelation', 'value', 'difference', 'microphone', 'dimension', 'lab', 'setup', 'allow', 'microphone', 'antialiasing', 'distance', 'already', 'calculate', 'microphone', 'keep', 'location', 'recording', 'microphone', 'draft', 'model', 'figure', 'audio', 'lab', 'setup', 'evaluation', 'pyroomacoustic', 'model', 'set', 'follow', 'configuration', 'audio', 'lab', 'audio', 'lab', 'loudspeaker', 'speaker', 'include', 'model', 'virtual', 'room', 'perimeter', 'set', 'size', 'lab', 'table', 'height', 'room', 'set', 'value', 'absorption', 'model', 'set', 'empirically', 'number', 'image', 'microphone', 'height', 'set', 'microphone', 'follow', 'observation', 'make', 'chapter', 'table', 'vii', 'show', 'final', 'dimension', 'virtual', 'room', 'location', 'source', 'loudspeaker', 'microphone', 'use', 'create', 'pyroomacoustics', 'model', 'final', 'model', 'geometry', 'generate', 'pyroomacoustic', 'show', 'fig', 'table', 'vii', 'dimension', 'virtual', 'room', 'location', 'source', 'source', 'mic', 'corner', 'corner', 'corner', 'corner', 'extrude', 'figure', 'final', 'model', 'audio', 'lab', 'setup', 'experimental', 'execution', 'audio', 'lab', 'simulation', 'section', 'experiment', 'use', 'source', 'anechoic', 'male', 'voice', 'duration', 'source', 'play', 'sequentially', 'loudspeaker', 'correspond', 'capture', 'simultaneously', 'audio', 'processor', 'correspond', 'microphone', 'channel', 'audio', 'save', 'independent', 'audio', 'file', 'use', 'tracktion', 'waveform', '®', 'simulation', 'pyroomacoustic', 'use', 'geometric', 'model', 'fig', 'need', 'estimate', 'source', 'simulation', 'reception', 'microphone', 'accomplish', 'run', 'room', 'model', 'generator', 'subvi', 'geometric', 'model', 'play', 'source', 'location', 'speaker', 's1', 'subvi', 'save', 'result', 'microphone', 'simulation', 'separate', 'txt', 'file', 'result', 'final', 'analysis', 'consist', 'run', 'multifunction', 'convolution', 'correlator', 'visualizer', 'subvi', 'calculate', 'crosscorrelation', 'real', 'microphone', 'audio', 'file', 'ground', 'truth', 'simulated', 'microphone', 'audio', 'file', 'cross', 'correlation', 'calculate', 'microphone', 'group', 'determine', 'calibration', 'need', 'audio', 'segmentation', 'short', 'duration', 'sample', 'audio', 'table', 'viii', 'show', 'result', 'offset', 'ground', 'truth', 'simulated', 'signal', 'correspond', 'sample', 'rate', 'khz', 'table', 'viii', 'experimental', 'result', 'simulation', 'software', 'evaluation', 'sim', 'sim', 'sim', 'table', 'viii', 'show', 'simulation', 'correctly', 'predict', 'sign', 'cross', 'correlation', 'microphone', 'pair', 'maximun', 'offset', 'difference', 'ms', 'correspond', 'difference', 'average', 'difference', 'hence', 'simulation', 'model', 'appear', 'sufficiently', 'accurate', 'differentiate', 'speaker', 'base', 'position', 'control', 'environment', 'experiment', 'objective', 'next', 'set', 'experiment', 'evaluate', 'performance', 'method', 'identify', 'speaker', 'singlechannel', 'audio', 'segment', 'record', 'control', 'condition', 'audio', 'lab', 'control', 'experiment', 'first', 'experiment', 'demonstrate', 'capability', 'propose', 'method', 'identify', 'speaker', 'base', 'location', 'second', 'experiment', 'demonstrate', 'capability', 'propose', 'method', 'identify', 'multiple', 'speaker', 'independently', 'spoken', 'word', 'methodology', 'approach', 'experiment', 'physically', 'emulate', 'open', 'collaborative', 'environment', 'aolme', 'record', 'audio', 'contain', 'speech', 'single', 'microphone', 'geometry', 'acoustic', 'scene', 'know', 'create', 'model', 'numerically', 'follow', 'real', 'scene', 'evaluate', 'performance', 'propose', 'method', 'use', 'model', 'conversely', 'control', 'parameter', 'location', 'source', 'possible', 'experiment', 'different', 'microphone', 'array', 'absorption', 'value', 'evaluate', 'performance', 'different', 'model', 'control', 'experiment', 'use', 'audio', 'lab', 'configuration', 'pyroomacoustics', 'model', 'previous', 'experiment', 'change', 'make', 'location', 'speaker', 'well', 'fit', 'distance', 'use', 'aolme', 'experiment', 'audio', 'lab', 'model', 'preparation', 'table', 'represent', 'audio', 'lab', 'configuration', 'experiment', 'location', 'loudspeaker', 'recording', 'microphone', 'mic3', 'audio', 'record', 'use', 'canon', 'video', 'camera', 'connect', 'video', 'recording', 'save', 'internal', 'sd', 'card', 'camera', 'way', 'recording', 'ambient', 'noise', 'inject', 'use', 'player', 'background', 'noise', 'aolme', 'video', 'session', 'table', 'distribution', 'microphone', 'source', 'control', 'experiment', 'source', 'mic', 'corner', 'corner', 'room', 'corner', 'corner', 'extrude', 'lab', 'setup', 'translate', 'model', 'show', 'fig', 'noise', 'represent', 'speaker', 'place', 'relative', 'location', 'resemble', 'location', 'source', 'microphone', 'keep', 'z', 'coordinate', 'value', 'previous', 'experiment', 'noise', 'locate', 'well', 'represent', 'location', 'cd', 'player', 'experiment', 'subsequent', 'experiment', 'research', 'use', 'linear', 'crosstype', 'virtual', 'microphone', 'array', 'element', 'record', 'microphone', 'locate', 'center', 'array', 'type', 'microphone', 'configuration', 'flexible', 'compact', 'allow', 'implementation', 'model', 'different', 'geometry', 'separation', 'microphone', 'array', 'set', 'distance', 'commonly', 'find', 'commercial', 'microphone', 'array', 'virtual', 'microphone', 'array', 'locate', 'offset', 'position', 'loudspeaker', 'avoid', 'symmetry', 'location', 'provide', 'distinctive', 'crosscorrelation', 'result', 'microphone', 'well', 'differentiation', 'figure', 'model', 'control', 'experiment', 'evaluation', 'criterion', 'common', 'method', 'measure', 'performance', 'diarization', 'system', 'diarization', 'error', 'rate', 'der', 'der', 'define', 'fraction', 'time', 'attribute', 'correctly', 'speaker', 'nonspeech', 'calculate', 'summation', 'error', 'follow', 'cid3019cid3032cid3033cid3032cid3045cid3032cid3041cid3030cid3032', 'cid3013cid3032cid3041cid3034cid3035', 'fa', 'length', 'false', 'alarm', 'miss', 'length', 'miss', 'speech', 'segment', 'overlap', 'total', 'length', 'overlapped', 'speech', 'confusion', 'total', 'length', 'misclassified', 'segment', 'reference', 'length', 'total', 'length', 'audio', 'reference', 'overlap', 'use', 'test', 'hal', 'experiment', 'objective', 'experiment', 'demonstrate', 'propose', 'method', 'identify', 'speaker', 'solely', 'location', 'speaker', 'independently', 'speech', 'characteristic', 'accomplish', 'use', 'nonanechoic', 'audio', 'speech', 'source', 'obtain', 'raw', 'video', 'clip', 'classic', 'movie', 'many', 'software', 'package', 'speech', 'processing', 'find', 'research', 'provide', 'sort', 'test', 'file', 'evaluation', 'demo', 'include', 'phrase', 'classical', 'movie', 'space', 'odyssey', 'movie', 'human', 'crew', 'face', 'rebellion', 'spaceship', 'computer', 'hal', 'malfunction', 'attempt', 'kill', 'crew', 'phrase', '’m', 'sorry', '’m', 'afraid', 'still', 'wellknown', 'nowadays', 'discuss', 'implication', 'artificial', 'intelligence', 'take', 'control', 'critical', 'mission', 'experiment', 'use', 'clip', 'second', 'duration', 'famous', 'phrase', 'speak', 'clip', 'include', 'conversation', 'space', 'pod', 'fig', 'clip1', 'hal', 'mothership', 'fig', 'clip2', 'video', 'scene', 'switch', 'space', 'pod', 'spaceship', 'voice', 'come', 'radio', 'transmission', 'inside', 'spaceship', 'depend', 'scene', 'also', 'background', 'noise', 'electronic', 'equipment', 'space', 'pod', 'clip', 'download', 'youtube', 'figure', 'video', 'clip', 'hal', 'clip2', 'source', 'fandango', 'movie', 'clip', 'set', 'experiment', 'perform', 'experiment', 'aim', 'determine', 'biasing', 'result', 'product', 'location', 'speaker', 'experiment', 'evaluate', 'effect', 'training', 'result', 'source', 'preparation', 'edit', 'experiment', 'play', 'voice', 'independently', 'loudspeaker', 'youtube', 'video', 'convert', 'single', 'channel', 'use', 'audacity', 'save', 'khz', 'audio', 'see', 'fig', 'use', 'audacity', 'segment', 'voice', 'cut', 'paste', 'separate', 'channel', 'new', 'stereo', 'track', 'fig', 'b', 'interval', 'noise', 'convert', 'silence', 'allow', 'recording', 'noise', 'come', 'external', 'source', 'place', 'right', 'track', 'hal', 'place', 'left', 'track', 'noise', 'segment', 'copy', 'paste', 'separate', 'audio', 'track', 'burn', 'fig', 'c', 'figure', 'source', 'noise', 'hal', 'experiment', 'configuration', 'possible', 'play', 'loudspeaker', 's2', 'hal', 'loudspeaker', 's3', 'use', 'loudspeaker', 'switch', 'noise', 'play', 'player', 'continuous', 'loop', 'model', 'ground', 'truth', 'record', 'set', 'recording', 'take', 'experiment', 'set', 'consist', 'play', 'audio', 'track', 'use', 'loudspeaker', 'hal', 'set', 'consist', 'play', 'loudspeaker', 'hal', 'noise', 'track', 'play', 'continuous', 'loop', 'cd', 'player', 'locate', 'position', 'source', 'audio', 'record', 'use', 'canon', 'video', 'camera', 'microphone', 'locate', 'position', 'microphone', 'table', 'recording', 'transfer', 'computer', 'segmentation', 'training', 'camera', 'record', 'audio', 'stereo', 'mode', 'code', 'handle', 'audio', 'stereo', 'track', 'convert', 'audio', 'remove', 'right', 'channel', 'conversion', 'keep', 'intact', 'spatial', 'information', 'contain', 'left', 'channel', 'use', 'audacity', 'convert', 'mono', 'feature', 'mix', 'channel', 'render', 'spatial', 'information', 'useless', 'fig', 'show', 'final', 'set', 'audio', 'capture', 'camera', 'training', 'segmentation', 'model', 'experiment', 'train', 'segment', 'speech', 'segment', 'noise', 'experiment', 'model', 'train', 'use', 'long', 'segment', 'hal', 'long', 'segment', 'show', 'fig', 'figure', 'ground', 'truth', 'set', 'b', 'hal', 'experiment', 'figure', 'training', 'segment', 'hal', 'noise', 'train', 'long', 'set', 'silence', 'experiment', 'train', 'train', 'set', 'silence', 'noise', 'training', 'segment', 'length', '1a', 'experiment', 'model', 'train', 'hal', 'speaker', 's1', 'noise', 'train', 'set', 'silence', 'recorded', 'audio', 'segment', 'different', 'way', 'experiment', 'set', 'maximum', 'length', 'segment', 'second', 'end', 'audio', 'subtract', 'drop', 'segment', 'experiment', 'length', 'segment', 'limit', 'maximum', 'frame', 'less', 'ms', 'discard', 'experiment', 'testing', 'result', 'table', 'show', 'result', 'experiment', 'appreciate', 'length', 'segment', 'influence', 'der', 'experiment', 'long', 'segment', 'less', 'error', 'result', 'agree', 'previous', 'discussion', 'amount', 'information', 'need', 'proper', 'crosscorrelation', 'important', 'optimize', 'length', 'segment', 'contain', 'much', 'information', 'possible', 'maximize', 'matching', 'probability', 'training', 'template', 'table', 'x', 'der', 'result', 'hal', 'experiment', 'test', 'segment', 'properly', 'classify', 'segment', 'false', 'alarm', 'confusion', 'der', 'multispeaker', 'identification', 'experiment', 'objective', 'experiment', 'section', 'measure', 'performance', 'propose', 'method', 'identify', 'several', 'speaker', 'singlechannel', 'recording', 'independently', 'content', 'speech', 'previous', 'experiment', 'geometry', 'room', 'location', 'speaker', 'know', 'allow', 'model', 'represent', 'accurately', 'actual', 'acoustic', 'scene', 'analysis', 'experiment', 'section', 'use', 'lab', 'setup', 'model', 'hal', 'experiment', 'experiment', 'divide', 'separate', 'test', 'include', 'speaker', 'speaker', 'experiment', 'independent', 'speaker', 'repeat', 'phrase', 'different', 'position', 'last', 'experiment', 'separate', 'speaker', 'different', 'location', 'source', 'preparation', 'edit', 'speech', 'source', 'experiment', 'consist', 'different', 'speaker', 'male', 'female', 'sample', 'rate', 'khz', 'source', 'download', 'telecommunication', 'signal', 'processing', 'laboratory', 'database', 'version', 'length', 'source', 'vary', 'approximately', 'total', 'audio', 'track', 'prepare', 'analysis', 'track', 'b', 'speaker', 'track', 'source', 'arrange', 'stereo', 'track', 'play', 'loudspeaker', 'ls1', 'switch', 'play', 'hal', 'experiment', 'small', 'pause', 'insert', 'allow', 'switching', 'loudspeaker', 'table', 'show', 'structure', 'audio', 'sample', 'sequence', 'table', 'indicate', 'label', 'active', 'speaker', 'loudspeaker', 'play', 'speech', 'label', 'spoken', 'phrase', 'example', 'audio', 'sample', 'contain', 'sequence', 'sequence', 'play', 'loudspeaker', 's1', 'speaker', 'speak', 'phrase', 'sequence', 'play', 'speaker', 'loudspeaker', 's3', 'speak', 'phrase', 'sample', 'c', 'speaker', 'repeat', 'phrase', 'objective', 'demonstrate', 'ability', 'propose', 'system', 'differentiate', 'speaker', 'regardless', 'speech', 'content', 'table', 'experiment', 'sequence', 'table', 'duration', 'condition', 'loudspeaker', 'speaker', 'phrase', 'b', 'loudspeaker', 'b', 'sequence', 'b', 'loudspeaker', 's1', 'speaker', 'phrase', 'b', 'c', 'e', 'g', 'h', 'l', 'e', 'p', 'loudspeaker', 'speaker', 'phrase', 'b', 'b', 'c', 'e', 'g', 'h', 'ground', 'truth', 'record', 'audio', 'capture', 'way', 'hal', 'experiment', 'use', 'canon', 'video', 'camera', 'save', 'video', 'recording', 'camera', 'internal', 'sd', 'storage', 'ambient', 'noise', 'inject', 'pay', 'background', 'noise', 'use', 'cd', 'player', 'hall', 'experiment', 'background', 'noise', 'extract', 'aolme', 'video', 'recording', 'hal', 'experiment', 'stereo', 'recording', 'video', 'camera', 'convert', 'singlechannel', 'audio', 'remove', 'right', 'channel', 'analysis', 'training', 'segmentation', 'training', 'segment', 'maximum', 'length', 'speaker', 'segment', 'noise', 'custom', 'vad', 'use', 'segmentation', 'number', 'segment', 'produce', 'audio', 'track', 'varied', 'show', 'result', 'table', 'testing', 'result', 'testing', 'conduct', 'manner', 'hal', 'experiment', 'result', 'segment', 'show', 'table', 'xii', 'table', 'xii', 'control', 'environment', 'experiment', 'diarization', 'error', 'rate', 'result', 'audio', 'sample', 'speaker', 'segment', 'b', 'c', 'properly', 'classify', 'segment', 'false', 'alarm', 'miss', 'confusion', 'der', 'table', 'v', 'show', 'der', 'bad', 'case', 'result', 'comparable', 'well', 'der', 'result', 'method', 'use', 'database', 'neural', 'network', 'aolme', 'experiment', 'control', 'environment', 'experiment', 'demonstrate', 'propose', 'method', 'identify', 'speaker', 'singlechannel', 'recording', 'experiment', 'analyze', 'audio', 'sample', 'feature', 'organize', 'speech', 'speaker', 'time', 'speaker', 'well', 'separate', 'overlapping', 'speaker', 'objective', 'aolme', 'experiment', 'section', 'evaluate', 'performance', 'propose', 'method', 'identify', 'speaker', 'audio', 'recording', 'video', 'noisy', 'collaborative', 'environment', 'section', 'evaluate', 'process', 'selection', 'aolme', 'video', 'experimental', 'analysis', 'discuss', 'model', 'employ', 'analysis', 'analysis', 'audio', 'follow', 'approach', 'previous', 'experiment', 'evaluation', 'selection', 'aolme', 'video', 'several', 'hour', 'aolme', 'video', 'recording', 'available', 'analysis', 'experimental', 'nature', 'research', 'work', 'necessary', 'select', 'video', 'meet', 'certain', 'characteristic', 'facilitate', 'preparation', 'model', 'setup', 'experiment', 'model', 'use', 'previous', 'experiment', 'prove', 'perform', 'well', 'reason', 'necessary', 'search', 'aolme', 'video', 'similar', 'geometric', 'characteristic', 'model', 'participant', 'similar', 'place', 'speaker', 'model', 'previous', 'experiment', 'selection', 'consist', 'video', 'participant', 'library', 'video', 'video', 'approximately', 'minute', 'long', 'fig', 'show', 'frame', 'video', 'participant', 'participant', 'participant', 'c', 'participant', 'previous', 'experiment', 'stereo', 'audio', 'track', 'video', 'extract', 'convert', 'khz', 'single', 'channel', 'remove', 'right', 'channel', 'figure', '47video', 'clip', 'aolme', 'experiment', 'model', 'preparation', 'model', 'use', 'experiment', 'follow', 'geometry', 'previous', 'experiment', 'width', 'table', 'adjust', 'fit', 'aolme', 'scene', 'accurately', 'instead', 'generate', 'separate', 'model', 'video', 'model', 'speaker', 'experiment', 'previously', 'location', 'absent', 'speaker', 'turn', 'training', 'silence', 'segment', 'fig', 'show', 'pyroomacoustic', 'model', 'table', 'xiii', 'show', 'location', 'speaker', 'microphone', 'figure', 'model', 'aolme', 'experiment', 'table', 'xiii', 'location', 'speaker', 'microphone', 'aolme', 'experiment', 'r', 'e', 'p', 'c', 'r', 'corner', 'corner', 'corner', 'corner', 'extrude', 'training', 'segmentation', 'training', 'segmentation', 'principle', 'use', 'previous', 'experiment', 'training', 'use', 'long', 'sample', 'participant', 'similar', 'length', 'segment', 'background', 'noise', 'model', 'use', 'participant', 'nonactive', 'speaker', 'train', 'silence', 'segment', 'duration', 'table', 'show', 'speaker', 'assignment', 'experiment', 'table', 'speaker', 'assignment', 'experiment', 'audio', 'sample', 'b', 'c', 'speaker', 's1', '\uf0fc\uf020', 'silence', '\uf0fc\uf020', 'silence', '\uf0fc\uf020', 'silence', 'silence', 'silence', 'silence', '\uf0fc\uf020', 'noise', 'noise', 'noise', 'noise', 'ground', 'truth', 'audio', 'segment', 'use', 'vad', 'discard', 'segment', 'less', 'duration', 'limit', 'length', 'segment', 'maximum', 'total', 'number', 'segment', 'sample', 'show', 'result', 'table', 'testing', 'result', 'type', 'analysis', 'apply', 'previous', 'experiment', 'table', 'xv', 'show', 'example', 'crosscorrelation', 'result', 'analyze', 'segment', 'audio', 'sample', 'b', 'table', 'show', 'training', 'cc', 'table', 'score', 'possible', 'speaker', 'match', 'represent', 'case', 'segment', 'correspond', 'speaker', 'table', 'table', 'aolme', 'experiment', 'microphone', 'cross', 'correlation', 'unknown', 'segment', 'b', 'microphone', 'cross', 'correlation', 'training', 'speaker', 'score', 'c', 'microphone', 'cross', 'correlation', 'training', 'speaker', 'score', 'microphone', 'cross', 'correlation', 'training', 'speaker', 'score', 'r', 'e', 'p', 'r', 'e', 'p', 'r', 'e', 'p', 'r', 'e', 'p', 'table', 'xvi', 'show', 'result', 'analysis', 'audio', 'sample', 'respective', 'der', 'experiment', 'table', 'xvi', 'classification', 'result', 'aolme', 'experiment', 'audio', 'sample', 'sample', 'duration', 'speaker', 'segment', 'properly', 'classify', 'segment', 'false', 'alarm', 'miss', 'confusion', 'der', 'b', 'c', 'comparison', 'method', 'final', 'set', 'experiment', 'focus', 'compare', 'propose', 'method', 'amazon', 'aw', 'cloudbase', 'speech', 'processing', 'service', 'introduce', 'background', 'section', 'dissertation', 'diarization', 'service', 'process', 'update', 'time', 'dissertation', 'write', 'therefore', 'possible', 'run', 'experiment', 'methodology', 'comparison', 'diarization', 'service', 'provide', 'amazon', 'differ', 'propose', 'method', 'aspect', 'first', 'require', 'sample', 'audio', 'training', 'second', 'audio', 'sample', 'diarize', 'need', 'minimum', 'duration', 'approximately', 'third', 'output', 'provide', 'label', 'active', 'speaker', 'rather', 'set', 'text', 'transcript', 'contain', 'speech', 'segment', 'abstract', 'speaker', 'speaker', 'active', 'time', 'speaker', 'transcript', 'segment', 'confidence', 'rate', 'give', 'constraint', 'fair', 'comparison', 'criterion', 'manually', 'measure', 'speaker', 'ground', 'truth', 'active', 'time', 'manually', 'compare', 'time', 'result', 'analysis', 'method', 'necessary', 'add', 'section', 'code', 'propose', 'method', 'measure', 'length', 'segment', 'already', 'classified', 'totalize', 'time', 'speaker', 'noise', 'selection', 'preparation', 'ground', 'truth', 'measurement', 'video', 'analysis', 'analysis', 'consist', 'total', 'aolme', 'video', 'contain', 'speaker', 'duration', 'video', 'limit', 'maximum', 'minute', 'audio', 'video', 'extract', 'use', 'audacity', 'downshifte', 'khz', 'upload', 'goggle', 'amazon', 'audio', 'file', 'method', 'sample', 'rate', 'khz', 'speaker', 'active', 'time', 'ground', 'truth', 'audio', 'measure', 'use', 'stopwatch', 'aolme', 'video', 'difficult', 'assess', 'time', 'several', 'speaker', 'active', 'simultaneously', 'case', 'speaker', 'time', 'record', 'listen', 'hisher', 'voice', 'watch', 'hisher', 'lip', 'movement', 'video', 'even', 'speech', 'overlap', 'moment', 'training', 'segmentation', 'system', 'train', 'audio', 'sample', 'long', 'speaker', 'noise', 'use', 'vad', 'maximum', 'segment', 'length', 'segment', 'duration', 'less', 'drop', 'need', 'training', 'amazon', 'system', 'train', 'use', 'upload', 'audio', 'database', 'testing', 'analysis', 'audio', 'file', 'video', 'analyze', 'use', 'modify', 'code', 'totalize', 'speaker', 'time', 'additional', 'step', 'amazon', 'audio', 'upload', 'cloud', 'method', 'return', 'abstract', 'label', 'output', 'transcription', 'speaker', 'use', 'manually', 'match', 'identity', 'speaker', 'segment', 'note', 'first', 'active', 'speaker', 'detect', 'speaker', 'result', 'table', 'xvii', 'show', 'result', 'experiment', 'percentage', 'error', 'highlight', 'light', 'blue', 'error', 'calculate', 'use', 'percent', 'error', 'estimate', 'time', '−', 'true', 'time', 'true', 'time', '∗', 'table', 'xvii', 'experimental', 'comparison', 'method', 'audio', 'sample', 'speaker', 'speaker', 'aw', 'time', 'error', 'error', 'time', 'propose', 'method', 'ground', 'truth', 'time', 'error', 'time', 'table', 'xviii', 'show', 'average', 'error', 'speaker', 'well', 'total', 'average', 'error', 'method', 'table', 'average', 'error', 'method', 'speaker', 'total', 'propose', 'method', 'amazon', 'aw', 'result', 'present', 'table', 'show', 'substantial', 'reduction', 'achieve', 'error', 'rate', 'specifically', 'error', 'reduction', 'range', 'color', 'code', 'use', 'table', 'xvii', 'emphasize', 'result', 'experiment', 'red', 'highlighting', 'denote', 'case', 'failure', 'speaker', 'completely', 'miss', 'estimate', 'talking', 'time', 'speaker', 'error', 'eg', 'overestimate', 'speaker', 'talk', 'time', 'possible', 'speaker', 'example', 'amazon', 'aw', 'give', 'fail', 'result', 'case', 'cloud', 'give', 'fail', 'result', 'case', 'propose', 'method', 'give', 'fail', 'result', 'case', 'interesting', 'notice', 'propose', 'method', 'never', 'fail', 'detect', 'speaker', 'error', 'amazon', 'aw', 'detect', 'talking', 'time', 'case', 'cloud', 'fail', 'detect', 'talking', 'time', 'case', 'also', 'failure', 'case', 'sample', 'amazon', 'aw', 'cloud', 'contrast', 'propose', 'method', 'sample', 'example', 'overestimation', 'sample', 'free', 'dramatic', 'failure', 'teal', 'highlighting', 'denote', 'case', 'total', 'estimate', 'speaking', 'time', 'give', 'less', 'error', 'base', 'criterion', 'aw', 'give', 'satisfactory', 'result', 'case', 'case', 'propose', 'method', 'chapter', 'summary', 'conclusion', 'future', 'work', 'dissertation', 'present', 'method', 'speaker', 'diarization', 'identification', 'use', 'virtual', 'microphone', 'crosscorrelation', 'pattern', 'propose', 'method', 'identify', 'speaker', 'singlechannel', 'recording', 'take', 'noisy', 'collaborative', 'environment', 'classroom', 'educational', 'workshop', 'method', 'give', 'error', 'rate', 'less', 'average', 'available', 'diarization', 'method', 'subject', 'testing', 'environment', 'contrast', 'method', 'consider', 'stateoftheart', 'propose', 'method', 'require', 'minimal', 'training', 'database', 'make', 'applicable', 'situation', 'possible', 'gather', 'clean', 'speech', 'sample', 'background', 'section', 'dissertation', 'present', 'similar', 'research', 'work', 'speaker', 'diarization', 'identification', 'base', 'microphone', 'arrays', 'work', 'include', 'virtual', 'microphone', 'arrays', 'none', 'approach', 'full', 'virtual', 'array', 'simulation', 'single', 'microphone', 'recording', 'give', 'unprecedented', 'focus', 'deep', 'learning', 'method', 'alternative', 'approach', 'avoid', 'limit', 'number', 'researcher', 'interested', 'pursue', 'yet', 'propose', 'methodology', 'clearly', 'outperform', 'commercial', 'deep', 'learning', 'method', 'demonstrate', 'limitation', 'need', 'large', 'training', 'dataset', 'method', 'present', 'dissertation', 'offer', 'alternative', 'educational', 'researcher', 'involve', 'collaborative', 'environment', 'depend', 'mostly', 'analysis', 'datum', 'provide', 'video', 'recording', 'work', 'dissertation', 'show', 'available', 'method', 'perform', 'poorly', 'environment', 'determine', 'speak', 'long', 'deficiency', 'present', 'method', 'even', 'prominent', 'participant', 'underrepresented', 'group', 'large', 'training', 'database', 'exist', 'propose', 'method', 'demonstrate', 'significant', 'performance', 'improvement', 'capitalize', 'real', 'video', 'information', 'environment', 'analysis', 'rather', 'depend', 'unrelated', 'training', 'datum', 'also', 'require', 'previous', 'speaker', 'enrollment', 'method', 'open', 'possibility', 'analysis', 'wide', 'variety', 'video', 'datum', 'record', 'know', 'intention', 'posterior', 'analysis', 'dissertation', 'method', 'constitute', 'proof', 'concept', 'fully', 'operational', 'method', 'success', 'propose', 'method', 'due', 'possibility', 'simulate', 'acoustic', 'wave', 'propagation', 'include', 'speech', 'even', 'modeling', 'complex', 'powerful', 'personal', 'computer', 'execute', 'calculation', 'require', 'signal', 'processing', 'algorithm', 'code', 'simulation', 'available', 'large', 'repository', 'contain', 'opensource', 'library', 'ready', 'implementation', 'nevertheless', 'work', 'need', 'address', 'weakness', 'observe', 'far', 'case', 'participant', 'speaker', 'move', 'change', 'original', 'location', 'invade', '’s', 'speaker', 'physical', 'location', 'area', 'possible', 'eventually', 'adapt', 'method', 'research', 'work', 'ivpcl', 'lab', 'regard', 'object', 'subject', 'track', 'location', 'speaker', 'general', 'geometry', 'room', 'dynamically', 'modify', 'model', 'base', 'information', 'video', 'datum', 'thus', 'improve', 'error', 'rate', 'also', 'experiment', 'consider', 'type', 'microphone', 'array', 'leave', 'open', 'question', 'performance', 'type', 'array', 'circular', 'even', 'volumetric', 'addition', 'simulation', 'version', 'available', 'development', 'dissertation', 'limitation', 'impact', 'accuracy', 'model', 'pyroomacoustic', 'release', 'new', 'version', 'include', 'improvement', 'model', 'parameter', 'physical', 'modeling', 'room', 'absorption', 'reverberation', 'modeling', 'multipattern', 'microphone', 'simulation', 'finally', 'method', 'depend', 'proper', 'audio', 'segmentation', 'final', 'classification', 'misclassification', 'method', 'product', 'improper', 'presegmentation', 'sub', 'optimal', 'classification', 'sophisticated', 'classifier', 'use', 'machine', 'learning', 'neural', 'network', 'help', 'improve', 'overall', 'performance', 'possible', 'also', 'apply', 'cluster', 'classification', 'unsupervised', 'identification', 'speaker', 'finally', 'method', 'extend', 'support', 'application', 'speech', 'processing', 'incorporate', 'front', 'end', 'preprocessor', 'example', 'method', 'use', 'improve', 'accuracy', 'spatial', 'filter', 'speech', 'enhancement', 'speaker', 'separation', 'mixture', 'parameter', 'spatial', 'filter', 'well', 'determine', 'estimate', 'location', 'speaker', 'optimize', 'parameter', 'location', 'pyroomacoustic', 'script', 'section', 'describe', 'script', 'call', 'pyroomacoustic', 'library', 'generate', 'room', 'geometry', 'parameter', 'calculate', 'rir', 'emulate', 'virtual', 'microphone', 'room', 'geometry', 'generator', 'script', 'accept', 'room', 'dimension', 'location', 'source', 'virtual', 'microphone', 'generate', '3d', 'geometric', 'model', 'room', 'geometry', 'save', 'set', 'txt', 'file', 'contain', 'geometry', 'arrays', 'script', 'run', 'jupyter', 'notebook', 'location', 'source', 'microphone', 'add', 'room', 'room', 'praroomfromcornerscorner', 'fsfs', 'location', 'microphone', 'array', 'r', 'nparraymicx', 'micy', 'add', 'source', 'room', 'roomaddsourcesource1', 'execute', 'location', 'room', 'praroomfromcornerscorner', 'fsfs', '143', 'r', 'roomaddmicrophonearraypramicrophonearrayr', 'roomfs', 'save', 'geometry', 'npsavetxtrcusersuserdesktopphd', 'folderdissertationexperimentsmodelestimationroomparameterscorn', 'sarraytxtcornersdelimiter', 'npsavetxtrcusersuserdesktopphd', 'folderdissertationexperimentsmodelestimationroomparametersmicar', 'raytxtrdelimiter', 'virtual', 'microphone', 'simulation', 'script', 'script', 'use', 'twice', 'first', 'calculate', 'rir', 'model', 'source', 'virtual', 'microphone', 'emulate', 'signal', 'virtual', 'microphone', 'use', 'estimate', 'source', 'script', 'call', 'labview', 'output', 'save', 'txt', 'file', 'setup', 'import', 'numpy', 'import', 'matplotlibpyplot', 'plt', 'scipyio', 'import', 'wavfile', 'scipysignal', 'import', 'fftconvolve', 'import', 'pyroomacoustic', 'pra', 'define', 'variable', 'ab', 'cornersarray', 'source1', 'source6', 'micarray', 'define', 'model', 'def', 'modelgeneration', 'delimit', 'corner', 'room', 'corner', 'room', 'praroomfromcornerscorner', 'roomextruderoomextrude', 'read', 'source', 'room', 'praroomfromcornerscorner', 'fsf', 'add', 'microphone', 'array', 'r', 'nparraymicarray', 'roomaddmicrophonearraypramicrophonearrayr', 'roomfs', 'set', 'maxorder', 'room', 'praroomfromcornerscorner', 'fsfs', 'absorptionab', 'set', 'extrusion', 'roomextruderoomextrude', 'add', 'source', 'array', 'microphone', 'source', 'roomaddsourcesource13d', 'signals1', 'roomfs', 'compute', 'image', 'source', 'roomimagesourcemodeluselibroomtrue', 'roomcomputerir', 'save', 'datum', 'npsavetxtrcroomrir00delimit', 'mic', 'datamicroommicarraysignals0', 'mic5', 'datamicroommicarraysignals4', 'datamicroommicarraysignals5', 'source', 'return', 'appendix', 'b', 'labview', 'subvis', 'room', 'parameter', 'reader', 'figure', 'room', 'parameter', 'reader', 'input', 'output', 'figure', 'room', 'parameter', 'reader', 'front', 'panel', 'figure', 'room', 'parameter', 'reader', 'block', 'diagram', 'b', 'room', 'model', 'generator', 'figure', 'room', 'model', 'generator', 'figure', 'room', 'model', 'generator', 'front', 'panel', 'figure', 'room', 'model', 'generator', 'block', 'c', 'source', 'estimator', 'sub', 'vi', 'complex', 'display', 'source', 'block', 'diagram', 'instead', 'simple', 'functional', 'block', 'diagram', 'show', 'figure', 'source', 'estimator', 'icon', 'figure', 'source', 'estimator', 'front', 'panel', 'figure', 'source', 'estimator', 'simplify', 'block', 'diagram', 'crosscorrelation', 'model', 'calculator', 'figure', 'crosscorrelation', 'model', 'calculator', 'icon', 'figure', 'crosscorrelation', 'model', 'calculator', 'front', 'panel', 'figure', 'crosscorrelation', 'model', 'calculator', 'block', 'diagram', 'figure', 'crosscorrelation', 'model', 'calculator', 'crosscorrelator', 'subvi', 'note', 'subvi', 'crosscorrelation', 'result', 'indicate', 'index', 'max', 'crosscorrelation', 'occur', 'method', 'make', 'result', 'independent', 'sample', 'frequency', 'also', 'subvi', 'truncate', 'large', 'input', 'make', 'input', 'file', 'size', 'small', 'e', 'model', 'classifier', 'figure', 'model', 'classifier', 'icon', 'input', 'output', 'figure', 'model', 'classifier', 'front', 'panel', 'multifunction', 'convolution', 'correlator', 'visualizer', 'figure', 'multifunction', 'convolution', 'correlator', 'visualizer', 'front', 'panel', 'figure', 'multifunction', 'convolution', 'audio', 'lab', 'equipment', 'specification', 'microphone', 'equipment', 'audiotechnica', '\uf0b7', 'condenser', '\uf0b7', 'polar', 'pattern', 'omnidirectional', 'response', 'hz', '\uf0b7', 'source', 'battery', 'type', 'impedance', 'ohm', 'cvmv020', '\uf0b7', 'transducer', 'back', 'electret', 'condenser', 'omnidirectional', 'range', '12khz', '\uf0b7', 'sensitivity', '\uf0b7', 'signalnoise', 'ratio', '\uf0b7', 'power', 'source', 'phantom', 'power', '\uf0b7', 'polar', 'pattern', 'unidirectional', '\uf0b7', 'frequency', 'response', '\uf0b7', 'sensitivity', '\uf0b7', 'output', '\uf0b7', 'load', 'impedance', '≥1000', 'equivalent', 'noise', 'level', '16dba', '\uf0b7', 'power', 'source', 'phantom', 'power', 'supply', 'b', 'audio', 'processing', 'equipment', 'tascam', 'model', '\uf0b7', 'response', 'line', 'outbalance', '20hz', '20khz', '±03dbjeita', '882k96k', 'hz', '20hz', '40khz', '±03dbjeita', '100db', '100db', '\uf0b7', 'less', '\uf0b7', 'ratio', '\uf0b7', 'sample', 'frequency', 'quantization', 'bit', 'rate', '1624bit', 'less', '\uf0b7', 'audio', 'input', 'mic', 'inin', 'connector', 'gnd', 'hot', 'cold', '24kω', 'balanced', 'input', 'impedance', 'nominal', 'input', 'level', 'gain', 'max', '68dbu', '00003vrm', 'gain', 'min', '12dbu', '0195vrm', 'maximum', 'input', 'level', '8dbu', '1947vrm', 'gain', '56db', 'line', 'connector', 'mm', 'trsjack', 'hot', 'r', 'cold', 'balance', 'input', 'impedance', 'nominal', 'input', 'level', 'gain', 'max', '41dbu', '00069vrm', 'gain', '4dbu', '1228vrm', 'maximum', 'input', 'level', '24dbu', '12182vrm', 'gain', 'amplifier', '\uf0b7', 'power', 'output', 'watt', 'channel', 'stereo', '\uf0b7', 'surround', 'output', '80w', 'front', '80w', 'rear', 'response', '20hz', '20khz', '\uf0b7', 'total', 'harmonic', 'distortion', '\uf0b7', '\uf0b7', '300mv', 'line', 'input', 'sensitivity', '25mv', '300mv', 'line', '\uf0b7', 'speaker', 'load', 'loudspeaker', 'polk', 'audio', 'power', 'response', 'hz', 'khz', '\uf0b7', 'sensitivity', '\uf0b7', 'impedance', 'reference', 'tirumala', 'r', 'shahamiri', 'r', 'speaker', 'identification', 'feature', 'extraction', 'method', 'systematic', 'review', 'expert', 'system', 'application', 'vol', 'pp', 'j', 'impact', 'dataset', 'size', 'deep', 'learning', 'model', 'skill', 'performance', 'estimate', 'deep', 'learning', 'performance', 'online', 'available', 'skillandperformanceestimate', 'yoon', 'estimate', 'impact', 'training', 'datum', 'reinforcement', 'learn', 'cloud', 'googleblogcom', 'para', 'oct', 'online', 'available', 'koenecke', 'toup', 'racial', 'disparity', 'automate', 'speech', 'recognition', 'proceeding', 'science', 'online', 'serial', 'available', 'understand', 'racial', 'disparity', 'automatic', 'speech', 'recognition', 'case', 'habitual', 'present', '21st', 'international', 'conference', 'speech', 'processing', 'application', 'r', 'hawa', 'r', 'speech', 'recognition', 'use', 'cross', 'correlation', 'feature', 'analysis', 'use', 'melfrequency', 'cepstral', 'coefficient', 'pitch', 'ieee', 'international', 'conference', 'innovation', 'technology', 'inocon', 'ikizler', 'atasoy', 'h', 'cavdar', 'speaker', 'recognition', 'system', 'use', 'cross', 'correlation', 'ieee', '16th', 'signal', 'processing', 'communication', 'application', 'conference', 'advance', 'outofschool', 'learn', 'mathematic', 'engineering', 'online', 'available', 'image', 'video', 'processing', 'communication', 'lab', 'ivpcl', 'online', 'available', 'darsey', 'hand', 'detection', 'collaborative', 'learning', 'environment', 'longterm', 'video', 'object', 'detection', 'tracking', 'collaborative', 'learning', 'environment', 'fall', 'distinction', 'fund', 'lópezleiva', 'c', 'fast', 'hand', 'detection', 'collaborative', 'learning', 'environment', '19th', 'international', 'conference', 'computer', 'analysis', 'image', 'pattern', 'jacoby', 'r', 'contextsensitive', 'human', 'activity', 'classification', 'video', 'utilize', 'object', 'recognition', 'motion', 'estimation', 'spring', 'jatla', 'lópezleiva', 'longterm', 'human', 'video', 'activity', 'quantification', 'student', 'participation', 'asilomar', 'conference', 'signal', 'system', 'computer', 'eilar', 'c', 'jatla', 'distribute', 'video', 'analysis', 'advance', 'school', 'learning', 'mathematic', 'engineering', 'project', 'asilomar', 'conference', 'signal', 'system', 'computer', 'lópezleiva', 'c', 'dynamic', 'group', 'interaction', 'collaborative', 'learning', 'conference', 'signal', 'system', 'computer', 'press', 'pp', 'x', 'bozonnet', 'vinyal', 'speaker', 'review', 'recent', 'research', 'ieee', 'transaction', 'audio', 'speech', 'language', 'processing', 'vol', 'glandon', 'km', 'survey', 'deep', 'neural', 'network', 'speech', 'vision', 'system', 'neurocomputing', 'volume', 'sztahó', 'g', 'szaszák', 'beke', 'deep', 'learning', 'method', 'speaker', 'recognition', 'review', 'electrical', 'engineering', 'computer', 'science', 'vol', 'pp', 'online', 'available', 'snyder', 'mccree', 'g', 'sell', 'dehak', 'p', 'torre', 'carrasquillo', 'n', 'dehak', 'stateoftheart', 'speaker', 'recognition', 'neural', 'network', 'embedding', 'nist', 'speaker', 'wild', 'evaluation', 'computer', 'speech', 'language', 'vol', 'snyder', 'g', 'sell', 'povey', 'xvector', 'robust', 'dnn', 'embedding', 'speaker', 'ieee', 'international', 'conference', 'acoustic', 'speech', 'processing', 'x', 'robust', 'speaker', 'diarization', 'meeting', 'thesis', 'speech', 'processing', 'group', 'theory', 'communication', 'mitianoudi', 'e', 'davy', 'use', 'beamforme', 'audio', 'source', 'separation', 'problem', 'seventh', 'international', 'symposium', 'signal', 'processing', 'application', 'proceeding', 'vol2', 'u', 'klein', 'quốc', 'directionofarrival', 'estimation', 'use', 'microphone', 'array', 'crosscorrelation', 'method', 'ieee', 'international', 'symposium', 'signal', 'processing', 'information', 'technology', 'isspit', 'acoustic', 'source', 'localization', 'base', 'generalized', 'crosscorrelation', 'generalized', 'mean', 'microphone', 'ritz', 'inform', 'source', 'location', 'doa', 'estimation', 'use', 'acoustic', 'room', 'impulse', 'response', 'parameter', 'ieee', 'international', 'symposium', 'signal', 'processing', 'information', 'technology', 'isspit', 'tervo', 'lokki', 'acoustic', 'reflection', 'localization', 'room', 'pp', 'waterschoot', 'brooke', 'base', 'spatial', 'feature', 'proc', 'ieee', 'workshop', 'application', 'signal', 'processing', 'audio', 'acoustic', 'waspaa', 'p', 'p', 'parada', 'naylor', 'nonintrusive', 'estimation', 'level', 'reverberation', 'speech', 'ieee', 'international', 'acoustic', 'speech', 'valente', 'h', 'bourlard', 'speaker', 'diarization', 'acoustic', 'feature', 'stream', 'proc', 'ieee', 'intl', 'conf', 'acoustic', 'speech', 'yoshioka', 'dimitriadi', 'stolcke', 'meeting', 'transcription', 'use', 'virtual', 'microphone', 'array', 'technical', 'report', 'h', 'speech', 'enhancement', 'virtual', 'increase', 'channel', 'maximum', 'snr', 'beamformer', 'advance', 'signal', 'processing', 'issue', 'article', 'g', 'thiergart', 'weller', 'e', 'p', 'habet', 'generate', 'virtual', 'microphone', 'signal', 'use', 'geometrical', 'information', 'gather', 'distribute', 'array', 'joint', 'workshop', 'handsfree', 'speech', 'communication', 'communication', 'microphone', 'array', 'edinburgh', 'implementation', 'virtual', 'microphone', 'array', 'obtain', 'high', 'resolution', 'acoustic', 'image', 'sensor', 'vol', 'p', 'esparza', 'lópezleiva', 'bilingual', 'speech', 'recognition', 'estimate', 'speaker', 'geometry', 'video', 'datum', '19th', 'international', 'conference', 'computer', 'analysis', 'image', 'pattern', 'siemen', 'simcenter', 'sound', 'field', 'free', 'diffuse', 'field', 'far', 'field', 'online', 'available', 'tashev', 'sound', 'capture', 'process', 'practical', 'approach', 'chichester', 'tashev', 'sound', 'capture', 'process', 'practical', 'approach', 'chichester', 'tashev', 'sound', 'capture', 'process', 'practical', 'approach', 'chichester', 'renal', 'bourlard', 'carletta', 'popescubelis', 'multimodal', 'signal', 'processing', 'human', 'interaction', 'meeting', 'press', 'tashev', 'sound', 'capture', 'process', 'practical', 'approach', 'chichester', 'cohen', 'processing', 'modern', 'communication', 'page', 'b', 'gunel', 'measurement', 'processing', 'room', 'impulse', 'online', 'available', 'xie', 'head', 'related', 'transfer', 'function', 'virtual', 'auditory', 'publishing', 'plantation', 'fl', 'pp', 'ever', 'master', 'diazguerra', 'miguel', 'beltran', 'gpurir', 'library', 'room', 'acceleration', 'multime', 'tool', 'appl', 'image', 'method', 'efficiently', 'simulate', 'smallroom', 'acoustic', 'acoustical', 'society', 'wikipedia', 'online', 'available', 'mcloughlin', 'speech', 'audio', 'processing', 'matlabbase', 'approach', 'cambridge', 'page', 'f', 'ever', 'master', 'renal', 'bourlard', 'carletta', 'popescubelis', 'multimodal', 'signal', 'processing', 'human', 'interaction', 'meeting', 'press', 'campos', 'lima', 'veiga', 'filho', 'g', 'adami', 'comparison', 'distance', 'measure', 'cluster', 'international', 'telecommunications', 'symposium', 'doi', 'gopalakrishnan', 'speaker', 'environment', 'channel', 'change', 'detection', 'cluster', 'information', 'criterion', 'proceeding', 'darpa', 'broadcast', 'news', 'transcription', 'understanding', 'workshop', 'z', 'speaker', 'base', 'deep', 'learn', 'overview', 'elsevi', 'journal', 'neural', 'network', 'volume', 'issn', 'online', 'available', 'ghahabi', 'deep', 'learning', 'ivector', 'speaker', 'language', 'recognition', 'phd', 'thesis', 'speech', 'processing', 'group', 'theory', 'communication', 'z', 'bai', 'speaker', 'base', 'deep', 'learn', 'overview', 'elsevi', 'journal', 'neural', 'network', 'volume', 'issn', 'online', 'available', 'deep', 'neural', 'network', 'base', 'ivector', 'mapping', 'speaker', 'verification', 'use', 'short', 'utterance', 'computer', 'speech', 'language', 'volume', 'online', 'available', 'shixiong', 'self', 'supervise', 'learning', 'audiovisual', 'speaker', 'diarization', 'ieee', 'international', 'conference', 'acoustic', 'speech', 'signal', 'processing', 'pp', 'j', 'park', 'p', 'georgiou', 'multimodal', 'speaker', 'segmentation', 'diarization', 'use', 'lexical', 'acoustic', 'cue', 'sequence', 'sequence', 'neural', 'network', 'interspeech', 'l', 'h', 'soltau', 'shafran', 'joint', 'speech', 'recognition', 'speaker', 'diarization', 'sequence', 'transduction', 'interspeech', 'b', 'roy', 'multimodal', 'speaker', 'diarization', 'realworld', 'meeting', 'use', 'dvector', 'spatial', 'feature', 'ieee', 'international', 'conference', 'acoustic', 'speech', 'signal', 'processing', 'amazon', 'aw', 'amazon', 'transcribe', 'online', 'available', 'cloud', 'separate', 'different', 'speaker', 'audio', 'recording', 'online', 'available', 'microsoft', 'azure', 'product', 'documentation', 'speaker', 'online', 'available', 'misal', 'google', 'speech', 'amazon', 'transcribe', 'war', 'speech', 'technology', 'analytic', 'magazine', 'online', 'available', 'speechtechnology', 'saraswat', 'r', 'tripathi', 'cloud', 'compute', 'comparison', 'analysis', 'cloud', 'service', 'providersaw', '9th', 'international', 'conference', 'system', 'modeling', 'advancement', 'research', 'trend', 'smart', 'pp', 'woollacott', 'benchmarke', 'speech', 'technology', 'online', 'available', 'academia', 'voxceleb', 'speaker', 'recognition', 'challenge', 'ieee', 'international', 'conference', 'acoustic', 'speech', 'processing', 'speaker', 'recognition', 'online', 'available', 'tashev', 'sound', 'capture', 'process', 'practical', 'approach', 'chichester', 'r', 'scheibler', 'e', 'dokmanić', 'pyroomacoustic', 'python', 'package', 'audio', 'room', 'simulation', 'array', 'processing', 'algorithm', 'ieee', 'international', 'conference', 'acoustic', 'speech', 'processing', 'pyroomacoustic', 'documentation', 'online', 'available', 'e', 'marin', 'voice', 'activity', 'detection', 'use', 'filter', 'eguaderramaunmedu', 'mcloughlin', 'speech', 'audio', 'processing', 'matlabbase', 'approach', 'cambridge', 'university', 'labview', 'online', 'available', 'labview', 'convolution', 'online', 'available', 'labview', 'deconvolution', 'online', 'available', 'ni', 'labview', 'correlation', 'online', 'available', 'labview', 'crosscorrelation', 'online', 'available', 'waveform', 'tracktion', 'online', 'available', 'galibert', 'methodology', 'evaluation', 'speaker', 'diarization', 'automatic', 'speech', 'recognition', 'presence', 'overlap', 'speech', 'interspeech', 'lightweight', 'library', 'compute', 'diarization', 'error', 'rate', 'der', 'online', 'available', 'audacity', '®', 'software', 'copyright', 'audacity', 'team', 'web', 'site', 'free', 'software', 'distribute', 'term', 'general', 'public', 'license', 'name', 'audacity', '®', 'register', 'trademark', 'p', 'tsp', 'speech', 'version', 'montreal', 'quebec', 'mcgill', 'university', 'department', 'electrical', 'computer', 'engineering', 'telecommunications', 'signal', 'processing', 'laboratory', 'online', 'available', 'mmspecemcgillcadocumentsdata', 'endtoend', 'neural', 'permutationfree', 'objective', 'interspeech']"
Denoised MDPs: Learning World Models Better Than the World Itself,"[{'href': 'http://arxiv.org/abs/2206.15477v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2206.15477v2', 'rel': 'related', 'type': 'application/pdf'}]",2022-06-30 17:59:49,"Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

Edoardo Cetin * 1 Philip J. Ball * 2 Steve Roberts 2 Oya Celiktutan 1

2
2
0
2

l
u
J

3

]

G
L
.
s
c
[

1
v
6
8
9
0
0
.
7
0
2
2
:
v
i
X
r
a

Abstract

Off-policy reinforcement learning (RL) from
pixel observations is notoriously unstable. As
a result, many successful algorithms must com-
bine different domain-speciﬁc practices and auxil-
iary losses to learn meaningful behaviors in com-
plex environments.
In this work, we provide
novel analysis demonstrating that these instabil-
ities arise from performing temporal-difference
learning with a convolutional encoder and low-
magnitude rewards. We show that this new visual
deadly triad causes unstable training and prema-
ture convergence to degenerate solutions, a phe-
nomenon we name catastrophic self-overﬁtting.
Based on our analysis, we propose A-LIX, a
method providing adaptive regularization to the
encoder’s gradients that explicitly prevents the
occurrence of catastrophic self-overﬁtting using
a dual objective. By applying A-LIX, we signiﬁ-
cantly outperform the prior state-of-the-art on the
DeepMind Control and Atari 100k benchmarks
without any data augmentation or auxiliary losses.

1. Introduction

One of the core challenges in real world Reinforcement
Learning (RL) is achieving stable training with sample-
efﬁcient algorithms (Dulac-Arnold et al., 2019). Combining
these properties with the ability to reason from visual obser-
vations has great implications for the application of RL to
the real world (Kalashnikov et al., 2018; Zhu et al., 2020).
Recent works utilizing temporal-difference (TD-) learning
have made great progress advancing sample-efﬁciency (Lil-
licrap et al., 2015; Fujimoto et al., 2018; Haarnoja et al.,
2018a; Cetin & Celiktutan, 2021). However, stability has
remained a key issue for these off-policy algorithms (Sutton,

*Equal contribution 1Centre for Robotics Research, Depart-
ment of Engineering, King’s College London 2Department of
Engineering Science, University of Oxford. Correspondence
to: Edoardo Cetin <edoardo.cetin@kcl.ac.uk>, Philip J. Ball
<ball@robots.ox.ac.uk>.

Proceedings of the 39 th International Conference on Machine
Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy-
right 2022 by the author(s).

Figure 1. Performance of agents in DMC (left) and Atari 100k
(right) benchmarks from 10 seeds. A-LIX outperforms previous
methods without using image augmentations or auxiliary losses.

1988; Duan et al., 2016; Van Hasselt et al., 2018; Bus¸oniu
et al., 2018), making their general applicability limited as
compared to their on-policy counterparts (Schulman et al.,
2017; Cobbe et al., 2021). At the same time, using pixel
observations has been another orthogonal source of insta-
bilities, with several successful approaches relying on pre-
training instead of end-to-end learning (Finn et al., 2015;
Dwibedi et al., 2018). In fact, alternative optimization ob-
jectives, large amounts of simulation data, and symbolic
observations have been common factors in most contempo-
rary large-scale RL milestones (Silver et al., 2017; Vinyals
et al., 2019; Berner et al., 2019).

In this work, we provide novel insights behind why ap-
plying successful off-policy RL algorithms designed for
proprioceptive tasks to pixel-based environments is gener-
ally underwhelming (Lee et al., 2019; Yarats et al., 2021).
In particular, we provide evidence that three key elements
strongly correlate with the occurrence of detrimental insta-
bilities: i) Exclusive reliance on the TD-loss. ii) Unregu-
larized end-to-end learning with a convolutional encoder.
iii) Low-magnitude sparse rewards. Using this framework,
we are able to motivate the effectiveness of auxiliary losses
(Laskin et al., 2020b; Schwarzer et al., 2020; Yarats et al.,
2021) and many domain-speciﬁc practices (Hessel et al.,
2018; Laskin et al., 2020a) by explaining how they address
elements of this new visual deadly triad.

We focus our analysis on the popular DeepMind Control
suite (DMC) (Tassa et al., 2018), where the introduction
of random shift augmentations has played a key role in re-
cent advances (Laskin et al., 2020a; Kostrikov et al., 2021;

DMC Performance

Atari 100K Performance

A-LIX

694.7

A-LIX

SPR

0.752

0.704

DrQ-v2

632.7

SPR (No Augs)

0.463

DrQ

241.2

CURL

262.1

SAC

51.9

DrQ

0.357

CURL

0.381

OTRainbow

0.264

DER

0.285

SimPLe

0.443

0

250

500

0.00

0.25

0.50

0.75

Average Score (Medium + Hard)

Mean Human-Normalized Score

 
 
 
 
 
 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

Table 1. Practices from recent pixel-based TD-learning methods
to mitigate elements of the visual deadly triad. †DrQ uses 10-step
returns on Atari. *CURL uses 20-step returns on Atari.

Algorithm

Visual Deadly Triad Mitigation

TD-Loss

CNN Overﬁt

DrQ/RAD
DrQ-v2
SAC-AE
SPR
DER
CURL

-
-
VAE Loss
Model-Based Loss
-
Contrastive Loss

Shift/Jitter Augmentations
Shift Augmentations
-
Shift/Jitter Augmentations
Non-Overlapping Strides
Shift Augmentations

Low-Density Reward
10-step returns†
3-step returns
-
10-step returns
20-step returns
20-step returns*

Yarats et al., 2022). In this domain, we observe that the
presence of the visual deadly triad results in the TD-loss
gradients through the convolutional encoder’s feature maps
having high spatial frequencies. We ﬁnd these gradients are
spatially inconsistent and result in degenerate optimization
landscapes when backpropagated to the encoder’s param-
eters. Furthermore, repeatedly updating the convolutional
encoder with these gradients consistently leads to early con-
vergence to degenerate feature representations causing the
critic to ﬁt high-variance erroneous targets, a phenomenon
we name catastrophic self-overﬁtting. As a way of iden-
tifying the direct implications of the visual deadly triad
in the gradient signal, we propose a new measure called
the Normalized Discontinuity (ND) score and show how its
value precisely correlates with agent performance. Thus, we
explain the effectiveness of shift augmentations by recog-
nizing that they regularize the gradient signal by providing
an implicit spatial smoothing effect.

Based on our analysis, we propose Adaptive Local SIgnal
MiXing (A-LIX) a novel method to prevent catastrophic
self-overﬁtting with two key components: i) A new parame-
terized layer (LIX) that explicitly enforces smooth feature
map gradients. ii) A dual objective that ensures learning sta-
bility by adapting the LIX parameters based on the estimated
ND scores. We show that integrating A-LIX with existing
off-policy algorithms achieves state-of-the-art performance
in both DeepMind Control and Atari 100k benchmarks with-
out requiring image augmentations or auxiliary losses and
signiﬁcantly fewer heuristics. We open-source our code to
facilitate reproducibility and future extensions1.

Our main contribution can be summarized as follows:

• We conjecture the existence of a visual deadly triad as
a principal source of instability in reinforcement learn-
ing from pixel observations and provide clear empirical
evidence validating our hypothesis.

• We show these instabilities affect the gradient signal
causing catastrophic self-overﬁtting, a phenomenon
that can severely harm TD-learning. As a result, we
design the normalized discontinuity score to explicitly

1https://github.com/Aladoro/Stabilizing-Off-Policy-RL

Figure 2. Returns of agents over 5 seeds. Solid lines represent
median performance, faded lines represent individual runs. The
vertical dashed line shows when augmentations are turned off.

anticipate its occurrence.

• We propose A-LIX, a new method that adaptively reg-
ularizes convolutional features to prevent catastrophic
self-overﬁtting, achieving state-of-the-art results on
two popular pixel-based RL benchmarks.

2. Background

We consider problem settings described by Markov Deci-
sion Processes (MDPs) (Bellman, 1957), deﬁned as the tuple
(S, A, P, p0, r, γ). This comprises a state space S, an action
space A, transitions dynamics given by P and p0, and a re-
ward function r. The RL objective is then for an agent to re-
cover an optimal policy π∗, yielding a distribution of trajec-
tories pπ(τ ) that maximizes its expected sum of discounted
future rewards, π∗ = arg maxπ Epπ(τ ) [(cid:80)∞
t=0 γtr(st, at)].
In off-policy RL, this objective is usually approached by
learning a critic function to evaluate the effectiveness of the
agent’s behavior. A common choice for the critic is to param-
eterize the policy’s Q-function Qπ : S × A → R, that quan-
tiﬁes the agent’s performance after performing a particular
action: Qπ(s, a) = Epπ(τ |s0=s,a0=a) [(cid:80)∞
t=0 γtr(st, at)].
Most off-policy algorithms entail storing trajectories in a
buffer D, and learning parameterized Q-functions by itera-
tively minimizing a squared temporal difference (TD-) loss:

JQ(φ) = E(s,a,s(cid:48),r)∼D

(cid:2)(Qπ

φ(s, a) − y)2(cid:3) ,
(cid:105)
(cid:104) ˆQπ
φ(cid:48)(s(cid:48), a)
.

y = r + γEa∼π(s(cid:48))

(1)

Here, the TD-targets y are computed from a 1-step bootstrap
operation with a slowly-changing target Q-function ˆQπ
φ(cid:48). In
continuous action spaces, we also learn a separate parame-
terized policy to exploit the information in the critic. This
practically results in alternating TD-learning with maximiz-
ing the Q-function’s expected return predictions, following
the policy gradient theorem (Sutton et al., 2000).

3. Instabilities in TD-Learning from Pixels

Unlike proprioceptive observations, off-policy RL from
pixel observations commonly requires additional domain-

Cheetah Run

Augs Turned Off

500

n
r
u
t
e
R

0

0

Augs

1

2

Frames (×106)
No Augs

3

No Augs @ 500k

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

Figure 3. Evidence of overﬁtting when augmentations are not used.
On the left, shaded lines are individual estimates, the solid line
represents the median Q-value. On the right, the Q-values Pearson
correlation with target values and Monte-Carlo returns (RM C ).

Figure 4. TD-loss of ofﬂine ﬁxed transitions during training, sepa-
rated based on having non-zero reward.

complementary experiments validating these claims).

speciﬁc practices to ensure stability. In this section, we
provide a novel analysis of this phenomenon by focusing
on the DeepMind Control Suite (Tassa et al., 2018). In this
benchmark, the introduction of random shift data augmen-
tations has been a core component of recent advances in
pixel-based off-policy RL (Laskin et al., 2020a; Yarats et al.,
2022), allowing us to isolate and reproduce stable and un-
stable training regimes. Our analysis suggests the existence
of speciﬁc elements that cause instabilities and strives to
explain their implications on learning dynamics. We vali-
date our ﬁndings via thorough empirical experimentation
showing numerous results corroborating our hypotheses.
Based on our discoveries, in Section 4 we provide a new
interpretation of random shifts and propose a new improved
method to isolate and counteract instabilities.

3.1. Why Do Augmentations Help?

The underlying mechanism behind the effectiveness of ran-
dom shifts is not immediately clear. While this augmen-
tation may appear to assist generalization by encoding an
invariance (Shorten & Khoshgoftaar, 2019), we note that all
the environments from DMC employ a camera that is ﬁxed
relative to the agent’s position. Hence, robustness to shifts
does not appear to introduce any useful inductive bias about
the underlying tasks. Moreover, prior work successfully
learned effective controllers without augmentations (Hafner
et al., 2020; Yarats et al., 2021), suggesting that shift gen-
eralization might not be the primary beneﬁt of this method.
We analyze the effect of random shifts by training a DrQ-v2
agent (Yarats et al., 2022) on Cheetah Run but turning off
augmentations after an initial 500,000 time-steps learning
phase. As shown in Fig. 2, while training without any shift
augmentation fails to make consistent progress, turning off
augmentations after the initial learning phase actually ap-
pears to slightly improve the performance of DrQ-v2. This
result is a clear indication that augmentations are not needed
for asymptotic performance, and are most helpful to coun-
teract instabilities present in the earlier stages of learning,
which we now focus on analyzing (see App. F.1-F.2 for

3.2. Identifying a New Deadly Triad

To reduce confounding factors and to disentangle the origin
of these instabilities, we design an ofﬂine RL experiment
(Levine et al., 2020). This experiment isolates three distinct
elements affecting off-policy RL: exploration, policy eval-
uation, and policy improvement. First, we gather a set of
15,000 transitions with pixel observations using a random
policy in Cheetah Run. This allows us to ground explo-
ration and analyze learning from ﬁxed data resembling the
early stages of online training (when augmentations appear
most helpful). We then isolate policy evaluation by training
both critic and encoder using SARSA (Rummery & Niran-
jan, 1994) until convergence on this ﬁxed data. Finally, we
run policy improvement, training an actor to maximize the
expected discounted return as predicted by the converged
critic (see App. B.1 for details). Interestingly, we ﬁnd that
turning on augmentations exclusively during exploration
or policy improvement has no apparent effect on stability
and ﬁnal performance. Hence, we focus on the effects that
augmentations have on TD-learning and analyze applying
augmentations only during policy evaluation.

Table 2. Performance and training statistics of different agent types
in the ofﬂine experiments from 15,000 random transitions.

Agent

Augmented
Non-Augmented

Proprioceptive
Frozen CNN (random)
Frozen CNN (pre-trained)

Non-Augmented (norm r)
Non-Augmented (10-step returns)

Final TD-Loss Final Policy Loss

Return

0.021
0.002

0.012
0.023
0.012

18.616
0.003

−0.99
−1.05

−1.14
−0.95
−0.99

3.86
−1.24

86.5 ± 11.3
9.2 ± 12.1

79.1 ± 7.7
43.6 ± 20.2
77.6 ± 18.5

38.6 ± 16.5
36.5 ± 20.3

As shown in Table 2, applying augmentations during pol-
icy evaluation enables us to learn policies that achieve a
return of 86.5, despite the best trajectory in the ofﬂine data
achieving only 10.8. In contrast, without augmentations we
consistently recover near 0 returns, resembling the failures
observed in the online experiments. On the left of Fig. 3
we show the evolution of the predicted Q-values for both

Q values during training

No Augs
Augs

2.0

1.5

1.0

0.5

0.0

l

s
e
u
a
V
Q

Corr. of Q with Qtarget and RMC
1.0

l

n
o
i
t
a
e
r
r
o
C

n
o
s
r
a
e
P

0.8

0.6

0.4

0.2

0.0

Qtarget
RMC

0

2500

5000
SGD Steps

7500

0

2500

5000
SGD Steps

7500

 
 
Zero reward samples

Non-Zero reward samples

No Augs
Augs

r
o
r
r
E
D
T

1.00

0.75

0.50

0.25

0.00

0

2000

4000
SGD Steps

6000

8000

0

2000

4000
SGD Steps

6000

8000

 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

agents on a ﬁxed batch of ofﬂine data. In particular, when
performing policy evaluation without augmentations, these
predictions display extremely high variance across different
state-action pairs. In Table 2 we further show that the non-
augmented agent displays signiﬁcantly lower loss, despite
having higher average Q-values than the augmented agent
(Schaul et al., 2021). We argue this is a clear indication of
the occurrence of overﬁtting. We corroborate our claim by
analyzing the evolution of the Pearson bi-variate correlation
between the estimated Q-values and target Q-values on the
right of Fig. 3. These results show that the non-augmented
agent displays near-perfect correlation with its own target
Q-values throughout training, indicating that it immediately
learns to ﬁt its own noisy, randomly-initialized predictions.
We also record the correlation with the actual discounted
Monte-Carlo returns, which represent the true targets the
Q-values should ideally approximate during policy evalu-
ation. For these results, we observe that the relationship
between applying augmentations and the recorded correla-
tion is reversed, with the non-augmented agent displaying
signiﬁcantly lower correlation. This dichotomy appears to
indicate that ﬁtting the noisy targets severely affects learn-
ing the useful training signal from the collected transitions
regarding the experienced rewards. We conﬁrm this phe-
nomenon by splitting the data into non-zero and zero reward
transitions, where the only learning signal propagated in
the TD-loss is from the initially random target values. In
Fig. 4 we illustrate that the non-augmented agents initially
experience much higher TD-errors on zero reward transi-
tions, conﬁrming that they focus on ﬁtting uninformative
components of the TD-objective.

In Table 2 we provide the results of additional experiments
that indicate that TD-learning is not the only cause for
the observed instabilities. First, we conﬁrm that the ob-
served overﬁtting appears to be exclusive to performing
end-to-end TD-learning with convolutional neural network
(CNN) encoders. Concretely, we run the same ofﬂine exper-
iment without training an encoder in three different settings.
First, we consider performing policy evaluation directly
from non-augmented proprioceptive observations with a
fully-connected critic network. Moreover, we also consider
freezing the encoder weights either to their initial random
values or to pre-trained values from the augmented agent
experiments. In all three cases, we attain largely superior
performance, almost matching the augmented agent’s per-
formance for both the proprioceptive and pre-trained exper-
iments. In addition, we also ﬁnd that the observed over-
ﬁtting phenomenon is diminished when simply increasing
the magnitude of the reward signal in the TD-loss. We
test this through two additional experiments which consider
normalizing the collected rewards before policy evaluation
and incorporating large n-step returns (Sutton, 1988). As
reported, both modiﬁcations considerably improve the non-

Figure 5. Feature maps in the ﬁnal layer of both augmented (top)
and non-augmented (bottom) agent encoders. Non-augmented
agents manifest inconsistent, high-frequency feature maps.

augmented agent’s performance. However, we note that
both practices introduce further unwanted variance in the
optimization, failing to yield the same improvements as
augmentations (see App. C.2).

Taken together, our results appear to strongly indicate that
instabilities in off-policy RL from pixel observation come
from three key conditions, which we refer to as the visual
deadly triad: i) Exclusive reliance on the TD-loss; ii) Un-
regularized learning with an expressive convolutional en-
coder; iii) Initial low-magnitude sparse rewards. Further
evidence arises when considering the ubiquity of partic-
ular practices employed in pixel-based off-policy RL. In
particular, as summarized in Table 1, most popular prior
algorithms feature design choices that appear to counteract
at least two elements of this triad, either directly or implic-
itly. Furthermore, we show these instabilities result in the
non-augmented critics focusing on learning their own noisy
predictions, rather than the actual experienced returns. We
observe this ultimately leads to convergence to erroneous
and high-variance Q-value predictions, a phenomenon we
name catastrophic self-overﬁtting.

3.3. Anticipating Catastrophic Self-Overﬁtting

We now attempt to unravel the links that connect the visual
deadly triad with catastrophic self-overﬁtting. We start by
observing that catastrophic self-overﬁtting comes with a
signiﬁcant reduction of the critic’s sensitivity to changes
in action inputs, implying that the erroneous high-variance
Q-value predictions arise primarily due to changes in the
observations (see App. F.3 for action-value surface plots).
Hence, we focus on analyzing the feature representations of
the pixel observations, computed by the convolutional en-
coder, z ∈ RC×H×W . In particular, we wish to quantify the
sensitivity of feature representations to small perturbations
in the input observations. To measure this, we evaluate the
Jacobians of the encoder across a ﬁxed batch of ofﬂine data
for the augmented and non-augmented agents. We then cal-
culate the Frobenius norm of each agent’s Jacobians, giving
us a measure of how quickly the encoder feature represen-

Augmented Final Feature Map

Non-augmented Final Feature Map

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

overﬁtting (Keskar et al., 2017) 2.

To quantify the level of discontinuity in the features and
their gradients, we propose a new metric that encodes the
aggregated immediate spatial ‘unevenness’ of each feature
location within its relative feature map. In particular, we
deﬁne D(z) ∈ RC×H×W as the expected squared local
discontinuity of z in any spatial direction, i.e.:
(cid:19)2(cid:35)

D(z)ijc ≈ Ev∼S1

,

(2)

(cid:34)(cid:18) ∂zijc
∂v

practically estimated via sampling. We then normalize each
value in D(z) by its squared input and average over all
the feature positions. We name this metric the normalized
discontinuity (ND) score:

ND(z) =

1
C × H × W

C
(cid:88)

H
(cid:88)

W
(cid:88)

c=1

j=1

i=1

D(z)ijc
z2
ijc

.

(3)

Intuitively, this score reﬂects how locally discontinuous z
is expected to be at any spatial location. In Fig. 7, we show
how the N D score of ∇z evolves during training in the
ofﬂine and an online setting for both augmented and non-
augmented agents. We see that augmented agents experi-
ence considerably less discontinuous gradients through their
features, and that recordings of lower N D scores also ap-
pear to be highly correlated with performance improvements.
We additionally show an accumulated N D score, using an
exponential moving average of ∇z in each spatial position
to calculate this metric. Interestingly, we observe that the
N D score over accumulated gradients is almost identical to
the instantaneous N D score, showing that similar gradient
discontinuities are propagated persistently through training
in each position of the feature map. This property conﬁrms
that the discontinuities are not smoothed by the stochastic
sampling of different consecutive training batches, in which
case we would expect to observe lower accumulated N D
scores. Thus, it suggests that self-overﬁtting emerges in
the non-augmented agents due to repeated gradient steps
towards persistent feature map discontinuities.

4. Counteracting Gradient Discontinuities

4.1. Gradient Smoothing and Random Shifts

As analyzed in Section 3, catastrophic self-overﬁtting oc-
curs when the gradients in the convolution layers are locally
discontinuous. As a result, we argue that the efﬁcacy of
random shifts arises from their downstream effect on feature
gradient computation, which counteracts these discontinu-
ities during backpropagation. In particular, while random
shifts do not act directly on the latent representation or their

2Instead, the loss surface with respect to the fully-connected

weights is smoother (App. F.5).

Figure 6. Critic loss surface plots of augmented (left) and non-
augmented (right) agents after 5,000 steps of ofﬂine training.

tations are changing locally around an input (see App. B.2
for details). Our results show a stark difference, with the
feature representations of the non-augmented agents being
on average 2.85 times more sensitive. This suggests that
overﬁtting is driven by the CNN encoder’s representations
learning high-frequency information about the input obser-
vations and, thus, breaking useful inductive biases about
this class of models (Rahaman et al., 2019).

In App. E.1 we demonstrate that lower sensitivity to ran-
dom noise, while desirable for optimization (Rosca et al.,
2020), is actually a byproduct of a stable feature represen-
tations, and not its deﬁning factor. Furthermore, observing
the actual feature maps of different observations in Fig. 5,
we see that augmentations make the encoder produce fea-
tures that are spatially consistent, aligned with common
understandings of how natural representations should ap-
pear (Alsallakh et al., 2021; Allen-Zhu & Li, 2021). In
contrast, the non-augmented agents display high-frequency
and discontinuous feature maps that do not reﬂect the spa-
tial properties of their inputs. Hence, our evidence suggests
that catastrophic self-overﬁtting speciﬁcally follows from
the same learning process that produces highly-sensitive
and discontinuous encoder feature maps. Therefore, we
turn our focus to analyzing the gradients backpropagated
to the encoder’s features maps and observe one key prop-
erty: the gradients of the output feature maps consistently
reﬂect the same spatial properties of their resulting features.
In particular, the gradients of the feature maps appear spa-
tially consistent for the augmented agent, and discontinuous
for the non-augmented agent. This optimization property
reﬂects intuitive understandings of backpropagation since
discontinuous gradients should push the encoder’s weights
to encode discontinuous representations. To provide further
complementary evidence that discontinuous gradients are
the direct cause of catastrophic self-overﬁtting, we analyze
the normalized loss surfaces when backpropagating these
discontinuous gradients to the encoder’s parameters (fol-
lowing Li et al. (2018)). In Fig. 6, we see that gradient
discontinuities in the non-augmented agent yield extreme
peaks in its encoder’s loss surface, clearly suggestive of

Critic with Augmentations

Critic w/o Augmentations

s
s
o
L
D
T

0.75

0.50
0.25

1

0

W eig ht S u bsp ace 2

1

0.75
0.50
0.25

1

0.75

0.50

0.25

0

TD Loss

1

0

1

1

1

0

Weight Subspace 1

1

 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

persistent discontinuities from accumulating. Hence, ran-
dom shifts break the second condition of the visual deadly
triad, by providing effective implicit regularization of the
convolutional encoder’s learning process. At the same time,
this minimally disrupts the information content of the re-
sultant features, since discarded observation borders almost
exclusively comprise background textures that are irrele-
vant for performing the task. This interpretation of random
shifts aligns with the analysis in Section 3, showing that im-
plicitly smoothing over the backpropagated gradient maps
consistently prevents catastrophic self-overﬁtting.

4.2. Local Signal Mixing

We extrapolate our hypotheses about catastrophic self-
overﬁtting and random shifts by proposing a technique that
aims to enforce gradient smoothing regularization explic-
itly. We propose Local SIgnal MiXing, or LIX, a new layer
speciﬁcally designed to prevent catastrophic self-overﬁtting
in convolutional reinforcement learning architectures. LIX
acts on the features produced by the convolutional encoder,
z ∈ RC×H×W , by randomly mixing each component zcij
with its neighbors belonging to the same feature map. Hence,
LIX outputs a new latent representation with the same di-
mensionality ˆz ∈ RC×H×W , whose computation graph
minimally disrupts the information content of each feature
zcij while smoothing discontinuous components of the gra-
dient signal during backpropagation.

LIX is a regularization layer that acts as a simple random
smoothing operation, reducing the expected magnitude of
gradient discontinuities by preventing higher frequency sig-
nals to persist. In the forward pass, LIX produces a new
latent representation where for each of the C feature maps,
ˆzcij is computed as a randomly weighted average of its
spatial neighbors around coordinates i, j. We further param-
eterize this stochastic operation using some maximum range
radius S, and consequently sample two uniform continuous
random variables δx, δy ∼ U [−S, S], representing shifts
in the x and y coordinates respectively. Correspondingly,
we deﬁne ˜i = i + δx and ˜j = j + δy and perform the
weighted averaging as a bilinear interpolation with weights
determined by the random shifts:

ˆzcij =zc(cid:98)˜i(cid:99)(cid:98)˜j(cid:99)((cid:100)˜i(cid:101) − ˜i)((cid:100)˜j(cid:101) − ˜j) + zc(cid:98)˜i(cid:99)(cid:100)˜j(cid:101)((cid:100)˜i(cid:101) − ˜i)(˜j − (cid:98)˜j(cid:99))
+zc(cid:100)i(cid:101)(cid:98)˜j(cid:99)(˜i − (cid:98)˜i(cid:99))((cid:100)˜j(cid:101) − ˜j) + zc(cid:100)i(cid:101)(cid:100)˜j(cid:101)(˜i − (cid:98)˜i(cid:99))(˜j − (cid:98)˜j(cid:99)).

Since nearby features in a convolutional feature map are
computed with very similar receptive ﬁelds, the mixing
effect of LIX should have a trivial effect on the informa-
tion the encoder can convey in its latent representations.
In addition, LIX should have a direct regularization ef-
fect on the gradients by acting on the feature maps them-
selves.
In particular, since LIX computes each output
feature from a weighted average of its neighbors, back-

Figure 7. Instantaneous (red and blue) and accumulated (orange
and purple) N D scores for the features gradients from ofﬂine (left)
and online (right) training in Cheetah Run.

respective gradients, they do affect how the latent represen-
tations are computed. This has an impact on how persistent
discontinuous components of the gradient are backpropa-
gated to the encoder’s parameters during learning. From
the approximate shift invariance of convolutional layers,
we can view a convolutional encoder as computing each
of the feature vectors [z1ij, ..., zCij]T with the same param-
eterized function, Vφ, that takes as input a subset of each
observation O ∈ RC(cid:48)×H (cid:48)×W (cid:48)
. This subset corresponds to a
local neighborhood around some reference input coordinates
i(cid:48), j(cid:48). Thus, the only factor differentiating features in the
same feature map (e.g., zcij and zckl) is some implicit func-
tion f (i, j) = i(cid:48), j(cid:48) translating each of the output features
coordinate into the relative reference input coordinate, i.e.
zcij = Vφ(O, i(cid:48), j(cid:48))c (determined by kernel sizes, strides...).
Therefore, random shifts are approximately equivalent to
further translating each reference coordinate by adding some
x, δ(cid:48)
uniform random variables δ(cid:48)
y:

zcij ≈ Vφ(O, i(cid:48) + δ(cid:48)
y ∼ U [−s(cid:48), s(cid:48)],
x, δ(cid:48)
δ(cid:48)

x, j(cid:48) + δ(cid:48)

y)c,
f (i, j) = i(cid:48), j(cid:48).

where

Due to the employed strides from the convolutional archi-
tectures used in DrQ-v2 (Yarats et al., 2022), the difference
in reference coordinates of adjacent features in a feature
map is less than the maximum allowable shift employed
in the augmentations, i.e., (i + 1)(cid:48) − i(cid:48), (j + 1)(cid:48) − j(cid:48) < s(cid:48)
(where s(cid:48) is the maximum allowable shift). Consequently,
shift augmentations effectively turn the deterministic com-
putation graph of each feature zcij into a random variable,
whose sample space comprises the computation graphs of
all nearby features within its feature map. Hence, applying
different random shifts to samples in a minibatch makes the
gradient of each feature ∇zcij backpropagate to a random
computation graph, sampled from a set that extends the
set of non-augmented computation graphs for all features
in a local neighborhood of coordinates i, j. Therefore, ag-
gregating the parameter gradients produced with different
δ(cid:48)
x, δ(cid:48)
y, provides a smoothing effect on how each discon-
tinuous component of ∇z affects learning, and prevents

Offline

Online

e
r
o
c
S
D
N

2.2

2.0

1.8

1.6

0

5000
SGD Steps

2.0

1.5

1.0

10000

0.0

0.5

1.0

1.5

No Augs
No Augs (Accumulated)

Frames (×106)

Augs
Augs (Accumulated)

 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

propagation will split each gradient ∇ˆzcij, to a random
local combination of features within the same feature map,
{∇zc(cid:98)˜i(cid:99)(cid:98)˜j(cid:99), ∇zc(cid:98)˜i(cid:99)(cid:100)˜j(cid:101), ∇zc(cid:100)i(cid:101)(cid:98)˜j(cid:99), ∇zc(cid:100)i(cid:101)(cid:100)˜j(cid:101)}. Thus, LIX
should mostly preserve the consistent component of ∇z,
while randomly smoothing its discontinuous component.

There are multiple key differences between the regulariza-
tion from LIX and random shifts. LIX provides a local
smoothing effect over the gradients explicitly and exactly,
without having to deal with the implications of padding
and strided convolutions breaking shift-invariance assump-
tions. Moreover, LIX smooths the gradient signal not only
across different inputs but also within each feature map.
In addition, by applying its operation solely at the feature
level, the encoder can still learn to entirely circumvent LIX’s
smoothing effect on the information encoded in the latent
representations, given enough capacity. This means that
LIX does not forcibly preclude any input information from
affecting the computation. Consequently, LIX also does not
have to enforce learning invariances which might not neces-
sarily reﬂect useful inductive biases about the distribution
of observations. In contrast, random shifts need to exploit
the particular uninformativeness of the observations borders
to avoid disrupting the features’ information content.

4.3. A-LIX

LIX introduces a single key parameter: the range radius S
used for sampling δx and δy. Intuitively, this value should
reﬂect how much we expect gradients to be locally consis-
tent for a given architecture and task. Therefore, we argue
that the value of S should ideally decrease throughout train-
ing as the useful learning signal from the TD-loss becomes
stronger. This is consistent with the results illustrated in
Figure 2, showing that turning off random shift augmenta-
tions after the TD-targets become informative can improve
learning. Hence, we propose an adaptive strategy to learn S
throughout training. Utilizing the normalized discontinuity
(N D) score in Section 3.3, we set up a dual optimization
objective to ensure a minimum value of local smoothness in
the representation gradients, N D. However, computing the
N D score of the gradient signal involves a ratio between po-
tentially very small values. As a result, estimation of these
values from a batch of gradient samples can lead to outliers
having an extreme impact on this average measure, trans-
lating into large erroneous updates of S. To overcome this,
we propose using a slightly modiﬁed version of the N D
score with increased robustness to outliers (see App. C.1 for
further details):

(cid:103)N D(∇ˆz) =

C
(cid:88)

H
(cid:88)

W
(cid:88)

(cid:32)

log

1 +

c=1

j=1

i=1

(cid:33)

D(∇ˆz)cij
∇ˆz2

ijc

.

(4)

In practice, we set up a dual optimization objective similar
to the automatic temperature adjustment from Haarnoja et al.

Figure 8. A-LIX’s S parameter evolution during training in Chee-
tah Run (left) and Quadruped Run (right). As the critic targets
become more informative, S falls, improving data efﬁciency and
asymptotic performance.

(2018b). This entails alternating the optimization of the TD-
learning objectives described in Section 2 with minimizing
a dual objective loss:

(cid:104)

−S × Eˆz

(cid:103)N D(∇ˆz) − N D

(cid:105)

,

(5)

arg min
S

approximating dual gradient descent (Boyd et al., 2004).
Hence, we call this new layer Adaptive LIX (A-LIX). In
Fig. 8 we show that A-LIX effectively anneals S as the agent
escapes its unstable regimes, in line with our intuition.

5. Performance Evaluation

We evaluate the effectiveness of A-LIX in pixel-based re-
inforcement learning tasks in two popular and distinct do-
mains featuring a diverse set of continuous and discrete
control problems. We integrate A-LIX with existing popu-
lar algorithms and compare against current state-of-the-art
model-free baselines. We provide further details of our
integration and full hyperparameters in App. D. We also
extend this section by providing more granular evaluation
metrics in App. A. Furthermore, we provide ablation studies
analyzing different components of A-LIX in App. E.

5.1. DeepMind Control Evaluation

We ﬁrst evaluate the effectiveness of A-LIX for pixel-based
RL on continuous control tasks from the DeepMind Control
Suite (DMC) (Tassa et al., 2018). Concretely, we integrate
A-LIX with the training procedure and network architecture
from DrQ-v2 (Yarats et al., 2022), but without using image
augmentations. To show the generality of our method we do
not modify any of the environment-speciﬁc hyperparameters
from DrQ-v2 and simply add our A-LIX layer after each
encoder nonlinearity. For simplicity, we optimize a shared
S for all the A-LIX layers with the dual objective in Eq. 5.
Hence, this introduces a single additional parameter and
negligible computational overhead. We compare A-LIX to
DrQ-v2, which represents the current state-of-the-art on this
benchmark. We also compare against three further baselines:
the original DrQ (Kostrikov et al., 2021), which foregoes n-
step returns and includes an entropy bonus; CURL (Laskin
et al., 2020b), which includes an auxiliary contrastive ob-

500

n
r
u
t
e
R

0

0.0

Cheetah Run

Quadruped Run

2

1

700

600

500

0.7

l

e
u
a
V

0.6

S

0.5

X
I
L
-
A

1.0

0.5
Frames (×106)

1.5

Agent Return

1.5

2.0

2.5

3.0

Frames (×106)
A-LIX Parameter S

 
 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

Table 3. Results summary for the Atari 100k benchmark. The
reported performance of A-LIX is from 10 seeds.

Metrics

SimPLe DER OTRainbow CURL DrQ SPR A-LIX

Norm. Mean
0.443 0.285
Norm. Median 0.144 0.161

# SOTA
# Super
Average Rank

7
2
3.92

1
2
5.00

0.264
0.204

1
1
5.21

0.381 0.357 0.704 0.753
0.175 0.268 0.415 0.411

1
2

1
2
3.92 4.85 2.88

4
7

11
7
2.21

Figure 9. Average performance in 10 seeds for DMC Medium (left)
and Hard tasks (right). Shaded regions represent ±1 SE.

jective; an extension of SAC (Haarnoja et al., 2018b) with
the encoder from Yarats et al. (2021). These last three base-
lines have been performant on a prior DMC benchmark that
considers fewer tasks with high action repeats, as described
by Hafner et al. (2019). Instead, we evaluate on the more
challenging ‘Medium’ and ‘Hard’ benchmarks from Yarats
et al. (2022), comprising 15 tasks with low action repeats.

Results. We summarize the results in Figure 9, showing the
mean performance curves for both medium and hard bench-
mark tasks. We provide further details and the full list of
results across all 15 environments in App. A.1. Overall, A-
LIX surpasses all prior methods with clear margins, both in
terms of efﬁciency and ﬁnal performanc. This is particularly
notable in the more complex ‘Hard’ tasks. As highlighted in
prior work (Cetin & Celiktutan, 2021), DrQ-v2 appears to
yield inconsistent results on some of the harder exploration
tasks with sparse rewards. This likely indicates that the
gradient regularization induced by random shifts (described
in Section 4.1) is unable to consistently prevent catastrophic
self-overﬁtting in scenarios where the initial learning signal
from TD-learning is particularly low. Finally, DrQ, CURL,
and SAC fail to make consistent meaningful progress on
this harder benchmark. This performance gap corroborates
the third component of the visual deadly triad, showing
how lower magnitude rewards due to harder exploration and
lower action-repeats further destabilize TD-learning based
algorithms, and explains the gains seen in DrQ-v2 when
incorporating n-step returns. We believe these results em-
phasize the challenge of overcoming the visual deadly triad
in continuous control problems and the particular effective-
ness of A-LIX to counteract its direct implications.

5.2. Atari 100k Evaluation

We perform a second set of experiments in an entirely dif-
ferent setting, discrete control. We make use of the popular
Atari Learning Environment (ALE) (Bellemare et al., 2013)
and consider the 100k evaluation benchmark from Kaiser
et al. (2020). In particular, this benchmark comprises eval-
uating performance for 26 tasks after only two hours of
play-time (100k interaction steps), following the evaluation

protocol in Machado et al. (2018). We integrate A-LIX with
Data-Efﬁcient Rainbow (DER) (van Hasselt et al., 2019),
a simple extension to Rainbow (Hessel et al., 2018) with
improved data-efﬁciency. We would like to note that our
integration has key differences to DER, designed to high-
light the generality of our method in tackling the visual
deadly triad. In particular, we reduce the n-step returns to 3
(from 20), and we maintain the same encoder architecture
as in DrQ-v2. To speak to the latter point, this means we
do not require the highly regularized encoders with large
convolutional ﬁlters and strides, used ubiquitously in off-
policy learning for Atari environments. Instead, to stabilize
learning we simply apply our A-LIX layer after the ﬁnal
encoder nonlinearity. We compare against three algorithms
that, like A-LIX, do not employ data-augmentation: Data-
Efﬁcient Rainbow (DER); Overtrained Rainbow (OTRain-
bow) (Kielak, 2019); and Simulated Policy Learning (Sim-
PLe) (Kaiser et al., 2020) (model-based). Moreover, we also
compare with additional state-of-the-art off-policy baselines
that make use of data augmentations: the aforementioned
CURL and DrQ; and Self-Predictive Representations (SPR)
(Schwarzer et al., 2020), the current state-of-the-art TD-
learning based algorithm on this benchmark. SPR combines
data augmentation with numerous additional algorithmic
design choices, such as an auxiliary self-supervised loss for
learning a latent dynamics model.

Results. We summarize the results in Table 3, showing
the mean and median human-normalized scores together
with the number of environments where each algorithm ei-
ther achieves state-of-the-art or super-human performance.
We include the full per-environment results in App. A.2.
Remarkably, A-LIX obtains a substantially higher human-
normalized mean performance than all other considered
algorithms. While the recorded normalized median per-
formance is slightly inferior to SPR, we argue that such
difference is not particularly signiﬁcant since this metric de-
pends on the performance obtained in just two environments.
Moreover, A-LIX achieves super-human performance in 7
games (the same as SPR), and state-of-the-art performance
in 11 games, considerably more than all other algorithms.
These results corroborate how tuned architectures, data aug-
mentation, and auxiliary losses used on ALE mostly serve
the purpose of counteracting the direct implications of the
visual deadly triad and show that A-LIX enables us to learn

DMC Medium Tasks

DMC Hard Tasks

n
r
u
t
e
R

600

400

200

0

0

600

400

200

0

1

2

3

0

1

2

3

Frames (×106)

Frames (×107)

A-LIX

DrQ-v2

CURL

DrQ

SAC

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

(a) DeepMind Control: Medium and Hard Tasks

(b) Atari 100k

Figure 10. Probability of improvement and performance proﬁles obtained from the recorded results in DMC (left) and Atari 100k (right).
A-LIX displays statistically signiﬁcantly improvements and stochastically dominates most prior algorithms.

powerful models without relying on these design choices.

5.3. Statistical Signiﬁcance

To validate the signiﬁcance of our improvements, we sta-
tistically analyze our results using the Rliable tools and
practices from Agarwal et al. (2021). We summarize some
of our key ﬁndings in Fig. 10, showing the probability of
improvements of A-LIX over prior methods (computed with
the Mann-Whitney U statistic (Mann & Whitney, 1947))
and the relative normalized performance proﬁles (Dolan &
Mor´e, 2002). The ranges correspond to 95% stratiﬁed boot-
strap conﬁdence intervals (Efron, 1992). In both DMC and
Atari benchmarks, we ﬁnd that our improvements are sta-
tistically signiﬁcant (lower conﬁdence intervals >0.5) and
observe ‘stochastic dominance’ of our algorithm against
almost all considered baselines (Dror et al., 2019). We pro-
vide further results and details of the employed statistical
analysis in App. A.1 and App. A.3 respectively.

6. Related Work

Previous works have characterized several optimization is-
sues related to performing RL via TD-learning (Baird &
Moore, 1998; Baird, 1999). In this work, we instead fo-
cus on the empirical analysis of modern TD-learning al-
gorithms, speciﬁc to the pixel-based RL setting. We also
observe links with recent work studying observational over-
ﬁtting (Song et al., 2020). Our work differs by focusing
on memorization effects particular to the combination of
CNNs and TD-learning. There are also connections with
existing feature-level augmentation work, such as Dropout
(Srivastava et al., 2014) and DropBlock (Ghiasi et al., 2018).
In particular, the latter also applies structured transforma-
tions directly to the feature maps and introduces a heuristic
to adjust this transformation over training, validating our
ﬁndings on the utility of adaptivity. Outside RL, there is a
rich body of work on implicit regularization and memoriza-
tion in CNNs (Keskar et al., 2017; Neyshabur et al., 2017;
Arpit et al., 2017; Liu et al., 2020; Maennel et al., 2020).
Rahaman et al. (2019) show that higher frequency data man-
ifolds cause CNNs to learn higher spectral frequency terms,
aligning with our analysis of higher frequency representa-

tions. Chatterjee (2020) show generalization arises when
similar examples induce similar gradients during learning
(i.e., coherence). Their work supports our ﬁndings since
inconsistent feature gradients are a manifestation of non-
coherence, explaining their poor generalization. Finally,
our dual objective falls under automatic tuning methods
in RL (AutoRL) (Parker-Holder et al., 2022). These ap-
proaches have been applied very successfully to manage
non-stationary trade-offs, such as exploration and exploita-
tion (Ball et al., 2020) and optimism (Moskovitz et al., 2021;
Cetin & Celiktutan, 2021). Finally, we note links with re-
cent work concerning implicit regularization in TD-learning
(Kumar et al., 2021). However, while Kumar et al. (2021)
observe an implicit ‘underﬁtting’ phenomenon in later train-
ing stages, we analyze an opposed ‘overﬁtting’ phenomenon
occurring during the ﬁrst training steps, which we ﬁnd to be
speciﬁc to learning from visual inputs.

7. Conclusion

In this work, we provide a novel analysis demonstrating that
instabilities in pixel-based off-policy RL come speciﬁcally
from performing TD-learning with a convolutional encoder
in the presence of a sparse reward signal. We show this
visual deadly triad affects the encoder’s gradients, causing
the critic to catastrophically self-overﬁt to its own noisy
predictions. Therefore, we propose Adaptive Local SIgnal
MiXing (A-LIX), a powerful regularization layer to explic-
itly counteract this phenomenon. Applying A-LIX enables
us to outperform prior state-of-the-art algorithms on pop-
ular benchmarks without relying on image augmentations,
auxiliary losses, or other notable design choices.

Acknowledgments

Edoardo Cetin and Oya Celiktutan would like to acknowl-
edge the support from the Engineering and Physical Sci-
ences Research Council [EP/R513064/1] and LISI Project
[EP/V010875/1]. Philip J. Ball would like to thank the Wil-
lowgrove Foundation for support and funding. Furthermore,
support from Toyota Motor Corporation contributed towards
funding the utilized computational resources.

P(A-LIX > Y)

Fraction of runs with score  > τ

SAC

CURL

DrQ

DrQv2

1.00

0.75

0.50

0.25

0.00

A-LIX
DrQv2
DrQ
CURL
SAC

0.60 0.75 0.90

0.0

0.5

1.0

P(A-LIX > Y)

Fraction of runs with score  > τ

SPR

DrQ

CURL

OTR

DER

SimPLe

1.00

0.75

0.50

0.25

0.00

A-LIX
SPR
DrQ
CURL

OTR
DER
SimPLe

0.6 0.7 0.8 0.9

0.0

1.0

2.0

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

References

Agarwal, R., Schwarzer, M., Castro, P. S., Courville, A.,
and Bellemare, M. G. Deep reinforcement learning at the
edge of the statistical precipice, 2021.

Allen-Zhu, Z. and Li, Y. Feature puriﬁcation: How adver-

sarial training performs robust deep learning, 2021.

Alsallakh, B., Kokhlikyan, N., Miglani, V., Yuan, J.,
and Reblitz-Richardson, O. Mind the pad – {cnn}s
In International Conference
can develop blind spots.
on Learning Representations, 2021. URL https://
openreview.net/forum?id=m1CD7tPubNy.

Arpit, D., Jastrzebski, S., Ballas, N., Krueger, D., Bengio,
E., Kanwal, M. S., Maharaj, T., Fischer, A., Courville,
A., Bengio, Y., and Lacoste-Julien, S. A closer look at
memorization in deep networks. In Precup, D. and Teh,
Y. W. (eds.), Proceedings of the 34th International Con-
ference on Machine Learning, volume 70 of Proceedings
of Machine Learning Research, pp. 233–242. PMLR, 06–
11 Aug 2017. URL https://proceedings.mlr.
press/v70/arpit17a.html.

Baird, L. Reinforcement learning through gradient descent.
Technical report, Carnegie-Mellon University, Depart-
ment of Computer Science, 1999.

Baird, L. and Moore, A. Gradient descent for general re-
inforcement learning. Advances in neural information
processing systems, 11, 1998.

Ball, P., Parker-Holder, J., Pacchiano, A., Choromanski,
K., and Roberts, S. Ready policy one: World building
through active learning. In Proceedings of the 37th Inter-
national Conference on Machine Learning, ICML. 2020.

Bellemare, M. G., Naddaf, Y., Veness, J., and Bowling, M.
The arcade learning environment: An evaluation plat-
form for general agents. Journal of Artiﬁcial Intelligence
Research, 47:253–279, 2013.

Bellman, R. A markovian decision process. Indiana Univ.

Math. J., 6:679–684, 1957. ISSN 0022-2518.

Berner, C., Brockman, G., Chan, B., Cheung, V., Debiak, P.,
Dennison, C., Farhi, D., Fischer, Q., Hashme, S., Hesse,
C., et al. Dota 2 with large scale deep reinforcement
learning. arXiv preprint arXiv:1912.06680, 2019.

Boyd, S., Boyd, S. P., and Vandenberghe, L. Convex opti-

mization. Cambridge university press, 2004.

Brandfonbrener, D., Whitney, W. F., Ranganath, R., and
Bruna, J. Ofﬂine RL without off-policy evaluation. In
Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan,
J. W. (eds.), Advances in Neural Information Processing
Systems, 2021. URL https://openreview.net/
forum?id=LU687itn08w.

Bus¸oniu, L., de Bruin, T., Toli´c, D., Kober, J., and Palunko, I.
Reinforcement learning for control: Performance, stabil-
ity, and deep approximators. Annual Reviews in Control,
46:8–28, 2018.

Cetin, E. and Celiktutan, O. Learning pessimism for robust
and efﬁcient off-policy reinforcement learning. arXiv
preprint arXiv:2110.03375, 2021.

Chatterjee, S. Coherent gradients: An approach to under-
standing generalization in gradient descent-based opti-
mization. arXiv preprint arXiv:2002.10657, 2020.

Cobbe, K. W., Hilton, J., Klimov, O., and Schulman, J.
Phasic policy gradient. In International Conference on
Machine Learning, pp. 2020–2027. PMLR, 2021.

Dolan, E. D. and Mor´e, J. J. Benchmarking optimization
software with performance proﬁles. Mathematical pro-
gramming, 91(2):201–213, 2002.

Dror, R., Shlomov, S., and Reichart, R. Deep dominance-
how to properly compare deep neural models. In Pro-
ceedings of the 57th Annual Meeting of the Association
for Computational Linguistics, pp. 2773–2785, 2019.

Duan, Y., Chen, X., Houthooft, R., Schulman, J., and
Abbeel, P. Benchmarking deep reinforcement learning
for continuous control. In International conference on
machine learning, pp. 1329–1338. PMLR, 2016.

Dulac-Arnold, G., Mankowitz, D., and Hester, T. Chal-
arXiv

lenges of real-world reinforcement learning.
preprint arXiv:1904.12901, 2019.

Dwibedi, D., Tompson, J., Lynch, C., and Sermanet, P.
Learning actionable representations from visual observa-
tions. In 2018 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS), pp. 1577–1584.
IEEE, 2018.

Efron, B. Bootstrap methods: another look at the jackknife.
In Breakthroughs in statistics, pp. 569–593. Springer,
1992.

Finn, C., Tan, X. Y., Duan, Y., Darrell, T., Levine, S., and
Abbeel, P. Learning visual feature spaces for robotic ma-
nipulation with deep spatial autoencoders. arXiv preprint
arXiv:1509.06113, 25, 2015.

Fu, J., Kumar, A., Nachum, O., Tucker, G., and Levine,
S. D4{rl}: Datasets for deep data-driven reinforcement
learning, 2021.

Fujimoto, S., van Hoof, H., and Meger, D. Addressing func-
tion approximation error in actor-critic methods. In ICML,
pp. 1582–1591, 2018. URL http://proceedings.
mlr.press/v80/fujimoto18a.html.

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

Ghiasi, G., Lin, T.-Y., and Le, Q. V. Dropblock: A regular-
ization method for convolutional networks. In Bengio,
S., Wallach, H., Larochelle, H., Grauman, K., Cesa-
Bianchi, N., and Garnett, R. (eds.), Advances in Neural
Information Processing Systems, volume 31. Curran As-
sociates, Inc., 2018. URL https://proceedings.
neurips.cc/paper/2018/file/
7edcfb2d8f6a659ef4cd1e6c9b6d7079-Paper.
pdf.

Gogianu, F., Berariu, T., Rosca, M. C., Clopath, C., Bu-
soniu, L., and Pascanu, R.
Spectral normalisation
for deep reinforcement learning: An optimisation per-
In Meila, M. and Zhang, T. (eds.), Pro-
spective.
ceedings of the 38th International Conference on Ma-
chine Learning, volume 139 of Proceedings of Machine
Learning Research, pp. 3734–3744. PMLR, 18–24 Jul
2021. URL https://proceedings.mlr.press/
v139/gogianu21a.html.

Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S. Soft actor-
critic: Off-policy maximum entropy deep reinforcement
learning with a stochastic actor. In Dy, J. and Krause,
A. (eds.), Proceedings of the 35th International Confer-
ence on Machine Learning, volume 80 of Proceedings of
Machine Learning Research, pp. 1861–1870. PMLR, 10–
15 Jul 2018a. URL https://proceedings.mlr.
press/v80/haarnoja18b.html.

Haarnoja, T., Zhou, A., Hartikainen, K., Tucker, G., Ha,
S., Tan, J., Kumar, V., Zhu, H., Gupta, A., Abbeel, P.,
et al. Soft actor-critic algorithms and applications. arXiv
preprint arXiv:1812.05905, 2018b.

Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D.,
Lee, H., and Davidson, J. Learning latent dynamics for
planning from pixels. In International Conference on
Machine Learning, pp. 2555–2565. PMLR, 2019.

Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M. Dream
to control: Learning behaviors by latent imagination. In
International Conference on Learning Representations,
2020.

Hernandez-Garcia, J. F. and Sutton, R. S. Understanding
multi-step deep reinforcement learning: A systematic
study of the dqn target, 2019.

Hessel, M., Modayil, J., Van Hasselt, H., Schaul, T., Ostro-
vski, G., Dabney, W., Horgan, D., Piot, B., Azar, M., and
Silver, D. Rainbow: Combining improvements in deep re-
inforcement learning. In Thirty-second AAAI conference
on artiﬁcial intelligence, 2018.

Kaiser, L., Babaeizadeh, M., Milos, P., Osi´nski, B., Camp-
bell, R. H., Czechowski, K., Erhan, D., Finn, C., Koza-
kowski, P., Levine, S., Mohiuddin, A., Sepassi, R.,

Tucker, G., and Michalewski, H. Model based reinforce-
ment learning for Atari. In International Conference on
Learning Representations, 2020.

Kalashnikov, D., Irpan, A., Pastor, P., Ibarz, J., Herzog,
A., Jang, E., Quillen, D., Holly, E., Kalakrishnan, M.,
Vanhoucke, V., et al. Qt-opt: Scalable deep reinforcement
learning for vision-based robotic manipulation. arXiv
preprint arXiv:1806.10293, 2018.

Kearns, M. J. and Singh, S. P. Bias-variance error bounds
for temporal difference updates. In Proceedings of the
Thirteenth Annual Conference on Computational Learn-
ing Theory, COLT ’00, pp. 142–147, San Francisco, CA,
USA, 2000. Morgan Kaufmann Publishers Inc. ISBN
155860703X.

Keskar, N. S., Mudigere, D., Nocedal, J., Smelyanskiy, M.,
and Tang, P. T. P. On large-batch training for deep learn-
ing: Generalization gap and sharp minima. In 5th Inter-
national Conference on Learning Representations, ICLR
2017, Toulon, France, April 24-26, 2017, Conference
Track Proceedings. OpenReview.net, 2017. URL https:
//openreview.net/forum?id=H1oyRlYgg.

Kielak, K. P. Do recent advancements in model-based deep
reinforcement learning really improve data efﬁciency?
2019.

Kingma, D. P. and Ba, J. Adam: A method for stochastic
optimization. arXiv preprint arXiv:1412.6980, 2014.

Kostrikov, I., Yarats, D., and Fergus, R. Image augmentation
is all you need: Regularizing deep reinforcement learning
from pixels. In International Conference on Learning
Representations. 2021.

Kumar, A., Agarwal, R., Ghosh, D., and Levine, S. Im-
plicit under-parameterization inhibits data-efﬁcient deep
In International Conference
reinforcement learning.
on Learning Representations, 2021. URL https://
openreview.net/forum?id=O9bnihsFfXU.

Laskin, M., Lee, K., Stooke, A., Pinto, L., Abbeel, P., and
Srinivas, A. Reinforcement learming with augmented
In Advances in Neural Information Processing
data.
Systems 33. 2020a.

Laskin, M., Srinivas, A., and Abbeel, P. CURL: Contrastive
unsupervised representations for reinforcement learning.
In Proceedings of the 37th International Conference on
Machine Learning, 2020b.

Lee, A. X., Nagabandi, A., Abbeel, P., and Levine,
S. Stochastic latent actor-critic: Deep reinforcement
learning with a latent variable model. arXiv preprint
arXiv:1907.00953, 2019.

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

Levine, S., Kumar, A., Tucker, G., and Fu, J. Ofﬂine rein-
forcement learning: Tutorial, review, and perspectives on
open problems, 2020.

Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T.
Visualizing the loss landscape of neural nets. In Neural
Information Processing Systems, 2018.

Lillicrap, T. P., Hunt, J. J., Pritzel, A., Heess, N., Erez,
T., Tassa, Y., Silver, D., and Wierstra, D. Continuous
control with deep reinforcement learning. arXiv preprint
arXiv:1509.02971, 2015.

Liu, S., Papailiopoulos, D., and Achlioptas, D. Bad global
minima exist and sgd can reach them. Advances in Neural
Information Processing Systems, 33, 2020.

Machado, M. C., Bellemare, M. G., Talvitie, E., Veness,
J., Hausknecht, M., and Bowling, M. Revisiting the
arcade learning environment: Evaluation protocols and
open problems for general agents. Journal of Artiﬁcial
Intelligence Research, 61:523–562, 2018.

Maennel, H., Alabdulmohsin, I. M., Tolstikhin, I. O.,
Baldock, R., Bousquet, O., Gelly, S., and Keysers,
D. What do neural networks learn when trained
with random labels?
In Larochelle, H., Ranzato,
M., Hadsell, R., Balcan, M. F., and Lin, H. (eds.),
Advances in Neural Information Processing Systems,
volume 33, pp. 19693–19704. Curran Associates,
URL https://proceedings.
Inc.,
neurips.cc/paper/2020/file/
e4191d610537305de1d294adb121b513-Paper.
pdf.

2020.

Mann, H. B. and Whitney, D. R. On a Test of Whether one of
Two Random Variables is Stochastically Larger than the
Other. The Annals of Mathematical Statistics, 18(1):50 –
60, 1947. doi: 10.1214/aoms/1177730491. URL https:
//doi.org/10.1214/aoms/1177730491.

Miyato, T., Kataoka, T., Koyama, M., and Yoshida, Y. Spec-
tral normalization for generative adversarial networks. In
International Conference on Learning Representations,
2018. URL https://openreview.net/forum?
id=B1QRgziT-.

Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A.,
Antonoglou, I., Wierstra, D., and Riedmiller, M. Playing
atari with deep reinforcement learning. arXiv preprint
arXiv:1312.5602, 2013.

Moskovitz, T., Parker-Holder, J., Pacchiano, A., Arbel, M.,
and Jordan, M. Tactical optimism and pessimism for deep
reinforcement learning. In Beygelzimer, A., Dauphin, Y.,
Liang, P., and Vaughan, J. W. (eds.), Advances in Neural
Information Processing Systems, 2021. URL https:
//openreview.net/forum?id=a4WgjcLeZIn.

Neyshabur, B., Bhojanapalli, S., McAllester, D., and Srebro,
N. Exploring generalization in deep learning. In Proceed-
ings of the 31st International Conference on Neural In-
formation Processing Systems, NIPS’17, pp. 5949–5958,
Red Hook, NY, USA, 2017. Curran Associates Inc. ISBN
9781510860964.

Parker-Holder, J., Rajan, R., Song, X., Biedenkapp, A.,
Miao, Y., Eimer, T., Zhang, B., Nguyen, V., Calandra, R.,
Faust, A., Hutter, F., and Lindauer, M. Automated rein-
forcement learning (autorl): A survey and open problems,
2022.

Rahaman, N., Baratin, A., Arpit, D., Draxler, F., Lin, M.,
Hamprecht, F., Bengio, Y., and Courville, A. On the spec-
tral bias of neural networks. In International Conference
on Machine Learning, pp. 5301–5310. PMLR, 2019.

Rosca, M., Weber, T., Gretton, A., and Mohamed, S. A case
for new neural networks smoothness constraints. In ”I
Can’t Believe It’s Not Better!” NeurIPS 2020 workshop,
2020. URL https://openreview.net/forum?
id=_b-uT9wCI-7.

Rummery, G. A. and Niranjan, M. On-line Q-learning using
connectionist systems. Technical Report TR 166, Cam-
bridge University Engineering Department, Cambridge,
England, 1994.

Schaul, T., Ostrovski, G., Kemaev, I., and Borsa, D. Return-
based scaling: Yet another normalisation trick for deep rl,
2021.

Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and
Klimov, O. Proximal policy optimization algorithms.
CoRR, abs/1707.06347, 2017. URL http://arxiv.
org/abs/1707.06347.

Schwarzer, M., Anand, A., Goel, R., Hjelm, R. D., Courville,
A., and Bachman, P. Data-efﬁcient reinforcement learn-
ing with self-predictive representations. arXiv preprint
arXiv:2007.05929, 2020.

Shorten, C. and Khoshgoftaar, T. M. A survey on image
data augmentation for deep learning. Journal of Big Data,
6(1):1–48, 2019.

Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and
Riedmiller, M. Deterministic policy gradient algorithms.
2014.

Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai,
M., Guez, A., Lanctot, M., Sifre, L., Kumaran, D., Grae-
pel, T., et al. Mastering chess and shogi by self-play
with a general reinforcement learning algorithm. arXiv
preprint arXiv:1712.01815, 2017.

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

Song, X., Jiang, Y., Tu, S., Du, Y., and Neyshabur, B. Ob-
servational overﬁtting in reinforcement learning. In Inter-
national Conference on Learning Representations, 2020.

In International Conference
reinforcement learning.
on Learning Representations, 2022. URL https://
openreview.net/forum?id=_SJ-_yyes8.

Zhu, H., Yu, J., Gupta, A., Shah, D., Hartikainen, K., Singh,
A., Kumar, V., and Levine, S. The ingredients of real-
world robotic reinforcement learning. arXiv preprint
arXiv:2004.12570, 2020.

Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever,
I., and Salakhutdinov, R. Dropout: A simple way
Jour-
to prevent neural networks from overﬁtting.
nal of Machine Learning Research, 15(56):1929–1958,
URL http://jmlr.org/papers/v15/
2014.
srivastava14a.html.

Student. The probable error of a mean. Biometrika, 6
(1):1–25, 1908. ISSN 00063444. URL http://www.
jstor.org/stable/2331554.

Sutton, R. Learning to predict by the method of temporal
differences. Machine Learning, 3:9–44, 08 1988. doi:
10.1007/BF00115009.

Sutton, R. S., McAllester, D. A., Singh, S. P., and Mansour,
Y. Policy gradient methods for reinforcement learning
with function approximation. In Advances in neural in-
formation processing systems, pp. 1057–1063, 2000.

Tassa, Y., Doron, Y., Muldal, A., Erez, T., Li, Y., Casas, D.
d. L., Budden, D., Abdolmaleki, A., Merel, J., Lefrancq,
arXiv preprint
A., et al. Deepmind control suite.
arXiv:1801.00690, 2018.

Van Hasselt, H., Doron, Y., Strub, F., Hessel, M., Sonnerat,
N., and Modayil, J. Deep reinforcement learning and the
deadly triad. arXiv preprint arXiv:1812.02648, 2018.

van Hasselt, H. P., Hessel, M., and Aslanides, J. When to use
parametric models in reinforcement learning? Advances
in Neural Information Processing Systems, 32:14322–
14333, 2019.

Vinyals, O., Babuschkin, I., Czarnecki, W. M., Mathieu, M.,
Dudzik, A., Chung, J., Choi, D. H., Powell, R., Ewalds,
T., Georgiev, P., et al. Grandmaster level in starcraft ii
using multi-agent reinforcement learning. Nature, 575
(7782):350–354, 2019.

Individual comparisons by ranking
Wilcoxon, F.
Biometrics Bulletin, 1(6):80–83, 1945.
methods.
ISSN 00994987. URL http://www.jstor.org/
stable/3001968.

Yarats, D., Zhang, A., Kostrikov, I., Amos, B., Pineau, J.,
and Fergus, R. Improving sample efﬁciency in model-
free reinforcement learning from images. Proceedings
of the AAAI Conference on Artiﬁcial Intelligence, 35(12):
10674–10681, May 2021. URL https://ojs.aaai.
org/index.php/AAAI/article/view/17276.

Yarats, D., Fergus, R., Lazaric, A., and Pinto, L. Master-
ing visual continuous control: Improved data-augmented

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

A. Detailed Results

A.1. DMC Medium and Hard Tasks

In Table 4, we show the performance in each of the evaluated 15 DMC environments by reporting the mean and standard
deviations over the cumulative returns obtained midway and at the end of training for the medium and hard benchmark tasks,
respectively. A-LIX attains state-of-the-art performance in the majority of the tasks at both reported checkpoints, while
still closely matching DrQ-v2’s performance on the remaining tasks. On the other hand, DrQ-v2 struggles to consistently
solve some of the harder exploration tasks such as Cartpole Swingup Sparse and Humanoid Run, as shown by the high
standard deviations. Interestingly, unlike in the simpler DMC benchmark from Hafner et al. (2019) with higher action repeat,
CURL appears have a slight edge over DrQ. In particular, the self-supervised signal from CURL appears to aid precisely
in the sparse reward environments where DrQ-v2 struggles. Hence, this appears to suggest that including an additional
self-supervised signal to the TD-loss, lessens the hindering effects of a lower-magnitude reward signal. We interpret this
result as additional evidence showing how addressing any individual component of the deadly triad helps counteracting the
catastrophic self-overﬁtting phenomenon.

We also test the signiﬁcance of our results by performing a Wilcoxon signed-rank test (Wilcoxon, 1945) between A-LIX and
DrQ-v2. We perform a paired rank test across both seeds and tasks, allowing us to obtain an p-value that takes into account
both population size and relative performance gains across all tasks. The choice of Wilcoxon signed-rank test also does not
presume normality in the distributions of performance which we believe is a more appropriate assumption than for instance
a paired t-test (Student, 1908), despite a potential loss of statistical power. To ensure correct population pairing, A-LIX and
DrQ-v2 seeds were identical, resulting in the same initially collected data and network initialization. Performing this test
over all 15 tasks and 5 seeds, we achieve a p-value of 0.0057 at 50% total frames (1.5M and 15M for Medium and Hard
respectively) and 0.0053 at 100% total frames (3.0M and 30M for Medium and Hard Respectively), much lower than the
typical rejection criteria of p > 0.05. We therefore believe this shows clear evidence that our results in DMC are strongly
statistically signiﬁcant.

Table 4. Full results for the DeepMind Control Suite benchmark. Each displayed return is averaged over 10 random seeds and from 10
evaluation runs collected at each experience checkpoint.

Medium tasks

SAC

CURL

DrQ

DrQv2 A-LIX (Ours)

SAC

CURL

DrQ

DrQv2 A-LIX (Ours)

1.5M frames

3.0M frames

8±9

9±8

6±5

24±27

Acrobot Swingup
256±47
Cartpole Swingup Sparse 118±233 479±329 318±389 485±396
Cheetah Run
507±114 788±59 792±29
Finger Turn Easy
190±137 297±150 199±132 854±73
Finger Turn Hard
79±73 174±106 100±63 491±182
Hopper Hop
184±127 268±91 198±102
0±0
Quadruped Run
164±91 129±97 419±204
68±72
Quadruped Walk
134±53 144±149 591±256
75±65
Reach Duplo
220±7
8±12
8±10
1±1
Reacher Easy
52±64 707±142 600±201 971±4
Reacher Hard
463±196 320±233 727±172
3±2
Walker Run
379±234 474±148 571±276
26±4

270±99
718±250
806±78
546±101
587±109
287±48
528±107
776±37
212±3
887±19
720±83
691±10

7±8

6±5

28±25

442±64
12±11
185±295 499±349 316±389 505±412
590±95 835±45 873±60
200±155 309±176 216±158 934±54
902±77
100±78 146±95
86±70
0±0
224±135 285±96 240±123
63±45 175±104 130±59 523±271
168±49 142±67 920±36
48±32
228±2
9±9
7±10
2±3
115±98 667±182 612±181 940±50
10±23 678±350 397±273 935±49
447±224 547±143 616±297
25±3

402±100
742±250
864±78
901±109
906±101
372±48
759±107
900±37
221±3
966±19
855±83
756±10

Average score

52.28

291.73

281.03

547.96

585.67

63.80

326.45

300.27

671.40

720.30

15.0M frames

30.0M frames

Hard tasks

Humanoid Walk
Humanoid Stand
Humanoid Run

Average score

SAC

CURL

DrQ

DrQv2 A-LIX (Ours)

SAC

CURL

DrQ

DrQv2 A-LIX (Ours)

7±3
5±3
5±3

5.64

5±3
6±3
6±2

5.74

3±2
4±3
5±3

243±162
167±159
22±30

476±79
519±94
122±59

4.02

144.16

372.78

4±3
6±3
3±3

4.30

4±3
6±2
4±3

4.89

5±3
6±2
4±2

675±86
588±63
170±122

754±79
781±94
242±59

4.90

477.74

592.48

We now compare our results using the Rliable framework introduced in Agarwal et al. (2021) (see App. A.3 for a detailed
explanation about the metrics introduced).

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

Figure 11. Performance proﬁles at 50% (left) and 100% (right) of the total steps in Medium and Hard DMC Tasks.

We plot performance proﬁles in Fig. 11 at both 50% and 100% the total training steps in DMC, which aim to represent
sample efﬁciency and asymptotic performance respectively. We see that in almost all cases, A-LIX improves upon DrQ-v2.

(a) Overall ranking statistics at 50%
(top) and 100% (bottom) of the to-
tal steps in Medium and Hard DMC
Tasks.

(b) Aggregate IQM (left) and Optimality Gap (right) metrics at 50%
of the total steps in Medium and Hard DMC Tasks.

We plot ranking statistics in Fig. 11 at both 50% and 100% the total training steps in DMC. We see that A-LIX clearly
appears most in the 1st ranked column, and rarely appears in lower ranked (i.e., > 3), suggesting strong performance across
all environments in DMC Medium and Hard. We also provide a further aggregated statistics plot in Fig. 12b (this time
at 50% the total steps), which shows A-LIX is particularly sample-efﬁcient and consistent (i.e., low error bars) across all
environments.

(a) 50% total steps.

(b) 100% total steps.

Figure 13. Probability of Improvement statitistics at both 50% (left) and 100% (right) of the total timesteps in Medium and Hard DMC
Tasks.

In Fig. 13 we observe that A-LIX likely improves over prior work, and note that whilst the improvement probability over
DrQ-v2 may seem slightly low at ∼60%, we note that this value is in line with statistics in prior works that achieve signiﬁcant
gains (as seen in Agarwal et al. (2021)), and furthermore it does not take into account absolute performance values, and
instead only compares relative values, which explains why the gains of A-LIX appear larger when evaluated under IQM
and OG. Furthermore, the lower CI for 50% total steps does not fall below 0.5, which means improvements are indeed
statistically signiﬁcant.

100% Total Steps

50% Total Steps

τ
>

e
r
o
c
s
h
t
i

w
s
n
u
r

f
o
n
o
i
t
c
a
r
F

1.00

0.75

0.50

0.25

0.00

τ
>

e
r
o
c
s
h
t
i

w
s
n
u
r

f
o
n
o
i
t
c
a
r
F

1.00

0.75

0.50

0.25

0.00

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

Normalized Score (τ)

Normalized Score (τ)

A-LIX

DrQv2

DrQ

CURL

SAC

 
 
 
 
 
 
 
 
 
 
50% Total Steps

100

80

60

40

20

0

100

)

%
n
i
(

n
o
i
t
c
a
r
F

100% Total Steps

80

60

40

20

0

1 2 3 4 5
Ranking

A-LIX
DrQv2
DrQ
CURL
SAC

 
 
A-LIX
DrQv2
DrQ
CURL
SAC

IQM

Optimality Gap

0.2

0.4

0.6

0.45 0.60 0.75 0.90

Max Normalized Score

P(A-LIX > Y)

Y
m
h
t
i
r
o
g
A

l

SAC

CURL

DrQ

DrQv2

0.60

0.75

0.90

 
Y
m
h
t
i
r
o
g
A

l

SAC

CURL

DrQ

DrQv2

P(A-LIX > Y)

0.60 0.75 0.90

 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

A.2. Atari 100k

In Table 5, we show the ﬁnal average performance for all the evaluated algorithms in each of the twenty-six tasks in the
Atari 100k benchmark. A-LIX outperforms SPR, the previous state-of-the-art off-policy algorithm on this benchmark, on 16
out of 26 tasks. Moreover, it attains comparatively similar performance on most of the remaining tasks despite using no
augmentation, auxiliary losses, or model-based elements.

Table 5. Full results for the Atari 100k benchmark, following the evaluation protocol from Machado et al. (2018). We report the results
collected from 10 random seeds.

Tasks

Random

Human

SimPLe

DER

OTRainbow

CURL

DrQ

SPR

A-LIX (Ours)

Alien
Amidar
Assault
Asterix
Bank Heist
Battle Zone
Boxing
Breakout
Chopper Command
Crazy Climber
Demon Attack
Freeway
Frostbite
Gopher
Hero
Jamesbond
Kangaroo
Krull
Kung Fu Master
Ms Pacman
Pong
Private Eye
Qbert
Road Runner
Seaquest
Up N Down

Human Norm. Mean
Human Norm. Median

# SOTA
# Super
Average Rank

227.80
5.80
222.40
210.00
14.20
2360.00
0.10
1.70
811.00
10780.50
152.10
0.00
65.20
257.60
1027.00
29.00
52.00
1598.00
258.50
307.30
-20.70
24.90
163.90
11.50
68.40
533.40

0.000
0.000

N/A
N/A
N/A

7127.70
1719.50
742.00
8503.30
753.10
37187.50
12.10
30.50
7387.80
35829.40
1971.00
29.60
4334.70
2412.50
30826.40
302.80
3035.00
2665.50
22736.30
6951.60
14.60
69571.30
13455.00
7845.00
42054.70
11693.20

1.000
1.000

N/A
N/A
N/A

616.9
88
527.2
1128.3
34.2
5184.4
9.1
16.4
1246.9
62583.6
208.1
20.3
254.7
771
2656.6
125.3
323.1
4539.9
17257.2
1480
12.8
58.3
1288.8
5640.6
683.3
3350.3

0.443
0.144

7
2
3.92

739.9
188.6
431.2
470.8
51
10124.6
0.2
1.9
861.8
16185.3
508
27.9
866.8
349.5
6857
301.6
779.3
2851.5
14346.1
1204.1
-19.3
97.8
1152.9
9600
354.1
2877.4

0.285
0.161

1
2
5.00

824.7
82.8
351.9
628.5
182.1
4060.6
2.5
9.8
1033.3
21327.8
711.8
25
231.6
778
6458.8
112.3
605.4
3277.9
5722.2
941.9
1.3
100
509.3
2696.7
286.9
2847.6

0.264
0.204

1
1
5.21

558.2
142.1
600.6
734.5
131.6
14870
1.2
4.9
1058.5
12146.5
817.6
26.7
1181.3
669.3
6279.3
471
872.5
4229.6
14307.8
1465.5
-16.5
218.4
1042.4
5661
384.5
2955.2

0.381
0.175

1
2
3.92

771.2
102.8
452.4
603.5
168.9
12954
6
16.1
780.3
20516.5
1113.4
9.8
331.1
636.3
3736.3
236
940.6
4018.1
9111
960.5
-8.5
-13.6
854.4
8895.1
301.2
3180.8

0.357
0.268

1
2
4.85

801.5
176.3
571
977.8
380.9
16651
35.8
17.1
974.8
42923.6
545.2
24.4
1821.5
715.2
7019.2
365.4
3276.4
3688.9
13192.7
1313.2
-5.9
124
669.1
14220.5
583.1
28138.5

0.704
0.415

4
7
2.88

902
174.27
660.53
809.5
639.4
14470
21.5
23.52
747
53166
888.15
31.04
1845.7
500.6
7185.85
341.5
6507
4884.04
16316
1258.4
6.03
100
2974
17471
654.6
5011.7

0.753
0.411

11
7
2.21

We now present additional evaluations under the Rliable framework, continuing on from the analysis in Fig. 10b.

Figure 14. Performance proﬁles with linear (left) and logarithmic (right) scaling in Atari 100k.

In Fig. 14 A-LIX performs noticeably better than previous work, and performs at least as well as SPR over all settings of

τ
>

e
r
o
c
s
h
t
i

w
s
n
u
r

f
o
n
o
i
t
c
a
r
F

1.00

0.75

0.50

0.25

0.00

0.0

Score Distributions with Non Linear Scaling

Score Distributions 

τ
>
e
r
o
c
s
h
t
i

w
s
n
u
r

f
o
n
o
i
t
c
a
r
F

1.00

0.75

0.50

0.25

0.00

0.5

1.0
Human Normalized Score (τ)

1.5

2.0

0.0

0.1

0.2

0.5

1.0 2.0

Human Normalized Score (τ)

A-LIX

SPR

DrQ

CURL

OTR

DER

SimPLe

 
 
 
 
 
 
 
 
 
 
 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

normalized scores.

(a) Ranking statistics.

(b) Probability of improvement statistics.

Figure 15. Bootstrapped ranking statistics (left) and probability of improvement plots (right) on Atari 100k.

In Fig. 15a A-LIX constitutes the majority of the algorithms ranked in 1st, and shows far fewer instances of being ranked in
lower positions (i.e., > 4). In Fig. 15b we observe A-LIX likely improves upon prior work. Similar to Fig. 13, while the
∼60% improvement value over SPR may seem low, this is justiﬁed due to shortcomings in this metric, such as not taking
into account actual performance values, and instead relative improvements. Furthermore, the lower CI does not fall below
0.5, which means improvements due to A-LIX are statistically signiﬁcant.

A.3. Rliable: A Primer

In addition to providing traditional methods of evaluation (e.g., performance tables, signiﬁcance testing), we use robust
metrics and evaluation strategies introduced in Rliable (Agarwal et al., 2021). Rliable advocates for computing aggregate
performance statistics not just across many seeds, but also across the many tasks within a benchmark suite.

We give details on how these metrics achieve reliable performance evaluation in RL, denoting number of seeds as N and
number of tasks as M . We follow Agarwal et al. (2021) as closely as possible; please refer to their paper for further details.

A.3.1. SEED AND TASK AGGREGATION

In order to aggregate performances across different tasks in the same benchmark suite, we must ﬁrst normalize each
benchmark to the same range. In Atari, this is usually done by normalizing scores with respect to those achieved by humans,
and in DMC this is done with respect to the maximum achievable score (i.e., 1, 000). We refer to this normalized score as τ .

A.3.2. IQM AND OG

Interquartile Mean (IQM) takes the middle 50% of the runs across seeds and benchmarks (i.e., [N M/2]) and then calculates
its mean score, improving outlier robustness whilst maintaining statistical efﬁciency. Optimality Gap (OG) calculates the
proportion of performances (N M ) that fail to meet a minimum threshold γ, with the assumption that improvements beyond
γ are not important. In both cases, stratiﬁed bootstrap sampling is used to calculate conﬁdence intervals (CIs).

A.3.3. PERFORMANCE PROFILES

Performance proﬁles are a form of empirical CDF, but with stratiﬁed bootstrap sampling to produce conﬁdence bands that
account for the underlying variability of the score. We can also establish ‘stochastic dominance’ by observing whether one
method’s performance proﬁle is consistently above another’s for all normalized performance values τ .

A.3.4. RANKING

Ranking shows the proportion of times a given algorithm ranks in a given position across all tasks, with distributions
produced using stratiﬁed bootstrap sampling having 200, 000 repetitions.

A.3.5. PROBABILITY OF IMPROVEMENT

Probability of improvement is calculated by calculating the Mann-Whitney U-statistic (Mann & Whitney, 1947) across all
M tasks. The distribution is then plotted as a boxplot, and if the lower CI > 0.5, the improvement is statistically signiﬁcant.

)

%
n
i
(

n
o
i
t
c
a
r
F

100

80

60

40

20

0

1 2 3 4 5 6 7
Ranking

A-LIX
SPR
DrQ
CURL
OTR
DER
SimPLe

 
 
P(A-LIX > Y)

Y
m
h
t
i
r
o
g
A

l

SPR

DrQ

CURL

OTR

DER

SimPLe

0.6

0.7

0.8

0.9

 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

B. Experiments Description

B.1. Ofﬂine Experiments

We follow the original training hyperparameters of DrQ-v2, and run policy evaluation and policy improvement until we saw
convergence in the TD-loss, which would occur at similar points in all agents (i.e., between 10-20k and 5-10k steps of SGD
in policy evaluation and policy iteration respectively). For the proprioceptive experiments, we keep everything consistent,
except the input to the critic and actor MLP layers are now the proprioceptive states from the DMC simulator, not the latent
representation z from the encoder. That is to say we do not modify the MLP architectures nor their learning rates in the
interests of a fair comparison. Furthermore, for any given seed of the ofﬂine experiment, we also instantiate all networks in
the agents identically and train on the same random ofﬂine data, with minibatches presented in the same order.

We also note that a similar algorithm is described in Brandfonbrener et al. (2021), but in the context of minimizing
extrapolation errors.

Now we present some additional analysis to provide further context to our ofﬂine experiments. First, we see that the
proprioceptive statistics mirror those of the augmented agent, further illustrating the crucial role of CNN regularization for
successful TD-learning from pixels:

Figure 16. Q values and Pearson Correlation of the ofﬂine Proprioceptive agent on an ofﬂine ﬁxed batch.

Secondly, we observe that the exact same self-overﬁt also manifests in the online setting by plotting the Pearson correlation
values over the initial stages of training in 5 seeds, conﬁrming that phenomena of our ofﬂine analysis applies to the online
RL problem:

Figure 17. Pearson Correlation of augmented and non-augmented online agents in Cheetah Run and Quadruped Walk across 5 seeds.
Shaded lines represent individual runs, and solid lines represent the median. We see that augmented agents do not immediately overﬁt to
their target networks, and become correlated only after useful signal is learned.

B.2. Jacobian Analysis

In order to measure local sensitivity, we linearize the encoder around its input using a Taylor series expansion. Consider an
N -dimensional input x ∈ RN and perturbation (cid:15) ∈ RN , an M -dimensional output y ∈ RM , and a function F : RN → RM .
Now, performing a Taylor series expansion around ˜x:

F(˜x + (cid:15)) = F(˜x) + (cid:15)F(x)∇T |x=˜x +

(cid:15)2
2

∇F(x)∇T |x=˜x + . . .

≈ F(˜x) + J(˜x)(cid:15)
= ˜y

(6)

(7)

(8)

Q values during training

l

n
o
i
t
a
e
r
r
o
C

n
o
s
r
a
e
P

1.5

1.0

0.5

0.0

0.5

l

s
e
u
a
V
Q

0

2000 4000 6000 8000

SGD Steps

Correlation of Q with Qtarget and r
1.0

0.8

0.6

0.4

0.2

0.0

Qtarget
r

0

2000 4000 6000 8000

SGD Steps

 
 
l

n
o
i
t
a
e
r
r
o
C

n
o
s
r
a
e
P

1.0

0.8

0.6

0.4

0.2

Cheetah Run

20000

40000

Frames

Quadruped Walk

1.0

0.9

0.8

0.7

0.6

5000 7500 10000 12500

Qtarget Augs

Qtarget No Augs

Frames

r Augs

r No Augs

 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

where we make the approximation in the second line by dropping the second order/Hessian and higher terms under the
assumption the perturbation vector (cid:15) is small. This allows us to write F in the form of a local linear system: y =
F(x) + J(x)(cid:15). It is straightforward to see that if the entries of the Jacobian matrix J are larger, then small perturbations (cid:15)
will cause larger changes in the output y. To measure the magnitude of the Jacobian entries, we take the Frobenius norm:

||J(x)||F =

(cid:88)

(cid:88)

n

m

(cid:19)2

(cid:18) ∂Fm(x)
∂xn

(9)

where xn is the ‘n’th entry of x and Fm is the ‘m’th entry of the codomain of F. The calculation of the Jacobian is trivial
through the use of an automatic differentiation framework.

In our analysis we calculate the Jacobians of both agents on of a ﬁxed batch of 128 frame stacked images taken from the
ofﬂine training dataset, and compare the corresponding ratios of their Frobenius norms, and take this average ratio over the
batch across 4 seeds.

C. Additional Analysis

C.1. Adaptive ND Dual Objective Optimization

The alternative N D score with increased outlier robustness, (cid:103)N D, proposed in Section 4.3 is inspired by recordings of
signal-to-noise ratio measurements. In particular, by passing the individual normalized D(z) terms through a log(1 + x)
smoothing function we downweight the effect that large individual outliers might have on this aggregated metric. We would
like to remark that since we set up the optimization of S with a dual objective, changes in the actual target value relating to
some appropriate smoothness constraint are mostly irrelevant when considering the optimization’s dynamics. Therefore, we
argue that tuning S with the actual N D should not considerably diverge from tuning S based on a re-scaled appropriate
target for (cid:103)N D.

We provide further plots comparing agent performance and respective adaptive parameter S during training:

Figure 18. Performance of agents across 4 different seeds of the Cheetah Run environment and their adaptive scalar parameter S. We
observe that initially, S is high until agents learn useful behaviors, whereupon it drops to maintain ND due to presence of useful signal in
the feature gradients.

Figure 19. Performance of agents across 4 different seeds of the Quadruped Run environment and their adaptive scalar parameter S. We
observe that as meaningful behaviors are learned in agents towards the end of training, S falls accordingly, whereupon it drops to maintain
ND due to presence of useful signal in the feature gradients.

We see the same effect in these two contrasting environments; in Cheetah Run, where learning is more stable due to more
predictable initializations and fewer degrees of freedom, we see the A-LIX parameter S drop almost immediately as the
TD-targets quickly become more accurate. In the less stable Quadruped Run, we also notice this annealing effect, however
this occurs later on in training, when the agent can consistently recover from poor initializations.

Seed 0

Seed 1

Seed 2

Seed 3

500

n
r
u
t
e
R

0

0.0

1.0

0.5
Frames (×106)

1.5

0.0

1.0

0.5
Frames (×106)

1.5

Agent Return

0.0

1.0

0.5
Frames (×106)
A-LIX Parameter S

1.5

2

1

l

e
u
a
V

S

X
I
L
-
A

0.0

1.0

0.5
Frames (×106)

1.5

 
 
Seed 0

Seed 1

Seed 2

Seed 3

800

600

n
r
u
t
e
R

400

1.5

2.0

2.5

3.0

1.5

2.0

2.5

3.0

1.5

2.0

2.5

3.0

1.5

2.0

2.5

3.0

Frames (×106)

Frames (×106)

Agent Return

Frames (×106)
A-LIX Parameter S

Frames (×106)

l

e
u
a
V

S

X
I
L
-
A

0.6

0.4

 
 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

C.2. N-Step Returns

Large n-step rewards have become an important part of many algorithms that use TD-learning from visual observations.
As motivated in Section 3, large n-step rewards can help towards mitigating self-overﬁtting by densifying the reward and
downweighting the contribution of the inaccurate target critic, especially early in training; indeed as shown in (Yarats
et al., 2022), using 1-step learning has a signiﬁcant negative impact on performance. However, it is known that there is a
bias-variance trade-off with multi-step approaches (Kearns & Singh, 2000), and furthermore, almost all approaches using
this method do not apply off-policy bias correction when sampling from a replay buffer. While we motivate the use of n-step
returns as a way to mitigate self-overﬁtting through incurring fewer 0 reward tuples (especially common in sparse reward
environments early in training), we believe there is evidence to show that this introduces bias when n is sufﬁciently large,
despite prior work suggesting this is not the case (Hernandez-Garcia & Sutton, 2019).

Figure 20. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs.

We show in Fig. 20 that 10-step (as is commonly done in algorithms used to solve Atari) returns can mitigate failure seeds
as predicted under the visual deadly triad framework (indeed in Cheetah Run there are no seeds that completely ﬂat-line
when 10-step returns are used). However, we also see evidence that applying 10-step returns can have negative impacts
on convergence and asymptotic performance in Cheetah Run when the deadly triad is sufﬁciently managed, such as using
augmentations; in Quadruped Run we see moderate beneﬁt initially, but note that asymptotically the 10-step and 3-step
agents converge to the same performance. We also provide further evidence in App. E.3, where applying 10-step returns to
an A-LIX agent generally has a laregely negative impact on performance. Finally, we note that trying 20-step returns, as
is done in some algorithms that solve Atari (Laskin et al., 2020b), caused signiﬁcant performance reductions in DMC. In
conclusion, this provides evidence that we should consider using lower values of ‘n’ in multi-step returns, and achieve this
through addressing other elements of the deadly triad.

Cheetah Run

Quadruped Walk

750

500

250

n
r
u
t
e
R

0

0

1

2

3

0

1

2

3

Frames (×106)

Frames (×106)

Augs 3-step
No Augs 3-step

Augs 10-step
No Augs 10-step

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

D. Implementation Details

In Tables 6 and 7 we provide the full list of hyperparameters used in our implementations for DMC and Atari 100k,
respectively. We show signiﬁcant differences from standard practices in bold. In particular, A-LIX uses the same encoder
architecture and n-step returns for both benchmarks, highlighting its lower reliance to environment-speciﬁc heuristics.
Moreover, unlike prior state-of-the-art algorithms it does not employ any data augmentation or auxiliary loss function. These
factors show the effectiveness of our adaptive method in counteracting instabilities from the visual deadly triad without any
additional help, highlighting its applicability.

Table 6. Full hyperparameters list used for the DeepMind Control A-LIX experiments. Bolded values represent signiﬁcant differences
from canonical implementations.

DDPG-integration hyperparameters (following (Yarats et al., 2022))

Replay data buffer size
Batch size
Minimum data before training
Random exploration steps
Optimizer

Policy/critic learning rate

Policy/critic β1
Critic UTD ratio
Policy UTD ratio
Discount γ
Polyak coefﬁcient ρ
N-step returns
Hidden dimensionality

Feature dimensionality

Nonlinearity
Exploration stddev. clip

Exploration stddev. schedule

Augmentations

1000000 (100000 for Quadruped Run)
256 (512 for Walker Run)
4000
2000
Adam (Kingma & Ba, 2014)
medium: 0.0001
hard: 0.00008
0.9
0.5
0.5
0.99
0.99
3 (1 for Walker Run)
1024
medium: 50
hard: 100
ReLU
0.3
medium: linear: 1 → 0.1 in 500000 steps
hard: linear: 1 → 0.1 in 2000000 steps
OFF

A-LIX-speciﬁc hyperparameters

Initial maximum sampling shift S
Normalized discontinuity targets N D
Maximum sampling shift learning rate
Maximum sampling shift β1

1.0
0.635
0.003
0.5

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

Table 7. Full hyperparameters list used for the Atari 100k A-LIX experiments. Bolded values represent signiﬁcant differences from
canonical implementations.

DER-integration hyperparameters

Gray-scaling
Down-sampling
Frames stacked
Action repetitions
Reward clipping
Max episode frames
Replay data buffer size
Replay period every
Batch size
Minimum data before training
Random exploration steps
Optimizer
Critic learning rate
Critic β1
Critic (cid:15)
Max gradient norm
Critic UTD ratio
Discount γ
Target update period
N-step returns
Feature maps
Filter sizes
Strides
Hidden dimensionality
Feature dimensionality
Nonlinearity
Exploration noisy nets parameter
Augmentations

True
84 × 84
4
4
[−1, 1]
108000
100000
1
32
1600
1600
Adam (Kingma & Ba, 2014)
0.0001
0.9
0.000015
10
2
0.99
1
3
32, 32, 32
3 × 3, 3 × 3, 3 × 3
2, 1, 1
256
50
ReLU
0.1
OFF

A-LIX-speciﬁc hyperparameters

Initial maximum sampling shift S
Normalized discontinuity targets N D
Maximum sampling shift learning rate
Maximum sampling shift β1

1.0
0.75
0.0001
0.5

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

E. Additional Ablations

E.1. Smoothness Regularization through Spectral Normalization

To distinguish between general smoothness contraints in convolutional features, and the smoothness that arises as a result
spatial consistency, we apply spectral normalization (Miyato et al., 2018) to the ﬁnal convolutional layer in the encoder to
represent the former class of constraints. Spectral normalization operates on the parameters of a network and constrains
its outputs to be 1-Lipschitz and has shown beneﬁts in prior work (Gogianu et al., 2021), but does not explicitly enforce a
spatial regularization in the features. We train agents without augmentations using spectral normalization.

Figure 21. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs.

We see that whilst there is clear improvement above the original non-augmented agents in some cases, the performance is
still lower than agents that use spatial consistency regularization, such as random shift augmentations.

E.2. Is Gradient Smoothing All We Need?

Following the argument in Section 4.1, we can view augmentations as a gradient smoothing regularizer. This naturally leads
us to ask the following: can we replace the stochastic shifting mechanism with a ﬁxed smoothing mechanism? To test this,
we instead apply a Gaussian smoothing kernel to the feature gradients in the CNN, and utilize our N D score to vary the
width of the kernel adaptively through training; we call this method A-Gauss (Adaptive Gaussian Feature Gradient Kernel).

Figure 22. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs.

We see that while there is improvement over non-augmented agents, overall performance is still lower than even simple
non-adaptive augmentation. We believe this is due to the Gaussian kernel having too signiﬁcant an effect on the information
contained in the feature gradients during backpropagation, causing information to be lost. We believe this explains the
effectiveness of shift-augmentations in reinforcement learning, which is that they effectively balance the information
contained in the gradients, as well as ensuring their smoothness to reduce overﬁtting.

E.3. Ablations to A-LIX

We now provide a set of ablations on both DMC and Atari, assessing the impact of individual components in A-LIX.

Cheetah Run

Quadruped Walk

750

500

250

n
r
u
t
e
R

0

800

600

400

200

0

1

2

3

0

1

2

3

Frames (×106)

Frames (×106)

Augs

Spectral Normalization

Cheetah Run

Quadruped Walk

750

500

250

n
r
u
t
e
R

0

800

600

400

200

0

1

2

3

0

1

2

3

Frames (×106)

Frames (×106)

Augs

A-Gauss

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

(a) DMC Control ablations in Cheetah Run (left) and Quadruped Run
(right) evaluated over 4 seeds.

(b) Atari 100k ablations evaluated over 4 seeds in 4
different Atari 100k tasks.

Figure 23. An ablation study of A-LIX, showing the contribution of its individual components to ultimate performance in DMC and Atari
100k.

In Fig. 23a we choose the following ablations for DMC:

• A-LIX

• Adaptive Random Shifts (where the magnitude of the random shift image augmentation is adjusted using the dual ND

objective)

• LIX

• Random Shifts (i.e., DrQ-v2)

While we see a slight asymptotic performance improvement in Cheetah Run by using LIX layers instead of random shifts,
we notice signiﬁcant differences in the less stable Quadruped Run environment. Concretely, we see much greater stability in
both LIX approaches compared with image augmentation approaches, with the former having no failure seeds. Furthermore,
we observe stronger asymptotic performance with the inclusion of the adaptive dual objective for both approaches. As
motivated in Fig. 19, this is likely a result of reducing the shift parameter as the signal in the target values increases.

In Fig. 23b, we choose the following ablations for Atari 100k on a subset of environments that represent a diverse set of
tasks and performances with baseline algorithms:

• A-LIX

• Adaptive Random Shifts (as before)

• LIX

• A-LIX with 10-step returns

• Random Shifts

We see that A-LIX performs consistently strongly across the environments tested, always placing in the top 2 with regards to
Human Normalized Score. We also notice that generally, LIX layer methods outperform random shift methods apart from in
Crazy Climber, where the opposite is true. We believe this may be due to random shift augmentations actually reﬂecting
the inductive biases concerning generalization in this environment, and believe this merits further investigation. Finally,
we observe that using 10-step returns instead of 3 generally harms performance with A-LIX, with justiﬁcation given in
App. C.2.

n
r
u
t
e
R

900

800

700

600

500

400

300

Cheetah Run

Quadruped Run

800

600

400

200

A-LIX
Adaptive Random Shifts
LIX
Random Shifts (DrQ-v2)

0

1
Frames (×106)

2

3

0

1
Frames (×106)

2

3

e
r
o
c
S

d
e
z
i
l

a
m
r
o
N
n
a
m
u
H

2.0

1.5

1.0

0.5

0.0

A-LIX
Adaptive Random Shifts
LIX
A-LIX 10-step
Random Shifts

Battle Zone

Crazy Climber Ms Pacman

Pong

Atari 100k Task

 
 
Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

F. Additional Ofﬂine Experiment Analysis

F.1. Behavior Cloning without Augmentations

Figure 24. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs. The grey
dotted horizontal line represents mean expert performance.

To illustrate that test time shift invariance is not required, we show that it is possible to learn a policy through supervised
learning. To do this, we generate a pixel-based dataset of 500,000 timesteps under an expert policy in Cheetah Run, and
jointly train a CNN encoder and policy using behavior cloning/supervised learning by minimizing the loss L = (a − π(o))2
until convergence, where o follows the stacked frame image inputs of (Mnih et al., 2013). We see that the pixel-based
policy performs as well as the behavior agent, despite using both higher dimensional data and fewer than half the samples
compared to existing expert ofﬂine RL benchmarks from proprioceptive states (Fu et al., 2021).

This provides clear evidence that shift invariance is not required at test time, and motivates us to ﬁnd an alternative
explanation for why random shift augmentations help the learning process in TD-learning. An alternative perspective is
that when the learning signal is strong, as is the case for supervised learning (and later stages during online learning when
target values are more accurate), the natural bias of CNNs to learn lower order representations acts as an implicit regularizer
(Rahaman et al., 2019) that results in test-time generalization.

F.2. Turning Off Augmentations

We present more evidence showing that augmentations beneﬁt learning the most at the beginning of training. In Fig. 25 we
show the effect of turning off augmentations at 200,000 steps in Cheetah Run, and at 500,000 in Quadruped Walk. In both
instances, we see large improvements over not augmenting at all, and both nearly converge to the same value as DrQ-v2,
showing further evidence that stability initially in learning is vital. We posit that turning off augmentations here did not
yield similar beneﬁts to Fig. 2 due to the fact that there is still high-frequency information in the targets (consider that
the augmentations in Cheetah Run are switched off signiﬁcantly earlier) that cause a marginal amount of self-overﬁtting,
reducing the rate of learning due to feature space degeneration.

Figure 25. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs. The grey
dashed line shows when augmentations are turned off.

Cheetah Run: BC

900

Expert Perfomance

800

n
r
u
t
e
R

700

600

0

No Augs

4

1
2
3
SGD Steps (×105)

Cheetah Run

Quadruped Walk

Augs Turned Off

Augs Turned Off

750

500

250

n
r
u
t
e
R

0

0

1

2

3

0

1

2

3

Frames (×106)

Frames (×106)

Augs

No Augs

Augs Removed

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

F.3. Action-Value Surfaces

Here we show the action-value surfaces of the ofﬂine agents’ critics at various tuples sampled from the data. This provides us
with an intuition over the loss landscape that the policies will be optimizing during the policy improvement, as accordingly
the policy under the deterministic policy gradient (Silver et al., 2014) updates its own weights towards maximizing the
action-values deﬁned by the critic through the chain rule:

∇φJπ ≈ Es∼E

(cid:2)∇aQθ(s, a)|a=fφ(s)∇φfφ(s)(cid:3)

(10)

where φ and θ are policy and critic weights respectively. We hypothesize that self-overﬁtting reduces the sensitivity of
the critic to actions, discarding important information regarding the causal link between actions and expected returns. To
evaluate this, we sample state-action pairs from our replay buffer, and then visualize the action-value surface by sampling
two random orthogonal direction vectors from the action space A. We then normalize the direction vectors to have a 2-norm
of 1, and then multiply each direction vector by scalars α, β ∈ [−2, 2] respectively. We then plot the action-value surface as
a result of adding the random vectors multiplied by their respective scalars onto the action sampled from ofﬂine dataset,
giving us a 3-D surface. We clip actions to a ∈ [−1, 1]|A| as actions are squashed to this range in the policy through a
truncated normal distribution.

(a) Random Sampled State-Action Pair 1

(b) Random Sampled State-Action Pair 2

(c) Random Sampled State-Action Pair 4

(d) Random Sampled State-Action Pair 4

Figure 26. Action-Value loss surface plotted with respect two orthogonal random directions sampled from the action space (i.e., dr ∈ A
and d1 ⊥ d2).

We see that the critics learned by the augmented agents are more sensitive to changes in action. We believe this is due to the
non-augmented agents overﬁtting to the observations, thus ignoring the lower-dimensional action inputs. To validate this, we
sampled 128 random state-action tuples from the ofﬂine buffer, and calculated the average variance across the loss surfaces.
We see a signiﬁcant difference, with the augmented agent having an average loss surface variance of 0.0129, whereas the
non-augmented agent has an average loss surface variance of 0.0044, suggestive of lower sensitivity.

F.4. Evidence of Critic MLP Overﬁtting from High-Frequency Features

We provide further evidence that measuring high-frequency features through the ND score is vital to understanding overﬁt
by showing how overﬁtting is able to occur in the fully-connected critic layers, which are usually stable under proprioceptive
observations (see Table 2). To do this, we construct a pattern containing high frequency checkerboard noise c ∈ RH×W ,
and produce as many patterns as there are channels C in the ﬁnal layer. To ensure consistency across each individual feature
map, we normalize each checkerboard pattern by the maximum value in its respective feature map, and then divide by the
width of the checkerboard. We then add this pattern multiplied by a scalar α onto each feature map.

Critic with Augmentations

Critic w/o Augmentations

0.2

0.4
0.6
0.8

0

1

A ctio n S u bsp ace 2

1

0.2
0.4
0.6
0.8

1

0.2

0.4

0.6

0.8

1

0

1

1

0

Loss

1

0

Action Subspace 1

1

Critic with Augmentations

Critic w/o Augmentations

0.6

0.8

1.0

0

1

A ctio n S u bsp ace 2

1

0.6

0.8

1.0

1

0.6

0.8

1.0

1

0

1

1

0

Loss

1

0

Action Subspace 1

1

Critic with Augmentations

Critic w/o Augmentations

0.4

0.6

0.8

0

1

A ctio n S u bsp ace 2

1

0.4

0.6

0.8

1

0.4

0.6

0.8

1

0

1

1

0

Loss

1

0

Action Subspace 1

1

Critic with Augmentations

Critic w/o Augmentations

0.4

0.6

0.8

1

0

A ctio n S u bsp ace 2

1

0.4

0.6

0.8

0.4

0.6

1

0

0.8

Loss

1

0

1

1

1

0

Action Subspace 1

1

Stabilizing Off-Policy Deep Reinforcement Learning from Pixels

(a) Example checkerboard artefacts.

(b) Sensitivity of agents to checkerboard artifact weight

Figure 27. Effect of checkerboard artifacts on feature maps and resultant loss sensitivity. We see the non-augmented agent is signiﬁcantly
more sensitive to this high-frequency noise.

As we see, the loss is signiﬁcantly more sensitive to high-frequency perturbations in the non-augmented agent, justifying its
reliance on high-frequency patterns in the feature maps to enable self-overﬁtting.

F.5. Additional Loss Surfaces

Here we show the loss surfaces of the ofﬂine agents under policy evaluation with at 1,000, 5,000, and 10,000 training steps.
We also show the surfaces respect to only the MLP layers, again following the normalization approach of Li et al. (2018).

(a) 1,000 SGD Steps

(b) 5,000 SGD Steps

(c) 10,000 SGD Steps

Figure 28. Loss surface plotted with respect to Encoder parameters at various stages of training.

(a) 1,000 SGD Steps

(b) 5,000 SGD Steps

(c) 10,000 SGD Steps

Figure 29. Loss surface plotted with respect to Critic MLP parameters at various stages of training.

As we see, the loss surface with respect to the MLP parameters is signiﬁcantly less sharp, lending further evidence that
self-overﬁtting is predominately a result of the ﬂexibility of the CNN layers to learn high-frequency features.

Augmented Agent

Non-Augmented Agent

0.4

0.3

0.2

s
s
o
L
D
T

0.1

0.0

0.00

Non Augs
Augs

0.25

0.50
 (Checkerboard Weight)

0.75

 
Critic with Augmentations

Critic w/o Augmentations

s
s
o
L
D
T

0.15

0.10

0.05

1

0

W eig ht S u bsp ace 2

1

0.15

0.10

0.05

1

0.15

0.10

0.05

0

TD Loss

1

0

1

1

1

0

Weight Subspace 1

1

 
Critic with Augmentations

Critic w/o Augmentations

s
s
o
L
D
T

0.75

0.50
0.25

0

1

W eig ht S u bsp ace 2

1

0.75
0.50
0.25

1

0.75

0.50

0.25

0

TD Loss

1

0

1

1

1

0

Weight Subspace 1

1

 
Critic with Augmentations

Critic w/o Augmentations

s
s
o
L
D
T

0.75

0.50
0.25

1

0

W eig ht S u bsp ace 2

1

0.75
0.50
0.25

1

0.75

0.50

0.25

0

TD Loss

1

0

1

1

1

0

Weight Subspace 1

1

 
Critic with Augmentations

Critic w/o Augmentations

s
s
o
L
D
T

4

2

1

0

W eig ht S u bsp ace 2

1

4

2

4

2

1

0

TD Loss

1

0

1

1

1

0

Weight Subspace 1

1

 
Critic with Augmentations

Critic w/o Augmentations

s
s
o
L
D
T

20

10

1

0

W eig ht S u bsp ace 2

1

20

10

20

10

1

0

TD Loss

1

0

1

1

1

0

Weight Subspace 1

1

 
Critic with Augmentations

Critic w/o Augmentations

s
s
o
L
D
T

10

5

1

0

W eig ht S u bsp ace 2

1

10

5

10

5

1

0

TD Loss

1

0

1

1

1

0

Weight Subspace 1

1

 
","Stabilizing Off-Policy Deep Reinforcement Learning from Pixels Edoardo Cetin * 1 Philip J. Ball * 2 Steve Roberts 2 Oya Celiktutan 1 2 2 0 2 l u J 3 ] G L . s c [ 1 v 6 8 9 0 0 . 7 0 2 2 : v i X r a Abstract Off-policy reinforcement learning (RL) from pixel observations is notoriously unstable. As a result, many successful algorithms must com- bine different domain-speciﬁc practices and auxil- iary losses to learn meaningful behaviors in com- plex environments. In this work, we provide novel analysis demonstrating that these instabil- ities arise from performing temporal-difference learning with a convolutional encoder and low- magnitude rewards. We show that this new visual deadly triad causes unstable training and prema- ture convergence to degenerate solutions, a phe- nomenon we name catastrophic self-overﬁtting. Based on our analysis, we propose A-LIX, a method providing adaptive regularization to the encoder’s gradients that explicitly prevents the occurrence of catastrophic self-overﬁtting using a dual objective. By applying A-LIX, we signiﬁ- cantly outperform the prior state-of-the-art on the DeepMind Control and Atari 100k benchmarks without any data augmentation or auxiliary losses. 1. Introduction One of the core challenges in real world Reinforcement Learning (RL) is achieving stable training with sample- efﬁcient algorithms (Dulac-Arnold et al., 2019). Combining these properties with the ability to reason from visual obser- vations has great implications for the application of RL to the real world (Kalashnikov et al., 2018; Zhu et al., 2020). Recent works utilizing temporal-difference (TD-) learning have made great progress advancing sample-efﬁciency (Lil- licrap et al., 2015; Fujimoto et al., 2018; Haarnoja et al., 2018a; Cetin & Celiktutan, 2021). However, stability has remained a key issue for these off-policy algorithms (Sutton, *Equal contribution 1Centre for Robotics Research, Depart- ment of Engineering, King’s College London 2Department of Engineering Science, University of Oxford. Correspondence to: Edoardo Cetin <edoardo.cetin@kcl.ac.uk>, Philip J. Ball <ball@robots.ox.ac.uk>. Proceedings of the 39 th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy- right 2022 by the author(s). Figure 1. Performance of agents in DMC (left) and Atari 100k (right) benchmarks from 10 seeds. A-LIX outperforms previous methods without using image augmentations or auxiliary losses. 1988; Duan et al., 2016; Van Hasselt et al., 2018; Bus¸oniu et al., 2018), making their general applicability limited as compared to their on-policy counterparts (Schulman et al., 2017; Cobbe et al., 2021). At the same time, using pixel observations has been another orthogonal source of insta- bilities, with several successful approaches relying on pre- training instead of end-to-end learning (Finn et al., 2015; Dwibedi et al., 2018). In fact, alternative optimization ob- jectives, large amounts of simulation data, and symbolic observations have been common factors in most contempo- rary large-scale RL milestones (Silver et al., 2017; Vinyals et al., 2019; Berner et al., 2019). In this work, we provide novel insights behind why ap- plying successful off-policy RL algorithms designed for proprioceptive tasks to pixel-based environments is gener- ally underwhelming (Lee et al., 2019; Yarats et al., 2021). In particular, we provide evidence that three key elements strongly correlate with the occurrence of detrimental insta- bilities: i) Exclusive reliance on the TD-loss. ii) Unregu- larized end-to-end learning with a convolutional encoder. iii) Low-magnitude sparse rewards. Using this framework, we are able to motivate the effectiveness of auxiliary losses (Laskin et al., 2020b; Schwarzer et al., 2020; Yarats et al., 2021) and many domain-speciﬁc practices (Hessel et al., 2018; Laskin et al., 2020a) by explaining how they address elements of this new visual deadly triad. We focus our analysis on the popular DeepMind Control suite (DMC) (Tassa et al., 2018), where the introduction of random shift augmentations has played a key role in re- cent advances (Laskin et al., 2020a; Kostrikov et al., 2021; DMC Performance Atari 100K Performance A-LIX 694.7 A-LIX SPR 0.752 0.704 DrQ-v2 632.7 SPR (No Augs) 0.463 DrQ 241.2 CURL 262.1 SAC 51.9 DrQ 0.357 CURL 0.381 OTRainbow 0.264 DER 0.285 SimPLe 0.443 0 250 500 0.00 0.25 0.50 0.75 Average Score (Medium + Hard) Mean Human-Normalized Score Stabilizing Off-Policy Deep Reinforcement Learning from Pixels Table 1. Practices from recent pixel-based TD-learning methods to mitigate elements of the visual deadly triad. †DrQ uses 10-step returns on Atari. *CURL uses 20-step returns on Atari. Algorithm Visual Deadly Triad Mitigation TD-Loss CNN Overﬁt DrQ/RAD DrQ-v2 SAC-AE SPR DER CURL - - VAE Loss Model-Based Loss - Contrastive Loss Shift/Jitter Augmentations Shift Augmentations - Shift/Jitter Augmentations Non-Overlapping Strides Shift Augmentations Low-Density Reward 10-step returns† 3-step returns - 10-step returns 20-step returns 20-step returns* Yarats et al., 2022). In this domain, we observe that the presence of the visual deadly triad results in the TD-loss gradients through the convolutional encoder’s feature maps having high spatial frequencies. We ﬁnd these gradients are spatially inconsistent and result in degenerate optimization landscapes when backpropagated to the encoder’s param- eters. Furthermore, repeatedly updating the convolutional encoder with these gradients consistently leads to early con- vergence to degenerate feature representations causing the critic to ﬁt high-variance erroneous targets, a phenomenon we name catastrophic self-overﬁtting. As a way of iden- tifying the direct implications of the visual deadly triad in the gradient signal, we propose a new measure called the Normalized Discontinuity (ND) score and show how its value precisely correlates with agent performance. Thus, we explain the effectiveness of shift augmentations by recog- nizing that they regularize the gradient signal by providing an implicit spatial smoothing effect. Based on our analysis, we propose Adaptive Local SIgnal MiXing (A-LIX) a novel method to prevent catastrophic self-overﬁtting with two key components: i) A new parame- terized layer (LIX) that explicitly enforces smooth feature map gradients. ii) A dual objective that ensures learning sta- bility by adapting the LIX parameters based on the estimated ND scores. We show that integrating A-LIX with existing off-policy algorithms achieves state-of-the-art performance in both DeepMind Control and Atari 100k benchmarks with- out requiring image augmentations or auxiliary losses and signiﬁcantly fewer heuristics. We open-source our code to facilitate reproducibility and future extensions1. Our main contribution can be summarized as follows: • We conjecture the existence of a visual deadly triad as a principal source of instability in reinforcement learn- ing from pixel observations and provide clear empirical evidence validating our hypothesis. • We show these instabilities affect the gradient signal causing catastrophic self-overﬁtting, a phenomenon that can severely harm TD-learning. As a result, we design the normalized discontinuity score to explicitly 1https://github.com/Aladoro/Stabilizing-Off-Policy-RL Figure 2. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs. The vertical dashed line shows when augmentations are turned off. anticipate its occurrence. • We propose A-LIX, a new method that adaptively reg- ularizes convolutional features to prevent catastrophic self-overﬁtting, achieving state-of-the-art results on two popular pixel-based RL benchmarks. 2. Background We consider problem settings described by Markov Deci- sion Processes (MDPs) (Bellman, 1957), deﬁned as the tuple (S, A, P, p0, r, γ). This comprises a state space S, an action space A, transitions dynamics given by P and p0, and a re- ward function r. The RL objective is then for an agent to re- cover an optimal policy π∗, yielding a distribution of trajec- tories pπ(τ ) that maximizes its expected sum of discounted future rewards, π∗ = arg maxπ Epπ(τ ) [(cid:80)∞ t=0 γtr(st, at)]. In off-policy RL, this objective is usually approached by learning a critic function to evaluate the effectiveness of the agent’s behavior. A common choice for the critic is to param- eterize the policy’s Q-function Qπ : S × A → R, that quan- tiﬁes the agent’s performance after performing a particular action: Qπ(s, a) = Epπ(τ |s0=s,a0=a) [(cid:80)∞ t=0 γtr(st, at)]. Most off-policy algorithms entail storing trajectories in a buffer D, and learning parameterized Q-functions by itera- tively minimizing a squared temporal difference (TD-) loss: JQ(φ) = E(s,a,s(cid:48),r)∼D (cid:2)(Qπ φ(s, a) − y)2(cid:3) , (cid:105) (cid:104) ˆQπ φ(cid:48)(s(cid:48), a) . y = r + γEa∼π(s(cid:48)) (1) Here, the TD-targets y are computed from a 1-step bootstrap operation with a slowly-changing target Q-function ˆQπ φ(cid:48). In continuous action spaces, we also learn a separate parame- terized policy to exploit the information in the critic. This practically results in alternating TD-learning with maximiz- ing the Q-function’s expected return predictions, following the policy gradient theorem (Sutton et al., 2000). 3. Instabilities in TD-Learning from Pixels Unlike proprioceptive observations, off-policy RL from pixel observations commonly requires additional domain- Cheetah Run Augs Turned Off 500 n r u t e R 0 0 Augs 1 2 Frames (×106) No Augs 3 No Augs @ 500k Stabilizing Off-Policy Deep Reinforcement Learning from Pixels Figure 3. Evidence of overﬁtting when augmentations are not used. On the left, shaded lines are individual estimates, the solid line represents the median Q-value. On the right, the Q-values Pearson correlation with target values and Monte-Carlo returns (RM C ). Figure 4. TD-loss of ofﬂine ﬁxed transitions during training, sepa- rated based on having non-zero reward. complementary experiments validating these claims). speciﬁc practices to ensure stability. In this section, we provide a novel analysis of this phenomenon by focusing on the DeepMind Control Suite (Tassa et al., 2018). In this benchmark, the introduction of random shift data augmen- tations has been a core component of recent advances in pixel-based off-policy RL (Laskin et al., 2020a; Yarats et al., 2022), allowing us to isolate and reproduce stable and un- stable training regimes. Our analysis suggests the existence of speciﬁc elements that cause instabilities and strives to explain their implications on learning dynamics. We vali- date our ﬁndings via thorough empirical experimentation showing numerous results corroborating our hypotheses. Based on our discoveries, in Section 4 we provide a new interpretation of random shifts and propose a new improved method to isolate and counteract instabilities. 3.1. Why Do Augmentations Help? The underlying mechanism behind the effectiveness of ran- dom shifts is not immediately clear. While this augmen- tation may appear to assist generalization by encoding an invariance (Shorten & Khoshgoftaar, 2019), we note that all the environments from DMC employ a camera that is ﬁxed relative to the agent’s position. Hence, robustness to shifts does not appear to introduce any useful inductive bias about the underlying tasks. Moreover, prior work successfully learned effective controllers without augmentations (Hafner et al., 2020; Yarats et al., 2021), suggesting that shift gen- eralization might not be the primary beneﬁt of this method. We analyze the effect of random shifts by training a DrQ-v2 agent (Yarats et al., 2022) on Cheetah Run but turning off augmentations after an initial 500,000 time-steps learning phase. As shown in Fig. 2, while training without any shift augmentation fails to make consistent progress, turning off augmentations after the initial learning phase actually ap- pears to slightly improve the performance of DrQ-v2. This result is a clear indication that augmentations are not needed for asymptotic performance, and are most helpful to coun- teract instabilities present in the earlier stages of learning, which we now focus on analyzing (see App. F.1-F.2 for 3.2. Identifying a New Deadly Triad To reduce confounding factors and to disentangle the origin of these instabilities, we design an ofﬂine RL experiment (Levine et al., 2020). This experiment isolates three distinct elements affecting off-policy RL: exploration, policy eval- uation, and policy improvement. First, we gather a set of 15,000 transitions with pixel observations using a random policy in Cheetah Run. This allows us to ground explo- ration and analyze learning from ﬁxed data resembling the early stages of online training (when augmentations appear most helpful). We then isolate policy evaluation by training both critic and encoder using SARSA (Rummery & Niran- jan, 1994) until convergence on this ﬁxed data. Finally, we run policy improvement, training an actor to maximize the expected discounted return as predicted by the converged critic (see App. B.1 for details). Interestingly, we ﬁnd that turning on augmentations exclusively during exploration or policy improvement has no apparent effect on stability and ﬁnal performance. Hence, we focus on the effects that augmentations have on TD-learning and analyze applying augmentations only during policy evaluation. Table 2. Performance and training statistics of different agent types in the ofﬂine experiments from 15,000 random transitions. Agent Augmented Non-Augmented Proprioceptive Frozen CNN (random) Frozen CNN (pre-trained) Non-Augmented (norm r) Non-Augmented (10-step returns) Final TD-Loss Final Policy Loss Return 0.021 0.002 0.012 0.023 0.012 18.616 0.003 −0.99 −1.05 −1.14 −0.95 −0.99 3.86 −1.24 86.5 ± 11.3 9.2 ± 12.1 79.1 ± 7.7 43.6 ± 20.2 77.6 ± 18.5 38.6 ± 16.5 36.5 ± 20.3 As shown in Table 2, applying augmentations during pol- icy evaluation enables us to learn policies that achieve a return of 86.5, despite the best trajectory in the ofﬂine data achieving only 10.8. In contrast, without augmentations we consistently recover near 0 returns, resembling the failures observed in the online experiments. On the left of Fig. 3 we show the evolution of the predicted Q-values for both Q values during training No Augs Augs 2.0 1.5 1.0 0.5 0.0 l s e u a V Q Corr. of Q with Qtarget and RMC 1.0 l n o i t a e r r o C n o s r a e P 0.8 0.6 0.4 0.2 0.0 Qtarget RMC 0 2500 5000 SGD Steps 7500 0 2500 5000 SGD Steps 7500 Zero reward samples Non-Zero reward samples No Augs Augs r o r r E D T 1.00 0.75 0.50 0.25 0.00 0 2000 4000 SGD Steps 6000 8000 0 2000 4000 SGD Steps 6000 8000 Stabilizing Off-Policy Deep Reinforcement Learning from Pixels agents on a ﬁxed batch of ofﬂine data. In particular, when performing policy evaluation without augmentations, these predictions display extremely high variance across different state-action pairs. In Table 2 we further show that the non- augmented agent displays signiﬁcantly lower loss, despite having higher average Q-values than the augmented agent (Schaul et al., 2021). We argue this is a clear indication of the occurrence of overﬁtting. We corroborate our claim by analyzing the evolution of the Pearson bi-variate correlation between the estimated Q-values and target Q-values on the right of Fig. 3. These results show that the non-augmented agent displays near-perfect correlation with its own target Q-values throughout training, indicating that it immediately learns to ﬁt its own noisy, randomly-initialized predictions. We also record the correlation with the actual discounted Monte-Carlo returns, which represent the true targets the Q-values should ideally approximate during policy evalu- ation. For these results, we observe that the relationship between applying augmentations and the recorded correla- tion is reversed, with the non-augmented agent displaying signiﬁcantly lower correlation. This dichotomy appears to indicate that ﬁtting the noisy targets severely affects learn- ing the useful training signal from the collected transitions regarding the experienced rewards. We conﬁrm this phe- nomenon by splitting the data into non-zero and zero reward transitions, where the only learning signal propagated in the TD-loss is from the initially random target values. In Fig. 4 we illustrate that the non-augmented agents initially experience much higher TD-errors on zero reward transi- tions, conﬁrming that they focus on ﬁtting uninformative components of the TD-objective. In Table 2 we provide the results of additional experiments that indicate that TD-learning is not the only cause for the observed instabilities. First, we conﬁrm that the ob- served overﬁtting appears to be exclusive to performing end-to-end TD-learning with convolutional neural network (CNN) encoders. Concretely, we run the same ofﬂine exper- iment without training an encoder in three different settings. First, we consider performing policy evaluation directly from non-augmented proprioceptive observations with a fully-connected critic network. Moreover, we also consider freezing the encoder weights either to their initial random values or to pre-trained values from the augmented agent experiments. In all three cases, we attain largely superior performance, almost matching the augmented agent’s per- formance for both the proprioceptive and pre-trained exper- iments. In addition, we also ﬁnd that the observed over- ﬁtting phenomenon is diminished when simply increasing the magnitude of the reward signal in the TD-loss. We test this through two additional experiments which consider normalizing the collected rewards before policy evaluation and incorporating large n-step returns (Sutton, 1988). As reported, both modiﬁcations considerably improve the non- Figure 5. Feature maps in the ﬁnal layer of both augmented (top) and non-augmented (bottom) agent encoders. Non-augmented agents manifest inconsistent, high-frequency feature maps. augmented agent’s performance. However, we note that both practices introduce further unwanted variance in the optimization, failing to yield the same improvements as augmentations (see App. C.2). Taken together, our results appear to strongly indicate that instabilities in off-policy RL from pixel observation come from three key conditions, which we refer to as the visual deadly triad: i) Exclusive reliance on the TD-loss; ii) Un- regularized learning with an expressive convolutional en- coder; iii) Initial low-magnitude sparse rewards. Further evidence arises when considering the ubiquity of partic- ular practices employed in pixel-based off-policy RL. In particular, as summarized in Table 1, most popular prior algorithms feature design choices that appear to counteract at least two elements of this triad, either directly or implic- itly. Furthermore, we show these instabilities result in the non-augmented critics focusing on learning their own noisy predictions, rather than the actual experienced returns. We observe this ultimately leads to convergence to erroneous and high-variance Q-value predictions, a phenomenon we name catastrophic self-overﬁtting. 3.3. Anticipating Catastrophic Self-Overﬁtting We now attempt to unravel the links that connect the visual deadly triad with catastrophic self-overﬁtting. We start by observing that catastrophic self-overﬁtting comes with a signiﬁcant reduction of the critic’s sensitivity to changes in action inputs, implying that the erroneous high-variance Q-value predictions arise primarily due to changes in the observations (see App. F.3 for action-value surface plots). Hence, we focus on analyzing the feature representations of the pixel observations, computed by the convolutional en- coder, z ∈ RC×H×W . In particular, we wish to quantify the sensitivity of feature representations to small perturbations in the input observations. To measure this, we evaluate the Jacobians of the encoder across a ﬁxed batch of ofﬂine data for the augmented and non-augmented agents. We then cal- culate the Frobenius norm of each agent’s Jacobians, giving us a measure of how quickly the encoder feature represen- Augmented Final Feature Map Non-augmented Final Feature Map Stabilizing Off-Policy Deep Reinforcement Learning from Pixels overﬁtting (Keskar et al., 2017) 2. To quantify the level of discontinuity in the features and their gradients, we propose a new metric that encodes the aggregated immediate spatial ‘unevenness’ of each feature location within its relative feature map. In particular, we deﬁne D(z) ∈ RC×H×W as the expected squared local discontinuity of z in any spatial direction, i.e.: (cid:19)2(cid:35) D(z)ijc ≈ Ev∼S1 , (2) (cid:34)(cid:18) ∂zijc ∂v practically estimated via sampling. We then normalize each value in D(z) by its squared input and average over all the feature positions. We name this metric the normalized discontinuity (ND) score: ND(z) = 1 C × H × W C (cid:88) H (cid:88) W (cid:88) c=1 j=1 i=1 D(z)ijc z2 ijc . (3) Intuitively, this score reﬂects how locally discontinuous z is expected to be at any spatial location. In Fig. 7, we show how the N D score of ∇z evolves during training in the ofﬂine and an online setting for both augmented and non- augmented agents. We see that augmented agents experi- ence considerably less discontinuous gradients through their features, and that recordings of lower N D scores also ap- pear to be highly correlated with performance improvements. We additionally show an accumulated N D score, using an exponential moving average of ∇z in each spatial position to calculate this metric. Interestingly, we observe that the N D score over accumulated gradients is almost identical to the instantaneous N D score, showing that similar gradient discontinuities are propagated persistently through training in each position of the feature map. This property conﬁrms that the discontinuities are not smoothed by the stochastic sampling of different consecutive training batches, in which case we would expect to observe lower accumulated N D scores. Thus, it suggests that self-overﬁtting emerges in the non-augmented agents due to repeated gradient steps towards persistent feature map discontinuities. 4. Counteracting Gradient Discontinuities 4.1. Gradient Smoothing and Random Shifts As analyzed in Section 3, catastrophic self-overﬁtting oc- curs when the gradients in the convolution layers are locally discontinuous. As a result, we argue that the efﬁcacy of random shifts arises from their downstream effect on feature gradient computation, which counteracts these discontinu- ities during backpropagation. In particular, while random shifts do not act directly on the latent representation or their 2Instead, the loss surface with respect to the fully-connected weights is smoother (App. F.5). Figure 6. Critic loss surface plots of augmented (left) and non- augmented (right) agents after 5,000 steps of ofﬂine training. tations are changing locally around an input (see App. B.2 for details). Our results show a stark difference, with the feature representations of the non-augmented agents being on average 2.85 times more sensitive. This suggests that overﬁtting is driven by the CNN encoder’s representations learning high-frequency information about the input obser- vations and, thus, breaking useful inductive biases about this class of models (Rahaman et al., 2019). In App. E.1 we demonstrate that lower sensitivity to ran- dom noise, while desirable for optimization (Rosca et al., 2020), is actually a byproduct of a stable feature represen- tations, and not its deﬁning factor. Furthermore, observing the actual feature maps of different observations in Fig. 5, we see that augmentations make the encoder produce fea- tures that are spatially consistent, aligned with common understandings of how natural representations should ap- pear (Alsallakh et al., 2021; Allen-Zhu & Li, 2021). In contrast, the non-augmented agents display high-frequency and discontinuous feature maps that do not reﬂect the spa- tial properties of their inputs. Hence, our evidence suggests that catastrophic self-overﬁtting speciﬁcally follows from the same learning process that produces highly-sensitive and discontinuous encoder feature maps. Therefore, we turn our focus to analyzing the gradients backpropagated to the encoder’s features maps and observe one key prop- erty: the gradients of the output feature maps consistently reﬂect the same spatial properties of their resulting features. In particular, the gradients of the feature maps appear spa- tially consistent for the augmented agent, and discontinuous for the non-augmented agent. This optimization property reﬂects intuitive understandings of backpropagation since discontinuous gradients should push the encoder’s weights to encode discontinuous representations. To provide further complementary evidence that discontinuous gradients are the direct cause of catastrophic self-overﬁtting, we analyze the normalized loss surfaces when backpropagating these discontinuous gradients to the encoder’s parameters (fol- lowing Li et al. (2018)). In Fig. 6, we see that gradient discontinuities in the non-augmented agent yield extreme peaks in its encoder’s loss surface, clearly suggestive of Critic with Augmentations Critic w/o Augmentations s s o L D T 0.75 0.50 0.25 1 0 W eig ht S u bsp ace 2 1 0.75 0.50 0.25 1 0.75 0.50 0.25 0 TD Loss 1 0 1 1 1 0 Weight Subspace 1 1 Stabilizing Off-Policy Deep Reinforcement Learning from Pixels persistent discontinuities from accumulating. Hence, ran- dom shifts break the second condition of the visual deadly triad, by providing effective implicit regularization of the convolutional encoder’s learning process. At the same time, this minimally disrupts the information content of the re- sultant features, since discarded observation borders almost exclusively comprise background textures that are irrele- vant for performing the task. This interpretation of random shifts aligns with the analysis in Section 3, showing that im- plicitly smoothing over the backpropagated gradient maps consistently prevents catastrophic self-overﬁtting. 4.2. Local Signal Mixing We extrapolate our hypotheses about catastrophic self- overﬁtting and random shifts by proposing a technique that aims to enforce gradient smoothing regularization explic- itly. We propose Local SIgnal MiXing, or LIX, a new layer speciﬁcally designed to prevent catastrophic self-overﬁtting in convolutional reinforcement learning architectures. LIX acts on the features produced by the convolutional encoder, z ∈ RC×H×W , by randomly mixing each component zcij with its neighbors belonging to the same feature map. Hence, LIX outputs a new latent representation with the same di- mensionality ˆz ∈ RC×H×W , whose computation graph minimally disrupts the information content of each feature zcij while smoothing discontinuous components of the gra- dient signal during backpropagation. LIX is a regularization layer that acts as a simple random smoothing operation, reducing the expected magnitude of gradient discontinuities by preventing higher frequency sig- nals to persist. In the forward pass, LIX produces a new latent representation where for each of the C feature maps, ˆzcij is computed as a randomly weighted average of its spatial neighbors around coordinates i, j. We further param- eterize this stochastic operation using some maximum range radius S, and consequently sample two uniform continuous random variables δx, δy ∼ U [−S, S], representing shifts in the x and y coordinates respectively. Correspondingly, we deﬁne ˜i = i + δx and ˜j = j + δy and perform the weighted averaging as a bilinear interpolation with weights determined by the random shifts: ˆzcij =zc(cid:98)˜i(cid:99)(cid:98)˜j(cid:99)((cid:100)˜i(cid:101) − ˜i)((cid:100)˜j(cid:101) − ˜j) + zc(cid:98)˜i(cid:99)(cid:100)˜j(cid:101)((cid:100)˜i(cid:101) − ˜i)(˜j − (cid:98)˜j(cid:99)) +zc(cid:100)i(cid:101)(cid:98)˜j(cid:99)(˜i − (cid:98)˜i(cid:99))((cid:100)˜j(cid:101) − ˜j) + zc(cid:100)i(cid:101)(cid:100)˜j(cid:101)(˜i − (cid:98)˜i(cid:99))(˜j − (cid:98)˜j(cid:99)). Since nearby features in a convolutional feature map are computed with very similar receptive ﬁelds, the mixing effect of LIX should have a trivial effect on the informa- tion the encoder can convey in its latent representations. In addition, LIX should have a direct regularization ef- fect on the gradients by acting on the feature maps them- selves. In particular, since LIX computes each output feature from a weighted average of its neighbors, back- Figure 7. Instantaneous (red and blue) and accumulated (orange and purple) N D scores for the features gradients from ofﬂine (left) and online (right) training in Cheetah Run. respective gradients, they do affect how the latent represen- tations are computed. This has an impact on how persistent discontinuous components of the gradient are backpropa- gated to the encoder’s parameters during learning. From the approximate shift invariance of convolutional layers, we can view a convolutional encoder as computing each of the feature vectors [z1ij, ..., zCij]T with the same param- eterized function, Vφ, that takes as input a subset of each observation O ∈ RC(cid:48)×H (cid:48)×W (cid:48) . This subset corresponds to a local neighborhood around some reference input coordinates i(cid:48), j(cid:48). Thus, the only factor differentiating features in the same feature map (e.g., zcij and zckl) is some implicit func- tion f (i, j) = i(cid:48), j(cid:48) translating each of the output features coordinate into the relative reference input coordinate, i.e. zcij = Vφ(O, i(cid:48), j(cid:48))c (determined by kernel sizes, strides...). Therefore, random shifts are approximately equivalent to further translating each reference coordinate by adding some x, δ(cid:48) uniform random variables δ(cid:48) y: zcij ≈ Vφ(O, i(cid:48) + δ(cid:48) y ∼ U [−s(cid:48), s(cid:48)], x, δ(cid:48) δ(cid:48) x, j(cid:48) + δ(cid:48) y)c, f (i, j) = i(cid:48), j(cid:48). where Due to the employed strides from the convolutional archi- tectures used in DrQ-v2 (Yarats et al., 2022), the difference in reference coordinates of adjacent features in a feature map is less than the maximum allowable shift employed in the augmentations, i.e., (i + 1)(cid:48) − i(cid:48), (j + 1)(cid:48) − j(cid:48) < s(cid:48) (where s(cid:48) is the maximum allowable shift). Consequently, shift augmentations effectively turn the deterministic com- putation graph of each feature zcij into a random variable, whose sample space comprises the computation graphs of all nearby features within its feature map. Hence, applying different random shifts to samples in a minibatch makes the gradient of each feature ∇zcij backpropagate to a random computation graph, sampled from a set that extends the set of non-augmented computation graphs for all features in a local neighborhood of coordinates i, j. Therefore, ag- gregating the parameter gradients produced with different δ(cid:48) x, δ(cid:48) y, provides a smoothing effect on how each discon- tinuous component of ∇z affects learning, and prevents Offline Online e r o c S D N 2.2 2.0 1.8 1.6 0 5000 SGD Steps 2.0 1.5 1.0 10000 0.0 0.5 1.0 1.5 No Augs No Augs (Accumulated) Frames (×106) Augs Augs (Accumulated) Stabilizing Off-Policy Deep Reinforcement Learning from Pixels propagation will split each gradient ∇ˆzcij, to a random local combination of features within the same feature map, {∇zc(cid:98)˜i(cid:99)(cid:98)˜j(cid:99), ∇zc(cid:98)˜i(cid:99)(cid:100)˜j(cid:101), ∇zc(cid:100)i(cid:101)(cid:98)˜j(cid:99), ∇zc(cid:100)i(cid:101)(cid:100)˜j(cid:101)}. Thus, LIX should mostly preserve the consistent component of ∇z, while randomly smoothing its discontinuous component. There are multiple key differences between the regulariza- tion from LIX and random shifts. LIX provides a local smoothing effect over the gradients explicitly and exactly, without having to deal with the implications of padding and strided convolutions breaking shift-invariance assump- tions. Moreover, LIX smooths the gradient signal not only across different inputs but also within each feature map. In addition, by applying its operation solely at the feature level, the encoder can still learn to entirely circumvent LIX’s smoothing effect on the information encoded in the latent representations, given enough capacity. This means that LIX does not forcibly preclude any input information from affecting the computation. Consequently, LIX also does not have to enforce learning invariances which might not neces- sarily reﬂect useful inductive biases about the distribution of observations. In contrast, random shifts need to exploit the particular uninformativeness of the observations borders to avoid disrupting the features’ information content. 4.3. A-LIX LIX introduces a single key parameter: the range radius S used for sampling δx and δy. Intuitively, this value should reﬂect how much we expect gradients to be locally consis- tent for a given architecture and task. Therefore, we argue that the value of S should ideally decrease throughout train- ing as the useful learning signal from the TD-loss becomes stronger. This is consistent with the results illustrated in Figure 2, showing that turning off random shift augmenta- tions after the TD-targets become informative can improve learning. Hence, we propose an adaptive strategy to learn S throughout training. Utilizing the normalized discontinuity (N D) score in Section 3.3, we set up a dual optimization objective to ensure a minimum value of local smoothness in the representation gradients, N D. However, computing the N D score of the gradient signal involves a ratio between po- tentially very small values. As a result, estimation of these values from a batch of gradient samples can lead to outliers having an extreme impact on this average measure, trans- lating into large erroneous updates of S. To overcome this, we propose using a slightly modiﬁed version of the N D score with increased robustness to outliers (see App. C.1 for further details): (cid:103)N D(∇ˆz) = C (cid:88) H (cid:88) W (cid:88) (cid:32) log 1 + c=1 j=1 i=1 (cid:33) D(∇ˆz)cij ∇ˆz2 ijc . (4) In practice, we set up a dual optimization objective similar to the automatic temperature adjustment from Haarnoja et al. Figure 8. A-LIX’s S parameter evolution during training in Chee- tah Run (left) and Quadruped Run (right). As the critic targets become more informative, S falls, improving data efﬁciency and asymptotic performance. (2018b). This entails alternating the optimization of the TD- learning objectives described in Section 2 with minimizing a dual objective loss: (cid:104) −S × Eˆz (cid:103)N D(∇ˆz) − N D (cid:105) , (5) arg min S approximating dual gradient descent (Boyd et al., 2004). Hence, we call this new layer Adaptive LIX (A-LIX). In Fig. 8 we show that A-LIX effectively anneals S as the agent escapes its unstable regimes, in line with our intuition. 5. Performance Evaluation We evaluate the effectiveness of A-LIX in pixel-based re- inforcement learning tasks in two popular and distinct do- mains featuring a diverse set of continuous and discrete control problems. We integrate A-LIX with existing popu- lar algorithms and compare against current state-of-the-art model-free baselines. We provide further details of our integration and full hyperparameters in App. D. We also extend this section by providing more granular evaluation metrics in App. A. Furthermore, we provide ablation studies analyzing different components of A-LIX in App. E. 5.1. DeepMind Control Evaluation We ﬁrst evaluate the effectiveness of A-LIX for pixel-based RL on continuous control tasks from the DeepMind Control Suite (DMC) (Tassa et al., 2018). Concretely, we integrate A-LIX with the training procedure and network architecture from DrQ-v2 (Yarats et al., 2022), but without using image augmentations. To show the generality of our method we do not modify any of the environment-speciﬁc hyperparameters from DrQ-v2 and simply add our A-LIX layer after each encoder nonlinearity. For simplicity, we optimize a shared S for all the A-LIX layers with the dual objective in Eq. 5. Hence, this introduces a single additional parameter and negligible computational overhead. We compare A-LIX to DrQ-v2, which represents the current state-of-the-art on this benchmark. We also compare against three further baselines: the original DrQ (Kostrikov et al., 2021), which foregoes n- step returns and includes an entropy bonus; CURL (Laskin et al., 2020b), which includes an auxiliary contrastive ob- 500 n r u t e R 0 0.0 Cheetah Run Quadruped Run 2 1 700 600 500 0.7 l e u a V 0.6 S 0.5 X I L - A 1.0 0.5 Frames (×106) 1.5 Agent Return 1.5 2.0 2.5 3.0 Frames (×106) A-LIX Parameter S Stabilizing Off-Policy Deep Reinforcement Learning from Pixels Table 3. Results summary for the Atari 100k benchmark. The reported performance of A-LIX is from 10 seeds. Metrics SimPLe DER OTRainbow CURL DrQ SPR A-LIX Norm. Mean 0.443 0.285 Norm. Median 0.144 0.161 # SOTA # Super Average Rank 7 2 3.92 1 2 5.00 0.264 0.204 1 1 5.21 0.381 0.357 0.704 0.753 0.175 0.268 0.415 0.411 1 2 1 2 3.92 4.85 2.88 4 7 11 7 2.21 Figure 9. Average performance in 10 seeds for DMC Medium (left) and Hard tasks (right). Shaded regions represent ±1 SE. jective; an extension of SAC (Haarnoja et al., 2018b) with the encoder from Yarats et al. (2021). These last three base- lines have been performant on a prior DMC benchmark that considers fewer tasks with high action repeats, as described by Hafner et al. (2019). Instead, we evaluate on the more challenging ‘Medium’ and ‘Hard’ benchmarks from Yarats et al. (2022), comprising 15 tasks with low action repeats. Results. We summarize the results in Figure 9, showing the mean performance curves for both medium and hard bench- mark tasks. We provide further details and the full list of results across all 15 environments in App. A.1. Overall, A- LIX surpasses all prior methods with clear margins, both in terms of efﬁciency and ﬁnal performanc. This is particularly notable in the more complex ‘Hard’ tasks. As highlighted in prior work (Cetin & Celiktutan, 2021), DrQ-v2 appears to yield inconsistent results on some of the harder exploration tasks with sparse rewards. This likely indicates that the gradient regularization induced by random shifts (described in Section 4.1) is unable to consistently prevent catastrophic self-overﬁtting in scenarios where the initial learning signal from TD-learning is particularly low. Finally, DrQ, CURL, and SAC fail to make consistent meaningful progress on this harder benchmark. This performance gap corroborates the third component of the visual deadly triad, showing how lower magnitude rewards due to harder exploration and lower action-repeats further destabilize TD-learning based algorithms, and explains the gains seen in DrQ-v2 when incorporating n-step returns. We believe these results em- phasize the challenge of overcoming the visual deadly triad in continuous control problems and the particular effective- ness of A-LIX to counteract its direct implications. 5.2. Atari 100k Evaluation We perform a second set of experiments in an entirely dif- ferent setting, discrete control. We make use of the popular Atari Learning Environment (ALE) (Bellemare et al., 2013) and consider the 100k evaluation benchmark from Kaiser et al. (2020). In particular, this benchmark comprises eval- uating performance for 26 tasks after only two hours of play-time (100k interaction steps), following the evaluation protocol in Machado et al. (2018). We integrate A-LIX with Data-Efﬁcient Rainbow (DER) (van Hasselt et al., 2019), a simple extension to Rainbow (Hessel et al., 2018) with improved data-efﬁciency. We would like to note that our integration has key differences to DER, designed to high- light the generality of our method in tackling the visual deadly triad. In particular, we reduce the n-step returns to 3 (from 20), and we maintain the same encoder architecture as in DrQ-v2. To speak to the latter point, this means we do not require the highly regularized encoders with large convolutional ﬁlters and strides, used ubiquitously in off- policy learning for Atari environments. Instead, to stabilize learning we simply apply our A-LIX layer after the ﬁnal encoder nonlinearity. We compare against three algorithms that, like A-LIX, do not employ data-augmentation: Data- Efﬁcient Rainbow (DER); Overtrained Rainbow (OTRain- bow) (Kielak, 2019); and Simulated Policy Learning (Sim- PLe) (Kaiser et al., 2020) (model-based). Moreover, we also compare with additional state-of-the-art off-policy baselines that make use of data augmentations: the aforementioned CURL and DrQ; and Self-Predictive Representations (SPR) (Schwarzer et al., 2020), the current state-of-the-art TD- learning based algorithm on this benchmark. SPR combines data augmentation with numerous additional algorithmic design choices, such as an auxiliary self-supervised loss for learning a latent dynamics model. Results. We summarize the results in Table 3, showing the mean and median human-normalized scores together with the number of environments where each algorithm ei- ther achieves state-of-the-art or super-human performance. We include the full per-environment results in App. A.2. Remarkably, A-LIX obtains a substantially higher human- normalized mean performance than all other considered algorithms. While the recorded normalized median per- formance is slightly inferior to SPR, we argue that such difference is not particularly signiﬁcant since this metric de- pends on the performance obtained in just two environments. Moreover, A-LIX achieves super-human performance in 7 games (the same as SPR), and state-of-the-art performance in 11 games, considerably more than all other algorithms. These results corroborate how tuned architectures, data aug- mentation, and auxiliary losses used on ALE mostly serve the purpose of counteracting the direct implications of the visual deadly triad and show that A-LIX enables us to learn DMC Medium Tasks DMC Hard Tasks n r u t e R 600 400 200 0 0 600 400 200 0 1 2 3 0 1 2 3 Frames (×106) Frames (×107) A-LIX DrQ-v2 CURL DrQ SAC Stabilizing Off-Policy Deep Reinforcement Learning from Pixels (a) DeepMind Control: Medium and Hard Tasks (b) Atari 100k Figure 10. Probability of improvement and performance proﬁles obtained from the recorded results in DMC (left) and Atari 100k (right). A-LIX displays statistically signiﬁcantly improvements and stochastically dominates most prior algorithms. powerful models without relying on these design choices. 5.3. Statistical Signiﬁcance To validate the signiﬁcance of our improvements, we sta- tistically analyze our results using the Rliable tools and practices from Agarwal et al. (2021). We summarize some of our key ﬁndings in Fig. 10, showing the probability of improvements of A-LIX over prior methods (computed with the Mann-Whitney U statistic (Mann & Whitney, 1947)) and the relative normalized performance proﬁles (Dolan & Mor´e, 2002). The ranges correspond to 95% stratiﬁed boot- strap conﬁdence intervals (Efron, 1992). In both DMC and Atari benchmarks, we ﬁnd that our improvements are sta- tistically signiﬁcant (lower conﬁdence intervals >0.5) and observe ‘stochastic dominance’ of our algorithm against almost all considered baselines (Dror et al., 2019). We pro- vide further results and details of the employed statistical analysis in App. A.1 and App. A.3 respectively. 6. Related Work Previous works have characterized several optimization is- sues related to performing RL via TD-learning (Baird & Moore, 1998; Baird, 1999). In this work, we instead fo- cus on the empirical analysis of modern TD-learning al- gorithms, speciﬁc to the pixel-based RL setting. We also observe links with recent work studying observational over- ﬁtting (Song et al., 2020). Our work differs by focusing on memorization effects particular to the combination of CNNs and TD-learning. There are also connections with existing feature-level augmentation work, such as Dropout (Srivastava et al., 2014) and DropBlock (Ghiasi et al., 2018). In particular, the latter also applies structured transforma- tions directly to the feature maps and introduces a heuristic to adjust this transformation over training, validating our ﬁndings on the utility of adaptivity. Outside RL, there is a rich body of work on implicit regularization and memoriza- tion in CNNs (Keskar et al., 2017; Neyshabur et al., 2017; Arpit et al., 2017; Liu et al., 2020; Maennel et al., 2020). Rahaman et al. (2019) show that higher frequency data man- ifolds cause CNNs to learn higher spectral frequency terms, aligning with our analysis of higher frequency representa- tions. Chatterjee (2020) show generalization arises when similar examples induce similar gradients during learning (i.e., coherence). Their work supports our ﬁndings since inconsistent feature gradients are a manifestation of non- coherence, explaining their poor generalization. Finally, our dual objective falls under automatic tuning methods in RL (AutoRL) (Parker-Holder et al., 2022). These ap- proaches have been applied very successfully to manage non-stationary trade-offs, such as exploration and exploita- tion (Ball et al., 2020) and optimism (Moskovitz et al., 2021; Cetin & Celiktutan, 2021). Finally, we note links with re- cent work concerning implicit regularization in TD-learning (Kumar et al., 2021). However, while Kumar et al. (2021) observe an implicit ‘underﬁtting’ phenomenon in later train- ing stages, we analyze an opposed ‘overﬁtting’ phenomenon occurring during the ﬁrst training steps, which we ﬁnd to be speciﬁc to learning from visual inputs. 7. Conclusion In this work, we provide a novel analysis demonstrating that instabilities in pixel-based off-policy RL come speciﬁcally from performing TD-learning with a convolutional encoder in the presence of a sparse reward signal. We show this visual deadly triad affects the encoder’s gradients, causing the critic to catastrophically self-overﬁt to its own noisy predictions. Therefore, we propose Adaptive Local SIgnal MiXing (A-LIX), a powerful regularization layer to explic- itly counteract this phenomenon. Applying A-LIX enables us to outperform prior state-of-the-art algorithms on pop- ular benchmarks without relying on image augmentations, auxiliary losses, or other notable design choices. Acknowledgments Edoardo Cetin and Oya Celiktutan would like to acknowl- edge the support from the Engineering and Physical Sci- ences Research Council [EP/R513064/1] and LISI Project [EP/V010875/1]. Philip J. Ball would like to thank the Wil- lowgrove Foundation for support and funding. Furthermore, support from Toyota Motor Corporation contributed towards funding the utilized computational resources. P(A-LIX > Y) Fraction of runs with score > τ SAC CURL DrQ DrQv2 1.00 0.75 0.50 0.25 0.00 A-LIX DrQv2 DrQ CURL SAC 0.60 0.75 0.90 0.0 0.5 1.0 P(A-LIX > Y) Fraction of runs with score > τ SPR DrQ CURL OTR DER SimPLe 1.00 0.75 0.50 0.25 0.00 A-LIX SPR DrQ CURL OTR DER SimPLe 0.6 0.7 0.8 0.9 0.0 1.0 2.0 Stabilizing Off-Policy Deep Reinforcement Learning from Pixels References Agarwal, R., Schwarzer, M., Castro, P. S., Courville, A., and Bellemare, M. G. Deep reinforcement learning at the edge of the statistical precipice, 2021. Allen-Zhu, Z. and Li, Y. Feature puriﬁcation: How adver- sarial training performs robust deep learning, 2021. Alsallakh, B., Kokhlikyan, N., Miglani, V., Yuan, J., and Reblitz-Richardson, O. Mind the pad – {cnn}s In International Conference can develop blind spots. on Learning Representations, 2021. URL https:// openreview.net/forum?id=m1CD7tPubNy. Arpit, D., Jastrzebski, S., Ballas, N., Krueger, D., Bengio, E., Kanwal, M. S., Maharaj, T., Fischer, A., Courville, A., Bengio, Y., and Lacoste-Julien, S. A closer look at memorization in deep networks. In Precup, D. and Teh, Y. W. (eds.), Proceedings of the 34th International Con- ference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pp. 233–242. PMLR, 06– 11 Aug 2017. URL https://proceedings.mlr. press/v70/arpit17a.html. Baird, L. Reinforcement learning through gradient descent. Technical report, Carnegie-Mellon University, Depart- ment of Computer Science, 1999. Baird, L. and Moore, A. Gradient descent for general re- inforcement learning. Advances in neural information processing systems, 11, 1998. Ball, P., Parker-Holder, J., Pacchiano, A., Choromanski, K., and Roberts, S. Ready policy one: World building through active learning. In Proceedings of the 37th Inter- national Conference on Machine Learning, ICML. 2020. Bellemare, M. G., Naddaf, Y., Veness, J., and Bowling, M. The arcade learning environment: An evaluation plat- form for general agents. Journal of Artiﬁcial Intelligence Research, 47:253–279, 2013. Bellman, R. A markovian decision process. Indiana Univ. Math. J., 6:679–684, 1957. ISSN 0022-2518. Berner, C., Brockman, G., Chan, B., Cheung, V., Debiak, P., Dennison, C., Farhi, D., Fischer, Q., Hashme, S., Hesse, C., et al. Dota 2 with large scale deep reinforcement learning. arXiv preprint arXiv:1912.06680, 2019. Boyd, S., Boyd, S. P., and Vandenberghe, L. Convex opti- mization. Cambridge university press, 2004. Brandfonbrener, D., Whitney, W. F., Ranganath, R., and Bruna, J. Ofﬂine RL without off-policy evaluation. In Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J. W. (eds.), Advances in Neural Information Processing Systems, 2021. URL https://openreview.net/ forum?id=LU687itn08w. Bus¸oniu, L., de Bruin, T., Toli´c, D., Kober, J., and Palunko, I. Reinforcement learning for control: Performance, stabil- ity, and deep approximators. Annual Reviews in Control, 46:8–28, 2018. Cetin, E. and Celiktutan, O. Learning pessimism for robust and efﬁcient off-policy reinforcement learning. arXiv preprint arXiv:2110.03375, 2021. Chatterjee, S. Coherent gradients: An approach to under- standing generalization in gradient descent-based opti- mization. arXiv preprint arXiv:2002.10657, 2020. Cobbe, K. W., Hilton, J., Klimov, O., and Schulman, J. Phasic policy gradient. In International Conference on Machine Learning, pp. 2020–2027. PMLR, 2021. Dolan, E. D. and Mor´e, J. J. Benchmarking optimization software with performance proﬁles. Mathematical pro- gramming, 91(2):201–213, 2002. Dror, R., Shlomov, S., and Reichart, R. Deep dominance- how to properly compare deep neural models. In Pro- ceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 2773–2785, 2019. Duan, Y., Chen, X., Houthooft, R., Schulman, J., and Abbeel, P. Benchmarking deep reinforcement learning for continuous control. In International conference on machine learning, pp. 1329–1338. PMLR, 2016. Dulac-Arnold, G., Mankowitz, D., and Hester, T. Chal- arXiv lenges of real-world reinforcement learning. preprint arXiv:1904.12901, 2019. Dwibedi, D., Tompson, J., Lynch, C., and Sermanet, P. Learning actionable representations from visual observa- tions. In 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 1577–1584. IEEE, 2018. Efron, B. Bootstrap methods: another look at the jackknife. In Breakthroughs in statistics, pp. 569–593. Springer, 1992. Finn, C., Tan, X. Y., Duan, Y., Darrell, T., Levine, S., and Abbeel, P. Learning visual feature spaces for robotic ma- nipulation with deep spatial autoencoders. arXiv preprint arXiv:1509.06113, 25, 2015. Fu, J., Kumar, A., Nachum, O., Tucker, G., and Levine, S. D4{rl}: Datasets for deep data-driven reinforcement learning, 2021. Fujimoto, S., van Hoof, H., and Meger, D. Addressing func- tion approximation error in actor-critic methods. In ICML, pp. 1582–1591, 2018. URL http://proceedings. mlr.press/v80/fujimoto18a.html. Stabilizing Off-Policy Deep Reinforcement Learning from Pixels Ghiasi, G., Lin, T.-Y., and Le, Q. V. Dropblock: A regular- ization method for convolutional networks. In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa- Bianchi, N., and Garnett, R. (eds.), Advances in Neural Information Processing Systems, volume 31. Curran As- sociates, Inc., 2018. URL https://proceedings. neurips.cc/paper/2018/file/ 7edcfb2d8f6a659ef4cd1e6c9b6d7079-Paper. pdf. Gogianu, F., Berariu, T., Rosca, M. C., Clopath, C., Bu- soniu, L., and Pascanu, R. Spectral normalisation for deep reinforcement learning: An optimisation per- In Meila, M. and Zhang, T. (eds.), Pro- spective. ceedings of the 38th International Conference on Ma- chine Learning, volume 139 of Proceedings of Machine Learning Research, pp. 3734–3744. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/ v139/gogianu21a.html. Haarnoja, T., Zhou, A., Abbeel, P., and Levine, S. Soft actor- critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor. In Dy, J. and Krause, A. (eds.), Proceedings of the 35th International Confer- ence on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 1861–1870. PMLR, 10– 15 Jul 2018a. URL https://proceedings.mlr. press/v80/haarnoja18b.html. Haarnoja, T., Zhou, A., Hartikainen, K., Tucker, G., Ha, S., Tan, J., Kumar, V., Zhu, H., Gupta, A., Abbeel, P., et al. Soft actor-critic algorithms and applications. arXiv preprint arXiv:1812.05905, 2018b. Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., and Davidson, J. Learning latent dynamics for planning from pixels. In International Conference on Machine Learning, pp. 2555–2565. PMLR, 2019. Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M. Dream to control: Learning behaviors by latent imagination. In International Conference on Learning Representations, 2020. Hernandez-Garcia, J. F. and Sutton, R. S. Understanding multi-step deep reinforcement learning: A systematic study of the dqn target, 2019. Hessel, M., Modayil, J., Van Hasselt, H., Schaul, T., Ostro- vski, G., Dabney, W., Horgan, D., Piot, B., Azar, M., and Silver, D. Rainbow: Combining improvements in deep re- inforcement learning. In Thirty-second AAAI conference on artiﬁcial intelligence, 2018. Kaiser, L., Babaeizadeh, M., Milos, P., Osi´nski, B., Camp- bell, R. H., Czechowski, K., Erhan, D., Finn, C., Koza- kowski, P., Levine, S., Mohiuddin, A., Sepassi, R., Tucker, G., and Michalewski, H. Model based reinforce- ment learning for Atari. In International Conference on Learning Representations, 2020. Kalashnikov, D., Irpan, A., Pastor, P., Ibarz, J., Herzog, A., Jang, E., Quillen, D., Holly, E., Kalakrishnan, M., Vanhoucke, V., et al. Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation. arXiv preprint arXiv:1806.10293, 2018. Kearns, M. J. and Singh, S. P. Bias-variance error bounds for temporal difference updates. In Proceedings of the Thirteenth Annual Conference on Computational Learn- ing Theory, COLT ’00, pp. 142–147, San Francisco, CA, USA, 2000. Morgan Kaufmann Publishers Inc. ISBN 155860703X. Keskar, N. S., Mudigere, D., Nocedal, J., Smelyanskiy, M., and Tang, P. T. P. On large-batch training for deep learn- ing: Generalization gap and sharp minima. In 5th Inter- national Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017. URL https: //openreview.net/forum?id=H1oyRlYgg. Kielak, K. P. Do recent advancements in model-based deep reinforcement learning really improve data efﬁciency? 2019. Kingma, D. P. and Ba, J. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. Kostrikov, I., Yarats, D., and Fergus, R. Image augmentation is all you need: Regularizing deep reinforcement learning from pixels. In International Conference on Learning Representations. 2021. Kumar, A., Agarwal, R., Ghosh, D., and Levine, S. Im- plicit under-parameterization inhibits data-efﬁcient deep In International Conference reinforcement learning. on Learning Representations, 2021. URL https:// openreview.net/forum?id=O9bnihsFfXU. Laskin, M., Lee, K., Stooke, A., Pinto, L., Abbeel, P., and Srinivas, A. Reinforcement learming with augmented In Advances in Neural Information Processing data. Systems 33. 2020a. Laskin, M., Srinivas, A., and Abbeel, P. CURL: Contrastive unsupervised representations for reinforcement learning. In Proceedings of the 37th International Conference on Machine Learning, 2020b. Lee, A. X., Nagabandi, A., Abbeel, P., and Levine, S. Stochastic latent actor-critic: Deep reinforcement learning with a latent variable model. arXiv preprint arXiv:1907.00953, 2019. Stabilizing Off-Policy Deep Reinforcement Learning from Pixels Levine, S., Kumar, A., Tucker, G., and Fu, J. Ofﬂine rein- forcement learning: Tutorial, review, and perspectives on open problems, 2020. Li, H., Xu, Z., Taylor, G., Studer, C., and Goldstein, T. Visualizing the loss landscape of neural nets. In Neural Information Processing Systems, 2018. Lillicrap, T. P., Hunt, J. J., Pritzel, A., Heess, N., Erez, T., Tassa, Y., Silver, D., and Wierstra, D. Continuous control with deep reinforcement learning. arXiv preprint arXiv:1509.02971, 2015. Liu, S., Papailiopoulos, D., and Achlioptas, D. Bad global minima exist and sgd can reach them. Advances in Neural Information Processing Systems, 33, 2020. Machado, M. C., Bellemare, M. G., Talvitie, E., Veness, J., Hausknecht, M., and Bowling, M. Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents. Journal of Artiﬁcial Intelligence Research, 61:523–562, 2018. Maennel, H., Alabdulmohsin, I. M., Tolstikhin, I. O., Baldock, R., Bousquet, O., Gelly, S., and Keysers, D. What do neural networks learn when trained with random labels? In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M. F., and Lin, H. (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 19693–19704. Curran Associates, URL https://proceedings. Inc., neurips.cc/paper/2020/file/ e4191d610537305de1d294adb121b513-Paper. pdf. 2020. Mann, H. B. and Whitney, D. R. On a Test of Whether one of Two Random Variables is Stochastically Larger than the Other. The Annals of Mathematical Statistics, 18(1):50 – 60, 1947. doi: 10.1214/aoms/1177730491. URL https: //doi.org/10.1214/aoms/1177730491. Miyato, T., Kataoka, T., Koyama, M., and Yoshida, Y. Spec- tral normalization for generative adversarial networks. In International Conference on Learning Representations, 2018. URL https://openreview.net/forum? id=B1QRgziT-. Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., and Riedmiller, M. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602, 2013. Moskovitz, T., Parker-Holder, J., Pacchiano, A., Arbel, M., and Jordan, M. Tactical optimism and pessimism for deep reinforcement learning. In Beygelzimer, A., Dauphin, Y., Liang, P., and Vaughan, J. W. (eds.), Advances in Neural Information Processing Systems, 2021. URL https: //openreview.net/forum?id=a4WgjcLeZIn. Neyshabur, B., Bhojanapalli, S., McAllester, D., and Srebro, N. Exploring generalization in deep learning. In Proceed- ings of the 31st International Conference on Neural In- formation Processing Systems, NIPS’17, pp. 5949–5958, Red Hook, NY, USA, 2017. Curran Associates Inc. ISBN 9781510860964. Parker-Holder, J., Rajan, R., Song, X., Biedenkapp, A., Miao, Y., Eimer, T., Zhang, B., Nguyen, V., Calandra, R., Faust, A., Hutter, F., and Lindauer, M. Automated rein- forcement learning (autorl): A survey and open problems, 2022. Rahaman, N., Baratin, A., Arpit, D., Draxler, F., Lin, M., Hamprecht, F., Bengio, Y., and Courville, A. On the spec- tral bias of neural networks. In International Conference on Machine Learning, pp. 5301–5310. PMLR, 2019. Rosca, M., Weber, T., Gretton, A., and Mohamed, S. A case for new neural networks smoothness constraints. In ”I Can’t Believe It’s Not Better!” NeurIPS 2020 workshop, 2020. URL https://openreview.net/forum? id=_b-uT9wCI-7. Rummery, G. A. and Niranjan, M. On-line Q-learning using connectionist systems. Technical Report TR 166, Cam- bridge University Engineering Department, Cambridge, England, 1994. Schaul, T., Ostrovski, G., Kemaev, I., and Borsa, D. Return- based scaling: Yet another normalisation trick for deep rl, 2021. Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O. Proximal policy optimization algorithms. CoRR, abs/1707.06347, 2017. URL http://arxiv. org/abs/1707.06347. Schwarzer, M., Anand, A., Goel, R., Hjelm, R. D., Courville, A., and Bachman, P. Data-efﬁcient reinforcement learn- ing with self-predictive representations. arXiv preprint arXiv:2007.05929, 2020. Shorten, C. and Khoshgoftaar, T. M. A survey on image data augmentation for deep learning. Journal of Big Data, 6(1):1–48, 2019. Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M. Deterministic policy gradient algorithms. 2014. Silver, D., Hubert, T., Schrittwieser, J., Antonoglou, I., Lai, M., Guez, A., Lanctot, M., Sifre, L., Kumaran, D., Grae- pel, T., et al. Mastering chess and shogi by self-play with a general reinforcement learning algorithm. arXiv preprint arXiv:1712.01815, 2017. Stabilizing Off-Policy Deep Reinforcement Learning from Pixels Song, X., Jiang, Y., Tu, S., Du, Y., and Neyshabur, B. Ob- servational overﬁtting in reinforcement learning. In Inter- national Conference on Learning Representations, 2020. In International Conference reinforcement learning. on Learning Representations, 2022. URL https:// openreview.net/forum?id=_SJ-_yyes8. Zhu, H., Yu, J., Gupta, A., Shah, D., Hartikainen, K., Singh, A., Kumar, V., and Levine, S. The ingredients of real- world robotic reinforcement learning. arXiv preprint arXiv:2004.12570, 2020. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. Dropout: A simple way Jour- to prevent neural networks from overﬁtting. nal of Machine Learning Research, 15(56):1929–1958, URL http://jmlr.org/papers/v15/ 2014. srivastava14a.html. Student. The probable error of a mean. Biometrika, 6 (1):1–25, 1908. ISSN 00063444. URL http://www. jstor.org/stable/2331554. Sutton, R. Learning to predict by the method of temporal differences. Machine Learning, 3:9–44, 08 1988. doi: 10.1007/BF00115009. Sutton, R. S., McAllester, D. A., Singh, S. P., and Mansour, Y. Policy gradient methods for reinforcement learning with function approximation. In Advances in neural in- formation processing systems, pp. 1057–1063, 2000. Tassa, Y., Doron, Y., Muldal, A., Erez, T., Li, Y., Casas, D. d. L., Budden, D., Abdolmaleki, A., Merel, J., Lefrancq, arXiv preprint A., et al. Deepmind control suite. arXiv:1801.00690, 2018. Van Hasselt, H., Doron, Y., Strub, F., Hessel, M., Sonnerat, N., and Modayil, J. Deep reinforcement learning and the deadly triad. arXiv preprint arXiv:1812.02648, 2018. van Hasselt, H. P., Hessel, M., and Aslanides, J. When to use parametric models in reinforcement learning? Advances in Neural Information Processing Systems, 32:14322– 14333, 2019. Vinyals, O., Babuschkin, I., Czarnecki, W. M., Mathieu, M., Dudzik, A., Chung, J., Choi, D. H., Powell, R., Ewalds, T., Georgiev, P., et al. Grandmaster level in starcraft ii using multi-agent reinforcement learning. Nature, 575 (7782):350–354, 2019. Individual comparisons by ranking Wilcoxon, F. Biometrics Bulletin, 1(6):80–83, 1945. methods. ISSN 00994987. URL http://www.jstor.org/ stable/3001968. Yarats, D., Zhang, A., Kostrikov, I., Amos, B., Pineau, J., and Fergus, R. Improving sample efﬁciency in model- free reinforcement learning from images. Proceedings of the AAAI Conference on Artiﬁcial Intelligence, 35(12): 10674–10681, May 2021. URL https://ojs.aaai. org/index.php/AAAI/article/view/17276. Yarats, D., Fergus, R., Lazaric, A., and Pinto, L. Master- ing visual continuous control: Improved data-augmented Stabilizing Off-Policy Deep Reinforcement Learning from Pixels A. Detailed Results A.1. DMC Medium and Hard Tasks In Table 4, we show the performance in each of the evaluated 15 DMC environments by reporting the mean and standard deviations over the cumulative returns obtained midway and at the end of training for the medium and hard benchmark tasks, respectively. A-LIX attains state-of-the-art performance in the majority of the tasks at both reported checkpoints, while still closely matching DrQ-v2’s performance on the remaining tasks. On the other hand, DrQ-v2 struggles to consistently solve some of the harder exploration tasks such as Cartpole Swingup Sparse and Humanoid Run, as shown by the high standard deviations. Interestingly, unlike in the simpler DMC benchmark from Hafner et al. (2019) with higher action repeat, CURL appears have a slight edge over DrQ. In particular, the self-supervised signal from CURL appears to aid precisely in the sparse reward environments where DrQ-v2 struggles. Hence, this appears to suggest that including an additional self-supervised signal to the TD-loss, lessens the hindering effects of a lower-magnitude reward signal. We interpret this result as additional evidence showing how addressing any individual component of the deadly triad helps counteracting the catastrophic self-overﬁtting phenomenon. We also test the signiﬁcance of our results by performing a Wilcoxon signed-rank test (Wilcoxon, 1945) between A-LIX and DrQ-v2. We perform a paired rank test across both seeds and tasks, allowing us to obtain an p-value that takes into account both population size and relative performance gains across all tasks. The choice of Wilcoxon signed-rank test also does not presume normality in the distributions of performance which we believe is a more appropriate assumption than for instance a paired t-test (Student, 1908), despite a potential loss of statistical power. To ensure correct population pairing, A-LIX and DrQ-v2 seeds were identical, resulting in the same initially collected data and network initialization. Performing this test over all 15 tasks and 5 seeds, we achieve a p-value of 0.0057 at 50% total frames (1.5M and 15M for Medium and Hard respectively) and 0.0053 at 100% total frames (3.0M and 30M for Medium and Hard Respectively), much lower than the typical rejection criteria of p > 0.05. We therefore believe this shows clear evidence that our results in DMC are strongly statistically signiﬁcant. Table 4. Full results for the DeepMind Control Suite benchmark. Each displayed return is averaged over 10 random seeds and from 10 evaluation runs collected at each experience checkpoint. Medium tasks SAC CURL DrQ DrQv2 A-LIX (Ours) SAC CURL DrQ DrQv2 A-LIX (Ours) 1.5M frames 3.0M frames 8±9 9±8 6±5 24±27 Acrobot Swingup 256±47 Cartpole Swingup Sparse 118±233 479±329 318±389 485±396 Cheetah Run 507±114 788±59 792±29 Finger Turn Easy 190±137 297±150 199±132 854±73 Finger Turn Hard 79±73 174±106 100±63 491±182 Hopper Hop 184±127 268±91 198±102 0±0 Quadruped Run 164±91 129±97 419±204 68±72 Quadruped Walk 134±53 144±149 591±256 75±65 Reach Duplo 220±7 8±12 8±10 1±1 Reacher Easy 52±64 707±142 600±201 971±4 Reacher Hard 463±196 320±233 727±172 3±2 Walker Run 379±234 474±148 571±276 26±4 270±99 718±250 806±78 546±101 587±109 287±48 528±107 776±37 212±3 887±19 720±83 691±10 7±8 6±5 28±25 442±64 12±11 185±295 499±349 316±389 505±412 590±95 835±45 873±60 200±155 309±176 216±158 934±54 902±77 100±78 146±95 86±70 0±0 224±135 285±96 240±123 63±45 175±104 130±59 523±271 168±49 142±67 920±36 48±32 228±2 9±9 7±10 2±3 115±98 667±182 612±181 940±50 10±23 678±350 397±273 935±49 447±224 547±143 616±297 25±3 402±100 742±250 864±78 901±109 906±101 372±48 759±107 900±37 221±3 966±19 855±83 756±10 Average score 52.28 291.73 281.03 547.96 585.67 63.80 326.45 300.27 671.40 720.30 15.0M frames 30.0M frames Hard tasks Humanoid Walk Humanoid Stand Humanoid Run Average score SAC CURL DrQ DrQv2 A-LIX (Ours) SAC CURL DrQ DrQv2 A-LIX (Ours) 7±3 5±3 5±3 5.64 5±3 6±3 6±2 5.74 3±2 4±3 5±3 243±162 167±159 22±30 476±79 519±94 122±59 4.02 144.16 372.78 4±3 6±3 3±3 4.30 4±3 6±2 4±3 4.89 5±3 6±2 4±2 675±86 588±63 170±122 754±79 781±94 242±59 4.90 477.74 592.48 We now compare our results using the Rliable framework introduced in Agarwal et al. (2021) (see App. A.3 for a detailed explanation about the metrics introduced). Stabilizing Off-Policy Deep Reinforcement Learning from Pixels Figure 11. Performance proﬁles at 50% (left) and 100% (right) of the total steps in Medium and Hard DMC Tasks. We plot performance proﬁles in Fig. 11 at both 50% and 100% the total training steps in DMC, which aim to represent sample efﬁciency and asymptotic performance respectively. We see that in almost all cases, A-LIX improves upon DrQ-v2. (a) Overall ranking statistics at 50% (top) and 100% (bottom) of the to- tal steps in Medium and Hard DMC Tasks. (b) Aggregate IQM (left) and Optimality Gap (right) metrics at 50% of the total steps in Medium and Hard DMC Tasks. We plot ranking statistics in Fig. 11 at both 50% and 100% the total training steps in DMC. We see that A-LIX clearly appears most in the 1st ranked column, and rarely appears in lower ranked (i.e., > 3), suggesting strong performance across all environments in DMC Medium and Hard. We also provide a further aggregated statistics plot in Fig. 12b (this time at 50% the total steps), which shows A-LIX is particularly sample-efﬁcient and consistent (i.e., low error bars) across all environments. (a) 50% total steps. (b) 100% total steps. Figure 13. Probability of Improvement statitistics at both 50% (left) and 100% (right) of the total timesteps in Medium and Hard DMC Tasks. In Fig. 13 we observe that A-LIX likely improves over prior work, and note that whilst the improvement probability over DrQ-v2 may seem slightly low at ∼60%, we note that this value is in line with statistics in prior works that achieve signiﬁcant gains (as seen in Agarwal et al. (2021)), and furthermore it does not take into account absolute performance values, and instead only compares relative values, which explains why the gains of A-LIX appear larger when evaluated under IQM and OG. Furthermore, the lower CI for 50% total steps does not fall below 0.5, which means improvements are indeed statistically signiﬁcant. 100% Total Steps 50% Total Steps τ > e r o c s h t i w s n u r f o n o i t c a r F 1.00 0.75 0.50 0.25 0.00 τ > e r o c s h t i w s n u r f o n o i t c a r F 1.00 0.75 0.50 0.25 0.00 0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0 Normalized Score (τ) Normalized Score (τ) A-LIX DrQv2 DrQ CURL SAC 50% Total Steps 100 80 60 40 20 0 100 ) % n i ( n o i t c a r F 100% Total Steps 80 60 40 20 0 1 2 3 4 5 Ranking A-LIX DrQv2 DrQ CURL SAC A-LIX DrQv2 DrQ CURL SAC IQM Optimality Gap 0.2 0.4 0.6 0.45 0.60 0.75 0.90 Max Normalized Score P(A-LIX > Y) Y m h t i r o g A l SAC CURL DrQ DrQv2 0.60 0.75 0.90 Y m h t i r o g A l SAC CURL DrQ DrQv2 P(A-LIX > Y) 0.60 0.75 0.90 Stabilizing Off-Policy Deep Reinforcement Learning from Pixels A.2. Atari 100k In Table 5, we show the ﬁnal average performance for all the evaluated algorithms in each of the twenty-six tasks in the Atari 100k benchmark. A-LIX outperforms SPR, the previous state-of-the-art off-policy algorithm on this benchmark, on 16 out of 26 tasks. Moreover, it attains comparatively similar performance on most of the remaining tasks despite using no augmentation, auxiliary losses, or model-based elements. Table 5. Full results for the Atari 100k benchmark, following the evaluation protocol from Machado et al. (2018). We report the results collected from 10 random seeds. Tasks Random Human SimPLe DER OTRainbow CURL DrQ SPR A-LIX (Ours) Alien Amidar Assault Asterix Bank Heist Battle Zone Boxing Breakout Chopper Command Crazy Climber Demon Attack Freeway Frostbite Gopher Hero Jamesbond Kangaroo Krull Kung Fu Master Ms Pacman Pong Private Eye Qbert Road Runner Seaquest Up N Down Human Norm. Mean Human Norm. Median # SOTA # Super Average Rank 227.80 5.80 222.40 210.00 14.20 2360.00 0.10 1.70 811.00 10780.50 152.10 0.00 65.20 257.60 1027.00 29.00 52.00 1598.00 258.50 307.30 -20.70 24.90 163.90 11.50 68.40 533.40 0.000 0.000 N/A N/A N/A 7127.70 1719.50 742.00 8503.30 753.10 37187.50 12.10 30.50 7387.80 35829.40 1971.00 29.60 4334.70 2412.50 30826.40 302.80 3035.00 2665.50 22736.30 6951.60 14.60 69571.30 13455.00 7845.00 42054.70 11693.20 1.000 1.000 N/A N/A N/A 616.9 88 527.2 1128.3 34.2 5184.4 9.1 16.4 1246.9 62583.6 208.1 20.3 254.7 771 2656.6 125.3 323.1 4539.9 17257.2 1480 12.8 58.3 1288.8 5640.6 683.3 3350.3 0.443 0.144 7 2 3.92 739.9 188.6 431.2 470.8 51 10124.6 0.2 1.9 861.8 16185.3 508 27.9 866.8 349.5 6857 301.6 779.3 2851.5 14346.1 1204.1 -19.3 97.8 1152.9 9600 354.1 2877.4 0.285 0.161 1 2 5.00 824.7 82.8 351.9 628.5 182.1 4060.6 2.5 9.8 1033.3 21327.8 711.8 25 231.6 778 6458.8 112.3 605.4 3277.9 5722.2 941.9 1.3 100 509.3 2696.7 286.9 2847.6 0.264 0.204 1 1 5.21 558.2 142.1 600.6 734.5 131.6 14870 1.2 4.9 1058.5 12146.5 817.6 26.7 1181.3 669.3 6279.3 471 872.5 4229.6 14307.8 1465.5 -16.5 218.4 1042.4 5661 384.5 2955.2 0.381 0.175 1 2 3.92 771.2 102.8 452.4 603.5 168.9 12954 6 16.1 780.3 20516.5 1113.4 9.8 331.1 636.3 3736.3 236 940.6 4018.1 9111 960.5 -8.5 -13.6 854.4 8895.1 301.2 3180.8 0.357 0.268 1 2 4.85 801.5 176.3 571 977.8 380.9 16651 35.8 17.1 974.8 42923.6 545.2 24.4 1821.5 715.2 7019.2 365.4 3276.4 3688.9 13192.7 1313.2 -5.9 124 669.1 14220.5 583.1 28138.5 0.704 0.415 4 7 2.88 902 174.27 660.53 809.5 639.4 14470 21.5 23.52 747 53166 888.15 31.04 1845.7 500.6 7185.85 341.5 6507 4884.04 16316 1258.4 6.03 100 2974 17471 654.6 5011.7 0.753 0.411 11 7 2.21 We now present additional evaluations under the Rliable framework, continuing on from the analysis in Fig. 10b. Figure 14. Performance proﬁles with linear (left) and logarithmic (right) scaling in Atari 100k. In Fig. 14 A-LIX performs noticeably better than previous work, and performs at least as well as SPR over all settings of τ > e r o c s h t i w s n u r f o n o i t c a r F 1.00 0.75 0.50 0.25 0.00 0.0 Score Distributions with Non Linear Scaling Score Distributions τ > e r o c s h t i w s n u r f o n o i t c a r F 1.00 0.75 0.50 0.25 0.00 0.5 1.0 Human Normalized Score (τ) 1.5 2.0 0.0 0.1 0.2 0.5 1.0 2.0 Human Normalized Score (τ) A-LIX SPR DrQ CURL OTR DER SimPLe Stabilizing Off-Policy Deep Reinforcement Learning from Pixels normalized scores. (a) Ranking statistics. (b) Probability of improvement statistics. Figure 15. Bootstrapped ranking statistics (left) and probability of improvement plots (right) on Atari 100k. In Fig. 15a A-LIX constitutes the majority of the algorithms ranked in 1st, and shows far fewer instances of being ranked in lower positions (i.e., > 4). In Fig. 15b we observe A-LIX likely improves upon prior work. Similar to Fig. 13, while the ∼60% improvement value over SPR may seem low, this is justiﬁed due to shortcomings in this metric, such as not taking into account actual performance values, and instead relative improvements. Furthermore, the lower CI does not fall below 0.5, which means improvements due to A-LIX are statistically signiﬁcant. A.3. Rliable: A Primer In addition to providing traditional methods of evaluation (e.g., performance tables, signiﬁcance testing), we use robust metrics and evaluation strategies introduced in Rliable (Agarwal et al., 2021). Rliable advocates for computing aggregate performance statistics not just across many seeds, but also across the many tasks within a benchmark suite. We give details on how these metrics achieve reliable performance evaluation in RL, denoting number of seeds as N and number of tasks as M . We follow Agarwal et al. (2021) as closely as possible; please refer to their paper for further details. A.3.1. SEED AND TASK AGGREGATION In order to aggregate performances across different tasks in the same benchmark suite, we must ﬁrst normalize each benchmark to the same range. In Atari, this is usually done by normalizing scores with respect to those achieved by humans, and in DMC this is done with respect to the maximum achievable score (i.e., 1, 000). We refer to this normalized score as τ . A.3.2. IQM AND OG Interquartile Mean (IQM) takes the middle 50% of the runs across seeds and benchmarks (i.e., [N M/2]) and then calculates its mean score, improving outlier robustness whilst maintaining statistical efﬁciency. Optimality Gap (OG) calculates the proportion of performances (N M ) that fail to meet a minimum threshold γ, with the assumption that improvements beyond γ are not important. In both cases, stratiﬁed bootstrap sampling is used to calculate conﬁdence intervals (CIs). A.3.3. PERFORMANCE PROFILES Performance proﬁles are a form of empirical CDF, but with stratiﬁed bootstrap sampling to produce conﬁdence bands that account for the underlying variability of the score. We can also establish ‘stochastic dominance’ by observing whether one method’s performance proﬁle is consistently above another’s for all normalized performance values τ . A.3.4. RANKING Ranking shows the proportion of times a given algorithm ranks in a given position across all tasks, with distributions produced using stratiﬁed bootstrap sampling having 200, 000 repetitions. A.3.5. PROBABILITY OF IMPROVEMENT Probability of improvement is calculated by calculating the Mann-Whitney U-statistic (Mann & Whitney, 1947) across all M tasks. The distribution is then plotted as a boxplot, and if the lower CI > 0.5, the improvement is statistically signiﬁcant. ) % n i ( n o i t c a r F 100 80 60 40 20 0 1 2 3 4 5 6 7 Ranking A-LIX SPR DrQ CURL OTR DER SimPLe P(A-LIX > Y) Y m h t i r o g A l SPR DrQ CURL OTR DER SimPLe 0.6 0.7 0.8 0.9 Stabilizing Off-Policy Deep Reinforcement Learning from Pixels B. Experiments Description B.1. Ofﬂine Experiments We follow the original training hyperparameters of DrQ-v2, and run policy evaluation and policy improvement until we saw convergence in the TD-loss, which would occur at similar points in all agents (i.e., between 10-20k and 5-10k steps of SGD in policy evaluation and policy iteration respectively). For the proprioceptive experiments, we keep everything consistent, except the input to the critic and actor MLP layers are now the proprioceptive states from the DMC simulator, not the latent representation z from the encoder. That is to say we do not modify the MLP architectures nor their learning rates in the interests of a fair comparison. Furthermore, for any given seed of the ofﬂine experiment, we also instantiate all networks in the agents identically and train on the same random ofﬂine data, with minibatches presented in the same order. We also note that a similar algorithm is described in Brandfonbrener et al. (2021), but in the context of minimizing extrapolation errors. Now we present some additional analysis to provide further context to our ofﬂine experiments. First, we see that the proprioceptive statistics mirror those of the augmented agent, further illustrating the crucial role of CNN regularization for successful TD-learning from pixels: Figure 16. Q values and Pearson Correlation of the ofﬂine Proprioceptive agent on an ofﬂine ﬁxed batch. Secondly, we observe that the exact same self-overﬁt also manifests in the online setting by plotting the Pearson correlation values over the initial stages of training in 5 seeds, conﬁrming that phenomena of our ofﬂine analysis applies to the online RL problem: Figure 17. Pearson Correlation of augmented and non-augmented online agents in Cheetah Run and Quadruped Walk across 5 seeds. Shaded lines represent individual runs, and solid lines represent the median. We see that augmented agents do not immediately overﬁt to their target networks, and become correlated only after useful signal is learned. B.2. Jacobian Analysis In order to measure local sensitivity, we linearize the encoder around its input using a Taylor series expansion. Consider an N -dimensional input x ∈ RN and perturbation (cid:15) ∈ RN , an M -dimensional output y ∈ RM , and a function F : RN → RM . Now, performing a Taylor series expansion around ˜x: F(˜x + (cid:15)) = F(˜x) + (cid:15)F(x)∇T |x=˜x + (cid:15)2 2 ∇F(x)∇T |x=˜x + . . . ≈ F(˜x) + J(˜x)(cid:15) = ˜y (6) (7) (8) Q values during training l n o i t a e r r o C n o s r a e P 1.5 1.0 0.5 0.0 0.5 l s e u a V Q 0 2000 4000 6000 8000 SGD Steps Correlation of Q with Qtarget and r 1.0 0.8 0.6 0.4 0.2 0.0 Qtarget r 0 2000 4000 6000 8000 SGD Steps l n o i t a e r r o C n o s r a e P 1.0 0.8 0.6 0.4 0.2 Cheetah Run 20000 40000 Frames Quadruped Walk 1.0 0.9 0.8 0.7 0.6 5000 7500 10000 12500 Qtarget Augs Qtarget No Augs Frames r Augs r No Augs Stabilizing Off-Policy Deep Reinforcement Learning from Pixels where we make the approximation in the second line by dropping the second order/Hessian and higher terms under the assumption the perturbation vector (cid:15) is small. This allows us to write F in the form of a local linear system: y = F(x) + J(x)(cid:15). It is straightforward to see that if the entries of the Jacobian matrix J are larger, then small perturbations (cid:15) will cause larger changes in the output y. To measure the magnitude of the Jacobian entries, we take the Frobenius norm: ||J(x)||F = (cid:88) (cid:88) n m (cid:19)2 (cid:18) ∂Fm(x) ∂xn (9) where xn is the ‘n’th entry of x and Fm is the ‘m’th entry of the codomain of F. The calculation of the Jacobian is trivial through the use of an automatic differentiation framework. In our analysis we calculate the Jacobians of both agents on of a ﬁxed batch of 128 frame stacked images taken from the ofﬂine training dataset, and compare the corresponding ratios of their Frobenius norms, and take this average ratio over the batch across 4 seeds. C. Additional Analysis C.1. Adaptive ND Dual Objective Optimization The alternative N D score with increased outlier robustness, (cid:103)N D, proposed in Section 4.3 is inspired by recordings of signal-to-noise ratio measurements. In particular, by passing the individual normalized D(z) terms through a log(1 + x) smoothing function we downweight the effect that large individual outliers might have on this aggregated metric. We would like to remark that since we set up the optimization of S with a dual objective, changes in the actual target value relating to some appropriate smoothness constraint are mostly irrelevant when considering the optimization’s dynamics. Therefore, we argue that tuning S with the actual N D should not considerably diverge from tuning S based on a re-scaled appropriate target for (cid:103)N D. We provide further plots comparing agent performance and respective adaptive parameter S during training: Figure 18. Performance of agents across 4 different seeds of the Cheetah Run environment and their adaptive scalar parameter S. We observe that initially, S is high until agents learn useful behaviors, whereupon it drops to maintain ND due to presence of useful signal in the feature gradients. Figure 19. Performance of agents across 4 different seeds of the Quadruped Run environment and their adaptive scalar parameter S. We observe that as meaningful behaviors are learned in agents towards the end of training, S falls accordingly, whereupon it drops to maintain ND due to presence of useful signal in the feature gradients. We see the same effect in these two contrasting environments; in Cheetah Run, where learning is more stable due to more predictable initializations and fewer degrees of freedom, we see the A-LIX parameter S drop almost immediately as the TD-targets quickly become more accurate. In the less stable Quadruped Run, we also notice this annealing effect, however this occurs later on in training, when the agent can consistently recover from poor initializations. Seed 0 Seed 1 Seed 2 Seed 3 500 n r u t e R 0 0.0 1.0 0.5 Frames (×106) 1.5 0.0 1.0 0.5 Frames (×106) 1.5 Agent Return 0.0 1.0 0.5 Frames (×106) A-LIX Parameter S 1.5 2 1 l e u a V S X I L - A 0.0 1.0 0.5 Frames (×106) 1.5 Seed 0 Seed 1 Seed 2 Seed 3 800 600 n r u t e R 400 1.5 2.0 2.5 3.0 1.5 2.0 2.5 3.0 1.5 2.0 2.5 3.0 1.5 2.0 2.5 3.0 Frames (×106) Frames (×106) Agent Return Frames (×106) A-LIX Parameter S Frames (×106) l e u a V S X I L - A 0.6 0.4 Stabilizing Off-Policy Deep Reinforcement Learning from Pixels C.2. N-Step Returns Large n-step rewards have become an important part of many algorithms that use TD-learning from visual observations. As motivated in Section 3, large n-step rewards can help towards mitigating self-overﬁtting by densifying the reward and downweighting the contribution of the inaccurate target critic, especially early in training; indeed as shown in (Yarats et al., 2022), using 1-step learning has a signiﬁcant negative impact on performance. However, it is known that there is a bias-variance trade-off with multi-step approaches (Kearns & Singh, 2000), and furthermore, almost all approaches using this method do not apply off-policy bias correction when sampling from a replay buffer. While we motivate the use of n-step returns as a way to mitigate self-overﬁtting through incurring fewer 0 reward tuples (especially common in sparse reward environments early in training), we believe there is evidence to show that this introduces bias when n is sufﬁciently large, despite prior work suggesting this is not the case (Hernandez-Garcia & Sutton, 2019). Figure 20. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs. We show in Fig. 20 that 10-step (as is commonly done in algorithms used to solve Atari) returns can mitigate failure seeds as predicted under the visual deadly triad framework (indeed in Cheetah Run there are no seeds that completely ﬂat-line when 10-step returns are used). However, we also see evidence that applying 10-step returns can have negative impacts on convergence and asymptotic performance in Cheetah Run when the deadly triad is sufﬁciently managed, such as using augmentations; in Quadruped Run we see moderate beneﬁt initially, but note that asymptotically the 10-step and 3-step agents converge to the same performance. We also provide further evidence in App. E.3, where applying 10-step returns to an A-LIX agent generally has a laregely negative impact on performance. Finally, we note that trying 20-step returns, as is done in some algorithms that solve Atari (Laskin et al., 2020b), caused signiﬁcant performance reductions in DMC. In conclusion, this provides evidence that we should consider using lower values of ‘n’ in multi-step returns, and achieve this through addressing other elements of the deadly triad. Cheetah Run Quadruped Walk 750 500 250 n r u t e R 0 0 1 2 3 0 1 2 3 Frames (×106) Frames (×106) Augs 3-step No Augs 3-step Augs 10-step No Augs 10-step Stabilizing Off-Policy Deep Reinforcement Learning from Pixels D. Implementation Details In Tables 6 and 7 we provide the full list of hyperparameters used in our implementations for DMC and Atari 100k, respectively. We show signiﬁcant differences from standard practices in bold. In particular, A-LIX uses the same encoder architecture and n-step returns for both benchmarks, highlighting its lower reliance to environment-speciﬁc heuristics. Moreover, unlike prior state-of-the-art algorithms it does not employ any data augmentation or auxiliary loss function. These factors show the effectiveness of our adaptive method in counteracting instabilities from the visual deadly triad without any additional help, highlighting its applicability. Table 6. Full hyperparameters list used for the DeepMind Control A-LIX experiments. Bolded values represent signiﬁcant differences from canonical implementations. DDPG-integration hyperparameters (following (Yarats et al., 2022)) Replay data buffer size Batch size Minimum data before training Random exploration steps Optimizer Policy/critic learning rate Policy/critic β1 Critic UTD ratio Policy UTD ratio Discount γ Polyak coefﬁcient ρ N-step returns Hidden dimensionality Feature dimensionality Nonlinearity Exploration stddev. clip Exploration stddev. schedule Augmentations 1000000 (100000 for Quadruped Run) 256 (512 for Walker Run) 4000 2000 Adam (Kingma & Ba, 2014) medium: 0.0001 hard: 0.00008 0.9 0.5 0.5 0.99 0.99 3 (1 for Walker Run) 1024 medium: 50 hard: 100 ReLU 0.3 medium: linear: 1 → 0.1 in 500000 steps hard: linear: 1 → 0.1 in 2000000 steps OFF A-LIX-speciﬁc hyperparameters Initial maximum sampling shift S Normalized discontinuity targets N D Maximum sampling shift learning rate Maximum sampling shift β1 1.0 0.635 0.003 0.5 Stabilizing Off-Policy Deep Reinforcement Learning from Pixels Table 7. Full hyperparameters list used for the Atari 100k A-LIX experiments. Bolded values represent signiﬁcant differences from canonical implementations. DER-integration hyperparameters Gray-scaling Down-sampling Frames stacked Action repetitions Reward clipping Max episode frames Replay data buffer size Replay period every Batch size Minimum data before training Random exploration steps Optimizer Critic learning rate Critic β1 Critic (cid:15) Max gradient norm Critic UTD ratio Discount γ Target update period N-step returns Feature maps Filter sizes Strides Hidden dimensionality Feature dimensionality Nonlinearity Exploration noisy nets parameter Augmentations True 84 × 84 4 4 [−1, 1] 108000 100000 1 32 1600 1600 Adam (Kingma & Ba, 2014) 0.0001 0.9 0.000015 10 2 0.99 1 3 32, 32, 32 3 × 3, 3 × 3, 3 × 3 2, 1, 1 256 50 ReLU 0.1 OFF A-LIX-speciﬁc hyperparameters Initial maximum sampling shift S Normalized discontinuity targets N D Maximum sampling shift learning rate Maximum sampling shift β1 1.0 0.75 0.0001 0.5 Stabilizing Off-Policy Deep Reinforcement Learning from Pixels E. Additional Ablations E.1. Smoothness Regularization through Spectral Normalization To distinguish between general smoothness contraints in convolutional features, and the smoothness that arises as a result spatial consistency, we apply spectral normalization (Miyato et al., 2018) to the ﬁnal convolutional layer in the encoder to represent the former class of constraints. Spectral normalization operates on the parameters of a network and constrains its outputs to be 1-Lipschitz and has shown beneﬁts in prior work (Gogianu et al., 2021), but does not explicitly enforce a spatial regularization in the features. We train agents without augmentations using spectral normalization. Figure 21. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs. We see that whilst there is clear improvement above the original non-augmented agents in some cases, the performance is still lower than agents that use spatial consistency regularization, such as random shift augmentations. E.2. Is Gradient Smoothing All We Need? Following the argument in Section 4.1, we can view augmentations as a gradient smoothing regularizer. This naturally leads us to ask the following: can we replace the stochastic shifting mechanism with a ﬁxed smoothing mechanism? To test this, we instead apply a Gaussian smoothing kernel to the feature gradients in the CNN, and utilize our N D score to vary the width of the kernel adaptively through training; we call this method A-Gauss (Adaptive Gaussian Feature Gradient Kernel). Figure 22. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs. We see that while there is improvement over non-augmented agents, overall performance is still lower than even simple non-adaptive augmentation. We believe this is due to the Gaussian kernel having too signiﬁcant an effect on the information contained in the feature gradients during backpropagation, causing information to be lost. We believe this explains the effectiveness of shift-augmentations in reinforcement learning, which is that they effectively balance the information contained in the gradients, as well as ensuring their smoothness to reduce overﬁtting. E.3. Ablations to A-LIX We now provide a set of ablations on both DMC and Atari, assessing the impact of individual components in A-LIX. Cheetah Run Quadruped Walk 750 500 250 n r u t e R 0 800 600 400 200 0 1 2 3 0 1 2 3 Frames (×106) Frames (×106) Augs Spectral Normalization Cheetah Run Quadruped Walk 750 500 250 n r u t e R 0 800 600 400 200 0 1 2 3 0 1 2 3 Frames (×106) Frames (×106) Augs A-Gauss Stabilizing Off-Policy Deep Reinforcement Learning from Pixels (a) DMC Control ablations in Cheetah Run (left) and Quadruped Run (right) evaluated over 4 seeds. (b) Atari 100k ablations evaluated over 4 seeds in 4 different Atari 100k tasks. Figure 23. An ablation study of A-LIX, showing the contribution of its individual components to ultimate performance in DMC and Atari 100k. In Fig. 23a we choose the following ablations for DMC: • A-LIX • Adaptive Random Shifts (where the magnitude of the random shift image augmentation is adjusted using the dual ND objective) • LIX • Random Shifts (i.e., DrQ-v2) While we see a slight asymptotic performance improvement in Cheetah Run by using LIX layers instead of random shifts, we notice signiﬁcant differences in the less stable Quadruped Run environment. Concretely, we see much greater stability in both LIX approaches compared with image augmentation approaches, with the former having no failure seeds. Furthermore, we observe stronger asymptotic performance with the inclusion of the adaptive dual objective for both approaches. As motivated in Fig. 19, this is likely a result of reducing the shift parameter as the signal in the target values increases. In Fig. 23b, we choose the following ablations for Atari 100k on a subset of environments that represent a diverse set of tasks and performances with baseline algorithms: • A-LIX • Adaptive Random Shifts (as before) • LIX • A-LIX with 10-step returns • Random Shifts We see that A-LIX performs consistently strongly across the environments tested, always placing in the top 2 with regards to Human Normalized Score. We also notice that generally, LIX layer methods outperform random shift methods apart from in Crazy Climber, where the opposite is true. We believe this may be due to random shift augmentations actually reﬂecting the inductive biases concerning generalization in this environment, and believe this merits further investigation. Finally, we observe that using 10-step returns instead of 3 generally harms performance with A-LIX, with justiﬁcation given in App. C.2. n r u t e R 900 800 700 600 500 400 300 Cheetah Run Quadruped Run 800 600 400 200 A-LIX Adaptive Random Shifts LIX Random Shifts (DrQ-v2) 0 1 Frames (×106) 2 3 0 1 Frames (×106) 2 3 e r o c S d e z i l a m r o N n a m u H 2.0 1.5 1.0 0.5 0.0 A-LIX Adaptive Random Shifts LIX A-LIX 10-step Random Shifts Battle Zone Crazy Climber Ms Pacman Pong Atari 100k Task Stabilizing Off-Policy Deep Reinforcement Learning from Pixels F. Additional Ofﬂine Experiment Analysis F.1. Behavior Cloning without Augmentations Figure 24. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs. The grey dotted horizontal line represents mean expert performance. To illustrate that test time shift invariance is not required, we show that it is possible to learn a policy through supervised learning. To do this, we generate a pixel-based dataset of 500,000 timesteps under an expert policy in Cheetah Run, and jointly train a CNN encoder and policy using behavior cloning/supervised learning by minimizing the loss L = (a − π(o))2 until convergence, where o follows the stacked frame image inputs of (Mnih et al., 2013). We see that the pixel-based policy performs as well as the behavior agent, despite using both higher dimensional data and fewer than half the samples compared to existing expert ofﬂine RL benchmarks from proprioceptive states (Fu et al., 2021). This provides clear evidence that shift invariance is not required at test time, and motivates us to ﬁnd an alternative explanation for why random shift augmentations help the learning process in TD-learning. An alternative perspective is that when the learning signal is strong, as is the case for supervised learning (and later stages during online learning when target values are more accurate), the natural bias of CNNs to learn lower order representations acts as an implicit regularizer (Rahaman et al., 2019) that results in test-time generalization. F.2. Turning Off Augmentations We present more evidence showing that augmentations beneﬁt learning the most at the beginning of training. In Fig. 25 we show the effect of turning off augmentations at 200,000 steps in Cheetah Run, and at 500,000 in Quadruped Walk. In both instances, we see large improvements over not augmenting at all, and both nearly converge to the same value as DrQ-v2, showing further evidence that stability initially in learning is vital. We posit that turning off augmentations here did not yield similar beneﬁts to Fig. 2 due to the fact that there is still high-frequency information in the targets (consider that the augmentations in Cheetah Run are switched off signiﬁcantly earlier) that cause a marginal amount of self-overﬁtting, reducing the rate of learning due to feature space degeneration. Figure 25. Returns of agents over 5 seeds. Solid lines represent median performance, faded lines represent individual runs. The grey dashed line shows when augmentations are turned off. Cheetah Run: BC 900 Expert Perfomance 800 n r u t e R 700 600 0 No Augs 4 1 2 3 SGD Steps (×105) Cheetah Run Quadruped Walk Augs Turned Off Augs Turned Off 750 500 250 n r u t e R 0 0 1 2 3 0 1 2 3 Frames (×106) Frames (×106) Augs No Augs Augs Removed Stabilizing Off-Policy Deep Reinforcement Learning from Pixels F.3. Action-Value Surfaces Here we show the action-value surfaces of the ofﬂine agents’ critics at various tuples sampled from the data. This provides us with an intuition over the loss landscape that the policies will be optimizing during the policy improvement, as accordingly the policy under the deterministic policy gradient (Silver et al., 2014) updates its own weights towards maximizing the action-values deﬁned by the critic through the chain rule: ∇φJπ ≈ Es∼E (cid:2)∇aQθ(s, a)|a=fφ(s)∇φfφ(s)(cid:3) (10) where φ and θ are policy and critic weights respectively. We hypothesize that self-overﬁtting reduces the sensitivity of the critic to actions, discarding important information regarding the causal link between actions and expected returns. To evaluate this, we sample state-action pairs from our replay buffer, and then visualize the action-value surface by sampling two random orthogonal direction vectors from the action space A. We then normalize the direction vectors to have a 2-norm of 1, and then multiply each direction vector by scalars α, β ∈ [−2, 2] respectively. We then plot the action-value surface as a result of adding the random vectors multiplied by their respective scalars onto the action sampled from ofﬂine dataset, giving us a 3-D surface. We clip actions to a ∈ [−1, 1]|A| as actions are squashed to this range in the policy through a truncated normal distribution. (a) Random Sampled State-Action Pair 1 (b) Random Sampled State-Action Pair 2 (c) Random Sampled State-Action Pair 4 (d) Random Sampled State-Action Pair 4 Figure 26. Action-Value loss surface plotted with respect two orthogonal random directions sampled from the action space (i.e., dr ∈ A and d1 ⊥ d2). We see that the critics learned by the augmented agents are more sensitive to changes in action. We believe this is due to the non-augmented agents overﬁtting to the observations, thus ignoring the lower-dimensional action inputs. To validate this, we sampled 128 random state-action tuples from the ofﬂine buffer, and calculated the average variance across the loss surfaces. We see a signiﬁcant difference, with the augmented agent having an average loss surface variance of 0.0129, whereas the non-augmented agent has an average loss surface variance of 0.0044, suggestive of lower sensitivity. F.4. Evidence of Critic MLP Overﬁtting from High-Frequency Features We provide further evidence that measuring high-frequency features through the ND score is vital to understanding overﬁt by showing how overﬁtting is able to occur in the fully-connected critic layers, which are usually stable under proprioceptive observations (see Table 2). To do this, we construct a pattern containing high frequency checkerboard noise c ∈ RH×W , and produce as many patterns as there are channels C in the ﬁnal layer. To ensure consistency across each individual feature map, we normalize each checkerboard pattern by the maximum value in its respective feature map, and then divide by the width of the checkerboard. We then add this pattern multiplied by a scalar α onto each feature map. Critic with Augmentations Critic w/o Augmentations 0.2 0.4 0.6 0.8 0 1 A ctio n S u bsp ace 2 1 0.2 0.4 0.6 0.8 1 0.2 0.4 0.6 0.8 1 0 1 1 0 Loss 1 0 Action Subspace 1 1 Critic with Augmentations Critic w/o Augmentations 0.6 0.8 1.0 0 1 A ctio n S u bsp ace 2 1 0.6 0.8 1.0 1 0.6 0.8 1.0 1 0 1 1 0 Loss 1 0 Action Subspace 1 1 Critic with Augmentations Critic w/o Augmentations 0.4 0.6 0.8 0 1 A ctio n S u bsp ace 2 1 0.4 0.6 0.8 1 0.4 0.6 0.8 1 0 1 1 0 Loss 1 0 Action Subspace 1 1 Critic with Augmentations Critic w/o Augmentations 0.4 0.6 0.8 1 0 A ctio n S u bsp ace 2 1 0.4 0.6 0.8 0.4 0.6 1 0 0.8 Loss 1 0 1 1 1 0 Action Subspace 1 1 Stabilizing Off-Policy Deep Reinforcement Learning from Pixels (a) Example checkerboard artefacts. (b) Sensitivity of agents to checkerboard artifact weight Figure 27. Effect of checkerboard artifacts on feature maps and resultant loss sensitivity. We see the non-augmented agent is signiﬁcantly more sensitive to this high-frequency noise. As we see, the loss is signiﬁcantly more sensitive to high-frequency perturbations in the non-augmented agent, justifying its reliance on high-frequency patterns in the feature maps to enable self-overﬁtting. F.5. Additional Loss Surfaces Here we show the loss surfaces of the ofﬂine agents under policy evaluation with at 1,000, 5,000, and 10,000 training steps. We also show the surfaces respect to only the MLP layers, again following the normalization approach of Li et al. (2018). (a) 1,000 SGD Steps (b) 5,000 SGD Steps (c) 10,000 SGD Steps Figure 28. Loss surface plotted with respect to Encoder parameters at various stages of training. (a) 1,000 SGD Steps (b) 5,000 SGD Steps (c) 10,000 SGD Steps Figure 29. Loss surface plotted with respect to Critic MLP parameters at various stages of training. As we see, the loss surface with respect to the MLP parameters is signiﬁcantly less sharp, lending further evidence that self-overﬁtting is predominately a result of the ﬂexibility of the CNN layers to learn high-frequency features. Augmented Agent Non-Augmented Agent 0.4 0.3 0.2 s s o L D T 0.1 0.0 0.00 Non Augs Augs 0.25 0.50 (Checkerboard Weight) 0.75 Critic with Augmentations Critic w/o Augmentations s s o L D T 0.15 0.10 0.05 1 0 W eig ht S u bsp ace 2 1 0.15 0.10 0.05 1 0.15 0.10 0.05 0 TD Loss 1 0 1 1 1 0 Weight Subspace 1 1 Critic with Augmentations Critic w/o Augmentations s s o L D T 0.75 0.50 0.25 0 1 W eig ht S u bsp ace 2 1 0.75 0.50 0.25 1 0.75 0.50 0.25 0 TD Loss 1 0 1 1 1 0 Weight Subspace 1 1 Critic with Augmentations Critic w/o Augmentations s s o L D T 0.75 0.50 0.25 1 0 W eig ht S u bsp ace 2 1 0.75 0.50 0.25 1 0.75 0.50 0.25 0 TD Loss 1 0 1 1 1 0 Weight Subspace 1 1 Critic with Augmentations Critic w/o Augmentations s s o L D T 4 2 1 0 W eig ht S u bsp ace 2 1 4 2 4 2 1 0 TD Loss 1 0 1 1 1 0 Weight Subspace 1 1 Critic with Augmentations Critic w/o Augmentations s s o L D T 20 10 1 0 W eig ht S u bsp ace 2 1 20 10 20 10 1 0 TD Loss 1 0 1 1 1 0 Weight Subspace 1 1 Critic with Augmentations Critic w/o Augmentations s s o L D T 10 5 1 0 W eig ht S u bsp ace 2 1 10 5 10 5 1 0 TD Loss 1 0 1 1 1 0 Weight Subspace 1 1","['stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'l', 'x', 'r', 'abstract', 'offpolicy', 'reinforcement', 'learn', 'pixel', 'observation', 'notoriously', 'unstable', 'result', 'many', 'successful', 'algorithm', 'com', 'bine', 'different', 'domainspeciﬁc', 'practice', 'auxil', 'iary', 'loss', 'learn', 'meaningful', 'behavior', 'com', 'plex', 'environment', 'work', 'provide', 'novel', 'analysis', 'demonstrate', 'instabil', 'itie', 'arise', 'perform', 'temporaldifference', 'learn', 'convolutional', 'encoder', 'low', 'magnitude', 'reward', 'show', 'new', 'visual', 'deadly', 'triad', 'cause', 'unstable', 'training', 'prema', 'ture', 'convergence', 'degenerate', 'solution', 'phe', 'nomenon', 'name', 'catastrophic', 'selfoverﬁtting', 'base', 'analysis', 'propose', 'method', 'provide', 'adaptive', 'regularization', 'encoder', 'gradient', 'explicitly', 'prevent', 'occurrence', 'catastrophic', 'selfoverﬁtting', 'use', 'dual', 'objective', 'apply', 'alix', 'signiﬁ', 'cantly', 'outperform', 'prior', 'stateoftheart', 'deepmind', 'control', 'atari', 'benchmark', 'data', 'augmentation', 'auxiliary', 'loss', 'introduction', 'core', 'challenge', 'real', 'world', 'reinforcement', 'learn', 'achieve', 'stable', 'training', 'sample', 'efﬁcient', 'algorithm', 'dulacarnold', 'combine', 'property', 'ability', 'reason', 'visual', 'obser', 'vation', 'great', 'implication', 'application', 'rl', 'real', 'world', 'kalashnikov', 'recent', 'work', 'utilize', 'temporaldifference', 'learning', 'make', 'great', 'progress', 'advance', 'sampleefﬁciency', 'fujimoto', 'haarnoja', 'however', 'stability', 'remain', 'key', 'issue', 'offpolicy', 'algorithm', 'equal', 'contribution', 'robotic', 'research', 'depart', 'ment', 'engineering', 'king', 'engineering', 'correspondence', 'ball', 'ballrobotsoxacuk', 'proceeding', 'international', 'conference', 'machine', 'learn', 'copy', 'right', 'author', 'figure', 'performance', 'agent', 'leave', 'atari', 'right', 'benchmark', 'seed', 'alix', 'outperform', 'previous', 'method', 'use', 'image', 'augmentation', 'auxiliary', 'loss', 'duan', 'make', 'general', 'applicability', 'limit', 'compare', 'onpolicy', 'counterpart', 'schulman', 'cobbe', 'time', 'use', 'pixel', 'observation', 'orthogonal', 'source', 'insta', 'bilitie', 'several', 'successful', 'approach', 'rely', 'pre', 'training', 'instead', 'endtoend', 'learn', 'dwibedi', 'fact', 'alternative', 'optimization', 'ob', 'jective', 'large', 'amount', 'simulation', 'datum', 'symbolic', 'observation', 'common', 'factor', 'contempo', 'rary', 'largescale', 'milestone', 'silver', 'vinyal', 'berner', 'work', 'provide', 'novel', 'insight', 'ply', 'successful', 'offpolicy', 'rl', 'algorithm', 'design', 'proprioceptive', 'task', 'pixelbase', 'environment', 'gener', 'ally', 'underwhelme', 'yarat', 'particular', 'provide', 'evidence', 'key', 'element', 'strongly', 'correlate', 'occurrence', 'detrimental', 'insta', 'bilitie', 'exclusive', 'reliance', 'tdloss', 'unregu', 'larized', 'endtoend', 'learn', 'convolutional', 'encoder', 'iii', 'lowmagnitude', 'sparse', 'reward', 'use', 'framework', 'able', 'motivate', 'effectiveness', 'auxiliary', 'loss', 'laskin', 'schwarzer', 'yarat', 'many', 'domainspeciﬁc', 'practice', 'hessel', 'laskin', '2020a', 'explain', 'address', 'element', 'new', 'visual', 'deadly', 'triad', 'focus', 'analysis', 'popular', 'deepmind', 'control', 'suite', 'introduction', 'random', 'shift', 'augmentation', 'play', 'key', 'role', 'cent', 'advance', 'laskin', 'dmc', 'performance', 'atari', 'performance', 'alix', 'alix', 'drqv2', 'spr', 'aug', 'curl', 'sac', 'drq', 'curl', 'otrainbow', 'der', 'simple', 'average', 'score', 'medium', 'hard', 'mean', 'humannormalize', 'score', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'table', 'practice', 'recent', 'pixelbased', 'tdlearning', 'method', 'mitigate', 'element', 'visual', 'deadly', 'triad', 'use', 'return', 'atari', 'curl', 'use', 'return', 'visual', 'deadly', 'mitigation', 'der', 'curl', 'vae', 'loss', 'modelbase', 'loss', 'contrastive', 'loss', 'shiftjitter', 'augmentation', 'shift', 'augmentation', 'shiftjitter', 'augmentation', 'nonoverlappe', 'stride', 'shift', 'augmentation', 'lowdensity', 'returns†', 'return', 'return', 'return', 'return', 'yarat', 'domain', 'observe', 'presence', 'visual', 'deadly', 'triad', 'result', 'tdloss', 'gradient', 'convolutional', 'encoder', 'feature', 'map', 'high', 'spatial', 'frequency', 'ﬁnd', 'gradient', 'spatially', 'inconsistent', 'result', 'degenerate', 'optimization', 'landscape', 'backpropagate', 'encoder', 'eter', 'furthermore', 'repeatedly', 'update', 'convolutional', 'encoder', 'gradient', 'consistently', 'lead', 'early', 'con', 'vergence', 'degenerate', 'feature', 'representation', 'cause', 'critic', 'ﬁt', 'highvariance', 'erroneous', 'target', 'phenomenon', 'name', 'catastrophic', 'selfoverﬁtte', 'way', 'tifye', 'direct', 'implication', 'visual', 'deadly', 'triad', 'gradient', 'signal', 'propose', 'new', 'measure', 'call', 'normalize', 'discontinuity', 'nd', 'score', 'show', 'value', 'precisely', 'correlate', 'agent', 'performance', 'thus', 'explain', 'effectiveness', 'shift', 'augmentation', 'recog', 'nize', 'regularize', 'gradient', 'signal', 'provide', 'implicit', 'spatial', 'smoothing', 'effect', 'base', 'analysis', 'propose', 'adaptive', 'local', 'signal', 'mix', 'alix', 'novel', 'method', 'prevent', 'catastrophic', 'selfoverﬁtte', 'key', 'component', 'new', 'parame', 'terize', 'layer', 'lix', 'explicitly', 'enforce', 'smooth', 'feature', 'map', 'gradient', 'dual', 'objective', 'ensure', 'learn', 'bility', 'adapt', 'lix', 'parameter', 'base', 'estimate', 'nd', 'score', 'show', 'integrate', 'alix', 'exist', 'offpolicy', 'algorithm', 'achieve', 'stateoftheart', 'performance', 'deepmind', 'control', 'atari', 'benchmark', 'require', 'image', 'augmentation', 'auxiliary', 'loss', 'signiﬁcantly', 'heuristic', 'opensource', 'code', 'facilitate', 'reproducibility', 'future', 'extensions1', 'main', 'contribution', 'summarize', 'follow', 'conjecture', 'existence', 'visual', 'deadly', 'triad', 'principal', 'source', 'instability', 'reinforcement', 'learn', 'e', 'pixel', 'observation', 'provide', 'clear', 'empirical', 'evidence', 'validate', 'hypothesis', 'show', 'instability', 'affect', 'cause', 'catastrophic', 'selfoverﬁtte', 'phenomenon', 'severely', 'harm', 'tdlearning', 'result', 'design', 'normalize', 'discontinuity', 'score', 'explicitly', 'figure', 'return', 'agent', 'seed', 'solid', 'line', 'represent', 'median', 'performance', 'fade', 'line', 'represent', 'individual', 'run', 'vertical', 'dash', 'line', 'show', 'augmentation', 'turn', 'anticipate', 'occurrence', 'propose', 'new', 'method', 'adaptively', 'reg', 'ularizes', 'convolutional', 'feature', 'prevent', 'catastrophic', 'selfoverﬁtte', 'achieve', 'stateoftheart', 'result', 'popular', 'pixelbase', 'benchmark', 'background', 'consider', 'problem', 'setting', 'describe', 'process', 'bellman', 'deﬁne', 'tuple', 'p', 'p0', 'r', 'γ', 'comprise', 'state', 'space', 'action', 'space', 'transition', 'dynamic', 'give', 'p', 'ward', 'function', 'r', 'rl', 'objective', 'agent', 'cover', 'optimal', 'policy', 'π∗', 'yield', 'distribution', 'trajec', 'tory', 'pπτ', 'maximize', 'expect', 'sum', 'discount', 'future', 'reward', 't0', 'γtrst', 'offpolicy', 'objective', 'usually', 'approach', 'learn', 'critic', 'function', 'evaluate', 'effectiveness', 'agent', 'behavior', 'common', 'choice', 'critic', 'param', 'eterize', 'policy', 'qfunction', '×', 'r', 'quan', 'agent', 'performance', 'perform', 'particular', 'action', 'qπs', 't0', 'γtrst', 'offpolicy', 'algorithm', 'entail', 'store', 'trajectory', 'buffer', 'learn', 'parameterized', 'qfunction', 'itera', 'tively', 'minimize', 'squared', 'temporal', 'difference', 'loss', '−', 'y2cid3', 'ˆqπ', 'φcid48scid48', 'r', 'tdtarget', 'compute', 'bootstrap', 'operation', 'slowlychange', 'target', 'qfunction', 'ˆqπ', 'φcid48', 'continuous', 'action', 'space', 'also', 'learn', 'separate', 'parame', 'terize', 'policy', 'exploit', 'information', 'critic', 'practically', 'result', 'alternate', 'tdlearne', 'e', 'qfunction', 'expect', 'return', 'prediction', 'follow', 'policy', 'gradient', 'theorem', 'instability', 'tdlearning', 'pixel', 'proprioceptive', 'observation', 'offpolicy', 'rl', 'pixel', 'observation', 'commonly', 'require', 'additional', 'domain', 'cheetah', 'run', 'aug', 'turn', 'r', 'u', 'e', 'r', 'aug', 'frame', 'aug', 'aug', '500k', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'figure', 'evidence', 'overﬁtte', 'augmentation', 'use', 'left', 'shaded', 'line', 'individual', 'estimate', 'solid', 'line', 'represent', 'median', 'qvalue', 'right', 'qvalue', 'pearson', 'correlation', 'target', 'value', 'montecarlo', 'return', 'figure', 'tdloss', 'ofﬂine', 'ﬁxed', 'transition', 'training', 'sepa', 'rate', 'base', 'nonzero', 'reward', 'complementary', 'experiment', 'validate', 'claim', 'speciﬁc', 'practice', 'ensure', 'stability', 'section', 'provide', 'novel', 'analysis', 'phenomenon', 'focus', 'deepmind', 'control', 'benchmark', 'introduction', 'random', 'shift', 'datum', 'augman', 'tation', 'core', 'component', 'recent', 'advance', 'pixelbase', 'offpolicy', 'laskin', 'yarat', 'allow', 'isolate', 'reproduce', 'stable', 'stable', 'training', 'regime', 'analysis', 'suggest', 'existence', 'speciﬁc', 'element', 'cause', 'instability', 'strive', 'explain', 'implication', 'learn', 'dynamic', 'vali', 'date', 'ﬁnding', 'thorough', 'empirical', 'experimentation', 'show', 'numerous', 'result', 'corroborate', 'hypothesis', 'base', 'discovery', 'section', 'provide', 'new', 'interpretation', 'random', 'shift', 'propose', 'new', 'improved', 'method', 'isolate', 'counteract', 'instability', 'augmentation', 'help', 'underlying', 'mechanism', 'effectiveness', 'run', 'dom', 'shift', 'immediately', 'clear', 'augman', 'tation', 'appear', 'assist', 'generalization', 'encode', 'invariance', 'shorten', 'note', 'environment', 'employ', 'camera', 'ﬁxe', 'relative', 'agent', 'position', 'hence', 'robustness', 'shift', 'appear', 'introduce', 'useful', 'inductive', 'bias', 'underlie', 'task', 'moreover', 'prior', 'work', 'successfully', 'learn', 'effective', 'controller', 'augmentation', 'hafner', 'yarat', 'suggest', 'shift', 'eralization', 'primary', 'beneﬁt', 'method', 'analyze', 'effect', 'random', 'shift', 'train', 'drqv2', 'agent', 'yarat', 'run', 'turn', 'augmentation', 'initial', 'timestep', 'learning', 'phase', 'show', 'fig', 'training', 'shift', 'augmentation', 'fail', 'make', 'consistent', 'progress', 'turn', 'augmentation', 'initial', 'learning', 'phase', 'actually', 'ap', 'pear', 'slightly', 'improve', 'performance', 'drqv2', 'result', 'clear', 'indication', 'augmentation', 'need', 'asymptotic', 'performance', 'helpful', 'teract', 'instability', 'present', 'early', 'stage', 'learn', 'focus', 'analyze', 'see', 'identify', 'new', 'deadly', 'triad', 'reduce', 'confound', 'factor', 'disentangle', 'origin', 'instability', 'design', 'ofﬂine', 'rl', 'experiment', 'levine', 'experiment', 'isolate', 'distinct', 'element', 'affect', 'offpolicy', 'exploration', 'policy', 'eval', 'uation', 'policy', 'improvement', 'first', 'gather', 'set', 'transition', 'pixel', 'observation', 'use', 'random', 'policy', 'run', 'allow', 'ground', 'explo', 'ration', 'analyze', 'learn', 'ﬁxed', 'datum', 'resemble', 'early', 'stage', 'online', 'training', 'augmentation', 'appear', 'helpful', 'isolate', 'policy', 'evaluation', 'train', 'critic', 'encoder', 'use', 'rummery', 'convergence', 'ﬁxed', 'datum', 'finally', 'run', 'policy', 'improvement', 'training', 'actor', 'maximize', 'expect', 'discount', 'return', 'predict', 'converge', 'critic', 'see', 'b1', 'detail', 'interestingly', 'ﬁnd', 'turn', 'augmentation', 'exclusively', 'exploration', 'policy', 'improvement', 'apparent', 'effect', 'stability', 'ﬁnal', 'performance', 'hence', 'focus', 'effect', 'augmentation', 'tdlearning', 'analyze', 'apply', 'augmentation', 'policy', 'evaluation', 'table', 'performance', 'training', 'statistic', 'different', 'agent', 'type', 'ofﬂine', 'experiment', 'random', 'transition', 'agent', 'augment', 'nonaugmente', 'proprioceptive', 'frozen', 'random', 'frozen', 'pretraine', 'nonaugmented', 'norm', 'r', 'nonaugmente', 'return', 'final', 'tdloss', 'final', 'policy', 'loss', 'return', '−114', '−095', '−099', '±', '±', '±', '±', '±', '±', 'show', 'table', 'apply', 'augmentation', 'pol', 'evaluation', 'enable', 'learn', 'policy', 'achieve', 'return', 'good', 'trajectory', 'ofﬂine', 'datum', 'achieve', 'contrast', 'augmentation', 'consistently', 'recover', 'return', 'resemble', 'failure', 'observe', 'online', 'experiment', 'left', 'fig', 'show', 'evolution', 'predict', 'qvalue', 'value', 'train', 'aug', 'aug', 'l', 'e', 'u', 'v', 'q', 'corr', 'q', 'qtarget', 'l', 'e', 'r', 'r', 'c', 'n', 'e', 'p', 'qtarget', 'sgd', 'step', 'sgd', 'step', 'reward', 'sample', 'nonzero', 'sample', 'aug', 'aug', 'r', 'r', 'r', 'e', 'sgd', 'step', 'sgd', 'step', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixels', 'agent', 'ﬁxed', 'batch', 'ofﬂine', 'datum', 'particular', 'perform', 'policy', 'evaluation', 'augmentation', 'prediction', 'display', 'extremely', 'high', 'variance', 'different', 'stateaction', 'pair', 'table', 'far', 'show', 'non', 'augmented', 'agent', 'display', 'signiﬁcantly', 'low', 'loss', 'high', 'average', 'qvalue', 'augmented', 'agent', 'schaul', 'argue', 'clear', 'indication', 'occurrence', 'overﬁtte', 'corroborate', 'claim', 'analyze', 'evolution', 'pearson', 'bivariate', 'correlation', 'estimate', 'qvalue', 'target', 'qvalue', 'right', 'fig', 'result', 'show', 'nonaugmented', 'agent', 'display', 'nearperfect', 'correlation', 'target', 'qvalue', 'training', 'indicate', 'immediately', 'learn', 'ﬁt', 'noisy', 'randomlyinitialize', 'prediction', 'also', 'record', 'correlation', 'actual', 'discount', 'montecarlo', 'return', 'represent', 'true', 'target', 'qvalue', 'ideally', 'approximate', 'policy', 'evalu', 'ation', 'result', 'observe', 'relationship', 'apply', 'augmentation', 'record', 'correla', 'tion', 'reverse', 'nonaugmented', 'agent', 'display', 'signiﬁcantly', 'low', 'correlation', 'dichotomy', 'appear', 'indicate', 'ﬁtte', 'noisy', 'target', 'severely', 'affect', 'learn', 'e', 'useful', 'training', 'signal', 'collect', 'transition', 'regard', 'experienced', 'reward', 'conﬁrm', 'split', 'datum', 'nonzero', 'reward', 'transition', 'learning', 'signal', 'propagate', 'tdloss', 'initially', 'random', 'target', 'value', 'fig', 'illustrate', 'nonaugmented', 'agent', 'initially', 'experience', 'much', 'high', 'tderror', 'reward', 'tion', 'conﬁrme', 'focus', 'ﬁtte', 'uninformative', 'component', 'tdobjective', 'table', 'provide', 'result', 'additional', 'experiment', 'indicate', 'tdlearning', 'cause', 'observe', 'instability', 'first', 'conﬁrm', 'ob', 'serve', 'overﬁtting', 'appear', 'exclusive', 'perform', 'endtoend', 'tdlearne', 'convolutional', 'network', 'encoder', 'concretely', 'run', 'ofﬂine', 'exper', 'iment', 'train', 'encoder', 'different', 'setting', 'first', 'consider', 'perform', 'policy', 'evaluation', 'directly', 'nonaugmented', 'proprioceptive', 'observation', 'fullyconnected', 'critic', 'network', 'moreover', 'also', 'consider', 'freeze', 'encoder', 'weight', 'initial', 'random', 'value', 'pretraine', 'value', 'augmented', 'agent', 'experiment', 'case', 'attain', 'largely', 'superior', 'performance', 'almost', 'match', 'augmented', 'agent', 'formance', 'proprioceptive', 'pretraine', 'exper', 'iment', 'addition', 'also', 'ﬁnd', 'observed', 'ﬁtte', 'phenomenon', 'diminish', 'simply', 'increase', 'magnitude', 'reward', 'tdloss', 'test', 'additional', 'experiment', 'consider', 'normalize', 'collect', 'reward', 'policy', 'evaluation', 'incorporate', 'large', 'nstep', 'return', 'report', 'modiﬁcation', 'considerably', 'improve', 'non', 'figure', 'feature', 'map', 'ﬁnal', 'layer', 'augment', 'top', 'nonaugmente', 'bottom', 'agent', 'encoder', 'nonaugmente', 'agent', 'manifest', 'inconsistent', 'highfrequency', 'feature', 'map', 'augment', 'agent', 'performance', 'however', 'note', 'practice', 'introduce', 'unwanted', 'variance', 'optimization', 'fail', 'yield', 'improvement', 'augmentation', 'see', 'take', 'together', 'result', 'appear', 'strongly', 'indicate', 'instability', 'offpolicy', 'pixel', 'observation', 'come', 'key', 'condition', 'refer', 'visual', 'deadly', 'triad', 'exclusive', 'reliance', 'regularize', 'learn', 'expressive', 'convolutional', 'coder', 'iii', 'initial', 'lowmagnitude', 'sparse', 'reward', 'evidence', 'arise', 'consider', 'ubiquity', 'partic', 'ular', 'practice', 'employ', 'pixelbase', 'offpolicy', 'particular', 'summarize', 'table', 'popular', 'prior', 'algorithm', 'feature', 'design', 'choice', 'appear', 'counteract', 'least', 'element', 'triad', 'directly', 'implic', 'itly', 'furthermore', 'show', 'instability', 'result', 'nonaugmented', 'critic', 'focus', 'learn', 'noisy', 'prediction', 'rather', 'actual', 'experienced', 'return', 'observe', 'ultimately', 'lead', 'convergence', 'erroneous', 'highvariance', 'qvalue', 'prediction', 'phenomenon', 'name', 'catastrophic', 'selfoverﬁtte', 'anticipate', 'catastrophic', 'selfoverﬁtte', 'attempt', 'unravel', 'link', 'connect', 'visual', 'deadly', 'triad', 'catastrophic', 'selfoverﬁtting', 'start', 'observe', 'catastrophic', 'selfoverﬁtting', 'come', 'signiﬁcant', 'reduction', 'critic', 'sensitivity', 'change', 'action', 'input', 'imply', 'erroneous', 'highvariance', 'qvalue', 'prediction', 'arise', 'primarily', 'due', 'change', 'observation', 'see', 'app', 'f3', 'actionvalue', 'surface', 'plot', 'hence', 'focus', 'analyze', 'feature', 'representation', 'pixel', 'observation', 'compute', 'convolutional', 'rc×h×w', 'particular', 'wish', 'quantify', 'sensitivity', 'feature', 'representation', 'small', 'perturbation', 'input', 'observation', 'measure', 'evaluate', 'jacobian', 'encoder', 'ﬁxed', 'batch', 'ofﬂine', 'datum', 'augmented', 'nonaugmented', 'agent', 'cal', 'culate', 'frobenius', 'norm', 'agent', 'jacobian', 'give', 'measure', 'quickly', 'encod', 'feature', 'represen', 'augmented', 'final', 'feature', 'map', 'nonaugmente', 'final', 'feature', 'map', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixel', 'overﬁtte', 'quantify', 'level', 'discontinuity', 'feature', 'gradient', 'propose', 'new', 'metric', 'encode', 'aggregated', 'immediate', 'spatial', 'feature', 'location', 'relative', 'feature', 'map', 'particular', 'deﬁne', 'rc×h×w', 'expect', 'square', 'local', 'discontinuity', 'spatial', 'direction', 'cid34cid18', 'practically', 'estimate', 'sample', 'normalize', 'value', 'dz', 'squared', 'input', 'average', 'feature', 'position', 'name', 'metric', 'normalize', 'discontinuity', 'nd', 'score', 'c', '×', 'h', '×', 'intuitively', 'score', 'reﬂect', 'locally', 'discontinuous', 'z', 'expect', 'spatial', 'location', 'fig', 'show', 'n', 'score', '∇z', 'evolve', 'training', 'ofﬂine', 'online', 'setting', 'augmented', 'non', 'augmented', 'agent', 'see', 'augmented', 'agent', 'experi', 'ence', 'considerably', 'less', 'discontinuous', 'gradient', 'feature', 'recording', 'low', 'score', 'also', 'pear', 'highly', 'correlate', 'performance', 'improvement', 'additionally', 'show', 'accumulate', 'score', 'use', 'exponential', 'move', 'average', '∇z', 'spatial', 'position', 'calculate', 'metric', 'interestingly', 'observe', 'n', 'score', 'accumulate', 'gradient', 'almost', 'identical', 'instantaneous', 'score', 'show', 'similar', 'gradient', 'discontinuity', 'propagate', 'persistently', 'training', 'position', 'feature', 'map', 'property', 'conﬁrm', 'discontinuity', 'smooth', 'stochastic', 'sampling', 'different', 'consecutive', 'training', 'batch', 'case', 'expect', 'observe', 'lower', 'accumulate', 'score', 'thus', 'suggest', 'selfoverﬁtte', 'emerge', 'nonaugmented', 'agent', 'due', 'repeat', 'gradient', 'step', 'persistent', 'feature', 'map', 'discontinuity', 'counteract', 'gradient', 'discontinuity', 'gradient', 'smoothing', 'random', 'shift', 'analyze', 'section', 'catastrophic', 'selfoverﬁtte', 'cur', 'gradient', 'convolution', 'layer', 'locally', 'discontinuous', 'result', 'argue', 'efﬁcacy', 'random', 'shift', 'arise', 'downstream', 'effect', 'feature', 'gradient', 'computation', 'counteract', 'discontinu', 'itie', 'backpropagation', 'particular', 'random', 'shift', 'act', 'directly', 'latent', 'representation', 'loss', 'surface', 'respect', 'fullyconnected', 'weight', 'smooth', 'figure', 'critic', 'loss', 'surface', 'plot', 'augmented', 'leave', 'non', 'augmented', 'right', 'agent', 'step', 'ofﬂine', 'training', 'tation', 'change', 'locally', 'input', 'see', 'app', 'detail', 'result', 'show', 'stark', 'difference', 'feature', 'representation', 'nonaugmented', 'agent', 'average', 'time', 'sensitive', 'suggest', 'overﬁtting', 'drive', 'encoder', 'representation', 'learn', 'highfrequency', 'information', 'input', 'obser', 'vation', 'thus', 'break', 'useful', 'inductive', 'bias', 'class', 'model', 'rahaman', 'demonstrate', 'low', 'sensitivity', 'run', 'dom', 'noise', 'desirable', 'optimization', 'actually', 'byproduct', 'stable', 'feature', 'represen', 'tation', 'deﬁne', 'factor', 'furthermore', 'observe', 'actual', 'feature', 'map', 'different', 'observation', 'fig', 'see', 'augmentation', 'make', 'encoder', 'produce', 'fea', 'ture', 'spatially', 'consistent', 'align', 'common', 'understanding', 'natural', 'representation', 'pear', 'contrast', 'nonaugmented', 'agent', 'display', 'highfrequency', 'discontinuous', 'feature', 'map', 'reﬂect', 'spa', 'tial', 'property', 'input', 'hence', 'evidence', 'suggest', 'catastrophic', 'selfoverﬁtting', 'speciﬁcally', 'follow', 'learning', 'process', 'produce', 'highlysensitive', 'discontinuous', 'encod', 'feature', 'map', 'therefore', 'turn', 'focus', 'analyze', 'gradient', 'backpropagate', 'encoder', 'feature', 'map', 'observe', 'key', 'prop', 'erty', 'gradient', 'output', 'feature', 'map', 'consistently', 'reﬂect', 'spatial', 'property', 'result', 'feature', 'particular', 'gradient', 'feature', 'map', 'appear', 'spa', 'tially', 'consistent', 'augmented', 'agent', 'discontinuous', 'nonaugmented', 'agent', 'optimization', 'property', 'reﬂect', 'intuitive', 'understanding', 'backpropagation', 'discontinuous', 'gradient', 'push', 'encoder', 'weight', 'encode', 'discontinuous', 'representation', 'provide', 'complementary', 'evidence', 'discontinuous', 'gradient', 'direct', 'cause', 'catastrophic', 'selfoverﬁtting', 'analyze', 'normalize', 'loss', 'surface', 'backpropagate', 'discontinuous', 'gradient', 'encoder', 'parameter', 'fig', 'see', 'gradient', 'discontinuity', 'nonaugmented', 'agent', 'yield', 'extreme', 'peak', 'encoder', 'loss', 'surface', 'clearly', 'suggestive', 'critic', 'augmentation', 'critic', 'augmentation', 'l', 'td', 'loss', 'weight', 'subspace', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixel', 'persistent', 'discontinuity', 'accumulate', 'hence', 'run', 'dom', 'shift', 'break', 'second', 'condition', 'visual', 'deadly', 'triad', 'provide', 'effective', 'implicit', 'regularization', 'convolutional', 'encoder', 'learning', 'process', 'time', 'minimally', 'disrupt', 'information', 'content', 'sultant', 'feature', 'discard', 'observation', 'border', 'almost', 'exclusively', 'comprise', 'background', 'texture', 'vant', 'perform', 'task', 'interpretation', 'random', 'shift', 'align', 'analysis', 'section', 'show', 'plicitly', 'smooth', 'backpropagate', 'gradient', 'map', 'consistently', 'prevent', 'catastrophic', 'selfoverﬁtte', 'local', 'signal', 'mix', 'extrapolate', 'hypothesis', 'catastrophic', 'self', 'overﬁtte', 'random', 'shift', 'propose', 'technique', 'aim', 'enforce', 'gradient', 'smoothing', 'regularization', 'explic', 'itly', 'propose', 'local', 'signal', 'mixing', 'lix', 'new', 'layer', 'speciﬁcally', 'design', 'prevent', 'catastrophic', 'selfoverﬁtte', 'convolutional', 'reinforcement', 'learning', 'architecture', 'lix', 'act', 'feature', 'produce', 'convolutional', 'encoder', 'rc×h×w', 'randomly', 'mix', 'component', 'neighbor', 'belong', 'feature', 'map', 'hence', 'lix', 'output', 'new', 'latent', 'representation', 'di', 'mensionality', 'computation', 'graph', 'minimally', 'disrupt', 'information', 'content', 'feature', 'zcij', 'smooth', 'discontinuous', 'component', 'dient', 'signal', 'backpropagation', 'regularization', 'layer', 'act', 'simple', 'random', 'smoothing', 'operation', 'reduce', 'expect', 'magnitude', 'gradient', 'discontinuity', 'prevent', 'high', 'frequency', 'sig', 'nal', 'persist', 'forward', 'lix', 'produce', 'new', 'latent', 'representation', 'c', 'feature', 'map', 'ˆzcij', 'compute', 'randomly', 'weight', 'average', 'spatial', 'neighbor', 'coordinate', 'param', 'eterize', 'stochastic', 'operation', 'use', 'maximum', 'range', 'consequently', 'sample', 'uniform', 'continuous', 'random', 'variable', 'δx', 'δy', '∼', 'represent', 'shift', 'coordinate', 'respectively', 'correspondingly', 'deﬁne', 'δy', 'perform', 'weighted', 'averaging', 'bilinear', 'interpolation', 'weight', 'determine', 'random', 'shift', '−', '−', '˜i˜j', '−', 'cid98˜jcid99', '−', '−', 'cid98˜icid99˜j', '−', 'cid98˜jcid99', 'nearby', 'feature', 'convolutional', 'feature', 'map', 'compute', 'similar', 'receptive', 'ﬁeld', 'mix', 'effect', 'lix', 'trivial', 'effect', 'tion', 'encoder', 'convey', 'latent', 'representation', 'addition', 'lix', 'direct', 'regularization', 'fect', 'gradient', 'act', 'feature', 'map', 'selve', 'particular', 'compute', 'output', 'feature', 'weighted', 'average', 'neighbor', 'back', 'figure', 'instantaneous', 'red', 'blue', 'accumulate', 'orange', 'purple', 'score', 'feature', 'gradient', 'ofﬂine', 'leave', 'online', 'right', 'training', 'run', 'respective', 'gradient', 'affect', 'latent', 'represen', 'tation', 'compute', 'impact', 'persistent', 'discontinuous', 'component', 'gradient', 'backpropa', 'gate', 'encoder', 'parameter', 'learn', 'approximate', 'shift', 'invariance', 'convolutional', 'layer', 'view', 'convolutional', 'encoder', 'compute', 'feature', 'vector', 'zcijt', 'param', 'eterize', 'function', 'vφ', 'take', 'input', 'subset', 'observation', '∈', 'rccid48×h', 'cid48×w', 'subset', 'correspond', 'local', 'neighborhood', 'reference', 'input', 'coordinate', 'icid48', 'jcid48', 'thus', 'factor', 'differentiate', 'feature', 'feature', 'map', 'zckl', 'implicit', 'func', 'jcid48', 'translate', 'output', 'feature', 'coordinate', 'relative', 'reference', 'input', 'coordinate', 'vφo', 'icid48', 'jcid48c', 'determine', 'kernel', 'size', 'stride', 'therefore', 'random', 'shift', 'approximately', 'equivalent', 'far', 'translate', 'reference', 'coordinate', 'add', 'δcid48', 'uniform', 'random', 'variable', 'δcid48', 'vφo', 'δcid48', 'scid48', 'δcid48', 'δcid48', 'jcid48', 'employed', 'stride', 'convolutional', 'archi', 'tecture', 'use', 'drqv2', 'yarat', 'difference', 'reference', 'coordinate', 'adjacent', 'feature', 'feature', 'map', 'less', 'maximum', 'allowable', 'shift', 'employ', 'augmentation', '−', 'icid48', '−', 'jcid48', 'scid48', 'scid48', 'maximum', 'allowable', 'shift', 'consequently', 'shift', 'augmentation', 'effectively', 'turn', 'deterministic', 'com', 'putation', 'graph', 'feature', 'zcij', 'random', 'variable', 'sample', 'space', 'comprise', 'computation', 'graphs', 'nearby', 'feature', 'feature', 'map', 'hence', 'apply', 'different', 'random', 'shift', 'sample', 'minibatch', 'make', 'gradient', 'feature', 'backpropagate', 'random', 'computation', 'graph', 'sample', 'set', 'extend', 'set', 'nonaugmented', 'computation', 'graphs', 'feature', 'local', 'neighborhood', 'coordinate', 'therefore', 'gregate', 'parameter', 'gradient', 'produce', 'different', 'δcid48', 'δcid48', 'provide', 'smooth', 'effect', 'discon', 'tinuous', 'component', '∇z', 'affect', 'learn', 'prevent', 'offline', 'online', 'e', 'r', 'sgd', 'step', 'aug', 'aug', 'accumulate', 'frame', 'aug', 'aug', 'accumulate', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'propagation', 'split', 'gradient', '∇ˆzcij', 'random', 'local', 'combination', 'feature', 'feature', 'map', '∇zccid98˜icid99cid98˜jcid99', 'thus', 'lix', 'mostly', 'preserve', 'consistent', 'component', '∇z', 'randomly', 'smooth', 'discontinuous', 'component', 'multiple', 'key', 'difference', 'regulariza', 'tion', 'lix', 'random', 'shift', 'provide', 'local', 'smoothing', 'effect', 'gradient', 'explicitly', 'exactly', 'deal', 'implication', 'padding', 'strided', 'convolution', 'break', 'shiftinvariance', 'assump', 'tion', 'moreover', 'lix', 'smooth', 'gradient', 'signal', 'different', 'input', 'also', 'feature', 'map', 'addition', 'apply', 'operation', 'solely', 'feature', 'level', 'encoder', 'still', 'learn', 'entirely', 'circumvent', 'smooth', 'effect', 'information', 'encode', 'latent', 'representation', 'give', 'enough', 'capacity', 'mean', 'lix', 'forcibly', 'preclude', 'input', 'information', 'affect', 'computation', 'consequently', 'lix', 'also', 'enforce', 'learn', 'invariance', 'nece', 'sarily', 'reﬂect', 'useful', 'inductive', 'bias', 'distribution', 'observation', 'contrast', 'random', 'shift', 'need', 'exploit', 'particular', 'uninformativeness', 'observation', 'border', 'avoid', 'disrupt', 'feature', 'information', 'content', 'alix', 'lix', 'introduce', 'single', 'key', 'parameter', 'use', 'sample', 'δy', 'intuitively', 'value', 'reﬂect', 'much', 'expect', 'gradient', 'locally', 'consis', 'tent', 'give', 'architecture', 'task', 'therefore', 'argue', 'value', 'ideally', 'decrease', 'train', 'ing', 'useful', 'learning', 'signal', 'tdloss', 'become', 'strong', 'consistent', 'result', 'illustrate', 'figure', 'show', 'turn', 'random', 'shift', 'augmenta', 'tion', 'tdtarget', 'become', 'informative', 'improve', 'learn', 'hence', 'propose', 'adaptive', 'strategy', 'learn', 'training', 'utilize', 'normalize', 'discontinuity', 'score', 'section', 'set', 'dual', 'optimization', 'objective', 'ensure', 'minimum', 'value', 'local', 'smoothness', 'representation', 'gradient', 'however', 'compute', 'score', 'gradient', 'signal', 'involve', 'ratio', 'tentially', 'small', 'value', 'result', 'estimation', 'value', 'batch', 'gradient', 'sample', 'lead', 'outlier', 'extreme', 'impact', 'average', 'measure', 'tran', 'late', 'large', 'erroneous', 'update', 'overcome', 'propose', 'use', 'slightly', 'modiﬁe', 'version', 'score', 'increase', 'robustness', 'outlier', 'see', 'c1', 'detail', 'log', 'i1', 'd∇ˆzcij', 'practice', 'set', 'dual', 'optimization', 'objective', 'similar', 'automatic', 'temperature', 'adjustment', 'figure', '’s', 'parameter', 'evolution', 'training', 'chee', 'run', 'leave', 'run', 'right', 'critic', 'target', 'become', 'informative', 'fall', 'improve', 'datum', 'efﬁciency', 'asymptotic', 'performance', '2018b', 'entail', 'alternate', 'optimization', 'learn', 'objective', 'describe', 'section', 'minimize', 'dual', 'objective', 'loss', 'cid104', '−s', '×', 'min', 'approximate', 'dual', 'gradient', 'descent', 'boyd', 'hence', 'call', 'new', 'layer', 'adaptive', 'alix', 'fig', 'show', 'alix', 'effectively', 'anneal', 'agent', 'escape', 'unstable', 'regime', 'line', 'intuition', 'performance', 'evaluation', 'evaluate', 'effectiveness', 'alix', 'pixelbase', 'inforcement', 'learning', 'task', 'popular', 'distinct', 'main', 'feature', 'diverse', 'set', 'continuous', 'discrete', 'control', 'problem', 'integrate', 'alix', 'exist', 'popu', 'lar', 'algorithm', 'compare', 'current', 'stateoftheart', 'modelfree', 'baseline', 'provide', 'detail', 'integration', 'full', 'hyperparameter', 'app', 'also', 'extend', 'section', 'provide', 'granular', 'evaluation', 'metric', 'app', 'furthermore', 'provide', 'ablation', 'study', 'analyze', 'different', 'component', 'alix', 'e', 'deepmind', 'control', 'evaluation', 'ﬁrst', 'evaluate', 'effectiveness', 'alix', 'pixelbase', 'continuous', 'control', 'task', 'deepmind', 'control', 'concretely', 'integrate', 'alix', 'training', 'procedure', 'network', 'architecture', 'drqv2', 'yarat', 'use', 'image', 'augmentation', 'show', 'generality', 'method', 'modify', 'environmentspeciﬁc', 'hyperparameter', 'drqv2', 'simply', 'add', 'alix', 'layer', 'encod', 'nonlinearity', 'simplicity', 'optimize', 'shared', 'alix', 'layer', 'dual', 'objective', 'eq', 'hence', 'introduce', 'single', 'additional', 'parameter', 'negligible', 'computational', 'overhead', 'compare', 'alix', 'drqv2', 'represent', 'current', 'stateoftheart', 'benchmark', 'also', 'compare', 'baseline', 'original', 'drq', 'kostrikov', 'forego', 'step', 'return', 'include', 'entropy', 'bonus', 'curl', 'laskin', 'include', 'auxiliary', 'contrastive', 'r', 'u', 'e', 'r', 'run', 'quadrupe', 'run', 'l', 'e', 'u', 'v', 'frame', '×106', 'agent', 'return', 'frame', 'alix', 'parameter', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'table', 'result', 'summary', 'benchmark', 'report', 'performance', 'alix', 'seed', 'metric', 'simple', 'der', 'otrainbow', 'curl', 'drq', 'spr', 'alix', 'norm', 'mean', 'norm', 'super', 'average', 'rank', 'figure', 'average', 'performance', 'seed', 'dmc', 'medium', 'left', 'hard', 'task', 'right', 'shaded', 'region', 'represent', '±1', 'extension', 'sac', 'encoder', 'yarat', 'last', 'base', 'line', 'performant', 'prior', 'dmc', 'benchmark', 'consider', 'task', 'high', 'action', 'repeat', 'describe', 'hafner', 'instead', 'evaluate', 'challenging', 'medium', 'hard', 'benchmark', 'yarat', 'comprise', 'task', 'low', 'action', 'repeat', 'result', 'summarize', 'result', 'figure', 'show', 'mean', 'performance', 'curve', 'medium', 'hard', 'bench', 'mark', 'task', 'provide', 'detail', 'full', 'list', 'result', 'environment', 'overall', 'lix', 'surpass', 'prior', 'method', 'clear', 'margin', 'term', 'efﬁciency', 'ﬁnal', 'performanc', 'particularly', 'notable', 'complex', 'hard', 'task', 'highlight', 'prior', 'work', 'drqv2', 'appear', 'yield', 'inconsistent', 'result', 'hard', 'exploration', 'task', 'sparse', 'reward', 'likely', 'indicate', 'gradient', 'regularization', 'induce', 'random', 'shift', 'describe', 'section', 'unable', 'consistently', 'prevent', 'catastrophic', 'selfoverﬁtting', 'scenario', 'initial', 'learning', 'signal', 'tdlearning', 'particularly', 'low', 'finally', 'drq', 'curl', 'sac', 'fail', 'make', 'consistent', 'meaningful', 'progress', 'hard', 'benchmark', 'performance', 'gap', 'corroborate', 'third', 'component', 'visual', 'deadly', 'triad', 'show', 'low', 'magnitude', 'reward', 'hard', 'exploration', 'low', 'actionrepeat', 'far', 'destabilize', 'tdlearne', 'base', 'algorithm', 'explain', 'gain', 'see', 'drqv2', 'incorporate', 'nstep', 'return', 'believe', 'result', 'phasize', 'challenge', 'overcome', 'visual', 'deadly', 'triad', 'continuous', 'control', 'problem', 'particular', 'effective', 'ness', 'alix', 'counteract', 'direct', 'implication', 'atari', 'evaluation', 'perform', 'second', 'set', 'experiment', 'entirely', 'dif', 'ferent', 'set', 'discrete', 'control', 'make', 'use', 'popular', 'atari', 'learn', 'environment', 'ale', 'bellemare', 'consider', 'evaluation', 'benchmark', 'kaiser', 'particular', 'benchmark', 'comprise', 'eval', 'uating', 'performance', 'task', 'hour', 'playtime', 'interaction', 'step', 'follow', 'evaluation', 'protocol', 'machado', 'integrate', 'alix', 'dataefﬁcient', 'simple', 'extension', 'rainbow', 'improve', 'dataefﬁciency', 'like', 'note', 'integration', 'key', 'difference', 'der', 'design', 'high', 'light', 'generality', 'method', 'tackle', 'visual', 'deadly', 'triad', 'particular', 'reduce', 'nstep', 'return', 'maintain', 'encoder', 'architecture', 'drqv2', 'speak', 'latter', 'point', 'mean', 'require', 'highly', 'regularize', 'encoder', 'large', 'convolutional', 'ﬁlter', 'stride', 'use', 'ubiquitously', 'policy', 'learning', 'atari', 'environment', 'instead', 'stabilize', 'learn', 'simply', 'apply', 'alix', 'layer', 'ﬁnal', 'encoder', 'nonlinearity', 'compare', 'algorithm', 'alix', 'employ', 'dataaugmentation', 'data', 'efﬁcient', 'overtraine', 'simulate', 'policy', 'learn', 'sim', 'kaiser', 'modelbase', 'moreover', 'also', 'compare', 'additional', 'stateoftheart', 'offpolicy', 'baseline', 'make', 'use', 'data', 'augmentation', 'aforementioned', 'curl', 'drq', 'selfpredictive', 'representation', 'spr', 'schwarzer', 'current', 'stateoftheart', 'learn', 'base', 'benchmark', 'spr', 'combine', 'data', 'augmentation', 'numerous', 'additional', 'algorithmic', 'design', 'choice', 'auxiliary', 'selfsupervise', 'loss', 'learn', 'latent', 'dynamic', 'model', 'result', 'summarize', 'result', 'table', 'show', 'mean', 'median', 'humannormalize', 'score', 'together', 'number', 'environment', 'ei', 'ther', 'achieve', 'stateoftheart', 'superhuman', 'performance', 'include', 'full', 'perenvironment', 'result', 'a2', 'remarkably', 'alix', 'obtain', 'substantially', 'high', 'human', 'normalize', 'mean', 'performance', 'consider', 'algorithm', 'record', 'normalize', 'median', 'formance', 'slightly', 'inferior', 'spr', 'argue', 'difference', 'particularly', 'signiﬁcant', 'metric', 'pend', 'performance', 'obtain', 'environment', 'moreover', 'alix', 'achieve', 'superhuman', 'performance', 'game', 'spr', 'stateoftheart', 'performance', 'game', 'considerably', 'algorithm', 'result', 'corroborate', 'tune', 'architecture', 'datum', 'mentation', 'auxiliary', 'loss', 'use', 'ale', 'mostly', 'serve', 'purpose', 'counteract', 'direct', 'implication', 'visual', 'deadly', 'triad', 'show', 'alix', 'enable', 'learn', 'medium', 'task', 'dmc', 'hard', 'task', 'r', 'u', 'e', 'r', 'frame', 'frame', 'alix', 'drqv2', 'curl', 'drq', 'sac', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixel', 'deepmind', 'control', 'medium', 'hard', 'task', 'figure', 'probability', 'improvement', 'performance', 'proﬁle', 'obtain', 'recorded', 'result', 'leave', 'right', 'alix', 'display', 'statistically', 'signiﬁcantly', 'improvement', 'stochastically', 'dominate', 'prior', 'algorithm', 'powerful', 'model', 'rely', 'design', 'choice', 'statistical', 'signiﬁcance', 'validate', 'signiﬁcance', 'improvement', 'sta', 'tistically', 'analyze', 'result', 'use', 'rliable', 'tool', 'practice', 'agarwal', 'summarize', 'key', 'ﬁnding', 'fig', 'show', 'probability', 'improvement', 'alix', 'prior', 'method', 'compute', 'mannwhitney', 'whitney', 'relative', 'normalize', 'performance', 'proﬁle', 'dolan', 'mor´e', 'range', 'correspond', 'boot', 'strap', 'interval', 'efron', 'atari', 'benchmark', 'ﬁnd', 'improvement', 'tistically', 'signiﬁcant', 'low', 'conﬁdence', 'interval', 'observe', 'stochastic', 'dominance', 'almost', 'consider', 'baseline', 'dror', 'pro', 'vide', 'result', 'detail', 'employ', 'statistical', 'analysis', 'a3', 'respectively', 'relate', 'work', 'previous', 'work', 'characterize', 'several', 'optimization', 'sue', 'relate', 'perform', 'rl', 'tdlearne', 'moore', 'baird', 'work', 'instead', 'empirical', 'analysis', 'modern', 'tdlearning', 'gorithm', 'speciﬁc', 'pixelbased', 'set', 'also', 'observe', 'link', 'recent', 'work', 'study', 'observational', 'ﬁtte', 'song', 'work', 'differ', 'focus', 'memorization', 'effect', 'particular', 'combination', 'cnn', 'tdlearne', 'also', 'connection', 'exist', 'featurelevel', 'augmentation', 'work', 'dropout', 'srivastava', 'dropblock', 'ghiasi', 'particular', 'latter', 'also', 'apply', 'structure', 'tion', 'directly', 'feature', 'map', 'introduce', 'heuristic', 'adjust', 'transformation', 'training', 'validate', 'ﬁnding', 'utility', 'adaptivity', 'rich', 'body', 'work', 'implicit', 'regularization', 'memoriza', 'tion', 'arpit', 'maennel', 'rahaman', 'show', 'high', 'frequency', 'datum', 'man', 'ifold', 'cause', 'cnn', 'learn', 'high', 'spectral', 'frequency', 'term', 'align', 'analysis', 'high', 'frequency', 'tion', 'chatterjee', 'show', 'generalization', 'arise', 'similar', 'example', 'induce', 'similar', 'gradient', 'learn', 'coherence', 'work', 'support', 'ﬁnding', 'inconsistent', 'feature', 'gradient', 'manifestation', 'non', 'coherence', 'explain', 'poor', 'generalization', 'finally', 'dual', 'objective', 'fall', 'automatic', 'tuning', 'method', 'proache', 'apply', 'successfully', 'manage', 'nonstationary', 'tradeoff', 'exploration', 'exploita', 'tion', 'ball', 'optimism', 'moskovitz', 'finally', 'note', 'link', 'cent', 'work', 'concern', 'implicit', 'regularization', 'tdlearne', 'however', 'observe', 'implicit', 'underﬁtting', 'phenomenon', 'later', 'train', 'e', 'stage', 'analyze', 'opposed', 'overﬁtting', 'phenomenon', 'occur', 'ﬁrst', 'training', 'step', 'ﬁnd', 'speciﬁc', 'learn', 'visual', 'input', 'conclusion', 'work', 'provide', 'novel', 'analysis', 'demonstrate', 'instability', 'pixelbase', 'offpolicy', 'rl', 'come', 'speciﬁcally', 'perform', 'tdlearning', 'convolutional', 'encoder', 'presence', 'sparse', 'reward', 'signal', 'show', 'visual', 'deadly', 'triad', 'affect', 'encoder', 'gradient', 'cause', 'critic', 'catastrophically', 'selfoverﬁt', 'noisy', 'prediction', 'therefore', 'propose', 'adaptive', 'local', 'signal', 'mix', 'alix', 'powerful', 'regularization', 'layer', 'explic', 'itly', 'counteract', 'phenomenon', 'apply', 'alix', 'enable', 'outperform', 'prior', 'stateoftheart', 'algorithm', 'pop', 'ular', 'benchmark', 'rely', 'image', 'augmentation', 'auxiliary', 'loss', 'notable', 'design', 'choice', 'acknowledgment', 'like', 'acknowl', 'edge', 'support', 'engineering', 'physical', 'research', 'ball', 'like', 'thank', 'wil', 'lowgrove', 'foundation', 'support', 'funding', 'furthermore', 'support', 'corporation', 'contribute', 'fund', 'utilize', 'computational', 'resource', 'fraction', 'run', 'score', 'τ', 'sac', 'drq', 'drqv2', 'alix', 'drqv2', 'curl', 'sac', 'palix', 'fraction', 'run', 'score', 'spr', 'drq', 'curl', 'otr', 'der', 'simple', 'alix', 'spr', 'drq', 'curl', 'otr', 'der', 'simple', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'reference', 'agarwal', 'r', 'schwarzer', 'bellemare', 'g', 'deep', 'reinforcement', 'learn', 'edge', 'statistical', 'precipice', 'allenzhu', 'feature', 'puriﬁcation', 'adver', 'sarial', 'training', 'perform', 'robust', 'deep', 'learning', 'n', 'miglani', 'mind', 'pad', 'cnn', 'international', 'conference', 'develop', 'blind', 'spot', 'learn', 'representation', 'arpit', 'ballas', 'krueger', 'e', 'fischer', 'courville', 'bengio', 'close', 'look', 'memorization', 'deep', 'network', 'teh', 'proceeding', '34th', 'international', 'con', 'ference', 'machine', 'learning', 'volume', 'proceeding', 'machine', 'learning', 'research', 'pmlr', 'url', 'baird', 'l', 'reinforcement', 'learn', 'gradient', 'descent', 'technical', 'report', 'depart', 'ment', 'computer', 'science', 'baird', 'l', 'moore', 'gradient', 'descent', 'general', 'inforcement', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'ball', 'p', 'parkerholder', 'choromanski', 'robert', 'ready', 'policy', 'world', 'building', 'active', 'learning', 'proceeding', '37th', 'inter', 'national', 'conference', 'machine', 'learning', 'icml', 'bellemare', 'naddaf', 'bowl', 'arcade', 'learn', 'environment', 'evaluation', 'plat', 'form', 'general', 'agent', 'journal', 'artiﬁcial', 'intelligence', 'research', '47253–279', 'bellman', 'r', 'markovian', 'decision', 'process', 'issn', 'berner', 'c', 'brockman', 'dennison', 'farhi', 'fischer', 'hashme', 'large', 'scale', 'deep', 'reinforcement', 'learn', 'arxiv', 'preprint', 'university', 'press', 'brandfonbrener', 'ranganath', 'r', 'bruna', 'offpolicy', 'evaluation', 'beygelzimer', 'advance', 'neural', 'information', 'processing', 'system', 'bruin', 'palunko', 'reinforcement', 'learn', 'control', 'performance', 'ity', 'deep', 'approximator', 'annual', 'review', 'control', 'cetin', 'e', 'learn', 'pessimism', 'robust', 'efﬁcient', 'offpolicy', 'reinforcement', 'learn', 'preprint', 'chatterjee', 'coherent', 'gradient', 'approach', 'stand', 'generalization', 'gradient', 'descentbase', 'mization', 'arxiv', 'preprint', 'schulman', 'phasic', 'policy', 'gradient', 'international', 'conference', 'machine', 'learning', 'pmlr', 'dolan', 'e', 'benchmarke', 'optimization', 'software', 'performance', 'proﬁle', 'mathematical', 'pro', 'gramme', 'dror', 'r', 'shlomov', 'reichart', 'r', 'deep', 'dominance', 'properly', 'compare', 'deep', 'neural', 'model', 'pro', 'ceeding', '57th', 'annual', 'meeting', 'association', 'computational', 'linguistic', 'duan', 'schulman', 'abbeel', 'p', 'benchmarke', 'deep', 'reinforcement', 'learn', 'continuous', 'control', 'international', 'conference', 'machine', 'learning', 'pmlr', 'hester', 'chal', 'arxiv', 'lenge', 'realworld', 'reinforcement', 'learning', 'preprint', 'dwibedi', 'sermanet', 'p', 'learn', 'actionable', 'representation', 'visual', 'observa', 'tion', 'ieeersj', 'international', 'conference', 'intelligent', 'robot', 'system', 'iro', 'ieee', 'efron', 'b', 'bootstrap', 'method', 'look', 'jackknife', 'breakthrough', 'statistic', 'springer', 'abbeel', 'p', 'learn', 'visual', 'feature', 'space', 'robotic', 'nipulation', 'deep', 'spatial', 'autoencoder', 'preprint', 'nachum', 'tucker', 'dataset', 'deep', 'datadriven', 'reinforcement', 'learn', 'fujimoto', 'address', 'func', 'tion', 'approximation', 'error', 'actorcritic', 'method', 'icml', 'url', 'mlrpressv80fujimoto18ahtml', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'q', 'dropblock', 'regular', 'ization', 'method', 'convolutional', 'network', 'grauman', 'n', 'garnett', 'r', 'ed', 'advance', 'neural', 'information', 'processing', 'system', 'volume', 'curran', 'pdf', 'berariu', 'clopath', 'c', 'bu', 'soniu', 'l', 'pascanu', 'r', 'spectral', 'normalisation', 'deep', 'reinforcement', 'learn', 'optimisation', 'ed', 'pro', 'spective', 'ceeding', '38th', 'international', 'conference', 'volume', 'proceeding', 'machine', 'learn', 'research', 'pmlr', 'abbeel', 'p', 'soft', 'actor', 'critic', 'offpolicy', 'maximum', 'deep', 'reinforcement', 'learn', 'stochastic', 'actor', 'krause', 'ed', 'proceeding', '35th', 'international', 'confer', 'ence', 'machine', 'learning', 'volume', 'proceeding', 'machine', 'learn', 'research', 'pmlr', '2018a', 'url', 'haarnoja', 'hartikainen', 'abbeel', 'p', 'soft', 'actorcritic', 'algorithm', 'application', 'preprint', 'hafner', 'fischer', 'villegas', 'davidson', 'learn', 'latent', 'dynamic', 'plan', 'pixel', 'international', 'conference', 'machine', 'learning', 'pmlr', 'hafner', 'dream', 'control', 'learn', 'behavior', 'latent', 'imagination', 'international', 'conference', 'learn', 'representation', 'r', 'understand', 'multistep', 'deep', 'reinforcement', 'learn', 'systematic', 'study', 'dqn', 'target', 'hessel', 'schaul', 'silver', 'rainbow', 'combine', 'improvement', 'deep', 'inforcement', 'learning', 'conference', 'artiﬁcial', 'intelligence', 'kaiser', 'l', 'milo', 'b', 'camp', 'bell', 'r', 'czechowski', 'koza', 'mohiuddin', 'r', 'tucker', 'h', 'model', 'base', 'reinforce', 'ment', 'learn', 'atari', 'international', 'conference', 'learn', 'representation', 'irpan', 'pastor', 'p', 'holly', 'vanhoucke', 'scalable', 'deep', 'reinforcement', 'learn', 'visionbase', 'robotic', 'manipulation', 'preprint', 'kearn', 'p', 'biasvariance', 'error', 'bound', 'temporal', 'difference', 'update', 'proceeding', 'thirteenth', 'annual', 'conference', 'computational', 'learn', 'ing', 'theory', 'colt', 'nocedal', 'smelyanskiy', 'p', 'p', 'largebatch', 'training', 'deep', 'learn', 'e', 'generalization', 'gap', 'sharp', 'minima', '5th', 'inter', 'national', 'conference', 'learn', 'representation', 'iclr', 'conference', 'track', 'proceeding', 'openreviewnet', 'kielak', 'recent', 'advancement', 'modelbased', 'deep', 'reinforcement', 'learning', 'really', 'improve', 'data', 'efﬁciency', 'kingma', 'p', 'method', 'stochastic', 'optimization', 'arxiv', 'preprint', 'yarat', 'fergus', 'r', 'image', 'augmentation', 'need', 'regularize', 'deep', 'reinforcement', 'learn', 'pixel', 'international', 'conference', 'learn', 'representation', 'agarwal', 'plicit', 'underparameterization', 'inhibit', 'dataefﬁcient', 'deep', 'international', 'conference', 'reinforcement', 'learn', 'learn', 'representation', 'stooke', 'l', 'abbeel', 'srinivas', 'reinforcement', 'learme', 'augment', 'advance', 'neural', 'information', 'processing', 'datum', 'system', '2020a', 'laskin', 'abbeel', 'p', 'curl', 'contrastive', 'unsupervised', 'representation', 'reinforcement', 'learning', 'proceeding', '37th', 'international', 'conference', 'machine', 'learning', '2020b', 'nagabandi', 'abbeel', 'p', 'actorcritic', 'deep', 'reinforcement', 'learn', 'latent', 'variable', 'model', 'preprint', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'tucker', 'ofﬂine', 'rein', 'forcement', 'learn', 'tutorial', 'review', 'perspective', 'open', 'problem', 'g', 'studer', 'visualize', 'loss', 'landscape', 'neural', 'net', 'neural', 'information', 'processing', 'system', 'lillicrap', 'heess', 'erez', 'tassa', 'wierstra', 'continuous', 'control', 'deep', 'reinforcement', 'learn', 'preprint', 'bad', 'global', 'minima', 'exist', 'sgd', 'reach', 'advance', 'neural', 'information', 'processing', 'system', 'machado', 'bellemare', 'g', 'talvitie', 'e', 'veness', 'hausknecht', 'bowling', 'revisit', 'arcade', 'learn', 'environment', 'evaluation', 'protocol', 'open', 'problem', 'general', 'agent', 'journal', 'artiﬁcial', 'intelligence', 'research', 'maennel', 'h', 'alabdulmohsin', 'tolstikhin', 'baldock', 'r', 'bousquet', 'keyser', 'neural', 'network', 'learn', 'train', 'random', 'label', 'r', 'ed', 'advance', 'neural', 'information', 'processing', 'system', 'volume', 'pdf', 'mann', 'h', 'b', 'whitney', 'r', 'test', 'random', 'variable', 'stochastically', 'large', 'annal', 'mathematical', 'statistic', 'tral', 'normalization', 'generative', 'adversarial', 'network', 'international', 'conference', 'learn', 'representation', 'grave', 'antonoglou', 'wierstra', 'riedmiller', 'play', 'atari', 'deep', 'reinforcement', 'learn', 'arxiv', 'preprint', 'moskovitz', 'parkerholder', 'arbel', 'tactical', 'optimism', 'pessimism', 'deep', 'reinforcement', 'learning', 'beygelzimer', 'advance', 'neural', 'information', 'processing', 'system', 'mcallester', 'explore', 'generalization', 'deep', 'learning', 'proceed', 'ing', '31st', 'international', 'conference', 'neural', 'formation', 'processing', 'system', 'nips’17', 'red', 'hook', 'parkerholder', 'r', 'song', 'miao', 'nguyen', 'r', 'faust', 'hutter', 'lindauer', 'automate', 'rein', 'forcement', 'learn', 'survey', 'open', 'problem', 'baratin', 'arpit', 'bengio', 'spec', 'tral', 'bias', 'neural', 'network', 'international', 'conference', 'machine', 'learning', 'pmlr', 'case', 'new', 'neural', 'network', 'smoothness', 'constraint', 'believe', '’', 'well', 'neurip', 'workshop', 'url', 'rummery', 'online', 'qlearne', 'use', 'connectionist', 'technical', 'report', 'tr', 'cam', 'bridge', 'university', 'engineering', 'ostrovski', 'return', 'base', 'scaling', 'normalisation', 'trick', 'deep', 'schulman', 'radford', 'klimov', 'proximal', 'policy', 'optimization', 'url', 'schwarzer', 'anand', 'goel', 'r', 'hjelm', 'r', 'bachman', 'p', 'dataefﬁcient', 'reinforcement', 'learn', 'e', 'selfpredictive', 'representation', 'preprint', 'shorten', 'survey', 'image', 'datum', 'augmentation', 'deep', 'learning', 'journal', 'big', 'datum', 'silver', 'lever', 'g', 'heess', 'riedmiller', 'deterministic', 'policy', 'gradient', 'algorithm', 'silver', 'hubert', 'schrittwieser', 'lanctot', 'sifre', 'l', 'pel', 'master', 'chess', 'shogi', 'selfplay', 'general', 'reinforcement', 'learn', 'preprint', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'servational', 'overﬁtting', 'reinforcement', 'learning', 'national', 'conference', 'learn', 'representation', 'international', 'conference', 'reinforcement', 'learn', 'learn', 'representation', 'v', 'ingredient', 'real', 'world', 'robotic', 'reinforcement', 'learn', 'preprint', 'sutskever', 'salakhutdinov', 'r', 'dropout', 'simple', 'way', 'jour', 'prevent', 'neural', 'network', 'overﬁtte', 'nal', 'machine', 'learn', 'research', 'student', 'probable', 'error', 'mean', 'url', 'r', 'learn', 'predict', 'method', 'temporal', 'difference', 'machine', 'learn', 'r', 'mcallester', 'singh', 'p', 'mansour', 'policy', 'gradient', 'method', 'reinforcement', 'learning', 'function', 'approximation', 'advance', 'neural', 'formation', 'processing', 'system', 'tassa', 'doron', 'muldal', 'erez', 'merel', 'preprint', 'doron', 'modayil', 'deep', 'reinforcement', 'learning', 'deadly', 'preprint', 'h', 'hessel', 'aslanide', 'use', 'parametric', 'model', 'reinforcement', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'vinyal', 'babuschkin', 'powell', 'r', 'ewald', 'georgiev', 'p', 'grandmaster', 'level', 'use', 'multiagent', 'reinforcement', 'learn', 'nature', 'individual', 'comparison', 'rank', 'wilcoxon', 'biometric', 'bulletin', 'method', 'url', 'yarat', 'fergus', 'r', 'improve', 'sample', 'efﬁciency', 'model', 'free', 'reinforcement', 'learn', 'image', 'proceeding', 'conference', 'artiﬁcial', 'intelligence', 'yarat', 'fergus', 'r', 'lazaric', 'master', 'e', 'visual', 'continuous', 'control', 'improve', 'dataaugmente', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixel', 'detailed', 'result', 'medium', 'hard', 'task', 'table', 'show', 'performance', 'evaluate', 'dmc', 'environment', 'report', 'mean', 'standard', 'deviation', 'cumulative', 'return', 'obtain', 'midway', 'end', 'training', 'medium', 'hard', 'benchmark', 'task', 'respectively', 'alix', 'attain', 'stateoftheart', 'performance', 'majority', 'task', 'report', 'checkpoint', 'still', 'closely', 'match', 'drqv2', 'performance', 'remain', 'task', 'hand', 'drqv2', 'struggle', 'consistently', 'solve', 'hard', 'exploration', 'task', 'cartpole', 'humanoid', 'run', 'show', 'high', 'standard', 'deviation', 'interestingly', 'simple', 'dmc', 'benchmark', 'high', 'action', 'repeat', 'appear', 'slight', 'edge', 'drq', 'particular', 'selfsupervise', 'signal', 'curl', 'appear', 'aid', 'precisely', 'sparse', 'reward', 'environment', 'drqv2', 'struggle', 'hence', 'appear', 'suggest', 'include', 'additional', 'selfsupervise', 'signal', 'tdloss', 'lessen', 'hinder', 'effect', 'lowermagnitude', 'reward', 'signal', 'interpret', 'result', 'additional', 'evidence', 'show', 'address', 'individual', 'component', 'deadly', 'triad', 'help', 'counteract', 'catastrophic', 'selfoverﬁtting', 'phenomenon', 'also', 'test', 'signiﬁcance', 'result', 'perform', 'wilcoxon', 'signedrank', 'test', 'wilcoxon', 'alix', 'drqv2', 'perform', 'pair', 'rank', 'test', 'seed', 'task', 'allow', 'obtain', 'pvalue', 'take', 'account', 'population', 'size', 'relative', 'performance', 'gain', 'task', 'choice', 'wilcoxon', 'signedrank', 'test', 'also', 'presume', 'normality', 'distribution', 'performance', 'believe', 'appropriate', 'assumption', 'instance', 'pair', 'tt', 'student', 'potential', 'loss', 'statistical', 'power', 'ensure', 'correct', 'population', 'pair', 'alix', 'drqv2', 'seed', 'identical', 'result', 'initially', 'collect', 'datum', 'network', 'initialization', 'perform', 'test', 'task', 'seed', 'achieve', 'pvalue', 'total', 'frame', 'medium', 'hard', 'respectively', 'total', 'frame', 'medium', 'hard', 'respectively', 'much', 'low', 'typical', 'rejection', 'criterion', 'therefore', 'believe', 'show', 'clear', 'evidence', 'result', 'strongly', 'statistically', 'signiﬁcant', 'table', 'full', 'result', 'benchmark', 'display', 'return', 'average', 'random', 'seed', 'evaluation', 'run', 'collect', 'experience', 'checkpoint', 'medium', 'task', 'sac', 'curl', 'drq', 'drqv2', 'alix', 'sac', 'curl', 'drq', 'drqv2', 'alix', 'frame', 'frame', '24±27', 'cartpole', 'swingup', 'sparse', '479±329', '318±389', 'finger', 'turn', 'easy', '297±150', 'finger', 'turn', 'hard', '79±73', '174±106', '491±182', 'hopper', '198±102', '0±0', 'quadrupe', 'run', '419±204', '68±72', 'quadrupe', 'walk', '591±256', '75±65', 'reach', 'duplo', '8±10', 'reacher', 'easy', '600±201', 'reacher', 'hard', '463±196', '320±233', 'walker', 'run', '474±148', '571±276', '26±4', '718±250', '546±101', '28±25', '185±295', '316±389', '309±176', '216±158', '902±77', '86±70', '224±135', '240±123', '63±45', '175±104', '523±271', '48±32', '667±182', '10±23', '447±224', '547±143', '742±250', '864±78', 'average', 'score', 'frame', 'frame', 'hard', 'task', 'walk', 'humanoid', 'stand', 'humanoid', 'run', 'average', 'score', 'sac', 'curl', 'drq', 'drqv2', 'alix', 'sac', 'curl', 'drq', 'drqv2', 'alix', '243±162', '167±159', '170±122', 'compare', 'result', 'use', 'rliable', 'framework', 'introduce', 'agarwal', 'see', 'app', 'a3', 'detailed', 'explanation', 'metric', 'introduce', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'figure', 'performance', 'proﬁle', 'leave', 'right', 'total', 'step', 'medium', 'hard', 'dmc', 'task', 'plot', 'performance', 'proﬁle', 'fig', 'total', 'training', 'step', 'aim', 'represent', 'sample', 'efﬁciency', 'asymptotic', 'performance', 'respectively', 'see', 'almost', 'case', 'alix', 'improve', 'drqv2', 'overall', 'ranking', 'statistic', 'top', 'bottom', 'tal', 'step', 'medium', 'hard', 'dmc', 'task', 'b', 'aggregate', 'iqm', 'leave', 'optimality', 'gap', 'right', 'metric', 'total', 'step', 'medium', 'hard', 'dmc', 'task', 'plot', 'rank', 'statistic', 'fig', 'total', 'training', 'step', 'see', 'alix', 'clearly', 'appear', '1st', 'rank', 'column', 'rarely', 'appear', 'lower', 'rank', 'suggest', 'strong', 'performance', 'environment', 'medium', 'hard', 'also', 'provide', 'far', 'aggregated', 'statistic', 'plot', 'fig', '12b', 'time', 'total', 'step', 'show', 'alix', 'particularly', 'sampleefﬁcient', 'consistent', 'low', 'error', 'bar', 'environment', 'total', 'step', 'total', 'step', 'figure', 'probability', 'improvement', 'statitistic', 'leave', 'right', 'total', 'timestep', 'medium', 'hard', 'dmc', 'task', 'fig', 'observe', 'alix', 'likely', 'improve', 'prior', 'work', 'note', 'improvement', 'probability', 'drqv2', 'seem', 'slightly', 'low', '∼60', 'note', 'value', 'line', 'statistic', 'prior', 'work', 'achieve', 'signiﬁcant', 'gain', 'see', 'agarwal', 'furthermore', 'take', 'account', 'absolute', 'performance', 'value', 'instead', 'compare', 'relative', 'value', 'explain', 'gain', 'alix', 'appear', 'large', 'evaluate', 'iqm', 'og', 'furthermore', 'low', 'ci', 'total', 'step', 'fall', 'mean', 'improvement', 'indeed', 'statistically', 'signiﬁcant', 'total', 'step', 'total', 'step', 'e', 'r', 'h', 'r', 'n', 'c', 'r', 'e', 'r', 'h', 'r', 'n', 'c', 'r', 'normalize', 'score', 'normalize', 'score', 'alix', 'drqv2', 'curl', 'sac', 'total', 'step', 'n', 'c', 'r', 'total', 'step', 'rank', 'alix', 'drqv2', 'drq', 'curl', 'sac', 'alix', 'drqv2', 'drq', 'curl', 'sac', 'iqm', 'optimality', 'gap', 'max', 'normalize', 'score', 'palix', 'h', 'r', 'g', 'l', 'sac', 'curl', 'drq', 'drqv2', 'h', 'r', 'g', 'l', 'sac', 'curl', 'drq', 'drqv2', 'palix', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'table', 'show', 'ﬁnal', 'average', 'performance', 'evaluate', 'algorithm', 'twentysix', 'task', 'benchmark', 'alix', 'outperform', 'spr', 'previous', 'stateoftheart', 'offpolicy', 'benchmark', 'task', 'moreover', 'attain', 'comparatively', 'similar', 'performance', 'remain', 'task', 'use', 'augmentation', 'auxiliary', 'loss', 'modelbase', 'element', 'table', 'full', 'result', 'benchmark', 'follow', 'evaluation', 'protocol', 'machado', 'report', 'result', 'collect', 'random', 'seed', 'task', 'random', 'human', 'simple', 'der', 'otrainbow', 'drq', 'spr', 'alix', 'alien', 'amidar', 'heist', 'battle', 'zone', 'box', 'breakout', 'chopper', 'command', 'crazy', 'freeway', 'frostbite', 'gopher', 'hero', 'private', 'eye', 'qbert', 'road', 'runner', 'seaquest', 'human', 'norm', 'mean', 'human', 'norm', 'super', 'average', 'rank', 'present', 'additional', 'evaluation', 'rliable', 'framework', 'continue', 'analysis', 'fig', '10b', 'figure', 'performance', 'proﬁle', 'linear', 'left', 'logarithmic', 'right', 'scaling', 'fig', 'alix', 'perform', 'noticeably', 'well', 'previous', 'work', 'perform', 'least', 'well', 'spr', 'setting', 'e', 'r', 'h', 'r', 'n', 'c', 'r', 'score', 'distribution', 'non', 'linear', 'scale', 'score', 'distribution', 'e', 'r', 'h', 'r', 'n', 'c', 'r', 'human', 'normalize', 'score', 'τ', 'human', 'normalize', 'score', 'alix', 'spr', 'curl', 'otr', 'der', 'simple', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'normalize', 'score', 'rank', 'statistic', 'probability', 'improvement', 'statistic', 'figure', 'bootstrappe', 'rank', 'statistic', 'leave', 'probability', 'improvement', 'plot', 'right', 'atari', 'constitute', 'majority', 'algorithm', 'rank', '1st', 'show', 'far', 'instance', 'rank', 'low', 'position', 'fig', '15b', 'observe', 'likely', 'improve', 'prior', 'work', 'similar', 'fig', '∼60', 'improvement', 'value', 'seem', 'low', 'shortcoming', 'metric', 'take', 'account', 'actual', 'performance', 'value', 'instead', 'relative', 'improvement', 'low', 'ci', 'fall', 'mean', 'improvement', 'due', 'alix', 'statistically', 'signiﬁcant', 'a3', 'rliable', 'primer', 'addition', 'provide', 'traditional', 'method', 'evaluation', 'eg', 'performance', 'table', 'signiﬁcance', 'testing', 'use', 'robust', 'metric', 'evaluation', 'strategy', 'introduce', 'rliable', 'agarwal', 'rliable', 'advocate', 'compute', 'aggregate', 'performance', 'statistic', 'many', 'seed', 'also', 'many', 'task', 'benchmark', 'suite', 'give', 'detail', 'metric', 'achieve', 'reliable', 'performance', 'evaluation', 'rl', 'denote', 'number', 'seed', 'n', 'number', 'task', 'follow', 'agarwal', 'closely', 'possible', 'refer', 'paper', 'detail', 'task', 'aggregation', 'order', 'aggregate', 'performance', 'different', 'task', 'benchmark', 'suite', 'ﬁrst', 'normalize', 'benchmark', 'range', 'atari', 'usually', 'normalize', 'score', 'respect', 'achieve', 'human', 'respect', 'maximum', 'achievable', 'score', 'refer', 'normalize', 'score', 'iqm', 'mean', 'take', 'middle', 'run', 'seed', 'benchmark', 'ie', 'calculate', 'mean', 'score', 'improve', 'outlier', 'robustness', 'maintain', 'statistical', 'efﬁciency', 'optimality', 'gap', 'calculate', 'proportion', 'performance', 'fail', 'meet', 'minimum', 'threshold', 'γ', 'assumption', 'improvement', 'γ', 'important', 'case', 'stratiﬁed', 'bootstrap', 'sampling', 'use', 'calculate', 'conﬁdence', 'interval', 'cis', 'a33', 'performance', 'profile', 'performance', 'proﬁle', 'form', 'empirical', 'cdf', 'bootstrap', 'sample', 'produce', 'conﬁdence', 'band', 'account', 'underlie', 'variability', 'score', 'also', 'establish', 'stochastic', 'dominance', 'observe', 'method', 'performance', 'consistently', '’', 'normalize', 'performance', 'value', 'a34', 'rank', 'ranking', 'show', 'proportion', 'time', 'give', 'rank', 'give', 'position', 'task', 'distribution', 'produce', 'use', 'sample', 'repetition', 'a35', 'probability', 'improvement', 'probability', 'improvement', 'calculate', 'calculate', 'ustatistic', 'whitney', 'task', 'distribution', 'plot', 'boxplot', 'low', 'ci', 'improvement', 'statistically', 'signiﬁcant', 'n', 'c', 'r', 'rank', 'alix', 'spr', 'drq', 'curl', 'otr', 'der', 'simple', 'palix', 'h', 'r', 'g', 'l', 'spr', 'drq', 'curl', 'otr', 'der', 'simple', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'b', 'experiment', 'description', 'b1', 'ofﬂine', 'experiment', 'follow', 'original', 'training', 'hyperparameter', 'drqv2', 'run', 'policy', 'evaluation', 'policy', 'improvement', 'see', 'convergence', 'tdloss', 'occur', 'similar', 'point', 'agent', '510k', 'step', 'sgd', 'policy', 'evaluation', 'policy', 'iteration', 'respectively', 'proprioceptive', 'experiment', 'keep', 'consistent', 'input', 'critic', 'actor', 'layer', 'proprioceptive', 'state', 'simulator', 'latent', 'representation', 'z', 'encoder', 'say', 'modify', 'architecture', 'learn', 'rate', 'interest', 'fair', 'comparison', 'furthermore', 'give', 'seed', 'ofﬂine', 'experiment', 'also', 'instantiate', 'network', 'agent', 'identically', 'train', 'random', 'ofﬂine', 'datum', 'minibatche', 'present', 'order', 'also', 'note', 'similar', 'describe', 'brandfonbren', 'context', 'minimize', 'extrapolation', 'error', 'present', 'additional', 'analysis', 'provide', 'context', 'ofﬂine', 'experiment', 'first', 'see', 'proprioceptive', 'statistic', 'mirror', 'augmented', 'agent', 'far', 'illustrate', 'crucial', 'role', 'regularization', 'successful', 'tdlearning', 'figure', 'q', 'value', 'pearson', 'correlation', 'ofﬂine', 'proprioceptive', 'agent', 'ofﬂine', 'ﬁxed', 'batch', 'secondly', 'observe', 'exact', 'selfoverﬁt', 'also', 'manifest', 'online', 'setting', 'plot', 'pearson', 'correlation', 'value', 'initial', 'stage', 'training', 'seed', 'conﬁrme', 'phenomenon', 'ofﬂine', 'analysis', 'apply', 'online', 'problem', 'figure', 'pearson', 'correlation', 'augmented', 'nonaugmente', 'online', 'agent', 'run', 'quadrupe', 'walk', 'seed', 'shade', 'line', 'represent', 'individual', 'run', 'solid', 'line', 'represent', 'median', 'see', 'augmented', 'agent', 'immediately', 'overﬁt', 'target', 'network', 'correlate', 'useful', 'signal', 'learn', 'jacobian', 'analysis', 'order', 'measure', 'local', 'sensitivity', 'linearize', 'encoder', 'input', 'use', 'series', 'expansion', 'consider', 'n', 'dimensional', 'input', '∈', 'rn', 'perturbation', 'dimensional', 'output', 'function', 'perform', 'series', 'expansion', 'j˜xcid15', 'q', 'value', 'training', 'l', 'e', 'r', 'r', 'c', 'n', 'e', 'p', 'l', 'e', 'u', 'v', 'q', 'sgd', 'step', 'correlation', 'q', 'qtarget', 'r', 'qtarget', 'r', 'sgd', 'step', 'l', 'e', 'r', 'r', 'c', 'n', 'e', 'p', 'run', 'frame', 'quadrupe', 'walk', 'qtarget', 'aug', 'qtarget', 'aug', 'frame', 'r', 'aug', 'r', 'aug', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixel', 'make', 'approximation', 'second', 'line', 'drop', 'second', 'orderhessian', 'high', 'term', 'assumption', 'perturbation', 'vector', 'small', 'allow', 'write', 'form', 'local', 'linear', 'system', 'jxcid15', 'straightforward', 'see', 'entry', 'jacobian', 'matrix', 'large', 'small', 'perturbation', 'cause', 'large', 'change', 'output', 'measure', 'magnitude', 'jacobian', 'entry', 'take', 'norm', 'n’th', 'entry', 'm’th', 'entry', 'codomain', 'calculation', 'trivial', 'use', 'automatic', 'differentiation', 'framework', 'analysis', 'calculate', 'jacobian', 'agent', 'ﬁxed', 'batch', 'frame', 'stack', 'image', 'take', 'ofﬂine', 'training', 'dataset', 'compare', 'correspond', 'ratio', 'frobenius', 'norm', 'take', 'average', 'ratio', 'batch', 'seed', 'c', 'additional', 'analysis', 'c1', 'adaptive', 'nd', 'dual', 'objective', 'optimization', 'alternative', 'score', 'increase', 'outlier', 'robustness', 'propose', 'section', 'inspire', 'recording', 'signaltonoise', 'ratio', 'measurement', 'particular', 'pass', 'individual', 'normalize', 'dz', 'term', 'smoothing', 'function', 'downweight', 'effect', 'large', 'individual', 'outlier', 'aggregated', 'metric', 'like', 'remark', 'set', 'optimization', 'dual', 'objective', 'change', 'actual', 'target', 'value', 'relate', 'appropriate', 'smoothness', 'constraint', 'mostly', 'irrelevant', 'consider', 'optimization', 'dynamic', 'therefore', 'argue', 'tune', 'actual', 'considerably', 'diverge', 'tune', 'base', 'rescaled', 'appropriate', 'target', 'provide', 'plot', 'compare', 'agent', 'performance', 'respective', 'adaptive', 'parameter', 'training', 'figure', 'performance', 'agent', 'different', 'seed', 'run', 'environment', 'adaptive', 'scalar', 'parameter', 'observe', 'initially', 'high', 'agent', 'learn', 'useful', 'behavior', 'drop', 'maintain', 'nd', 'presence', 'useful', 'signal', 'feature', 'gradient', 'figure', 'performance', 'agent', 'different', 'seed', 'quadrupe', 'run', 'environment', 'adaptive', 'scalar', 'parameter', 'observe', 'meaningful', 'behavior', 'learn', 'agent', 'end', 'training', 'fall', 'accordingly', 'drop', 'maintain', 'nd', 'presence', 'useful', 'signal', 'feature', 'gradient', 'see', 'effect', 'contrast', 'environment', 'run', 'learning', 'stable', 'predictable', 'initialization', 'degree', 'freedom', 'see', 'alix', 'parameter', 'drop', 'almost', 'immediately', 'tdtarget', 'quickly', 'become', 'accurate', 'less', 'stable', 'quadrupe', 'run', 'also', 'notice', 'anneal', 'effect', 'however', 'occur', 'later', 'training', 'agent', 'consistently', 'recover', 'poor', 'initialization', 'seed', 'seed', 'seed', 'seed', 'n', 'r', 'u', 'e', 'r', 'frame', 'frame', '×106', 'agent', 'return', 'frame', 'alix', 'parameter', 'l', 'e', 'u', 'v', 'x', 'frame', '×106', 'seed', 'seed', 'seed', 'seed', 'n', 'r', 'u', 'e', 'r', 'frame', 'frame', 'agent', 'return', 'frame', 'alix', 'parameter', 'frame', 'l', 'e', 'u', 'v', 'x', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'return', 'large', 'nstep', 'reward', 'become', 'important', 'part', 'many', 'algorithm', 'use', 'tdlearne', 'visual', 'observation', 'motivate', 'section', 'large', 'nstep', 'reward', 'help', 'mitigate', 'selfoverﬁtte', 'densifye', 'reward', 'downweighte', 'contribution', 'inaccurate', 'target', 'critic', 'especially', 'early', 'training', 'indeed', 'show', 'yarat', 'use', 'learning', 'signiﬁcant', 'negative', 'impact', 'performance', 'however', 'know', 'biasvariance', 'tradeoff', 'multistep', 'approach', 'kearn', 'singh', 'furthermore', 'almost', 'approach', 'use', 'method', 'apply', 'offpolicy', 'bias', 'correction', 'sample', 'replay', 'buffer', 'motivate', 'use', 'nstep', 'return', 'way', 'mitigate', 'selfoverﬁtte', 'incur', 'reward', 'tuple', 'especially', 'common', 'sparse', 'reward', 'environment', 'early', 'training', 'believe', 'evidence', 'show', 'introduce', 'bias', 'sufﬁciently', 'large', 'prior', 'work', 'suggest', 'case', 'figure', 'return', 'agent', 'seed', 'solid', 'line', 'represent', 'median', 'performance', 'fade', 'line', 'represent', 'individual', 'run', 'show', 'fig', 'commonly', 'algorithm', 'use', 'solve', 'atari', 'return', 'mitigate', 'failure', 'seed', 'predict', 'visual', 'deadly', 'triad', 'framework', 'indeed', 'run', 'seed', 'completely', 'ﬂatline', 'return', 'use', 'however', 'also', 'see', 'evidence', 'apply', 'return', 'negative', 'impact', 'convergence', 'asymptotic', 'performance', 'run', 'deadly', 'triad', 'sufﬁciently', 'manage', 'use', 'augmentation', 'quadrupe', 'run', 'see', 'moderate', 'beneﬁt', 'initially', 'note', 'asymptotically', 'agent', 'converge', 'performance', 'also', 'provide', 'evidence', 'apply', 'return', 'alix', 'agent', 'generally', 'laregely', 'negative', 'impact', 'performance', 'finally', 'note', 'try', 'return', 'algorithm', 'solve', 'atari', 'laskin', 'cause', 'signiﬁcant', 'performance', 'reduction', 'conclusion', 'provide', 'evidence', 'consider', 'use', 'low', 'value', 'multistep', 'return', 'achieve', 'address', 'element', 'deadly', 'run', 'quadrupe', 'walk', 'n', 'r', 'u', 'e', 'r', 'frame', 'frame', 'aug', 'aug', 'aug', '10step', 'aug', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixel', 'implementation', 'detail', 'table', 'provide', 'full', 'list', 'hyperparameter', 'use', 'implementation', 'respectively', 'show', 'signiﬁcant', 'difference', 'standard', 'practice', 'bold', 'particular', 'alix', 'use', 'encoder', 'architecture', 'nstep', 'return', 'benchmark', 'highlight', 'low', 'reliance', 'environmentspeciﬁc', 'heuristic', 'moreover', 'prior', 'stateoftheart', 'algorithm', 'employ', 'datum', 'augmentation', 'auxiliary', 'loss', 'function', 'factor', 'show', 'effectiveness', 'adaptive', 'method', 'counteract', 'instability', 'visual', 'deadly', 'triad', 'additional', 'help', 'highlight', 'applicability', 'table', 'full', 'hyperparameter', 'list', 'use', 'deepmind', 'control', 'alix', 'experiment', 'bolde', 'value', 'represent', 'signiﬁcant', 'difference', 'canonical', 'implementation', 'ddpgintegration', 'hyperparameter', 'follow', 'yarat', 'replay', 'datum', 'buffer', 'size', 'batch', 'size', 'minimum', 'datum', 'train', 'random', 'exploration', 'step', 'optimizer', 'policycritic', 'learning', 'rate', 'policycritic', 'critic', 'ratio', 'policy', 'utd', 'ratio', 'discount', 'coefﬁcient', 'nstep', 'return', 'hide', 'dimensionality', 'feature', 'dimensionality', 'nonlinearity', 'exploration', 'stddev', 'clip', 'exploration', 'stddev', 'schedule', 'augmentation', 'quadrupe', 'run', 'run', 'medium', 'hard', 'run', 'medium', 'hard', 'relu', 'medium', 'linear', 'step', 'hard', 'linear', 'step', 'alixspeciﬁc', 'hyperparameter', 'initial', 'maximum', 'sampling', 'shift', 'normalize', 'discontinuity', 'target', 'maximum', 'sampling', 'shift', 'learning', 'rate', 'maximum', 'sampling', 'shift', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'table', 'full', 'hyperparameter', 'list', 'use', 'atari', 'alix', 'experiment', 'bolde', 'value', 'represent', 'signiﬁcant', 'difference', 'canonical', 'implementation', 'derintegration', 'hyperparameter', 'grayscale', 'downsampling', 'frame', 'stack', 'action', 'repetition', 'reward', 'clip', 'max', 'episode', 'frame', 'replay', 'datum', 'buffer', 'size', 'replay', 'period', 'batch', 'size', 'minimum', 'datum', 'train', 'random', 'exploration', 'step', 'optimizer', 'critic', 'learning', 'rate', 'critic', 'critic', 'norm', 'critic', 'utd', 'ratio', 'discount', 'γ', 'target', 'update', 'period', 'nstep', 'return', 'feature', 'map', 'filter', 'size', 'stride', 'hidden', 'dimensionality', 'feature', 'dimensionality', 'nonlinearity', 'exploration', 'noisy', 'net', 'parameter', 'augmentation', 'true', '×', '×', '×', '×', 'relu', 'alixspeciﬁc', 'hyperparameter', 'initial', 'maximum', 'sampling', 'shift', 'normalize', 'discontinuity', 'target', 'maximum', 'sampling', 'shift', 'learning', 'rate', 'maximum', 'sampling', 'shift', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixel', 'e', 'additional', 'ablation', 'e1', 'smoothness', 'regularization', 'spectral', 'normalization', 'distinguish', 'general', 'smoothness', 'contraint', 'convolutional', 'feature', 'smoothness', 'arise', 'result', 'spatial', 'consistency', 'apply', 'spectral', 'normalization', 'miyato', 'ﬁnal', 'convolutional', 'layer', 'encoder', 'represent', 'former', 'class', 'constraint', 'spectral', 'normalization', 'operate', 'parameter', 'network', 'constrain', 'output', 'show', 'beneﬁts', 'prior', 'work', 'gogianu', 'explicitly', 'enforce', 'spatial', 'regularization', 'feature', 'train', 'agent', 'augmentation', 'use', 'spectral', 'normalization', 'figure', 'return', 'agent', 'seed', 'solid', 'line', 'represent', 'median', 'performance', 'fade', 'line', 'represent', 'individual', 'run', 'see', 'clear', 'improvement', 'original', 'nonaugmented', 'agent', 'case', 'performance', 'still', 'low', 'agent', 'use', 'spatial', 'consistency', 'regularization', 'random', 'shift', 'augmentation', 'gradient', 'smooth', 'need', 'follow', 'argument', 'section', 'view', 'augmentation', 'gradient', 'smoothing', 'regularizer', 'naturally', 'lead', 'ask', 'follow', 'replace', 'stochastic', 'shifting', 'mechanism', 'ﬁxed', 'smoothing', 'mechanism', 'test', 'instead', 'apply', 'gaussian', 'smoothing', 'kernel', 'feature', 'gradient', 'cnn', 'utilize', 'n', 'score', 'vary', 'width', 'kernel', 'adaptively', 'training', 'call', 'method', 'agauss', 'adaptive', 'gaussian', 'feature', 'kernel', 'figure', 'return', 'agent', 'seed', 'solid', 'line', 'represent', 'median', 'performance', 'fade', 'line', 'represent', 'individual', 'run', 'see', 'improvement', 'nonaugmented', 'agent', 'overall', 'performance', 'still', 'low', 'even', 'simple', 'nonadaptive', 'augmentation', 'believe', 'due', 'gaussian', 'kernel', 'signiﬁcant', 'effect', 'information', 'contain', 'feature', 'gradient', 'backpropagation', 'cause', 'information', 'lose', 'believe', 'explain', 'effectiveness', 'shiftaugmentation', 'reinforcement', 'learning', 'effectively', 'balance', 'information', 'contain', 'gradient', 'well', 'ensure', 'smoothness', 'reduce', 'overﬁtte', 'ablation', 'alix', 'provide', 'set', 'ablation', 'atari', 'assess', 'impact', 'individual', 'component', 'alix', 'run', 'quadrupe', 'walk', 'n', 'r', 'u', 'e', 'r', 'frame', 'frame', 'aug', 'spectral', 'normalization', 'run', 'quadrupe', 'walk', 'n', 'r', 'u', 'e', 'r', 'frame', 'frame', 'aug', 'agauss', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixel', 'control', 'ablation', 'run', 'leave', 'quadrupe', 'run', 'right', 'evaluate', 'seed', 'ablation', 'evaluate', 'seed', 'different', 'atari', 'task', 'figure', 'ablation', 'study', 'alix', 'show', 'contribution', 'individual', 'component', 'ultimate', 'performance', 'fig', '23a', 'choose', 'follow', 'ablation', 'dmc', 'adaptive', 'random', 'shift', 'magnitude', 'random', 'shift', 'image', 'augmentation', 'adjust', 'use', 'dual', 'nd', 'objective', 'lix', 'random', 'shift', 'drqv2', 'see', 'slight', 'asymptotic', 'performance', 'improvement', 'run', 'use', 'lix', 'layer', 'instead', 'random', 'shift', 'notice', 'signiﬁcant', 'difference', 'less', 'stable', 'quadrupe', 'run', 'environment', 'concretely', 'see', 'much', 'great', 'stability', 'lix', 'approach', 'compare', 'image', 'augmentation', 'approach', 'former', 'failure', 'seed', 'furthermore', 'observe', 'strong', 'asymptotic', 'performance', 'inclusion', 'adaptive', 'dual', 'objective', 'approach', 'motivate', 'fig', 'likely', 'result', 'reduce', 'shift', 'parameter', 'signal', 'target', 'value', 'increase', 'fig', '23b', 'choose', 'follow', 'ablation', 'atari', '100k', 'subset', 'environment', 'represent', 'diverse', 'set', 'task', 'performance', 'baseline', 'algorithm', 'alix', 'adaptive', 'random', 'shift', 'lix', 'alix', 'return', 'random', 'shift', 'see', 'alix', 'perform', 'consistently', 'strongly', 'environment', 'test', 'always', 'place', 'top', 'regard', 'human', 'normalized', 'score', 'also', 'notice', 'generally', 'lix', 'layer', 'method', 'outperform', 'random', 'shift', 'method', 'apart', 'crazy', 'climber', 'opposite', 'true', 'believe', 'due', 'random', 'shift', 'augmentation', 'actually', 'reﬂecte', 'inductive', 'bias', 'concern', 'generalization', 'environment', 'believe', 'merit', 'investigation', 'finally', 'observe', 'use', 'return', 'instead', 'generally', 'harm', 'performance', 'alix', 'justiﬁcation', 'give', 'r', 'e', 'r', 'run', 'quadrupe', 'run', 'alix', 'adaptive', 'random', 'shift', 'lix', 'random', 'shift', 'drqv2', 'frame', '×106', 'frame', '×106', 'e', 'r', 'l', 'r', 'n', 'h', 'alix', 'adaptive', 'random', 'shift', 'lix', 'alix', 'random', 'shift', 'battle', 'zone', 'crazy', 'task', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'additional', 'ofﬂine', 'experiment', 'analysis', 'f1', 'behavior', 'clone', 'augmentation', 'figure', 'return', 'agent', 'seed', 'solid', 'line', 'represent', 'median', 'performance', 'fade', 'line', 'represent', 'individual', 'run', 'grey', 'dot', 'horizontal', 'line', 'represent', 'mean', 'expert', 'performance', 'illustrate', 'test', 'time', 'shift', 'invariance', 'require', 'show', 'possible', 'learn', 'policy', 'supervised', 'learning', 'generate', 'pixelbased', 'dataset', 'timestep', 'expert', 'policy', 'run', 'jointly', 'train', 'cnn', 'encoder', 'policy', 'use', 'behavior', 'cloningsupervise', 'learning', 'minimize', 'loss', 'convergence', 'follow', 'stacked', 'frame', 'image', 'input', 'mnih', 'et', 'see', 'pixelbase', 'policy', 'perform', 'well', 'behavior', 'agent', 'use', 'high', 'dimensional', 'datum', 'sample', 'compare', 'exist', 'expert', 'ofﬂine', 'benchmark', 'proprioceptive', 'provide', 'clear', 'evidence', 'shift', 'invariance', 'require', 'test', 'time', 'motivate', 'alternative', 'explanation', 'random', 'shift', 'augmentation', 'help', 'learning', 'process', 'tdlearne', 'alternative', 'perspective', 'learning', 'signal', 'strong', 'case', 'supervised', 'learning', 'later', 'stage', 'online', 'learning', 'target', 'value', 'accurate', 'natural', 'bias', 'cnn', 'learn', 'low', 'order', 'representation', 'act', 'implicit', 'regularizer', 'rahaman', 'result', 'testtime', 'generalization', 'f2', 'turn', 'augmentation', 'present', 'evidence', 'show', 'augmentation', 'beneﬁt', 'learn', 'beginning', 'training', 'fig', 'show', 'effect', 'turn', 'augmentation', 'step', 'run', 'quadrupe', 'walk', 'instance', 'see', 'large', 'improvement', 'augment', 'nearly', 'converge', 'value', 'drqv2', 'show', 'evidence', 'stability', 'initially', 'learn', 'vital', 'posit', 'turn', 'augmentation', 'yield', 'similar', 'beneﬁts', 'fig', 'due', 'fact', 'still', 'highfrequency', 'information', 'target', 'consider', 'augmentation', 'run', 'switch', 'signiﬁcantly', 'early', 'cause', 'marginal', 'amount', 'selfoverﬁtte', 'reduce', 'rate', 'learn', 'feature', 'space', 'degeneration', 'figure', 'return', 'agent', 'seed', 'solid', 'line', 'represent', 'median', 'performance', 'fade', 'line', 'represent', 'individual', 'run', 'grey', 'dash', 'line', 'show', 'augmentation', 'turn', 'run', 'expert', 'perfomance', 'r', 'u', 'e', 'r', 'aug', 'sgd', 'step', '×105', 'run', 'quadrupe', 'walk', 'aug', 'turn', 'aug', 'turn', 'n', 'r', 'u', 'e', 'r', 'frame', 'frame', 'aug', 'aug', 'aug', 'remove', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'f3', 'actionvalue', 'surface', 'show', 'actionvalue', 'surface', 'ofﬂine', 'agent', 'critic', 'various', 'tuple', 'sample', 'datum', 'provide', 'intuition', 'loss', 'landscape', 'policy', 'optimize', 'policy', 'improvement', 'accordingly', 'policy', 'deterministic', 'policy', 'gradient', 'silver', 'update', 'weight', 'maximize', 'actionvalue', 'deﬁne', 'critic', 'chain', 'rule', 'aafφs∇φfφscid3', 'θ', 'policy', 'critic', 'weight', 'respectively', 'hypothesize', 'selfoverﬁtte', 'reduce', 'sensitivity', 'critic', 'action', 'discard', 'important', 'information', 'regard', 'causal', 'link', 'action', 'expect', 'return', 'evaluate', 'sample', 'stateaction', 'pair', 'replay', 'buffer', 'visualize', 'actionvalue', 'surface', 'sample', 'random', 'orthogonal', 'direction', 'vector', 'action', 'space', 'normalize', 'direction', 'vector', 'multiply', 'direction', 'vector', 'scalar', '−2', 'respectively', 'plot', 'actionvalue', 'surface', 'result', 'add', 'random', 'vector', 'multiply', 'respective', 'scalar', 'action', 'sample', 'ofﬂine', 'dataset', 'give', 'surface', 'clip', 'action', '∈', '−1', 'action', 'squash', 'range', 'policy', 'truncated', 'normal', 'distribution', 'random', 'sample', 'stateaction', 'pair', 'b', 'random', 'sample', 'stateaction', 'pair', 'c', 'random', 'sample', 'stateaction', 'pair', 'random', 'sample', 'stateaction', 'pair', 'figure', 'actionvalue', 'loss', 'surface', 'plot', 'respect', 'orthogonal', 'random', 'direction', 'sample', 'action', 'space', 'd1', '⊥', 'd2', 'see', 'critic', 'learn', 'augmented', 'agent', 'sensitive', 'change', 'action', 'believe', 'due', 'nonaugmented', 'agent', 'overﬁtte', 'observation', 'thus', 'ignore', 'lowerdimensional', 'action', 'input', 'validate', 'sample', 'random', 'stateaction', 'tuple', 'ofﬂine', 'buffer', 'calculate', 'average', 'variance', 'loss', 'surface', 'see', 'signiﬁcant', 'difference', 'augmented', 'agent', 'average', 'loss', 'surface', 'variance', 'nonaugmented', 'agent', 'average', 'loss', 'surface', 'variance', 'suggestive', 'low', 'sensitivity', 'f4', 'evidence', 'critic', 'overﬁtte', 'highfrequency', 'feature', 'provide', 'evidence', 'measure', 'highfrequency', 'feature', 'nd', 'score', 'vital', 'understand', 'show', 'overﬁtte', 'able', 'occur', 'fullyconnected', 'critic', 'layer', 'usually', 'stable', 'proprioceptive', 'observation', 'see', 'table', 'construct', 'pattern', 'contain', 'high', 'frequency', 'checkerboard', 'noise', 'produce', 'many', 'pattern', 'channel', 'c', 'ﬁnal', 'layer', 'ensure', 'consistency', 'individual', 'feature', 'map', 'normalize', 'checkerboard', 'pattern', 'maximum', 'value', 'respective', 'feature', 'map', 'divide', 'width', 'checkerboard', 'add', 'pattern', 'multiply', 'scalar', 'α', 'feature', 'map', 'critic', 'augmentation', 'critic', 'augmentation', 'ctio', 'loss', 'action', 'subspace', 'critic', 'augmentation', 'critic', 'augmentation', 'ctio', 'loss', 'action', 'subspace', 'critic', 'augmentation', 'critic', 'augmentation', 'ctio', 'loss', 'action', 'subspace', 'critic', 'augmentation', 'critic', 'augmentation', 'ctio', 'loss', 'action', 'subspace', 'stabilize', 'offpolicy', 'deep', 'reinforcement', 'learn', 'pixel', 'example', 'checkerboard', 'artefact', 'b', 'sensitivity', 'agent', 'checkerboard', 'artifact', 'weight', 'figure', 'effect', 'checkerboard', 'artifact', 'feature', 'map', 'resultant', 'loss', 'sensitivity', 'see', 'nonaugmented', 'agent', 'signiﬁcantly', 'sensitive', 'highfrequency', 'noise', 'see', 'loss', 'signiﬁcantly', 'sensitive', 'highfrequency', 'perturbation', 'nonaugmented', 'agent', 'justify', 'reliance', 'highfrequency', 'pattern', 'feature', 'map', 'enable', 'selfoverﬁtte', 'f5', 'additional', 'loss', 'surface', 'show', 'loss', 'surface', 'ofﬂine', 'agent', 'policy', 'evaluation', 'training', 'step', 'also', 'show', 'surface', 'respect', 'layer', 'follow', 'normalization', 'approach', 'sgd', 'step', 'sgd', 'step', 'c', 'sgd', 'step', 'figure', 'loss', 'surface', 'plot', 'respect', 'encod', 'parameter', 'various', 'stage', 'training', 'sgd', 'step', 'sgd', 'step', 'c', 'sgd', 'step', 'figure', 'loss', 'surface', 'plot', 'respect', 'critic', 'parameter', 'various', 'stage', 'training', 'see', 'loss', 'surface', 'respect', 'parameter', 'signiﬁcantly', 'less', 'sharp', 'lending', 'evidence', 'selfoverﬁtte', 'predominately', 'result', 'ﬂexibility', 'layer', 'learn', 'highfrequency', 'feature', 'augmented', 'agent', 'nonaugmente', 'agent', 'l', 'aug', 'aug', 'checkerboard', 'weight', 'critic', 'augmentation', 'critic', 'augmentation', 'l', 'td', 'loss', 'weight', 'subspace', 'critic', 'augmentation', 'critic', 'augmentation', 'l', 'w', 'td', 'loss', 'weight', 'subspace', 'critic', 'augmentation', 'critic', 'augmentation', 'l', 'td', 'loss', 'weight', 'subspace', 'critic', 'augmentation', 'critic', 'augmentation', 'l', 'td', 'loss', 'weight', 'subspace', 'critic', 'augmentation', 'critic', 'augmentation', 'l', 'td', 'loss', 'weight', 'subspace', 'critic', 'augmentation', 'critic', 'augmentation', 'l', 'td', 'loss', 'weight', 'subspace']"
"Watch and Match: Supercharging Imitation with Regularized Optimal
  Transport","[{'href': 'http://arxiv.org/abs/2206.15469v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2206.15469v1', 'rel': 'related', 'type': 'application/pdf'}]",2022-06-30 17:58:18,"2
2
0
2

n
u
J

0
3

]
h
p
-
t
n
a
u
q
[

1
v
5
0
4
5
1
.
6
0
2
2
:
v
i
X
r
a

Multivariate trace estimation in constant quantum depth

Yihui Quek,1, 2 Eneet Kaur,3, 4 and Mark M. Wilde5, 6
1Dahlem Center for Complex Quantum Systems,
Freie Universit¨at Berlin, 14195 Berlin, Germany
2Information Systems Laboratory, Stanford University, Stanford, California 94305, USA
3Institute for Quantum Computing and Department of Physics and Astronomy,
University of Waterloo, Waterloo, Ontario, Canada N2L 3G1
4Wyant College of Optical Sciences, University of Arizona, Tucson, AZ 85721, USA
5Hearne Institute for Theoretical Physics, Department of Physics and Astronomy,
and Center for Computation and Technology, Louisiana State University, Baton Rouge, Louisiana 70803, USA
6School of Electrical and Computer Engineering,
Cornell University, Ithaca, New York 14850, USA
(Dated: July 1, 2022)

There is a folkloric belief that a depth-Θ(m) quantum circuit is needed to estimate the trace of
the product of m density matrices (i.e., a multivariate trace). We prove that this belief is overly
conservative by constructing a constant quantum-depth circuit for the task, inspired by the method
of Shor error correction. Furthermore, our circuit demands only local gates in a two dimensional
circuit – we show how to implement it in a highly parallelized way on an architecture similar to that
of Google’s Sycamore processor. With these features, our algorithm brings the task of multivariate
trace estimation, crucial to applications in condensed matter and estimating nonlinear functions of
quantum states, closer to the capabilities of near-term quantum processors. We instantiate the latter
application with a theorem on estimating nonlinear functions of quantum states with “well-behaved”
polynomial approximations.

Contents

I.

INTRODUCTION

I. Introduction

II. The principle: using cyclic shifts for

multivariate trace estimation

III. Our circuit construction

A. Preparing GHZ states in constant quantum

depth

B. Multiply-controlled cyclic permutation in

constant quantum depth
C. Explicit circuit description

IV. Implementation of multivariate trace
estimation on a two-dimensional
architecture

V. Guarantees of our estimator

VI. Applications of our method

VII. Conclusion

Acknowledgments

References

1

2

3

3

4
5

6

6

8

10

10

11

A. Proof of faithfulness and data processing 12

The task of estimating quantities like

Tr[ρ1 · · · ρm]

‘Multivariate traces’

(1)

to copies of

given access
the quantum states ρ1
through ρm is a fundamental building block in quan-
tum information science. This subroutine, which we call
‘multivariate trace estimation’, opens the door to esti-
mating nonlinear functions of quantum states [1, 2], such
as quantum distinguishability measures [3], integer R´enyi
entropies [4], and entanglement measures [5]. This esti-
mation procedure is a component of many quantum pro-
tocols such as quantum ﬁngerprinting [3] and quantum
digital signatures [6].

When ρi = (cid:37) for all i ∈ [m] in Eq. (1), an impor-
tant application of multivariate trace estimation is to
entanglement spectroscopy [4] – deducing the full set of
eigenvalues {λ1, . . . , λD} (the ‘spectrum’) of (cid:37), where
(cid:37) is the reduced state of a bipartite pure state (that
is, (cid:37) = TrB(ψAB) with ψAB a bipartite pure state).
The spectrum unlocks a wealth of information about the
properties of (cid:37). The smallest eigenvalue of (cid:37) diagnoses
whether ψ is separable or entangled [5].
In addition,
the inverse of the smallest eigenvalue acts as a condition
number for many quantum algorithms that manipulate
quantum states (see for instance [7–9]), and it constrains
their runtime. The entanglement spectrum is also use-
ful to identify topological order [10–13], emergent irre-
versibility [14], quantum phase transitions [15], and to
determine if the system obeys an area law [16].

With the wealth of applications described above, there
has been much interest in bringing multivariate trace esti-

 
 
 
 
 
 
mation within the reach of near-term quantum hardware.
A glimmer of hope in this regard is the observation that
quantities like Eq. (1) can be estimated without the need
for full state tomography. In the quantum information
sphere, one of the progenitors of this line of thinking was
Ref. [1], which proposed a method leveraging the follow-
ing well-known identity (related to the replica trick orig-
inating in spin glass theory [17]):

Tr[W π(ρ1 ⊗ · · · ⊗ ρm)] = Tr[ρ1 · · · ρm] ,

(2)

where the right-hand-side is the multivariate trace we
would like to estimate, and W π is a unitary representa-
tion of the cyclic shift permutation

π := (1, 2, . . . , m) .

(3)

Here, π represents a cyclic permutation that sends 1 to
2, 2 to 3, and so forth. That is to say, multivariate trace
estimation can be accomplished by estimating the real
and imaginary parts of the cyclic shift operator in (2),
using quantum hardware. This identity subsequently be-
came the backbone of many proposals [4, 5, 18, 19] for
multivariate trace estimation with yet more near-term
constraints. However, there appears to be a lack of clar-
ity regarding the actual resource requirements of mul-
tivariate trace estimation. Refs. [4, 5, 18, 19] have all
suggested that a quantum circuit whose depth is linear
in m is needed to perform the task.

In this paper, we show that this is an overly-
conservative characterization: multivariate trace estima-
tion can be implemented in constant quantum depth,
with only linearly-many controlled two-qubit gates and
a linear amount of classical pre-processing. We invoke
ideas from Shor error correction [20] to construct a circuit
that achieves this claim (Section III), show how this cir-
cuit can be implemented in a highly parallelized way on
a two-dimensional architecture similar to Google’s (Sec-
tion IV), prove Theorem 3 about the statistical guar-
antees of the resulting estimator (Section V), and show
that our method ﬁnds further application in estimating
traces of ‘well-behaved’ polynomial functions of density
matrices (Section VI).

1. Prepare a qubit in the |+(cid:105) := (|0(cid:105) + |1(cid:105))/
and adjoin to it the state ρ1 ⊗ · · · ⊗ ρm.

√

2

2 state

2. Perform a controlled cyclic permutation unitary

gate, deﬁned as

|0(cid:105)(cid:104)0| ⊗ I ⊗m + |1(cid:105)(cid:104)1| ⊗ W π.

(4)

3. Measure the ﬁrst qubit in the basis {|+(cid:105), |−(cid:105)},
where |−(cid:105) := (|0(cid:105) − |1(cid:105))/
2, and record the out-
come X = +1 if the ﬁrst outcome |+(cid:105) is observed
and X = −1 if the second outcome |−(cid:105) is observed.

√

4. Repeat Steps 1 to 3 a number of times equal to
N := O(ε−2 log δ−1) and return ˆX := 1
i=1 Xi,
N
where Xi is the outcome of the i-th repetition of
Step 3.

(cid:80)N

It is known that

E[X] = Re[Tr[ρ1 · · · ρm]] ,

(5)

and thus ˆX computed in Step 4 is an empirical estimate
of the desired quantity. That is, by invoking the well
known Hoeﬀding inequality, it is guaranteed, for ε > 0
and δ ∈ (0, 1), that

Pr(| ˆX − Re[Tr[ρ1 · · · ρm]]| ≤ ε) ≥ 1 − δ.

(6)

For completeness, we recall the Hoeﬀding inequality now:

Lemma 1 (Hoeﬀding [21]) Suppose that we are given
n independent samples Y1, . . . , Yn of a bounded random
variable Y taking values in [a, b] and having mean µ. Set

Y n :=

1
n

(Y1 + · · · + Yn)

(7)

to be the sample mean. Let ε ∈ (0, 1) be the desired ac-
curacy, and let 1 − δ be the desired success probability,
where δ ∈ (0, 1). Then

Pr(cid:2)(cid:12)

(cid:12)Y n − µ(cid:12)

(cid:12) ≤ ε(cid:3) ≥ 1 − δ,

as long as

(8)

(9)

II. THE PRINCIPLE: USING CYCLIC SHIFTS
FOR MULTIVARIATE TRACE ESTIMATION

where M := b − a.

n ≥

M 2
2ε2 ln

(cid:18) 2
δ

(cid:19)

,

The principle behind our circuit construction is simple.
To explain it, let us ﬁrst recall a well known circuit con-
struction [1] for multivariate trace estimation that has no
clear realization on near-term quantum computers. The
idea is to estimate the quantities Re[Tr[ρ1 · · · ρm]] and
Im[Tr[ρ1 · · · ρm]] separately.

The circuits to estimate both quantities are similar,
and we now describe them. To estimate the real part
Re[Tr[ρ1 · · · ρm]], we proceed according to the following
steps:

To see that Eq. (5) holds, note that in the special case
when all the states are pure, i.e., ρi = |ψi(cid:105)(cid:104)ψi|, the input
to the circuit is an m-partite pure-state |ψ(m)(cid:105) := |ψ1(cid:105) ⊗
· · · ⊗ |ψm(cid:105), and so

Pr(X = +1)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
1
4

=

=

((cid:104)+| ⊗ I)

(cid:16)

1
√
2

|0(cid:105)|ψ(m)(cid:105) + |1(cid:105)W π|ψ(m)(cid:105)

(cid:17)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
2

(cid:107)|ψ(m)(cid:105) + W π|ψ(m)(cid:105)(cid:107)2
2

(10)

(11)

(2 + (cid:104)ψ(m)|W π|ψ(m)(cid:105) + (cid:104)ψ(m)|(W π)†|ψ(m)(cid:105))

(12)

A. Preparing GHZ states in constant quantum
depth

3

=

=

=

1
4
1
2
1
2

(1 + Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]])

(1 + Re[Tr[ρ1 · · · ρm]])

(13)

(14)

where in the last equality we have used the well-known
identity in Eq. (2). Similarly, we have that

Pr(X = −1) =

1
2

(1 − Re[Tr[ρ1 · · · ρm]]),

(15)

so that

E[X] = (+1) Pr(X = +1) + (−1) Pr(X = −1)

= Re[Tr[ρ1 · · · ρm]].

(16)
(17)

Eq. (5), which asserts that the conclusion Eq. (14) still
holds when the ρi are mixed states, follows by convexity
(i.e., that every mixed state can be written as a convex
combination of pure states).

To estimate the second quantity Im[Tr[ρ1 · · · ρm]], a
simple variation of the above argument suﬃces. The
technique is identical, except that the ﬁnal measure-
:=
ment is in the basis {|+Y (cid:105), |−Y (cid:105)}, where |±Y (cid:105)
(|0(cid:105) ± |1(cid:105)) /

√

2.

III. OUR CIRCUIT CONSTRUCTION

We propose a variation of the above method, which in-
stead estimates Tr[ρ1 · · · ρm] in constant quantum depth.
This makes the circuit more amenable to run on near-
term quantum processors. This circuit is depicted for
m = 4 — it has some similarities with the method of
Shor error correction from fault-tolerant quantum com-
putation [20] (see also Figure 2 of [22]).

The crux of our method is to replace the |+(cid:105) =
(|0(cid:105) + |1(cid:105)) state at the single qubit control wire in

1√
2

the circuit in [1], with an (cid:98)m/2(cid:99)-party GHZ state

|Φ(cid:98)m/2(cid:99)

GHZ (cid:105) :=

1
√
2

(cid:16)

|0(cid:105)⊗(cid:98)m/2(cid:99) + |1(cid:105)⊗(cid:98)m/2(cid:99)(cid:17)

(18)

on (cid:98)m/2(cid:99) control wires. This modiﬁcation allows the
number of controls to the permutation to increase to
(cid:98)m/2(cid:99), which is half the input size.
In turn, it paves
the way for an implementation of multivariate trace esti-
mation in quantum depth two using parallelized cSWAP
gates.

In order to achieve an overall constant quantum depth,
in Section III A we show that constant quantum depth
suﬃces to generate the input GHZ state in (18). Then,
in Section III B, we show how to implement the permu-
tation W π, again in constant quantum depth. Finally,
in Section III C, we describe our full estimator and the
accompanying circuit.

We now describe two methods to generate the GHZ
state in constant quantum depth. The ﬁrst is related to
a method discussed previously in [23] and is a constant-
depth quantum circuit assisted by measurements, clas-
sical feedback, and a logarithmic depth classical circuit.
See also the discussion after [24, Theorem 1.1]. The sec-
ond is a variation of the ﬁrst, which additionally allows
for qubit resets to make more eﬃcient usage of qubits.

Method 1. We begin by discussing the ﬁrst approach,
which generates an r-party GHZ state using a constant-
depth quantum circuit assisted by measurements, clas-
sical feedback, and a logarithmic depth classical circuit.
We proceed according to the following steps:

1. Generate r − 1 Bell states; i.e., each pair is in the

state

|Φ+(cid:105) :=

1
√
2

(|00(cid:105) + |11(cid:105)) .

(19)

2. Perform controlled-NOT gates between the second
qubit in each Bell state and the ﬁrst qubit of the
following one.

That is, apply a controlled-NOT from qubit 2k to
qubit 2k + 1 for all k ∈ {1, . . . , r − 2}.

3. Measure the target of each controlled-NOT gate (all
odd-numbered qubits except the ﬁrst qubit) in the
computational basis.

4. Controlled

on

the measurement

outcome
b1, . . . , br−2, apply a tensor product of Pauli
X operators as a correction to all even-numbered
qubits except the second qubit.
That is, apply X b1⊕···⊕bk−1 to qubit 2k for k ∈
{2, . . . , r − 1}.

This procedure prepares an r-party GHZ state on qubits
1, 2, 4, 6, . . . , 2(r − 1).

We now show in detail that the scheme prepares an
r-party GHZ state. Consider that the initial state can be
written as

r−1
(cid:79)

i=1

|Φ+(cid:105)

=

√

=

√

1
2r−1

1
2r−1

r−1
(cid:79)

(cid:88)

i=1

xi∈{0,1}

|xi, xi(cid:105)

(20)

(cid:88)

|x1, x1(cid:105) ⊗

x1,...,xr∈{0,1}

r−1
(cid:79)

i=2

|xi, xi(cid:105).

(21)

After step 2, the state becomes

√

1
2r−1

(cid:88)

|x1, x1(cid:105) ⊗

x1,...,xr∈{0,1}

r−1
(cid:79)

i=2

|xi ⊕ xi−1, xi(cid:105).

(22)

After step 3, the (r − 2)-bit string b1 · · · br−2 is obtained
from the measurements, where

b1 = x2 ⊕ x1,
b2 = x3 ⊕ x2,

· · · ,

br−2 = xr−1 ⊕ xr−2,

(23)
(24)
(25)
(26)

and this projects the state onto the following state:

1
√
2

=

(cid:88)

|x1, x1(cid:105) ⊗ |b1, x2(cid:105) ⊗ |b2, x3(cid:105) · · · ⊗ |br−2, xr−1(cid:105)

x1∈{0,1}
1
(cid:88)
√
2

x1∈{0,1}

|x1, x1(cid:105) ⊗ |b1, b1 ⊕ x1(cid:105)⊗

|b2, b1 ⊕ b2 ⊕ x1(cid:105) · · · ⊗ |br−2, b1 ⊕ · · · ⊕ br−2 ⊕ x1(cid:105)

= (I ⊗ I ⊗ I ⊗ X b1 ⊗ I ⊗ X b1⊕b2 ⊗ · · ·
⊗ I ⊗ X b1⊕···⊕br−2)×





1
√
2

(cid:88)

x1∈{0,1}

|x1, x1(cid:105)|b1, x1(cid:105)|b2, x1(cid:105) · · · |br−2, x1(cid:105)



(27)



4

FIG. 1: A constant-depth quantum circuit for preparing an
eight-party GHZ state, assisted by measurement, classical
feedback, and qubit resets. Method 1 consists of all the steps
depicted, except for the qubit resets (but only prepares a ﬁve-
party state). In Method 2, the measured qubits are addition-
ally reset to the |0(cid:105) state and connected by CNOTs so that a
larger, eight-party state can be prepared instead.

(28)

Proposition 2 The following decomposition holds

The r-party GHZ state on qubits 1, 2, 4, 6, . . . , 2(r − 1)
is then recovered by performing the following correction
operation:

I ⊗ I ⊗ I ⊗ X b1 ⊗ I ⊗ X b1⊕b2 ⊗ · · · I ⊗ X b1⊕···⊕br−2 (29)

The leftmost part of Figure 1 (all except the qubit

resets) depicts this procedure.

Method 2. The second method is very similar to the
one just described. The only diﬀerence is that we addi-
tionally perform qubit resets on the measured qubits and
then controlled-NOTs from the nearest neighbor qubits
in the GHZ state to the reset qubits. This scheme is de-
picted in Figure 1. It prepares a GHZ state on a number
of parties equal to the number of input qubits (hence a
2(r −1)-party GHZ state, as opposed to the r-party GHZ
state without the qubit resets).

B. Multiply-controlled cyclic permutation in
constant quantum depth

Rather than implement a controlled-W π gate, we in-
stead implement a multiply-controlled-W π gate, in or-
der to reduce the depth of this part of the circuit from
linear to constant. Our implementation of the multiply-
controlled-W π gate in constant depth is based on the
observation that there is a particularly convenient way
to decompose a cyclic shift into a product of transposi-
tions, as shown in [25, Eqs. (4.2)–(4.3)]. We state this
observation here, along with a brief proof, for complete-
ness:

(1, . . . , m) =


m/2
(cid:89)




l=2
(cid:100)m/2(cid:101)
(cid:89)

l=2

(l, m + 2 − l)

m/2
(cid:89)

(k, m + 1 − k)

k=1

: m even

(l, m + 2 − l)

(cid:98)m/2(cid:99)
(cid:89)

k=1

(k, m + 1 − k) : m odd

(30)

where all arithmetic is modulo m.

So, for instance, when m = 8 (the case in Figure 2),
Eq. (30) would read

(1, . . . , 8) = (2, 8)(3, 7)(4, 6)

(1, 8)(2, 7)(3, 6)(4, 5) .

(31)
Proof. For m even, the ﬁrst transposition sends k to
m + 1 − k for every k ∈ [m]. If k = m, it gets sent to 1 by
the ﬁrst transposition and is not acted on by the second
transposition. Otherwise, the second transposition sends
m + 1 − k to m + 2 − (m + 1 − k) = k + 1, so the overall
eﬀect is to send k → k + 1 for all k ∈ [m], as desired.

For m odd, there are two indices that are involved in
only one transposition: k = m, which, as before, gets
sent to 1 by the ﬁrst transposition and is not acted on
by the second transposition; and k = (cid:100)m/2(cid:101), which is
transposed only in the second transposition where it gets
sent to m + 2 − (cid:100)m/2(cid:101) = (cid:100)m/2(cid:101) + 1. All other indices
are involved in the same two transpositions as described
above. Thus, the overall eﬀect is also k → k + 1 for all
k ∈ [m].

H

H

H

H

|0〉

|0〉

|0〉

|0〉

|0〉

|0〉

|0〉

|0〉

|0〉

|0〉

|0〉

b1

b2

b3

X b1

X b1 b2

X b1 b2 b3

5

1. Prepare an (cid:98)m/2(cid:99)-party GHZ state using one of
the constant quantum-depth circuit constructions
described in the previous section. Let us call the
(cid:98)m/2(cid:99) qubits of the GHZ state the control qubits
and the m states ρ1 ⊗ · · · ⊗ ρm the target qubits.

2. To implement the multiply-controlled cyclic shift,

• If m is even, adjoin ρ1, . . . , ρm to the GHZ

state, in the order

ρ1 ⊗ ρm ⊗ ρ2 ⊗ ρm−1 ⊗ ρ3 ⊗ · · · ⊗ ρm/2+2 ⊗ ρm/2 ⊗ ρm/2+1.
(32)
Perform a controlled-SWAP gate from the
ith control qubit to target qubits 2i − 1
and 2i, for all i ∈ {1, . . . , m/2}. Now per-
form a controlled-SWAP from the ith con-
trol qubit to target qubits 2i and 2i + 1 for
i ∈ {1, . . . , m/2 − 1}.

• If m is odd, adjoin ρ1, . . . , ρm to the GHZ

state, in the order

ρ1⊗ρm⊗ρ2⊗ρm−1⊗ρ3⊗· · ·⊗ρ(cid:100)m/2(cid:101)−1⊗ρ(cid:100)m/2(cid:101)+1⊗ρ(cid:100)m/2(cid:101).
(33)
Perform a controlled-SWAP gate from the
ith control qubit to target qubits 2i − 1 and
2i,
for all i ∈ {1, . . . , (cid:98)m/2(cid:99)}. Now per-
form a controlled-SWAP from the ith con-
trol qubit to target qubits 2i and 2i + 1 for
i ∈ {1, . . . , (cid:98)m/2(cid:99)}.

It can be checked that this prescription implements
precisely Eq. (30), with the states adjoined in a
speciﬁc order (see Eq. (32) or Eq. (33)) that allows
only nearest neighbors to be swapped.

3. Perform a Hadamard on all (cid:98)m/2(cid:99) control qubits
and measure them in the computational basis, re-
ceiving outcomes 0 or 1. This has the eﬀect of
performing a measurement in the X basis on each
control qubit. Let Xi ∈ {0, 1} denote the result of
the ith measurement, for i ∈ {1, · · · , (cid:98)m/2(cid:99)}. Set

R = (−1)

(cid:80)(cid:98)m/2(cid:99)

i=1 Xi.

4. Repeat Steps 1 to 3 a number of times equal to N :=
O(ε−2 log δ−1). Compute ˆR := 1
j=1 Rj, where
N
Rj is the output of Step 3 on the j-th application of
the circuit. ˆR is our estimate for Re[Tr[ρ1 · · · ρm]].

(cid:80)N

5. To estimate Im[Tr[ρ1 · · · ρm]], repeat Steps 1 to 4,
except that in Step 3, replace each Hadamard with
HS†, where S is the phase gate

S :=

(cid:21)
(cid:20)1 0
0 i

,

(34)

before the measurement in the computational basis.
This has the eﬀect of performing a measurement in
the Y basis on each control qubit. Let Y (j)
i ∈ {0, 1}
be the outcome of the measurement on the i-th

FIG. 2: The leftmost part of the circuit prepares a four-party
GHZ state. The middle part of the circuit performs a con-
trolled cyclic-shift. The ﬁnal part of the circuit results in
the classical bits x1, x2, x3, x4, which are used to generate
r = (−1)x1+x2+x3+x4 . As argued in Section V, the expecta-
tion of r is equal to Re[Tr[ρ1 · · · ρ8]], so that this latter quan-
tity can be estimated through repetition.

Eq. (30) says that, for a ﬁxed m, the m-wise cyclic
shift permutation can be decomposed into a product of
two terms. Each term is itself a product of disjoint trans-
positions and every index gets transposed once per term.
This has a clear interpretation in terms of how to
construct a quantum circuit to implement a multiply-
controlled-W π. Transposing two qubit labels can be
achieved by applying a SWAP gate to the relevant qubits.
Disjoint transpositions can thus be accomplished by im-
plementing SWAP gates in parallel,
in a single time
step. Proposition 2 thus implies that, for every m, the
multiply-controlled-W π can be implemented in two time
steps (depth two), each of which performs (cid:98)m/2(cid:99) con-
trolled SWAPs in parallel.

We give a more explicit description of the circuit in the
next subsection. Note that, as depicted in Figure 2, we
have made another optimization for near-term feasibility:
we adjoin the input states to the cyclic shift in a speciﬁc
order that ensures that only nearest-neighbor states need
to be swapped.

C. Explicit circuit description

We now put together the ﬁndings of the previous two
subsections and describe our proposed technique for esti-
mating Tr[ρ1 · · · ρm] in the case that each local dimension
d = 2 (i.e., each ρi is a single-qubit state). The corre-
sponding circuit is depicted in Figure 2. After that, we
discuss how to generalize the construction to the case in
which d is a power of two, so that each local system con-
sists of multiple qubits. The estimator works as follows:

H

H

H

H

x1

x2

x3

x4

H

H

H

|0〉

|0〉

|0〉

|0〉

|0〉

|0〉

b1

b2

X b1

X b1 b2
ρ1

ρ8

ρ2

ρ7

ρ3

ρ6

ρ4

ρ5

qubit on the j-th application of the circuit. Set
j=1 Jj. ˆJ
Jj = (−1)
is our estimate for Im[Tr[ρ1 · · · ρm]].

. Compute ˆJ = 1
N

(cid:80)(cid:98)m/2(cid:99)
i=1

(cid:80)N

Y (j)
i

6. Output ˆT = ˆR + i ˆJ.

Our proposed architecture is highly ﬂexible and can
be tailored to the availability of resources such as long
coherence times and multi-qubit gates. This is evident
in two ways:

Firstly, we can smoothly trade oﬀ circuit width for the
availability of entangling gates. At one extreme, observe
that we could have implemented our circuit with only one
control qubit (instead of (cid:98)m/2(cid:99)) if we had at our disposal
a highly-entangling gate: a single-qubit controlled simul-
taneous SWAP gate that swapped (cid:98)m/2(cid:99) pairs of qubits
simultaneously. Such a gate would not be feasible in the
near term, as it requires highly nonlocal interactions to
implement in a real physical architecture. However, even
gates that entangle only a subset of qubits aﬀord us sav-
ings in circuit width: every additional controlled k-wise
SWAP gate at our disposal allows for a reduction of cir-
cuit width by k, as k fewer control qubits are necessary
(hence the GHZ state needs to be on k fewer parties).

to

Secondly,

generalize

of
the
Tr[ρ1ρ2 · · · ρm] beyond single-qubit
can
either increase the width or the depth of the circuit
described above. Suppose that ρ1, . . . , ρm each consist
of p qubits.

estimation
states, we

• We can increase the width of the circuit by prepar-
ing GHZ states with mp qubits and then group
these into p groups of m qubits each. Correspond-
ingly, group the 2m states ρ1, . . . , ρ2m into p groups
of 2m qubits, where the kth group has the kth qubit
of each state, for k ∈ {1, . . . , p}. Then we per-
form controlled SWAPs as detailed above, for each
group. Finally, perform Hadamards on all of the
mp control qubits and measure each of them in the
computational basis.

• To increase the depth of the circuit, prepare an m-
party GHZ state, and then sequentially perform the
controlled-SWAP tests for the p groups of qubits,
so that the depth of the circuit increases by a factor
of p. Then measure the control qubits as before.

IV.

IMPLEMENTATION OF MULTIVARIATE

TRACE ESTIMATION ON A
TWO-DIMENSIONAL ARCHITECTURE

6

GHZ state preparation, as depicted in Figure 1. Explana-
tions of the steps are given in the caption of Figure 3. The
main point to highlight here is that our circuit leads to a
highly parallelized implementation on a two-dimensional
architecture that should make it more amenable to real-
ization on near-term quantum computers.

V. GUARANTEES OF OUR ESTIMATOR

In this section, we show that the estimator ˆT described
in Section III C is accurate and precise with high proba-
bility.

Theorem 3 Let {ρ1, . . . , ρm} be single-qubit
states.
There exists a random variable ˆT that can be computed
with O( 1
δ )) repetitions of a constant-depth quan-
tum circuit consisting of O(m) three-qubit gates, and sat-
isﬁes

ε2 log( 1

Pr(| ˆT − Tr[ρ1 · · · ρm]| ≤ ε) ≥ 1 − δ .

(35)

Proof. By the Hoeﬀding inequality (see Lemma 1), it
suﬃces to prove that the estimator ˆT output by the
method of Section III C satisﬁes

E[ ˆT ] = Tr[W π(ρ1 ⊗ · · · ⊗ ρm)] = Tr[ρ1 · · · ρm] .

(36)

It suﬃces to prove the ﬁrst equality. To begin with, let
us suppose for simplicity that all the states are pure, i.e.
ρi = |ψi(cid:105)(cid:104)ψi|, and deﬁne the state of the target qubits as

|ψ(m)(cid:105) := |ψ1(cid:105) ⊗ · · · ⊗ |ψm(cid:105).

(37)

Step 1 of our procedure prepares a GHZ state |Φ(cid:98)m/2(cid:99)
GHZ (cid:105)
and adjoins it to |ψ(m)(cid:105), such that the overall state at
the end of Step 1 is

|Φ(cid:98)m/2(cid:99)

GHZ (cid:105)|ψ(m)(cid:105).

(38)

After Step 2 (the multiply-controlled cyclic shift), the
overall state becomes

|0(cid:105)⊗(cid:98)m/2(cid:99)|ψ(m)(cid:105) + |1(cid:105)⊗(cid:98)m/2(cid:99)W π|ψ(m)(cid:105)

(cid:17)

.

(39)

(cid:16)

1
√
2

In Step 3, one measures the (cid:98)m/2(cid:99) control qubits in the
X basis, obtaining an (cid:98)m/2(cid:99)-bitstring where the i-th bit
is denoted by the random variable Xi ∈ {0, 1}. We then
compute the expectation of the random variable ˆR which
will be output as the real part of our estimator

We now outline how to implement our algorithm using
a two-dimensional architecture similar to Google’s [26].
We do so by means of a series of ﬁgures, which outline the
time steps of the circuit implementation. See Figure 3.
These ﬁgures can be understood as a two-dimensional
implementation of the circuit depicted in Figure 2, with
the exception that we also include qubit resets during the

ˆR ≡ ˆR(X1, . . . , X(cid:98)m/2(cid:99)) := (−1)

(cid:80)(cid:98)m/2(cid:99)

i=1 Xi.

(40)

Introducing the following notation for X basis eigenvec-
tors

|˜x(cid:105) :=

1
√
2

|0(cid:105) + (−1)x|1(cid:105)

for x ∈ {0, 1},

(41)

7

In
FIG. 3: (1) The squares in light grey represent control qubits, and the squares in dark grey represent data qubits.
this example, there are ﬁve data states involved, each consisting of four qubits.
(2) The quantum data is loaded during
this stage, which we note here can be conducted in parallel with the preparation of the GHZ state in the control qubits.
The state ρi, for i ∈ {1, . . . , 5}, is a four-qubit state that occupies the indicated column of the data qubits in dark grey.
The light grey control qubits are prepared in the all zeros state. (3) First step of the preparation of the GHZ state of the
control qubits. Every other control qubit has a Hadamard gate applied in parallel.
(4) Every pair of control qubits has
CNOT gates applied in parallel. (5) Every other pair of control qubits has CNOT gates applied in parallel. (6) Starting
from the third control qubit from the top left, every other control qubit is measured, and the measurement outcome is
stored in a binary vector b1, . . . , b7. (7) Based on the measurement outcomes from the previous step, Pauli-X corrections are
applied to every other qubit, starting from the fourth in the top row. The particular corrections needed are abbreviated by
a multivariate function f , the details of which are available in Eq. (29). (8) The measured qubits are reset to the all zeros
state. (9) Final step of the preparation of the GHZ state of the control qubits. CNOT gates are again applied to every other
control qubit. The ﬁnal state of all control qubits is equal to a GHZ state. (10) Controlled-SWAPs are applied in parallel
between control qubits and data qubits, in a ﬁrst round of the implementation of the cyclic shift. (11) Controlled-SWAPs
are applied in parallel between other control qubits and data qubits, in a second round of the implementation of the cyclic
shift.
(13) In a ﬁnal step, all control qubits are measured in the
computational basis and the measurement outcomes are processed according to Eq. (40) to form an estimate of the real part of
Tr[ρ1 · · · ρ5]. To estimate the imaginary part, replace H in step (12) with HS†. A GIF of the entire procedure may be viewed
at https://twitter.com/quekpottheories/status/1542545522392809477?s=20&t=rb1PDn27W3pVaAKHWDDS1Q

(12) Hadamard gates are applied to all control qubits.

(1)

(2)

Load Data

ρ1

ρ5

ρ2

ρ4

ρ3

(3)

GHZ Preparation

H

H

H

H

H

H

H

H

(4)

GHZ Preparation

(5)

GHZ Preparation

(6)

GHZ Preparation

(7)

GHZ Preparation

Xf

Xf

Xf

Xf

Xf

Xf

Xf

(8)

GHZ Preparation

|0〉

|0〉

|0〉

|0〉

|0〉

|0〉

|0〉

(9)

GHZ Preparation

(10)

(11)

(12)

H

H

H

H

H

H

H

H

H

H

H

H

H

H

H

H

(13)

the probability of the X basis measurement outputting
the bitstring x1 · · · x(cid:98)m/2(cid:99) ∈ {0, 1}(cid:98)m/2(cid:99) is given by

Pr(x1 · · · x(cid:98)m/2(cid:99))

(cid:88)

=

x1,··· ,xm

= 1,

1 + (−1)

i=1 xi Re[Tr[W πρ(m)]]

(cid:80)m

2m

8

(54)

(55)

=

=

=

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2
(42)

(43)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1√
2

(cid:0)(cid:104)(cid:102)x1, (cid:102)x2, · · · , (cid:94)x(cid:98)m/2(cid:99)| ⊗ I(cid:1) ×
(cid:0)|0(cid:105)⊗(cid:98)m/2(cid:99)|ψ(m)(cid:105) + |1(cid:105)⊗(cid:98)m/2(cid:99)W π|ψ(m)(cid:105)(cid:1)

1
2(cid:98)m/2(cid:99)+1
1 + (−1)

(cid:13)
(cid:13)|ψ(m)(cid:105) + (−1)
(cid:13)

(cid:80)(cid:98)m/2(cid:99)
i=1

(cid:13)
2
xiW π|ψ(m)(cid:105)
(cid:13)
(cid:13)
2

(cid:80)(cid:98)m/2(cid:99)
i=1

xi Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]]

2(cid:98)m/2(cid:99)

.

(44)

Thus,
E[ ˆR]

=

=

(cid:88)

x1,...,x(cid:98)m/2(cid:99)

Pr(x1, · · · , x(cid:98)m/2(cid:99))r(x1, · · · , x(cid:98)m/2(cid:99)) (45)

(cid:32)

1 + (−1)

(cid:80)(cid:98)m/2(cid:99)
i=1

xi Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]]

(cid:33)

2(cid:98)m/2(cid:99)

(cid:88)

x1,...,
x(cid:98)m/2(cid:99)

× (−1)

(cid:80)(cid:98)m/2(cid:99)
i=1

xi

(46)

=

1
2(cid:98)m/2(cid:99)

(cid:88)

(cid:16)

(cid:80)(cid:98)m/2(cid:99)
i=1

(−1)

xi +

x1,...,x(cid:98)m/2(cid:99)

= Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]],

Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]]

(cid:17)

(47)

(48)

where, in the second-to-last equality, we have used the
fact that

(cid:88)

x1,...,xl∈{0,1}l

(cid:80)l

(−1)

i=1 xi = 0 for all l.

(49)

The claim for mixed states ρ(m) := ρ1 ⊗ · · · ⊗ ρm, i.e.,
E[ ˆR] = Re[Tr[W πρ(m)]],

(50)

follows by convexity (i.e., that every mixed state can be
written as a convex combination of pure states). That is,
we use the fact that

1 + (−1)

i=1 xi Re[Tr[W πρ(m)]]

(cid:80)m

Pr(x1, . . . , xm) =

2m

(51)
for this case and then repeat the calculation above for
every eigenvector of ρ(m).

Using a similar chain of logic, we conclude that

E[ ˆJ] = Im[Tr[W πρ(m)]] ,

(52)

and the ﬁrst equality of (36) follows.

We also compute the variance of ˆT . Consider that

Var[ ˆR] := E[( ˆR − E[ ˆR])2] = E[ ˆR2] − E[ ˆR]2. Since

E[ ˆR2] =

(cid:88)

x1,··· ,xm

Pr(x1, · · · , xm) (r(x1, · · · , xm))2

(53)

we conclude that Var[ ˆR] = 1 − (Re[Tr[W πρ(m)]])2. Sim-
ilarly, Var[ ˆJ] = 1 − (Im[Tr[W πρ(m)]])2. Since these two
random variables are independent,

Var[ ˆT ] = 2 −

(cid:12)
(cid:12)
(cid:12)Tr[W πρ(m)]
(cid:12)
(cid:12)
(cid:12)

2

.

(56)

We now discuss the generalization of Theorem 3 to
states of more than one qubit. This generalization can
be accomplished by increasing the circuit width or the
circuit depth as discussed in Section III C.

Proposition 4 Let {ρ1, . . . , ρm} be a set of p-qubit
states, and ﬁx ε > 0 and δ ∈ (0, 1). There exists a ran-
dom variable ˆTp that can be computed using O( 1
δ ))
repetitions of a constant-depth quantum circuit consisting
of O(mp) three-qubit gates, and satisﬁes

ε2 log( 1

Pr(| ˆTp − Tr[ρ1 · · · ρm]| ≤ ε) ≥ 1 − δ .

(57)

Proof. The gate count for the circuits for both con-
structions detailed in Section III C is O(mp). For the
second construction (increasing the depth), Eq. (57) fol-
lows from the exact same calculation as in the proof of
Theorem 3. For the ﬁrst construction (increasing the
width), let us deﬁne ρ(m,p) := ρ1 ⊗ · · · ⊗ ρm. It suﬃces to
prove that for the estimator ˆRp := (−1)X1+···+Xmp de-
rived from the mp measurement outcomes X1, · · · , Xmp
fulﬁls E[ ˆRp] = Re[Tr[W πρ(m,p)]]. This follows from a
similar calculation to Eqs. (42)–(50).

Similarly,

Var[ ˆTp] = 2 −

(cid:12)
(cid:12)
(cid:12)Tr[W πρ(m,p)]
(cid:12)
(cid:12)
(cid:12)

2

.

(58)

VI. APPLICATIONS OF OUR METHOD

An application of our method is to estimate functions
of density matrices that can be approximated by ‘well-
behaved’ polynomials. This was already suggested in the
original work of [1], but no complexity analysis was put
forth. Here we formalize the analysis of the application
in the following theorem:

Theorem 5 Let ρ be a quantum state with rank at most
d. Suppose there exist constants η, ε and a function C
such that g : R → R is approximated by a degree-m poly-
nomial f (x) = (cid:80)m
k=0 ckxk on the interval [η, 1], in the
sense that

sup
x∈[η,1]

|g(x) − f (x)| <

ε
2d

,

(59)

and

3. Let

m
(cid:88)

k=0

|ck| < C .

(60)

N =

8C 2
ε2 ln

(cid:18) 2
δ

(cid:19)

.

9

(66)

Then estimating Tr[g(ρ)] within ε additive error with
success probability not smaller than 1 − δ requires
δ )) copies of ρ and O(m C2
O(m2 C2
δ )) runs of
a circuit with O(m) controlled SWAP gates.

ε2 log( 1

ε2 log( 1

(Here, we should think of C as a slowly-growing function
of m.) An example of a function of a quantum state that
can be estimated in this way is g(x) = (1 + x)α for α > 0,
which has the following expansion as a binomial series

(1 + x)α =

∞
(cid:88)

k=0

(cid:19)

(cid:18)α
k

xk,

(61)

k

where (cid:0)α
(cid:1) is the generalized binomial coeﬃcient.
It is
well known that the binomial series converges absolutely
for x = 1 and α > 0, which implies that, for every α > 0,
there exists a positive constant C(α) such that

m
(cid:88)

k=0

(cid:12)
(cid:18)α
(cid:12)
(cid:12)
k
(cid:12)

(cid:19)(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

∞
(cid:88)

k=0

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:18)α
k

(cid:19)(cid:12)
(cid:12)
(cid:12)
(cid:12)

= C(α).

(62)

Thus, this series satisﬁes the criterion in Eq. (60). An-
other function of a quantum state that can be estimated
in this way is f (x) = ln(x + 1). Indeed, this function has
the following well known expansion:

ln(x + 1) =

∞
(cid:88)

k=1

(−1)k
k

xk,

(63)

Repeat the ﬁrst two steps N − 1 more times, on the
i-th iteration outputting the random variable R(i).

4. Output ˆg = 1
N
Re[Tr[g(ρ)]].

(cid:80)N

i=1 R(i) as the estimator for

Let us now prove the correctness of this procedure.

Suppose the spectral decomposition of ρ is as follows:

ρ =

rρ
(cid:88)

i=1

λi|ψi(cid:105)(cid:104)ψi| ,

(67)

where rρ is the rank of ρ. In the limit of N → ∞, the
only error in the estimator ˆg would come from the error
in the polynomial approximation. That is,

| Tr[g(ρ)] −

m
(cid:88)

k=0

ck Tr[ρk]| =

rρ
(cid:88)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
i=1
≤ ε/2

(cid:32)

g(λi) −

m
(cid:88)

k=0

ckλk
i

(cid:33)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(68)

where the inequality follows from Eq. (59) and the fact
that d > rρ. Now we account for the other source of
error, which is the statistical error caused by taking a
ﬁnite number of samples. Consider that

|R(i)| ≤

m
(cid:88)

k=0

|ck||Rk| ≤

m
(cid:88)

k=0

|ck| ≤ C,

(69)

(cid:12)
(cid:12)
(cid:12)

k=1

(−1)k
k

so that the absolute partial sum of the coeﬃcients sat-
(cid:12)
isﬁes (cid:80)m
(cid:12)
(cid:12) ≈ ln m + γ, where γ ≈ 0.577 is the
Euler–Mascheroni constant. The point here is that, even
though the absolute partial sums are not bounded by a
constant, they still grow suﬃciently slowly such that the
algorithm runs eﬃciently.

Proof of Theorem 5. We will present an estimator for
the desired quantity that satisﬁes the claimed complexity
guarantees. Let us describe the estimator for Re[Tr[g(ρ)]]
(the estimator for the imaginary part follows immedi-
ately). To estimate Re[Tr[g(ρ)]], we run the following
procedure:

1. For each k ∈ [m], run the circuit described in
Steps 1-3 of Section III C once to output a random
variable Rk ∈ {−1, 1} such that

E[Rk] = Re[Tr[ρk]] .

(64)

for all i ∈ {1, . . . , N }, where the ﬁrst inequality follows
from the triangle inequality, the second from the fact
that Rk ∈ {−1, 1}, and the third from the assumption
in (60). By applying (69), the Hoeﬀding inequality in
Lemma 1 immediately applies to our setting when we
take Yi ← R(i) and [a, b] ← [−C, C]. We also see that
µ ← E[R(1)] = (cid:80)m

k=0 ck Tr[ρk]. Then if we set N to
(cid:19)
(cid:18) 2
δ

8C 2
ε2 ln

N =

(70)

we get that

Pr

(cid:34)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ˆg −

m
(cid:88)

k=0

(cid:12)
(cid:12)
ck Tr[ρk]
(cid:12)
(cid:12)
(cid:12)

(cid:35)

≤ ε/2

≥ 1 − δ.

(71)

Combining the two sources of error in Eqs. (68) and (71),
we get that with probability 1 − δ,

2. Linearly combine the above random variables to

|ˆg − Re[Tr[g(ρ)]]| ≤

form the new random variable

R(1) =

m
(cid:88)

k=0

ckRk .

(65)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

ˆg −

m
(cid:88)

k=0

ck Tr[ρk]

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

Re[Tr[g(ρ)]] −

m
(cid:88)

k=0

(cid:12)
(cid:12)
ck Tr[ρk]
(cid:12)
(cid:12)
(cid:12)

≤ ε.

(72)

Repeating the analysis for the estimation of Im[Tr[g(ρ)]]
yields the stated complexity.

ak Tr[(σ1/2ρσ1/2)k] =

(cid:88)

k

ak Tr[(ρσ)k],

(79)

(cid:88)

k

10

We remark that, an alternative way to estimate Tr[ρk]
for each k ∈ [m] is by using the method of classical
shadows to obtain ‘classical snapshots’ of ρ that can be
linearly combined to obtain a classical random variable
whose expectation is Tr[ρk] (see Supplementary Material
Section 6 of [27]). However, it is unclear to us if this
method would oﬀer savings in the quantum resources re-
quired, as the total number of times the quantum circuit
needs to be run in the data acquisition phase should scale
with the variance of the corresponding estimator. We do
not know of a concise expression for this variance for ar-
bitrary m. Indeed, calculating it for just a single value
of m (m = 2) required four pages of calculations in [27].
One might also wonder whether we could use this ap-
proach to estimate R´enyi or von Neumann entropies of
quantum states. The main diﬃculty in doing so is that
well known polynomial approximations of the functions
xα and −x ln x, given respectively by

xα =

=

∞
(cid:88)

k=0

∞
(cid:88)

k=0

−x ln x = x

= x

∞
(cid:88)

k=1

∞
(cid:88)

k=1

(cid:19)

(cid:18)α
k

(x − 1)k

(73)

(cid:19)

(−1)k−(cid:96)x(cid:96),

(74)

(cid:19) k

(cid:88)

(cid:18)α
k

(cid:18)k
(cid:96)

(cid:96)=0
(1 − x)k
k

(75)

(76)

1
k

k
(cid:88)

(cid:96)=0

(cid:19)

(cid:18)k
(cid:96)

(−1)(cid:96)x(cid:96)

=

∞
(cid:88)

k=1

1
k

k
(cid:88)

(cid:96)=0

(cid:19)

(cid:18)k
(cid:96)

(−1)(cid:96)x(cid:96)+1,

(77)

do not satisfy the condition in (60), in the sense that the
absolute partial sums grow too quickly and therefore do
not lead to an eﬃcient algorithm using this approach. See
also [28] in this context. It thus remains open whether
this approach can be used eﬀectively for estimating these
important uncertainty measures. See [29–32] for work on
this topic in the ﬁeld of classical information theory and
[33–37] for a ﬂurry of recent eﬀorts on estimating R´enyi
and von Neumann entropies using quantum computers,
which propose alternative approaches.

We note here that the method outlined above can be
generalized to functions of multiple density matrices. For
example, let ρ and σ be quantum states, and suppose
that g1 and g2 are well behaved polynomials in the sense
described in Theorem 5. Then we can employ a similar
approach to estimate the functions Tr[g1(ρ)g2(σ)] and
Tr[g1(σ1/2ρσ1/2)]. Polynomial approximations of these
functions take the following form:

(cid:34)(cid:32)

Tr

(cid:88)

ckρk

(cid:33) (cid:32)

(cid:88)

d(cid:96)σ(cid:96)

(cid:33)(cid:35)

k

(cid:96)

(cid:88)

=

k,(cid:96)

ckd(cid:96) Tr[ρkσ(cid:96)], (78)

respectively, and can be estimated using our circuits com-
bined with classical postprocessing. Thus, by the dis-
cussion after Theorem 5, we can take g1(x) = (1 + x)α
and g2(x) = (1 + x)β for α, β > 0. A case of interest
is when we set α ∈ (0, 1) and β = 1 − α. The resulting
function Tr[g1(ρ)g2(σ)] then satisﬁes faithfulness and the
data-processing inequality under unital quantum chan-
nels and thus can serve as an alternative to the widely
used Hilbert–Schmidt distance measure (which also sat-
isﬁes the data-processing inequality under unital chan-
nels [38]). We prove these claims in Appendix A.

VII. CONCLUSION

We have provided a quantum circuit for multivariate
trace estimation that requires only constant quantum
depth, and hence it is more amenable to be implemented
on near-term quantum computers than previous meth-
ods that required linear depth. Our architecture is also
ﬂexible and can be smoothly tailored to the availability
of circuit width (at the cost of more-entangling gates).

Going forward from here, one can further consider the
application of our method to estimating nonlinear func-
tions of quantum states. “The most important applica-
tion of computers has been designing better computers”
[39], and these methods can be used for this purpose. Our
method to estimate functions of quantum states based on
their polynomial approximations opens the door to the
idea that near-term quantum computers can be used to
design better quantum computers. An important open
question in this regard is whether any functions whose
polynomial approximations fulﬁll Eq. (60) have an in-
terpretation as quality metrics for quantum computer
design. Conversely, it would also be interesting to ex-
plore further whether there are any quantum state distin-
guishability measures – critical in applications like quan-
tum compiling [40, 41] and state learning [42, 43] – that
fulﬁll this condition.

Acknowledgments

We acknowledge helpful discussions with Jayadev
Acharya, Patrick Coles, Andr´as Gily´en, Zo¨e Holmes,
Dhrumil Patel, Eliott Rosenberg, Aliza Siddiqui, and An-
tonio Anna Mele. EK and MMW acknowledge support
from the National Science Foundation (NSF) under grant
no. 1714215. YQ acknowledges support from a Stanford
QFARM fellowship, an NUS Overseas Graduate Scholar-
ship and an Alexander von Humboldt Fellowship.

[1] Artur K. Ekert, Carolina Moura Alves, Daniel K. L. Oi,
Micha(cid:32)l Horodecki, Pawe(cid:32)l Horodecki, and L. C. Kwek.
Direct estimations of linear and nonlinear functionals of
a quantum state. Physical Review Letters, 88(21):217901,
May 2002. arXiv:quant-ph/0203016.

[2] Todd A. Brun. Measuring polynomial functions of states.
Quantum Information and Computation, 4(5):401–408,
September 2004. arXiv:quant-ph/0401067.

[3] Harry Buhrman, Richard Cleve, John Watrous, and
Phys-
Ronald de Wolf.
ical Review Letters, 87(16):167902, September 2001.
arXiv:quant-ph/0102001.

Quantum ﬁngerprinting.

[4] Sonika Johri, Damian S. Steiger, and Matthias Troyer.
Entanglement spectroscopy on a quantum computer.
Physical Review B, 96(19):195136, November 2017.
arXiv:1707.07658.

[5] Pawe(cid:32)l Horodecki and Artur Ekert. Method for di-
rect detection of quantum entanglement. Physical Re-
view Letters, 89(12):127902, August 2002. arXiv:quant-
ph/0111064.

[6] Daniel Gottesman and Isaac Chuang. Quantum digital

signatures. May 2001. arXiv:quant-ph/0105032.

[7] Aram W. Harrow, Avinatan Hassidim, and Seth Lloyd.
Quantum algorithm for linear systems of equations.
Physical Review Letters, 103(15):150502, October 2009.
arXiv:0811.3171.

[8] Andr´as Gily´en, Yuan Su, Guang Hao Low, and Nathan
Wiebe. Quantum singular value transformation and
improvements for quantum ma-
beyond:
trix arithmetics.
In Proceedings of the 51st Sympo-
sium on the Theory of Computing, pages 193–204, 2019.
arXiv:1806.01838.

exponential

[9] Andr´as Gily´en, Seth Lloyd,

Iman Marvian, Yihui
Quek, and Mark M. Wilde. Quantum algorithm for
Petz recovery channels and pretty good measurements.
Physical Review Letters, 128(22):220502, June 2022.
arXiv:2006.16924.

[10] Frank Pollmann, Ari M. Turner, Erez Berg, and Masaki
Oshikawa. Entanglement spectrum of a topological phase
in one dimension. Physical Review B, 81(6):064439,
February 2010. arXiv:0910.1811.
[11] Hong Yao and Xiao-Liang Qi.

Entanglement en-
tropy and entanglement spectrum of the Kitaev model.
Physical Review Letters, 105(8):080501, August 2010.
arXiv:1001.1165.

[12] Lukasz Fidkowski. Entanglement spectrum of topological
insulators and superconductors. Physical Review Letters,
104(13):130502, April 2010. arXiv:1001.1165.

[13] Hui Li and F. D. M. Haldane. Entanglement spectrum as
a generalization of entanglement entropy: Identiﬁcation
of topological order in non-Abelian fractional quantum
Hall eﬀect states. Physical Review Letters, 101(1):010504,
July 2008. arXiv:0805.0332.

[14] Claudio Chamon, Alioscia Hamma, and Eduardo R.
irreversibility and entangle-
Physical Review Letters,

Mucciolo.
ment spectrum statistics.
112(24):240501, June 2014. arXiv:1310.2702.

Emergent

[15] G. De Chiara, L. Lepori, M. Lewenstein, and A. Sanpera.
Entanglement spectrum, critical exponents, and order
parameters in quantum spin chains. Physical Review Let-
ters, 109(23):237208, December 2012. arXiv:1104.1331.

11

[16] Jens Eisert, Marcus Cramer, and Martin B. Plenio. Col-
loquium: Area laws for the entanglement entropy. Re-
views of Modern Physics, 82(1):277–306, February 2010.
arXiv:0808.3773.

[17] M. Mezard, G. Parisi, and M. Virasoro. Spin Glass The-

ory and Beyond. World Scientiﬁc, 1986.

[18] Justin Yirka and Yi˘git Suba¸sı. Qubit-eﬃcient entangle-
ment spectroscopy using qubit resets. Quantum, 5:535,
September 2021. arXiv:2010.03080.

[19] Yi˘git Suba¸sı, Lukasz Cincio, and Patrick J. Coles. En-
tanglement spectroscopy with a depth-two quantum cir-
cuit. Journal of Physics A: Mathematical and Theoreti-
cal, 52(4):044001, January 2019. arXiv:1806.08863.
[20] Peter W. Shor. Fault-tolerant quantum computation. In
Proceedings of the 37th Annual Symposium on Founda-
tions of Computer Science, FOCS ’96, page 56, USA,
1996. IEEE Computer Society. arXiv:quant-ph/9605011.
[21] Wassily Hoeﬀding. Probability inequalities for sums of
bounded random variables. Journal of the American Sta-
tistical Association, 58(301):13–30, March 1963.

[22] Daniel Gottesman. An introduction to quantum er-
ror correction and fault-tolerant quantum computation.
Quantum Information Science and Its Contributions to
Mathematics, Proceedings of Symposia in Applied Math-
ematics, 68:13–58, 2010. arXiv:0904.2557.

[23] Adam Bene Watts, Robin Kothari, Luke Schaeﬀer, and
Avishay Tal. Exponential separation between shallow
quantum circuits and unbounded fan-in shallow classi-
In Proceedings of the 51st Annual ACM
cal circuits.
SIGACT Symposium on Theory of Computing, STOC
2019, pages 515–526, New York, NY, USA, 2019. As-
sociation for Computing Machinery. arXiv:1906.08890.

[24] Zhenning Liu and Alexandru Gheorghiu. Depth-eﬃcient
proofs of quantumness. July 2021. arXiv:2107.02163.
[25] Markus Grassl and Thomas Beth. Cyclic quantum error-
correcting codes and quantum shift registers. Proceedings
of the Royal Society of London. Series A: Mathematical,
Physical and Engineering Sciences, 456(2003):2689–2706,
November 2000. arXiv:quant-ph/9910061.

[26] Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon,
Joseph C. Bardin, Rami Barends, Rupak Biswas, Sergio
Boixo, Fernando G. S. L. Brandao, David A. Buell, Brian
Burkett, Yu Chen, Zijun Chen, Ben Chiaro, Roberto
Collins, William Courtney, Andrew Dunsworth, Ed-
ward Farhi, Brooks Foxen, Austin Fowler, Craig Gidney,
Marissa Giustina, Rob Graﬀ, Keith Guerin, Steve Habeg-
ger, Matthew P. Harrigan, Michael J. Hartmann, Alan
Ho, Markus Hoﬀmann, Trent Huang, Travis S. Humble,
Sergei V. Isakov, Evan Jeﬀrey, Zhang Jiang, Dvir Kafri,
Kostyantyn Kechedzhi, Julian Kelly, Paul V. Klimov,
Sergey Knysh, Alexander Korotkov, Fedor Kostritsa,
David Landhuis, Mike Lindmark, Erik Lucero, Dmitry
Lyakh, Salvatore Mandr`a, Jarrod R. McClean, Matthew
McEwen, Anthony Megrant, Xiao Mi, Kristel Michielsen,
Masoud Mohseni, Josh Mutus, Ofer Naaman, Matthew
Neeley, Charles Neill, Murphy Yuezhen Niu, Eric Os-
tby, Andre Petukhov, John C. Platt, Chris Quintana,
Eleanor G. Rieﬀel, Pedram Roushan, Nicholas C. Ru-
bin, Daniel Sank, Kevin J. Satzinger, Vadim Smelyan-
skiy, Kevin J. Sung, Matthew D. Trevithick, Amit
Vainsencher, Benjamin Villalonga, Theodore White,

Z. Jamie Yao, Ping Yeh, Adam Zalcman, Hartmut
Neven, and John M. Martinis. Quantum supremacy us-
ing a programmable superconducting processor. Nature,
574(7779):505–510, October 2019. arXiv:1910.11333.
[27] Hsin-Yuan Huang, Richard Kueng, and John Preskill.
Predicting many properties of a quantum system from
very few measurements. Nature Physics, 16(10):1050–
1057, June 2020. arXiv:2002.08953.

[28] fedja. Answer to stack exchange post. https://tinyurl.

com/3b9v7pum, July 2021.

[29] Jiantao Jiao, Kartik Venkat, Yanjun Han, and Tsachy
Weissman. Minimax estimation of functionals of discrete
distributions. IEEE Transactions on Information The-
ory, 61(5):2835–2885, May 2015. arXiv:1406.6956.
[30] Yihong Wu and Pengkun Yang. Minimax rates of en-
tropy estimation on large alphabets via best polynomial
approximation. IEEE Transactions on Information The-
ory, 62(6):3702–3720, June 2016. arXiv:1407.0381.
[31] Jiantao Jiao, Kartik Venkat, Yanjun Han, and Tsachy
Weissman. Maximum likelihood estimation of function-
als of discrete distributions. IEEE Transactions on In-
formation Theory, 63(10):6774–6798, 2017.

[32] Jayadev Acharya, Alon Orlitsky, Ananda Theertha
Suresh, and Himanshu Tyagi. Estimating renyi en-
tropy of discrete distributions.
IEEE Transactions
on Information Theory, 63(1):38–56, January 2017.
arXiv:1408.1000.

[33] Jayadev Acharya,

Ibrahim Issa, Nirmal V. Shende,
and Aaron B. Wagner. Estimating quantum entropy.
IEEE Journal on Selected Areas in Information Theory,
1(2):454–468, August 2020. arXiv:1711.00814.

[34] Andr´as Gily´en and Tongyang Li. Distributional Prop-
erty Testing in a Quantum World.
In Thomas Vidick,
editor, 11th Innovations in Theoretical Computer Sci-
ence Conference (ITCS 2020), volume 151 of Leibniz In-
ternational Proceedings in Informatics (LIPIcs), pages
25:1–25:19, Dagstuhl, Germany, 2020. Schloss Dagstuhl–
Leibniz-Zentrum fuer Informatik. arXiv:1902.00814.

[35] Alessandro Luongo and Changpeng Shao.

Quan-
tum algorithms for spectral sums. November 2020.
arXiv:2011.06475.

[36] Sathyawageeswar Subramanian and Min-Hsiu Hsieh.
Quantum algorithm for estimating α-renyi entropies of
quantum states. Physical Review A, 104(2):022428, Au-
gust 2021. arXiv:1908.05251.

[37] Youle Wang, Benchi Zhao, and Xin Wang. Quantum al-
gorithms for estimating quantum entropies. March 2022.
arXiv:2203.02386.

[38] David P´erez-Garc´ıa, Michael M. Wolf, Denes Petz, and
Mary Beth Ruskai. Contractivity of positive and trace-
preserving maps under lp norms. Journal of Mathemat-
ical Physics, 47(8):083506, August 2006. arXiv:math-
ph/0601063.

[39] Umesh Vazirani. Computational probes of Hilbert space.
Talk available at https://www.youtube.com/watch?v=
ajKoO5RFtwo, December 2019. Quote from Q2B 2019,
attributed to an unknown person.

[40] Sumeet Khatri, Ryan LaRose, Alexander Poremba,
Lukasz Cincio, Andrew T. Sornborger, and Patrick J.
Coles. Quantum-assisted quantum compiling. Quantum,
3:140, May 2019. arXiv:1807.00800.

[41] Kunal Sharma, Sumeet Khatri, Marco Cerezo, and
Patrick J. Coles. Noise resilience of variational quantum
compiling. New Journal of Physics, 22(4):043006, April

12

2020. arXiv:1908.04416.

[42] Sang Min Lee, Jinhyoung Lee, and Jeongho Bang. Learn-
ing unknown pure quantum states. Physical Review A,
98(5):052302, November 2018. arXiv:1805.06580.

[43] Ranyiliu Chen, Zhixin Song, Xuanqiang Zhao, and Xin
Wang. Variational quantum algorithms for trace distance
and ﬁdelity estimation. Quantum Science and Technol-
ogy, 7(1):015019, January 2022. arXiv:2012.05768.
[44] D´enes Petz. Quasi-entropies for states of a von Neu-
mann algebra. Publ. RIMS, Kyoto University, 21:787–
800, 1985.

[45] D´enes Petz. Quasi-entropies for ﬁnite quantum systems.

Reports in Mathematical Physics, 23:57–65, 1986.

Appendix A: Proof of faithfulness and data
processing

Let us deﬁne the following measures for states ρ and σ

and α ∈ (0, 1) ∪ (1, ∞):

Kα(ρ(cid:107)σ) := Tr[(I + ρ)α (I + σ)1−α],
Qα(ρ(cid:107)σ) := Tr[ρασ1−α].

These measures are related as follows:
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Kα(ρ(cid:107)σ) = (d + 1) Qα

(cid:18) I + ρ
d + 1

I + σ
d + 1

(cid:19)

,

where we observe that I+ρ
known that

d+1 and I+σ

d+1 are states.

0 ≤ Qα(ρ(cid:107)σ) ≤ 1

(A1)

(A2)

(A3)

It is

(A4)

for all states ρ and σ (the lower bound follows because
ρ and σ are positive semi-deﬁnite and the upper bound
follows by applying the H¨older inequality). Furthermore,
the measure Qα(ρ(cid:107)σ) is faithful on states, i.e., equal to 1
if and only if ρ = σ, and it satisﬁes the data-processing
inequality [44, 45]:

Qα(ρ(cid:107)σ) ≤ Qα(N (ρ)(cid:107)N (σ)),
Qα(ρ(cid:107)σ) ≥ Qα(N (ρ)(cid:107)N (σ)),

for α ∈ (0, 1) ,
for α ∈ (1, 2],

(A5)
(A6)

for every channel N .

By the relation in (A3), we can conclude properties of

Kα(ρ(cid:107)σ) from properties of Qα(ρ(cid:107)σ). Indeed,

0 ≤ Kα(ρ(cid:107)σ) ≤ d + 1.

(A7)

Also, the measure Kα(ρ(cid:107)σ) is faithful, i.e., equal to d + 1
if and only if ρ = σ. To see this, consider that
(cid:18) I + ρ
d + 1

I + σ
d + 1

(A8)

= 1

Qα

(cid:19)

(cid:13)
(cid:13)
(cid:13)
(cid:13)

d+1 = I+σ

if and only if I+ρ
d+1 . This last equality is equivalent
to ρ = σ. Thus, the faithfulness claim follows. Finally,
the measure Kα(ρ(cid:107)σ) obeys the data-processing inequal-
ity for unital quantum channels. For α ∈ (0, 1) and a
unital channel N (i.e., N (I) = I), we have that

Kα(ρ(cid:107)σ) ≤ Kα(N (ρ)(cid:107)N (σ)),

(A9)

and for α ∈ (1, 2], we have that

Kα(ρ(cid:107)σ) ≥ Kα(N (ρ)(cid:107)N (σ)).

(A10)

These inequalities follow from the data-processing in-
equality for Qα. Indeed, consider for α ∈ (0, 1) that

= (d + 1) Qα

(cid:18) I + N (ρ)
d + 1

(cid:13)
(cid:13)
(cid:13)
(cid:13)

I + N (σ)
d + 1

(cid:19)

= Kα(N (ρ)(cid:107)N (σ)).

13

(A13)

(A14)

Kα(ρ(cid:107)σ) = (d + 1) Qα

(cid:18) I + ρ
d + 1

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:18) I + ρ
d + 1

I + σ
d + 1
(cid:19)(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:19)

N

(cid:18)

≤ (d + 1) Qα

N

(A11)

(cid:19)(cid:19)

(cid:18) I + σ
d + 1

(A12)

The second equality follows from linearity of the channel
N and the fact that it is unital. The inequality for α ∈
(1, 2] follows similar reasoning as above but instead makes
use of (A6).

","2 2 0 2 n u J 0 3 ] h p - t n a u q [ 1 v 5 0 4 5 1 . 6 0 2 2 : v i X r a Multivariate trace estimation in constant quantum depth Yihui Quek,1, 2 Eneet Kaur,3, 4 and Mark M. Wilde5, 6 1Dahlem Center for Complex Quantum Systems, Freie Universit¨at Berlin, 14195 Berlin, Germany 2Information Systems Laboratory, Stanford University, Stanford, California 94305, USA 3Institute for Quantum Computing and Department of Physics and Astronomy, University of Waterloo, Waterloo, Ontario, Canada N2L 3G1 4Wyant College of Optical Sciences, University of Arizona, Tucson, AZ 85721, USA 5Hearne Institute for Theoretical Physics, Department of Physics and Astronomy, and Center for Computation and Technology, Louisiana State University, Baton Rouge, Louisiana 70803, USA 6School of Electrical and Computer Engineering, Cornell University, Ithaca, New York 14850, USA (Dated: July 1, 2022) There is a folkloric belief that a depth-Θ(m) quantum circuit is needed to estimate the trace of the product of m density matrices (i.e., a multivariate trace). We prove that this belief is overly conservative by constructing a constant quantum-depth circuit for the task, inspired by the method of Shor error correction. Furthermore, our circuit demands only local gates in a two dimensional circuit – we show how to implement it in a highly parallelized way on an architecture similar to that of Google’s Sycamore processor. With these features, our algorithm brings the task of multivariate trace estimation, crucial to applications in condensed matter and estimating nonlinear functions of quantum states, closer to the capabilities of near-term quantum processors. We instantiate the latter application with a theorem on estimating nonlinear functions of quantum states with “well-behaved” polynomial approximations. Contents I. INTRODUCTION I. Introduction II. The principle: using cyclic shifts for multivariate trace estimation III. Our circuit construction A. Preparing GHZ states in constant quantum depth B. Multiply-controlled cyclic permutation in constant quantum depth C. Explicit circuit description IV. Implementation of multivariate trace estimation on a two-dimensional architecture V. Guarantees of our estimator VI. Applications of our method VII. Conclusion Acknowledgments References 1 2 3 3 4 5 6 6 8 10 10 11 A. Proof of faithfulness and data processing 12 The task of estimating quantities like Tr[ρ1 · · · ρm] ‘Multivariate traces’ (1) to copies of given access the quantum states ρ1 through ρm is a fundamental building block in quan- tum information science. This subroutine, which we call ‘multivariate trace estimation’, opens the door to esti- mating nonlinear functions of quantum states [1, 2], such as quantum distinguishability measures [3], integer R´enyi entropies [4], and entanglement measures [5]. This esti- mation procedure is a component of many quantum pro- tocols such as quantum ﬁngerprinting [3] and quantum digital signatures [6]. When ρi = (cid:37) for all i ∈ [m] in Eq. (1), an impor- tant application of multivariate trace estimation is to entanglement spectroscopy [4] – deducing the full set of eigenvalues {λ1, . . . , λD} (the ‘spectrum’) of (cid:37), where (cid:37) is the reduced state of a bipartite pure state (that is, (cid:37) = TrB(ψAB) with ψAB a bipartite pure state). The spectrum unlocks a wealth of information about the properties of (cid:37). The smallest eigenvalue of (cid:37) diagnoses whether ψ is separable or entangled [5]. In addition, the inverse of the smallest eigenvalue acts as a condition number for many quantum algorithms that manipulate quantum states (see for instance [7–9]), and it constrains their runtime. The entanglement spectrum is also use- ful to identify topological order [10–13], emergent irre- versibility [14], quantum phase transitions [15], and to determine if the system obeys an area law [16]. With the wealth of applications described above, there has been much interest in bringing multivariate trace esti- mation within the reach of near-term quantum hardware. A glimmer of hope in this regard is the observation that quantities like Eq. (1) can be estimated without the need for full state tomography. In the quantum information sphere, one of the progenitors of this line of thinking was Ref. [1], which proposed a method leveraging the follow- ing well-known identity (related to the replica trick orig- inating in spin glass theory [17]): Tr[W π(ρ1 ⊗ · · · ⊗ ρm)] = Tr[ρ1 · · · ρm] , (2) where the right-hand-side is the multivariate trace we would like to estimate, and W π is a unitary representa- tion of the cyclic shift permutation π := (1, 2, . . . , m) . (3) Here, π represents a cyclic permutation that sends 1 to 2, 2 to 3, and so forth. That is to say, multivariate trace estimation can be accomplished by estimating the real and imaginary parts of the cyclic shift operator in (2), using quantum hardware. This identity subsequently be- came the backbone of many proposals [4, 5, 18, 19] for multivariate trace estimation with yet more near-term constraints. However, there appears to be a lack of clar- ity regarding the actual resource requirements of mul- tivariate trace estimation. Refs. [4, 5, 18, 19] have all suggested that a quantum circuit whose depth is linear in m is needed to perform the task. In this paper, we show that this is an overly- conservative characterization: multivariate trace estima- tion can be implemented in constant quantum depth, with only linearly-many controlled two-qubit gates and a linear amount of classical pre-processing. We invoke ideas from Shor error correction [20] to construct a circuit that achieves this claim (Section III), show how this cir- cuit can be implemented in a highly parallelized way on a two-dimensional architecture similar to Google’s (Sec- tion IV), prove Theorem 3 about the statistical guar- antees of the resulting estimator (Section V), and show that our method ﬁnds further application in estimating traces of ‘well-behaved’ polynomial functions of density matrices (Section VI). 1. Prepare a qubit in the |+(cid:105) := (|0(cid:105) + |1(cid:105))/ and adjoin to it the state ρ1 ⊗ · · · ⊗ ρm. √ 2 2 state 2. Perform a controlled cyclic permutation unitary gate, deﬁned as |0(cid:105)(cid:104)0| ⊗ I ⊗m + |1(cid:105)(cid:104)1| ⊗ W π. (4) 3. Measure the ﬁrst qubit in the basis {|+(cid:105), |−(cid:105)}, where |−(cid:105) := (|0(cid:105) − |1(cid:105))/ 2, and record the out- come X = +1 if the ﬁrst outcome |+(cid:105) is observed and X = −1 if the second outcome |−(cid:105) is observed. √ 4. Repeat Steps 1 to 3 a number of times equal to N := O(ε−2 log δ−1) and return ˆX := 1 i=1 Xi, N where Xi is the outcome of the i-th repetition of Step 3. (cid:80)N It is known that E[X] = Re[Tr[ρ1 · · · ρm]] , (5) and thus ˆX computed in Step 4 is an empirical estimate of the desired quantity. That is, by invoking the well known Hoeﬀding inequality, it is guaranteed, for ε > 0 and δ ∈ (0, 1), that Pr(| ˆX − Re[Tr[ρ1 · · · ρm]]| ≤ ε) ≥ 1 − δ. (6) For completeness, we recall the Hoeﬀding inequality now: Lemma 1 (Hoeﬀding [21]) Suppose that we are given n independent samples Y1, . . . , Yn of a bounded random variable Y taking values in [a, b] and having mean µ. Set Y n := 1 n (Y1 + · · · + Yn) (7) to be the sample mean. Let ε ∈ (0, 1) be the desired ac- curacy, and let 1 − δ be the desired success probability, where δ ∈ (0, 1). Then Pr(cid:2)(cid:12) (cid:12)Y n − µ(cid:12) (cid:12) ≤ ε(cid:3) ≥ 1 − δ, as long as (8) (9) II. THE PRINCIPLE: USING CYCLIC SHIFTS FOR MULTIVARIATE TRACE ESTIMATION where M := b − a. n ≥ M 2 2ε2 ln (cid:18) 2 δ (cid:19) , The principle behind our circuit construction is simple. To explain it, let us ﬁrst recall a well known circuit con- struction [1] for multivariate trace estimation that has no clear realization on near-term quantum computers. The idea is to estimate the quantities Re[Tr[ρ1 · · · ρm]] and Im[Tr[ρ1 · · · ρm]] separately. The circuits to estimate both quantities are similar, and we now describe them. To estimate the real part Re[Tr[ρ1 · · · ρm]], we proceed according to the following steps: To see that Eq. (5) holds, note that in the special case when all the states are pure, i.e., ρi = |ψi(cid:105)(cid:104)ψi|, the input to the circuit is an m-partite pure-state |ψ(m)(cid:105) := |ψ1(cid:105) ⊗ · · · ⊗ |ψm(cid:105), and so Pr(X = +1) (cid:13) (cid:13) (cid:13) (cid:13) 1 4 = = ((cid:104)+| ⊗ I) (cid:16) 1 √ 2 |0(cid:105)|ψ(m)(cid:105) + |1(cid:105)W π|ψ(m)(cid:105) (cid:17)(cid:13) 2 (cid:13) (cid:13) (cid:13) 2 (cid:107)|ψ(m)(cid:105) + W π|ψ(m)(cid:105)(cid:107)2 2 (10) (11) (2 + (cid:104)ψ(m)|W π|ψ(m)(cid:105) + (cid:104)ψ(m)|(W π)†|ψ(m)(cid:105)) (12) A. Preparing GHZ states in constant quantum depth 3 = = = 1 4 1 2 1 2 (1 + Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]]) (1 + Re[Tr[ρ1 · · · ρm]]) (13) (14) where in the last equality we have used the well-known identity in Eq. (2). Similarly, we have that Pr(X = −1) = 1 2 (1 − Re[Tr[ρ1 · · · ρm]]), (15) so that E[X] = (+1) Pr(X = +1) + (−1) Pr(X = −1) = Re[Tr[ρ1 · · · ρm]]. (16) (17) Eq. (5), which asserts that the conclusion Eq. (14) still holds when the ρi are mixed states, follows by convexity (i.e., that every mixed state can be written as a convex combination of pure states). To estimate the second quantity Im[Tr[ρ1 · · · ρm]], a simple variation of the above argument suﬃces. The technique is identical, except that the ﬁnal measure- := ment is in the basis {|+Y (cid:105), |−Y (cid:105)}, where |±Y (cid:105) (|0(cid:105) ± |1(cid:105)) / √ 2. III. OUR CIRCUIT CONSTRUCTION We propose a variation of the above method, which in- stead estimates Tr[ρ1 · · · ρm] in constant quantum depth. This makes the circuit more amenable to run on near- term quantum processors. This circuit is depicted for m = 4 — it has some similarities with the method of Shor error correction from fault-tolerant quantum com- putation [20] (see also Figure 2 of [22]). The crux of our method is to replace the |+(cid:105) = (|0(cid:105) + |1(cid:105)) state at the single qubit control wire in 1√ 2 the circuit in [1], with an (cid:98)m/2(cid:99)-party GHZ state |Φ(cid:98)m/2(cid:99) GHZ (cid:105) := 1 √ 2 (cid:16) |0(cid:105)⊗(cid:98)m/2(cid:99) + |1(cid:105)⊗(cid:98)m/2(cid:99)(cid:17) (18) on (cid:98)m/2(cid:99) control wires. This modiﬁcation allows the number of controls to the permutation to increase to (cid:98)m/2(cid:99), which is half the input size. In turn, it paves the way for an implementation of multivariate trace esti- mation in quantum depth two using parallelized cSWAP gates. In order to achieve an overall constant quantum depth, in Section III A we show that constant quantum depth suﬃces to generate the input GHZ state in (18). Then, in Section III B, we show how to implement the permu- tation W π, again in constant quantum depth. Finally, in Section III C, we describe our full estimator and the accompanying circuit. We now describe two methods to generate the GHZ state in constant quantum depth. The ﬁrst is related to a method discussed previously in [23] and is a constant- depth quantum circuit assisted by measurements, clas- sical feedback, and a logarithmic depth classical circuit. See also the discussion after [24, Theorem 1.1]. The sec- ond is a variation of the ﬁrst, which additionally allows for qubit resets to make more eﬃcient usage of qubits. Method 1. We begin by discussing the ﬁrst approach, which generates an r-party GHZ state using a constant- depth quantum circuit assisted by measurements, clas- sical feedback, and a logarithmic depth classical circuit. We proceed according to the following steps: 1. Generate r − 1 Bell states; i.e., each pair is in the state |Φ+(cid:105) := 1 √ 2 (|00(cid:105) + |11(cid:105)) . (19) 2. Perform controlled-NOT gates between the second qubit in each Bell state and the ﬁrst qubit of the following one. That is, apply a controlled-NOT from qubit 2k to qubit 2k + 1 for all k ∈ {1, . . . , r − 2}. 3. Measure the target of each controlled-NOT gate (all odd-numbered qubits except the ﬁrst qubit) in the computational basis. 4. Controlled on the measurement outcome b1, . . . , br−2, apply a tensor product of Pauli X operators as a correction to all even-numbered qubits except the second qubit. That is, apply X b1⊕···⊕bk−1 to qubit 2k for k ∈ {2, . . . , r − 1}. This procedure prepares an r-party GHZ state on qubits 1, 2, 4, 6, . . . , 2(r − 1). We now show in detail that the scheme prepares an r-party GHZ state. Consider that the initial state can be written as r−1 (cid:79) i=1 |Φ+(cid:105) = √ = √ 1 2r−1 1 2r−1 r−1 (cid:79) (cid:88) i=1 xi∈{0,1} |xi, xi(cid:105) (20) (cid:88) |x1, x1(cid:105) ⊗ x1,...,xr∈{0,1} r−1 (cid:79) i=2 |xi, xi(cid:105). (21) After step 2, the state becomes √ 1 2r−1 (cid:88) |x1, x1(cid:105) ⊗ x1,...,xr∈{0,1} r−1 (cid:79) i=2 |xi ⊕ xi−1, xi(cid:105). (22) After step 3, the (r − 2)-bit string b1 · · · br−2 is obtained from the measurements, where b1 = x2 ⊕ x1, b2 = x3 ⊕ x2, · · · , br−2 = xr−1 ⊕ xr−2, (23) (24) (25) (26) and this projects the state onto the following state: 1 √ 2 = (cid:88) |x1, x1(cid:105) ⊗ |b1, x2(cid:105) ⊗ |b2, x3(cid:105) · · · ⊗ |br−2, xr−1(cid:105) x1∈{0,1} 1 (cid:88) √ 2 x1∈{0,1} |x1, x1(cid:105) ⊗ |b1, b1 ⊕ x1(cid:105)⊗ |b2, b1 ⊕ b2 ⊕ x1(cid:105) · · · ⊗ |br−2, b1 ⊕ · · · ⊕ br−2 ⊕ x1(cid:105) = (I ⊗ I ⊗ I ⊗ X b1 ⊗ I ⊗ X b1⊕b2 ⊗ · · · ⊗ I ⊗ X b1⊕···⊕br−2)×   1 √ 2 (cid:88) x1∈{0,1} |x1, x1(cid:105)|b1, x1(cid:105)|b2, x1(cid:105) · · · |br−2, x1(cid:105)  (27)  4 FIG. 1: A constant-depth quantum circuit for preparing an eight-party GHZ state, assisted by measurement, classical feedback, and qubit resets. Method 1 consists of all the steps depicted, except for the qubit resets (but only prepares a ﬁve- party state). In Method 2, the measured qubits are addition- ally reset to the |0(cid:105) state and connected by CNOTs so that a larger, eight-party state can be prepared instead. (28) Proposition 2 The following decomposition holds The r-party GHZ state on qubits 1, 2, 4, 6, . . . , 2(r − 1) is then recovered by performing the following correction operation: I ⊗ I ⊗ I ⊗ X b1 ⊗ I ⊗ X b1⊕b2 ⊗ · · · I ⊗ X b1⊕···⊕br−2 (29) The leftmost part of Figure 1 (all except the qubit resets) depicts this procedure. Method 2. The second method is very similar to the one just described. The only diﬀerence is that we addi- tionally perform qubit resets on the measured qubits and then controlled-NOTs from the nearest neighbor qubits in the GHZ state to the reset qubits. This scheme is de- picted in Figure 1. It prepares a GHZ state on a number of parties equal to the number of input qubits (hence a 2(r −1)-party GHZ state, as opposed to the r-party GHZ state without the qubit resets). B. Multiply-controlled cyclic permutation in constant quantum depth Rather than implement a controlled-W π gate, we in- stead implement a multiply-controlled-W π gate, in or- der to reduce the depth of this part of the circuit from linear to constant. Our implementation of the multiply- controlled-W π gate in constant depth is based on the observation that there is a particularly convenient way to decompose a cyclic shift into a product of transposi- tions, as shown in [25, Eqs. (4.2)–(4.3)]. We state this observation here, along with a brief proof, for complete- ness: (1, . . . , m) =  m/2 (cid:89)   l=2 (cid:100)m/2(cid:101) (cid:89) l=2 (l, m + 2 − l) m/2 (cid:89) (k, m + 1 − k) k=1 : m even (l, m + 2 − l) (cid:98)m/2(cid:99) (cid:89) k=1 (k, m + 1 − k) : m odd (30) where all arithmetic is modulo m. So, for instance, when m = 8 (the case in Figure 2), Eq. (30) would read (1, . . . , 8) = (2, 8)(3, 7)(4, 6) (1, 8)(2, 7)(3, 6)(4, 5) . (31) Proof. For m even, the ﬁrst transposition sends k to m + 1 − k for every k ∈ [m]. If k = m, it gets sent to 1 by the ﬁrst transposition and is not acted on by the second transposition. Otherwise, the second transposition sends m + 1 − k to m + 2 − (m + 1 − k) = k + 1, so the overall eﬀect is to send k → k + 1 for all k ∈ [m], as desired. For m odd, there are two indices that are involved in only one transposition: k = m, which, as before, gets sent to 1 by the ﬁrst transposition and is not acted on by the second transposition; and k = (cid:100)m/2(cid:101), which is transposed only in the second transposition where it gets sent to m + 2 − (cid:100)m/2(cid:101) = (cid:100)m/2(cid:101) + 1. All other indices are involved in the same two transpositions as described above. Thus, the overall eﬀect is also k → k + 1 for all k ∈ [m]. H H H H |0〉 |0〉 |0〉 |0〉 |0〉 |0〉 |0〉 |0〉 |0〉 |0〉 |0〉 b1 b2 b3 X b1 X b1 b2 X b1 b2 b3 5 1. Prepare an (cid:98)m/2(cid:99)-party GHZ state using one of the constant quantum-depth circuit constructions described in the previous section. Let us call the (cid:98)m/2(cid:99) qubits of the GHZ state the control qubits and the m states ρ1 ⊗ · · · ⊗ ρm the target qubits. 2. To implement the multiply-controlled cyclic shift, • If m is even, adjoin ρ1, . . . , ρm to the GHZ state, in the order ρ1 ⊗ ρm ⊗ ρ2 ⊗ ρm−1 ⊗ ρ3 ⊗ · · · ⊗ ρm/2+2 ⊗ ρm/2 ⊗ ρm/2+1. (32) Perform a controlled-SWAP gate from the ith control qubit to target qubits 2i − 1 and 2i, for all i ∈ {1, . . . , m/2}. Now per- form a controlled-SWAP from the ith con- trol qubit to target qubits 2i and 2i + 1 for i ∈ {1, . . . , m/2 − 1}. • If m is odd, adjoin ρ1, . . . , ρm to the GHZ state, in the order ρ1⊗ρm⊗ρ2⊗ρm−1⊗ρ3⊗· · ·⊗ρ(cid:100)m/2(cid:101)−1⊗ρ(cid:100)m/2(cid:101)+1⊗ρ(cid:100)m/2(cid:101). (33) Perform a controlled-SWAP gate from the ith control qubit to target qubits 2i − 1 and 2i, for all i ∈ {1, . . . , (cid:98)m/2(cid:99)}. Now per- form a controlled-SWAP from the ith con- trol qubit to target qubits 2i and 2i + 1 for i ∈ {1, . . . , (cid:98)m/2(cid:99)}. It can be checked that this prescription implements precisely Eq. (30), with the states adjoined in a speciﬁc order (see Eq. (32) or Eq. (33)) that allows only nearest neighbors to be swapped. 3. Perform a Hadamard on all (cid:98)m/2(cid:99) control qubits and measure them in the computational basis, re- ceiving outcomes 0 or 1. This has the eﬀect of performing a measurement in the X basis on each control qubit. Let Xi ∈ {0, 1} denote the result of the ith measurement, for i ∈ {1, · · · , (cid:98)m/2(cid:99)}. Set R = (−1) (cid:80)(cid:98)m/2(cid:99) i=1 Xi. 4. Repeat Steps 1 to 3 a number of times equal to N := O(ε−2 log δ−1). Compute ˆR := 1 j=1 Rj, where N Rj is the output of Step 3 on the j-th application of the circuit. ˆR is our estimate for Re[Tr[ρ1 · · · ρm]]. (cid:80)N 5. To estimate Im[Tr[ρ1 · · · ρm]], repeat Steps 1 to 4, except that in Step 3, replace each Hadamard with HS†, where S is the phase gate S := (cid:21) (cid:20)1 0 0 i , (34) before the measurement in the computational basis. This has the eﬀect of performing a measurement in the Y basis on each control qubit. Let Y (j) i ∈ {0, 1} be the outcome of the measurement on the i-th FIG. 2: The leftmost part of the circuit prepares a four-party GHZ state. The middle part of the circuit performs a con- trolled cyclic-shift. The ﬁnal part of the circuit results in the classical bits x1, x2, x3, x4, which are used to generate r = (−1)x1+x2+x3+x4 . As argued in Section V, the expecta- tion of r is equal to Re[Tr[ρ1 · · · ρ8]], so that this latter quan- tity can be estimated through repetition. Eq. (30) says that, for a ﬁxed m, the m-wise cyclic shift permutation can be decomposed into a product of two terms. Each term is itself a product of disjoint trans- positions and every index gets transposed once per term. This has a clear interpretation in terms of how to construct a quantum circuit to implement a multiply- controlled-W π. Transposing two qubit labels can be achieved by applying a SWAP gate to the relevant qubits. Disjoint transpositions can thus be accomplished by im- plementing SWAP gates in parallel, in a single time step. Proposition 2 thus implies that, for every m, the multiply-controlled-W π can be implemented in two time steps (depth two), each of which performs (cid:98)m/2(cid:99) con- trolled SWAPs in parallel. We give a more explicit description of the circuit in the next subsection. Note that, as depicted in Figure 2, we have made another optimization for near-term feasibility: we adjoin the input states to the cyclic shift in a speciﬁc order that ensures that only nearest-neighbor states need to be swapped. C. Explicit circuit description We now put together the ﬁndings of the previous two subsections and describe our proposed technique for esti- mating Tr[ρ1 · · · ρm] in the case that each local dimension d = 2 (i.e., each ρi is a single-qubit state). The corre- sponding circuit is depicted in Figure 2. After that, we discuss how to generalize the construction to the case in which d is a power of two, so that each local system con- sists of multiple qubits. The estimator works as follows: H H H H x1 x2 x3 x4 H H H |0〉 |0〉 |0〉 |0〉 |0〉 |0〉 b1 b2 X b1 X b1 b2 ρ1 ρ8 ρ2 ρ7 ρ3 ρ6 ρ4 ρ5 qubit on the j-th application of the circuit. Set j=1 Jj. ˆJ Jj = (−1) is our estimate for Im[Tr[ρ1 · · · ρm]]. . Compute ˆJ = 1 N (cid:80)(cid:98)m/2(cid:99) i=1 (cid:80)N Y (j) i 6. Output ˆT = ˆR + i ˆJ. Our proposed architecture is highly ﬂexible and can be tailored to the availability of resources such as long coherence times and multi-qubit gates. This is evident in two ways: Firstly, we can smoothly trade oﬀ circuit width for the availability of entangling gates. At one extreme, observe that we could have implemented our circuit with only one control qubit (instead of (cid:98)m/2(cid:99)) if we had at our disposal a highly-entangling gate: a single-qubit controlled simul- taneous SWAP gate that swapped (cid:98)m/2(cid:99) pairs of qubits simultaneously. Such a gate would not be feasible in the near term, as it requires highly nonlocal interactions to implement in a real physical architecture. However, even gates that entangle only a subset of qubits aﬀord us sav- ings in circuit width: every additional controlled k-wise SWAP gate at our disposal allows for a reduction of cir- cuit width by k, as k fewer control qubits are necessary (hence the GHZ state needs to be on k fewer parties). to Secondly, generalize of the Tr[ρ1ρ2 · · · ρm] beyond single-qubit can either increase the width or the depth of the circuit described above. Suppose that ρ1, . . . , ρm each consist of p qubits. estimation states, we • We can increase the width of the circuit by prepar- ing GHZ states with mp qubits and then group these into p groups of m qubits each. Correspond- ingly, group the 2m states ρ1, . . . , ρ2m into p groups of 2m qubits, where the kth group has the kth qubit of each state, for k ∈ {1, . . . , p}. Then we per- form controlled SWAPs as detailed above, for each group. Finally, perform Hadamards on all of the mp control qubits and measure each of them in the computational basis. • To increase the depth of the circuit, prepare an m- party GHZ state, and then sequentially perform the controlled-SWAP tests for the p groups of qubits, so that the depth of the circuit increases by a factor of p. Then measure the control qubits as before. IV. IMPLEMENTATION OF MULTIVARIATE TRACE ESTIMATION ON A TWO-DIMENSIONAL ARCHITECTURE 6 GHZ state preparation, as depicted in Figure 1. Explana- tions of the steps are given in the caption of Figure 3. The main point to highlight here is that our circuit leads to a highly parallelized implementation on a two-dimensional architecture that should make it more amenable to real- ization on near-term quantum computers. V. GUARANTEES OF OUR ESTIMATOR In this section, we show that the estimator ˆT described in Section III C is accurate and precise with high proba- bility. Theorem 3 Let {ρ1, . . . , ρm} be single-qubit states. There exists a random variable ˆT that can be computed with O( 1 δ )) repetitions of a constant-depth quan- tum circuit consisting of O(m) three-qubit gates, and sat- isﬁes ε2 log( 1 Pr(| ˆT − Tr[ρ1 · · · ρm]| ≤ ε) ≥ 1 − δ . (35) Proof. By the Hoeﬀding inequality (see Lemma 1), it suﬃces to prove that the estimator ˆT output by the method of Section III C satisﬁes E[ ˆT ] = Tr[W π(ρ1 ⊗ · · · ⊗ ρm)] = Tr[ρ1 · · · ρm] . (36) It suﬃces to prove the ﬁrst equality. To begin with, let us suppose for simplicity that all the states are pure, i.e. ρi = |ψi(cid:105)(cid:104)ψi|, and deﬁne the state of the target qubits as |ψ(m)(cid:105) := |ψ1(cid:105) ⊗ · · · ⊗ |ψm(cid:105). (37) Step 1 of our procedure prepares a GHZ state |Φ(cid:98)m/2(cid:99) GHZ (cid:105) and adjoins it to |ψ(m)(cid:105), such that the overall state at the end of Step 1 is |Φ(cid:98)m/2(cid:99) GHZ (cid:105)|ψ(m)(cid:105). (38) After Step 2 (the multiply-controlled cyclic shift), the overall state becomes |0(cid:105)⊗(cid:98)m/2(cid:99)|ψ(m)(cid:105) + |1(cid:105)⊗(cid:98)m/2(cid:99)W π|ψ(m)(cid:105) (cid:17) . (39) (cid:16) 1 √ 2 In Step 3, one measures the (cid:98)m/2(cid:99) control qubits in the X basis, obtaining an (cid:98)m/2(cid:99)-bitstring where the i-th bit is denoted by the random variable Xi ∈ {0, 1}. We then compute the expectation of the random variable ˆR which will be output as the real part of our estimator We now outline how to implement our algorithm using a two-dimensional architecture similar to Google’s [26]. We do so by means of a series of ﬁgures, which outline the time steps of the circuit implementation. See Figure 3. These ﬁgures can be understood as a two-dimensional implementation of the circuit depicted in Figure 2, with the exception that we also include qubit resets during the ˆR ≡ ˆR(X1, . . . , X(cid:98)m/2(cid:99)) := (−1) (cid:80)(cid:98)m/2(cid:99) i=1 Xi. (40) Introducing the following notation for X basis eigenvec- tors |˜x(cid:105) := 1 √ 2 |0(cid:105) + (−1)x|1(cid:105) for x ∈ {0, 1}, (41) 7 In FIG. 3: (1) The squares in light grey represent control qubits, and the squares in dark grey represent data qubits. this example, there are ﬁve data states involved, each consisting of four qubits. (2) The quantum data is loaded during this stage, which we note here can be conducted in parallel with the preparation of the GHZ state in the control qubits. The state ρi, for i ∈ {1, . . . , 5}, is a four-qubit state that occupies the indicated column of the data qubits in dark grey. The light grey control qubits are prepared in the all zeros state. (3) First step of the preparation of the GHZ state of the control qubits. Every other control qubit has a Hadamard gate applied in parallel. (4) Every pair of control qubits has CNOT gates applied in parallel. (5) Every other pair of control qubits has CNOT gates applied in parallel. (6) Starting from the third control qubit from the top left, every other control qubit is measured, and the measurement outcome is stored in a binary vector b1, . . . , b7. (7) Based on the measurement outcomes from the previous step, Pauli-X corrections are applied to every other qubit, starting from the fourth in the top row. The particular corrections needed are abbreviated by a multivariate function f , the details of which are available in Eq. (29). (8) The measured qubits are reset to the all zeros state. (9) Final step of the preparation of the GHZ state of the control qubits. CNOT gates are again applied to every other control qubit. The ﬁnal state of all control qubits is equal to a GHZ state. (10) Controlled-SWAPs are applied in parallel between control qubits and data qubits, in a ﬁrst round of the implementation of the cyclic shift. (11) Controlled-SWAPs are applied in parallel between other control qubits and data qubits, in a second round of the implementation of the cyclic shift. (13) In a ﬁnal step, all control qubits are measured in the computational basis and the measurement outcomes are processed according to Eq. (40) to form an estimate of the real part of Tr[ρ1 · · · ρ5]. To estimate the imaginary part, replace H in step (12) with HS†. A GIF of the entire procedure may be viewed at https://twitter.com/quekpottheories/status/1542545522392809477?s=20&t=rb1PDn27W3pVaAKHWDDS1Q (12) Hadamard gates are applied to all control qubits. (1) (2) Load Data ρ1 ρ5 ρ2 ρ4 ρ3 (3) GHZ Preparation H H H H H H H H (4) GHZ Preparation (5) GHZ Preparation (6) GHZ Preparation (7) GHZ Preparation Xf Xf Xf Xf Xf Xf Xf (8) GHZ Preparation |0〉 |0〉 |0〉 |0〉 |0〉 |0〉 |0〉 (9) GHZ Preparation (10) (11) (12) H H H H H H H H H H H H H H H H (13) the probability of the X basis measurement outputting the bitstring x1 · · · x(cid:98)m/2(cid:99) ∈ {0, 1}(cid:98)m/2(cid:99) is given by Pr(x1 · · · x(cid:98)m/2(cid:99)) (cid:88) = x1,··· ,xm = 1, 1 + (−1) i=1 xi Re[Tr[W πρ(m)]] (cid:80)m 2m 8 (54) (55) = = = (cid:13) 2 (cid:13) (cid:13) (cid:13) (cid:13) 2 (42) (43) (cid:13) (cid:13) (cid:13) (cid:13) (cid:13) 1√ 2 (cid:0)(cid:104)(cid:102)x1, (cid:102)x2, · · · , (cid:94)x(cid:98)m/2(cid:99)| ⊗ I(cid:1) × (cid:0)|0(cid:105)⊗(cid:98)m/2(cid:99)|ψ(m)(cid:105) + |1(cid:105)⊗(cid:98)m/2(cid:99)W π|ψ(m)(cid:105)(cid:1) 1 2(cid:98)m/2(cid:99)+1 1 + (−1) (cid:13) (cid:13)|ψ(m)(cid:105) + (−1) (cid:13) (cid:80)(cid:98)m/2(cid:99) i=1 (cid:13) 2 xiW π|ψ(m)(cid:105) (cid:13) (cid:13) 2 (cid:80)(cid:98)m/2(cid:99) i=1 xi Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]] 2(cid:98)m/2(cid:99) . (44) Thus, E[ ˆR] = = (cid:88) x1,...,x(cid:98)m/2(cid:99) Pr(x1, · · · , x(cid:98)m/2(cid:99))r(x1, · · · , x(cid:98)m/2(cid:99)) (45) (cid:32) 1 + (−1) (cid:80)(cid:98)m/2(cid:99) i=1 xi Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]] (cid:33) 2(cid:98)m/2(cid:99) (cid:88) x1,..., x(cid:98)m/2(cid:99) × (−1) (cid:80)(cid:98)m/2(cid:99) i=1 xi (46) = 1 2(cid:98)m/2(cid:99) (cid:88) (cid:16) (cid:80)(cid:98)m/2(cid:99) i=1 (−1) xi + x1,...,x(cid:98)m/2(cid:99) = Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]], Re[Tr[W π|ψ(m)(cid:105)(cid:104)ψ(m)|]] (cid:17) (47) (48) where, in the second-to-last equality, we have used the fact that (cid:88) x1,...,xl∈{0,1}l (cid:80)l (−1) i=1 xi = 0 for all l. (49) The claim for mixed states ρ(m) := ρ1 ⊗ · · · ⊗ ρm, i.e., E[ ˆR] = Re[Tr[W πρ(m)]], (50) follows by convexity (i.e., that every mixed state can be written as a convex combination of pure states). That is, we use the fact that 1 + (−1) i=1 xi Re[Tr[W πρ(m)]] (cid:80)m Pr(x1, . . . , xm) = 2m (51) for this case and then repeat the calculation above for every eigenvector of ρ(m). Using a similar chain of logic, we conclude that E[ ˆJ] = Im[Tr[W πρ(m)]] , (52) and the ﬁrst equality of (36) follows. We also compute the variance of ˆT . Consider that Var[ ˆR] := E[( ˆR − E[ ˆR])2] = E[ ˆR2] − E[ ˆR]2. Since E[ ˆR2] = (cid:88) x1,··· ,xm Pr(x1, · · · , xm) (r(x1, · · · , xm))2 (53) we conclude that Var[ ˆR] = 1 − (Re[Tr[W πρ(m)]])2. Sim- ilarly, Var[ ˆJ] = 1 − (Im[Tr[W πρ(m)]])2. Since these two random variables are independent, Var[ ˆT ] = 2 − (cid:12) (cid:12) (cid:12)Tr[W πρ(m)] (cid:12) (cid:12) (cid:12) 2 . (56) We now discuss the generalization of Theorem 3 to states of more than one qubit. This generalization can be accomplished by increasing the circuit width or the circuit depth as discussed in Section III C. Proposition 4 Let {ρ1, . . . , ρm} be a set of p-qubit states, and ﬁx ε > 0 and δ ∈ (0, 1). There exists a ran- dom variable ˆTp that can be computed using O( 1 δ )) repetitions of a constant-depth quantum circuit consisting of O(mp) three-qubit gates, and satisﬁes ε2 log( 1 Pr(| ˆTp − Tr[ρ1 · · · ρm]| ≤ ε) ≥ 1 − δ . (57) Proof. The gate count for the circuits for both con- structions detailed in Section III C is O(mp). For the second construction (increasing the depth), Eq. (57) fol- lows from the exact same calculation as in the proof of Theorem 3. For the ﬁrst construction (increasing the width), let us deﬁne ρ(m,p) := ρ1 ⊗ · · · ⊗ ρm. It suﬃces to prove that for the estimator ˆRp := (−1)X1+···+Xmp de- rived from the mp measurement outcomes X1, · · · , Xmp fulﬁls E[ ˆRp] = Re[Tr[W πρ(m,p)]]. This follows from a similar calculation to Eqs. (42)–(50). Similarly, Var[ ˆTp] = 2 − (cid:12) (cid:12) (cid:12)Tr[W πρ(m,p)] (cid:12) (cid:12) (cid:12) 2 . (58) VI. APPLICATIONS OF OUR METHOD An application of our method is to estimate functions of density matrices that can be approximated by ‘well- behaved’ polynomials. This was already suggested in the original work of [1], but no complexity analysis was put forth. Here we formalize the analysis of the application in the following theorem: Theorem 5 Let ρ be a quantum state with rank at most d. Suppose there exist constants η, ε and a function C such that g : R → R is approximated by a degree-m poly- nomial f (x) = (cid:80)m k=0 ckxk on the interval [η, 1], in the sense that sup x∈[η,1] |g(x) − f (x)| < ε 2d , (59) and 3. Let m (cid:88) k=0 |ck| < C . (60) N = 8C 2 ε2 ln (cid:18) 2 δ (cid:19) . 9 (66) Then estimating Tr[g(ρ)] within ε additive error with success probability not smaller than 1 − δ requires δ )) copies of ρ and O(m C2 O(m2 C2 δ )) runs of a circuit with O(m) controlled SWAP gates. ε2 log( 1 ε2 log( 1 (Here, we should think of C as a slowly-growing function of m.) An example of a function of a quantum state that can be estimated in this way is g(x) = (1 + x)α for α > 0, which has the following expansion as a binomial series (1 + x)α = ∞ (cid:88) k=0 (cid:19) (cid:18)α k xk, (61) k where (cid:0)α (cid:1) is the generalized binomial coeﬃcient. It is well known that the binomial series converges absolutely for x = 1 and α > 0, which implies that, for every α > 0, there exists a positive constant C(α) such that m (cid:88) k=0 (cid:12) (cid:18)α (cid:12) (cid:12) k (cid:12) (cid:19)(cid:12) (cid:12) (cid:12) (cid:12) ≤ ∞ (cid:88) k=0 (cid:12) (cid:12) (cid:12) (cid:12) (cid:18)α k (cid:19)(cid:12) (cid:12) (cid:12) (cid:12) = C(α). (62) Thus, this series satisﬁes the criterion in Eq. (60). An- other function of a quantum state that can be estimated in this way is f (x) = ln(x + 1). Indeed, this function has the following well known expansion: ln(x + 1) = ∞ (cid:88) k=1 (−1)k k xk, (63) Repeat the ﬁrst two steps N − 1 more times, on the i-th iteration outputting the random variable R(i). 4. Output ˆg = 1 N Re[Tr[g(ρ)]]. (cid:80)N i=1 R(i) as the estimator for Let us now prove the correctness of this procedure. Suppose the spectral decomposition of ρ is as follows: ρ = rρ (cid:88) i=1 λi|ψi(cid:105)(cid:104)ψi| , (67) where rρ is the rank of ρ. In the limit of N → ∞, the only error in the estimator ˆg would come from the error in the polynomial approximation. That is, | Tr[g(ρ)] − m (cid:88) k=0 ck Tr[ρk]| = rρ (cid:88) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) i=1 ≤ ε/2 (cid:32) g(λi) − m (cid:88) k=0 ckλk i (cid:33)(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (68) where the inequality follows from Eq. (59) and the fact that d > rρ. Now we account for the other source of error, which is the statistical error caused by taking a ﬁnite number of samples. Consider that |R(i)| ≤ m (cid:88) k=0 |ck||Rk| ≤ m (cid:88) k=0 |ck| ≤ C, (69) (cid:12) (cid:12) (cid:12) k=1 (−1)k k so that the absolute partial sum of the coeﬃcients sat- (cid:12) isﬁes (cid:80)m (cid:12) (cid:12) ≈ ln m + γ, where γ ≈ 0.577 is the Euler–Mascheroni constant. The point here is that, even though the absolute partial sums are not bounded by a constant, they still grow suﬃciently slowly such that the algorithm runs eﬃciently. Proof of Theorem 5. We will present an estimator for the desired quantity that satisﬁes the claimed complexity guarantees. Let us describe the estimator for Re[Tr[g(ρ)]] (the estimator for the imaginary part follows immedi- ately). To estimate Re[Tr[g(ρ)]], we run the following procedure: 1. For each k ∈ [m], run the circuit described in Steps 1-3 of Section III C once to output a random variable Rk ∈ {−1, 1} such that E[Rk] = Re[Tr[ρk]] . (64) for all i ∈ {1, . . . , N }, where the ﬁrst inequality follows from the triangle inequality, the second from the fact that Rk ∈ {−1, 1}, and the third from the assumption in (60). By applying (69), the Hoeﬀding inequality in Lemma 1 immediately applies to our setting when we take Yi ← R(i) and [a, b] ← [−C, C]. We also see that µ ← E[R(1)] = (cid:80)m k=0 ck Tr[ρk]. Then if we set N to (cid:19) (cid:18) 2 δ 8C 2 ε2 ln N = (70) we get that Pr (cid:34)(cid:12) (cid:12) (cid:12) (cid:12) (cid:12) ˆg − m (cid:88) k=0 (cid:12) (cid:12) ck Tr[ρk] (cid:12) (cid:12) (cid:12) (cid:35) ≤ ε/2 ≥ 1 − δ. (71) Combining the two sources of error in Eqs. (68) and (71), we get that with probability 1 − δ, 2. Linearly combine the above random variables to |ˆg − Re[Tr[g(ρ)]]| ≤ form the new random variable R(1) = m (cid:88) k=0 ckRk . (65) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) ˆg − m (cid:88) k=0 ck Tr[ρk] (cid:12) (cid:12) (cid:12) (cid:12) (cid:12) + Re[Tr[g(ρ)]] − m (cid:88) k=0 (cid:12) (cid:12) ck Tr[ρk] (cid:12) (cid:12) (cid:12) ≤ ε. (72) Repeating the analysis for the estimation of Im[Tr[g(ρ)]] yields the stated complexity. ak Tr[(σ1/2ρσ1/2)k] = (cid:88) k ak Tr[(ρσ)k], (79) (cid:88) k 10 We remark that, an alternative way to estimate Tr[ρk] for each k ∈ [m] is by using the method of classical shadows to obtain ‘classical snapshots’ of ρ that can be linearly combined to obtain a classical random variable whose expectation is Tr[ρk] (see Supplementary Material Section 6 of [27]). However, it is unclear to us if this method would oﬀer savings in the quantum resources re- quired, as the total number of times the quantum circuit needs to be run in the data acquisition phase should scale with the variance of the corresponding estimator. We do not know of a concise expression for this variance for ar- bitrary m. Indeed, calculating it for just a single value of m (m = 2) required four pages of calculations in [27]. One might also wonder whether we could use this ap- proach to estimate R´enyi or von Neumann entropies of quantum states. The main diﬃculty in doing so is that well known polynomial approximations of the functions xα and −x ln x, given respectively by xα = = ∞ (cid:88) k=0 ∞ (cid:88) k=0 −x ln x = x = x ∞ (cid:88) k=1 ∞ (cid:88) k=1 (cid:19) (cid:18)α k (x − 1)k (73) (cid:19) (−1)k−(cid:96)x(cid:96), (74) (cid:19) k (cid:88) (cid:18)α k (cid:18)k (cid:96) (cid:96)=0 (1 − x)k k (75) (76) 1 k k (cid:88) (cid:96)=0 (cid:19) (cid:18)k (cid:96) (−1)(cid:96)x(cid:96) = ∞ (cid:88) k=1 1 k k (cid:88) (cid:96)=0 (cid:19) (cid:18)k (cid:96) (−1)(cid:96)x(cid:96)+1, (77) do not satisfy the condition in (60), in the sense that the absolute partial sums grow too quickly and therefore do not lead to an eﬃcient algorithm using this approach. See also [28] in this context. It thus remains open whether this approach can be used eﬀectively for estimating these important uncertainty measures. See [29–32] for work on this topic in the ﬁeld of classical information theory and [33–37] for a ﬂurry of recent eﬀorts on estimating R´enyi and von Neumann entropies using quantum computers, which propose alternative approaches. We note here that the method outlined above can be generalized to functions of multiple density matrices. For example, let ρ and σ be quantum states, and suppose that g1 and g2 are well behaved polynomials in the sense described in Theorem 5. Then we can employ a similar approach to estimate the functions Tr[g1(ρ)g2(σ)] and Tr[g1(σ1/2ρσ1/2)]. Polynomial approximations of these functions take the following form: (cid:34)(cid:32) Tr (cid:88) ckρk (cid:33) (cid:32) (cid:88) d(cid:96)σ(cid:96) (cid:33)(cid:35) k (cid:96) (cid:88) = k,(cid:96) ckd(cid:96) Tr[ρkσ(cid:96)], (78) respectively, and can be estimated using our circuits com- bined with classical postprocessing. Thus, by the dis- cussion after Theorem 5, we can take g1(x) = (1 + x)α and g2(x) = (1 + x)β for α, β > 0. A case of interest is when we set α ∈ (0, 1) and β = 1 − α. The resulting function Tr[g1(ρ)g2(σ)] then satisﬁes faithfulness and the data-processing inequality under unital quantum chan- nels and thus can serve as an alternative to the widely used Hilbert–Schmidt distance measure (which also sat- isﬁes the data-processing inequality under unital chan- nels [38]). We prove these claims in Appendix A. VII. CONCLUSION We have provided a quantum circuit for multivariate trace estimation that requires only constant quantum depth, and hence it is more amenable to be implemented on near-term quantum computers than previous meth- ods that required linear depth. Our architecture is also ﬂexible and can be smoothly tailored to the availability of circuit width (at the cost of more-entangling gates). Going forward from here, one can further consider the application of our method to estimating nonlinear func- tions of quantum states. “The most important applica- tion of computers has been designing better computers” [39], and these methods can be used for this purpose. Our method to estimate functions of quantum states based on their polynomial approximations opens the door to the idea that near-term quantum computers can be used to design better quantum computers. An important open question in this regard is whether any functions whose polynomial approximations fulﬁll Eq. (60) have an in- terpretation as quality metrics for quantum computer design. Conversely, it would also be interesting to ex- plore further whether there are any quantum state distin- guishability measures – critical in applications like quan- tum compiling [40, 41] and state learning [42, 43] – that fulﬁll this condition. Acknowledgments We acknowledge helpful discussions with Jayadev Acharya, Patrick Coles, Andr´as Gily´en, Zo¨e Holmes, Dhrumil Patel, Eliott Rosenberg, Aliza Siddiqui, and An- tonio Anna Mele. EK and MMW acknowledge support from the National Science Foundation (NSF) under grant no. 1714215. YQ acknowledges support from a Stanford QFARM fellowship, an NUS Overseas Graduate Scholar- ship and an Alexander von Humboldt Fellowship. [1] Artur K. Ekert, Carolina Moura Alves, Daniel K. L. Oi, Micha(cid:32)l Horodecki, Pawe(cid:32)l Horodecki, and L. C. Kwek. Direct estimations of linear and nonlinear functionals of a quantum state. Physical Review Letters, 88(21):217901, May 2002. arXiv:quant-ph/0203016. [2] Todd A. Brun. Measuring polynomial functions of states. Quantum Information and Computation, 4(5):401–408, September 2004. arXiv:quant-ph/0401067. [3] Harry Buhrman, Richard Cleve, John Watrous, and Phys- Ronald de Wolf. ical Review Letters, 87(16):167902, September 2001. arXiv:quant-ph/0102001. Quantum ﬁngerprinting. [4] Sonika Johri, Damian S. Steiger, and Matthias Troyer. Entanglement spectroscopy on a quantum computer. Physical Review B, 96(19):195136, November 2017. arXiv:1707.07658. [5] Pawe(cid:32)l Horodecki and Artur Ekert. Method for di- rect detection of quantum entanglement. Physical Re- view Letters, 89(12):127902, August 2002. arXiv:quant- ph/0111064. [6] Daniel Gottesman and Isaac Chuang. Quantum digital signatures. May 2001. arXiv:quant-ph/0105032. [7] Aram W. Harrow, Avinatan Hassidim, and Seth Lloyd. Quantum algorithm for linear systems of equations. Physical Review Letters, 103(15):150502, October 2009. arXiv:0811.3171. [8] Andr´as Gily´en, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and improvements for quantum ma- beyond: trix arithmetics. In Proceedings of the 51st Sympo- sium on the Theory of Computing, pages 193–204, 2019. arXiv:1806.01838. exponential [9] Andr´as Gily´en, Seth Lloyd, Iman Marvian, Yihui Quek, and Mark M. Wilde. Quantum algorithm for Petz recovery channels and pretty good measurements. Physical Review Letters, 128(22):220502, June 2022. arXiv:2006.16924. [10] Frank Pollmann, Ari M. Turner, Erez Berg, and Masaki Oshikawa. Entanglement spectrum of a topological phase in one dimension. Physical Review B, 81(6):064439, February 2010. arXiv:0910.1811. [11] Hong Yao and Xiao-Liang Qi. Entanglement en- tropy and entanglement spectrum of the Kitaev model. Physical Review Letters, 105(8):080501, August 2010. arXiv:1001.1165. [12] Lukasz Fidkowski. Entanglement spectrum of topological insulators and superconductors. Physical Review Letters, 104(13):130502, April 2010. arXiv:1001.1165. [13] Hui Li and F. D. M. Haldane. Entanglement spectrum as a generalization of entanglement entropy: Identiﬁcation of topological order in non-Abelian fractional quantum Hall eﬀect states. Physical Review Letters, 101(1):010504, July 2008. arXiv:0805.0332. [14] Claudio Chamon, Alioscia Hamma, and Eduardo R. irreversibility and entangle- Physical Review Letters, Mucciolo. ment spectrum statistics. 112(24):240501, June 2014. arXiv:1310.2702. Emergent [15] G. De Chiara, L. Lepori, M. Lewenstein, and A. Sanpera. Entanglement spectrum, critical exponents, and order parameters in quantum spin chains. Physical Review Let- ters, 109(23):237208, December 2012. arXiv:1104.1331. 11 [16] Jens Eisert, Marcus Cramer, and Martin B. Plenio. Col- loquium: Area laws for the entanglement entropy. Re- views of Modern Physics, 82(1):277–306, February 2010. arXiv:0808.3773. [17] M. Mezard, G. Parisi, and M. Virasoro. Spin Glass The- ory and Beyond. World Scientiﬁc, 1986. [18] Justin Yirka and Yi˘git Suba¸sı. Qubit-eﬃcient entangle- ment spectroscopy using qubit resets. Quantum, 5:535, September 2021. arXiv:2010.03080. [19] Yi˘git Suba¸sı, Lukasz Cincio, and Patrick J. Coles. En- tanglement spectroscopy with a depth-two quantum cir- cuit. Journal of Physics A: Mathematical and Theoreti- cal, 52(4):044001, January 2019. arXiv:1806.08863. [20] Peter W. Shor. Fault-tolerant quantum computation. In Proceedings of the 37th Annual Symposium on Founda- tions of Computer Science, FOCS ’96, page 56, USA, 1996. IEEE Computer Society. arXiv:quant-ph/9605011. [21] Wassily Hoeﬀding. Probability inequalities for sums of bounded random variables. Journal of the American Sta- tistical Association, 58(301):13–30, March 1963. [22] Daniel Gottesman. An introduction to quantum er- ror correction and fault-tolerant quantum computation. Quantum Information Science and Its Contributions to Mathematics, Proceedings of Symposia in Applied Math- ematics, 68:13–58, 2010. arXiv:0904.2557. [23] Adam Bene Watts, Robin Kothari, Luke Schaeﬀer, and Avishay Tal. Exponential separation between shallow quantum circuits and unbounded fan-in shallow classi- In Proceedings of the 51st Annual ACM cal circuits. SIGACT Symposium on Theory of Computing, STOC 2019, pages 515–526, New York, NY, USA, 2019. As- sociation for Computing Machinery. arXiv:1906.08890. [24] Zhenning Liu and Alexandru Gheorghiu. Depth-eﬃcient proofs of quantumness. July 2021. arXiv:2107.02163. [25] Markus Grassl and Thomas Beth. Cyclic quantum error- correcting codes and quantum shift registers. Proceedings of the Royal Society of London. Series A: Mathematical, Physical and Engineering Sciences, 456(2003):2689–2706, November 2000. arXiv:quant-ph/9910061. [26] Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C. Bardin, Rami Barends, Rupak Biswas, Sergio Boixo, Fernando G. S. L. Brandao, David A. Buell, Brian Burkett, Yu Chen, Zijun Chen, Ben Chiaro, Roberto Collins, William Courtney, Andrew Dunsworth, Ed- ward Farhi, Brooks Foxen, Austin Fowler, Craig Gidney, Marissa Giustina, Rob Graﬀ, Keith Guerin, Steve Habeg- ger, Matthew P. Harrigan, Michael J. Hartmann, Alan Ho, Markus Hoﬀmann, Trent Huang, Travis S. Humble, Sergei V. Isakov, Evan Jeﬀrey, Zhang Jiang, Dvir Kafri, Kostyantyn Kechedzhi, Julian Kelly, Paul V. Klimov, Sergey Knysh, Alexander Korotkov, Fedor Kostritsa, David Landhuis, Mike Lindmark, Erik Lucero, Dmitry Lyakh, Salvatore Mandr`a, Jarrod R. McClean, Matthew McEwen, Anthony Megrant, Xiao Mi, Kristel Michielsen, Masoud Mohseni, Josh Mutus, Ofer Naaman, Matthew Neeley, Charles Neill, Murphy Yuezhen Niu, Eric Os- tby, Andre Petukhov, John C. Platt, Chris Quintana, Eleanor G. Rieﬀel, Pedram Roushan, Nicholas C. Ru- bin, Daniel Sank, Kevin J. Satzinger, Vadim Smelyan- skiy, Kevin J. Sung, Matthew D. Trevithick, Amit Vainsencher, Benjamin Villalonga, Theodore White, Z. Jamie Yao, Ping Yeh, Adam Zalcman, Hartmut Neven, and John M. Martinis. Quantum supremacy us- ing a programmable superconducting processor. Nature, 574(7779):505–510, October 2019. arXiv:1910.11333. [27] Hsin-Yuan Huang, Richard Kueng, and John Preskill. Predicting many properties of a quantum system from very few measurements. Nature Physics, 16(10):1050– 1057, June 2020. arXiv:2002.08953. [28] fedja. Answer to stack exchange post. https://tinyurl. com/3b9v7pum, July 2021. [29] Jiantao Jiao, Kartik Venkat, Yanjun Han, and Tsachy Weissman. Minimax estimation of functionals of discrete distributions. IEEE Transactions on Information The- ory, 61(5):2835–2885, May 2015. arXiv:1406.6956. [30] Yihong Wu and Pengkun Yang. Minimax rates of en- tropy estimation on large alphabets via best polynomial approximation. IEEE Transactions on Information The- ory, 62(6):3702–3720, June 2016. arXiv:1407.0381. [31] Jiantao Jiao, Kartik Venkat, Yanjun Han, and Tsachy Weissman. Maximum likelihood estimation of function- als of discrete distributions. IEEE Transactions on In- formation Theory, 63(10):6774–6798, 2017. [32] Jayadev Acharya, Alon Orlitsky, Ananda Theertha Suresh, and Himanshu Tyagi. Estimating renyi en- tropy of discrete distributions. IEEE Transactions on Information Theory, 63(1):38–56, January 2017. arXiv:1408.1000. [33] Jayadev Acharya, Ibrahim Issa, Nirmal V. Shende, and Aaron B. Wagner. Estimating quantum entropy. IEEE Journal on Selected Areas in Information Theory, 1(2):454–468, August 2020. arXiv:1711.00814. [34] Andr´as Gily´en and Tongyang Li. Distributional Prop- erty Testing in a Quantum World. In Thomas Vidick, editor, 11th Innovations in Theoretical Computer Sci- ence Conference (ITCS 2020), volume 151 of Leibniz In- ternational Proceedings in Informatics (LIPIcs), pages 25:1–25:19, Dagstuhl, Germany, 2020. Schloss Dagstuhl– Leibniz-Zentrum fuer Informatik. arXiv:1902.00814. [35] Alessandro Luongo and Changpeng Shao. Quan- tum algorithms for spectral sums. November 2020. arXiv:2011.06475. [36] Sathyawageeswar Subramanian and Min-Hsiu Hsieh. Quantum algorithm for estimating α-renyi entropies of quantum states. Physical Review A, 104(2):022428, Au- gust 2021. arXiv:1908.05251. [37] Youle Wang, Benchi Zhao, and Xin Wang. Quantum al- gorithms for estimating quantum entropies. March 2022. arXiv:2203.02386. [38] David P´erez-Garc´ıa, Michael M. Wolf, Denes Petz, and Mary Beth Ruskai. Contractivity of positive and trace- preserving maps under lp norms. Journal of Mathemat- ical Physics, 47(8):083506, August 2006. arXiv:math- ph/0601063. [39] Umesh Vazirani. Computational probes of Hilbert space. Talk available at https://www.youtube.com/watch?v= ajKoO5RFtwo, December 2019. Quote from Q2B 2019, attributed to an unknown person. [40] Sumeet Khatri, Ryan LaRose, Alexander Poremba, Lukasz Cincio, Andrew T. Sornborger, and Patrick J. Coles. Quantum-assisted quantum compiling. Quantum, 3:140, May 2019. arXiv:1807.00800. [41] Kunal Sharma, Sumeet Khatri, Marco Cerezo, and Patrick J. Coles. Noise resilience of variational quantum compiling. New Journal of Physics, 22(4):043006, April 12 2020. arXiv:1908.04416. [42] Sang Min Lee, Jinhyoung Lee, and Jeongho Bang. Learn- ing unknown pure quantum states. Physical Review A, 98(5):052302, November 2018. arXiv:1805.06580. [43] Ranyiliu Chen, Zhixin Song, Xuanqiang Zhao, and Xin Wang. Variational quantum algorithms for trace distance and ﬁdelity estimation. Quantum Science and Technol- ogy, 7(1):015019, January 2022. arXiv:2012.05768. [44] D´enes Petz. Quasi-entropies for states of a von Neu- mann algebra. Publ. RIMS, Kyoto University, 21:787– 800, 1985. [45] D´enes Petz. Quasi-entropies for ﬁnite quantum systems. Reports in Mathematical Physics, 23:57–65, 1986. Appendix A: Proof of faithfulness and data processing Let us deﬁne the following measures for states ρ and σ and α ∈ (0, 1) ∪ (1, ∞): Kα(ρ(cid:107)σ) := Tr[(I + ρ)α (I + σ)1−α], Qα(ρ(cid:107)σ) := Tr[ρασ1−α]. These measures are related as follows: (cid:13) (cid:13) (cid:13) (cid:13) Kα(ρ(cid:107)σ) = (d + 1) Qα (cid:18) I + ρ d + 1 I + σ d + 1 (cid:19) , where we observe that I+ρ known that d+1 and I+σ d+1 are states. 0 ≤ Qα(ρ(cid:107)σ) ≤ 1 (A1) (A2) (A3) It is (A4) for all states ρ and σ (the lower bound follows because ρ and σ are positive semi-deﬁnite and the upper bound follows by applying the H¨older inequality). Furthermore, the measure Qα(ρ(cid:107)σ) is faithful on states, i.e., equal to 1 if and only if ρ = σ, and it satisﬁes the data-processing inequality [44, 45]: Qα(ρ(cid:107)σ) ≤ Qα(N (ρ)(cid:107)N (σ)), Qα(ρ(cid:107)σ) ≥ Qα(N (ρ)(cid:107)N (σ)), for α ∈ (0, 1) , for α ∈ (1, 2], (A5) (A6) for every channel N . By the relation in (A3), we can conclude properties of Kα(ρ(cid:107)σ) from properties of Qα(ρ(cid:107)σ). Indeed, 0 ≤ Kα(ρ(cid:107)σ) ≤ d + 1. (A7) Also, the measure Kα(ρ(cid:107)σ) is faithful, i.e., equal to d + 1 if and only if ρ = σ. To see this, consider that (cid:18) I + ρ d + 1 I + σ d + 1 (A8) = 1 Qα (cid:19) (cid:13) (cid:13) (cid:13) (cid:13) d+1 = I+σ if and only if I+ρ d+1 . This last equality is equivalent to ρ = σ. Thus, the faithfulness claim follows. Finally, the measure Kα(ρ(cid:107)σ) obeys the data-processing inequal- ity for unital quantum channels. For α ∈ (0, 1) and a unital channel N (i.e., N (I) = I), we have that Kα(ρ(cid:107)σ) ≤ Kα(N (ρ)(cid:107)N (σ)), (A9) and for α ∈ (1, 2], we have that Kα(ρ(cid:107)σ) ≥ Kα(N (ρ)(cid:107)N (σ)). (A10) These inequalities follow from the data-processing in- equality for Qα. Indeed, consider for α ∈ (0, 1) that = (d + 1) Qα (cid:18) I + N (ρ) d + 1 (cid:13) (cid:13) (cid:13) (cid:13) I + N (σ) d + 1 (cid:19) = Kα(N (ρ)(cid:107)N (σ)). 13 (A13) (A14) Kα(ρ(cid:107)σ) = (d + 1) Qα (cid:18) I + ρ d + 1 (cid:13) (cid:13) (cid:13) (cid:13) (cid:18) I + ρ d + 1 I + σ d + 1 (cid:19)(cid:13) (cid:13) (cid:13) (cid:13) (cid:19) N (cid:18) ≤ (d + 1) Qα N (A11) (cid:19)(cid:19) (cid:18) I + σ d + 1 (A12) The second equality follows from linearity of the channel N and the fact that it is unital. The inequality for α ∈ (1, 2] follows similar reasoning as above but instead makes use of (A6).","['p', 'u', 'multivariate', 'trace', 'estimation', 'constant', 'quantum', 'depth', 'yihui', 'quek1', 'eneet', 'kaur3', 'center', 'complex', 'system', 'laboratory', 'quantum', 'computing', 'department', 'physics', 'astronomy', 'university', 'college', 'theoretical', 'physics', 'department', 'physics', 'astronomy', 'center', 'computation', 'technology', 'electrical', 'computer', 'engineering', 'date', 'folkloric', 'belief', 'need', 'estimate', 'trace', 'product', 'matrix', 'multivariate', 'trace', 'prove', 'belief', 'overly', 'conservative', 'construct', 'constant', 'quantumdepth', 'circuit', 'task', 'inspire', 'method', 'error', 'correction', 'circuit', 'demand', 'local', 'gate', 'dimensional', 'circuit', 'show', 'implement', 'highly', 'parallelize', 'way', 'architecture', 'similar', 'processor', 'feature', 'algorithm', 'bring', 'task', 'multivariate', 'trace', 'estimation', 'crucial', 'application', 'condensed', 'matter', 'estimate', 'nonlinear', 'function', 'quantum', 'state', 'close', 'capability', 'nearterm', 'quantum', 'processor', 'instantiate', 'latter', 'application', 'theorem', 'estimate', 'nonlinear', 'function', 'quantum', 'state', 'wellbehave', 'polynomial', 'approximation', 'content', 'introduction', 'introduction', 'principle', 'use', 'cyclic', 'shift', 'multivariate', 'trace', 'estimation', 'circuit', 'construction', 'prepare', 'ghz', 'state', 'constant', 'quantum', 'depth', 'b', 'multiplycontrolled', 'cyclic', 'permutation', 'constant', 'quantum', 'depth', 'c', 'explicit', 'circuit', 'description', 'implementation', 'multivariate', 'trace', 'estimation', 'twodimensional', 'architecture', 'guarantee', 'estimator', 'vi', 'application', 'method', 'vii', 'conclusion', 'acknowledgment', 'reference', 'proof', 'faithfulness', 'datum', 'processing', 'task', 'estimate', 'quantity', 'trρ1', 'multivariate', 'trace', 'copy', 'give', 'access', 'quantum', 'state', 'ρ1', 'fundamental', 'building', 'block', 'information', 'science', 'subroutine', 'call', 'multivariate', 'trace', 'estimation', 'open', 'door', 'esti', 'mate', 'nonlinear', 'function', 'quantum', 'quantum', 'distinguishability', 'measure', 'integer', 'r´enyi', 'entropy', 'entanglement', 'measure', 'mation', 'procedure', 'component', 'many', 'quantum', 'pro', 'tocol', 'quantum', 'ﬁngerprinte', 'digital', 'signature', 'eq', 'impor', 'tant', 'application', 'multivariate', 'trace', 'estimation', 'entanglement', 'spectroscopy', 'deduce', 'full', 'set', 'eigenvalue', 'λd', 'spectrum', 'reduce', 'state', 'bipartite', 'pure', 'state', 'trbψab', 'bipartite', 'pure', 'state', 'spectrum', 'unlock', 'wealth', 'information', 'property', 'small', 'eigenvalue', 'diagnosis', 'separable', 'entangle', 'addition', 'inverse', 'small', 'eigenvalue', 'act', 'condition', 'number', 'many', 'quantum', 'algorithm', 'manipulate', 'quantum', 'state', 'see', 'instance', 'constrain', 'runtime', 'entanglement', 'spectrum', 'also', 'use', 'ful', 'identify', 'topological', 'order', 'emergent', 'irre', 'versibility', 'quantum', 'phase', 'transition', 'determine', 'system', 'obey', 'area', 'law', 'wealth', 'application', 'describe', 'much', 'interest', 'bring', 'multivariate', 'trace', 'mation', 'reach', 'nearterm', 'hardware', 'glimmer', 'hope', 'regard', 'observation', 'quantitie', 'eq', 'estimate', 'need', 'full', 'state', 'tomography', 'quantum', 'information', 'progenitor', 'line', 'thinking', 'ref', 'propose', 'method', 'leverage', 'follow', 'e', 'wellknown', 'identity', 'relate', 'trick', 'orig', 'inate', 'spin', 'glass', 'theory', '⊗', '⊗', 'trρ1', 'righthandside', 'multivariate', 'trace', 'like', 'estimate', 'unitary', 'representa', 'tion', 'cyclic', 'shift', 'permutation', 'represent', 'cyclic', 'permutation', 'send', 'forth', 'say', 'multivariate', 'trace', 'estimation', 'accomplish', 'estimate', 'real', 'imaginary', 'part', 'cyclic', 'shift', 'operator', 'use', 'quantum', 'hardware', 'identity', 'subsequently', 'come', 'backbone', 'many', 'proposal', 'multivariate', 'trace', 'estimation', 'nearterm', 'constraint', 'however', 'appear', 'lack', 'clar', 'ity', 'regard', 'actual', 'resource', 'requirement', 'mul', 'tivariate', 'trace', 'estimation', 'ref', 'suggest', 'quantum', 'circuit', 'depth', 'linear', 'need', 'perform', 'task', 'paper', 'show', 'overly', 'conservative', 'characterization', 'multivariate', 'trace', 'estima', 'tion', 'implement', 'constant', 'quantum', 'depth', 'linearlymany', 'control', 'twoqubit', 'gate', 'linear', 'amount', 'classical', 'preprocessing', 'invoke', 'idea', 'correction', 'construct', 'circuit', 'achieve', 'claim', 'section', 'show', 'cir', 'cuit', 'implement', 'highly', 'parallelize', 'way', 'twodimensional', 'architecture', 'similar', 'iv', 'prove', 'theorem', 'statistical', 'guar', 'antee', 'result', 'estimator', 'section', 'show', 'method', 'ﬁnd', 'application', 'estimate', 'trace', 'wellbehave', 'polynomial', 'function', 'density', 'matrix', 'section', 'vi', 'prepare', 'qubit', 'adjoin', 'state', 'ρ1', '⊗', '⊗', 'state', 'perform', 'control', 'cyclic', 'permutation', 'unitary', 'gate', 'deﬁne', '⊗', '⊗', 'measure', 'ﬁrst', 'qubit', 'basis', '−cid105', 'record', 'come', 'outcome', 'observe', '−1', 'second', 'outcome', '−cid105', 'observe', 'repeat', 'step', 'number', 'time', 'equal', 'return', 'outcome', 'repetition', 'step', 'know', 'retrρ1', 'thus', 'ˆx', 'compute', 'step', 'empirical', 'estimate', 'desire', 'quantity', 'invoke', 'well', 'known', 'hoeﬀde', 'inequality', 'guarantee', 'retrρ1', '≥', 'completeness', 'recall', 'hoeﬀde', 'inequality', 'hoeﬀding', 'suppose', 'give', 'independent', 'sample', 'y1', 'bound', 'random', 'variable', 'take', 'value', 'b', 'mean', 'set', 'sample', 'mean', 'let', 'desire', 'curacy', 'let', '−', 'δ', 'desire', 'success', 'probability', 'prcid2cid12', 'cid12y', '−', 'µcid12', 'εcid3', '≥', '−', 'δ', 'long', 'principle', 'use', 'cyclic', 'shift', 'multivariate', 'trace', 'estimation', 'n', '≥', '2ε2', 'principle', 'circuit', 'construction', 'simple', 'explain', 'let', 'ﬁrst', 'recall', 'well', 'know', 'circuit', 'con', 'struction', 'multivariate', 'trace', 'estimation', 'clear', 'realization', 'nearterm', 'quantum', 'computer', 'idea', 'estimate', 'quantity', 'retrρ1', 'ρm', 'imtrρ1', 'separately', 'circuit', 'estimate', 'quantity', 'similar', 'describe', 'estimate', 'real', 'part', 'retrρ1', 'proceed', 'accord', 'follow', 'step', 'see', 'eq', 'hold', 'note', 'special', 'case', 'state', 'pure', 'ψicid105cid104ψi', 'input', 'circuit', 'mpartite', 'purestate', 'ψ1cid105', '⊗', '⊗', 'ψmcid105', 'cid104', '⊗', 'πψmcid105', 'cid17cid13', 'cid107ψmcid105', 'prepare', 'ghz', 'state', 'constant', 'quantum', 'depth', 'retrw', 'retrρ1', 'last', 'equality', 'use', 'wellknown', 'identity', 'eq', 'similarly', '−', 'retrρ1', 'prx', 'retrρ1', 'eq', 'assert', 'conclusion', 'eq', 'still', 'hold', 'ρi', 'mixed', 'state', 'follow', 'convexity', 'mixed', 'state', 'write', 'convex', 'combination', 'pure', 'state', 'estimate', 'second', 'quantity', 'imtrρ1', 'ρm', 'simple', 'variation', 'argument', 'suﬃce', 'technique', 'identical', 'ﬁnal', 'measure', 'ment', 'basis', '−y', 'cid105', 'circuit', 'construction', 'propose', 'variation', 'method', 'stead', 'estimate', 'trρ1', 'ρm', 'constant', 'quantum', 'depth', 'make', 'circuit', 'amenable', 'run', 'near', 'term', 'quantum', 'processor', 'circuit', 'depict', 'similarity', 'method', 'error', 'correction', 'faulttolerant', 'quantum', 'com', 'putation', 'see', 'also', 'figure', 'crux', 'method', 'replace', 'state', 'single', 'qubit', 'control', 'wire', 'circuit', 'cid98m2cid99party', 'ghz', 'state', 'cid98m2cid99', 'control', 'wire', 'modiﬁcation', 'allow', 'number', 'control', 'permutation', 'increase', 'cid98m2cid99', 'input', 'size', 'turn', 'pave', 'way', 'implementation', 'multivariate', 'trace', 'mation', 'quantum', 'depth', 'use', 'parallelize', 'cswap', 'gate', 'order', 'achieve', 'overall', 'constant', 'quantum', 'depth', 'section', 'show', 'constant', 'quantum', 'depth', 'suﬃce', 'generate', 'input', 'ghz', 'state', 'section', 'b', 'show', 'implement', 'permu', 'tation', 'constant', 'quantum', 'depth', 'finally', 'section', 'c', 'describe', 'full', 'estimator', 'accompany', 'circuit', 'describe', 'method', 'generate', 'ghz', 'state', 'constant', 'quantum', 'depth', 'relate', 'method', 'discuss', 'previously', 'constant', 'depth', 'quantum', 'circuit', 'assist', 'measurement', 'sical', 'feedback', 'logarithmic', 'depth', 'classical', 'circuit', 'see', 'also', 'discussion', 'theorem', 'ond', 'variation', 'ﬁrst', 'additionally', 'allow', 'qubit', 'reset', 'make', 'eﬃcient', 'usage', 'qubit', 'method', 'begin', 'discuss', 'ﬁrst', 'approach', 'generate', 'rparty', 'ghz', 'state', 'use', 'constant', 'depth', 'quantum', 'circuit', 'assist', 'measurement', 'sical', 'feedback', 'logarithmic', 'depth', 'classical', 'circuit', 'proceed', 'accord', 'follow', 'step', 'generate', 'r', 'pair', 'state', 'φcid105', '00cid105', 'perform', 'controllednot', 'gate', 'second', 'qubit', 'ﬁrst', 'qubit', 'follow', 'one', 'apply', 'controllednot', 'qubit', 'qubit', 'r', '−', 'measure', 'target', 'controllednot', 'gate', 'oddnumbere', 'qubit', 'ﬁrst', 'qubit', 'computational', 'basis', 'control', 'measurement', 'outcome', 'b1', 'br−2', 'apply', 'tensor', 'product', 'operator', 'correction', 'evennumbered', 'qubit', 'second', 'qubit', 'apply', 'qubit', 'r', '−', 'procedure', 'prepare', 'rparty', 'ghz', 'state', 'qubit', '−', 'show', 'detail', 'scheme', 'prepare', 'rparty', 'ghz', 'state', 'consider', 'initial', 'state', 'write', 'i1', '⊗', 'step', 'state', 'become', '⊗', 'step', 'r', '−', '2bit', 'string', 'b1', 'obtain', 'measurement', 'b1', 'project', 'state', 'follow', 'state', '⊗', 'b1', '⊗', 'b1', '⊗', '⊗', '⊗', '⊗', '⊗', '⊗', '⊗', '⊗', '\uf8ed', 'x1', 'x1cid105', 'x1cid105', '\uf8f6', 'fig', 'constantdepth', 'quantum', 'circuit', 'prepare', 'eightparty', 'ghz', 'state', 'assist', 'measurement', 'classical', 'feedback', 'qubit', 'reset', 'method', 'consist', 'step', 'depict', 'qubit', 'reset', 'prepare', 'ﬁve', 'party', 'state', 'method', 'measure', 'qubit', 'addition', 'ally', 'reset', '0cid105', 'state', 'connect', 'cnot', 'large', 'eightparty', 'state', 'prepare', 'instead', 'proposition', 'follow', 'decomposition', 'hold', 'rparty', 'ghz', 'state', 'qubit', '−', 'recover', 'perform', 'follow', 'correction', 'operation', '⊗', '⊗', '⊗', '⊗', '⊗', '⊗', '⊗', 'leftmost', 'part', 'figure', 'qubit', 'reset', 'depict', 'procedure', 'method', 'second', 'method', 'similar', 'one', 'describe', 'diﬀerence', 'addi', 'tionally', 'perform', 'qubit', 'reset', 'measure', 'qubit', 'controllednot', 'near', 'neighbor', 'qubit', 'ghz', 'state', 'reset', 'qubit', 'scheme', 'picte', 'figure', 'prepare', 'ghz', 'state', 'number', 'party', 'equal', 'number', 'input', 'qubit', 'hence', 'ghz', 'state', 'oppose', 'rparty', 'ghz', 'state', 'qubit', 'reset', 'multiplycontrolled', 'cyclic', 'permutation', 'constant', 'quantum', 'depth', 'rather', 'implement', 'controlledw', 'π', 'gate', 'stead', 'implement', 'multiplycontrolledw', 'π', 'gate', 'der', 'reduce', 'depth', 'part', 'circuit', 'linear', 'constant', 'implementation', 'multiply', 'controlledw', 'π', 'gate', 'constant', 'depth', 'base', 'observation', 'particularly', 'convenient', 'way', 'decompose', 'cyclic', 'shift', 'product', 'transposi', 'tion', 'show', 'eq', 'state', 'observation', 'brief', 'proof', 'complete', 'ness', 'even', '−', 'l', 'cid98m2cid99', 'cid89', 'odd', 'arithmetic', 'modulo', 'instance', 'case', 'figure', 'eq', 'read', 'proof', 'even', 'ﬁrst', 'transposition', 'send', 'send', 'ﬁrst', 'transposition', 'act', 'second', 'transposition', 'otherwise', 'second', 'transposition', 'send', '−', 'overall', 'eﬀect', 'send', 'desire', 'odd', 'index', 'involve', 'transposition', 'send', 'ﬁrst', 'transposition', 'act', 'second', 'transposition', 'transpose', 'second', 'transposition', 'send', 'index', 'involve', 'transposition', 'describe', 'thus', 'overall', 'eﬀect', 'also', 'h', 'h', 'h', 'prepare', 'cid98m2cid99party', 'ghz', 'state', 'use', 'constant', 'quantumdepth', 'circuit', 'construction', 'describe', 'previous', 'section', 'let', 'call', 'cid98m2cid99', 'qubit', 'ghz', 'state', 'control', 'qubit', '⊗', '⊗', 'target', 'qubit', 'implement', 'multiplycontrolle', 'cyclic', 'shift', 'even', 'adjoin', 'ρ1', 'ghz', 'state', 'order', 'ρ1', '⊗', '⊗', '⊗', '⊗', 'ρ3', '⊗', '⊗', '⊗', '⊗', 'perform', 'controlledswap', 'gate', 'qubit', 'target', 'qubit', '−', '2i', 'form', 'controlledswap', 'qubit', 'target', 'qubit', '2i', '2i', 'm2', 'odd', 'adjoin', 'ρ1', 'ρm', 'ghz', 'state', 'order', 'perform', 'controlledswap', 'gate', 'qubit', 'target', 'qubit', '−', '2i', 'cid98m2cid99', 'form', 'controlledswap', 'qubit', 'target', 'qubit', '2i', '2i', 'cid98m2cid99', 'check', 'prescription', 'implement', 'precisely', 'eq', 'state', 'adjoin', 'speciﬁc', 'order', 'see', 'eq', 'eq', 'allow', 'near', 'neighbor', 'swap', 'perform', 'hadamard', 'cid98m2cid99', 'control', 'qubit', 'measure', 'computational', 'basis', 'ceive', 'outcome', 'eﬀect', 'perform', 'measurement', 'x', 'basis', 'control', 'qubit', 'let', 'denote', 'result', 'measurement', 'cid98m2cid99', 'set', 'r', '−1', 'repeat', 'step', 'number', 'time', 'equal', 'compute', 'output', 'step', 'application', 'circuit', 'estimate', 'retrρ1', 'estimate', 'imtrρ1', 'repeat', 'step', 'step', 'replace', 'hadamard', 'phase', 'gate', 'measurement', 'computational', 'basis', 'eﬀect', 'perform', 'measurement', 'basis', 'control', 'qubit', 'let', 'outcome', 'measurement', 'fig', 'leftmost', 'part', 'circuit', 'prepare', 'fourparty', 'ghz', 'state', 'middle', 'part', 'circuit', 'perform', 'con', 'troll', 'cyclicshift', 'ﬁnal', 'part', 'circuit', 'result', 'classical', 'bit', 'use', 'generate', 'r', 'argue', 'section', 'expecta', 'tion', 'r', 'equal', 'retrρ1', 'latter', 'quan', 'tity', 'estimate', 'repetition', 'say', 'ﬁxed', 'mwise', 'cyclic', 'shift', 'permutation', 'decompose', 'product', 'term', 'term', 'product', 'disjoint', 'position', 'index', 'transpose', 'term', 'clear', 'interpretation', 'term', 'construct', 'quantum', 'circuit', 'implement', 'multiply', 'controlledw', 'π', 'transpose', 'qubit', 'label', 'achieve', 'apply', 'swap', 'gate', 'relevant', 'qubit', 'disjoint', 'transposition', 'thus', 'accomplish', 'plemente', 'swap', 'gate', 'parallel', 'single', 'time', 'step', 'proposition', 'thus', 'imply', 'multiplycontrolledw', 'π', 'implement', 'time', 'step', 'depth', 'perform', 'cid98m2cid99', 'con', 'trolled', 'swap', 'parallel', 'give', 'explicit', 'description', 'circuit', 'next', 'subsection', 'note', 'depict', 'figure', 'make', 'optimization', 'nearterm', 'feasibility', 'adjoin', 'input', 'state', 'cyclic', 'shift', 'speciﬁc', 'order', 'ensure', 'nearestneighbor', 'state', 'need', 'swap', 'c', 'explicit', 'circuit', 'description', 'put', 'together', 'ﬁnding', 'previous', 'subsection', 'describe', 'propose', 'technique', 'esti', 'mate', 'trρ1', 'ρm', 'case', 'local', 'dimension', 'ρi', 'singlequbit', 'state', 'corre', 'depict', 'figure', 'discuss', 'generalize', 'construction', 'case', 'power', 'local', 'system', 'con', 'sist', 'multiple', 'qubit', 'estimator', 'work', 'follow', 'h', 'h', 'h', 'x1', 'qubit', 'application', 'circuit', 'set', 'j1', 'estimate', 'imtrρ1', 'compute', 'i1', 'output', 'ˆj', 'propose', 'architecture', 'highly', 'ﬂexible', 'tailor', 'availability', 'resource', 'long', 'coherence', 'time', 'multiqubit', 'gate', 'evident', 'way', 'firstly', 'smoothly', 'trade', 'width', 'availability', 'entangle', 'gate', 'extreme', 'observe', 'implement', 'circuit', 'control', 'qubit', 'instead', 'disposal', 'highlyentangling', 'gate', 'singlequbit', 'control', 'simul', 'taneous', 'swap', 'gate', 'swap', 'cid98m2cid99', 'pair', 'qubit', 'simultaneously', 'gate', 'feasible', 'near', 'term', 'require', 'highly', 'nonlocal', 'interaction', 'implement', 'real', 'physical', 'architecture', 'however', 'even', 'gate', 'entangle', 'subset', 'qubit', 'aﬀord', 'ing', 'additional', 'control', 'swap', 'gate', 'disposal', 'allow', 'reduction', 'width', 'control', 'qubit', 'necessary', 'hence', 'ghz', 'state', 'need', 'k', 'party', 'secondly', 'generalize', 'trρ1ρ2', 'singlequbit', 'increase', 'width', 'depth', 'circuit', 'describe', 'suppose', 'ρ1', 'consist', 'p', 'qubit', 'estimation', 'state', '•', 'increase', 'width', 'circuit', 'prepar', 'ing', 'ghz', 'state', 'qubit', 'group', 'p', 'group', 'qubit', 'correspond', 'ingly', 'group', 'p', 'group', 'qubit', 'kth', 'group', 'kth', 'qubit', 'state', 'p', 'form', 'control', 'swap', 'detailed', 'group', 'finally', 'perform', 'hadamard', 'mp', 'control', 'qubit', 'measure', 'computational', 'basis', 'increase', 'depth', 'circuit', 'prepare', 'party', 'ghz', 'state', 'sequentially', 'perform', 'controlledswap', 'test', 'p', 'group', 'qubit', 'depth', 'circuit', 'increase', 'factor', 'p', 'measure', 'control', 'qubit', 'iv', 'implementation', 'multivariate', 'trace', 'estimation', 'twodimensional', 'architecture', 'ghz', 'state', 'preparation', 'depict', 'figure', 'tion', 'step', 'give', 'caption', 'figure', 'main', 'point', 'highlight', 'circuit', 'lead', 'highly', 'parallelize', 'implementation', 'twodimensional', 'architecture', 'make', 'amenable', 'real', 'ization', 'nearterm', 'quantum', 'computer', 'guarantee', 'estimator', 'section', 'show', 'estimator', 'ˆt', 'describe', 'section', 'accurate', 'precise', 'high', 'proba', 'bility', 'theorem', 'ρ1', 'singlequbit', 'state', 'exist', 'random', 'variable', 'ˆt', 'compute', 'repetition', 'constantdepth', 'quan', 'consist', 'threequbit', 'gate', 'sit', 'ˆt', '−', 'trρ1', '≥', 'proof', 'hoeﬀde', 'inequality', 'see', 'suﬃce', 'prove', 'estimator', 'ˆt', 'output', 'method', 'section', 'c', 'satisﬁes', 'e', '⊗', '⊗', 'trρ1', 'suﬃce', 'prove', 'ﬁrst', 'equality', 'begin', 'let', 'suppose', 'simplicity', 'state', 'pure', 'ψicid105cid104ψi', 'deﬁne', 'state', 'target', 'qubit', 'ψ1cid105', '⊗', '⊗', 'ψmcid105', 'step', 'procedure', 'prepare', 'ghz', 'state', 'φcid98m2cid99', 'ghz', 'adjoin', 'ψmcid105', 'overall', 'state', 'end', 'step', 'φcid98m2cid99', 'ghz', 'cid105ψmcid105', 'step', 'multiplycontrolle', 'cyclic', 'shift', 'overall', 'state', 'become', '1cid105⊗cid98m2cid99w', 'πψmcid105', 'step', 'measure', 'cid98m2cid99', 'control', 'qubit', 'x', 'basis', 'obtain', 'cid98m2cid99bitstring', 'bit', 'denote', 'random', 'variable', 'compute', 'expectation', 'random', 'variable', 'output', 'real', 'part', 'estimator', 'outline', 'implement', 'use', 'twodimensional', 'architecture', 'similar', 'mean', 'series', 'ﬁgure', 'outline', 'time', 'step', 'circuit', 'implementation', 'see', 'figure', 'ﬁgure', 'understand', 'twodimensional', 'implementation', 'circuit', 'depict', 'figure', 'exception', 'also', 'include', 'qubit', 'reset', 'cid80cid98m2cid99', 'introduce', 'follow', 'notation', 'basis', 'tor', 'fig', 'square', 'light', 'grey', 'represent', 'control', 'qubit', 'square', 'dark', 'grey', 'represent', 'data', 'qubit', 'example', 'ﬁve', 'datum', 'state', 'involve', 'consist', 'qubit', 'quantum', 'datum', 'load', 'stage', 'note', 'conduct', 'parallel', 'preparation', 'ghz', 'state', 'control', 'qubit', 'state', 'ρi', 'fourqubit', 'state', 'occupy', 'indicate', 'column', 'datum', 'qubit', 'dark', 'grey', 'light', 'grey', 'control', 'qubit', 'prepare', 'zero', 'state', 'first', 'step', 'preparation', 'ghz', 'state', 'control', 'qubit', 'control', 'qubit', 'hadamard', 'gate', 'apply', 'parallel', 'pair', 'control', 'qubit', 'cnot', 'gate', 'apply', 'parallel', 'pair', 'control', 'qubit', 'cnot', 'gate', 'apply', 'parallel', 'start', 'third', 'control', 'qubit', 'top', 'leave', 'control', 'qubit', 'measure', 'measurement', 'outcome', 'store', 'binary', 'vector', 'b1', 'base', 'measurement', 'outcome', 'previous', 'step', 'paulix', 'correction', 'apply', 'qubit', 'start', 'fourth', 'top', 'row', 'particular', 'correction', 'need', 'abbreviate', 'multivariate', 'function', 'detail', 'available', 'eq', 'measure', 'qubit', 'reset', 'zero', 'state', 'final', 'step', 'preparation', 'ghz', 'state', 'control', 'qubit', 'cnot', 'gate', 'apply', 'control', 'qubit', 'ﬁnal', 'state', 'control', 'qubit', 'equal', 'ghz', 'state', 'controlledswap', 'apply', 'parallel', 'control', 'qubit', 'datum', 'qubit', 'ﬁrst', 'round', 'implementation', 'cyclic', 'shift', 'controlledswap', 'apply', 'parallel', 'control', 'qubit', 'datum', 'qubit', 'second', 'round', 'implementation', 'cyclic', 'shift', 'ﬁnal', 'step', 'control', 'qubit', 'measure', 'computational', 'basis', 'measurement', 'outcome', 'process', 'accord', 'eq', 'form', 'estimate', 'real', 'part', 'trρ1', 'estimate', 'imaginary', 'part', 'replace', 'h', 'step', 'gif', 'entire', 'procedure', 'view', 'hadamard', 'gate', 'apply', 'control', 'qubit', 'load', 'datum', 'ρ4', 'ghz', 'preparation', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'ghz', 'preparation', 'ghz', 'preparation', 'ghz', 'preparation', 'ghz', 'preparation', 'ghz', 'preparation', 'ghz', 'preparation', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'h', 'probability', 'basis', 'measurement', 'output', 'bitstring', 'x1', 'give', 'cid0cid104cid102x1', 'cid94xcid98m2cid99', '⊗', 'icid1', '×', 'cid00cid105⊗cid98m2cid99ψmcid105', 'πψmcid105cid1', 'cid13ψmcid105', '−1', 'i1', 'xiw', 'πψmcid105', 'thus', '−1', 'πψmcid105cid104ψm', '×', 'cid80cid98m2cid99', 'i1', 'i1', 'πψmcid105cid104ψm', 'πψmcid105cid104ψm', 'secondtolast', 'equality', 'use', 'fact', 'l', 'claim', 'mixed', 'state', 'ρ1', '⊗', '⊗', 'retrw', 'πρm', 'follow', 'convexity', 'mixed', 'state', 'write', 'convex', 'combination', 'pure', 'state', 'use', 'fact', 'case', 'repeat', 'calculation', 'eigenvector', 'use', 'similar', 'chain', 'logic', 'conclude', 'imtrw', 'πρm', 'ﬁrst', 'equality', 'follow', 'also', 'compute', 'variance', 'consider', 'e', '−', 'e', '−', 'e', 'conclude', 'retrw', 'πρm2', 'sim', 'ilarly', '−', 'imtrw', 'πρm2', 'random', 'variable', 'independent', 'var', 'cid12trw', 'πρm', 'discuss', 'generalization', 'state', 'qubit', 'generalization', 'accomplish', 'increase', 'circuit', 'width', 'circuit', 'depth', 'discuss', 'section', 'c', 'proposition', 'let', 'ρ1', 'set', 'pqubit', 'state', 'exist', 'ran', 'dom', 'variable', 'ˆtp', 'compute', 'use', 'repetition', 'constantdepth', 'quantum', 'circuit', 'consist', 'omp', 'threequbit', 'gate', 'satisﬁes', 'trρ1', '≥', 'proof', 'gate', 'count', 'circuit', 'con', 'struction', 'detail', 'section', 'omp', 'second', 'construction', 'increase', 'depth', 'eq', 'low', 'exact', 'calculation', 'proof', 'theorem', 'ﬁrst', 'construction', 'increase', 'width', 'let', 'deﬁne', 'ρ1', '⊗', '⊗', 'suﬃce', 'prove', 'estimator', 'rive', 'mp', 'measurement', 'fulﬁls', 'retrw', 'πρmp', 'follow', 'similar', 'calculation', 'eq', 'similarly', 'cid12trw', 'πρmp', 'vi', 'application', 'method', 'application', 'method', 'estimate', 'function', 'density', 'matrix', 'approximate', 'well', 'behave', 'polynomial', 'already', 'suggest', 'original', 'work', 'complexity', 'analysis', 'put', 'forth', 'formalize', 'analysis', 'application', 'follow', 'let', 'quantum', 'state', 'rank', 'suppose', 'exist', 'constant', 'ε', 'function', 'c', 'r', 'r', 'approximate', 'degreem', 'poly', 'nomial', 'ckxk', 'interval', 'sense', 'let', 'ε2', 'ln', 'estimate', 'trgρ', 'ε', 'additive', 'error', 'success', 'probability', 'small', '−', 'δ', 'require', 'copy', 'run', 'circuit', 'control', 'swap', 'gate', 'ε2', 'log', 'log', 'think', 'slowlygrowing', 'function', 'example', 'function', 'quantum', 'state', 'estimate', 'way', 'follow', 'expansion', 'binomial', 'series', '∞', 'k', 'cid1', 'generalize', 'binomial', 'coeﬃcient', 'well', 'known', 'binomial', 'series', 'converge', 'absolutely', 'imply', 'exist', 'positive', 'constant', 'cα', 'cid18α', '∞', 'cid18α', 'cα', 'thus', 'serie', 'satisﬁes', 'criterion', 'eq', 'function', 'quantum', 'state', 'estimate', 'way', 'indeed', 'function', 'follow', 'well', 'know', 'expansion', 'lnx', '∞', 'k', 'repeat', 'ﬁrst', 'step', '−', 'time', 'iteration', 'output', 'random', 'variable', 'ri', 'output', 'n', 'i1', 'ri', 'estimator', 'let', 'prove', 'correctness', 'procedure', 'suppose', 'spectral', 'decomposition', 'follow', 'rank', 'ρ', 'limit', '∞', 'error', 'estimator', 'ˆg', 'come', 'error', 'polynomial', 'approximation', 'trgρ', '−', 'i1', 'ε2', 'ckλk', 'cid33cid12', 'inequality', 'follow', 'eq', 'fact', 'rρ', 'account', 'source', 'error', 'statistical', 'error', 'cause', 'take', 'ﬁnite', 'number', 'sample', 'consider', 'ckrk', 'k', 'absolute', 'partial', 'sum', 'coeﬃcient', 'sit', 'γ', 'euler', 'mascheroni', 'constant', 'point', 'even', 'absolute', 'partial', 'sum', 'bound', 'constant', 'still', 'grow', 'suﬃciently', 'slowly', 'run', 'eﬃciently', 'proof', 'theorem', 'present', 'estimator', 'desire', 'quantity', 'satisﬁes', 'claim', 'complexity', 'guarantee', 'let', 'describe', 'estimator', 'retrgρ', 'estimator', 'imaginary', 'part', 'follow', 'immedi', 'ately', 'estimate', 'retrgρ', 'run', 'follow', 'procedure', 'run', 'circuit', 'describe', 'step', 'section', 'c', 'output', 'random', 'variable', 'rk', '∈', 'ﬁrst', 'inequality', 'follow', 'triangle', 'inequality', 'second', 'fact', 'rk', 'third', 'assumption', 'apply', 'hoeﬀde', 'inequality', 'immediately', 'apply', 'setting', 'take', 'b', '−c', 'c', 'also', 'see', 'set', 'get', 'pr', 'ˆg', '−', 'ck', 'trρk', 'δ', 'combine', 'source', 'error', 'eq', 'get', 'probability', '−', 'δ', 'linearly', 'combine', 'random', 'variable', 'retrgρ', 'form', 'new', 'random', 'variable', 'ckrk', 'ˆg', '−', 'retrgρ', '−', 'ck', 'trρk', 'ε', 'repeat', 'analysis', 'estimation', 'imtrgρ', 'yield', 'stated', 'complexity', 'remark', 'alternative', 'way', 'estimate', 'trρk', 'use', 'method', 'classical', 'shadow', 'obtain', 'classical', 'snapshot', 'ρ', 'linearly', 'combine', 'obtain', 'classical', 'random', 'variable', 'expectation', 'trρk', 'see', 'supplementary', 'material', 'section', 'however', 'unclear', 'method', 'oﬀer', 'saving', 'quantum', 'resource', 'quire', 'total', 'number', 'time', 'need', 'run', 'datum', 'acquisition', 'phase', 'scale', 'variance', 'correspond', 'estimator', 'know', 'concise', 'expression', 'variance', 'indeed', 'calculate', 'single', 'value', 'require', 'page', 'calculation', 'also', 'wonder', 'use', 'ap', 'proach', 'estimate', 'state', 'main', 'diﬃculty', 'well', 'know', 'polynomial', 'approximation', 'function', 'xα', '−x', 'ln', 'give', 'respectively', '∞', '∞', '∞', '∞', 'k1', '∞', 'satisfy', 'condition', 'sense', 'absolute', 'partial', 'sum', 'grow', 'quickly', 'therefore', 'lead', 'eﬃcient', 'use', 'approach', 'see', 'also', 'context', 'thus', 'remain', 'open', 'approach', 'use', 'eﬀectively', 'estimate', 'important', 'uncertainty', 'measure', 'see', 'work', 'topic', 'ﬁeld', 'classical', 'information', 'theory', 'ﬂurry', 'recent', 'eﬀort', 'estimate', 'entropy', 'use', 'quantum', 'computer', 'propose', 'alternative', 'approach', 'note', 'method', 'outline', 'generalize', 'function', 'multiple', 'density', 'matrix', 'example', 'let', 'quantum', 'state', 'suppose', 'g1', 'g2', 'well', 'behaved', 'polynomial', 'sense', 'describe', 'employ', 'similar', 'approach', 'estimate', 'function', 'trg1σ12ρσ12', 'polynomial', 'approximation', 'function', 'take', 'following', 'form', 'cid34cid32', 'tr', 'ckρk', 'kcid96', 'ckdcid96', 'trρkσcid96', 'respectively', 'estimate', 'use', 'circuit', 'com', 'bin', 'classical', 'postprocessing', 'thus', 'cussion', 'theorem', 'take', 'g1x', 'xβ', 'case', 'interest', 'set', '−', 'result', 'function', 'satisﬁes', 'faithfulness', 'dataprocesse', 'inequality', 'unital', 'nel', 'thus', 'serve', 'alternative', 'widely', 'use', 'hilbert', 'schmidt', 'distance', 'measure', 'also', 'sit', 'isﬁes', 'dataprocesse', 'inequality', 'unital', 'nel', 'prove', 'claim', 'vii', 'conclusion', 'provide', 'quantum', 'circuit', 'multivariate', 'trace', 'estimation', 'require', 'constant', 'quantum', 'depth', 'hence', 'amenable', 'implement', 'nearterm', 'quantum', 'computer', 'previous', 'meth', 'od', 'require', 'linear', 'depth', 'architecture', 'also', 'ﬂexible', 'smoothly', 'tailor', 'availability', 'circuit', 'width', 'cost', 'moreentangle', 'gate', 'go', 'forward', 'far', 'consider', 'application', 'method', 'estimate', 'nonlinear', 'func', 'tion', 'quantum', 'state', 'important', 'applica', 'tion', 'computer', 'design', 'well', 'computer', 'method', 'use', 'purpose', 'method', 'estimate', 'function', 'quantum', 'state', 'base', 'polynomial', 'approximation', 'open', 'door', 'idea', 'nearterm', 'quantum', 'computer', 'use', 'design', 'well', 'quantum', 'computer', 'important', 'open', 'question', 'regard', 'function', 'polynomial', 'approximation', 'fulﬁll', 'terpretation', 'quality', 'metric', 'quantum', 'computer', 'design', 'conversely', 'also', 'interesting', 'ex', 'plore', 'far', 'quantum', 'state', 'guishability', 'measure', 'critical', 'application', 'compile', 'state', 'learn', 'fulﬁll', 'condition', 'acknowledgment', 'acknowledge', 'helpful', 'discussion', 'cole', 'andr´as', 'gily´en', 'holme', 'aliza', 'anna', 'mmw', 'acknowledge', 'support', 'national', 'science', 'nsf', 'grant', 'yq', 'acknowledge', 'support', 'qfarm', 'fellowship', 'nus', 'overseas', 'graduate', 'scholar', 'ship', 'artur', 'moura', 'alve', 'michacid32l', 'direct', 'estimation', 'linear', 'nonlinear', 'functional', 'quantum', 'state', 'physical', 'review', 'letter', 'todd', 'brun', 'measure', 'polynomial', 'function', 'state', 'information', 'computation', '45401–408', 'phy', 'letter', 'quantum', 'ﬁngerprinte', 'troyer', 'entanglement', 'spectroscopy', 'quantum', 'computer', 'physical', 'review', 'b', 'pawecid32l', 'artur', 'ekert', 'method', 'di', 'rect', 'detection', 'view', 'letter', 'arxivquant', 'signature', 'linear', 'system', 'equation', 'physical', 'review', 'letter', 'value', 'transformation', 'improvement', 'trix', 'arithmetic', 'proceeding', '51st', 'theory', 'compute', 'page', 'exponential', 'marvian', 'petz', 'recovery', 'channel', 'pretty', 'good', 'measurement', 'physical', 'review', 'letter', 'masaki', 'entanglement', 'spectrum', 'topological', 'phase', 'dimension', 'physical', 'review', 'b', 'hong', 'tropy', 'entanglement', 'spectrum', 'review', 'letter', 'lukasz', 'spectrum', 'topological', 'insulator', 'superconductor', 'physical', 'review', 'letter', 'entanglement', 'spectrum', 'generalization', 'entanglement', 'identiﬁcation', 'topological', 'order', 'nonabelian', 'eﬀect', 'state', 'physical', 'review', 'letter', 'claudio', 'chamon', 'eduardo', 'r', 'irreversibility', 'entangle', 'physical', 'review', 'letter', 'ment', 'spectrum', 'statistic', 'emergent', 'sanpera', 'entanglement', 'spectrum', 'critical', 'exponent', 'order', 'parameter', 'quantum', 'spin', 'chain', 'physical', 'review', 'let', 'ter', 'area', 'law', 'entanglement', 'view', 'modern', 'physic', 'mezard', 'g', 'parisi', 'spin', 'glass', 'ory', 'world', 'yirka', 'suba¸sı', 'qubiteﬃcient', 'entangle', 'ment', 'spectroscopy', 'use', 'qubit', 'reset', 'suba¸sı', 'lukasz', 'cincio', 'patrick', 'cole', 'tanglement', 'spectroscopy', 'depthtwo', 'quantum', 'cir', 'cuit', 'journal', 'physics', 'mathematical', 'theoreti', 'cal', 'computation', 'proceeding', '37th', 'annual', 'symposium', 'tion', 'computer', 'science', 'foc', 'page', 'ieee', 'computer', 'society', 'wassily', 'hoeﬀde', 'probability', 'inequality', 'sum', 'bound', 'random', 'variable', 'journal', 'daniel', 'introduction', 'quantum', 'ror', 'correction', 'faulttolerant', 'quantum', 'computation', 'quantum', 'information', 'science', 'contribution', 'mathematic', 'proceeding', 'symposia', 'apply', 'math', 'ematic', 'bene', 'avishay', 'tal', 'exponential', 'separation', 'shallow', 'quantum', 'circuit', 'unbounded', 'fanin', 'shallow', 'classi', 'proceeding', '51st', 'annual', 'acm', 'cal', 'circuit', 'sigact', 'symposium', 'theory', 'compute', 'stoc', 'page', 'sociation', 'compute', 'machinery', 'zhenning', 'alexandru', 'gheorghiu', 'deptheﬃcient', 'proof', 'quantumness', 'markus', 'error', 'correcting', 'code', 'quantum', 'shift', 'register', 'proceeding', 'royal', 'society', 'mathematical', 'physical', 'engineering', 'science', 'frank', 'arute', 'kunal', 'arya', 'barend', 'rupak', 'biswa', 'boixo', 'buell', 'humble', 'kostritsa', 'lucero', 'ofer', 'tby', 'andre', 'sink', 'amit', 'vainsencher', 'villalonga', 'theodore', 'white', 'jamie', 'supremacy', 'e', 'programmable', 'superconducte', 'processor', 'nature', 'predict', 'many', 'property', 'quantum', 'system', 'measurement', 'nature', 'physics', 'fedja', 'answer', 'stack', 'exchange', 'post', 'tsachy', 'weissman', 'minimax', 'estimation', 'functional', 'discrete', 'distribution', 'ieee', 'transaction', 'information', 'ory', 'rate', 'tropy', 'estimation', 'large', 'alphabet', 'good', 'polynomial', 'approximation', 'ieee', 'transaction', 'information', 'ory', 'weissman', 'maximum', 'likelihood', 'estimation', 'function', 'al', 'discrete', 'distribution', 'ieee', 'transaction', 'formation', 'theory', 'jayadev', 'acharya', 'orlitsky', 'tyagi', 'estimate', 'tropy', 'discrete', 'distribution', 'ieee', 'transaction', 'information', 'theory', 'jayadev', 'acharya', 'issa', 'nirmal', 'b', 'wagner', 'estimate', 'quantum', 'entropy', 'ieee', 'journal', 'select', 'area', 'information', 'theory', 'andr´as', 'gily´en', 'distributional', 'prop', 'erty', 'testing', 'quantum', 'world', 'innovation', 'theoretical', 'computer', 'conference', 'itcs', 'volume', 'leibniz', 'ternational', 'proceeding', 'informatic', 'lipic', 'page', 'alessandro', 'tum', 'algorithm', 'spectral', 'sum', 'sathyawageeswar', 'subramanian', 'estimate', 'αrenyi', 'entropy', 'physical', 'review', 'au', 'gust', 'gorithm', 'estimate', 'quantum', 'entropy', 'petz', 'contractivity', 'positive', 'trace', 'preserve', 'map', 'lp', 'norm', 'journal', 'umesh', 'vazirani', 'computational', 'probe', 'hilbert', 'space', 'talk', 'available', 'quote', 'attribute', 'unknown', 'person', 'cincio', 'sornborger', 'patrick', 'cole', 'quantumassiste', 'quantum', 'compile', 'quantum', 'kunal', 'patrick', 'cole', 'noise', 'resilience', 'variational', 'quantum', 'compile', 'new', 'journal', 'physics', 'sing', 'learn', 'e', 'unknown', 'pure', 'quantum', 'state', 'physical', 'review', 'algorithm', 'trace', 'distance', 'ﬁdelity', 'estimation', 'quantum', 'science', 'technol', 'ogy', 'd´ene', 'petz', 'quasientropie', 'state', 'rim', 'd´ene', 'petz', 'quasientropie', 'ﬁnite', 'quantum', 'system', 'report', 'mathematical', 'physics', 'appendix', 'proof', 'faithfulness', 'datum', 'processing', 'let', 'deﬁne', 'follow', 'measure', 'state', 'σ', 'measure', 'relate', 'follow', 'observe', 'iρ', 'know', 'd1', 'iσ', 'd1', 'a3', 'state', 'ρ', 'σ', 'lower', 'bind', 'follow', 'ρ', 'σ', 'positive', 'semideﬁnite', 'upper', 'bound', 'follow', 'apply', 'h¨older', 'inequality', 'furthermore', 'measure', 'faithful', 'state', 'equal', 'σ', 'satisﬁes', 'dataprocesse', 'inequality', 'qαρcid107σ', 'qαn', 'qαn', 'σ', 'a6', 'channel', 'relation', 'a3', 'conclude', 'property', 'property', 'indeed', 'also', 'measure', 'faithful', 'equal', 'σ', 'see', 'consider', 'iσ', 'd1', 'last', 'equality', 'equivalent', 'thus', 'faithfulness', 'claim', 'follow', 'finally', 'measure', 'obey', 'dataprocesse', 'inequal', 'ity', 'unital', 'quantum', 'channel', 'unital', 'channel', 'kαn', 'ρcid107n', 'σ', 'kαn', 'ρcid107n', 'a10', 'inequality', 'follow', 'dataprocessing', 'equality', 'indeed', 'consider', 'kαn', 'ρcid107n', 'a13', 'a14', 'cid19cid13', 'a11', 'cid19cid19', 'a12', 'second', 'equality', 'follow', 'linearity', 'channel', 'fact', 'unital', 'inequality', 'follow', 'similar', 'reasoning', 'instead', 'make', 'use']"
"Speaker Diarization and Identification from Single-Channel Classroom
  Audio Recording Using Virtual Microphones","[{'href': 'http://arxiv.org/abs/2207.00660v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2207.00660v1', 'rel': 'related', 'type': 'application/pdf'}]",2022-07-01 21:03:50,"Personalized Showcases: Generating Multi-Modal Explanations
for Recommendations
An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley
UC San Diego
La Jolla, CA, USA
{ayan,zhh004,j9li,tiz010,jmcauley}@ucsd.edu

2
2
0
2

n
u
J

0
3

]

R

I
.
s
c
[

1
v
2
2
4
0
0
.
7
0
2
2
:
v
i
X
r
a

ABSTRACT

Existing explanation models generate only text for recommenda-
tions but still struggle to produce diverse contents. In this paper,
to further enrich explanations, we propose a new task named per-
sonalized showcases, in which we provide both textual and visual
information to explain our recommendations. Specifically, we first
select a personalized image set that is the most relevant to a user’s
interest toward a recommended item. Then, natural language ex-
planations are generated accordingly given our selected images.
For this new task, we collect a large-scale dataset from Google Lo-
cal (i.e., maps) and construct a high-quality subset for generating
multi-modal explanations. We propose a personalized multi-modal
framework which can generate diverse and visually-aligned ex-
planations via contrastive learning. Experiments show that our
framework benefits from different modalities as inputs, and is able
to produce more diverse and expressive explanations compared to
previous methods on a variety of evaluation metrics.

1 INTRODUCTION

Personalized explanation generation models have the potential
to increase the transparency and reliability of recommendations.
Previous works [1, 7, 49, 52] considered generating textual explana-
tions from users’ historical reviews, tips [27] or justifications [31].
However, these methods still struggle to provide diverse explana-
tions because a large amount of general sentences (e.g., ‘food is
very good!’) exist in generated explanations and the text gener-
ation models lack grounding information (e.g., images) for their
generation process. To further diversify and enrich explanations
for recommendations, we propose a new explanation generation
task named personalized showcases (shown in Figure 1). In this new
task, we explain recommendations via both textual and visual infor-
mation. Our task aims to provide a set of images that are relevant
to a user’s interest and generate textual explanations accordingly.
Compared to previous works that generate only text as explana-
tions, our showcases present diverse explanations including images
and visually-guided text.

To this end, the first challenge of this task is building a dataset.
Existing review datasets (e.g., Amazon [31] and Yelp1) are largely
unsuitable for this task (we further discuss these datasets in Sec-
tion 3.2). Thus, we first construct a large-scale multi-modal dataset,
namely Gest, which is collected from Google Local2 Restaurants
including review text and corresponding pictures. Then, to improve
the quality of Gest for personalized showcases, we annotate a
small subset to find highly matched image-sentence pairs. Based
on the annotations, we train a classifier with CLIP [36] to extract

1https://www.yelp.com/dataset
2https://www.google.com/maps

Figure 1: Illustration of previous text-only explanation and
our personalized showcases for recommendations. Given a
recommended item or business: (1) Text-only Explanation
models only use historical textual reviews from user and
item sides to generate textual explanations. (2) We propose
a personalized showcases task to enrich the personalized ex-
planations with multi-modal (visual and textual) informa-
tion, which can largely improve the informativeness and di-
versity of generated explanations.

visually-aware explanations from the full dataset. The images and
text explanations from users are used as the learning target for
personalized showcases.

For this new task, we design a new multi-modal explanation
framework. To begin with, the framework selects several images
from historical photos of the business that the user is most in-
terested in. Then, the framework takes the displayed images and
users’ profiles (e.g., historical reviews) as inputs and learns to gen-
erate textual explanations with a multi-modal decoder. However,
generating expressive, diverse and engaging text that will capture
users’ interest remains a challenging problem. First, different from
previous textual explanation generation, the alignment between
multiple images and generated text becomes an important problem
for showcases, which poses higher requirements for information
extraction and fusion across modalities. Second, a typical encoder-
decoder model with a cross-entropy loss and teacher forcing can
easily lead to generating repetitive and dull sentences that occur
frequently in the training corpus (e.g., “food is great”) [18].

To tackle these challenges, we propose a Personalized Cross-
Modal Contrastive Learning (PC2L) framework by contrasting in-
put modalities with output sequences. Contrastive learning has

Recommendations

…

R1: Chinese Food

R2: American Food

R3: Japanese Food

Food is very
delicious!

Burgers are great,
service is good, too.

Great selection of 
beers and delicious 
burgers!

The bread that comes with 
the entree soup is amazing. 
The cheesecake is on point.

Previous:
Text-Only
Explanations
(e.g. Ref2Seq)

Ours:
Personalized
Showcases
(Visual+Textual)

 
 
 
 
 
 
An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley

Figure 2: Example of business and user reviews in Gest. For a business (e.g., an Italian restaurant), Gest contains historical
reviews and images from different users.

drawn attention as a self-supervised representation learning ap-
proach [5, 33]. However, simply training with negative samples in
a mini-batch is suboptimal [23] for many tasks, as the randomly se-
lected embeddings could be easily discriminated in the latent space.
Hence, we first design a cross-modal contrastive loss to enforce the
alignment between images and output explanations, by construct-
ing hard negative samples with randomly replaced entities in the
output. Motivated by the observation that users with similar histori-
cal reviews share similar interests, we further design a personalized
contrastive loss to reweight the negative samples based on their
history similarities. Experimental results on both automatic and
human evaluation show that our model is able to generate more
expressive, diverse and visually-aligned explanations compared to
a variety of baselines.

Overall, our contributions are as follows:

• To generate more informative explanations for recommenda-
tions, we present a new task: personalized showcases which
can provide both textual and visual explanations for recom-
mendations.

• For this new task, we collect a large-scale multi-modal dataset
from Google Local (i.e., maps). To ensure alignment between
images and text, we annotate a small dataset and train a
classifier to propagate labels on Gest, and construct a high-
quality subset for generating textual explanations.

• We propose a novel multi-modal framework for personalized
showcases which applies contrastive learning to improve
diversity and visual alignment of generated text. Comprehen-
sive experiments on both automatic and human evaluation
indicate that textual explanations from our showcases are
more expressive and diverse than existing explanation gen-
eration methods.

2 TASK DEFINITION

In the personalized showcases task, we aim to provide both per-
sonalized textual and visual explanations to explain recommen-
dations for users. Formally, given user 𝑢 ∈ 𝑈 and business (item)
𝑏 ∈ 𝐵, where 𝑈 and 𝐵 are the user set and business set respectively,

the personalized showcases task will provide textual explanations
𝑆 = {𝑠1, 𝑠2, ..., 𝑠𝑚 } and visual explanations 𝐼 = {𝑖1, 𝑖2, ..., 𝑖𝑛 }, where
𝑠 and 𝑖 represent sentences and images in explanations. 𝑆 and 𝐼
are matched with each other and personalized to explain why 𝑏 is
recommended to 𝑢.

To better study the relation between textual and visual expla-
nations and provide baselines for future work, in this paper, we
decompose the task into two steps as shown in Figure 5: (1) Select-
ing an image set as a visual explanation that is relevant to a user’s
interest; (2) Generating textual explanations given the selected
images and a user’s historical reviews.

|𝐼𝑏 |

, 𝑖𝑏
2

, . . . 𝑖𝑏

Formally, given user 𝑢, business 𝑏 and the image candidate set
𝐼𝑏 = {𝑖𝑏
} from 𝑏, we first select a set of images as visual
1
explanations 𝐼 from 𝐼𝑏 which user 𝑢 will be interested in, based
on user 𝑢’s profile (i.e., historical reviews 𝑋𝑢 = {𝑥𝑢
𝐾 }
1
and images 𝐼𝑢 = {𝑖𝑢
, ..., 𝑖𝑢
𝑛 }). Then, we use the user’s historical
1
reviews 𝑋𝑢 and selected images 𝐼 to generate visually-aware textual
explanations 𝑆.

, ..., 𝑥𝑢

, 𝑥𝑢
2

, 𝑖𝑢
2

For our method, we consider the following aspects:

• Accuracy: We aim to predict the target images (i.e., images
associated with the ground-truth review) from business im-
age candidates correctly, and the generated text is expected
to be relevant to the business.

• Diversity: The selected images should be diverse and cover
more information from businesses (e.g., including more dishes
from a restaurant). Textual explanations should be diverse
and expressive.

• Alignment: Unlike previous explanation or review gener-
ation tasks which only use historical reviews or aspects as
inputs, our visually-aware setting provides grounding to the
images. Hence the generated explanations in this new task
should aim to accurately describe the content and cover the
main objects (e.g., the name of dishes, the environment) in
the given set of images.

Amazing! Best Cesar salad I ever 
had and the cake was delicious.

Seafood soup was excellent. Granddaughter 
loved the Spaghetti and meatballs.

I had an excellent experience at this restaurant. 
The ambience is romantic and perfect for a 
couple date night.

An Italian 
Restaurant

User
Reviews

Personalized Showcases: Generating Multi-Modal Explanations for Recommendations

Figure 3: Visual Diversity Comparison. A, B, C, E in Ama-
zon denote different categories of amazon review datasets,
which are uniformly sampled from All, Beauty, Clothing
and Electronics, respectively. Intra-/Inter- User Diversity for
the Yelp dataset is unavailable since Yelp images lack user
information.

3 DATASET
3.1 Dataset Statistics

We collected reviews with images from Google Local. Gest-raw in
Table 1 shows the data statistics of our crawled dataset. We can see
that Gest-raw contains 1,771,160 reviews from 1,010,511 users and
65,113 businesses. Every review has at least one image and the raw
dataset has 4,435,565 image urls.

We processed our dataset into two subsets as (1) Gest-s1 for
personalized image set selection, and (2) Gest-s2 for visually-aware
explanation generation. Statistics of our processed dataset are in Ta-
ble 1, with more processing details in Section 3.3 and Appendix A.

3.2 Visual Diversity Analysis

To distinguish our Gest from existing review datasets and show the
usefulness of personalized showcases, we first define CLIP-based dis-
similarity in three levels to measure the diversity of user-generated
images in each business. Then, we compare the visual diversities
between our Gest data with two representative review datasets,
Amazon Reviews [29, 31] and Yelp.

First, similar to [36, 53], we use the cosine similarity (denoted
as sim) from pre-trained CLIP to define the dis-similarity between
image 𝑖𝑚 and 𝑖𝑛 as dis(𝑖𝑚, 𝑖𝑛) = 1 − sim(𝑖𝑚, 𝑖𝑛). Thus, we introduce
visual diversity in three levels as Intra-Business Div, Inter-User Div
and Intra-User Div, which are formally defined in Appendix B;
higher scores mean more visual diversity.

Then, we investigate the visual diversities for our Gest data
as well as Amazon Reviews (using all categories All (A) and sub-
categories Beauty (B), Clothing (C), Electronics (E)) and Yelp. For
Amazon, we treat each item page as a “business” because reviews
are collected according to items. In our calculation, we sample 5,000
items with more than one user-uploaded image. Note that images
in Yelp dataset do not have user information, so we cannot calculate
user-level diversities for Yelp. From Figure 3, we have the following
observations:

• Diversities within datasets: Figure 3 shows that for Gest
and Amazon, Inter-User Div is the highest and Intra-User Div
is the lowest. It indicates even for the same business (item),
users focus on and present different visual information.

Figure 4: Example of user-generated images from Amazon
from an item page and for Yelp from a business. Amazon
images mainly focus on a single item and Yelp images for a
business are diverse (yet the current public Yelp dataset has
no user-image interactions).

Table 1: Data statistics for Gest. Avg. R. Len. denotes average
review length and #Bus. denotes the number of Businesses.
-raw denotes raw Gest. -s1 denotes Gest data for the first
step, and -s2 denotes Gest data for the second step of our
proposed personalized showcases framework.

Dataset

#Image

#Review

#User

#Bus. Avg. R. Len.

Gest-raw 4,435,565
1,722,296
Gest-s1
203,433
Gest-s2

1,771,160
370,563
108,888

1,010,511
119,086
36,996

65,113
48,330
30,831

36.26
45.48
24.32

• Gest vs. Amazon: In Figure 3, three visual diversities of
Amazon are consistently lower than Gest by a large margin.
We try to explain this by discussing the difference of user
behaviors on these two platforms. As an example in Figure 4,
user-generated images usually focus on the purchased item.
Though the information they want to show differs, there
is usually a single object in an image (i.e., the purchased
item). Thus visual diversity is limited. While for Gest, as
examples in Figure 2 show, reviews on restaurants allow
users to share more diverse information from more varied
items, angles or aspects. Compared with Amazon, using Gest
should generate more informative personalized showcases
according to different user profiles.

• Gest vs. Yelp: Yelp images are high-quality (as an example
in Figure 4) and the intra-business div. is higher (0.44) than
Gest (0.39). Images in Yelp themselves are similar to images
in Gest. However, Yelp images do not fit our task due to the
lack of user information.

3.3 Explanation Distillation

Reviews often contain uninformative text that is irrelevant to the
images, and cannot be used directly as explanations. Hence, we con-
struct an explanation dataset from Gest-raw. We distill sentences
in reviews that align with the content of a given image as valid
explanations. Three annotators were asked to label 1,000 reviews
(with 9,930 image-sentence pairs) randomly sampled from the full
dataset. The task is to decide if a sentence describes a image. Label-
ing was performed iteratively, followed by feedback and discussion,

Intra-Business Div

Inter-User Div

Intra-User Div

0.4

0.2

0.0

GEST

Amazon-A Amazon-B Amazon-C Amazon-E

Yelp

Amazon

Yelp

…

…

An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley

Figure 5: Illustration of our personalized showcases framework for the given business. We take user historical images and tex-
tual reviews as inputs. First, we select an image set that is most relevant to a user’s interest. Then we generate natural language
explanations accordingly with a multi-modal decoder. A cross-modal contrastive loss and a personalized contrastive loss are
applied between each input modality and the explanations. Last, the selected images and generated textual explanations will
be organized as multi-modal explanations to users.

until the quality was aligned between the three annotators. The
annotated image-sentence pairs are then split into train, validation,
and testing with a ratio of 8:1:1.

We then train a binary classification model Φ based on these
annotated image-sentence pairs and their corresponding labels.
Specifically, we extract the embedding of each sentence and image
via CLIP. The two features are concatenated and fed into a fully
connected layer. The classifier achieves an AUC of 0.97 and F-1
score of 0.71 on the test set, where similar results are obtained
in [31] for building a text-only explanation dataset. We use this
model to extract explanations from all reviews. The statistics of the
dataset Gest-s2 can be found in Table 1.

4 METHODOLOGY

In this section, we present our framework of producing personal-
ized showcases. As the overview shows (Figure 5), we start with
personalized image set selection and the visually-aware explanation
generation module, then introduce our personalized cross-modal
contrastive learning approach in Section 4.3.

4.1 Personalized Image Set Selection

The first step is to select an image set as a visual explanation that
is relevant to a user’s interests, and is diverse. We formulate this
selection step as diverse recommendation with multi-modal inputs.
Multi-Modal Encoder. Generally, these user textual- or visual-
profiles can be effectively encoded with different pre-trained deep
neural networks (e.g., ResNet [16], ViT [11], BERT [9]). Here we
choose CLIP [35], a state-of-the-art pre-trained cross-modal re-
trieval model as both textual- and visual-encoders. CLIP encodes
raw images as image features, and encodes user textual- and visual-
profiles as user profile features.
Image Selection Model. We use a Determinantal Point Process
(DPP) method [22] to select the image subset, which has recently

been used for different diverse recommendation tasks [2, 45]. Com-
pared with other algorithms for individual item recommendation,
DPP-based models are suitable for multiple image selection. Given
user 𝑢 and business 𝑏, we predict the image set ˆ𝐼𝑢,𝑏 as follows:

ˆ𝐼𝑢,𝑏 = DPP(𝐼𝑏, 𝑢),
(1)
where 𝐼𝑏 is the image set belonging to business 𝑏. In our design, we
calculate user-image relevance using the CLIP-based user’s profile
features and image features. More details of the model are in [45].

4.2 Visually-Aware Explanation Generation

After obtaining an image set, we aim to generate personalized expla-
nations given a set of images and a user’s historical reviews, with
the extracted explanation dataset Gest-s2 in Section 3.3. Specifically,
we build a multi-modal encoder-decoder model with GPT-2 [37] as
the backbone.
Multi-Modal Encoder. Given a set of user 𝑢’s3 historical reviews
𝑋 = {𝑥1, 𝑥2, . . . , 𝑥𝐾 }, we use the text encoder of CLIP to extract the
review features 𝑅 = {𝑟1, 𝑟2, . . . , 𝑟𝐾 }. Similar operations are applied
to the input images 𝐼 = {𝑖1, 𝑖2, . . . , 𝑖𝑛 }, where we use a pretrained
ResNet to extract the visual features 𝑉 = {𝑣1, 𝑣2, . . . , 𝑣𝑛 }. Those
features are then projected into a latent space:
𝑖 = 𝑊 𝑉 𝑣𝑖, 𝑍 𝑅
𝑍𝑉
𝑖 𝑟𝑖,

(2)
where 𝑊 𝑉 and 𝑊 𝑅 are two learnable projection matrices. Then
we use a multi-modal attention (MMA) module with stacked self-
attention layers [43] to encode the input features:
; 𝑍 𝑅]),

; 𝐻 𝑅] = MMA([𝑍𝑉

𝑖 = 𝑊 𝑅

[𝐻𝑉

(3)

, 𝐻 𝑅

where each 𝐻𝑉
𝑖 aggregate features from two modalities and
𝑖
[; ] denotes concatenation. This flexible design allows for variable
lengths of each modality and enables interactions between modali-
ties via co-attentions.

3We omit the subscript 𝑢 below for simplicity

All review images from the business

Multi-
Modal
Encoder

Selection
Model

…

User historical images

You have to get 
the scallops.
The “one bad 
hombre” drink is 
amazing! ……

User historical reviews

…

STEP 1:
Personalized Image
Set Selection

Cross-Modal
Contrastive Learning

Multi-
Modal
Encoder

Multi-
Modal
Decoder

Personalized
Contrastive Learning

STEP 2:
Visually-Aware
Explanation

Everything was fresh 
and good. Toro Sushi 
was the bomb and I 
even dream about it 
the night after!

Personalized Showcases: Generating Multi-Modal Explanations for Recommendations

Multi-Modal Decoder. Inspired by recent advances of powerful
pre-trained language models, we leverage GPT-2 as the decoder for
generating explanations. To efficiently adapt the linguistic knowl-
edge from GPT-2, we insert the encoder-decoder attention module
into the pre-trained model with a similar architecture in [4].

With this multi-modal GPT-2, given a target explanation 𝑌 =
{𝑦1, 𝑦2, ..., 𝑦𝐿 }, the decoding process at each time step 𝑡 can be
formalized as

ˆ𝑦𝑡 = Decoder([𝐻𝑉

; 𝐻 𝑅], 𝑦1, . . . , 𝑦𝑡 −1).

(4)

We use a cross-entropy (CE) loss to maximize the conditional log
likelihood log 𝑝𝜃 (𝑌 |𝑋, 𝐼 ) for 𝑁 training samples (𝑋 (𝑖), 𝐼 (𝑖), 𝑌 (𝑖) )𝑁
𝑖=1
as follows:

LCE = −

𝑁
∑︁

𝑖=1

log 𝑝𝜃 (𝑌 (𝑖) |𝑋 (𝑖), 𝐼 (𝑖) ).

(5)

We use ground truth images from the user for training and images
from our image-selection model for inference.

4.3 Personalized Cross-Modal Contrastive

Learning

Unlike image captioning tasks where the caption is a short descrip-
tion of an image, our task utilizes multiple images as “prompts” to
express personal feelings and opinions about them. To encourage
generating expressive, diverse and visual-aligned explanations, we
propose a Personalized Cross-Modal Contrastive Learning (𝑃𝐶2𝐿)
framework. We first project the hidden representations of images,
historical reviews, and the target sequence into a latent space:

˜𝐻𝑌 = 𝜙𝑌 (𝐻𝑌 )

˜𝐻𝑉 = 𝜙𝑉 (𝐻𝑉 ),

˜𝐻 𝑅 = 𝜙𝑅 (𝐻 𝑅),
(6)
where 𝜙𝑉 , 𝜙𝑅, and 𝜙𝑌 consist of two fully connected layers with
ReLU activation [30] and average pooling over the hidden states
𝐻𝑉 , 𝐻𝑅 and 𝐻𝑌 from the last self-attention layers. For the vanilla
contrastive learning with InfoNCE loss [5, 33], we then maximize
the similarity between the pair of source modality and target se-
quence, while minimizing the similarity between the negative pairs
as follows:

LCL = −

𝑁
∑︁

𝑖=1

log

exp(𝑠𝑋 ,𝑌
𝑖,𝑖
) + (cid:205)
𝑗 ∈𝐾

)
exp(𝑠𝑋 ,𝑌
𝑖,𝑗

exp(𝑠𝑋 ,𝑌
𝑖,𝑖

,

)

(7)

, ˜𝐻𝑌
( 𝑗)

= sim( ˜𝐻 𝑋
(𝑖)

where 𝑠𝑋 ,𝑌
)/𝜏, sim is the cosine similarity be-
𝑖,𝑗
tween two vectors, 𝜏 is the temperature parameter, (𝑖) and ( 𝑗) are
two samples in the mini-batch, 𝐾 is the set of negative samples for
sample (𝑖).

One challenge of this task is the model is asked to describe
multiple objects or contents in a set of images. To ensure the visual
grounding between multiple image features and output text, we
design a novel cross-modal contrastive loss. Specifically, given a
target explanation 𝑌 = {𝑦1, 𝑦2, ..., 𝑦𝐿 }, we randomly replace the
entities 4 in the text with other entities presented in the dataset
to construct a hard negative sample 𝑌 ent = {𝑦 ′
, ...𝑦𝐿 }
(i.e., “I like the sushi” to “I like the burger”), such that during training,
the model is exposed to samples with incorrect entities regarding
the images, which are non-trivial to distinguish from the original

, 𝑦2, ...𝑦 ′

ent2

ent1

4We extract entities using spaCy noun chunks (https://spacy.io/).

target sequence. Thus, we add the hidden representation of 𝑌 ent
as an additional negative sample ent to formulate the cross-modal
contrastive loss:

LCCL = −

𝑁
∑︁

𝑖=1

log

exp(𝑠𝑉 ,𝑌
𝑖,𝑖

)

exp(𝑠𝑉 ,𝑌
𝑖,𝑖
) + (cid:205)

𝑗 ∈𝐾∪ent

,

(8)

exp(𝑠𝑉 ,𝑌
𝑖,𝑗

)

On the other hand, to enhance the personalization of explanation
generation, we re-weight negative pairs according to user personal-
ities. The intuition is that users with more distinct personalities are
more likely to generate different explanations. Motivated by this,
we propose a weighted contrastive loss for personalization:

LPCL = −

𝑁
∑︁

𝑖=1

log

exp(𝑠𝑅,𝑌
𝑖,𝑖 )
𝑖,𝑖 ) + 𝑓 (𝑖, 𝑗) (cid:205)
𝑗 ∈𝐾

exp(𝑠𝑅,𝑌

.

(9)

exp(𝑠𝑅,𝑌
𝑖,𝑗 )

where negative pairs in a mini-batch are re-weighted based on user
personality similarity function 𝑓 . In our framework, user person-
alities are represented by their historical reviews. Specifically, we
define 𝑓 function as:

𝑓 (𝑖, 𝑗) = 𝛼 (1−sim( ˜𝑅 (𝑖 ) , ˜𝑅 ( 𝑗 ) ))

(10)

i.e., we reduce the weights of negative pairs with similar histories,
and increase those with distinct histories. 𝛼 (𝛼 > 1) is a hyperparam-
eter that weighs the negative samples, sim is the cosine similarity,
˜𝑅 (𝑖) and ˜𝑅 ( 𝑗) are the average features of two users’ input historical
reviews.

Overall, the model is optimized with a mixture of a cross-entropy

loss and the two contrastive losses:

L𝑙𝑜𝑠𝑠 = LCE + 𝜆1LCCL + 𝜆2LPCL,

(11)

where 𝜆1 and 𝜆2 are hyperparameters that weigh the two losses.

4.4 A Metric for Visual Grounding

As mentioned in Section 2, we want our model to generate explana-
tions that can accurately describe the content in a given image set.
Typical n-gram evaluation metrics such as BLEU compute scores
based on n-gram co-occurrences, which are originally proposed for
diagnostic evaluation of machine translation systems but not capa-
ble of evaluating text quality, as they are only sensitive to lexical
variation and fail to reward semantic or syntactic variations be-
tween predictions and references [38, 39, 50]. To effectively test the
performance of the alignment between visual images and text ex-
planations, we design an automatic evaluation metric: CLIP-Align
based on [36].

Given a set of images 𝐼 = {𝑖1, 𝑖2, ..., 𝑖𝑛 } and a set of sentences
from the generated text 𝑆 = {𝑠1, 𝑠2, ..., 𝑠𝑚 }, we first extract the
embeddings of all the images and sentences with CLIP, we compute
the metric as follows:

CLIP-Align =

1
𝑛

𝑛
∑︁

𝑖=1

𝑚𝑎𝑥 ({cs1,𝑖, ..., cs𝑚,𝑖 })

(12)

where cs𝑖,𝑗 is the confidence score produced by the CLIP-based
classifier Φ trained on our annotated data. By replacing cs𝑖,𝑗 with
the cosine similarity of image and sentence embeddings, we obtain
another metric CLIP-Score, similar to [17].

Table 2: Results on personalized showcases with different models and different input modalities. Results are reported in per-
centage (%). GT is the ground truth.

An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley

Model

Input

N-Gram Metrics

Diversity Metrics

Embedding Metrics

BLEU-1 METEOR NIST Distinct-1 Distinct-2 CLIP-Align CLIP-Score BERT-Score

GT

ST
R2Gen

Ref2Seq
Peter

Ours

-

img
img

text
text

-

8.24
6.47

7.09
8.89

img
img+text

9.92
10.40

-

3.41
3.10

3.80
3.28

3.64
3.83

-

28.08
36.55

30.78
34.45

37.35
50.64

6.06

2.74
3.23

0.92
0.38

3.37
3.58

43.23

17.41
22.45

5.89
1.27

26.37
28.58

90.47

80.84
82.07

73.51
72.70

84.78
85.31

28.41

24.31
24.28

23.83
23.27
24.68
24.50

-

85.20
85.89

84.71
86.94

88.03
88.23

Compared with previous CLIP-based metrics [17, 53], CLIP-
Align focuses specifically on the accuracy and the alignment be-
tween objects in the sentences and the images (e.g. “food is great”
and “burger is great” achieves similar high scores with the same
burger image computed on CLIP-Score, and a model that repet-
itively generates “food is great” can reach high performance on
CLIPscore in corpus level). Moreover, the vanilla CLIPscore [17]
showed poor correlations with captions containing personal feel-
ings, making it less suitable for this task. We show in Section 5 with
automatic and human evaluation results that our metric performs
better when evaluating alignment between images and text.

5 EXPERIMENTS

In this section, we conduct extensive experiments to evaluate the
performance of our personalized showcases framework. Ablation
studies show the influence of different modalities to personalized
showcases. Case studies and human evaluation are conducted to
validate that our model present more diverse and accurate explana-
tions than baselines.

5.1 Experimental Setting

Baselines. To show the effectiveness of our model, we compare it
with a number of popular baselines from different tasks, including
image captioning, report generation and explanation generation:

• ST [47] is a classic CNN+LSTM model for image captioning.
• R2Gen [6] is a state-of-the-art memory-driven transformer

specialized at generating long text with visual inputs.

• Ref2Seq [31] is a popular reference-based seq2seq model for

explanation generation in recommendation.

• Peter [25] is a recent transformer-based explanation genera-
tion model which uses the user and item IDs to predict the
words in the target explanation.

• img and text refer to image and text features respectively.

K images {𝑖1, . . . , 𝑖𝐾 }, div@K is defined as:

div@𝐾 =

∑︁

1≤𝑚<𝑛 ≤𝐾

dis(𝑖𝑚, 𝑖𝑛)
𝐾 (𝐾 − 1)/2

.

(13)

For textual explanations, we first evaluate the relevance of gener-
ated text and ground truth by n-gram based text evaluation metrics:
BLEU (n=1,4) [34], METEOR [8] and NIST (n=4) [10]. To evaluate di-
versity, we report Dinstinct-1 and Distinct-2 which is proposed
in [24] for text generation models. We then use CLIP and BERT to
compute embedding-based metrics. CLIP-Align is our proposed
metrics in Section 4.2. CLIP-Score [17] BERT-Score [50] are two
recent embedding-based metrics.
Implementation Details. We use CLIP [35] with ViT-B/32 as
image and text encoder to encode user historical reviews and images.
We convert user profile feature into a 128-dimensional vector with
a MLP model (1024→512→512→256→128), and convert candidate
images with another MLP (512→512→512→256→128), where both
models use ReLU activations [30]. We follow [45] to calculate each
element of 𝑳 and optimize DPP using Adam [28] with an initial
learning rate of 1e-3 and batch size 512. For inference, we use greedy
decoding to select 𝐾 = 3 images as visual explanation.

For training PC2L, we use AdamW [28] as the optimizer with an
initial learning rate of 1e-4. The maximum sequence lengths are set
to 64 which covers 95% of the explanations. The maximum number
of images and historical reviews are set to 5 and 10 respectively. The
hidden sizes of both the encoder and decoder are 768 with 12 heads.
There are 3 layers in the encoder and 12 layers in the decoder. The
batch size for training is 32. We use the GPT-2-small pre-trained
weights with 117M parameters. The weighting parameters 𝜆1, 𝛼
and temperature 𝜏 are set to 0.2, 0.2, 𝑒 and 0.1 respectively. We use a
beam size of 2 for decoding to balance the generation effectiveness
and efficiency.

Evaluation Metrics. For image selection, we report Precision@K,
Recall@K and F1@K to measure the ranking quality. Due to the
nature of our task, we set a small K (𝐾 = 3). To evaluate diversity,
we introduce the truncated div@K (𝐾 = 3) for the average dissimi-
larities for all image pairs in recommended images. Formally, given

5.2 Framework Performance

We first report the model performance on text evaluation met-
rics in Table 2, as we found this last step in our framework came
with more challenges and interesting findings, e.g., how to gener-
ate human-like explanations and avoid dull text, how to evaluate

Personalized Showcases: Generating Multi-Modal Explanations for Recommendations

Table 3: Ablation study for personalized image selection. Re-
sults are reported in percentage (%).

Accuracy

Diversity

Method

random

img
text
img+text

Prec@3 Recall@3

F1@3

Div@3

4.87
25.21
15.28
25.21

6.14

34.05
20.58
34.37

5.43

28.97
17.54
29.09

30.24

17.12
18.68
17.07

the generation quality. Here the input images are selected by our
model,5 and the input text consists of historical reviews from users.
First, the clear gap between text-input models and image-input
models on diversity and CLIP-based metrics validates the impor-
tance of incorporating image features. The setting of visually-aware
generation models is able to generate accurate explanations with
diverse language style. Second, our 𝑃𝐶2𝐿 shows substantial im-
provement on most of the metrics compared to LSTM and trans-
former based models, showing that a pretrained language model
with contrastive learning is able to generate high quality explana-
tions. Finally, though text-based models Ref2Seq and Peter achieve
competitive results with our method on some n-gram metrics such
as BLEU and METEOR, their performance is much worse on di-
versity and embedding metrics. The text quality is also low with
repetitive and non-informative sentences appearing often, which
we further validate with human evaluations and case studies.

5.3 Component Analysis

We conduct ablation studies to evaluate the effectiveness of each
component individually.
Model for image set selection. First, we evaluate the perfor-
mance of personalized image set selection. For general ranking
performance, we compare our model with random selection and
different input modalities. As shown in Table 3, though the trun-
cated diversity of the text-only model is the highest, its performance
is significantly worse than those with images in terms of ranking
metrics. This indicates text input alone is far insufficient to pro-
vide personalization for users, and its recommendation result is
closer to that of random selection. Historical images on the other
hand, provide an important visual cue for modeling users’ prefer-
ence. Overall, a model with images and text can achieve the best
ranking performance for image set selection, which validates the
importance of our multi-modal setting for personalized showcases.
Effectiveness of Contrastive Learning We conduct ablation stud-
ies on different variations of our contrastive loss to verify the ef-
fectiveness of our method. As shown in Table 4, our PC2L achieves
the best performance over all baselines on different metrics. Specif-
ically, CCL contributes more to the visual grounding by enforcing
the model to distinguish random entities from the correct ones, and

5For effective training and evaluation of our framework, ground truth images of a
given user are included in the image candidate pool for selecting. If it is for real-world
deployment, ground truth images are not available but similar images can be selected.

Table 4: Ablation study on contrastive learning. Baseline is
to train a multi-modal decoder without contrastive learning.
CL, CCL and PCL are the contrastive losses in Eq. (7), Eq. (8)
and Eq. (9)

Method

Baseline

img CL + text CL
CCL+ text CL
img CL + PCL

𝑃𝐶2𝐿

BLEU-1 Distinct-2 CLIP-Align

7.96

9.72
10.19
9.96

10.40

25.90

27.58
28.10
28.32

28.58

.

82.50

84.03
85.12
84.15

85.31

Figure 6: (a) The length distributions of generated texts on
the test set. (b) The generated explanation coverage of nouns
(Noun), adjectives (ADJ) and adverbs (ADV) in ground truth.

improves CLIP-Align compared to the vanilla contrastive frame-
work [5]. PCL improves more on diversity by encouraging the model
to focus on users with dissimilar interest.

To further evaluate the generation quality improved by con-
trastive learning, we analyze the generated explanations from two
aspects, length distributions of generations and keywords coverage.
Figure 6 (a) compares the length distributions of generations on
the test set to the ground truth. We categorize text lengths into
6 groups (within the range of [0, 60] with an interval of 10). The
model without PC2L has a sharper distribution, while adding our
PC2L leads to a distribution which is closer to the ground truth,
demonstrating its effectiveness and the ability to generalize on
unseen images. Note the ground truth contains more long texts
than generations from the model since we set the max length to 64
during training and inference, which results in the discrepancy for
text length greater than 60.

Figure 6 (b) shows the keyword coverage (i.e., nouns, adjectives
and adverbs) in output sentences. We consider an output as covering
a keyword if the word exists in the corresponding ground truth.
We compare two models trained with and without PC2L. We can
see that PC2L improves the coverage of all kinds of keywords,
which indicates our contrastive learning method diversifies and
personalizes the generated text. Overall, incorporating contrastive
learning into multi-modal explanation generation leads to better
output quality with more diverse and visually-aligned texts.
Can GPT-2 provide linguistic knowledge? Finally, we study
whether GPT-2 can provide linguistic knowledge for our generation

(cid:40)(cid:83)(cid:80)(cid:86)(cid:79)(cid:69)(cid:1)(cid:53)(cid:83)(cid:86)(cid:85)(cid:73)

(cid:88)(cid:16)(cid:80)(cid:1)

(cid:88)(cid:16)(cid:1)

(cid:88)(cid:16)(cid:80)(cid:1)

(cid:88)(cid:16)(cid:1)

(cid:90)
(cid:68)
(cid:79)
(cid:70)
(cid:86)
(cid:82)
(cid:70)
(cid:83)
(cid:39)

(cid:19)(cid:17)(cid:17)(cid:17)

(cid:18)(cid:22)(cid:17)(cid:17)

(cid:18)(cid:17)(cid:17)(cid:17)

(cid:22)(cid:17)(cid:17)

(cid:17)

(cid:70)
(cid:72)
(cid:66)
(cid:83)
(cid:70)
(cid:87)
(cid:80)
(cid:36)

(cid:18)(cid:19)(cid:22)(cid:17)

(cid:18)(cid:17)(cid:17)(cid:17)

(cid:24)(cid:22)(cid:17)

(cid:22)(cid:17)(cid:17)

(cid:19)(cid:22)(cid:17)

(cid:17)

(cid:47)(cid:80)(cid:86)(cid:79)

(cid:34)(cid:37)(cid:43)(cid:1)(cid:7)(cid:1)(cid:34)(cid:37)(cid:55)

(b)

(cid:17)

(cid:18)(cid:17)

(cid:21)(cid:17)
(cid:20)(cid:17)
(cid:19)(cid:17)
(cid:53)(cid:70)(cid:89)(cid:85)(cid:1)(cid:45)(cid:70)(cid:79)(cid:72)(cid:85)(cid:73)
(a)

(cid:22)(cid:17)

(cid:23)(cid:17)

An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley

Figure 7: Comparison between text-only explanations (i.e., Ref2Seq and Text GPT-2) and our showcases. User reviews are pro-
cessed following Section 3.3.

Table 5: Ablation Study on different initializations of the
decoder. Random randomly initializes model weights. Text
GPT-2 and Img GPT-2 are initialized with weights from [37].
Img GPT-2 + FT finetunes the model on a corpus similar to
our training text data. Results are in percentage (%).

Table 6: Human evaluation results on two models. We
present the workers with reference text and images, and ask
them to give scores from different aspects. Results are statis-
tically significant via sign test (p<0.01).

Method

Img Random
Text GPT-2
Img GPT-2
Img GPT-2 + FT

BLEU-1 Distinct-1 Distinct-2

5.21
4.81
7.59
7.10

0.23
3.43
4.05
4.32

5.08
19.27
29.41
30.82

task. We train models with different weight initializations, with
ground truth images (Img) or historical reviews (Text) as inputs.
As shown in Table 5, comparing the performance of random and
GPT-2 initialization, it is evident that the pretrained weights play
a significant role. Finetuning on in-domain data (260k samples
from users with one review and excluded from our personalization
dataset) further improves domain-specific knowledge of the decoder
and benefits generation performance on diversity metrics.

5.4 Case Study

We study three examples (see Figure 7) and compare our person-
alized showcases to single-modal explanations from Ref2Seq and
Text GPT-2. Overall, our visual explanations is able to recommend
images that fit users’ interest. This indicates the effectiveness of our
image selection module and the selected images can be used as valid
visual explanations. More importantly, these images can provide
grounding information for text generation such that the textual
explanations become more informative (i.e., specific dishes), which
aligns with our CLIP-Align metric as well as human evaluations
in Section 5.5. As is shown in Figure 7, we can see historical review
text alone cannot provide correct explanations (see Case 1) to the

Method Expressiveness Visual Alignment

Ref2Seq
PC2L

3.72
4.25

3.65
4.10

user (i.e., explanations from Ref2Seq and Text GPT-2 are irrelevant
to the user review) and the sentences are monotonous (see Case
2). In contrast, our showcase provides relevant and diverse textual
explanations based on images. In case 3, our generated text missed
some entities in the user’s review since it only correctly describes
one of the selected images. Hence, generating texts from multiple
images is still a challenging problem for this new task.

As we can observe from the examples, Ref2Seq tends to gen-
erate explanations with the same pattern, which also match the
observation in Table 2 that it has low Distinct-1 and Distinct-2.

5.5 Human Evaluation

To fully evaluate our model, we conduct human evaluation on
Amazon Mechanical Turk.6 For each model, we randomly sample
500 examples from the test set. Each example is scored by three
human judges using a 5-point Likert scale to reduce variance. We
instruct the annotators to consider two perspectives, expressiveness
(semantically correct, diversity, no repetition) and visual alignment
(the text describes the context of the images). As is shown in Table 6,
PC2L significantly outperforms Ref2Seq, which is consistent with
the automatic evaluation metrics.

6https://www.mturk.com/

We ordered pork and shrimp spring rolls that came with 
a peanut-y dipping sauce. Then we ordered a chicken 
banh-mi and a lemongrass beef with noodles.

The steak frites was tasty - it was charred, which I really 
liked, and topped with a butter sauce. The truffle fries 
were also really, really good.

The burger was delicious though! My co worker said the 
Pork Torta was delicious! Other guys had Gyro, pizza 
and fish tacos. My Bacon Cheeseburger was excellent.

we ordered the fried rice and it was very good.

i had the grilled chicken sandwich , which was delicious .

i had the grilled cheese sandwich and it was delicious !

i love it if you want to eat japanese - style ramen.

first time here, i had the bbq bacon cheeseburger 
medium rare with onion rings.

the rice pilaf was very good as well.

if you like vietnamese food, you should try this place 
out. the spring rolls are a definite must -. the pho is good.

old school rustic feel with a wide selection of burgers 
and beers. the burgers were done well ……

bloody mary was perfect. food was wonderful, try the 
fried green tomato breakfast tacos.

EXAMPLE 1

EXAMPLE 2

EXAMPLE 3

Processed
User 
Reviews

Previous
Ref2Seq

Previous
Text GPT-2

Ours
Personalized
Showcases

Personalized Showcases: Generating Multi-Modal Explanations for Recommendations

6 RELATED WORK
6.1 Explanation Generation

There has been a line of work that studies how to generate explana-
tions for recommendations. Some work generates product reviews
based on categorical attributes [52] images [42], or aspects [32].
Due to noise in reviews, Li et al. [26] generated ‘tips’ from the Yelp
dataset which are more concise and informative as explanations
in recommendation. To further improve the quality of generation,
Ni et al. [31] proposed to identify justifications by dividing re-
views into text segments and classifying text segments to get “good”
justifications. Li et al. [25] proposed transformer-based model for
recommendation explanation generations by incorporating user,
item embeddings and related features. These text generation tasks
leverage historical reviews from users or items. Images, on the other
hand, provide rich information and grounding for text generation.
Moreover, multi-modal information in our task (i.e., images and
text) are more acceptable than text as explanations for users.

In this paper, we propose a new task for generating multi-modal
explanations and present a framework that provides personalized
image showcases and visually-aware text explanations for recom-
mendations.

6.2 Multi-Modal Learning

Recent years have witnessed the success of deep learning on multi-
modal learning and pretraining [4, 20, 35, 41]. These models usually
adopt the Transformer [43] structure to encode visual and textual
features for pretraining, to later benefit the multimodal downstream
tasks. Among them, CLIP [35] is a powerful model trained on a
massive amount of image-caption pairs, and has shown a strong
zero-shot capability on various vision and language tasks [40]. Sev-
eral methods [17, 53] used CLIP embeddings to compute modality
similarities as evaluation metrics for image captioning and text
generation tasks.

In our work, we used CLIP extensively as the multi-modal en-
coder for our framework. We also designed a new metric based on
CLIP for evaluating the visual alignment between the image set
and generated explanations.

6.3 Contrastive Learning

The goal of contrastive learning [14, 33] is to learn representations
by contrasting positive and negative pairs. It has been investigated
in several fields of machine learning, including computer vision [5,
15, 21], natural language processing [12, 13, 19], and recommender
systems [44, 46, 51]. A few recent work showed promising results
of applying contrastive learning to conditional text generation, by
generating adversarial examples [23], or finding hard negatives
with pretrained language models [3, 48].

Our work differs in that we study contrastive learning for condi-
tional text generation in a cross-modal setting, where we proposed
a novel contrastive framework for generating personalized multi-
modal explanations.

7 CONCLUSION

In this paper, to generate explanations with rich information for
recommendations, we introduce a new task, namely personalized

showcases, and collect a large-scale dataset Gest from Google Local
for the task. We design a personalized cross-modal contrastive
learning framework to learn visual and textual explanations from
user reviews. Experimental results show that showcases provide
more informative and diverse explanations compared to previous
text-only explanations. As future work, one promising direction is
to develop an end-to-end framework for generating both visual and
textual explanations. Besides, visual grounding on multiple images
is still challenging for showcases. Another interesting setting is
to address cold-start users or reviews written without images. We
hope our dataset and framework would benefit the community for
future research on multi-modalities and recommendations.

A DATA CONSTRUCTION

Our dataset is constructed from Google Local (i.e., maps) using a
breadth-first-search algorithm with memorization. After collect-
ing the review data, we filtered out reviews of length less than
5 words, which are less likely to provide useful information; we
also removed reviews (2.13%) containing more than 10 images. The
details of Gest-s1 construction for personalized image selection
are as follows: We remove users with only one review for building
a personalized dataset, then filter out reviews whose image urls are
expired. After pre-processing, statistics for the personalized show-
case dataset are shown in Table 1, where the number of images per
business is 35.63 on average. We then randomly split the dataset by
users, with 95,270/11,908/11,908 users for train/val/test.

B VISUAL DIVERSITY DEFINITION

We define the visual diversities in three levels as below:

• Intra-Business Div: Measure the average diversity for im-
age pairs at a business-level, where P1 (𝑏) means all the
possible image pairs for business 𝑏. 𝑍1 is the valid counts7
of dis-similarity calculations (same as below):

∑︁

∑︁

𝑏 ∈𝐵

𝑚,𝑛 ∈ P (𝑏)

dis(𝑖𝑏
𝑚, 𝑖𝑏
𝑛)
𝑍1

.

(14)

• Inter-User Div: Measure the average diversity for image
pairs from different users for the same business, where P2 (𝑏)
means all possible image pairs for business 𝑏 that come from
different users:

∑︁

∑︁

𝑏 ∈𝐵

𝑚,𝑛 ∈ P2 (𝑏)

dis(𝑖𝑏
𝑚, 𝑖𝑏
𝑛)
𝑍2

.

(15)

• Intra-User Div: Measure the average diversity in (business,
user)-level, where P3 (𝑢, 𝑏) means all possible image pairs
from user 𝑢 to business 𝑏:

∑︁

∑︁

∑︁

𝑏 ∈𝐵

𝑢 ∈𝑈

𝑚,𝑛 ∈ P3 (𝑢,𝑏)

dis(𝑖𝑏
𝑚, 𝑖𝑏
𝑛)
𝑍3

.

(16)

REFERENCES
[1] Ashutosh Baheti, Alan Ritter, Jiwei Li, and William B. Dolan. 2018. Generating
More Interesting Responses in Neural Conversation Models with Distributional
Constraints. In EMNLP.

7When image set size is not more than 1, the dis-similarity calculation is invalid.

[2] Jinze Bai, Chang Zhou, Junshuai Song, Xiaoru Qu, Weiting An, Zhao Li, and Jun
Gao. 2019. Personalized Bundle List Recommendation. The World Wide Web
Conference (2019).

[3] Hengyi Cai, Hongshen Chen, Yonghao Song, Zhuoye Ding, Yongjun Bao, Weipeng
Yan, and Xiaofang Zhao. 2020. Group-wise contrastive learning for neural dia-
logue generation. arXiv preprint arXiv:2009.07543 (2020).

[4] Jun Chen, Han Guo, Kai Yi, Boyang Li, and Mohamed Elhoseiny. 2021. VisualGPT:
Data-efficient Adaptation of Pretrained Language Models for Image Captioning.
[5] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A
simple framework for contrastive learning of visual representations. In Interna-
tional conference on machine learning. PMLR, 1597–1607.

[6] Zhihong Chen, Yan Song, Tsung-Hui Chang, and Xiang Wan. 2020. Generating Ra-
diology Reports via Memory-driven Transformer. arXiv preprint arXiv:2010.16056
(2020).

[7] Zhongxia Chen, Xiting Wang, Xing Xie, Tong Wu, Guoqing Bu, Yining Wang,
and Enhong Chen. 2019. Co-Attentive Multi-Task Learning for Explainable
Recommendation. In IJCAI.

[8] Michael Denkowski and Alon Lavie. 2011. Meteor 1.3: Automatic metric for reli-
able optimization and evaluation of machine translation systems. In Proceedings
of the sixth workshop on statistical machine translation. 85–91.

[9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:
Pre-training of Deep Bidirectional Transformers for Language Understanding. In
NAACL.

[10] George Doddington. 2002. Automatic evaluation of machine translation quality
using n-gram co-occurrence statistics. In Proceedings of the second international
conference on Human Language Technology Research. 138–145.

[11] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-
aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2021. An Image
is Worth 16x16 Words: Transformers for Image Recognition at Scale. ArXiv
abs/2010.11929 (2021).

[12] Hongchao Fang, Sicheng Wang, Meng Zhou, Jiayuan Ding, and Pengtao Xie. 2020.
Cert: Contrastive self-supervised learning for language understanding. arXiv
preprint arXiv:2005.12766 (2020).

[13] Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021. SimCSE: Simple Contrastive
Learning of Sentence Embeddings. arXiv preprint arXiv:2104.08821 (2021).
[14] Michael Gutmann and Aapo Hyvärinen. 2010. Noise-contrastive estimation:
A new estimation principle for unnormalized statistical models. In Proceedings
of the Thirteenth International Conference on Artificial Intelligence and Statistics.
JMLR Workshop and Conference Proceedings, 297–304.

[15] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2020. Momen-
tum contrast for unsupervised visual representation learning. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 9729–9738.
[16] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770–778.

[17] Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras, and Yejin Choi. 2021.
CLIPScore: A Reference-free Evaluation Metric for Image Captioning. arXiv
preprint arXiv:2104.08718 (2021).

[18] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious
case of neural text degeneration. arXiv preprint arXiv:1904.09751 (2019).
[19] Jiaji Huang, Yi Li, Wei Ping, and Liang Huang. 2018. Large margin neural language

model. arXiv preprint arXiv:1808.08987 (2018).

[20] Zhicheng Huang, Zhaoyang Zeng, Bei Liu, Dongmei Fu, and Jianlong Fu. 2020.
Pixel-bert: Aligning image pixels with text by deep multi-modal transformers.
arXiv preprint arXiv:2004.00849 (2020).

[21] Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip
Isola, Aaron Maschinot, Ce Liu, and Dilip Krishnan. 2020. Supervised contrastive
learning. arXiv preprint arXiv:2004.11362 (2020).

[22] Alex Kulesza and Ben Taskar. 2012. Determinantal Point Processes for Machine

Learning. Found. Trends Mach. Learn. 5 (2012), 123–286.

[23] Seanie Lee, Dong Bok Lee, and Sung Ju Hwang. 2020. Contrastive Learning
with Adversarial Perturbations for Conditional Text Generation. arXiv preprint
arXiv:2012.07280 (2020).

[24] Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2015. A
diversity-promoting objective function for neural conversation models. arXiv
preprint arXiv:1510.03055 (2015).

An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley

[29] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel.
2015. Image-based recommendations on styles and substitutes. In Proceedings
of the 38th international ACM SIGIR conference on research and development in
information retrieval. 43–52.

[30] Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted

boltzmann machines. In Icml.

[31] Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Justifying recommendations
using distantly-labeled reviews and fine-grained aspects. In Proceedings of the
2019 Conference on Empirical Methods in Natural Language Processing and the 9th
International Joint Conference on Natural Language Processing (EMNLP-IJCNLP).
188–197.

[32] Jianmo Ni and Julian McAuley. 2018. Personalized Review Generation By Ex-
panding Phrases and Attending on Aspect-Aware Representations. In ACL.
[33] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation learning
with contrastive predictive coding. arXiv preprint arXiv:1807.03748 (2018).
[34] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a
method for automatic evaluation of machine translation. In Proceedings of the
40th annual meeting of the Association for Computational Linguistics. 311–318.

[35] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
et al. 2021. Learning transferable visual models from natural language supervision.
arXiv preprint arXiv:2103.00020 (2021).

[36] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
Gretchen Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual Models
From Natural Language Supervision. In ICML.

[37] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019. Language Models are Unsupervised Multitask Learners.
[38] Ehud Reiter. 2018. A structured review of the validity of BLEU. Computational

Linguistics 44, 3 (2018), 393–401.

[39] Thibault Sellam, Dipanjan Das, and Ankur P Parikh. 2020. BLEURT: Learning
robust metrics for text generation. arXiv preprint arXiv:2004.04696 (2020).
[40] Sheng Shen, Liunian Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach, Kai-
Wei Chang, Zhewei Yao, and Kurt Keutzer. 2021. How Much Can CLIP Benefit
Vision-and-Language Tasks? arXiv preprint arXiv:2107.06383 (2021).

[41] Hao Tan and Mohit Bansal. 2019. Lxmert: Learning cross-modality encoder
representations from transformers. arXiv preprint arXiv:1908.07490 (2019).
[42] Quoc-Tuan Truong and Hady Lauw. 2019. Multimodal review generation for

recommender systems. In The World Wide Web Conference. 1864–1874.

[43] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In Advances in neural information processing systems. 5998–6008.
[44] Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, Xuanping Li, and Tat-Seng
Chua. 2021. Contrastive learning for cold-start recommendation. In Proceedings
of the 29th ACM International Conference on Multimedia. 5382–5390.

[45] Mark Wilhelm, Ajith Ramanathan, Alexander Bonomo, Sagar Jain, Ed H. Chi, and
Jennifer Gillenwater. 2018. Practical Diversified Recommendations on YouTube
with Determinantal Point Processes. Proceedings of the 27th ACM International
Conference on Information and Knowledge Management (2018).

[46] Xu Xie, Fei Sun, Zhaoyang Liu, Shiwen Wu, Jinyang Gao, Bolin Ding, and Bin
Cui. 2020. Contrastive Learning for Sequential Recommendation. arXiv preprint
arXiv:2010.14395 (2020).

[47] Ke Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C. Courville, Ruslan
Salakhutdinov, Richard S. Zemel, and Yoshua Bengio. 2015. Show, Attend and
Tell: Neural Image Caption Generation with Visual Attention. In ICML.

[48] An Yan, Zexue He, Xing Lu, Jiang Du, Eric Chang, Amilcare Gentili, Julian
McAuley, and Chun-Nan Hsu. 2021. Weakly Supervised Contrastive Learning
for Chest X-Ray Report Generation. arXiv preprint arXiv:2109.12242 (2021).
[49] Hongyu Zang and Xiaojun Wan. 2017. Towards Automatic Generation of Product

Reviews from Aspect-Sentiment Scores. In INLG.

[50] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav
Artzi. 2019. Bertscore: Evaluating text generation with bert. arXiv preprint
arXiv:1904.09675 (2019).

[51] Chang Zhou, Jianxin Ma, Jianwei Zhang, Jingren Zhou, and Hongxia Yang. 2021.
Contrastive learning for debiased candidate generation in large-scale recom-
mender systems. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge
Discovery & Data Mining. 3985–3995.

[25] Lei Li, Yongfeng Zhang, and Li Chen. 2021. Personalized Transformer for Ex-

[52] M. Zhou, Mirella Lapata, Furu Wei, Li Dong, Shaohan Huang, and Ke Xu. 2017.

plainable Recommendation. In ACL/IJCNLP.

[26] Piji Li, Zihao Wang, Lidong Bing, and Wai Lam. 2019. Persona-Aware Tips

Generation? The World Wide Web Conference (2019).

[27] Piji Li, Zihao Wang, Zhaochun Ren, Lidong Bing, and Wai Lam. 2017. Neu-
ral Rating Regression with Abstractive Tips Generation for Recommendation.
Proceedings of the 40th International ACM SIGIR Conference on Research and
Development in Information Retrieval (2017).

[28] Ilya Loshchilov and Frank Hutter. 2017. Fixing Weight Decay Regularization in

Adam. ArXiv abs/1711.05101 (2017).

Learning to Generate Product Reviews from Attributes. In EACL.

[53] Wanrong Zhu, Xin Eric Wang, An Yan, Miguel Eckstein, and William Yang Wang.
2021. ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural
Language Generation. arXiv preprint arXiv:2106.05970 (2021).

","Personalized Showcases: Generating Multi-Modal Explanations for Recommendations An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley UC San Diego La Jolla, CA, USA {ayan,zhh004,j9li,tiz010,jmcauley}@ucsd.edu 2 2 0 2 n u J 0 3 ] R I . s c [ 1 v 2 2 4 0 0 . 7 0 2 2 : v i X r a ABSTRACT Existing explanation models generate only text for recommenda- tions but still struggle to produce diverse contents. In this paper, to further enrich explanations, we propose a new task named per- sonalized showcases, in which we provide both textual and visual information to explain our recommendations. Specifically, we first select a personalized image set that is the most relevant to a user’s interest toward a recommended item. Then, natural language ex- planations are generated accordingly given our selected images. For this new task, we collect a large-scale dataset from Google Lo- cal (i.e., maps) and construct a high-quality subset for generating multi-modal explanations. We propose a personalized multi-modal framework which can generate diverse and visually-aligned ex- planations via contrastive learning. Experiments show that our framework benefits from different modalities as inputs, and is able to produce more diverse and expressive explanations compared to previous methods on a variety of evaluation metrics. 1 INTRODUCTION Personalized explanation generation models have the potential to increase the transparency and reliability of recommendations. Previous works [1, 7, 49, 52] considered generating textual explana- tions from users’ historical reviews, tips [27] or justifications [31]. However, these methods still struggle to provide diverse explana- tions because a large amount of general sentences (e.g., ‘food is very good!’) exist in generated explanations and the text gener- ation models lack grounding information (e.g., images) for their generation process. To further diversify and enrich explanations for recommendations, we propose a new explanation generation task named personalized showcases (shown in Figure 1). In this new task, we explain recommendations via both textual and visual infor- mation. Our task aims to provide a set of images that are relevant to a user’s interest and generate textual explanations accordingly. Compared to previous works that generate only text as explana- tions, our showcases present diverse explanations including images and visually-guided text. To this end, the first challenge of this task is building a dataset. Existing review datasets (e.g., Amazon [31] and Yelp1) are largely unsuitable for this task (we further discuss these datasets in Sec- tion 3.2). Thus, we first construct a large-scale multi-modal dataset, namely Gest, which is collected from Google Local2 Restaurants including review text and corresponding pictures. Then, to improve the quality of Gest for personalized showcases, we annotate a small subset to find highly matched image-sentence pairs. Based on the annotations, we train a classifier with CLIP [36] to extract 1https://www.yelp.com/dataset 2https://www.google.com/maps Figure 1: Illustration of previous text-only explanation and our personalized showcases for recommendations. Given a recommended item or business: (1) Text-only Explanation models only use historical textual reviews from user and item sides to generate textual explanations. (2) We propose a personalized showcases task to enrich the personalized ex- planations with multi-modal (visual and textual) informa- tion, which can largely improve the informativeness and di- versity of generated explanations. visually-aware explanations from the full dataset. The images and text explanations from users are used as the learning target for personalized showcases. For this new task, we design a new multi-modal explanation framework. To begin with, the framework selects several images from historical photos of the business that the user is most in- terested in. Then, the framework takes the displayed images and users’ profiles (e.g., historical reviews) as inputs and learns to gen- erate textual explanations with a multi-modal decoder. However, generating expressive, diverse and engaging text that will capture users’ interest remains a challenging problem. First, different from previous textual explanation generation, the alignment between multiple images and generated text becomes an important problem for showcases, which poses higher requirements for information extraction and fusion across modalities. Second, a typical encoder- decoder model with a cross-entropy loss and teacher forcing can easily lead to generating repetitive and dull sentences that occur frequently in the training corpus (e.g., “food is great”) [18]. To tackle these challenges, we propose a Personalized Cross- Modal Contrastive Learning (PC2L) framework by contrasting in- put modalities with output sequences. Contrastive learning has Recommendations … R1: Chinese Food R2: American Food R3: Japanese Food Food is very delicious! Burgers are great, service is good, too. Great selection of beers and delicious burgers! The bread that comes with the entree soup is amazing. The cheesecake is on point. Previous: Text-Only Explanations (e.g. Ref2Seq) Ours: Personalized Showcases (Visual+Textual) An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley Figure 2: Example of business and user reviews in Gest. For a business (e.g., an Italian restaurant), Gest contains historical reviews and images from different users. drawn attention as a self-supervised representation learning ap- proach [5, 33]. However, simply training with negative samples in a mini-batch is suboptimal [23] for many tasks, as the randomly se- lected embeddings could be easily discriminated in the latent space. Hence, we first design a cross-modal contrastive loss to enforce the alignment between images and output explanations, by construct- ing hard negative samples with randomly replaced entities in the output. Motivated by the observation that users with similar histori- cal reviews share similar interests, we further design a personalized contrastive loss to reweight the negative samples based on their history similarities. Experimental results on both automatic and human evaluation show that our model is able to generate more expressive, diverse and visually-aligned explanations compared to a variety of baselines. Overall, our contributions are as follows: • To generate more informative explanations for recommenda- tions, we present a new task: personalized showcases which can provide both textual and visual explanations for recom- mendations. • For this new task, we collect a large-scale multi-modal dataset from Google Local (i.e., maps). To ensure alignment between images and text, we annotate a small dataset and train a classifier to propagate labels on Gest, and construct a high- quality subset for generating textual explanations. • We propose a novel multi-modal framework for personalized showcases which applies contrastive learning to improve diversity and visual alignment of generated text. Comprehen- sive experiments on both automatic and human evaluation indicate that textual explanations from our showcases are more expressive and diverse than existing explanation gen- eration methods. 2 TASK DEFINITION In the personalized showcases task, we aim to provide both per- sonalized textual and visual explanations to explain recommen- dations for users. Formally, given user 𝑢 ∈ 𝑈 and business (item) 𝑏 ∈ 𝐵, where 𝑈 and 𝐵 are the user set and business set respectively, the personalized showcases task will provide textual explanations 𝑆 = {𝑠1, 𝑠2, ..., 𝑠𝑚 } and visual explanations 𝐼 = {𝑖1, 𝑖2, ..., 𝑖𝑛 }, where 𝑠 and 𝑖 represent sentences and images in explanations. 𝑆 and 𝐼 are matched with each other and personalized to explain why 𝑏 is recommended to 𝑢. To better study the relation between textual and visual expla- nations and provide baselines for future work, in this paper, we decompose the task into two steps as shown in Figure 5: (1) Select- ing an image set as a visual explanation that is relevant to a user’s interest; (2) Generating textual explanations given the selected images and a user’s historical reviews. |𝐼𝑏 | , 𝑖𝑏 2 , . . . 𝑖𝑏 Formally, given user 𝑢, business 𝑏 and the image candidate set 𝐼𝑏 = {𝑖𝑏 } from 𝑏, we first select a set of images as visual 1 explanations 𝐼 from 𝐼𝑏 which user 𝑢 will be interested in, based on user 𝑢’s profile (i.e., historical reviews 𝑋𝑢 = {𝑥𝑢 𝐾 } 1 and images 𝐼𝑢 = {𝑖𝑢 , ..., 𝑖𝑢 𝑛 }). Then, we use the user’s historical 1 reviews 𝑋𝑢 and selected images 𝐼 to generate visually-aware textual explanations 𝑆. , ..., 𝑥𝑢 , 𝑥𝑢 2 , 𝑖𝑢 2 For our method, we consider the following aspects: • Accuracy: We aim to predict the target images (i.e., images associated with the ground-truth review) from business im- age candidates correctly, and the generated text is expected to be relevant to the business. • Diversity: The selected images should be diverse and cover more information from businesses (e.g., including more dishes from a restaurant). Textual explanations should be diverse and expressive. • Alignment: Unlike previous explanation or review gener- ation tasks which only use historical reviews or aspects as inputs, our visually-aware setting provides grounding to the images. Hence the generated explanations in this new task should aim to accurately describe the content and cover the main objects (e.g., the name of dishes, the environment) in the given set of images. Amazing! Best Cesar salad I ever had and the cake was delicious. Seafood soup was excellent. Granddaughter loved the Spaghetti and meatballs. I had an excellent experience at this restaurant. The ambience is romantic and perfect for a couple date night. An Italian Restaurant User Reviews Personalized Showcases: Generating Multi-Modal Explanations for Recommendations Figure 3: Visual Diversity Comparison. A, B, C, E in Ama- zon denote different categories of amazon review datasets, which are uniformly sampled from All, Beauty, Clothing and Electronics, respectively. Intra-/Inter- User Diversity for the Yelp dataset is unavailable since Yelp images lack user information. 3 DATASET 3.1 Dataset Statistics We collected reviews with images from Google Local. Gest-raw in Table 1 shows the data statistics of our crawled dataset. We can see that Gest-raw contains 1,771,160 reviews from 1,010,511 users and 65,113 businesses. Every review has at least one image and the raw dataset has 4,435,565 image urls. We processed our dataset into two subsets as (1) Gest-s1 for personalized image set selection, and (2) Gest-s2 for visually-aware explanation generation. Statistics of our processed dataset are in Ta- ble 1, with more processing details in Section 3.3 and Appendix A. 3.2 Visual Diversity Analysis To distinguish our Gest from existing review datasets and show the usefulness of personalized showcases, we first define CLIP-based dis- similarity in three levels to measure the diversity of user-generated images in each business. Then, we compare the visual diversities between our Gest data with two representative review datasets, Amazon Reviews [29, 31] and Yelp. First, similar to [36, 53], we use the cosine similarity (denoted as sim) from pre-trained CLIP to define the dis-similarity between image 𝑖𝑚 and 𝑖𝑛 as dis(𝑖𝑚, 𝑖𝑛) = 1 − sim(𝑖𝑚, 𝑖𝑛). Thus, we introduce visual diversity in three levels as Intra-Business Div, Inter-User Div and Intra-User Div, which are formally defined in Appendix B; higher scores mean more visual diversity. Then, we investigate the visual diversities for our Gest data as well as Amazon Reviews (using all categories All (A) and sub- categories Beauty (B), Clothing (C), Electronics (E)) and Yelp. For Amazon, we treat each item page as a “business” because reviews are collected according to items. In our calculation, we sample 5,000 items with more than one user-uploaded image. Note that images in Yelp dataset do not have user information, so we cannot calculate user-level diversities for Yelp. From Figure 3, we have the following observations: • Diversities within datasets: Figure 3 shows that for Gest and Amazon, Inter-User Div is the highest and Intra-User Div is the lowest. It indicates even for the same business (item), users focus on and present different visual information. Figure 4: Example of user-generated images from Amazon from an item page and for Yelp from a business. Amazon images mainly focus on a single item and Yelp images for a business are diverse (yet the current public Yelp dataset has no user-image interactions). Table 1: Data statistics for Gest. Avg. R. Len. denotes average review length and #Bus. denotes the number of Businesses. -raw denotes raw Gest. -s1 denotes Gest data for the first step, and -s2 denotes Gest data for the second step of our proposed personalized showcases framework. Dataset #Image #Review #User #Bus. Avg. R. Len. Gest-raw 4,435,565 1,722,296 Gest-s1 203,433 Gest-s2 1,771,160 370,563 108,888 1,010,511 119,086 36,996 65,113 48,330 30,831 36.26 45.48 24.32 • Gest vs. Amazon: In Figure 3, three visual diversities of Amazon are consistently lower than Gest by a large margin. We try to explain this by discussing the difference of user behaviors on these two platforms. As an example in Figure 4, user-generated images usually focus on the purchased item. Though the information they want to show differs, there is usually a single object in an image (i.e., the purchased item). Thus visual diversity is limited. While for Gest, as examples in Figure 2 show, reviews on restaurants allow users to share more diverse information from more varied items, angles or aspects. Compared with Amazon, using Gest should generate more informative personalized showcases according to different user profiles. • Gest vs. Yelp: Yelp images are high-quality (as an example in Figure 4) and the intra-business div. is higher (0.44) than Gest (0.39). Images in Yelp themselves are similar to images in Gest. However, Yelp images do not fit our task due to the lack of user information. 3.3 Explanation Distillation Reviews often contain uninformative text that is irrelevant to the images, and cannot be used directly as explanations. Hence, we con- struct an explanation dataset from Gest-raw. We distill sentences in reviews that align with the content of a given image as valid explanations. Three annotators were asked to label 1,000 reviews (with 9,930 image-sentence pairs) randomly sampled from the full dataset. The task is to decide if a sentence describes a image. Label- ing was performed iteratively, followed by feedback and discussion, Intra-Business Div Inter-User Div Intra-User Div 0.4 0.2 0.0 GEST Amazon-A Amazon-B Amazon-C Amazon-E Yelp Amazon Yelp … … An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley Figure 5: Illustration of our personalized showcases framework for the given business. We take user historical images and tex- tual reviews as inputs. First, we select an image set that is most relevant to a user’s interest. Then we generate natural language explanations accordingly with a multi-modal decoder. A cross-modal contrastive loss and a personalized contrastive loss are applied between each input modality and the explanations. Last, the selected images and generated textual explanations will be organized as multi-modal explanations to users. until the quality was aligned between the three annotators. The annotated image-sentence pairs are then split into train, validation, and testing with a ratio of 8:1:1. We then train a binary classification model Φ based on these annotated image-sentence pairs and their corresponding labels. Specifically, we extract the embedding of each sentence and image via CLIP. The two features are concatenated and fed into a fully connected layer. The classifier achieves an AUC of 0.97 and F-1 score of 0.71 on the test set, where similar results are obtained in [31] for building a text-only explanation dataset. We use this model to extract explanations from all reviews. The statistics of the dataset Gest-s2 can be found in Table 1. 4 METHODOLOGY In this section, we present our framework of producing personal- ized showcases. As the overview shows (Figure 5), we start with personalized image set selection and the visually-aware explanation generation module, then introduce our personalized cross-modal contrastive learning approach in Section 4.3. 4.1 Personalized Image Set Selection The first step is to select an image set as a visual explanation that is relevant to a user’s interests, and is diverse. We formulate this selection step as diverse recommendation with multi-modal inputs. Multi-Modal Encoder. Generally, these user textual- or visual- profiles can be effectively encoded with different pre-trained deep neural networks (e.g., ResNet [16], ViT [11], BERT [9]). Here we choose CLIP [35], a state-of-the-art pre-trained cross-modal re- trieval model as both textual- and visual-encoders. CLIP encodes raw images as image features, and encodes user textual- and visual- profiles as user profile features. Image Selection Model. We use a Determinantal Point Process (DPP) method [22] to select the image subset, which has recently been used for different diverse recommendation tasks [2, 45]. Com- pared with other algorithms for individual item recommendation, DPP-based models are suitable for multiple image selection. Given user 𝑢 and business 𝑏, we predict the image set ˆ𝐼𝑢,𝑏 as follows: ˆ𝐼𝑢,𝑏 = DPP(𝐼𝑏, 𝑢), (1) where 𝐼𝑏 is the image set belonging to business 𝑏. In our design, we calculate user-image relevance using the CLIP-based user’s profile features and image features. More details of the model are in [45]. 4.2 Visually-Aware Explanation Generation After obtaining an image set, we aim to generate personalized expla- nations given a set of images and a user’s historical reviews, with the extracted explanation dataset Gest-s2 in Section 3.3. Specifically, we build a multi-modal encoder-decoder model with GPT-2 [37] as the backbone. Multi-Modal Encoder. Given a set of user 𝑢’s3 historical reviews 𝑋 = {𝑥1, 𝑥2, . . . , 𝑥𝐾 }, we use the text encoder of CLIP to extract the review features 𝑅 = {𝑟1, 𝑟2, . . . , 𝑟𝐾 }. Similar operations are applied to the input images 𝐼 = {𝑖1, 𝑖2, . . . , 𝑖𝑛 }, where we use a pretrained ResNet to extract the visual features 𝑉 = {𝑣1, 𝑣2, . . . , 𝑣𝑛 }. Those features are then projected into a latent space: 𝑖 = 𝑊 𝑉 𝑣𝑖, 𝑍 𝑅 𝑍𝑉 𝑖 𝑟𝑖, (2) where 𝑊 𝑉 and 𝑊 𝑅 are two learnable projection matrices. Then we use a multi-modal attention (MMA) module with stacked self- attention layers [43] to encode the input features: ; 𝑍 𝑅]), ; 𝐻 𝑅] = MMA([𝑍𝑉 𝑖 = 𝑊 𝑅 [𝐻𝑉 (3) , 𝐻 𝑅 where each 𝐻𝑉 𝑖 aggregate features from two modalities and 𝑖 [; ] denotes concatenation. This flexible design allows for variable lengths of each modality and enables interactions between modali- ties via co-attentions. 3We omit the subscript 𝑢 below for simplicity All review images from the business Multi- Modal Encoder Selection Model … User historical images You have to get the scallops. The “one bad hombre” drink is amazing! …… User historical reviews … STEP 1: Personalized Image Set Selection Cross-Modal Contrastive Learning Multi- Modal Encoder Multi- Modal Decoder Personalized Contrastive Learning STEP 2: Visually-Aware Explanation Everything was fresh and good. Toro Sushi was the bomb and I even dream about it the night after! Personalized Showcases: Generating Multi-Modal Explanations for Recommendations Multi-Modal Decoder. Inspired by recent advances of powerful pre-trained language models, we leverage GPT-2 as the decoder for generating explanations. To efficiently adapt the linguistic knowl- edge from GPT-2, we insert the encoder-decoder attention module into the pre-trained model with a similar architecture in [4]. With this multi-modal GPT-2, given a target explanation 𝑌 = {𝑦1, 𝑦2, ..., 𝑦𝐿 }, the decoding process at each time step 𝑡 can be formalized as ˆ𝑦𝑡 = Decoder([𝐻𝑉 ; 𝐻 𝑅], 𝑦1, . . . , 𝑦𝑡 −1). (4) We use a cross-entropy (CE) loss to maximize the conditional log likelihood log 𝑝𝜃 (𝑌 |𝑋, 𝐼 ) for 𝑁 training samples (𝑋 (𝑖), 𝐼 (𝑖), 𝑌 (𝑖) )𝑁 𝑖=1 as follows: LCE = − 𝑁 ∑︁ 𝑖=1 log 𝑝𝜃 (𝑌 (𝑖) |𝑋 (𝑖), 𝐼 (𝑖) ). (5) We use ground truth images from the user for training and images from our image-selection model for inference. 4.3 Personalized Cross-Modal Contrastive Learning Unlike image captioning tasks where the caption is a short descrip- tion of an image, our task utilizes multiple images as “prompts” to express personal feelings and opinions about them. To encourage generating expressive, diverse and visual-aligned explanations, we propose a Personalized Cross-Modal Contrastive Learning (𝑃𝐶2𝐿) framework. We first project the hidden representations of images, historical reviews, and the target sequence into a latent space: ˜𝐻𝑌 = 𝜙𝑌 (𝐻𝑌 ) ˜𝐻𝑉 = 𝜙𝑉 (𝐻𝑉 ), ˜𝐻 𝑅 = 𝜙𝑅 (𝐻 𝑅), (6) where 𝜙𝑉 , 𝜙𝑅, and 𝜙𝑌 consist of two fully connected layers with ReLU activation [30] and average pooling over the hidden states 𝐻𝑉 , 𝐻𝑅 and 𝐻𝑌 from the last self-attention layers. For the vanilla contrastive learning with InfoNCE loss [5, 33], we then maximize the similarity between the pair of source modality and target se- quence, while minimizing the similarity between the negative pairs as follows: LCL = − 𝑁 ∑︁ 𝑖=1 log exp(𝑠𝑋 ,𝑌 𝑖,𝑖 ) + (cid:205) 𝑗 ∈𝐾 ) exp(𝑠𝑋 ,𝑌 𝑖,𝑗 exp(𝑠𝑋 ,𝑌 𝑖,𝑖 , ) (7) , ˜𝐻𝑌 ( 𝑗) = sim( ˜𝐻 𝑋 (𝑖) where 𝑠𝑋 ,𝑌 )/𝜏, sim is the cosine similarity be- 𝑖,𝑗 tween two vectors, 𝜏 is the temperature parameter, (𝑖) and ( 𝑗) are two samples in the mini-batch, 𝐾 is the set of negative samples for sample (𝑖). One challenge of this task is the model is asked to describe multiple objects or contents in a set of images. To ensure the visual grounding between multiple image features and output text, we design a novel cross-modal contrastive loss. Specifically, given a target explanation 𝑌 = {𝑦1, 𝑦2, ..., 𝑦𝐿 }, we randomly replace the entities 4 in the text with other entities presented in the dataset to construct a hard negative sample 𝑌 ent = {𝑦 ′ , ...𝑦𝐿 } (i.e., “I like the sushi” to “I like the burger”), such that during training, the model is exposed to samples with incorrect entities regarding the images, which are non-trivial to distinguish from the original , 𝑦2, ...𝑦 ′ ent2 ent1 4We extract entities using spaCy noun chunks (https://spacy.io/). target sequence. Thus, we add the hidden representation of 𝑌 ent as an additional negative sample ent to formulate the cross-modal contrastive loss: LCCL = − 𝑁 ∑︁ 𝑖=1 log exp(𝑠𝑉 ,𝑌 𝑖,𝑖 ) exp(𝑠𝑉 ,𝑌 𝑖,𝑖 ) + (cid:205) 𝑗 ∈𝐾∪ent , (8) exp(𝑠𝑉 ,𝑌 𝑖,𝑗 ) On the other hand, to enhance the personalization of explanation generation, we re-weight negative pairs according to user personal- ities. The intuition is that users with more distinct personalities are more likely to generate different explanations. Motivated by this, we propose a weighted contrastive loss for personalization: LPCL = − 𝑁 ∑︁ 𝑖=1 log exp(𝑠𝑅,𝑌 𝑖,𝑖 ) 𝑖,𝑖 ) + 𝑓 (𝑖, 𝑗) (cid:205) 𝑗 ∈𝐾 exp(𝑠𝑅,𝑌 . (9) exp(𝑠𝑅,𝑌 𝑖,𝑗 ) where negative pairs in a mini-batch are re-weighted based on user personality similarity function 𝑓 . In our framework, user person- alities are represented by their historical reviews. Specifically, we define 𝑓 function as: 𝑓 (𝑖, 𝑗) = 𝛼 (1−sim( ˜𝑅 (𝑖 ) , ˜𝑅 ( 𝑗 ) )) (10) i.e., we reduce the weights of negative pairs with similar histories, and increase those with distinct histories. 𝛼 (𝛼 > 1) is a hyperparam- eter that weighs the negative samples, sim is the cosine similarity, ˜𝑅 (𝑖) and ˜𝑅 ( 𝑗) are the average features of two users’ input historical reviews. Overall, the model is optimized with a mixture of a cross-entropy loss and the two contrastive losses: L𝑙𝑜𝑠𝑠 = LCE + 𝜆1LCCL + 𝜆2LPCL, (11) where 𝜆1 and 𝜆2 are hyperparameters that weigh the two losses. 4.4 A Metric for Visual Grounding As mentioned in Section 2, we want our model to generate explana- tions that can accurately describe the content in a given image set. Typical n-gram evaluation metrics such as BLEU compute scores based on n-gram co-occurrences, which are originally proposed for diagnostic evaluation of machine translation systems but not capa- ble of evaluating text quality, as they are only sensitive to lexical variation and fail to reward semantic or syntactic variations be- tween predictions and references [38, 39, 50]. To effectively test the performance of the alignment between visual images and text ex- planations, we design an automatic evaluation metric: CLIP-Align based on [36]. Given a set of images 𝐼 = {𝑖1, 𝑖2, ..., 𝑖𝑛 } and a set of sentences from the generated text 𝑆 = {𝑠1, 𝑠2, ..., 𝑠𝑚 }, we first extract the embeddings of all the images and sentences with CLIP, we compute the metric as follows: CLIP-Align = 1 𝑛 𝑛 ∑︁ 𝑖=1 𝑚𝑎𝑥 ({cs1,𝑖, ..., cs𝑚,𝑖 }) (12) where cs𝑖,𝑗 is the confidence score produced by the CLIP-based classifier Φ trained on our annotated data. By replacing cs𝑖,𝑗 with the cosine similarity of image and sentence embeddings, we obtain another metric CLIP-Score, similar to [17]. Table 2: Results on personalized showcases with different models and different input modalities. Results are reported in per- centage (%). GT is the ground truth. An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley Model Input N-Gram Metrics Diversity Metrics Embedding Metrics BLEU-1 METEOR NIST Distinct-1 Distinct-2 CLIP-Align CLIP-Score BERT-Score GT ST R2Gen Ref2Seq Peter Ours - img img text text - 8.24 6.47 7.09 8.89 img img+text 9.92 10.40 - 3.41 3.10 3.80 3.28 3.64 3.83 - 28.08 36.55 30.78 34.45 37.35 50.64 6.06 2.74 3.23 0.92 0.38 3.37 3.58 43.23 17.41 22.45 5.89 1.27 26.37 28.58 90.47 80.84 82.07 73.51 72.70 84.78 85.31 28.41 24.31 24.28 23.83 23.27 24.68 24.50 - 85.20 85.89 84.71 86.94 88.03 88.23 Compared with previous CLIP-based metrics [17, 53], CLIP- Align focuses specifically on the accuracy and the alignment be- tween objects in the sentences and the images (e.g. “food is great” and “burger is great” achieves similar high scores with the same burger image computed on CLIP-Score, and a model that repet- itively generates “food is great” can reach high performance on CLIPscore in corpus level). Moreover, the vanilla CLIPscore [17] showed poor correlations with captions containing personal feel- ings, making it less suitable for this task. We show in Section 5 with automatic and human evaluation results that our metric performs better when evaluating alignment between images and text. 5 EXPERIMENTS In this section, we conduct extensive experiments to evaluate the performance of our personalized showcases framework. Ablation studies show the influence of different modalities to personalized showcases. Case studies and human evaluation are conducted to validate that our model present more diverse and accurate explana- tions than baselines. 5.1 Experimental Setting Baselines. To show the effectiveness of our model, we compare it with a number of popular baselines from different tasks, including image captioning, report generation and explanation generation: • ST [47] is a classic CNN+LSTM model for image captioning. • R2Gen [6] is a state-of-the-art memory-driven transformer specialized at generating long text with visual inputs. • Ref2Seq [31] is a popular reference-based seq2seq model for explanation generation in recommendation. • Peter [25] is a recent transformer-based explanation genera- tion model which uses the user and item IDs to predict the words in the target explanation. • img and text refer to image and text features respectively. K images {𝑖1, . . . , 𝑖𝐾 }, div@K is defined as: div@𝐾 = ∑︁ 1≤𝑚<𝑛 ≤𝐾 dis(𝑖𝑚, 𝑖𝑛) 𝐾 (𝐾 − 1)/2 . (13) For textual explanations, we first evaluate the relevance of gener- ated text and ground truth by n-gram based text evaluation metrics: BLEU (n=1,4) [34], METEOR [8] and NIST (n=4) [10]. To evaluate di- versity, we report Dinstinct-1 and Distinct-2 which is proposed in [24] for text generation models. We then use CLIP and BERT to compute embedding-based metrics. CLIP-Align is our proposed metrics in Section 4.2. CLIP-Score [17] BERT-Score [50] are two recent embedding-based metrics. Implementation Details. We use CLIP [35] with ViT-B/32 as image and text encoder to encode user historical reviews and images. We convert user profile feature into a 128-dimensional vector with a MLP model (1024→512→512→256→128), and convert candidate images with another MLP (512→512→512→256→128), where both models use ReLU activations [30]. We follow [45] to calculate each element of 𝑳 and optimize DPP using Adam [28] with an initial learning rate of 1e-3 and batch size 512. For inference, we use greedy decoding to select 𝐾 = 3 images as visual explanation. For training PC2L, we use AdamW [28] as the optimizer with an initial learning rate of 1e-4. The maximum sequence lengths are set to 64 which covers 95% of the explanations. The maximum number of images and historical reviews are set to 5 and 10 respectively. The hidden sizes of both the encoder and decoder are 768 with 12 heads. There are 3 layers in the encoder and 12 layers in the decoder. The batch size for training is 32. We use the GPT-2-small pre-trained weights with 117M parameters. The weighting parameters 𝜆1, 𝛼 and temperature 𝜏 are set to 0.2, 0.2, 𝑒 and 0.1 respectively. We use a beam size of 2 for decoding to balance the generation effectiveness and efficiency. Evaluation Metrics. For image selection, we report Precision@K, Recall@K and F1@K to measure the ranking quality. Due to the nature of our task, we set a small K (𝐾 = 3). To evaluate diversity, we introduce the truncated div@K (𝐾 = 3) for the average dissimi- larities for all image pairs in recommended images. Formally, given 5.2 Framework Performance We first report the model performance on text evaluation met- rics in Table 2, as we found this last step in our framework came with more challenges and interesting findings, e.g., how to gener- ate human-like explanations and avoid dull text, how to evaluate Personalized Showcases: Generating Multi-Modal Explanations for Recommendations Table 3: Ablation study for personalized image selection. Re- sults are reported in percentage (%). Accuracy Diversity Method random img text img+text Prec@3 Recall@3 F1@3 Div@3 4.87 25.21 15.28 25.21 6.14 34.05 20.58 34.37 5.43 28.97 17.54 29.09 30.24 17.12 18.68 17.07 the generation quality. Here the input images are selected by our model,5 and the input text consists of historical reviews from users. First, the clear gap between text-input models and image-input models on diversity and CLIP-based metrics validates the impor- tance of incorporating image features. The setting of visually-aware generation models is able to generate accurate explanations with diverse language style. Second, our 𝑃𝐶2𝐿 shows substantial im- provement on most of the metrics compared to LSTM and trans- former based models, showing that a pretrained language model with contrastive learning is able to generate high quality explana- tions. Finally, though text-based models Ref2Seq and Peter achieve competitive results with our method on some n-gram metrics such as BLEU and METEOR, their performance is much worse on di- versity and embedding metrics. The text quality is also low with repetitive and non-informative sentences appearing often, which we further validate with human evaluations and case studies. 5.3 Component Analysis We conduct ablation studies to evaluate the effectiveness of each component individually. Model for image set selection. First, we evaluate the perfor- mance of personalized image set selection. For general ranking performance, we compare our model with random selection and different input modalities. As shown in Table 3, though the trun- cated diversity of the text-only model is the highest, its performance is significantly worse than those with images in terms of ranking metrics. This indicates text input alone is far insufficient to pro- vide personalization for users, and its recommendation result is closer to that of random selection. Historical images on the other hand, provide an important visual cue for modeling users’ prefer- ence. Overall, a model with images and text can achieve the best ranking performance for image set selection, which validates the importance of our multi-modal setting for personalized showcases. Effectiveness of Contrastive Learning We conduct ablation stud- ies on different variations of our contrastive loss to verify the ef- fectiveness of our method. As shown in Table 4, our PC2L achieves the best performance over all baselines on different metrics. Specif- ically, CCL contributes more to the visual grounding by enforcing the model to distinguish random entities from the correct ones, and 5For effective training and evaluation of our framework, ground truth images of a given user are included in the image candidate pool for selecting. If it is for real-world deployment, ground truth images are not available but similar images can be selected. Table 4: Ablation study on contrastive learning. Baseline is to train a multi-modal decoder without contrastive learning. CL, CCL and PCL are the contrastive losses in Eq. (7), Eq. (8) and Eq. (9) Method Baseline img CL + text CL CCL+ text CL img CL + PCL 𝑃𝐶2𝐿 BLEU-1 Distinct-2 CLIP-Align 7.96 9.72 10.19 9.96 10.40 25.90 27.58 28.10 28.32 28.58 . 82.50 84.03 85.12 84.15 85.31 Figure 6: (a) The length distributions of generated texts on the test set. (b) The generated explanation coverage of nouns (Noun), adjectives (ADJ) and adverbs (ADV) in ground truth. improves CLIP-Align compared to the vanilla contrastive frame- work [5]. PCL improves more on diversity by encouraging the model to focus on users with dissimilar interest. To further evaluate the generation quality improved by con- trastive learning, we analyze the generated explanations from two aspects, length distributions of generations and keywords coverage. Figure 6 (a) compares the length distributions of generations on the test set to the ground truth. We categorize text lengths into 6 groups (within the range of [0, 60] with an interval of 10). The model without PC2L has a sharper distribution, while adding our PC2L leads to a distribution which is closer to the ground truth, demonstrating its effectiveness and the ability to generalize on unseen images. Note the ground truth contains more long texts than generations from the model since we set the max length to 64 during training and inference, which results in the discrepancy for text length greater than 60. Figure 6 (b) shows the keyword coverage (i.e., nouns, adjectives and adverbs) in output sentences. We consider an output as covering a keyword if the word exists in the corresponding ground truth. We compare two models trained with and without PC2L. We can see that PC2L improves the coverage of all kinds of keywords, which indicates our contrastive learning method diversifies and personalizes the generated text. Overall, incorporating contrastive learning into multi-modal explanation generation leads to better output quality with more diverse and visually-aligned texts. Can GPT-2 provide linguistic knowledge? Finally, we study whether GPT-2 can provide linguistic knowledge for our generation (cid:40)(cid:83)(cid:80)(cid:86)(cid:79)(cid:69)(cid:1)(cid:53)(cid:83)(cid:86)(cid:85)(cid:73) (cid:88)(cid:16)(cid:80)(cid:1) (cid:88)(cid:16)(cid:1) (cid:88)(cid:16)(cid:80)(cid:1) (cid:88)(cid:16)(cid:1) (cid:90) (cid:68) (cid:79) (cid:70) (cid:86) (cid:82) (cid:70) (cid:83) (cid:39) (cid:19)(cid:17)(cid:17)(cid:17) (cid:18)(cid:22)(cid:17)(cid:17) (cid:18)(cid:17)(cid:17)(cid:17) (cid:22)(cid:17)(cid:17) (cid:17) (cid:70) (cid:72) (cid:66) (cid:83) (cid:70) (cid:87) (cid:80) (cid:36) (cid:18)(cid:19)(cid:22)(cid:17) (cid:18)(cid:17)(cid:17)(cid:17) (cid:24)(cid:22)(cid:17) (cid:22)(cid:17)(cid:17) (cid:19)(cid:22)(cid:17) (cid:17) (cid:47)(cid:80)(cid:86)(cid:79) (cid:34)(cid:37)(cid:43)(cid:1)(cid:7)(cid:1)(cid:34)(cid:37)(cid:55) (b) (cid:17) (cid:18)(cid:17) (cid:21)(cid:17) (cid:20)(cid:17) (cid:19)(cid:17) (cid:53)(cid:70)(cid:89)(cid:85)(cid:1)(cid:45)(cid:70)(cid:79)(cid:72)(cid:85)(cid:73) (a) (cid:22)(cid:17) (cid:23)(cid:17) An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley Figure 7: Comparison between text-only explanations (i.e., Ref2Seq and Text GPT-2) and our showcases. User reviews are pro- cessed following Section 3.3. Table 5: Ablation Study on different initializations of the decoder. Random randomly initializes model weights. Text GPT-2 and Img GPT-2 are initialized with weights from [37]. Img GPT-2 + FT finetunes the model on a corpus similar to our training text data. Results are in percentage (%). Table 6: Human evaluation results on two models. We present the workers with reference text and images, and ask them to give scores from different aspects. Results are statis- tically significant via sign test (p<0.01). Method Img Random Text GPT-2 Img GPT-2 Img GPT-2 + FT BLEU-1 Distinct-1 Distinct-2 5.21 4.81 7.59 7.10 0.23 3.43 4.05 4.32 5.08 19.27 29.41 30.82 task. We train models with different weight initializations, with ground truth images (Img) or historical reviews (Text) as inputs. As shown in Table 5, comparing the performance of random and GPT-2 initialization, it is evident that the pretrained weights play a significant role. Finetuning on in-domain data (260k samples from users with one review and excluded from our personalization dataset) further improves domain-specific knowledge of the decoder and benefits generation performance on diversity metrics. 5.4 Case Study We study three examples (see Figure 7) and compare our person- alized showcases to single-modal explanations from Ref2Seq and Text GPT-2. Overall, our visual explanations is able to recommend images that fit users’ interest. This indicates the effectiveness of our image selection module and the selected images can be used as valid visual explanations. More importantly, these images can provide grounding information for text generation such that the textual explanations become more informative (i.e., specific dishes), which aligns with our CLIP-Align metric as well as human evaluations in Section 5.5. As is shown in Figure 7, we can see historical review text alone cannot provide correct explanations (see Case 1) to the Method Expressiveness Visual Alignment Ref2Seq PC2L 3.72 4.25 3.65 4.10 user (i.e., explanations from Ref2Seq and Text GPT-2 are irrelevant to the user review) and the sentences are monotonous (see Case 2). In contrast, our showcase provides relevant and diverse textual explanations based on images. In case 3, our generated text missed some entities in the user’s review since it only correctly describes one of the selected images. Hence, generating texts from multiple images is still a challenging problem for this new task. As we can observe from the examples, Ref2Seq tends to gen- erate explanations with the same pattern, which also match the observation in Table 2 that it has low Distinct-1 and Distinct-2. 5.5 Human Evaluation To fully evaluate our model, we conduct human evaluation on Amazon Mechanical Turk.6 For each model, we randomly sample 500 examples from the test set. Each example is scored by three human judges using a 5-point Likert scale to reduce variance. We instruct the annotators to consider two perspectives, expressiveness (semantically correct, diversity, no repetition) and visual alignment (the text describes the context of the images). As is shown in Table 6, PC2L significantly outperforms Ref2Seq, which is consistent with the automatic evaluation metrics. 6https://www.mturk.com/ We ordered pork and shrimp spring rolls that came with a peanut-y dipping sauce. Then we ordered a chicken banh-mi and a lemongrass beef with noodles. The steak frites was tasty - it was charred, which I really liked, and topped with a butter sauce. The truffle fries were also really, really good. The burger was delicious though! My co worker said the Pork Torta was delicious! Other guys had Gyro, pizza and fish tacos. My Bacon Cheeseburger was excellent. we ordered the fried rice and it was very good. i had the grilled chicken sandwich , which was delicious . i had the grilled cheese sandwich and it was delicious ! i love it if you want to eat japanese - style ramen. first time here, i had the bbq bacon cheeseburger medium rare with onion rings. the rice pilaf was very good as well. if you like vietnamese food, you should try this place out. the spring rolls are a definite must -. the pho is good. old school rustic feel with a wide selection of burgers and beers. the burgers were done well …… bloody mary was perfect. food was wonderful, try the fried green tomato breakfast tacos. EXAMPLE 1 EXAMPLE 2 EXAMPLE 3 Processed User Reviews Previous Ref2Seq Previous Text GPT-2 Ours Personalized Showcases Personalized Showcases: Generating Multi-Modal Explanations for Recommendations 6 RELATED WORK 6.1 Explanation Generation There has been a line of work that studies how to generate explana- tions for recommendations. Some work generates product reviews based on categorical attributes [52] images [42], or aspects [32]. Due to noise in reviews, Li et al. [26] generated ‘tips’ from the Yelp dataset which are more concise and informative as explanations in recommendation. To further improve the quality of generation, Ni et al. [31] proposed to identify justifications by dividing re- views into text segments and classifying text segments to get “good” justifications. Li et al. [25] proposed transformer-based model for recommendation explanation generations by incorporating user, item embeddings and related features. These text generation tasks leverage historical reviews from users or items. Images, on the other hand, provide rich information and grounding for text generation. Moreover, multi-modal information in our task (i.e., images and text) are more acceptable than text as explanations for users. In this paper, we propose a new task for generating multi-modal explanations and present a framework that provides personalized image showcases and visually-aware text explanations for recom- mendations. 6.2 Multi-Modal Learning Recent years have witnessed the success of deep learning on multi- modal learning and pretraining [4, 20, 35, 41]. These models usually adopt the Transformer [43] structure to encode visual and textual features for pretraining, to later benefit the multimodal downstream tasks. Among them, CLIP [35] is a powerful model trained on a massive amount of image-caption pairs, and has shown a strong zero-shot capability on various vision and language tasks [40]. Sev- eral methods [17, 53] used CLIP embeddings to compute modality similarities as evaluation metrics for image captioning and text generation tasks. In our work, we used CLIP extensively as the multi-modal en- coder for our framework. We also designed a new metric based on CLIP for evaluating the visual alignment between the image set and generated explanations. 6.3 Contrastive Learning The goal of contrastive learning [14, 33] is to learn representations by contrasting positive and negative pairs. It has been investigated in several fields of machine learning, including computer vision [5, 15, 21], natural language processing [12, 13, 19], and recommender systems [44, 46, 51]. A few recent work showed promising results of applying contrastive learning to conditional text generation, by generating adversarial examples [23], or finding hard negatives with pretrained language models [3, 48]. Our work differs in that we study contrastive learning for condi- tional text generation in a cross-modal setting, where we proposed a novel contrastive framework for generating personalized multi- modal explanations. 7 CONCLUSION In this paper, to generate explanations with rich information for recommendations, we introduce a new task, namely personalized showcases, and collect a large-scale dataset Gest from Google Local for the task. We design a personalized cross-modal contrastive learning framework to learn visual and textual explanations from user reviews. Experimental results show that showcases provide more informative and diverse explanations compared to previous text-only explanations. As future work, one promising direction is to develop an end-to-end framework for generating both visual and textual explanations. Besides, visual grounding on multiple images is still challenging for showcases. Another interesting setting is to address cold-start users or reviews written without images. We hope our dataset and framework would benefit the community for future research on multi-modalities and recommendations. A DATA CONSTRUCTION Our dataset is constructed from Google Local (i.e., maps) using a breadth-first-search algorithm with memorization. After collect- ing the review data, we filtered out reviews of length less than 5 words, which are less likely to provide useful information; we also removed reviews (2.13%) containing more than 10 images. The details of Gest-s1 construction for personalized image selection are as follows: We remove users with only one review for building a personalized dataset, then filter out reviews whose image urls are expired. After pre-processing, statistics for the personalized show- case dataset are shown in Table 1, where the number of images per business is 35.63 on average. We then randomly split the dataset by users, with 95,270/11,908/11,908 users for train/val/test. B VISUAL DIVERSITY DEFINITION We define the visual diversities in three levels as below: • Intra-Business Div: Measure the average diversity for im- age pairs at a business-level, where P1 (𝑏) means all the possible image pairs for business 𝑏. 𝑍1 is the valid counts7 of dis-similarity calculations (same as below): ∑︁ ∑︁ 𝑏 ∈𝐵 𝑚,𝑛 ∈ P (𝑏) dis(𝑖𝑏 𝑚, 𝑖𝑏 𝑛) 𝑍1 . (14) • Inter-User Div: Measure the average diversity for image pairs from different users for the same business, where P2 (𝑏) means all possible image pairs for business 𝑏 that come from different users: ∑︁ ∑︁ 𝑏 ∈𝐵 𝑚,𝑛 ∈ P2 (𝑏) dis(𝑖𝑏 𝑚, 𝑖𝑏 𝑛) 𝑍2 . (15) • Intra-User Div: Measure the average diversity in (business, user)-level, where P3 (𝑢, 𝑏) means all possible image pairs from user 𝑢 to business 𝑏: ∑︁ ∑︁ ∑︁ 𝑏 ∈𝐵 𝑢 ∈𝑈 𝑚,𝑛 ∈ P3 (𝑢,𝑏) dis(𝑖𝑏 𝑚, 𝑖𝑏 𝑛) 𝑍3 . (16) REFERENCES [1] Ashutosh Baheti, Alan Ritter, Jiwei Li, and William B. Dolan. 2018. Generating More Interesting Responses in Neural Conversation Models with Distributional Constraints. In EMNLP. 7When image set size is not more than 1, the dis-similarity calculation is invalid. [2] Jinze Bai, Chang Zhou, Junshuai Song, Xiaoru Qu, Weiting An, Zhao Li, and Jun Gao. 2019. Personalized Bundle List Recommendation. The World Wide Web Conference (2019). [3] Hengyi Cai, Hongshen Chen, Yonghao Song, Zhuoye Ding, Yongjun Bao, Weipeng Yan, and Xiaofang Zhao. 2020. Group-wise contrastive learning for neural dia- logue generation. arXiv preprint arXiv:2009.07543 (2020). [4] Jun Chen, Han Guo, Kai Yi, Boyang Li, and Mohamed Elhoseiny. 2021. VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning. [5] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A simple framework for contrastive learning of visual representations. In Interna- tional conference on machine learning. PMLR, 1597–1607. [6] Zhihong Chen, Yan Song, Tsung-Hui Chang, and Xiang Wan. 2020. Generating Ra- diology Reports via Memory-driven Transformer. arXiv preprint arXiv:2010.16056 (2020). [7] Zhongxia Chen, Xiting Wang, Xing Xie, Tong Wu, Guoqing Bu, Yining Wang, and Enhong Chen. 2019. Co-Attentive Multi-Task Learning for Explainable Recommendation. In IJCAI. [8] Michael Denkowski and Alon Lavie. 2011. Meteor 1.3: Automatic metric for reli- able optimization and evaluation of machine translation systems. In Proceedings of the sixth workshop on statistical machine translation. 85–91. [9] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL. [10] George Doddington. 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In Proceedings of the second international conference on Human Language Technology Research. 138–145. [11] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi- aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2021. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. ArXiv abs/2010.11929 (2021). [12] Hongchao Fang, Sicheng Wang, Meng Zhou, Jiayuan Ding, and Pengtao Xie. 2020. Cert: Contrastive self-supervised learning for language understanding. arXiv preprint arXiv:2005.12766 (2020). [13] Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021. SimCSE: Simple Contrastive Learning of Sentence Embeddings. arXiv preprint arXiv:2104.08821 (2021). [14] Michael Gutmann and Aapo Hyvärinen. 2010. Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics. JMLR Workshop and Conference Proceedings, 297–304. [15] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. 2020. Momen- tum contrast for unsupervised visual representation learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 9729–9738. [16] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition. 770–778. [17] Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras, and Yejin Choi. 2021. CLIPScore: A Reference-free Evaluation Metric for Image Captioning. arXiv preprint arXiv:2104.08718 (2021). [18] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751 (2019). [19] Jiaji Huang, Yi Li, Wei Ping, and Liang Huang. 2018. Large margin neural language model. arXiv preprint arXiv:1808.08987 (2018). [20] Zhicheng Huang, Zhaoyang Zeng, Bei Liu, Dongmei Fu, and Jianlong Fu. 2020. Pixel-bert: Aligning image pixels with text by deep multi-modal transformers. arXiv preprint arXiv:2004.00849 (2020). [21] Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, and Dilip Krishnan. 2020. Supervised contrastive learning. arXiv preprint arXiv:2004.11362 (2020). [22] Alex Kulesza and Ben Taskar. 2012. Determinantal Point Processes for Machine Learning. Found. Trends Mach. Learn. 5 (2012), 123–286. [23] Seanie Lee, Dong Bok Lee, and Sung Ju Hwang. 2020. Contrastive Learning with Adversarial Perturbations for Conditional Text Generation. arXiv preprint arXiv:2012.07280 (2020). [24] Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. 2015. A diversity-promoting objective function for neural conversation models. arXiv preprint arXiv:1510.03055 (2015). An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, Julian McAuley [29] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. 2015. Image-based recommendations on styles and substitutes. In Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval. 43–52. [30] Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve restricted boltzmann machines. In Icml. [31] Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Justifying recommendations using distantly-labeled reviews and fine-grained aspects. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 188–197. [32] Jianmo Ni and Julian McAuley. 2018. Personalized Review Generation By Ex- panding Phrases and Attending on Aspect-Aware Representations. In ACL. [33] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748 (2018). [34] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting of the Association for Computational Linguistics. 311–318. [35] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. 2021. Learning transferable visual models from natural language supervision. arXiv preprint arXiv:2103.00020 (2021). [36] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. 2021. Learning Transferable Visual Models From Natural Language Supervision. In ICML. [37] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. Language Models are Unsupervised Multitask Learners. [38] Ehud Reiter. 2018. A structured review of the validity of BLEU. Computational Linguistics 44, 3 (2018), 393–401. [39] Thibault Sellam, Dipanjan Das, and Ankur P Parikh. 2020. BLEURT: Learning robust metrics for text generation. arXiv preprint arXiv:2004.04696 (2020). [40] Sheng Shen, Liunian Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach, Kai- Wei Chang, Zhewei Yao, and Kurt Keutzer. 2021. How Much Can CLIP Benefit Vision-and-Language Tasks? arXiv preprint arXiv:2107.06383 (2021). [41] Hao Tan and Mohit Bansal. 2019. Lxmert: Learning cross-modality encoder representations from transformers. arXiv preprint arXiv:1908.07490 (2019). [42] Quoc-Tuan Truong and Hady Lauw. 2019. Multimodal review generation for recommender systems. In The World Wide Web Conference. 1864–1874. [43] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998–6008. [44] Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, Xuanping Li, and Tat-Seng Chua. 2021. Contrastive learning for cold-start recommendation. In Proceedings of the 29th ACM International Conference on Multimedia. 5382–5390. [45] Mark Wilhelm, Ajith Ramanathan, Alexander Bonomo, Sagar Jain, Ed H. Chi, and Jennifer Gillenwater. 2018. Practical Diversified Recommendations on YouTube with Determinantal Point Processes. Proceedings of the 27th ACM International Conference on Information and Knowledge Management (2018). [46] Xu Xie, Fei Sun, Zhaoyang Liu, Shiwen Wu, Jinyang Gao, Bolin Ding, and Bin Cui. 2020. Contrastive Learning for Sequential Recommendation. arXiv preprint arXiv:2010.14395 (2020). [47] Ke Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C. Courville, Ruslan Salakhutdinov, Richard S. Zemel, and Yoshua Bengio. 2015. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. In ICML. [48] An Yan, Zexue He, Xing Lu, Jiang Du, Eric Chang, Amilcare Gentili, Julian McAuley, and Chun-Nan Hsu. 2021. Weakly Supervised Contrastive Learning for Chest X-Ray Report Generation. arXiv preprint arXiv:2109.12242 (2021). [49] Hongyu Zang and Xiaojun Wan. 2017. Towards Automatic Generation of Product Reviews from Aspect-Sentiment Scores. In INLG. [50] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. 2019. Bertscore: Evaluating text generation with bert. arXiv preprint arXiv:1904.09675 (2019). [51] Chang Zhou, Jianxin Ma, Jianwei Zhang, Jingren Zhou, and Hongxia Yang. 2021. Contrastive learning for debiased candidate generation in large-scale recom- mender systems. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 3985–3995. [25] Lei Li, Yongfeng Zhang, and Li Chen. 2021. Personalized Transformer for Ex- [52] M. Zhou, Mirella Lapata, Furu Wei, Li Dong, Shaohan Huang, and Ke Xu. 2017. plainable Recommendation. In ACL/IJCNLP. [26] Piji Li, Zihao Wang, Lidong Bing, and Wai Lam. 2019. Persona-Aware Tips Generation? The World Wide Web Conference (2019). [27] Piji Li, Zihao Wang, Zhaochun Ren, Lidong Bing, and Wai Lam. 2017. Neu- ral Rating Regression with Abstractive Tips Generation for Recommendation. Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval (2017). [28] Ilya Loshchilov and Frank Hutter. 2017. Fixing Weight Decay Regularization in Adam. ArXiv abs/1711.05101 (2017). Learning to Generate Product Reviews from Attributes. In EACL. [53] Wanrong Zhu, Xin Eric Wang, An Yan, Miguel Eckstein, and William Yang Wang. 2021. ImaginE: An Imagination-Based Automatic Evaluation Metric for Natural Language Generation. arXiv preprint arXiv:2106.05970 (2021).","['personalize', 'showcase', 'generate', 'multimodal', 'explanation', 'recommendation', 'yan', 'zhankui', 'tianyang', 'r', 'x', 'abstract', 'exist', 'explanation', 'model', 'generate', 'text', 'recommenda', 'tion', 'still', 'struggle', 'produce', 'diverse', 'content', 'paper', 'far', 'enrich', 'explanation', 'propose', 'new', 'task', 'name', 'sonalized', 'showcase', 'provide', 'textual', 'visual', 'information', 'explain', 'recommendation', 'specifically', 'first', 'select', 'personalized', 'image', 'set', 'relevant', 'user', 'interest', 'recommend', 'item', 'natural', 'language', 'ex', 'planation', 'generate', 'accordingly', 'give', 'select', 'image', 'new', 'task', 'collect', 'largescale', 'dataset', 'cal', 'map', 'construct', 'highquality', 'subset', 'generate', 'multimodal', 'explanation', 'propose', 'personalized', 'multimodal', 'framework', 'generate', 'diverse', 'visuallyaligne', 'ex', 'planation', 'contrastive', 'learning', 'experiment', 'show', 'framework', 'benefit', 'different', 'modality', 'input', 'able', 'produce', 'diverse', 'expressive', 'explanation', 'compare', 'previous', 'method', 'variety', 'evaluation', 'metric', 'introduction', 'personalize', 'explanation', 'generation', 'model', 'potential', 'increase', 'transparency', 'reliability', 'recommendation', 'previous', 'work', 'consider', 'generate', 'textual', 'tion', 'user', 'historical', 'review', 'tip', 'justification', 'however', 'method', 'still', 'struggle', 'provide', 'diverse', 'explana', 'tion', 'large', 'amount', 'general', 'sentence', 'food', 'good', 'exist', 'generate', 'explanation', 'text', 'gener', 'ation', 'model', 'lack', 'ground', 'information', 'eg', 'image', 'generation', 'process', 'far', 'diversify', 'enrich', 'explanation', 'recommendation', 'propose', 'new', 'explanation', 'generation', 'task', 'name', 'personalize', 'showcase', 'show', 'figure', 'new', 'task', 'explain', 'recommendation', 'textual', 'visual', 'infor', 'mation', 'task', 'aim', 'provide', 'set', 'image', 'relevant', 'user', 'interest', 'generate', 'textual', 'explanation', 'accordingly', 'compare', 'previous', 'work', 'generate', 'text', 'tion', 'showcase', 'present', 'diverse', 'explanation', 'include', 'image', 'visuallyguide', 'text', 'end', 'first', 'challenge', 'task', 'build', 'dataset', 'exist', 'review', 'dataset', 'eg', 'amazon', 'yelp1', 'largely', 'unsuitable', 'task', 'far', 'discuss', 'dataset', 'thus', 'first', 'construct', 'largescale', 'multimodal', 'dataset', 'namely', 'g', 'collect', 'local2', 'restaurant', 'include', 'review', 'text', 'correspond', 'picture', 'improve', 'quality', 'g', 'personalized', 'showcase', 'annotate', 'small', 'subset', 'find', 'highly', 'match', 'imagesentence', 'pair', 'base', 'annotation', 'train', 'classifier', 'clip', 'extract', 'figure', 'illustration', 'previous', 'textonly', 'explanation', 'personalized', 'showcase', 'recommendation', 'give', 'recommend', 'item', 'business', 'textonly', 'explanation', 'model', 'use', 'historical', 'textual', 'review', 'user', 'item', 'side', 'generate', 'textual', 'explanation', 'propose', 'personalized', 'showcase', 'task', 'enrich', 'personalized', 'ex', 'planation', 'multimodal', 'visual', 'textual', 'tion', 'largely', 'improve', 'informativeness', 'di', 'versity', 'generate', 'explanation', 'visuallyaware', 'explanation', 'full', 'dataset', 'image', 'text', 'explanation', 'user', 'use', 'learning', 'target', 'personalized', 'showcase', 'new', 'task', 'design', 'new', 'multimodal', 'explanation', 'framework', 'begin', 'framework', 'select', 'several', 'image', 'historical', 'photo', 'business', 'user', 'tereste', 'framework', 'take', 'display', 'image', 'user', 'profile', 'eg', 'historical', 'review', 'input', 'learn', 'erate', 'textual', 'explanation', 'multimodal', 'decoder', 'however', 'generate', 'expressive', 'diverse', 'engaging', 'text', 'capture', 'user', 'interest', 'remain', 'challenge', 'problem', 'first', 'different', 'previous', 'textual', 'explanation', 'generation', 'alignment', 'multiple', 'image', 'generate', 'text', 'become', 'important', 'problem', 'showcase', 'pose', 'high', 'requirement', 'information', 'extraction', 'fusion', 'modality', 'second', 'typical', 'encod', 'decoder', 'model', 'crossentropy', 'loss', 'teacher', 'force', 'easily', 'lead', 'generate', 'repetitive', 'dull', 'sentence', 'occur', 'frequently', 'training', 'corpus', 'food', 'great', 'tackle', 'challenge', 'propose', 'personalized', 'cross', 'modal', 'contrastive', 'learn', 'pc2l', 'framework', 'contrast', 'put', 'modality', 'output', 'sequence', 'contrastive', 'learning', 'recommendation', 'food', 'japanese', 'food', 'food', 'delicious', 'burger', 'great', 'service', 'good', 'great', 'selection', 'beer', 'delicious', 'burger', 'bread', 'come', 'entree', 'soup', 'amazing', 'cheesecake', 'point', 'previous', 'textonly', 'explanation', 'eg', 'personalized', 'showcase', 'visualtextual', 'yan', 'zhankui', 'tianyang', 'figure', 'example', 'business', 'user', 'review', 'g', 'business', 'eg', 'italian', 'restaurant', 'gest', 'contain', 'historical', 'review', 'image', 'different', 'user', 'draw', 'attention', 'selfsupervise', 'representation', 'learn', 'proach', 'however', 'simply', 'train', 'negative', 'sample', 'minibatch', 'suboptimal', 'many', 'task', 'randomly', 'lected', 'embedding', 'easily', 'discriminate', 'latent', 'space', 'hence', 'first', 'design', 'crossmodal', 'contrastive', 'loss', 'enforce', 'alignment', 'image', 'output', 'explanation', 'construct', 'e', 'hard', 'negative', 'sample', 'randomly', 'replace', 'entity', 'output', 'motivate', 'observation', 'user', 'similar', 'histori', 'cal', 'review', 'share', 'similar', 'interest', 'far', 'design', 'personalized', 'contrastive', 'loss', 'reweight', 'negative', 'sample', 'base', 'history', 'similaritie', 'experimental', 'result', 'automatic', 'human', 'evaluation', 'show', 'model', 'able', 'generate', 'expressive', 'diverse', 'visuallyaligne', 'explanation', 'compare', 'variety', 'baseline', 'overall', 'contribution', 'follow', 'generate', 'informative', 'explanation', 'recommenda', 'tion', 'present', 'new', 'task', 'personalize', 'showcase', 'provide', 'textual', 'visual', 'explanation', 'recom', 'mendation', 'new', 'task', 'collect', 'largescale', 'multimodal', 'dataset', 'local', 'map', 'ensure', 'alignment', 'image', 'text', 'annotate', 'small', 'dataset', 'train', 'classifier', 'propagate', 'label', 'g', 'construct', 'high', 'quality', 'subset', 'generate', 'textual', 'explanation', 'propose', 'novel', 'multimodal', 'framework', 'personalized', 'showcase', 'apply', 'contrastive', 'learning', 'improve', 'diversity', 'visual', 'alignment', 'generate', 'text', 'comprehen', 'sive', 'experiment', 'automatic', 'human', 'evaluation', 'indicate', 'textual', 'explanation', 'showcase', 'expressive', 'diverse', 'exist', 'explanation', 'gen', 'eration', 'method', 'task', 'definition', 'personalized', 'showcase', 'task', 'aim', 'provide', 'sonalize', 'textual', 'visual', 'explanation', 'explain', 'recomman', 'dation', 'user', 'formally', 'give', 'user', 'business', 'item', '𝑏', '∈', '𝐵', 'user', 'set', 'business', 'set', 'respectively', 'personalized', 'showcase', 'task', 'provide', 'textual', 'explanation', 'visual', 'explanation', 'represent', 'sentence', 'image', 'explanation', '𝐼', 'match', 'personalize', 'explain', '𝑏', 'recommend', 'well', 'study', 'relation', 'textual', 'visual', 'expla', 'nation', 'provide', 'baseline', 'future', 'work', 'paper', 'decompose', 'task', 'step', 'show', 'figure', 'select', 'e', 'image', 'set', 'visual', 'explanation', 'relevant', 'user', 'interest', 'generate', 'textual', 'explanation', 'give', 'select', 'image', 'user', 'historical', 'review', '𝑖𝑏', '𝑖𝑏', 'formally', 'give', 'user', 'image', 'candidate', 'set', 'first', 'select', 'set', 'image', 'visual', 'explanation', 'user', 'interested', 'base', 'profile', 'historical', 'review', 'image', 'use', 'user', 'historical', 'review', '𝑋𝑢', 'select', 'image', 'generate', 'visuallyaware', 'textual', 'explanation', '𝑖𝑢', 'method', 'consider', 'follow', 'aspect', 'accuracy', 'aim', 'predict', 'target', 'image', 'image', 'associate', 'groundtruth', 'review', 'business', 'age', 'candidate', 'correctly', 'generate', 'text', 'expect', 'relevant', 'business', 'diversity', 'select', 'image', 'diverse', 'cover', 'information', 'business', 'eg', 'include', 'dish', 'restaurant', 'textual', 'explanation', 'diverse', 'expressive', 'alignment', 'previous', 'explanation', 'review', 'gener', 'ation', 'task', 'use', 'historical', 'review', 'aspect', 'input', 'visuallyaware', 'setting', 'provide', 'ground', 'image', 'hence', 'generate', 'explanation', 'new', 'task', 'aim', 'accurately', 'describe', 'content', 'cover', 'main', 'object', 'eg', 'name', 'dish', 'environment', 'give', 'set', 'image', 'amazing', 'good', 'cesar', 'salad', 'ever', 'cake', 'delicious', 'seafood', 'soup', 'excellent', 'granddaughter', 'love', 'spaghetti', 'meatball', 'excellent', 'experience', 'restaurant', 'ambience', 'romantic', 'perfect', 'couple', 'date', 'night', 'italian', 'restaurant', 'user', 'review', 'personalize', 'showcase', 'generate', 'multimodal', 'explanation', 'recommendation', 'figure', 'visual', 'diversity', 'comparison', 'b', 'c', 'e', 'denote', 'different', 'category', 'amazon', 'review', 'dataset', 'uniformly', 'sample', 'beauty', 'clothing', 'electronic', 'respectively', 'intrainter', 'user', 'diversity', 'yelp', 'dataset', 'unavailable', 'yelp', 'image', 'lack', 'user', 'information', 'dataset', 'statistic', 'collect', 'review', 'image', 'local', 'gestraw', 'table', 'show', 'data', 'statistic', 'crawl', 'dataset', 'see', 'gestraw', 'contain', 'review', 'user', 'business', 'review', 'least', 'image', 'raw', 'dataset', 'image', 'url', 'process', 'dataset', 'subset', 'gests1', 'personalized', 'image', 'set', 'selection', 'gests2', 'generation', 'statistic', 'process', 'dataset', 'ble', 'processing', 'detail', 'section', 'appendix', 'visual', 'diversity', 'analysis', 'distinguish', 'g', 'exist', 'review', 'dataset', 'show', 'usefulness', 'personalized', 'showcase', 'first', 'define', 'clipbase', 'similarity', 'level', 'measure', 'diversity', 'usergenerated', 'image', 'business', 'compare', 'visual', 'diversity', 'g', 'datum', 'representative', 'review', 'dataset', 'amazon', 'review', 'yelp', 'first', 'similar', 'use', 'cosine', 'similarity', 'denote', 'sim', 'pretraine', 'clip', 'define', 'dissimilarity', 'image', 'dis𝑖𝑚', 'sim𝑖𝑚', 'thus', 'introduce', 'visual', 'diversity', 'level', 'intrabusiness', 'div', 'interuser', 'div', 'intrauser', 'div', 'formally', 'define', 'b', 'high', 'score', 'mean', 'visual', 'diversity', 'investigate', 'visual', 'diversity', 'g', 'datum', 'well', 'amazon', 'review', 'use', 'category', 'sub', 'category', 'beauty', 'b', 'clothing', 'c', 'electronic', 'e', 'yelp', 'amazon', 'treat', 'item', 'page', 'business', 'review', 'collect', 'accord', 'item', 'calculation', 'sample', 'item', 'useruploaded', 'image', 'note', 'image', 'yelp', 'dataset', 'user', 'information', 'calculate', 'userlevel', 'diversity', 'yelp', 'figure', 'follow', 'observation', 'diversity', 'dataset', 'figure', 'show', 'g', 'amazon', 'interuser', 'div', 'high', 'intrauser', 'div', 'low', 'indicate', 'even', 'business', 'item', 'user', 'focus', 'present', 'different', 'visual', 'information', 'figure', 'example', 'usergenerated', 'image', 'amazon', 'item', 'page', 'yelp', 'business', 'amazon', 'image', 'mainly', 'focus', 'single', 'item', 'yelp', 'image', 'business', 'diverse', 'current', 'public', 'yelp', 'dataset', 'userimage', 'interaction', 'table', 'datum', 'statistic', 'g', 'avg', 'r', 'len', 'denote', 'average', 'review', 'length', 'bus', 'denote', 'number', 'business', 'raw', 'denote', 'raw', 's1', 'denote', 'g', 'datum', 'first', 'step', 's2', 'denote', 'g', 'datum', 'second', 'step', 'propose', 'personalized', 'showcase', 'framework', 'dataset', 'image', 'review', 'user', 'bus', 'r', 'gestraw', 'gests1', 'gests2', 'g', 'amazon', 'figure', 'visual', 'diversity', 'amazon', 'consistently', 'low', 'gest', 'large', 'margin', 'try', 'explain', 'discuss', 'difference', 'user', 'behavior', 'platform', 'example', 'figure', 'usergenerated', 'image', 'usually', 'focus', 'purchase', 'item', 'information', 'want', 'show', 'differ', 'usually', 'single', 'object', 'image', 'purchase', 'item', 'thus', 'visual', 'diversity', 'limit', 'g', 'example', 'figure', 'show', 'review', 'restaurant', 'allow', 'user', 'share', 'diverse', 'information', 'varied', 'item', 'angle', 'aspect', 'compare', 'amazon', 'use', 'g', 'generate', 'informative', 'personalized', 'showcase', 'accord', 'different', 'user', 'profile', 'g', 'yelp', 'yelp', 'image', 'highquality', 'example', 'figure', 'intrabusiness', 'div', 'high', 'gest', 'image', 'yelp', 'similar', 'image', 'g', 'however', 'yelp', 'image', 'fit', 'task', 'lack', 'user', 'information', 'explanation', 'distillation', 'review', 'often', 'contain', 'uninformative', 'text', 'irrelevant', 'image', 'use', 'directly', 'explanation', 'hence', 'con', 'struct', 'explanation', 'dataset', 'gestraw', 'distill', 'sentence', 'review', 'align', 'content', 'give', 'image', 'valid', 'explanation', 'annotator', 'ask', 'label', 'review', 'imagesentence', 'pair', 'randomly', 'sample', 'full', 'dataset', 'task', 'decide', 'sentence', 'describe', 'image', 'label', 'ing', 'perform', 'iteratively', 'follow', 'feedback', 'discussion', 'intrabusiness', 'interuser', 'intrauser', 'g', 'amazona', 'amazonb', 'amazonc', 'amazone', 'yelp', 'amazon', 'yelp', 'yan', 'zhankui', 'tianyang', 'figure', 'illustration', 'personalized', 'showcase', 'framework', 'give', 'business', 'take', 'user', 'historical', 'image', 'tual', 'review', 'input', 'first', 'select', 'image', 'set', 'relevant', 'user', 'interest', 'generate', 'natural', 'language', 'explanation', 'accordingly', 'multimodal', 'decoder', 'crossmodal', 'contrastive', 'loss', 'personalized', 'contrastive', 'loss', 'apply', 'input', 'modality', 'explanation', 'last', 'select', 'image', 'generate', 'textual', 'explanation', 'organize', 'multimodal', 'explanation', 'user', 'quality', 'align', 'annotator', 'annotated', 'imagesentence', 'pair', 'split', 'train', 'validation', 'testing', 'ratio', 'train', 'binary', 'classification', 'model', 'base', 'annotated', 'imagesentence', 'pair', 'correspond', 'label', 'specifically', 'extract', 'embedding', 'sentence', 'image', 'clip', 'feature', 'concatenate', 'feed', 'fully', 'connected', 'layer', 'classifier', 'achieve', 'auc', 'f1', 'score', 'test', 'set', 'similar', 'result', 'obtain', 'build', 'textonly', 'explanation', 'dataset', 'use', 'model', 'extract', 'explanation', 'review', 'statistic', 'dataset', 'gests2', 'find', 'table', 'methodology', 'section', 'present', 'framework', 'produce', 'personal', 'ized', 'showcase', 'overview', 'show', 'figure', 'start', 'personalized', 'image', 'set', 'selection', 'visuallyaware', 'generation', 'module', 'introduce', 'personalized', 'crossmodal', 'contrastive', 'learning', 'approach', 'section', 'personalize', 'image', 'set', 'selection', 'first', 'step', 'select', 'image', 'set', 'visual', 'explanation', 'relevant', 'user', 'interest', 'diverse', 'formulate', 'selection', 'step', 'diverse', 'recommendation', 'multimodal', 'input', 'multimodal', 'encoder', 'generally', 'user', 'textual', 'visual', 'profile', 'effectively', 'encode', 'different', 'pretraine', 'deep', 'neural', 'network', 'eg', 'resnet', 'choose', 'stateoftheart', 'pretraine', 'crossmodal', 'trieval', 'model', 'textual', 'visualencoder', 'clip', 'encode', 'raw', 'image', 'image', 'feature', 'encode', 'user', 'textual', 'visual', 'profile', 'user', 'profile', 'feature', 'image', 'selection', 'model', 'use', 'determinantal', 'point', 'process', 'dpp', 'method', 'select', 'image', 'subset', 'recently', 'use', 'different', 'diverse', 'recommendation', 'task', 'com', 'pare', 'algorithm', 'individual', 'item', 'recommendation', 'dppbased', 'model', 'suitable', 'multiple', 'image', 'selection', 'give', 'user', 'business', '𝑏', 'predict', 'image', 'set', 'follow', 'image', 'set', 'belong', 'business', '𝑏', 'design', 'calculate', 'userimage', 'relevance', 'use', 'clipbased', 'user', 'profile', 'feature', 'image', 'feature', 'detail', 'model', 'visuallyaware', 'explanation', 'generation', 'obtain', 'image', 'set', 'aim', 'generate', 'personalized', 'expla', 'nation', 'give', 'set', 'image', 'user', 'historical', 'review', 'extract', 'explanation', 'dataset', 'gests2', 'section', 'specifically', 'build', 'multimodal', 'encoderdecod', 'model', 'gpt2', 'backbone', 'multimodal', 'encoder', 'give', 'set', 'user', '𝑢’s3', 'historical', 'review', 'use', 'text', 'encoder', 'clip', 'extract', 'review', 'feature', '𝑟𝐾', 'similar', 'operation', 'apply', 'input', 'image', 'use', 'pretraine', 'resnet', 'extract', 'visual', 'feature', '𝑣1', 'feature', 'project', 'latent', 'space', '𝑖', '𝑊', '𝑉', '𝑣𝑖', '𝑍', '𝑟𝑖', 'learnable', 'projection', 'matrix', 'use', 'multimodal', 'attention', 'mma', 'module', 'stack', 'self', 'attention', 'layer', 'encode', 'input', 'feature', '𝑖', '𝑊', '𝐻', '𝑅', '𝑖', 'aggregate', 'feature', 'modality', '𝑖', 'denote', 'concatenation', 'flexible', 'design', 'allow', 'variable', 'length', 'modality', 'enable', 'interaction', 'modali', 'tie', 'coattention', '3we', 'omit', 'subscript', '𝑢', 'review', 'image', 'business', 'multi', 'modal', 'encod', 'selection', 'model', 'user', 'historical', 'image', 'get', 'scallop', 'bad', 'hombre', 'drink', 'amazing', 'user', 'historical', 'review', 'step', 'personalize', 'image', 'set', 'selection', 'crossmodal', 'contrastive', 'learn', 'multi', 'modal', 'encod', 'modal', 'decoder', 'personalize', 'contrastive', 'learning', 'step', 'visuallyaware', 'explanation', 'fresh', 'good', 'bomb', 'even', 'dream', 'night', 'personalized', 'showcase', 'generate', 'multimodal', 'explanation', 'recommendation', 'multimodal', 'decoder', 'inspire', 'recent', 'advance', 'powerful', 'pretraine', 'language', 'model', 'leverage', 'gpt2', 'decoder', 'generate', 'explanation', 'efficiently', 'adapt', 'linguistic', 'knowl', 'edge', 'gpt2', 'insert', 'encoderdecod', 'attention', 'module', 'pretraine', 'model', 'similar', 'architecture', 'multimodal', 'gpt2', 'give', 'target', 'explanation', 'decode', 'process', 'time', 'step', 'formalize', 'ˆ𝑦𝑡', 'decoder𝐻𝑉', '𝑦𝑡', 'use', 'crossentropy', 'ce', 'loss', 'maximize', 'conditional', 'log', 'likelihood', 'log', '𝑁', 'training', 'sample', '𝑖', '𝑖', 'follow', '−', '∑︁', 'log', '𝑝𝜃', '𝑖', 'use', 'ground', 'truth', 'image', 'user', 'training', 'image', 'imageselection', 'model', 'inference', 'personalize', 'crossmodal', 'contrastive', 'learning', 'image', 'captioning', 'task', 'caption', 'short', 'descrip', 'tion', 'image', 'task', 'utilize', 'multiple', 'image', 'prompt', 'express', 'personal', 'feeling', 'opinion', 'encourage', 'generate', 'expressive', 'diverse', 'visualaligne', 'explanation', 'propose', 'personalized', 'crossmodal', 'contrastive', 'learning', '𝑃𝐶2𝐿', 'framework', 'first', 'project', 'hide', 'representation', 'image', 'historical', 'review', 'target', 'sequence', 'latent', 'space', '𝜙𝑅', '𝜙𝑅', 'consist', 'fully', 'connect', 'layer', 'relu', 'activation', 'average', 'pooling', 'hide', 'state', 'last', 'selfattention', 'layer', 'vanilla', 'contrastive', 'learn', 'infonce', 'loss', 'maximize', 'similarity', 'pair', 'source', 'modality', 'target', 'quence', 'minimize', 'similarity', 'negative', 'pair', 'follow', '−', '∑︁', 'log', 'cid205', 'sim', '𝜏', 'sim', 'cosine', 'similarity', 'tween', 'vector', 'temperature', 'parameter', '𝑗', 'sample', 'minibatch', 'set', 'negative', 'sample', 'sample', 'challenge', 'task', 'model', 'ask', 'describe', 'multiple', 'object', 'content', 'set', 'image', 'ensure', 'visual', 'grounding', 'multiple', 'image', 'feature', 'output', 'text', 'design', 'novel', 'crossmodal', 'contrastive', 'loss', 'specifically', 'give', 'target', 'explanation', 'randomly', 'replace', 'entity', 'text', 'entity', 'present', 'dataset', 'construct', 'hard', 'negative', 'sample', 'ent', '𝑦', '′', 'like', 'burger', 'train', 'model', 'expose', 'sample', 'incorrect', 'entity', 'regard', 'image', 'nontrivial', 'distinguish', 'original', '𝑦', '′', 'ent2', '4we', 'extract', 'entity', 'use', 'spacy', 'noun', 'chunk', 'target', 'sequence', 'thus', 'add', 'hide', 'representation', 'ent', 'additional', 'negative', 'sample', 'ent', 'formulate', 'crossmodal', 'contrastive', 'loss', 'lccl', '−', '∑︁', 'log', 'cid205', '∈𝐾∪ent', 'hand', 'enhance', 'personalization', 'explanation', 'generation', 'reweight', 'negative', 'pair', 'accord', 'user', 'personal', 'itie', 'intuition', 'user', 'distinct', 'personality', 'likely', 'generate', 'different', 'explanation', 'motivate', 'propose', 'weighted', 'contrastive', 'loss', 'personalization', 'lpcl', '−', '∑︁', 'cid205', '𝑗', 'exp𝑠𝑅𝑌', 'negative', 'pair', 'minibatch', 'reweighte', 'base', 'user', 'personality', 'similarity', 'function', 'framework', 'user', 'person', 'alitie', 'represent', 'historical', 'review', 'specifically', 'define', 'function', 'reduce', 'weight', 'negative', 'pair', 'similar', 'history', 'increase', 'distinct', 'history', 'hyperparam', 'eter', 'weigh', 'negative', 'sample', 'sim', 'cosine', 'similarity', '𝑖', '𝑗', 'average', 'feature', 'user', 'input', 'historical', 'review', 'overall', 'model', 'optimize', 'mixture', 'crossentropy', 'loss', 'contrastive', 'loss', 'l𝑙𝑜𝑠𝑠', '𝜆2lpcl', '𝜆2', 'hyperparameter', 'weigh', 'loss', 'metric', 'visual', 'grounding', 'mention', 'section', 'want', 'model', 'generate', 'explana', 'tion', 'accurately', 'describe', 'content', 'give', 'image', 'set', 'typical', 'evaluation', 'metric', 'compute', 'score', 'base', 'cooccurrence', 'originally', 'propose', 'diagnostic', 'evaluation', 'machine', 'translation', 'system', 'capa', 'evaluate', 'text', 'quality', 'sensitive', 'lexical', 'variation', 'fail', 'reward', 'semantic', 'syntactic', 'variation', 'tween', 'prediction', 'reference', 'effectively', 'test', 'performance', 'alignment', 'visual', 'image', 'text', 'ex', 'planation', 'design', 'automatic', 'evaluation', 'metric', 'clipalign', 'base', 'give', 'set', 'image', 'set', 'sentence', 'generate', 'text', 'first', 'extract', 'embedding', 'image', 'sentence', 'clip', 'compute', 'metric', 'follow', '∑︁', 'cs𝑚𝑖', 'cs𝑖𝑗', 'confidence', 'score', 'produce', 'clipbased', 'classifier', 'φ', 'train', 'annotated', 'datum', 'replace', 'cs𝑖𝑗', 'cosine', 'similarity', 'image', 'sentence', 'embedding', 'obtain', 'metric', 'clipscore', 'similar', 'table', 'result', 'personalized', 'showcase', 'different', 'model', 'different', 'input', 'modality', 'result', 'report', 'centage', 'gt', 'ground', 'truth', 'yan', 'zhankui', 'tianyang', 'metric', 'diversity', 'metric', 'embed', 'metric', 'bleu1', 'meteor', 'nist', 'distinct1', 'distinct2', 'bertscore', 'peter', 'img', 'text', 'text', 'img', 'imgtext', 'compare', 'previous', 'clipbased', 'metric', 'clip', 'align', 'focus', 'specifically', 'accuracy', 'alignment', 'tween', 'object', 'sentence', 'image', 'eg', 'food', 'great', 'burger', 'great', 'achieve', 'similar', 'high', 'score', 'burger', 'image', 'compute', 'clipscore', 'model', 'repet', 'itively', 'generate', 'food', 'great', 'reach', 'high', 'performance', 'clipscore', 'level', 'moreover', 'vanilla', 'clipscore', 'show', 'poor', 'correlation', 'caption', 'contain', 'personal', 'feel', 'ing', 'make', 'less', 'suitable', 'task', 'show', 'section', 'automatic', 'human', 'evaluation', 'result', 'metric', 'perform', 'well', 'evaluate', 'alignment', 'image', 'text', 'experiment', 'section', 'conduct', 'extensive', 'experiment', 'evaluate', 'performance', 'personalized', 'showcase', 'framework', 'ablation', 'study', 'show', 'influence', 'different', 'modality', 'personalized', 'showcase', 'case', 'study', 'human', 'evaluation', 'conduct', 'validate', 'model', 'present', 'diverse', 'accurate', 'tion', 'baseline', 'experimental', 'set', 'baseline', 'show', 'effectiveness', 'model', 'compare', 'number', 'popular', 'baseline', 'different', 'task', 'include', 'image', 'captioning', 'report', 'generation', 'explanation', 'generation', 'classic', 'cnnlstm', 'model', 'image', 'captioning', 'stateoftheart', 'transformer', 'specialize', 'generate', 'long', 'text', 'visual', 'input', 'popular', 'referencebased', 'seq2seq', 'model', 'explanation', 'generation', 'recommendation', 'recent', 'transformerbase', 'explanation', 'genera', 'tion', 'model', 'use', 'user', 'item', 'id', 'predict', 'word', 'target', 'explanation', 'text', 'refer', 'image', 'text', 'feature', 'respectively', 'image', 'define', 'div𝐾', '∑︁', '≤𝐾', 'dis𝑖𝑚', 'textual', 'explanation', 'first', 'evaluate', 'relevance', 'gener', 'ate', 'text', 'ground', 'truth', 'base', 'text', 'evaluation', 'metric', 'meteor', 'nist', 'n4', 'evaluate', 'di', 'versity', 'report', 'dinstinct1', 'distinct2', 'propose', 'text', 'generation', 'model', 'use', 'clip', 'compute', 'embeddingbased', 'metric', 'clipalign', 'propose', 'metric', 'section', 'clipscore', 'recent', 'embeddingbased', 'metric', 'implementation', 'detail', 'use', 'clip', 'vitb32', 'image', 'text', 'encoder', 'encode', 'user', 'historical', 'review', 'image', 'convert', 'user', 'profile', 'feature', 'vector', 'model', 'convert', 'candidate', 'image', 'model', 'use', 'relu', 'activation', 'follow', 'calculate', 'element', 'optimize', 'dpp', 'use', 'initial', 'learning', 'rate', 'batch', 'size', 'inference', 'use', 'greedy', 'decode', 'select', 'image', 'visual', 'explanation', 'training', 'use', 'optimizer', 'initial', 'learning', 'rate', 'maximum', 'sequence', 'length', 'set', 'cover', 'explanation', 'maximum', 'number', 'image', 'historical', 'review', 'set', 'respectively', 'hide', 'size', 'encoder', 'decoder', 'head', 'layer', 'encoder', 'layer', 'decoder', 'batch', 'size', 'training', 'use', 'pretraine', 'weight', 'parameter', 'weighting', 'parameter', '𝜆1', '𝛼', 'temperature', '𝜏', 'set', '𝑒', 'respectively', 'use', 'beam', 'size', 'decode', 'balance', 'generation', 'effectiveness', 'efficiency', 'evaluation', 'metric', 'image', 'selection', 'report', 'precisionk', 'recallk', 'f1k', 'measure', 'ranking', 'quality', 'nature', 'task', 'set', 'small', 'evaluate', 'diversity', 'introduce', 'truncated', 'average', 'dissimi', 'laritie', 'image', 'pair', 'recommend', 'image', 'formally', 'give', 'framework', 'performance', 'first', 'report', 'model', 'performance', 'text', 'evaluation', 'meet', 'ric', 'table', 'find', 'last', 'step', 'framework', 'come', 'challenge', 'interesting', 'finding', 'eg', 'eat', 'humanlike', 'explanation', 'avoid', 'dull', 'text', 'evaluate', 'personalized', 'showcase', 'generate', 'multimodal', 'explanation', 'recommendation', 'table', 'ablation', 'study', 'personalized', 'image', 'selection', 'sult', 'report', 'percentage', 'accuracy', 'diversity', 'method', 'random', 'img', 'text', 'imgtext', 'prec3', 'recall3', 'generation', 'quality', 'input', 'image', 'select', 'model5', 'input', 'text', 'consist', 'historical', 'review', 'user', 'first', 'clear', 'gap', 'textinput', 'model', 'imageinput', 'model', 'diversity', 'clipbased', 'metric', 'validate', 'impor', 'tance', 'incorporate', 'image', 'feature', 'setting', 'visuallyaware', 'generation', 'model', 'able', 'generate', 'accurate', 'explanation', 'diverse', 'language', 'style', 'second', '𝑃𝐶2𝐿', 'show', 'substantial', 'provement', 'metric', 'compare', 'lstm', 'former', 'base', 'model', 'show', 'pretraine', 'language', 'model', 'contrastive', 'learning', 'able', 'generate', 'high', 'quality', 'explana', 'tion', 'finally', 'textbase', 'model', 'achieve', 'competitive', 'result', 'method', 'ngram', 'metric', 'meteor', 'performance', 'much', 'bad', 'di', 'versity', 'embed', 'metric', 'text', 'quality', 'also', 'low', 'repetitive', 'noninformative', 'sentence', 'appear', 'often', 'far', 'validate', 'human', 'evaluation', 'case', 'study', 'component', 'analysis', 'conduct', 'ablation', 'study', 'evaluate', 'effectiveness', 'component', 'individually', 'model', 'image', 'set', 'selection', 'first', 'evaluate', 'perfor', 'mance', 'personalized', 'image', 'set', 'selection', 'general', 'rank', 'performance', 'compare', 'model', 'random', 'selection', 'different', 'input', 'modality', 'show', 'table', 'trun', 'cat', 'diversity', 'textonly', 'model', 'high', 'performance', 'significantly', 'bad', 'image', 'term', 'rank', 'metric', 'indicate', 'text', 'input', 'alone', 'far', 'insufficient', 'pro', 'vide', 'personalization', 'user', 'recommendation', 'result', 'close', 'random', 'selection', 'historical', 'image', 'hand', 'provide', 'important', 'visual', 'cue', 'model', 'user', 'prefer', 'ence', 'overall', 'model', 'image', 'text', 'achieve', 'well', 'rank', 'performance', 'image', 'set', 'selection', 'validate', 'importance', 'multimodal', 'setting', 'personalized', 'showcase', 'effectiveness', 'contrastive', 'learning', 'conduct', 'ablation', 'stud', 'ie', 'different', 'variation', 'contrastive', 'loss', 'verify', 'fectiveness', 'method', 'show', 'table', 'pc2l', 'achieve', 'good', 'performance', 'baseline', 'different', 'metric', 'specif', 'ically', 'contribute', 'visual', 'grounding', 'enforce', 'model', 'distinguish', 'random', 'entity', 'correct', 'one', '5for', 'effective', 'training', 'evaluation', 'framework', 'ground', 'truth', 'image', 'give', 'user', 'include', 'image', 'candidate', 'pool', 'select', 'realworld', 'deployment', 'ground', 'truth', 'image', 'available', 'similar', 'image', 'select', 'table', 'ablation', 'study', 'contrastive', 'learn', 'baseline', 'train', 'multimodal', 'decoder', 'contrastive', 'learning', 'cl', 'pcl', 'contrastive', 'loss', 'eq', 'eq', 'eq', 'method', 'baseline', 'cl', 'text', 'cl', 'img', 'bleu1', 'distinct2', 'figure', 'length', 'distribution', 'generate', 'text', 'test', 'set', 'generate', 'explanation', 'coverage', 'noun', 'adverb', 'ground', 'truth', 'improve', 'clipalign', 'compare', 'vanilla', 'contrastive', 'frame', 'work', 'pcl', 'improve', 'diversity', 'encourage', 'model', 'focus', 'user', 'dissimilar', 'interest', 'far', 'evaluate', 'generation', 'quality', 'improve', 'trastive', 'learning', 'analyze', 'generate', 'explanation', 'aspect', 'length', 'distribution', 'generation', 'keyword', 'coverage', 'figure', 'compare', 'length', 'distribution', 'generation', 'test', 'set', 'ground', 'truth', 'categorize', 'text', 'length', 'group', 'range', 'interval', 'model', 'sharp', 'distribution', 'add', 'lead', 'distribution', 'close', 'ground', 'truth', 'demonstrate', 'effectiveness', 'ability', 'generalize', 'unseen', 'image', 'note', 'ground', 'truth', 'contain', 'long', 'text', 'generation', 'model', 'set', 'max', 'length', 'training', 'inference', 'result', 'discrepancy', 'text', 'length', 'great', 'figure', 'b', 'show', 'noun', 'adverb', 'output', 'sentence', 'consider', 'output', 'cover', 'keyword', 'word', 'exist', 'correspond', 'ground', 'truth', 'compare', 'model', 'train', 'see', 'improve', 'coverage', 'kind', 'keyword', 'indicate', 'contrastive', 'learning', 'method', 'diversifie', 'personalize', 'generate', 'text', 'overall', 'incorporate', 'contrastive', 'learning', 'multimodal', 'explanation', 'generation', 'lead', 'well', 'output', 'quality', 'diverse', 'visuallyaligne', 'text', 'gpt2', 'provide', 'linguistic', 'knowledge', 'finally', 'study', 'gpt2', 'provide', 'linguistic', 'knowledge', 'generation', 'cid40cid83cid80cid86cid79cid69cid1cid53cid83cid86cid85cid73', 'cid88cid16cid80cid1', 'cid88cid16cid80cid1', 'cid18cid22cid17cid17', 'cid18cid17cid17cid17', 'cid22cid17cid17', 'cid18cid19cid22cid17', 'cid18cid17cid17cid17', 'cid24cid22cid17', 'cid22cid17cid17', 'cid19cid22cid17', 'cid34cid37cid43cid1cid7cid1cid34cid37cid55', 'cid18cid17', 'cid21cid17', 'cid20cid17', 'cid22cid17', 'cid23cid17', 'yan', 'zhankui', 'tianyang', 'figure', 'comparison', 'textonly', 'explanation', 'ref2seq', 'text', 'gpt2', 'showcase', 'user', 'review', 'pro', 'cessed', 'follow', 'section', 'table', 'ablation', 'study', 'different', 'initialization', 'decoder', 'random', 'randomly', 'initialize', 'model', 'weight', 'text', 'gpt2', 'img', 'initialize', 'weight', 'finetune', 'model', 'corpus', 'similar', 'training', 'text', 'datum', 'result', 'percentage', 'table', 'human', 'evaluation', 'result', 'model', 'present', 'worker', 'reference', 'text', 'image', 'ask', 'give', 'score', 'different', 'aspect', 'result', 'tically', 'significant', 'sign', 'test', 'p001', 'method', 'img', 'random', 'text', 'gpt2', 'bleu1', 'distinct1', 'task', 'train', 'model', 'different', 'weight', 'initialization', 'ground', 'truth', 'image', 'img', 'historical', 'review', 'text', 'input', 'show', 'table', 'compare', 'performance', 'random', 'gpt2', 'initialization', 'evident', 'pretraine', 'weight', 'play', 'significant', 'role', 'finetune', 'indomain', 'datum', 'sample', 'user', 'review', 'exclude', 'personalization', 'dataset', 'far', 'improve', 'domainspecific', 'knowledge', 'decoder', 'benefit', 'generation', 'performance', 'diversity', 'metric', 'case', 'study', 'study', 'example', 'see', 'figure', 'compare', 'person', 'alize', 'showcase', 'singlemodal', 'explanation', 'text', 'gpt2', 'overall', 'visual', 'explanation', 'able', 'recommend', 'image', 'fit', 'user', 'interest', 'indicate', 'effectiveness', 'image', 'selection', 'module', 'select', 'image', 'use', 'valid', 'visual', 'explanation', 'importantly', 'image', 'provide', 'ground', 'information', 'text', 'generation', 'textual', 'explanation', 'become', 'informative', 'specific', 'dish', 'align', 'clipalign', 'metric', 'well', 'human', 'evaluation', 'section', 'show', 'figure', 'see', 'historical', 'review', 'text', 'alone', 'provide', 'correct', 'explanation', 'see', 'case', 'method', 'visual', 'alignment', 'user', 'explanation', 'text', 'gpt2', 'irrelevant', 'user', 'review', 'sentence', 'monotonous', 'see', 'case', 'contrast', 'showcase', 'provide', 'relevant', 'diverse', 'textual', 'explanation', 'base', 'image', 'case', 'generate', 'text', 'miss', 'entity', 'user', 'review', 'correctly', 'describe', 'select', 'image', 'hence', 'generate', 'text', 'multiple', 'image', 'still', 'challenging', 'problem', 'new', 'task', 'observe', 'example', 'tend', 'explanation', 'pattern', 'also', 'match', 'observation', 'table', 'low', 'distinct1', 'distinct2', 'human', 'evaluation', 'fully', 'evaluate', 'model', 'conduct', 'human', 'evaluation', 'amazon', 'mechanical', 'turk6', 'model', 'randomly', 'sample', 'example', 'test', 'set', 'example', 'score', 'human', 'judge', 'use', 'likert', 'scale', 'reduce', 'variance', 'instruct', 'annotator', 'consider', 'perspective', 'expressiveness', 'semantically', 'correct', 'diversity', 'repetition', 'visual', 'alignment', 'text', 'describe', 'context', 'image', 'show', 'table', 'pc2l', 'significantly', 'outperform', 'consistent', 'automatic', 'evaluation', 'metric', 'order', 'pork', 'shrimp', 'spring', 'roll', 'come', 'peanuty', 'dip', 'sauce', 'order', 'chicken', 'banhmi', 'lemongrass', 'beef', 'noodle', 'steak', 'frite', 'tasty', 'char', 'really', 'like', 'top', 'butter', 'sauce', 'truffle', 'fry', 'also', 'really', 'really', 'good', 'burger', 'delicious', 'co', 'worker', 'say', 'pork', 'delicious', 'guy', 'gyro', 'pizza', 'fish', 'taco', 'bacon', 'cheeseburger', 'excellent', 'order', 'fry', 'rice', 'good', 'grill', 'chicken', 'sandwich', 'delicious', 'grill', 'cheese', 'sandwich', 'delicious', 'love', 'want', 'eat', 'japanese', 'style', 'raman', 'first', 'time', 'cheeseburger', 'medium', 'rare', 'onion', 'ring', 'rice', 'good', 'well', 'like', 'vietnamese', 'food', 'try', 'place', 'spring', 'roll', 'definite', 'pho', 'good', 'old', 'school', 'rustic', 'feel', 'wide', 'selection', 'burger', 'beer', 'burger', 'well', 'bloody', 'perfect', 'food', 'wonderful', 'try', 'fry', 'green', 'tomato', 'breakfast', 'taco', 'example', 'example', 'example', 'process', 'user', 'review', 'previous', 'previous', 'text', 'gpt2', 'personalized', 'showcase', 'personalize', 'showcase', 'generate', 'multimodal', 'explanation', 'recommendation', 'relate', 'work', 'explanation', 'generation', 'line', 'work', 'study', 'generate', 'explana', 'tion', 'recommendation', 'work', 'generate', 'product', 'review', 'base', 'categorical', 'attribute', 'image', 'aspect', 'due', 'noise', 'review', 'generate', 'tip', 'yelp', 'dataset', 'concise', 'informative', 'explanation', 'recommendation', 'far', 'improve', 'quality', 'generation', 'propose', 'identify', 'justification', 'divide', 'view', 'text', 'segment', 'classify', 'text', 'segment', 'get', 'good', 'justification', 'propose', 'transformerbase', 'model', 'recommendation', 'explanation', 'generation', 'incorporate', 'user', 'item', 'embedding', 'related', 'feature', 'text', 'generation', 'task', 'leverage', 'historical', 'review', 'user', 'item', 'image', 'hand', 'provide', 'rich', 'information', 'ground', 'text', 'generation', 'moreover', 'multimodal', 'information', 'task', 'image', 'text', 'acceptable', 'text', 'explanation', 'user', 'paper', 'propose', 'new', 'task', 'generate', 'multimodal', 'explanation', 'present', 'framework', 'provide', 'personalized', 'image', 'showcase', 'visuallyaware', 'text', 'explanation', 'recom', 'mendation', 'multimodal', 'learn', 'recent', 'year', 'witness', 'success', 'deep', 'learning', 'multi', 'modal', 'learning', 'pretraine', 'model', 'usually', 'adopt', 'transformer', 'structure', 'encode', 'visual', 'textual', 'feature', 'pretraine', 'later', 'benefit', 'multimodal', 'downstream', 'task', 'clip', 'powerful', 'model', 'train', 'massive', 'amount', 'imagecaption', 'pair', 'show', 'strong', 'zeroshot', 'capability', 'various', 'vision', 'language', 'task', 'sev', 'eral', 'method', 'use', 'clip', 'embedding', 'compute', 'modality', 'similarity', 'evaluation', 'metric', 'image', 'captioning', 'text', 'generation', 'task', 'work', 'use', 'clip', 'extensively', 'multimodal', 'coder', 'framework', 'also', 'design', 'new', 'metric', 'base', 'clip', 'evaluate', 'visual', 'alignment', 'image', 'set', 'generate', 'explanation', 'contrastive', 'learn', 'goal', 'contrastive', 'learning', 'learn', 'representation', 'contrast', 'positive', 'negative', 'pair', 'investigate', 'several', 'field', 'machine', 'learning', 'include', 'computer', 'vision', 'natural', 'language', 'processing', 'recommender', 'system', 'recent', 'work', 'show', 'promise', 'result', 'apply', 'contrastive', 'learning', 'conditional', 'text', 'generation', 'generate', 'adversarial', 'example', 'find', 'hard', 'negative', 'pretraine', 'language', 'model', 'work', 'differ', 'study', 'contrastive', 'learning', 'condi', 'text', 'generation', 'crossmodal', 'setting', 'propose', 'novel', 'contrastive', 'framework', 'generate', 'personalize', 'modal', 'explanation', 'conclusion', 'paper', 'generate', 'explanation', 'rich', 'information', 'recommendation', 'introduce', 'new', 'task', 'namely', 'personalize', 'showcase', 'collect', 'largescale', 'dataset', 'g', 'local', 'task', 'design', 'personalized', 'crossmodal', 'contrastive', 'learning', 'framework', 'learn', 'visual', 'textual', 'explanation', 'user', 'review', 'experimental', 'result', 'show', 'showcase', 'provide', 'informative', 'diverse', 'explanation', 'compare', 'previous', 'textonly', 'explanation', 'future', 'work', 'promise', 'direction', 'develop', 'endtoend', 'framework', 'generate', 'visual', 'textual', 'explanation', 'visual', 'grounding', 'multiple', 'image', 'still', 'challenge', 'showcase', 'interesting', 'setting', 'address', 'coldstart', 'user', 'review', 'write', 'image', 'hope', 'dataset', 'framework', 'benefit', 'community', 'future', 'research', 'multimodalitie', 'recommendation', 'data', 'construction', 'dataset', 'construct', 'local', 'map', 'use', 'breadthfirstsearch', 'algorithm', 'memorization', 'collect', 'e', 'review', 'datum', 'filter', 'review', 'length', 'less', 'word', 'less', 'likely', 'provide', 'useful', 'information', 'also', 'remove', 'review', 'contain', 'image', 'detail', 'gests1', 'construction', 'personalized', 'image', 'selection', 'follow', 'remove', 'user', 'review', 'build', 'personalized', 'dataset', 'filter', 'review', 'image', 'url', 'expire', 'preprocesse', 'statistic', 'personalized', 'show', 'case', 'dataset', 'show', 'table', 'number', 'image', 'business', 'average', 'randomly', 'split', 'dataset', 'user', 'user', 'trainvalt', 'visual', 'diversity', 'definition', 'define', 'visual', 'diversity', 'level', 'intrabusiness', 'div', 'measure', 'average', 'diversity', 'age', 'pair', 'businesslevel', 'mean', 'possible', 'image', 'pair', 'business', '𝑏', '𝑍1', 'valid', 'counts7', 'dissimilarity', 'calculation', '∑︁', '∑︁', '𝑏', 'p', 'dis𝑖𝑏', 'interuser', 'div', 'measure', 'average', 'diversity', 'image', 'pair', 'different', 'user', 'business', 'p2', '𝑏', 'mean', 'possible', 'image', 'pair', 'business', '𝑏', 'come', 'different', 'user', '∑︁', '∑︁', '𝑏', 'p2', 'dis𝑖𝑏', 'intrauser', 'div', 'measure', 'average', 'diversity', 'business', 'userlevel', 'mean', 'possible', 'image', 'pair', 'user', '𝑢', 'business', '𝑏', '∑︁', '∑︁', '∑︁', '𝑏', 'p3', 'reference', 'ashutosh', 'dolan', 'generate', 'interesting', 'response', 'neural', 'conversation', 'model', 'distributional', 'constraint', 'emnlp', 'image', 'set', 'size', 'dissimilarity', 'calculation', 'invalid', 'weite', 'personalized', 'bundle', 'list', 'recommendation', 'world', 'wide', 'web', 'conference', 'contrastive', 'learning', 'preprint', 'visualgpt', 'dataefficient', 'adaptation', 'pretraine', 'language', 'model', 'image', 'captioning', 'simple', 'framework', 'contrastive', 'learning', 'visual', 'representation', 'interna', 'tional', 'conference', 'machine', 'learning', 'pmlr', 'generate', 'diology', 'report', 'preprint', 'yine', 'multitask', 'learning', 'explainable', 'recommendation', 'meteor', 'automatic', 'metric', 'reli', 'able', 'optimization', 'evaluation', 'machine', 'translation', 'system', 'proceeding', 'sixth', 'workshop', 'statistical', 'machine', 'translation', 'pretraining', 'deep', 'bidirectional', 'transformer', 'language', 'understanding', 'automatic', 'evaluation', 'machine', 'translation', 'quality', 'use', 'cooccurrence', 'statistic', 'proceeding', 'second', 'international', 'conference', 'human', 'language', 'technology', 'research', 'alexey', 'dosovitskiy', 'minderer', 'georg', 'heigold', 'sylvain', 'gelly', 'jakob', 'uszkoreit', 'image', 'worth', 'word', 'transformer', 'image', 'recognition', 'scale', 'abs201011929', 'hongchao', 'cert', 'contrastive', 'selfsupervise', 'learning', 'language', 'understand', 'preprint', 'simple', 'contrastive', 'learning', 'sentence', 'embedding', 'arxiv', 'preprint', 'noisecontrastive', 'estimation', 'new', 'estimation', 'principle', 'unnormalized', 'statistical', 'model', 'proceeding', 'thirteenth', 'international', 'conference', 'artificial', 'intelligence', 'statistic', 'jmlr', 'workshop', 'conference', 'proceeding', 'kaime', 'fan', 'moman', 'tum', 'contrast', 'unsupervised', 'visual', 'representation', 'learn', 'proceeding', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'kaime', 'xiangyu', 'shaoqe', 'deep', 'residual', 'learning', 'image', 'recognition', 'proceeding', 'ieee', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'forbe', 'clipscore', 'referencefree', 'evaluation', 'metric', 'image', 'captioning', 'arxiv', 'preprint', 'buy', 'curious', 'case', 'neural', 'text', 'degeneration', 'preprint', 'large', 'margin', 'neural', 'language', 'preprint', 'pixelbert', 'align', 'image', 'pixel', 'text', 'deep', 'multimodal', 'transformer', 'preprint', 'prannay', 'khosla', 'dilip', 'supervise', 'contrastive', 'learning', 'arxiv', 'preprint', 'alex', 'determinantal', 'point', 'process', 'machine', 'learning', 'find', 'trend', 'mach', 'learn', 'seanie', 'contrastive', 'learning', 'adversarial', 'perturbation', 'conditional', 'text', 'generation', 'arxiv', 'preprint', 'bill', 'dolan', 'diversitypromote', 'objective', 'function', 'neural', 'conversation', 'model', 'preprint', 'yan', 'zhankui', 'tianyang', 'imagebase', 'recommendation', 'style', 'substitute', 'proceeding', '38th', 'international', 'acm', 'sigir', 'conference', 'research', 'development', 'information', 'vinod', 'nair', 'rectify', 'linear', 'unit', 'improve', 'restrict', 'boltzmann', 'machine', 'justify', 'recommendation', 'use', 'distantlylabele', 'review', 'finegrained', 'aspect', 'proceeding', 'conference', 'empirical', 'method', 'natural', 'language', 'processing', '9th', 'international', 'joint', 'conference', 'natural', 'language', 'processing', 'emnlpijcnlp', 'personalize', 'review', 'generation', 'ex', 'pande', 'phrase', 'attend', 'aspectaware', 'representation', 'vinyal', 'representation', 'learn', 'contrastive', 'predictive', 'code', 'arxiv', 'preprint', 'kishore', 'todd', 'ward', 'weije', 'bleu', 'method', 'automatic', 'evaluation', 'machine', 'translation', 'proceeding', '40th', 'annual', 'meeting', 'association', 'computational', 'linguistic', 'girish', 'sastry', 'learn', 'transferable', 'visual', 'model', 'natural', 'preprint', 'girish', 'sastry', 'ilya', 'sutskever', 'learn', 'transferable', 'visual', 'model', 'natural', 'language', 'supervision', 'sutskever', 'language', 'model', 'unsupervised', 'multitask', 'learner', 'structure', 'review', 'validity', 'thibault', 'bleurt', 'learn', 'robust', 'metric', 'text', 'generation', 'preprint', 'bansal', 'anna', 'much', 'clip', 'benefit', 'visionandlanguage', 'task', 'preprint', 'mohit', 'bansal', 'lxmert', 'learn', 'crossmodality', 'encod', 'representation', 'transformer', 'preprint', 'quoctuan', 'truong', 'multimodal', 'review', 'generation', 'recommender', 'system', 'world', 'wide', 'web', 'conference', 'ashish', 'vaswani', 'łukasz', 'attention', 'need', 'advance', 'neural', 'information', 'processing', 'system', '5998–6008', 'contrastive', 'learning', 'coldstart', 'recommendation', 'proceeding', '29th', 'acm', 'international', 'conference', 'multimedia', 'mark', 'gillenwater', 'practical', 'diversified', 'recommendation', 'youtube', 'determinantal', 'point', 'process', 'proceeding', '27th', 'acm', 'international', 'conference', 'information', 'knowledge', 'management', 'contrastive', 'learning', 'sequential', 'recommendation', 'preprint', 'show', 'attend', 'tell', 'neural', 'image', 'caption', 'generation', 'visual', 'attention', 'icml', 'yan', 'zexue', 'weakly', 'supervise', 'contrastive', 'learning', 'preprint', 'automatic', 'generation', 'product', 'review', 'aspectsentiment', 'score', 'inlg', 'weinberger', 'yoav', 'artzi', 'bertscore', 'evaluate', 'text', 'generation', 'preprint', 'contrastive', 'learning', 'debiased', 'candidate', 'generation', 'largescale', 'mender', 'system', 'proceeding', '27th', 'sigkdd', 'conference', 'knowledge', 'discovery', 'datum', 'mining', 'personalize', 'transformer', 'mirella', 'plainable', 'recommendation', 'personaaware', 'tip', 'generation', 'world', 'wide', 'web', 'conference', 'bing', 'neu', 'rating', 'regression', 'abstractive', 'tip', 'generation', 'recommendation', 'proceeding', '40th', 'international', 'acm', 'sigir', 'conference', 'research', 'development', 'information', 'ilya', 'loshchilov', 'hutter', 'fix', 'weight', 'decay', 'regularization', 'learn', 'generate', 'product', 'review', 'attribute', 'imagine', 'imaginationbase', 'automatic', 'evaluation', 'metric', 'natural', 'language', 'generation', 'preprint']"
Multivariate trace estimation in constant quantum depth,"[{'href': 'http://arxiv.org/abs/2206.15405v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2206.15405v1', 'rel': 'related', 'type': 'application/pdf'}]",2022-06-30 16:44:58,"Watch and Match: Supercharging Imitation with
Regularized Optimal Transport

Siddhant Haldar1

Vaibhav Mathur

Denis Yarats

Lerrel Pinto

New York University

rot-robot.github.io

Abstract:
Imitation learning holds tremendous promise in learning policies efﬁciently for
complex decision making problems. Current state-of-the-art algorithms often use
inverse reinforcement learning (IRL), where given a set of expert demonstrations,
an agent alternatively infers a reward function and the associated optimal policy.
However, such IRL approaches often require substantial online interactions for
complex control problems. In this work, we present Regularized Optimal Transport
(ROT), a new imitation learning algorithm that builds on recent advances in optimal
transport based trajectory-matching. Our key technical insight is that adaptively
combining trajectory-matching rewards with behavior cloning can signiﬁcantly
accelerate imitation even with only a few demonstrations. Our experiments on 20
visual control tasks across the DeepMind Control Suite, the OpenAI Robotics Suite,
and the Meta-World Benchmark demonstrate an average of 7.8× faster imitation
to reach 90% of expert performance compared to prior state-of-the-art methods.
On real-world robotic manipulation, with just one demonstration and an hour of
online training, ROT achieves an average success rate of 90.1% across 14 tasks.

Keywords: Imitation Learning, Manipulation, Robotics

2
2
0
2

n
u
J

0
3

]

O
R
.
s
c
[

1
v
9
6
4
5
1
.
6
0
2
2
:
v
i
X
r
a

Figure 1: (Top) Regularized Optimal Transport (ROT) is a new imitation learning algorithm that
adaptively combines ofﬂine behavior cloning with online trajectory-matching based rewards. This
enables signiﬁcantly faster imitation across a variety of simulated and real robotics tasks, while being
compatible with high-dimensional visual observation. (Bottom) On our xArm robot, ROT can learn
visual policies with only a single human demonstration and under an hour of online training.

1Correspondence to: sh6474@nyu.edu

Opening a box

Hanging a tote bag

Placing peg in a box

Pouring almonds

t
n
e
g
A

t
r
e
p
x
E

πBC

πROT

OT 
Rewards

Adaptive  
Regularization

OT Computation

Environments

Environment  
Interactions

 
 
 
 
 
 
1

Introduction

Imitation Learning (IL) [1, 2, 3] has a rich history that can be categorized across two broad paradigms,
Behavior Cloning (BC) [1] and Inverse Reinforcement Learning (IRL) [4]. BC uses supervised
learning to obtain a policy that maximizes the likelihood of taking the demonstrated action given an
observation in the demonstration. While this allows for training without online interactions, it suffers
from distributional mismatch during online rollouts [5]. IRL, on the other hand, infers the underlying
reward function from the demonstrated trajectories before employing RL to optimize a policy through
online environment rollouts. This results in a policy that can robustly solve demonstrated tasks even
in the absence of task-speciﬁc rewards [6, 7].

Although powerful, IRL methods suffer from a signiﬁcant drawback – they require numerous
expensive online interactions with the environment. There are three reasons for this: (a) the inferred
reward function is often highly non-stationary, which compromises the learning of the associated
behavior policy [7]; (b) even when the rewards are stationary, policy learning still requires effective
exploration to maximize rewards [8]; and (c) when strong priors such as pretraining with BC are
applied to accelerate policy learning, ensuing updates to the policy cause a distribution shift that
destabilizes training [9, 10]. Combined, these issues manifest themselves on empirical benchmarks,
where IRL methods have poor efﬁciency compared to vanilla RL methods on hard control tasks [11].

In this work, we present Regularized Optimal Transport (ROT) for imitation learning, a new method
that is conceptually simple, compatible with high-dimensional observations, and requires minimal
additional hyperparameters compared to standard IRL approaches. In order to address the challenge of
reward non-stationarity in IRL, ROT builds upon recent advances in using Optimal Transport (OT) [12,
13, 11] for reward computation that use non-parametric trajectory-matching functions. To alleviate the
challenge of exploration, we pretrain the IRL behavior policy using BC on the expert demonstrations.
This reduces the need for our imitation agent to explore from scratch.

However, even with OT-based reward computation and pretrained policies, we only obtain marginal
gains in empirical performance. The reason for this is that the high-variance of IRL policy gradi-
ents [14, 15] often wipe away the progress made by the ofﬂine BC pretraining. This phenomenon has
been observed in both online RL [16] and ofﬂine RL [9] methods. Inspired by solutions presented in
these works, we stabilize the online learning process by regularizing the IRL policy to stay close to
the pretrained BC policy. To enable this, we develop a new adaptive weighing scheme called soft
Q-ﬁltering that automatically sets the regularization – prioritizing staying close to the BC policy in the
beginning of training and prioritizing exploration later on. In contrast to prior policy regularization
schemes [16, 17], soft Q-ﬁltering does not require hand-speciﬁcation of decay schedules.

To demonstrate the effectiveness of ROT, we run extensive experiments on 20 simulated tasks across
DM Control [18], OpenAI Robotics [19], and Meta-world [20], and 14 robotic manipulation tasks on
an xArm (see Fig. 1). Our main ﬁndings are summarized below.

1. ROT outperforms prior state-of-the-art imitation methods, reaching 90% of expert performance

7.8× faster than our strongest baselines on simulated visual control benchmarks.

2. On real-world tasks, with a single human demonstration and an hour of training, ROT achieves an
average success rate of 90.1% with randomized robot initialization and image observations. This
is signiﬁcantly higher than behavior cloning (36.1%) and adversarial IRL (14.6%).

3. ROT exceeds the performance of state-of-the-art RL trained with rewards, while coming close to
methods that augment RL with demonstrations (Section 5.5 & Appendix H.3). Unlike standard
RL methods, ROT does not require hand-speciﬁcation of the reward function.

4. Ablation studies demonstrate the importance of every component in ROT, particularly the role
that soft Q-ﬁltering plays in stabilizing training and the need for OT-based rewards during online
learning (Section 5.3 & Appendix H.4).

Open-source code and demonstration data will be publicly released on our project website. Videos of
our trained policies can be seen here: rot-robot.github.io/.

2

Figure 2: (a) Given a single demonstration to avoid the grey obstacle and reach the goal location, BC
is unable to solve the task. (b) Finetuning from this BC policy with OT-based reward also fails to
solve the task. (c) ROT, with adaptive regularization of OT-based IRL with BC successfully solves
the task. (d) Even when the ROT agent is initialized randomly, it is able to solve the task.

2 Background

Before describing our method in detail, we provide a brief background to imitation learning with
optimal transport, which serves as the backbone of our method. Formalism related to RL follows the
convention in prior work [8, 11] and is described in Appendix A.

t=1}N

Imitation Learning with Optimal Transport (OT) The goal of imitation learning is to learn a
behavior policy πb given access to either the expert policy πe or trajectories derived from the expert
policy T e. While there are a multitude of settings with differing levels of access to the expert [21],
our work operates in the setting where the agent only has access to observation-based trajectories,
i.e. T e ≡ {(ot, at)T
n=1. Here N and T denotes the number of trajectory rollouts and episode
timesteps respectively. Inverse Reinforcement Learning (IRL) [4, 22] tackles the IL problem by
inferring the reward function re based on expert trajectories T e. Then given the inferred reward re,
policy optimization is used to derive the behavior policy πb.
To compute re, a new line of OT-based approaches for IL [12, 13, 11] have been proposed. Intuitively,
the closeness between expert trajectories T e and behavior trajectories T b can be computed by
measuring the optimal transport of probability mass from T b → T e. Thus, given a cost matrix
Ct,t(cid:48) = c(ob
t(cid:48)) and the optimal alignment µ∗ between a behavior trajectory ob and and expert
trajectory oe, a reward signal for each observation can be computed using the equation:

t , oe

rOT (ob

t ) = −

T
(cid:88)

t(cid:48)=1

Ct,t(cid:48) µ∗
t,t(cid:48)

(1)

A detailed account of the OT formulation has been provided in Appendix A.

Actor-Critic based reward maximization Given rewards obtained through OT computation, efﬁ-
cient maximization of the reward can be achieved through off-policy learning [7]. In this work, we use
Deep Deterministic Policy Gradient (DDPG) [23] as our base RL optimizer which is an actor-critic
algorithm that concurrently learns a deterministic policy πφ and a Q-function Qθ. However, instead
of minimizing a one step Bellman residual in vanilla DDPG, we use the recent n-step version of
DDPG from Yarats et al. [8] that achieves high performance on visual control problems.

3 Challenges in Online Finetuning from a Pretrained Policy

In this section, we study the challenges with ﬁnetuning a pretrained policy with online interactions in
the environment. Fig. 2 illustrates a task where an agent is supposed to navigate the environment
from the top left to the bottom right, while dodging obstacles in between. The agent has access to a
single expert demonstration, which is used to learn a BC policy for the task. Fig. 2 (a) shows that this
BC policy, though close to the expert demonstration, performs suboptimally due to accumulating
errors on out-of-distribution states during online rollouts [5]. Further, Fig. 2 (b) uses this BC policy

3

Expert trajectory
BC trajectory
Start location
Goal location

(a) Task: Particle Reach

(b) IRL Finetune w/o Reg.

(c) ROT

(d) ROT + random init.

100k

s
p
e
t
s
e
m

i
t

0

Expert trajectory

BC trajectory

Start location

Goal location

as an initialization and naively ﬁnetunes it with OT rewards (described in Section 2). Such naive
ﬁnetuning of a pretrained policy (or actor) with an untrained critic in an actor-critic framework
exhibits a forgetting behavior in the actor, resulting in performance degradation as compared to
the pretrained policy. This phenomenon has also been reported by Nair et al. [9] and we provide
a detailed discussion in Appendix B. In this paper, we propose ROT which addresses this issue by
adaptively keeping the policy close to the behavior data during the initial phase of ﬁnetuning and
reduces this dependence over time. Fig. 2 (c) demonstrates the performance of our approach on
such ﬁnetuning. It can be clearly seen that even though the BC policy is suboptimal, our proposed
adaptive regularization scheme quickly improves and solves the task by driving it closer to the expert
demonstration. In Fig. 2 (d), we demonstrate that even if the agent was initialized at points outside
the expert trajectory, the agent is still able to learn quickly and complete the task. This generalization
to starting states would not be possible with regular BC.

4 Regularized Optimal Transport

A fundamental challenge in imitation learning is to balance the ability to mimic demonstrated
actions along with the ability to recover from states outside the distribution of demonstrated states.
Behavior Cloning (BC) specializes in mimicking demonstrated actions through supervised learning,
while Inverse Reinforcement Learning (IRL) specializes in obtaining policies that can recover from
arbitrary states. Regularized Optimal Transport (ROT) combines the best of both worlds by adaptively
combining the two objectives. This is done in two phases. In the ﬁrst phase, a randomly initialized
policy is trained using the BC objective on expert demonstrated data. This ‘BC-pretrained’ policy
then serves as an initialization for the second phase. In the second phase, the policy is allowed access
to the environment where it can train using an IRL objective. To accelerate the IRL training, the
BC loss is added to the objective with an adaptive weight. Details of each component are described
below, with additional algorithmic details in Appendix C.

4.1 Phase 1: BC Pretraining

BC corresponds to solving the maximum likelihood problem shown in Eq. 2. Here T e refers to expert
demonstrations. When parameterized by a normal distribution with ﬁxed variance, the objective can
be framed as a regression problem where, given inputs se, πBC needs to output ae.

LBC = E(se,ae)∼T e (cid:107)ae − πBC(se)(cid:107)2

(2)

After training, it enables πBC to mimic the actions corresponding to the observations seen in the
demonstrations. However, during rollouts in an environment, small errors in action prediction can
lead to the agent visiting states not seen in the demonstrations [5]. This distributional mismatch often
causes πBC to fail on empirical benchmarks [16, 11] (see Fig. 2 (a) in Sec. 3).

4.2 Phase 2: Online Finetuning with IRL

Given a pretrained πBC model, we now begin online ‘ﬁnetuning’ of the policy πb ≡ πROT in the
environment. Since we are operating without explicit task rewards, we use rewards obtained through
OT-based trajectory matching, which is described in Section 2. These OT-based rewards rOT enable
the use of standard RL optimizers to maximize cumulative reward from πb ≡ πROT . In this work we
use n-step DDPG [23], a deterministic actor-critic based method that provides high-performance in
continuous control [8].

Finetuning with Regularization πBC is susceptible to distribution shift due to accumulation of
errors during online rollouts [5] and directly ﬁnetuning πBC also leads to subpar performance (refer
to Fig. 2 in Sec. 3). To address this, we build upon prior work in guided RL [16] and ofﬂine RL [9],
and regularize the training of πROT by combining it with a BC loss as seen in Eq. 3.

πROT = argmax

π

(cid:2)(1 − λ(π)))E(s,a)∼Dβ [Q(s, a)] − αλ(π)E(se,ae)∼T e (cid:107)ae − πBC(se)(cid:107)2(cid:3)

(3)

4

Here, Q(s, a) represents the Q-value from the critic used in actor-critic policy optimization. α is a
ﬁxed weight, while λ(π) is a policy-dependent adaptive weight that controls the contributions of the
two loss terms. Dβ refers to the replay buffer for online rollouts.

Adaptive Regularization with Soft Q-ﬁltering While prior work [16, 17] use hand-tuned sched-
ules for λ(π), we propose a new adaptive scheme that removes the need for tuning. This is done by
comparing the performance of the current policy πROT and the pretrained policy πBC on a batch of
data sampled from an expert replay buffer De. More precisely, given a behavior policy πBC(s), the
current policy πROT (s), the Q-function Q(s, a) and the replay buffer De, we set λ as:

λ(πROT ) = E(s,·)∼De

(4)
The strength of the BC regularization hence depends on the performance of the current policy with
respect to the behavior policy. This ﬁltering strategy is inspired by Nair et al. [24], where instead of a
binary hard assignment we use a soft continuous weight. Experimental comparisons with hand-tuned
decay strategies are presented in Section 5.3.

(cid:2)1Q(s,πBC (s))>Q(s,πROT (s))

(cid:3)

Considerations for image-based observations Since we are interested in using ROT with high-
dimensional visual observations, additional machinery is required to ensure compatibility. Following
prior work in image-based RL and imitation [8, 11], we perform data augmentations on visual
observations and then feed it into a CNN encoder. Similar to Cohen et al. [11], we use a target
encoder with Polyak averaging to obtain representations for OT reward computation. This is necessary
to reduce the non-stationarity caused by learning the encoder alongside the ROT imitation process.
Further implementation details and the training procedure can be found in Appendix C.

5 Experiments

Our experiments are designed to answer the following questions: (a) How efﬁcient is ROT for
imitation learning? (b) How does ROT perform on real-world tasks? (c) How important is the choice
of IRL method in ROT? (d) Does soft Q-ﬁltering improve imitation? (e) How does ROT compare to
standard reward-based RL? Additional results and analysis have been provided in Appendix H.

Simulated tasks We experiment with 10 tasks from the DeepMind Control suite [18, 25], 3 tasks
from the OpenAI Robotics suite [26], and 7 tasks from the Meta-world suite [27]. For DeepMind
Control tasks, we train expert policies using DrQ-v2 [8] and collect 10 demonstrations for each
task using this policy. For OpenAI Robotics tasks, we train a state-based DrQ-v2 with hindsight
experience replay [28] and collect 50 demonstrations for each task. For Meta-world tasks, we
use a single hard-coded expert demonstration from their open-source implementation [27]. Full
environment details can be found in Appendix D and details about the variations in demonstrations
and initialization conditions can be found in Appendix E.

Robot tasks Our real world setup for each of the 14 manipulation tasks can be seen in Fig. 4.
We use an Ufactory xArm 7 robot with a xArm Gripper as the robot platform for our real world
experiments. However, our method is agnostic to the speciﬁc robot hardware. The observations
are RGB images from a ﬁxed camera. In this setup, we only use a single expert demonstration
collected by a human operator with a joystick and limit the online training to a ﬁxed period of 1 hour.
Descriptions of each task and the evaluation procedure is in Appendix F.

Primary baselines We compare ROT with baselines against several prominent imitation learning
methods. While a full description of our baselines are in Appendix G, a brief description of the two
strongest ones are as follows:

1. Adversarial IRL (DAC): Discriminator Actor Critic [7] is a state-of-the-art adversarial imitation
learning method [6, 29, 7]. DAC outperforms prior work such as GAIL [6] and AIRL [30], and
thus it serves as our primary adversarial imitation baseline.

2. Trajectory-matching IRL (OT): Sinkhorn Imitation Learning [12, 13] is a state-of-the-art
trajectory-matching imitation learning method [31] that approximates OT matching through
the Sinkhorn Knopp algorithm [32, 33]. Since ROT is derived from similar OT-based foundations,
we use SIL as our primary state-matching imitation baseline.

5

Expert

BC

OT

DAC

ROT (Ours)

Figure 3: Pixel-based continuous control learning on 9 selected environments. Shaded region
represents ±1 standard deviation across 5 seeds. We notice that ROT is signiﬁcantly more sample
efﬁcient compared to prior work.

5.1 How efﬁcient is ROT for imitation learning?

Performance of ROT for image-based imitation is depicted on select environments in Fig. 3. On all
but one task, ROT trains signiﬁcantly faster than prior work. To reach 90% of expert performance,
ROT is on average 8.7× faster on DeepMind Control tasks, 2.1× faster on OpenAI Robotics tasks,
and 8.9× faster on Meta-world tasks. We also ﬁnd that the improvements of ROT are most apparent
on the harder tasks, which are in rightmost column of Fig. 3. Appendix H.1 shows results on all 20
simulated tasks, along with experiments that exhibit similar improvements in state-based settings.

5.2 How does ROT perform on real-world tasks?

We devise a set of 14 manipulation tasks on our xArm robot to compare the performance of ROT
with BC and our strongest baseline RDAC, an adversarial IRL method that combines DAC [7] with
our pretraining and regularization scheme. The BC policy is trained using supervised learning on a
single expert demonstration collected by a human operator. ROT and RDAC ﬁnetune the pretrained
BC policy through 1 hour of online training, which amounts to ∼ 6k environment steps. Since
there is just one demonstration, our tasks are designed to have random initializations but ﬁxed goals.
Note that a single demonstration only demonstrates solving the tasks from one initial condition.
Evaluation results across 20 different initial conditions can be seen in Fig. 4. We observe that ROT
has an average success rate of 90.1% over 20 evaluation trajectories across all tasks as compared to
36.1% for BC and 14.6% for RDAC. The poor performance of BC can be attributed to distributional
mismatch due to accumulation of error in online rollouts and different initial conditions. The poor
performance of RDAC can be attributed to slow learning during the initial phase of training. More
detailed evaluations of RDAC on simulated environments is present in Sec. 5.4.

6

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

e
t
a
r

s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

1.0

e
t
a
r

s
s
e
c
c
u
s

0.8

0.6

0.4

0.2

0.0

dmc_cheetah_run

dmc_hopper_hop

dmc_walker_run

300

200

100

d
r
a
w
e
r
_
e
d
o
s
i
p
e

0

800

600

400

200

d
r
a
w
e
r
_
e
d
o
s
i
p
e

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

fetch_reach

fetch_push

fetch_pick_and_place

e
t
a
r

s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

e
t
a
r

s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

metaworld_drawer_close

metaworld_hammer

metaworld_door_open

e
t
a
r

s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

e
t
a
r

s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

 
 
 
 
 
 
Figure 4: (Top) ROT is evaluated on a set of 14 robotic manipulation tasks. (Bottom) Success rates
for each task is computed by running 20 trajectories from varying initial conditions on the robot.

BC

RDAC

ROT (Ours)

5.3 Does soft Q-ﬁltering improve imitation?

To understand the importance of soft
Q-ﬁltering, we compare ROT against
two variants of our proposed regular-
ization scheme: (a) A tuned ﬁxed BC
regularization weight (ignoring λ(π)
in Eq. 3); (b) A carefully designed
linear-decay schedule for λ(π), where
it varies from 1.0 to 0.0 in the ﬁrst 20k
environment steps [16]. As demon-
strated in Fig. 5 (and Appendix H.2),
ROT is on par and in some cases ex-
ceeds the efﬁciency of a hand-tuned
decay schedule, while not having to
hand-tune its regularization weights.
We hypothesize this improvement is primarily due to the better stability of adaptive weighing as seen
in the signiﬁcantly smaller standard deviation on the Meta-world tasks.

Figure 5: Effect of various BC regularization schemes com-
pared with our adaptive soft-Q ﬁltering regularization.

Finetune with ﬁxed weight

Finetune with ﬁxed

ROT (Ours)

schedule

5.4 How important is the choice of IRL method in ROT?

In ROT, we build on OT-based IRL instead of adversarial IRL. This is because adversarial IRL
methods require iterative reward learning, which produces a highly non-stationary reward function for
policy optimization. In Fig. 6, we compare ROT with adversarial IRL methods that use our pretraining
and adaptive BC regularization technique (RDAC). We ﬁnd that our soft Q-ﬁltering method does
improve prior state-of-the-art adversarial IRL (RDAC vs. DAC in Fig. 6). However, our OT-based
approach (ROT) is more stable and on average leads to more efﬁcient learning.

5.5 How does ROT compare to standard reward-based RL?

We compare the performance of ROT against DrQ-v2 [8], a state-of-the-art algorithm for image-based
RL. As opposed to the reward-free setting ROT operates in, DrQ-v2 has access to environments
rewards. The results in Fig. 6 show that ROT handily outperforms DrQ-v2. This clearly demonstrates

7

Close a door

Hang a hanger

Erasing a board

Reach

Hanging a mug

Hanging a tote bag

Turn a knob

Stacking cups

Pressing a switch

Peg in a box (Easy)

Peg in a box (Med)

Peg in a box (Hard)

Opening a box

Pouring almonds

dmc_hopper_hop

metaworld_hammer

300

200

100

d
r
a
w
e
r

e
d
o
s
p
e

i

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

1.0

0.8

0.6

0.4

0.2

e
t
a
r

s
s
e
c
c
u
s

0.0

0.0

0.2

0.4

0.6

0.8

frame

1.0

1e6

 
 
Expert

BC

DAC

OT

DrQ-v2 (RL)

RDAC

ROT (Ours)

Figure 6: Ablation analysis on the choice of base IRL method. We ﬁnd that although adversarial
methods beneﬁt from regularized BC, the gains seen are smaller compared to ROT. Here, we also see
that ROT can outperform plain RL that requires explicit task-rewards.

the usefulness of imitation learning in domains where expert demonstrations are available over
reward-based RL. We also compare against a demo-assisted variant of DrQ-v2 agent using the same
pretraining and regularization scheme as ROT (refer to Appendix H.3). Interestingly, we ﬁnd that our
soft Q-ﬁltering based regularization can accelerate learning of RL with task rewards, which can be
seen in the high performance of the demo-assisted variant of DrQ-v2.

6 Related Work

Imitation Learning (IL)
IL [34] refers to the setting where agents learn from demonstrations
without access to environment rewards.
IL can be broadly categorized into Behavior Cloning
(BC) [1, 21, 35, 36] and Inverse Reinforcement Learning (IRL) [4, 22]. BC solely learns from ofﬂine
demonstrations but suffers on out-of-distributions samples [5] whereas IRL focuses on learning a
robust reward function through online interactions but suffers from sample inefﬁciency [7]. Deep IRL
methods can be further divided into two categories: (1) adversarial learning [37] based methods, and
(2) state-matching [38, 39] based methods. GAIL [6] is an adversarial learning based formulation
inspired by maximum entropy IRL [40] and GANs [37]. There has been a signiﬁcant body of work
built up on GAIL proposing alternative losses [30, 41, 29], and enhancing its sample efﬁciency by
porting it to an off-policy setting [7]. There have also been visual extensions of these adversarial
learning approaches [42, 43, 44, 11]. However, although adversarial methods produce competent
policies, they are inefﬁcient due to the non-stationarity associated with iterative reward inference [11].

Optimal Transport (OT) OT [38, 39] is a tool for comparing probability measures while including
the geometry of the space. In the context of IL, OT computes an alignment between a set of agent
and expert observations using distance metrics such as Sinkhorn [33], Gromov-Wasserstein [45],
GDTW [46], CO-OT [47] and Soft-DTW [48]. For many of these distance measures, there is
an associated IL algorithm, with SIL [12] using Sinkhorn, PWIL [13] using greedy Wasserstein,
GDTW-IL [46] using GDTW, and GWIL [49] using Gromov-Wasserstein. Recent work from Cohen
et al. [11] demonstrates that the Sinkhorn distance [12] produces the most efﬁcient learning among
the discussed metrics. They further show that SIL is compatible with high-dimensional visual
observations and encoded representations. Inspired by this, ROT adopts the Sinkhorn metric for its
OT reward computation, and improves upon SIL through adaptive behavior regularization.

Behavior Regularized Control Behavior regularization is a widely used technique in ofﬂine
RL [50] where explicit constraints are added to the policy improvement update to avoid bootstrapping
on out-of-distribution actions [51, 52, 53, 54, 55, 56]. In an online setting with access to environment
rewards, prior work [16, 10] has shown that behavior regularization can be used to boost sample
efﬁciency by ﬁnetuning a pretrained policy via online interactions. For instance, Jena et al. [17]
demonstrates the effectiveness of behavior regularization to enhance sample efﬁciency in the context
of adversarial IL. ROT builds upon this idea by extending to visual observations, OT-based IL, and
adaptive regularization, which leads to improved performance (see Appendix H.4). We also note that
the idea of using adaptive regularization has been previously explored in RL [24]. However, ROT
uses a soft, continuous adaptive scheme, which on initial experiments provided signiﬁcantly faster
learning compared to hard assignments.

8

1000

d
r
a
w
e
r

e
d
o
s
i
p
e

800

600

400

200

0

dmc_walker_run

fetch_pick_and_place

metaworld_hammer

e
t
a
r

s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

e
t
a
r

s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.00

0.25

0.50

0.75
frame

1.00

1.25

1.50
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

 
 
 
7 Conclusion and Limitations

In this work, we have proposed a new imitation learning algorithm, ROT, that demonstrates improved
performance compared to prior state-of-the-art work on a variety of simulated and robotic domains.
However, we recognize a few limitations in this work: (a) Since our OT-based approach aligns agents
with demonstrations without task-speciﬁc rewards, it relies on the demonstrator being an ‘expert’.
Extending ROT to suboptimal, noisy and multimodal demonstrations would be an exciting problem to
tackle. (b) Performing BC pretraining and BC-based regularization requires access to expert actions,
which may not be present in some real-world scenarios particularly when learning from humans.
Recent work on using inverse models to infer actions given observational data could alleviate this
challenge [57]. (c) On robotic tasks such as Peg in box (hard) and Pressing a switch from Fig. 4, we
ﬁnd that ROT’s performance drops substantially compared to other tasks. This might be due to the
lack of visual features corresponding to the task success. For example, in the ‘Peg’ task, it is visually
difﬁcult to discriminate if the peg is in the box or behind the box. Similarly for the ‘Switch’ task, it is
difﬁcult to discern if the button was pressed or not. This limitation can be addressed by integrating
more sensory modalities such as additional cameras, and tactile sensors in the observation space.

Acknowledgments

We thank Ben Evans, Anthony Chen, Ulyana Piterbarg and Abitha Thankaraj for valuable feedback
and discussions. This work was supported by grants from Honda, Amazon, and ONR awards
N00014-21-1-2404 and N00014-21-1-2758.

References

[1] D. Pomerleau. An autonomous land vehicle in a neural network. Advances in Neural Information

Processing Systems, 1, 1998.

[2] O. M. Andrychowicz, B. Baker, M. Chociej, R. Jozefowicz, B. McGrew, J. Pachocki, A. Petron,
M. Plappert, G. Powell, A. Ray, et al. Learning dexterous in-hand manipulation. The Interna-
tional Journal of Robotics Research, 39(1):3–20, 2020.

[3] P. N. Kolm and G. Ritter. Modern perspectives on reinforcement learning in ﬁnance. Modern
Perspectives on Reinforcement Learning in Finance (September 6, 2019). The Journal of
Machine Learning in Finance, 1(1), 2020.

[4] A. Y. Ng, S. J. Russell, et al. Algorithms for inverse reinforcement learning. In Icml, volume 1,

page 2, 2000.

[5] S. Ross, G. Gordon, and D. Bagnell. A reduction of imitation learning and structured prediction
to no-regret online learning. In Proceedings of the fourteenth international conference on artiﬁ-
cial intelligence and statistics, pages 627–635. JMLR Workshop and Conference Proceedings,
2011.

[6] J. Ho and S. Ermon. Generative adversarial imitation learning. Advances in neural information

processing systems, 29, 2016.

[7] I. Kostrikov, K. K. Agrawal, D. Dwibedi, S. Levine, and J. Tompson. Discriminator-actor-critic:
Addressing sample inefﬁciency and reward bias in adversarial imitation learning. arXiv preprint
arXiv:1809.02925, 2018.

[8] D. Yarats, R. Fergus, A. Lazaric, and L. Pinto. Mastering visual continuous control: Improved

data-augmented reinforcement learning. arXiv preprint arXiv:2107.09645, 2021.

[9] A. Nair, A. Gupta, M. Dalal, and S. Levine. Awac: Accelerating online reinforcement learning

with ofﬂine datasets. arXiv preprint arXiv:2006.09359, 2020.

[10] I. Uchendu, T. Xiao, Y. Lu, B. Zhu, M. Yan, J. Simon, M. Bennice, C. Fu, C. Ma, J. Jiao, et al.

Jump-start reinforcement learning. arXiv preprint arXiv:2204.02372, 2022.

[11] S. Cohen, B. Amos, M. P. Deisenroth, M. Henaff, E. Vinitsky, and D. Yarats. Imitation learning
from pixel observations for continuous control, 2022. URL https://openreview.net/
forum?id=JLbXkHkLCG6.

9

[12] G. Papagiannis and Y. Li.
arXiv:2008.09167, 2020.

Imitation learning with sinkhorn distances. arXiv preprint

[13] R. Dadashi, L. Hussenot, M. Geist, and O. Pietquin. Primal wasserstein imitation learning.

arXiv preprint arXiv:2006.04678, 2020.

[14] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov. Proximal policy optimization

algorithms. arXiv preprint arXiv:1707.06347, 2017.

[15] D. Silver, G. Lever, N. Heess, T. Degris, D. Wierstra, and M. Riedmiller. Deterministic policy
gradient algorithms. In International conference on machine learning, pages 387–395. PMLR,
2014.

[16] A. Rajeswaran, V. Kumar, A. Gupta, G. Vezzani, J. Schulman, E. Todorov, and S. Levine.
Learning complex dexterous manipulation with deep reinforcement learning and demonstrations.
arXiv preprint arXiv:1709.10087, 2017.

[17] R. Jena, C. Liu, and K. Sycara. Augmenting gail with bc for sample efﬁcient imitation learning.

arXiv preprint arXiv:2001.07798, 2020.

[18] Y. Tassa, Y. Doron, A. Muldal, T. Erez, Y. Li, D. d. L. Casas, D. Budden, A. Abdolmaleki,
J. Merel, A. Lefrancq, et al. Deepmind control suite. arXiv preprint arXiv:1801.00690, 2018.

[19] G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, and W. Zaremba.

Openai gym. arXiv preprint arXiv:1606.01540, 2016.

[20] T. Yu, D. Quillen, Z. He, R. Julian, K. Hausman, C. Finn, and S. Levine. Meta-world: A
benchmark and evaluation for multi-task and meta reinforcement learning. In Conference on
Robot Learning, pages 1094–1100. PMLR, 2020.

[21] F. Torabi, G. Warnell, and P. Stone. Recent advances in imitation learning from observation.

arXiv preprint arXiv:1905.13566, 2019.

[22] P. Abbeel and A. Y. Ng. Apprenticeship learning via inverse reinforcement learning.

In

Proceedings of the twenty-ﬁrst international conference on Machine learning, page 1, 2004.

[23] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, and D. Wierstra.
Continuous control with deep reinforcement learning. arXiv preprint arXiv:1509.02971, 2015.

[24] A. Nair, B. McGrew, M. Andrychowicz, W. Zaremba, and P. Abbeel. Overcoming exploration in
reinforcement learning with demonstrations. In 2018 IEEE international conference on robotics
and automation (ICRA), pages 6292–6299. IEEE, 2018.

[25] E. Todorov, T. Erez, and Y. Tassa. Mujoco: A physics engine for model-based control. In 2012
IEEE/RSJ international conference on intelligent robots and systems, pages 5026–5033. IEEE,
2012.

[26] M. Plappert, M. Andrychowicz, A. Ray, B. McGrew, B. Baker, G. Powell, J. Schneider, J. Tobin,
M. Chociej, P. Welinder, et al. Multi-goal reinforcement learning: Challenging robotics
environments and request for research. arXiv preprint arXiv:1802.09464, 2018.

[27] T. Yu, D. Quillen, Z. He, R. Julian, K. Hausman, C. Finn, and S. Levine. Meta-world: A
benchmark and evaluation for multi-task and meta reinforcement learning. In Conference on
Robot Learning (CoRL), 2019. URL https://arxiv.org/abs/1910.10897.

[28] M. Andrychowicz, F. Wolski, A. Ray, J. Schneider, R. Fong, P. Welinder, B. McGrew, J. Tobin,
O. Pieter Abbeel, and W. Zaremba. Hindsight experience replay. Advances in neural information
processing systems, 30, 2017.

[29] F. Torabi, G. Warnell, and P. Stone. Generative adversarial imitation from observation. arXiv

preprint arXiv:1807.06158, 2018.

[30] J. Fu, K. Luo, and S. Levine. Learning robust rewards with adversarial inverse reinforcement

learning. arXiv preprint arXiv:1710.11248, 2017.

10

[31] S. K. S. Ghasemipour, R. Zemel, and S. Gu. A divergence minimization perspective on imitation
learning methods. In Conference on Robot Learning, pages 1259–1277. PMLR, 2020.

[32] R. Sinkhorn and P. Knopp. Concerning nonnegative matrices and doubly stochastic matrices.

Paciﬁc Journal of Mathematics, 21(2):343–348, 1967.

[33] M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. Advances in

neural information processing systems, 26, 2013.

[34] A. Hussein, M. M. Gaber, E. Elyan, and C. Jayne. Imitation learning: A survey of learning

methods. ACM Computing Surveys (CSUR), 50(2):1–35, 2017.

[35] S. P. Arunachalam, S. Silwal, B. Evans, and L. Pinto. Dexterous imitation made easy: A learning-
based framework for efﬁcient dexterous manipulation. arXiv preprint arXiv:2203.13251, 2022.

[36] J. Pari, N. Muhammad, S. P. Arunachalam, and L. Pinto. The surprising effectiveness of

representation learning for visual imitation. arXiv preprint arXiv:2112.01511, 2021.

[37] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and
Y. Bengio. Generative adversarial nets. Advances in neural information processing systems, 27,
2014.

[38] C. Villani. Optimal transport: old and new, volume 338. Springer, 2009.

[39] G. Peyr´e, M. Cuturi, et al. Computational optimal transport: With applications to data science.

Foundations and Trends® in Machine Learning, 11(5-6):355–607, 2019.

[40] B. D. Ziebart, A. L. Maas, J. A. Bagnell, A. K. Dey, et al. Maximum entropy inverse reinforce-

ment learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL, USA, 2008.

[41] H. Xiao, M. Herman, J. Wagner, S. Ziesche, J. Etesami, and T. H. Linh. Wasserstein adversarial

imitation learning. arXiv preprint arXiv:1906.08113, 2019.

[42] E. Cetin and O. Celiktutan. Domain-robust visual imitation learning with mutual information

constraints. arXiv preprint arXiv:2103.05079, 2021.

[43] S. Toyer, R. Shah, A. Critch, and S. Russell. The magical benchmark for robust imitation.

Advances in Neural Information Processing Systems, 33:18284–18295, 2020.

[44] R. Rafailov, T. Yu, A. Rajeswaran, and C. Finn. Visual adversarial imitation learning using

variational models. Advances in Neural Information Processing Systems, 34, 2021.

[45] G. Peyr´e, M. Cuturi, and J. Solomon. Gromov-wasserstein averaging of kernel and distance
matrices. In International Conference on Machine Learning, pages 2664–2672. PMLR, 2016.

[46] S. Cohen, G. Luise, A. Terenin, B. Amos, and M. Deisenroth. Aligning time series on incom-
parable spaces. In International Conference on Artiﬁcial Intelligence and Statistics, pages
1036–1044. PMLR, 2021.

[47] I. Redko, T. Vayer, R. Flamary, and N. Courty. Co-optimal transport. arXiv preprint

arXiv:2002.03731, 2020.

[48] M. Cuturi and M. Blondel. Soft-dtw: a differentiable loss function for time-series. In Interna-

tional conference on machine learning, pages 894–903. PMLR, 2017.

[49] A. Fickinger, S. Cohen, S. Russell, and B. Amos. Cross-domain imitation learning via optimal

transport. arXiv preprint arXiv:2110.03684, 2021.

[50] S. Levine, A. Kumar, G. Tucker, and J. Fu. Ofﬂine reinforcement learning: Tutorial, review,

and perspectives on open problems. arXiv preprint arXiv:2005.01643, 2020.

[51] S. Fujimoto and S. S. Gu. A minimalist approach to ofﬂine reinforcement learning. Advances

in Neural Information Processing Systems, 34, 2021.

[52] Y. Wu, G. Tucker, and O. Nachum. Behavior regularized ofﬂine reinforcement learning. arXiv

preprint arXiv:1911.11361, 2019.

11

[53] A. Ajay, A. Kumar, P. Agrawal, S. Levine, and O. Nachum. {OPAL}: Ofﬂine primitive discovery
In International Conference on Learning

for accelerating ofﬂine reinforcement learning.
Representations, 2021. URL https://openreview.net/forum?id=V69LGwJ0lIN.

[54] A. Kumar, J. Fu, M. Soh, G. Tucker, and S. Levine. Stabilizing off-policy q-learning via
bootstrapping error reduction. Advances in Neural Information Processing Systems, 32, 2019.

[55] N. Y. Siegel, J. T. Springenberg, F. Berkenkamp, A. Abdolmaleki, M. Neunert, T. Lampe,
R. Hafner, N. Heess, and M. Riedmiller. Keep doing what worked: Behavioral modelling priors
for ofﬂine reinforcement learning. arXiv preprint arXiv:2002.08396, 2020.

[56] S. Fujimoto, D. Meger, and D. Precup. Off-policy deep reinforcement learning without explo-
ration. In International Conference on Machine Learning, pages 2052–2062. PMLR, 2019.

[57] I. Radosavovic, X. Wang, L. Pinto, and J. Malik. State-only imitation learning for dexterous
manipulation. In 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS), pages 7865–7871. IEEE, 2020.

[58] R. Bellman. A markovian decision process. Journal of mathematics and mechanics, pages

679–684, 1957.

[59] R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction. MIT press, 2018.

[60] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves,
M. Riedmiller, A. K. Fidjeland, G. Ostrovski, et al. Human-level control through deep rein-
forcement learning. nature, 518(7540):529–533, 2015.

[61] A. Zhan, P. Zhao, L. Pinto, P. Abbeel, and M. Laskin. A framework for efﬁcient robotic

manipulation. arXiv preprint arXiv:2012.07975, 2020.

[62] S. Young, D. Gandhi, S. Tulsiani, A. Gupta, P. Abbeel, and L. Pinto. Visual imitation made

easy. arXiv preprint arXiv:2008.04899, 2020.

[63] P. A. Knight. The sinkhorn–knopp algorithm: convergence and applications. SIAM Journal on

Matrix Analysis and Applications, 30(1):261–275, 2008.

12

A Background

Reinforcement Learning (RL) We study RL as a discounted inﬁnite-horizon Markov Decision
Process (MDP) [58, 59]. For pixel observations, the agent’s state is approximated as a stack of
consecutive RGB frames [60]. The MDP is of the form (O, A, P, R, γ, d0) where O is the observation
space, A is the action space, P : O × A → ∆(O) is the transition function that deﬁnes the probability
distribution over the next state given the current state and action, R : O × A → R is the reward
function, γ is the discount factor and d0 is the initial state distribution. The goal is to ﬁnd a policy
π : O → ∆(A) that maximizes the expected discount sum of rewards Eπ[Σ∞
t=0γtR(ot, at)], where
o0 ∼ d0, at ∼ π(ot) and ot+1 ∼ P (.|ot, at).

Imitation Learning (IL) The goal of imitation learning is to learn a behavior policy πb given
access to either the expert policy πe or trajectories derived from the expert policy T e. While there
are a multitude of settings with differing levels of access to the expert [21], this work operates in the
setting where the agent only has access to observation-based trajectories, i.e. T e ≡ {(ot, at)T
n=0.
Here N and T denotes the number of trajectory rollouts and episode timesteps respectively. We
choose this speciﬁc setting since obtaining observations and actions from expert or near-expert
demonstrators is feasible in real-world settings [61, 62] and falls in line with recent work in this
area [13, 6, 7].

t=0}N

Inverse Reinforcement Learning (IRL)
IRL [4, 22] tackles the IL problem by inferring the reward
function re based on expert trajectories T e. Then given the inferred reward re, policy optimization
is used to derive the behavior policy πb. Prominent algorithms in IRL [7, 6] requires alternating
the inference of reward and optimization of policy in an iterative manner, which is practical for
restricted model classes [22]. For compatibility with more expressive deep networks, techniques such
as adversarial learning [6, 7] or optimal-transport [12, 13, 11] are needed. Adversarial learning based
approaches tackle this problem by learning a discriminator that models the gap between the expert
trajectories T e and behavior trajectories T b. The behavior policy πb is then optimized to minimize
this gap through gap-minimizing rewards re. Such a training procedure is prone to instabilities since
re is updated at every iteration and is hence non-stationary for the optimization of πb.

Optimal Transport for Imitation Learning (OT) To alleviate the non-stationary reward problem
with adversarial IRL frameworks, a new line of OT-based approaches have been recently proposed [12,
13, 11]. Intuitively, the closeness between expert trajectories T e and behavior trajectories T b can be
computed by measuring the optimal transport of probability mass from T b → T e. During policy
learning, the policy πφ encompasses a feature preprocessor fφ which transforms observations into
informative state representations. Some examples of a preprocessor function fφ are an identity
function, a mean-variance scaling function and a parametric neural network. In this work, we use a
parametric neural network as fφ. Given a cost function c : O × O → R deﬁned in the preprocessor’s
output space and an OT objective g, the optimal alignment between an expert trajectory oe and a
behavior trajectory ob can be computed as

µ∗ ∈ arg min
µ∈M

g(µ, fφ(ob), fφ(oe), c)

(5)

where M = {µ ∈ RT ×T : µ1 = µT 1 = 1
T 1} is the set of coupling matrices and the cost c can be
the Euclidean or Cosine distance. In this work, inspired by [11], we use the entropic Wasserstein
distance with cosine cost as our OT metric, which is given by the equation

g(µ, fφ(ob), fφ(oe), c) = W 2(fφ(ob), fφ(oe))

T
(cid:88)

=

t,t(cid:48)=1

Ct,t(cid:48) µt,t(cid:48)

13

(6)

where the cost matrix Ct,t(cid:48) = c(fφ(ob), fφ(oe)). Using Eq. 6 and the optimal alignment µ∗ obtained
by optimizing Eq. 5, a reward signal can be computed for each observation using the equation

rOT (ob

t ) = −

T
(cid:88)

t(cid:48)=1

Ct,t(cid:48) µ∗
t,t(cid:48)

(7)

Intuitively, maximizing this reward encourages the imitating agent to produce trajectories that closely
match demonstrated trajectories. Since solving Eq. 5 is computationally expensive, approximate
solutions such as the Sinkhorn algorithm [63, 12] are used instead.

B Issue with Fine-tuning Actor-Critic Frameworks

In this paper, we use n-step DDPG proposed by Yarats et al. [8] as our RL optimizer for actor-
critic based reward maximization. DDPG [23] concurrently learns a deterministic policy πφ using
deterministic policy gradients (DPG) [15] and a Q-function Qθ by minimizing a n-step Bellman
residual (for n-step DDPG). For a parameterized actor network πφ(s) and a critic function Qθ(s, a),
the deterministic policy gradients (DPG) for updating the actor weights is given by

∇φJ ≈ Est∼ρβ

= Est∼ρβ

(cid:104)

(cid:104)

∇φ Qθ(s, a)|s=st,a=πφ(st)

(cid:105)

∇a Qθ(s, a)|s=st,a=πφ(st) ∇φ πφ(s)|s=st

(cid:105)

(8)

Here, ρβ refers to the state visitation distribution of the data present in the replay buffer at time t.
From Eq. 8, it is clear that the policy gradients in this framework depend on the gradients with respect
to the critic value. Hence, as mentioned in [9, 10], naively initializing the actor with a pretrained
policy while using a randomly initialized critic results in the untrained critic providing an exceedingly
poor signal to the actor network during training. As a result, the actor performance drops immediately
and the good behavior of the informed initialization of the policy gets forgotten. In this paper, we
propose an adaptive regularization scheme that permits ﬁnetuning a pretrained actor policy in an
actor-critic framework. As opposed to Rajeswaran et al. [16], Jena et al. [17] which employ on-policy
learning, our method is off-policy and aims to leverage the sample efﬁcient characteristic of off-policy
learning as compared to on-policy learning [7].

C Algorithmic Details

C.1

Implementation

Algorithm 1 describes our proposed algorithm, Regularized Optimal Transport (ROT), for sample
efﬁcient imitation learning for continuous control tasks. Further implementation details are as follows:

Algorithm and training procedure Our model consists of 3 primary neural networks - the encoder,
the actor and the critic. During the BC pretraining phase, the encoder and the actor are trained using
a mean squared error (MSE) on the expert demonstrations. Next, for ﬁnetuning, weights of the
pretrained encoder and actor are loaded from memory and the critic is initialized randomly. We
observed that the performance of the algorithm is not very sensitive to the value of α and we set it
to 0.03 for all experiments in this paper. A copy of the pretrained encoder and actor are stored with
ﬁxed weights to be used for computing λ(π) for soft Q-ﬁltering.

Actor-critic based reward maximization We use a recent n-step DDPG proposed by Yarats et al.
[8] as our RL backbone. The deterministic actor is trained using deterministic policy gradients
(DPG) [15] given by Eq. 8. The critic is trained using clipped double Q-learning similar to Yarats
et al. [8] in order to reduce the overestimation bias in the target value. This is done using two
Q-functions, Qθ1 and Qθ2. The critic loss for each critic is given by the equation

Lθk = E(s,a)∼Dβ

(cid:2)(Qθk (s, a) − y)2(cid:3) ∀ k ∈ {1, 2}

(9)

14

Algorithm 1 ROT: Regularized Optimal Transport

Require:
Expert Demonstrations T e ≡ {(ot, at)T
Pretrained policy πBC
Replay buffer D, Training steps T , Episode Length L
Task environment env
Parametric networks for RL backbone (e.g., the encoder, policy and critic function for DrQ-v2)
A discriminator D for adversarial baselines

t=0}N

n=0

Algorithm:
πROT ← πBC
for each timestep t = 1...T do

if done then

r1:L = rewarderOT (episode)
Update episode with r1:L and add (ot, at, ot+1, rt) to D
ot = env.reset(), done = False, episode = [ ]

(cid:46) Initialize with pretrained policy

(cid:46) OT-based reward computation

end if
at = πROT (ot)
ot+1, done = env.step(at)
episode.append([ot, at, ot+1])
Update backbone-speciﬁc networks and reward-speciﬁc networks using D

end for

where Dβ is the replay buffer for online rollouts and y is the target value for n-step DDPG given by

y =

n−1
(cid:88)

i=0

γirt+i + γn min
k=1,2

Q¯θk

(st+n, at+n)

(10)

Here, γ is the discount factor, r is the reward obtained using OT-based reward computation and ¯θ1,
¯θ2 are the slow moving weights of target Q-networks.

Target feature processor to stabilize OT rewards The OT rewards are computed on the output
of the feature processor fφ which is initialized with a parametric neural network. Hence, as the
weights of fφ change during training, the rewards become non-stationary resulting in unstable training.
In order to increase the stability of training, the OT rewards are computed using a target feature
processor fφ(cid:48) [11] which is updated with the weights of fφ every Tupdate environment steps. For
state-based observations, fφ corresponds to a ’trunk’ network which is a single layer neural network.
For pixel-based observations, fφ includes DrQ-v2’s encoder followed by the ’trunk’ network.

C.2 Hyperparameters

The complete list of hyperparameters is provided in Table 1. Similar to Yarats et al. [8], there is
a slight deviation from the given setting for the Walker Stand/Walk/Run task from the DeepMind
Control suite where we use a mini-batch size of 512 and a n-step return of 1.

D Environments

Table 2 lists the different tasks that we experiment with from the DeepMind Control suite [18, 25],
OpenAI Robotics suite [26] and the Meta-world suite [27] along with the number of training steps
and the number of demonstrations used. For the tasks in the OpenAI Robotics suite, we ﬁx the goal
while keeping the initial state randomized. No modiﬁcations are made in case of the DeepMind
Control suite and the Meta-world suite. The episode length for all tasks in DeepMind Control is 1000
steps, for OpenAI Robotics is 50 steps and Meta-world is 125 steps (except bin picking which runs
for 175 steps).

15

Method

Common

Parameter

Replay buffer size

Learning rate

Discount γ

n-step returns

Action repeat

Seed frames

Mini-batch size

Agent update frequency

Critic soft-update rate

Feature dim

Hidden dim

Optimizer

ROT

Exploration steps

DDPG exploration schedule

Target feature processor update frequency(steps)

Reward scale factor

Fixed weight α

Value

150000
1e−4

0.99

3

2

12000

256

2

0.01

50

1024

Adam

0

0.1

20000

10

0.03

Linear decay schedule for λ(π)

linear(1,0.1,20000)

OT

Exploration steps

2000

DDPG exploration schedule

linear(1,0.1,500000)

DAC

Target feature processor update frequency(steps)

Reward scale factor

Exploration steps

DDPG exploration schedule

Gradient penalty coefﬁcient

Table 1: List of hyperparameters.

20000

10

2000

linear(1,0.1,500000)

10

E Demonstrations

For DeepMind Control tasks, we train expert policies using pixel-based DrQ-v2 [8] and collect 10
demonstrations for each task using this expert policy. The expert policy is trained using a stack
of 3 consecutive RGB frames of size 84 × 84 with random crop augmentation. Each action in the
environment is repeated 2 times. For OpenAI Robotics tasks, we train a state-based DrQ-v2 with
hindsight experience replay [28] and collect 50 demonstrations for each task. The state representation
comprises the observation from the environment appended with the desired goal location. For this, we
did not do frame stacking and action repeat was set to 2. For Meta-World tasks, we use a single expert
demonstration obtained using the task-speciﬁc hard-coded policies provided in their open-source
implementation [27].

16

Suite

Tasks

DeepMind Control

Acrobot Swingup

Allowed Steps
2 × 106

# Demonstrations

10

Cartpole Swingup

Cheetah Run

Finger Spin

Hopper Stand

Hopper Hop

Quadruped Run

Walker Stand

Walker Walk

Walker Run

OpenAI Robotics

Fetch Reach

1.5 × 106

50

1

1

Fetch Push

Fetch Pick and Place

Meta-World

Hammer

1 × 106

xArm Robot

6 × 103

Drawer Close

Door Open

Bin Picking

Button Press Topdown

Door Unlock.

Close Door

Hang Hanger

Erase Board

Reach

Hang Mug

Hang Bag

Turn Knob

Stack Cups

Press Switch

Peg (Easy)

Peg (Medium)

Peg (Hard)

Open Box

Pour

Table 2: List of tasks used for evaluation.

F Robot Tasks

In this section, we describe the suite of manipulation experiments carried out on a real robot in this
paper.

17

Figure 7: Examples of different initializations for the real robot tasks.

18

r
o
o
D
e
s
o
l
C

r
e
g
n
a
H
g
n
a
H

d
r
a
o
B
e
s
a
r
E

h
c
a
e
R

g
u
M
g
n
a
H

g
a
B
g
n
a
H

b
o
n
K
n
r
u
T

s
p
u
C
k
c
a
t
S

h
c
t
i

w
S
s
s
e
r
P

)
y
s
a
E
(

g
e
P

)
d
e
M

(

g
e
P

)
d
r
a
H

(
g
e
P

x
o
B
n
e
p
O

r
u
o
P

 
 
 
 
 
 
 
 
 
 
 
 
Figure 8: Example trajectories for selected real robot tasks.

(a) Door Close: Here, the robot arm is supposed to close an open door by pushing it to the target.
(b) Hang Hanger: While holding a hanger between the grippers, the robot arm is initialized at

random position and is tasked with putting the hanger at a goal region on a closet rod.

(c) Erase Board: While holding a board duster between the grippers, the robot arm is tasks with

erasing marking drawn on the board while getting initialized from random positions.

(d) Reach: The robot arm is required to reach a speciﬁc goal after being initialized at a random

position.

(e) Hang Mug: While holding a mug between the grippers, the robot arm is initialized at random

position and is tasked with hanging the mug on a speciﬁc hook.

(f) Hang Bag: While holding a tote between the grippers, the robot arm is initialized at random

position and is tasked with hanging the tote bag on a speciﬁc hook.

(g) Turn Knob: The robot arm is tasked with rotating a knob placed on the table by a certain angle
after being initialized at a random position. We consider a 90 degree rotation as success.
(h) Cup Stack: While holding a cup between the gripper, the robot arm is required to stack it into

another cup placed on the table.

(i) Press Switch: With the gripper kept closed, the robot arm is required to press a switch (with an

LED light) placed on the table.

(j) Peg (Easy, Medium, Hard): The robot arm is supposed to insert a peg, hanging by a string,
into a bucket placed on the table. This task has 3 variants - Easy, Medium, Hard - with the size
of the bucket decreasing from Easy to Hard.

(k) Box Open: In this task, the robot arm is supposed to open the lid of a box placed on the table by

lifting a handle provided in the front of the box.

(l) Pour: Given a cup with some item place inside (in our case, almonds), the robot arm is supposed

to move towards a cup place on the table and pour the item into the cup.

Evaluation procedure For each task, we obtained a set of 20 random initializations and evaluate
all of the methods (BC, RDAC and ROT) over 20 trajectories from the same set of initializations.
These initializations are different for each task based on the limits of the observation space for the
task.

G Baselines

Throughout the paper, we compare ROT with several prominent imitation learning and reinforcement
learning methods. Here, we give a brief description of each of the baseline models that have been
used.

(a) Expert: For each task, the expert refers to the expert policy used to generate the demonstrations

for the task (described in Appendix E).

19

d
r
a
o
B
e
s
a
r
E

g
a
B
g
n
a
H

b
o
n
K
n
r
u
T

)
d
r
a
H

(

g
e
P

x
o
B
n
e
p
O

 
 
 
 
 
(b) Behavior Cloning (BC): This refers to the behavior cloned policy trained on expert demonstra-

tions.

(c) Adversarial IRL (DAC): Discriminator Actor Critic [7] is a state-of-the-art adversarial imi-
tation learning method [6, 29, 7]. Since DAC outperforms prior work such as GAIL[6] and
AIRL[30], it serves as our primary adversarial imitation baseline.

(d) State-matching IRL (OT): Sinkhorn Imitation Learning [12, 13] is a state-of-the-art state-
matching imitation learning method [31] that approximates OT matching through the Sinkhorn
Knopp algorithm. Since ROT is derived from similar OT-based foundations, we use SIL as our
primary state-matching imitation baseline.

(e) RDAC: This is the same as ROT, but instead of using state-matching IRL (OT), adversarial IRL

(DAC) is used.

(f) Finetune with ﬁxed weight: This is similar to ROT where instead of using a time-varying

adaptive weight λ(i), only the ﬁxed weight λ0 is used. λ0 is set to a ﬁxed value of 0.03.

(g) Finetune with ﬁxed schedule: This is similar to ROT that uses both the ﬁxed weight λ0 and
the time-varying adaptive weight λ1(i). However, instead of using Soft Q-ﬁltering to compute
λ1(i), a hand-coded linear decay schedule is used.

(h) DrQ-v2 (RL): DrQ-v2 [8] is a state-of-the-art algorithm for pixel-based RL. DrQ-v2 is assumed
to have access to environment rewards as opposed to ROT which computes the reward using
OT-based techniques.

(i) Demo-DrQ-v2: This refers to DrQ-v2 but with access to both environment rewards and expert
demonstrations. The model is initialized with a pretrained BC policy followed by RL ﬁnetuning
with an adaptive regularization scheme like ROT. During RL ﬁnetuning, this baseline has access
to environment rewards.

(j) BC+OT: This is the same as the OT baseline but the policy is initialized with a pretrained BC

policy. No adaptive regularization scheme is used while ﬁnetuning the pretrained policy.

(k) OT+BC Reg.: This is the same as the OT baseline with randomly initialized networks but

during training, the adaptive regularization scheme is added to the objective function.

H Additional Experimental Results

H.1 How efﬁcient is ROT for imitation learning?

In addition to the results provided in Sec. 5.1, Fig. 9 and Fig. 10 shows the performance of ROT
for pixel-based imitation on 10 tasks from the DeepMind Control suite, 3 tasks from the OpenAI
Robotics suite and 7 tasks from the Meta-world suite. On all but one task, ROT is signiﬁcantly
more sample efﬁcient than prior work. Finally, the improvements from ROT hold on state-based
observations as well(see Fig. 11). Table 3 provides a comparison between the factor of speedup of
ROT to reach 90% of expert performance compared to prior state-of-the-art [7, 11] methods.

H.2 Does soft Q-ﬁltering improve imitation?

Extending the results shown in Fig. 5, we provide training curves from representative tasks in each
suite in Fig. 12. We observe that our adaptive soft-Q ﬁltering regularization is more stable compared
to prior hand-tuned regularization schemes. ROT is on par and in some cases exceeds the efﬁciency
of a hand-tuned decay schedule, while not having to hand-tune its regularization weights.

H.3 How does ROT compare to standard reward-based RL?

Extending the results shown in Fig. 6, we provide training curves from representative tasks in each
suite in Fig. 13, thus showing that ROT can outperform standard RL that requires explicit task-
reward. We also show that this RL method combined with our regularization scheme (represented by
Demo-DrQ-v2 in Fig. 13 provides strong results.

20

Expert

BC

OT

DAC

ROT (Ours)

Figure 9: Pixel-based continuous control learning on 10 DMC environments. Shaded region represents
±1 standard deviation across 5 seeds. We notice that ROT is signiﬁcantly more sample efﬁcient
compared to prior work.

H.4 How important are the design choices in ROT?

Importance of pretraining and regularizing the IRL policy Fig. 14 compares the following
variants of ROT on set of pixel-based tasks: (a) Training the IRL policy from scratch (OT); (b)
Finetuning a pretrained BC policy without BC regularization (BC+OT); (c) Training the IRL policy
from scratch with BC regularization (OT+BC Reg.). We observe that pretraining the IRL policy
(BC+OT) does not provide a signiﬁcant difference without regularization. This can be attributed to
the ‘forgetting behavior’ of pre-trained policies, studied in Nair et al. [9]. Interestingly, we see that
even without BC pretraining, keeping the policy close to a behavior distribution (OT+BC Reg.) can
yield improvements in efﬁciency over vanilla training from scratch. Our key takeaway from these
experiments is that both pretraining and BC regularization are required to obtain sample-efﬁcient
imitation learning.

Choice of IRL method In ROT, we build on OT-based IRL instead of adversarial IRL. This is
because adversarial IRL methods require iterative reward learning, which produces a highly non-
stationary reward function for policy optimization. In Fig. 15, we compare ROT with adversarial

21

400

300

200

100

d
r
a
w
e
r
_
e
d
o
s
i
p
e

0

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

dmc_acrobot_swingup

dmc_cartpole_swingup

dmc_finger_spin

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1200

1000

800

600

400

200

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

dmc_cheetah_run

dmc_hopper_stand

dmc_hopper_hop

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

200

300

200

100

d
r
a
w
e
r
_
e
d
o
s
i
p
e

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

dmc_walker_stand

dmc_walker_walk

dmc_walker_run

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

800

600

400

200

d
r
a
w
e
r
_
e
d
o
s
i
p
e

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

dmc_quadruped_run

600

400

200

d
r
a
w
e
r
_
e
d
o
s
i
p
e

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

Expert

BC

OT

DAC

ROT (Ours)

Figure 10: Pixel-based continuous control learning on 3 OpenAI Gym Robotics and 7 Meta-World
tasks. Shaded region represents ±1 standard deviation across 5 seeds. We notice that ROT is
signiﬁcantly more sample efﬁcient compared to prior work.

IRL methods that use our pretraining and adaptive BC regularization technique (RDAC). We ﬁnd
that our soft Q-ﬁltering method does improve prior state-of-the-art adversarial IRL (RDAC vs. DAC
in Fig. 15). However, our OT-based approach (ROT) is more stable and on average leads to more
efﬁcient learning.

22

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

1.25

1.00

0.75

0.50

0.25

0.00

0.25

1.00

0.75

0.50

0.25

0.00

0.25

fetch_reach

fetch_push

fetch_pick_and_place

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

metaworld_hammer

metaworld_drawer_close

metaworld_drawer_open

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

0.2

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

metaworld_door_open

metaworld_bin_picking

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.00

0.75

0.50

0.25

0.00

0.25

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

0.2

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

metaworld_button_press_topdown

1.0

0.8

0.6

0.4

0.2

0.0

0.2

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

metaworld_door_unlock

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

Expert

BC

OT

DAC

ROT (Ours)

Figure 11: State-based continuous control learning on DMC and Meta-World tasks. We notice that
ROT is signiﬁcantly more sample efﬁcient compared to prior work.

23

d
r
a
w
e
r
_
e
d
o
s
i
p
e

500

400

300

200

100

0

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

200

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

dmc_acrobot_swingup

dmc_cartpole_swingup

dmc_finger_spin

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

dmc_hopper_stand

dmc_hopper_hop

300

200

100

d
r
a
w
e
r
_
e
d
o
s
i
p
e

0

dmc_walker_stand

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1200

1000

800

600

400

200

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

dmc_walker_walk

dmc_walker_run

dmc_quadruped_run

d
r
a
w
e
r
_
e
d
o
s
i
p
e

800

600

400

200

0

600

400

200

d
r
a
w
e
r
_
e
d
o
s
i
p
e

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

metaworld_hammer

metaworld_drawer_close

metaworld_door_open

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.00

0.75

0.50

0.25

0.00

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.00

0.75

0.50

0.25

0.00

0.25

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

metaworld_drawer_open

metaworld_button_press_topdown

metaworld_door_unlock

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

Suite

Tasks

ROT 2nd Best Model Speedup Factor

DeepMind Control

Acrobot Swingup

Cartpole Swingup

Finger Spin

Cheetah Run

Hopper Stand

Hopper Hop

Walker Stand

Walker Walk

Walker Run

Quadruped Run

OpenAI Robotics

Fetch Reach

200k

100k

20k

400k

60k.

200k

80k

200k

320k

400k

300k

600k (OT)

350k (OT)

700k (OT)

2M (DAC)

750k (OT)

>2M (DAC)

400k (DAC)

750k (DAC)

>2M (OT)

>2M (DAC)

1.1M (DAC)

Fetch Push

1.1M 600k (DAC)

Fetch Pick and Place

Meta-World

Hammer

Drawer Close

Drawer Open

Door Open

Bin Picking

750k

200k

20k

>1M

400k

700k

>1.5M (OT)

>1M (DAC)

>1M (OT)

>1M (OT)

>1M (OT)

>1M (OT)

Button Press Topdown >1M

>1M (OT)

Door Unlock

1M

>1M (OT)

3

3.5

35

5

12.5

10

5

3.75

6.25

5

3.67

0.54

2

5

50

1

2.5

1.43

1

1

Table 3: Task-wise comparison between environment steps required to reach 90% of expert perfor-
mance for pixel-based ROT compared to the strongest baseline for each task.

24

Expert

BC

Finetune with ﬁxed weight

Finetune with ﬁxed schedule

ROT (Ours)

Figure 12: Pixel-based ablation analysis on the effect of varying BC regularization schemes. We
observe that our adaptive soft-Q ﬁltering regularization is more stable compared to prior hand-tuned
regularization schemes.

25

d
r
a
w
e
r
_
e
d
o
s
p
e

i

800

600

400

200

0

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.2

1.0

0.8

0.6

0.4

0.2

0.0

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

dmc_cheetah_run

dmc_hopper_hop

dmc_quadruped_run

300

200

100

d
r
a
w
e
r
_
e
d
o
s
p
e

i

0

d
r
a
w
e
r
_
e
d
o
s
p
e

i

600

500

400

300

200

100

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

fetch_reach

fetch_push

fetch_pick_and_place

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

0.00

0.25

0.50

0.75
frame

1.00

1.25

1.50
1e6

0.00

0.25

0.50

0.75
frame

1.00

1.25

1.50
1e6

0.00

0.25

0.50

0.75
frame

1.00

1.25

1.50
1e6

metaworld_door_open

metaworld_hammer

metaworld_drawer_close

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.0

0.2

0.4

0.6

0.8

frame

1.0

1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0

1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0

1e6

Expert

BC

OT

DrQ-v2(RL)

Demo-DrQ-v2

ROT (Ours)

Figure 13: Pixel-based ablation analysis on the performance comparison of ROT against DrQ-v2,
a reward-based RL method. Here we see that ROT can outperform plain RL that requires explicit
task-reward. However, we also observe that this RL method combined with our regularization scheme
provides strong results.

26

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

1.25

1.00

0.75

0.50

0.25

0.00

0.25

dmc_finger_spin

dmc_cheetah_run

dmc_walker_run

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

fetch_reach

fetch_push

fetch_pick_and_place

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

metaworld_door_open

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

1.25

1.00

0.75

0.50

0.25

0.00

0.25

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

metaworld_bin_picking

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

1.00

0.75

0.50

0.25

0.00

0.25

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

metaworld_hammer

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

BC

OT

BC+OT

OT+BC Reg.

ROT (Ours)

Figure 14: Pixel-based ablation analysis on the importance of pretraining and regularizing the IRL
policy. The key takeaway from these experiments is that both pretraining and BC regularization are
required to obtain sample-efﬁcient imitation learning.

27

1200

1000

800

600

400

200

0

d
r
a
w
e
r
_
e
d
o
s
i
p
e

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

1.00

0.75

0.50

0.25

0.00

0.25

dmc_finger_spin

dmc_cheetah_run

dmc_walker_run

800

600

400

200

d
r
a
w
e
r
_
e
d
o
s
i
p
e

0

800

d
r
a
w
e
r
_
e
d
o
s
i
p
e

600

400

200

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

fetch_reach

fetch_push

fetch_pick_and_place

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

metaworld_door_open

metaworld_hammer

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

metaworld_button_press_topdown

1.25

1.00

0.75

0.50

0.25

0.00

0.25

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

Expert

BC

DAC

OT

RDAC

ROT (Ours)

Figure 15: Pixel-based ablation analysis on the choice of base IRL method. We ﬁnd that although
adversarial methods beneﬁt from regularized BC, the gains seen are smaller compared to ROT.

28

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1250

1000

750

500

250

0

250

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

1.00

0.75

0.50

0.25

0.00

0.25

dmc_finger_spin

dmc_cheetah_run

d
r
a
w
e
r
_
e
d
o
s
i
p
e

1000

800

600

400

200

0

dmc_walker_run

1000

d
r
a
w
e
r
_
e
d
o
s
i
p
e

800

600

400

200

0

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

0.0

0.5

1.0
frame

1.5

2.0
1e6

fetch_reach

1.2

1.0

0.8

0.6

0.4

0.2

0.0

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

fetch_push

fetch_pick_and_place

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

0.00 0.25 0.50 0.75 1.00 1.25 1.50
1e6
frame

metaworld_door_open

metaworld_hammer

metaworld_button_press_topdown

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.25

1.00

0.75

0.50

0.25

0.00

0.25

e
g
a
t
n
e
c
r
e
p
_
s
s
e
c
c
u
s

1.0

0.8

0.6

0.4

0.2

0.0

0.2

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

0.0

0.2

0.4

0.6

0.8

frame

1.0
1e6

","Watch and Match: Supercharging Imitation with Regularized Optimal Transport Siddhant Haldar1 Vaibhav Mathur Denis Yarats Lerrel Pinto New York University rot-robot.github.io Abstract: Imitation learning holds tremendous promise in learning policies efﬁciently for complex decision making problems. Current state-of-the-art algorithms often use inverse reinforcement learning (IRL), where given a set of expert demonstrations, an agent alternatively infers a reward function and the associated optimal policy. However, such IRL approaches often require substantial online interactions for complex control problems. In this work, we present Regularized Optimal Transport (ROT), a new imitation learning algorithm that builds on recent advances in optimal transport based trajectory-matching. Our key technical insight is that adaptively combining trajectory-matching rewards with behavior cloning can signiﬁcantly accelerate imitation even with only a few demonstrations. Our experiments on 20 visual control tasks across the DeepMind Control Suite, the OpenAI Robotics Suite, and the Meta-World Benchmark demonstrate an average of 7.8× faster imitation to reach 90% of expert performance compared to prior state-of-the-art methods. On real-world robotic manipulation, with just one demonstration and an hour of online training, ROT achieves an average success rate of 90.1% across 14 tasks. Keywords: Imitation Learning, Manipulation, Robotics 2 2 0 2 n u J 0 3 ] O R . s c [ 1 v 9 6 4 5 1 . 6 0 2 2 : v i X r a Figure 1: (Top) Regularized Optimal Transport (ROT) is a new imitation learning algorithm that adaptively combines ofﬂine behavior cloning with online trajectory-matching based rewards. This enables signiﬁcantly faster imitation across a variety of simulated and real robotics tasks, while being compatible with high-dimensional visual observation. (Bottom) On our xArm robot, ROT can learn visual policies with only a single human demonstration and under an hour of online training. 1Correspondence to: sh6474@nyu.edu Opening a box Hanging a tote bag Placing peg in a box Pouring almonds t n e g A t r e p x E πBC πROT OT Rewards Adaptive Regularization OT Computation Environments Environment Interactions 1 Introduction Imitation Learning (IL) [1, 2, 3] has a rich history that can be categorized across two broad paradigms, Behavior Cloning (BC) [1] and Inverse Reinforcement Learning (IRL) [4]. BC uses supervised learning to obtain a policy that maximizes the likelihood of taking the demonstrated action given an observation in the demonstration. While this allows for training without online interactions, it suffers from distributional mismatch during online rollouts [5]. IRL, on the other hand, infers the underlying reward function from the demonstrated trajectories before employing RL to optimize a policy through online environment rollouts. This results in a policy that can robustly solve demonstrated tasks even in the absence of task-speciﬁc rewards [6, 7]. Although powerful, IRL methods suffer from a signiﬁcant drawback – they require numerous expensive online interactions with the environment. There are three reasons for this: (a) the inferred reward function is often highly non-stationary, which compromises the learning of the associated behavior policy [7]; (b) even when the rewards are stationary, policy learning still requires effective exploration to maximize rewards [8]; and (c) when strong priors such as pretraining with BC are applied to accelerate policy learning, ensuing updates to the policy cause a distribution shift that destabilizes training [9, 10]. Combined, these issues manifest themselves on empirical benchmarks, where IRL methods have poor efﬁciency compared to vanilla RL methods on hard control tasks [11]. In this work, we present Regularized Optimal Transport (ROT) for imitation learning, a new method that is conceptually simple, compatible with high-dimensional observations, and requires minimal additional hyperparameters compared to standard IRL approaches. In order to address the challenge of reward non-stationarity in IRL, ROT builds upon recent advances in using Optimal Transport (OT) [12, 13, 11] for reward computation that use non-parametric trajectory-matching functions. To alleviate the challenge of exploration, we pretrain the IRL behavior policy using BC on the expert demonstrations. This reduces the need for our imitation agent to explore from scratch. However, even with OT-based reward computation and pretrained policies, we only obtain marginal gains in empirical performance. The reason for this is that the high-variance of IRL policy gradi- ents [14, 15] often wipe away the progress made by the ofﬂine BC pretraining. This phenomenon has been observed in both online RL [16] and ofﬂine RL [9] methods. Inspired by solutions presented in these works, we stabilize the online learning process by regularizing the IRL policy to stay close to the pretrained BC policy. To enable this, we develop a new adaptive weighing scheme called soft Q-ﬁltering that automatically sets the regularization – prioritizing staying close to the BC policy in the beginning of training and prioritizing exploration later on. In contrast to prior policy regularization schemes [16, 17], soft Q-ﬁltering does not require hand-speciﬁcation of decay schedules. To demonstrate the effectiveness of ROT, we run extensive experiments on 20 simulated tasks across DM Control [18], OpenAI Robotics [19], and Meta-world [20], and 14 robotic manipulation tasks on an xArm (see Fig. 1). Our main ﬁndings are summarized below. 1. ROT outperforms prior state-of-the-art imitation methods, reaching 90% of expert performance 7.8× faster than our strongest baselines on simulated visual control benchmarks. 2. On real-world tasks, with a single human demonstration and an hour of training, ROT achieves an average success rate of 90.1% with randomized robot initialization and image observations. This is signiﬁcantly higher than behavior cloning (36.1%) and adversarial IRL (14.6%). 3. ROT exceeds the performance of state-of-the-art RL trained with rewards, while coming close to methods that augment RL with demonstrations (Section 5.5 & Appendix H.3). Unlike standard RL methods, ROT does not require hand-speciﬁcation of the reward function. 4. Ablation studies demonstrate the importance of every component in ROT, particularly the role that soft Q-ﬁltering plays in stabilizing training and the need for OT-based rewards during online learning (Section 5.3 & Appendix H.4). Open-source code and demonstration data will be publicly released on our project website. Videos of our trained policies can be seen here: rot-robot.github.io/. 2 Figure 2: (a) Given a single demonstration to avoid the grey obstacle and reach the goal location, BC is unable to solve the task. (b) Finetuning from this BC policy with OT-based reward also fails to solve the task. (c) ROT, with adaptive regularization of OT-based IRL with BC successfully solves the task. (d) Even when the ROT agent is initialized randomly, it is able to solve the task. 2 Background Before describing our method in detail, we provide a brief background to imitation learning with optimal transport, which serves as the backbone of our method. Formalism related to RL follows the convention in prior work [8, 11] and is described in Appendix A. t=1}N Imitation Learning with Optimal Transport (OT) The goal of imitation learning is to learn a behavior policy πb given access to either the expert policy πe or trajectories derived from the expert policy T e. While there are a multitude of settings with differing levels of access to the expert [21], our work operates in the setting where the agent only has access to observation-based trajectories, i.e. T e ≡ {(ot, at)T n=1. Here N and T denotes the number of trajectory rollouts and episode timesteps respectively. Inverse Reinforcement Learning (IRL) [4, 22] tackles the IL problem by inferring the reward function re based on expert trajectories T e. Then given the inferred reward re, policy optimization is used to derive the behavior policy πb. To compute re, a new line of OT-based approaches for IL [12, 13, 11] have been proposed. Intuitively, the closeness between expert trajectories T e and behavior trajectories T b can be computed by measuring the optimal transport of probability mass from T b → T e. Thus, given a cost matrix Ct,t(cid:48) = c(ob t(cid:48)) and the optimal alignment µ∗ between a behavior trajectory ob and and expert trajectory oe, a reward signal for each observation can be computed using the equation: t , oe rOT (ob t ) = − T (cid:88) t(cid:48)=1 Ct,t(cid:48) µ∗ t,t(cid:48) (1) A detailed account of the OT formulation has been provided in Appendix A. Actor-Critic based reward maximization Given rewards obtained through OT computation, efﬁ- cient maximization of the reward can be achieved through off-policy learning [7]. In this work, we use Deep Deterministic Policy Gradient (DDPG) [23] as our base RL optimizer which is an actor-critic algorithm that concurrently learns a deterministic policy πφ and a Q-function Qθ. However, instead of minimizing a one step Bellman residual in vanilla DDPG, we use the recent n-step version of DDPG from Yarats et al. [8] that achieves high performance on visual control problems. 3 Challenges in Online Finetuning from a Pretrained Policy In this section, we study the challenges with ﬁnetuning a pretrained policy with online interactions in the environment. Fig. 2 illustrates a task where an agent is supposed to navigate the environment from the top left to the bottom right, while dodging obstacles in between. The agent has access to a single expert demonstration, which is used to learn a BC policy for the task. Fig. 2 (a) shows that this BC policy, though close to the expert demonstration, performs suboptimally due to accumulating errors on out-of-distribution states during online rollouts [5]. Further, Fig. 2 (b) uses this BC policy 3 Expert trajectory BC trajectory Start location Goal location (a) Task: Particle Reach (b) IRL Finetune w/o Reg. (c) ROT (d) ROT + random init. 100k s p e t s e m i t 0 Expert trajectory BC trajectory Start location Goal location as an initialization and naively ﬁnetunes it with OT rewards (described in Section 2). Such naive ﬁnetuning of a pretrained policy (or actor) with an untrained critic in an actor-critic framework exhibits a forgetting behavior in the actor, resulting in performance degradation as compared to the pretrained policy. This phenomenon has also been reported by Nair et al. [9] and we provide a detailed discussion in Appendix B. In this paper, we propose ROT which addresses this issue by adaptively keeping the policy close to the behavior data during the initial phase of ﬁnetuning and reduces this dependence over time. Fig. 2 (c) demonstrates the performance of our approach on such ﬁnetuning. It can be clearly seen that even though the BC policy is suboptimal, our proposed adaptive regularization scheme quickly improves and solves the task by driving it closer to the expert demonstration. In Fig. 2 (d), we demonstrate that even if the agent was initialized at points outside the expert trajectory, the agent is still able to learn quickly and complete the task. This generalization to starting states would not be possible with regular BC. 4 Regularized Optimal Transport A fundamental challenge in imitation learning is to balance the ability to mimic demonstrated actions along with the ability to recover from states outside the distribution of demonstrated states. Behavior Cloning (BC) specializes in mimicking demonstrated actions through supervised learning, while Inverse Reinforcement Learning (IRL) specializes in obtaining policies that can recover from arbitrary states. Regularized Optimal Transport (ROT) combines the best of both worlds by adaptively combining the two objectives. This is done in two phases. In the ﬁrst phase, a randomly initialized policy is trained using the BC objective on expert demonstrated data. This ‘BC-pretrained’ policy then serves as an initialization for the second phase. In the second phase, the policy is allowed access to the environment where it can train using an IRL objective. To accelerate the IRL training, the BC loss is added to the objective with an adaptive weight. Details of each component are described below, with additional algorithmic details in Appendix C. 4.1 Phase 1: BC Pretraining BC corresponds to solving the maximum likelihood problem shown in Eq. 2. Here T e refers to expert demonstrations. When parameterized by a normal distribution with ﬁxed variance, the objective can be framed as a regression problem where, given inputs se, πBC needs to output ae. LBC = E(se,ae)∼T e (cid:107)ae − πBC(se)(cid:107)2 (2) After training, it enables πBC to mimic the actions corresponding to the observations seen in the demonstrations. However, during rollouts in an environment, small errors in action prediction can lead to the agent visiting states not seen in the demonstrations [5]. This distributional mismatch often causes πBC to fail on empirical benchmarks [16, 11] (see Fig. 2 (a) in Sec. 3). 4.2 Phase 2: Online Finetuning with IRL Given a pretrained πBC model, we now begin online ‘ﬁnetuning’ of the policy πb ≡ πROT in the environment. Since we are operating without explicit task rewards, we use rewards obtained through OT-based trajectory matching, which is described in Section 2. These OT-based rewards rOT enable the use of standard RL optimizers to maximize cumulative reward from πb ≡ πROT . In this work we use n-step DDPG [23], a deterministic actor-critic based method that provides high-performance in continuous control [8]. Finetuning with Regularization πBC is susceptible to distribution shift due to accumulation of errors during online rollouts [5] and directly ﬁnetuning πBC also leads to subpar performance (refer to Fig. 2 in Sec. 3). To address this, we build upon prior work in guided RL [16] and ofﬂine RL [9], and regularize the training of πROT by combining it with a BC loss as seen in Eq. 3. πROT = argmax π (cid:2)(1 − λ(π)))E(s,a)∼Dβ [Q(s, a)] − αλ(π)E(se,ae)∼T e (cid:107)ae − πBC(se)(cid:107)2(cid:3) (3) 4 Here, Q(s, a) represents the Q-value from the critic used in actor-critic policy optimization. α is a ﬁxed weight, while λ(π) is a policy-dependent adaptive weight that controls the contributions of the two loss terms. Dβ refers to the replay buffer for online rollouts. Adaptive Regularization with Soft Q-ﬁltering While prior work [16, 17] use hand-tuned sched- ules for λ(π), we propose a new adaptive scheme that removes the need for tuning. This is done by comparing the performance of the current policy πROT and the pretrained policy πBC on a batch of data sampled from an expert replay buffer De. More precisely, given a behavior policy πBC(s), the current policy πROT (s), the Q-function Q(s, a) and the replay buffer De, we set λ as: λ(πROT ) = E(s,·)∼De (4) The strength of the BC regularization hence depends on the performance of the current policy with respect to the behavior policy. This ﬁltering strategy is inspired by Nair et al. [24], where instead of a binary hard assignment we use a soft continuous weight. Experimental comparisons with hand-tuned decay strategies are presented in Section 5.3. (cid:2)1Q(s,πBC (s))>Q(s,πROT (s)) (cid:3) Considerations for image-based observations Since we are interested in using ROT with high- dimensional visual observations, additional machinery is required to ensure compatibility. Following prior work in image-based RL and imitation [8, 11], we perform data augmentations on visual observations and then feed it into a CNN encoder. Similar to Cohen et al. [11], we use a target encoder with Polyak averaging to obtain representations for OT reward computation. This is necessary to reduce the non-stationarity caused by learning the encoder alongside the ROT imitation process. Further implementation details and the training procedure can be found in Appendix C. 5 Experiments Our experiments are designed to answer the following questions: (a) How efﬁcient is ROT for imitation learning? (b) How does ROT perform on real-world tasks? (c) How important is the choice of IRL method in ROT? (d) Does soft Q-ﬁltering improve imitation? (e) How does ROT compare to standard reward-based RL? Additional results and analysis have been provided in Appendix H. Simulated tasks We experiment with 10 tasks from the DeepMind Control suite [18, 25], 3 tasks from the OpenAI Robotics suite [26], and 7 tasks from the Meta-world suite [27]. For DeepMind Control tasks, we train expert policies using DrQ-v2 [8] and collect 10 demonstrations for each task using this policy. For OpenAI Robotics tasks, we train a state-based DrQ-v2 with hindsight experience replay [28] and collect 50 demonstrations for each task. For Meta-world tasks, we use a single hard-coded expert demonstration from their open-source implementation [27]. Full environment details can be found in Appendix D and details about the variations in demonstrations and initialization conditions can be found in Appendix E. Robot tasks Our real world setup for each of the 14 manipulation tasks can be seen in Fig. 4. We use an Ufactory xArm 7 robot with a xArm Gripper as the robot platform for our real world experiments. However, our method is agnostic to the speciﬁc robot hardware. The observations are RGB images from a ﬁxed camera. In this setup, we only use a single expert demonstration collected by a human operator with a joystick and limit the online training to a ﬁxed period of 1 hour. Descriptions of each task and the evaluation procedure is in Appendix F. Primary baselines We compare ROT with baselines against several prominent imitation learning methods. While a full description of our baselines are in Appendix G, a brief description of the two strongest ones are as follows: 1. Adversarial IRL (DAC): Discriminator Actor Critic [7] is a state-of-the-art adversarial imitation learning method [6, 29, 7]. DAC outperforms prior work such as GAIL [6] and AIRL [30], and thus it serves as our primary adversarial imitation baseline. 2. Trajectory-matching IRL (OT): Sinkhorn Imitation Learning [12, 13] is a state-of-the-art trajectory-matching imitation learning method [31] that approximates OT matching through the Sinkhorn Knopp algorithm [32, 33]. Since ROT is derived from similar OT-based foundations, we use SIL as our primary state-matching imitation baseline. 5 Expert BC OT DAC ROT (Ours) Figure 3: Pixel-based continuous control learning on 9 selected environments. Shaded region represents ±1 standard deviation across 5 seeds. We notice that ROT is signiﬁcantly more sample efﬁcient compared to prior work. 5.1 How efﬁcient is ROT for imitation learning? Performance of ROT for image-based imitation is depicted on select environments in Fig. 3. On all but one task, ROT trains signiﬁcantly faster than prior work. To reach 90% of expert performance, ROT is on average 8.7× faster on DeepMind Control tasks, 2.1× faster on OpenAI Robotics tasks, and 8.9× faster on Meta-world tasks. We also ﬁnd that the improvements of ROT are most apparent on the harder tasks, which are in rightmost column of Fig. 3. Appendix H.1 shows results on all 20 simulated tasks, along with experiments that exhibit similar improvements in state-based settings. 5.2 How does ROT perform on real-world tasks? We devise a set of 14 manipulation tasks on our xArm robot to compare the performance of ROT with BC and our strongest baseline RDAC, an adversarial IRL method that combines DAC [7] with our pretraining and regularization scheme. The BC policy is trained using supervised learning on a single expert demonstration collected by a human operator. ROT and RDAC ﬁnetune the pretrained BC policy through 1 hour of online training, which amounts to ∼ 6k environment steps. Since there is just one demonstration, our tasks are designed to have random initializations but ﬁxed goals. Note that a single demonstration only demonstrates solving the tasks from one initial condition. Evaluation results across 20 different initial conditions can be seen in Fig. 4. We observe that ROT has an average success rate of 90.1% over 20 evaluation trajectories across all tasks as compared to 36.1% for BC and 14.6% for RDAC. The poor performance of BC can be attributed to distributional mismatch due to accumulation of error in online rollouts and different initial conditions. The poor performance of RDAC can be attributed to slow learning during the initial phase of training. More detailed evaluations of RDAC on simulated environments is present in Sec. 5.4. 6 d r a w e r _ e d o s i p e 1000 800 600 400 200 0 e t a r s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 1.0 e t a r s s e c c u s 0.8 0.6 0.4 0.2 0.0 dmc_cheetah_run dmc_hopper_hop dmc_walker_run 300 200 100 d r a w e r _ e d o s i p e 0 800 600 400 200 d r a w e r _ e d o s i p e 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 fetch_reach fetch_push fetch_pick_and_place e t a r s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 e t a r s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame metaworld_drawer_close metaworld_hammer metaworld_door_open e t a r s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 e t a r s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 Figure 4: (Top) ROT is evaluated on a set of 14 robotic manipulation tasks. (Bottom) Success rates for each task is computed by running 20 trajectories from varying initial conditions on the robot. BC RDAC ROT (Ours) 5.3 Does soft Q-ﬁltering improve imitation? To understand the importance of soft Q-ﬁltering, we compare ROT against two variants of our proposed regular- ization scheme: (a) A tuned ﬁxed BC regularization weight (ignoring λ(π) in Eq. 3); (b) A carefully designed linear-decay schedule for λ(π), where it varies from 1.0 to 0.0 in the ﬁrst 20k environment steps [16]. As demon- strated in Fig. 5 (and Appendix H.2), ROT is on par and in some cases ex- ceeds the efﬁciency of a hand-tuned decay schedule, while not having to hand-tune its regularization weights. We hypothesize this improvement is primarily due to the better stability of adaptive weighing as seen in the signiﬁcantly smaller standard deviation on the Meta-world tasks. Figure 5: Effect of various BC regularization schemes com- pared with our adaptive soft-Q ﬁltering regularization. Finetune with ﬁxed weight Finetune with ﬁxed ROT (Ours) schedule 5.4 How important is the choice of IRL method in ROT? In ROT, we build on OT-based IRL instead of adversarial IRL. This is because adversarial IRL methods require iterative reward learning, which produces a highly non-stationary reward function for policy optimization. In Fig. 6, we compare ROT with adversarial IRL methods that use our pretraining and adaptive BC regularization technique (RDAC). We ﬁnd that our soft Q-ﬁltering method does improve prior state-of-the-art adversarial IRL (RDAC vs. DAC in Fig. 6). However, our OT-based approach (ROT) is more stable and on average leads to more efﬁcient learning. 5.5 How does ROT compare to standard reward-based RL? We compare the performance of ROT against DrQ-v2 [8], a state-of-the-art algorithm for image-based RL. As opposed to the reward-free setting ROT operates in, DrQ-v2 has access to environments rewards. The results in Fig. 6 show that ROT handily outperforms DrQ-v2. This clearly demonstrates 7 Close a door Hang a hanger Erasing a board Reach Hanging a mug Hanging a tote bag Turn a knob Stacking cups Pressing a switch Peg in a box (Easy) Peg in a box (Med) Peg in a box (Hard) Opening a box Pouring almonds dmc_hopper_hop metaworld_hammer 300 200 100 d r a w e r e d o s p e i 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 1.0 0.8 0.6 0.4 0.2 e t a r s s e c c u s 0.0 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 Expert BC DAC OT DrQ-v2 (RL) RDAC ROT (Ours) Figure 6: Ablation analysis on the choice of base IRL method. We ﬁnd that although adversarial methods beneﬁt from regularized BC, the gains seen are smaller compared to ROT. Here, we also see that ROT can outperform plain RL that requires explicit task-rewards. the usefulness of imitation learning in domains where expert demonstrations are available over reward-based RL. We also compare against a demo-assisted variant of DrQ-v2 agent using the same pretraining and regularization scheme as ROT (refer to Appendix H.3). Interestingly, we ﬁnd that our soft Q-ﬁltering based regularization can accelerate learning of RL with task rewards, which can be seen in the high performance of the demo-assisted variant of DrQ-v2. 6 Related Work Imitation Learning (IL) IL [34] refers to the setting where agents learn from demonstrations without access to environment rewards. IL can be broadly categorized into Behavior Cloning (BC) [1, 21, 35, 36] and Inverse Reinforcement Learning (IRL) [4, 22]. BC solely learns from ofﬂine demonstrations but suffers on out-of-distributions samples [5] whereas IRL focuses on learning a robust reward function through online interactions but suffers from sample inefﬁciency [7]. Deep IRL methods can be further divided into two categories: (1) adversarial learning [37] based methods, and (2) state-matching [38, 39] based methods. GAIL [6] is an adversarial learning based formulation inspired by maximum entropy IRL [40] and GANs [37]. There has been a signiﬁcant body of work built up on GAIL proposing alternative losses [30, 41, 29], and enhancing its sample efﬁciency by porting it to an off-policy setting [7]. There have also been visual extensions of these adversarial learning approaches [42, 43, 44, 11]. However, although adversarial methods produce competent policies, they are inefﬁcient due to the non-stationarity associated with iterative reward inference [11]. Optimal Transport (OT) OT [38, 39] is a tool for comparing probability measures while including the geometry of the space. In the context of IL, OT computes an alignment between a set of agent and expert observations using distance metrics such as Sinkhorn [33], Gromov-Wasserstein [45], GDTW [46], CO-OT [47] and Soft-DTW [48]. For many of these distance measures, there is an associated IL algorithm, with SIL [12] using Sinkhorn, PWIL [13] using greedy Wasserstein, GDTW-IL [46] using GDTW, and GWIL [49] using Gromov-Wasserstein. Recent work from Cohen et al. [11] demonstrates that the Sinkhorn distance [12] produces the most efﬁcient learning among the discussed metrics. They further show that SIL is compatible with high-dimensional visual observations and encoded representations. Inspired by this, ROT adopts the Sinkhorn metric for its OT reward computation, and improves upon SIL through adaptive behavior regularization. Behavior Regularized Control Behavior regularization is a widely used technique in ofﬂine RL [50] where explicit constraints are added to the policy improvement update to avoid bootstrapping on out-of-distribution actions [51, 52, 53, 54, 55, 56]. In an online setting with access to environment rewards, prior work [16, 10] has shown that behavior regularization can be used to boost sample efﬁciency by ﬁnetuning a pretrained policy via online interactions. For instance, Jena et al. [17] demonstrates the effectiveness of behavior regularization to enhance sample efﬁciency in the context of adversarial IL. ROT builds upon this idea by extending to visual observations, OT-based IL, and adaptive regularization, which leads to improved performance (see Appendix H.4). We also note that the idea of using adaptive regularization has been previously explored in RL [24]. However, ROT uses a soft, continuous adaptive scheme, which on initial experiments provided signiﬁcantly faster learning compared to hard assignments. 8 1000 d r a w e r e d o s i p e 800 600 400 200 0 dmc_walker_run fetch_pick_and_place metaworld_hammer e t a r s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 e t a r s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.00 0.25 0.50 0.75 frame 1.00 1.25 1.50 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 7 Conclusion and Limitations In this work, we have proposed a new imitation learning algorithm, ROT, that demonstrates improved performance compared to prior state-of-the-art work on a variety of simulated and robotic domains. However, we recognize a few limitations in this work: (a) Since our OT-based approach aligns agents with demonstrations without task-speciﬁc rewards, it relies on the demonstrator being an ‘expert’. Extending ROT to suboptimal, noisy and multimodal demonstrations would be an exciting problem to tackle. (b) Performing BC pretraining and BC-based regularization requires access to expert actions, which may not be present in some real-world scenarios particularly when learning from humans. Recent work on using inverse models to infer actions given observational data could alleviate this challenge [57]. (c) On robotic tasks such as Peg in box (hard) and Pressing a switch from Fig. 4, we ﬁnd that ROT’s performance drops substantially compared to other tasks. This might be due to the lack of visual features corresponding to the task success. For example, in the ‘Peg’ task, it is visually difﬁcult to discriminate if the peg is in the box or behind the box. Similarly for the ‘Switch’ task, it is difﬁcult to discern if the button was pressed or not. This limitation can be addressed by integrating more sensory modalities such as additional cameras, and tactile sensors in the observation space. Acknowledgments We thank Ben Evans, Anthony Chen, Ulyana Piterbarg and Abitha Thankaraj for valuable feedback and discussions. This work was supported by grants from Honda, Amazon, and ONR awards N00014-21-1-2404 and N00014-21-1-2758. References [1] D. Pomerleau. An autonomous land vehicle in a neural network. Advances in Neural Information Processing Systems, 1, 1998. [2] O. M. Andrychowicz, B. Baker, M. Chociej, R. Jozefowicz, B. McGrew, J. Pachocki, A. Petron, M. Plappert, G. Powell, A. Ray, et al. Learning dexterous in-hand manipulation. The Interna- tional Journal of Robotics Research, 39(1):3–20, 2020. [3] P. N. Kolm and G. Ritter. Modern perspectives on reinforcement learning in ﬁnance. Modern Perspectives on Reinforcement Learning in Finance (September 6, 2019). The Journal of Machine Learning in Finance, 1(1), 2020. [4] A. Y. Ng, S. J. Russell, et al. Algorithms for inverse reinforcement learning. In Icml, volume 1, page 2, 2000. [5] S. Ross, G. Gordon, and D. Bagnell. A reduction of imitation learning and structured prediction to no-regret online learning. In Proceedings of the fourteenth international conference on artiﬁ- cial intelligence and statistics, pages 627–635. JMLR Workshop and Conference Proceedings, 2011. [6] J. Ho and S. Ermon. Generative adversarial imitation learning. Advances in neural information processing systems, 29, 2016. [7] I. Kostrikov, K. K. Agrawal, D. Dwibedi, S. Levine, and J. Tompson. Discriminator-actor-critic: Addressing sample inefﬁciency and reward bias in adversarial imitation learning. arXiv preprint arXiv:1809.02925, 2018. [8] D. Yarats, R. Fergus, A. Lazaric, and L. Pinto. Mastering visual continuous control: Improved data-augmented reinforcement learning. arXiv preprint arXiv:2107.09645, 2021. [9] A. Nair, A. Gupta, M. Dalal, and S. Levine. Awac: Accelerating online reinforcement learning with ofﬂine datasets. arXiv preprint arXiv:2006.09359, 2020. [10] I. Uchendu, T. Xiao, Y. Lu, B. Zhu, M. Yan, J. Simon, M. Bennice, C. Fu, C. Ma, J. Jiao, et al. Jump-start reinforcement learning. arXiv preprint arXiv:2204.02372, 2022. [11] S. Cohen, B. Amos, M. P. Deisenroth, M. Henaff, E. Vinitsky, and D. Yarats. Imitation learning from pixel observations for continuous control, 2022. URL https://openreview.net/ forum?id=JLbXkHkLCG6. 9 [12] G. Papagiannis and Y. Li. arXiv:2008.09167, 2020. Imitation learning with sinkhorn distances. arXiv preprint [13] R. Dadashi, L. Hussenot, M. Geist, and O. Pietquin. Primal wasserstein imitation learning. arXiv preprint arXiv:2006.04678, 2020. [14] J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017. [15] D. Silver, G. Lever, N. Heess, T. Degris, D. Wierstra, and M. Riedmiller. Deterministic policy gradient algorithms. In International conference on machine learning, pages 387–395. PMLR, 2014. [16] A. Rajeswaran, V. Kumar, A. Gupta, G. Vezzani, J. Schulman, E. Todorov, and S. Levine. Learning complex dexterous manipulation with deep reinforcement learning and demonstrations. arXiv preprint arXiv:1709.10087, 2017. [17] R. Jena, C. Liu, and K. Sycara. Augmenting gail with bc for sample efﬁcient imitation learning. arXiv preprint arXiv:2001.07798, 2020. [18] Y. Tassa, Y. Doron, A. Muldal, T. Erez, Y. Li, D. d. L. Casas, D. Budden, A. Abdolmaleki, J. Merel, A. Lefrancq, et al. Deepmind control suite. arXiv preprint arXiv:1801.00690, 2018. [19] G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, and W. Zaremba. Openai gym. arXiv preprint arXiv:1606.01540, 2016. [20] T. Yu, D. Quillen, Z. He, R. Julian, K. Hausman, C. Finn, and S. Levine. Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning. In Conference on Robot Learning, pages 1094–1100. PMLR, 2020. [21] F. Torabi, G. Warnell, and P. Stone. Recent advances in imitation learning from observation. arXiv preprint arXiv:1905.13566, 2019. [22] P. Abbeel and A. Y. Ng. Apprenticeship learning via inverse reinforcement learning. In Proceedings of the twenty-ﬁrst international conference on Machine learning, page 1, 2004. [23] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N. Heess, T. Erez, Y. Tassa, D. Silver, and D. Wierstra. Continuous control with deep reinforcement learning. arXiv preprint arXiv:1509.02971, 2015. [24] A. Nair, B. McGrew, M. Andrychowicz, W. Zaremba, and P. Abbeel. Overcoming exploration in reinforcement learning with demonstrations. In 2018 IEEE international conference on robotics and automation (ICRA), pages 6292–6299. IEEE, 2018. [25] E. Todorov, T. Erez, and Y. Tassa. Mujoco: A physics engine for model-based control. In 2012 IEEE/RSJ international conference on intelligent robots and systems, pages 5026–5033. IEEE, 2012. [26] M. Plappert, M. Andrychowicz, A. Ray, B. McGrew, B. Baker, G. Powell, J. Schneider, J. Tobin, M. Chociej, P. Welinder, et al. Multi-goal reinforcement learning: Challenging robotics environments and request for research. arXiv preprint arXiv:1802.09464, 2018. [27] T. Yu, D. Quillen, Z. He, R. Julian, K. Hausman, C. Finn, and S. Levine. Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning. In Conference on Robot Learning (CoRL), 2019. URL https://arxiv.org/abs/1910.10897. [28] M. Andrychowicz, F. Wolski, A. Ray, J. Schneider, R. Fong, P. Welinder, B. McGrew, J. Tobin, O. Pieter Abbeel, and W. Zaremba. Hindsight experience replay. Advances in neural information processing systems, 30, 2017. [29] F. Torabi, G. Warnell, and P. Stone. Generative adversarial imitation from observation. arXiv preprint arXiv:1807.06158, 2018. [30] J. Fu, K. Luo, and S. Levine. Learning robust rewards with adversarial inverse reinforcement learning. arXiv preprint arXiv:1710.11248, 2017. 10 [31] S. K. S. Ghasemipour, R. Zemel, and S. Gu. A divergence minimization perspective on imitation learning methods. In Conference on Robot Learning, pages 1259–1277. PMLR, 2020. [32] R. Sinkhorn and P. Knopp. Concerning nonnegative matrices and doubly stochastic matrices. Paciﬁc Journal of Mathematics, 21(2):343–348, 1967. [33] M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. Advances in neural information processing systems, 26, 2013. [34] A. Hussein, M. M. Gaber, E. Elyan, and C. Jayne. Imitation learning: A survey of learning methods. ACM Computing Surveys (CSUR), 50(2):1–35, 2017. [35] S. P. Arunachalam, S. Silwal, B. Evans, and L. Pinto. Dexterous imitation made easy: A learning- based framework for efﬁcient dexterous manipulation. arXiv preprint arXiv:2203.13251, 2022. [36] J. Pari, N. Muhammad, S. P. Arunachalam, and L. Pinto. The surprising effectiveness of representation learning for visual imitation. arXiv preprint arXiv:2112.01511, 2021. [37] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014. [38] C. Villani. Optimal transport: old and new, volume 338. Springer, 2009. [39] G. Peyr´e, M. Cuturi, et al. Computational optimal transport: With applications to data science. Foundations and Trends® in Machine Learning, 11(5-6):355–607, 2019. [40] B. D. Ziebart, A. L. Maas, J. A. Bagnell, A. K. Dey, et al. Maximum entropy inverse reinforce- ment learning. In Aaai, volume 8, pages 1433–1438. Chicago, IL, USA, 2008. [41] H. Xiao, M. Herman, J. Wagner, S. Ziesche, J. Etesami, and T. H. Linh. Wasserstein adversarial imitation learning. arXiv preprint arXiv:1906.08113, 2019. [42] E. Cetin and O. Celiktutan. Domain-robust visual imitation learning with mutual information constraints. arXiv preprint arXiv:2103.05079, 2021. [43] S. Toyer, R. Shah, A. Critch, and S. Russell. The magical benchmark for robust imitation. Advances in Neural Information Processing Systems, 33:18284–18295, 2020. [44] R. Rafailov, T. Yu, A. Rajeswaran, and C. Finn. Visual adversarial imitation learning using variational models. Advances in Neural Information Processing Systems, 34, 2021. [45] G. Peyr´e, M. Cuturi, and J. Solomon. Gromov-wasserstein averaging of kernel and distance matrices. In International Conference on Machine Learning, pages 2664–2672. PMLR, 2016. [46] S. Cohen, G. Luise, A. Terenin, B. Amos, and M. Deisenroth. Aligning time series on incom- parable spaces. In International Conference on Artiﬁcial Intelligence and Statistics, pages 1036–1044. PMLR, 2021. [47] I. Redko, T. Vayer, R. Flamary, and N. Courty. Co-optimal transport. arXiv preprint arXiv:2002.03731, 2020. [48] M. Cuturi and M. Blondel. Soft-dtw: a differentiable loss function for time-series. In Interna- tional conference on machine learning, pages 894–903. PMLR, 2017. [49] A. Fickinger, S. Cohen, S. Russell, and B. Amos. Cross-domain imitation learning via optimal transport. arXiv preprint arXiv:2110.03684, 2021. [50] S. Levine, A. Kumar, G. Tucker, and J. Fu. Ofﬂine reinforcement learning: Tutorial, review, and perspectives on open problems. arXiv preprint arXiv:2005.01643, 2020. [51] S. Fujimoto and S. S. Gu. A minimalist approach to ofﬂine reinforcement learning. Advances in Neural Information Processing Systems, 34, 2021. [52] Y. Wu, G. Tucker, and O. Nachum. Behavior regularized ofﬂine reinforcement learning. arXiv preprint arXiv:1911.11361, 2019. 11 [53] A. Ajay, A. Kumar, P. Agrawal, S. Levine, and O. Nachum. {OPAL}: Ofﬂine primitive discovery In International Conference on Learning for accelerating ofﬂine reinforcement learning. Representations, 2021. URL https://openreview.net/forum?id=V69LGwJ0lIN. [54] A. Kumar, J. Fu, M. Soh, G. Tucker, and S. Levine. Stabilizing off-policy q-learning via bootstrapping error reduction. Advances in Neural Information Processing Systems, 32, 2019. [55] N. Y. Siegel, J. T. Springenberg, F. Berkenkamp, A. Abdolmaleki, M. Neunert, T. Lampe, R. Hafner, N. Heess, and M. Riedmiller. Keep doing what worked: Behavioral modelling priors for ofﬂine reinforcement learning. arXiv preprint arXiv:2002.08396, 2020. [56] S. Fujimoto, D. Meger, and D. Precup. Off-policy deep reinforcement learning without explo- ration. In International Conference on Machine Learning, pages 2052–2062. PMLR, 2019. [57] I. Radosavovic, X. Wang, L. Pinto, and J. Malik. State-only imitation learning for dexterous manipulation. In 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pages 7865–7871. IEEE, 2020. [58] R. Bellman. A markovian decision process. Journal of mathematics and mechanics, pages 679–684, 1957. [59] R. S. Sutton and A. G. Barto. Reinforcement learning: An introduction. MIT press, 2018. [60] V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski, et al. Human-level control through deep rein- forcement learning. nature, 518(7540):529–533, 2015. [61] A. Zhan, P. Zhao, L. Pinto, P. Abbeel, and M. Laskin. A framework for efﬁcient robotic manipulation. arXiv preprint arXiv:2012.07975, 2020. [62] S. Young, D. Gandhi, S. Tulsiani, A. Gupta, P. Abbeel, and L. Pinto. Visual imitation made easy. arXiv preprint arXiv:2008.04899, 2020. [63] P. A. Knight. The sinkhorn–knopp algorithm: convergence and applications. SIAM Journal on Matrix Analysis and Applications, 30(1):261–275, 2008. 12 A Background Reinforcement Learning (RL) We study RL as a discounted inﬁnite-horizon Markov Decision Process (MDP) [58, 59]. For pixel observations, the agent’s state is approximated as a stack of consecutive RGB frames [60]. The MDP is of the form (O, A, P, R, γ, d0) where O is the observation space, A is the action space, P : O × A → ∆(O) is the transition function that deﬁnes the probability distribution over the next state given the current state and action, R : O × A → R is the reward function, γ is the discount factor and d0 is the initial state distribution. The goal is to ﬁnd a policy π : O → ∆(A) that maximizes the expected discount sum of rewards Eπ[Σ∞ t=0γtR(ot, at)], where o0 ∼ d0, at ∼ π(ot) and ot+1 ∼ P (.|ot, at). Imitation Learning (IL) The goal of imitation learning is to learn a behavior policy πb given access to either the expert policy πe or trajectories derived from the expert policy T e. While there are a multitude of settings with differing levels of access to the expert [21], this work operates in the setting where the agent only has access to observation-based trajectories, i.e. T e ≡ {(ot, at)T n=0. Here N and T denotes the number of trajectory rollouts and episode timesteps respectively. We choose this speciﬁc setting since obtaining observations and actions from expert or near-expert demonstrators is feasible in real-world settings [61, 62] and falls in line with recent work in this area [13, 6, 7]. t=0}N Inverse Reinforcement Learning (IRL) IRL [4, 22] tackles the IL problem by inferring the reward function re based on expert trajectories T e. Then given the inferred reward re, policy optimization is used to derive the behavior policy πb. Prominent algorithms in IRL [7, 6] requires alternating the inference of reward and optimization of policy in an iterative manner, which is practical for restricted model classes [22]. For compatibility with more expressive deep networks, techniques such as adversarial learning [6, 7] or optimal-transport [12, 13, 11] are needed. Adversarial learning based approaches tackle this problem by learning a discriminator that models the gap between the expert trajectories T e and behavior trajectories T b. The behavior policy πb is then optimized to minimize this gap through gap-minimizing rewards re. Such a training procedure is prone to instabilities since re is updated at every iteration and is hence non-stationary for the optimization of πb. Optimal Transport for Imitation Learning (OT) To alleviate the non-stationary reward problem with adversarial IRL frameworks, a new line of OT-based approaches have been recently proposed [12, 13, 11]. Intuitively, the closeness between expert trajectories T e and behavior trajectories T b can be computed by measuring the optimal transport of probability mass from T b → T e. During policy learning, the policy πφ encompasses a feature preprocessor fφ which transforms observations into informative state representations. Some examples of a preprocessor function fφ are an identity function, a mean-variance scaling function and a parametric neural network. In this work, we use a parametric neural network as fφ. Given a cost function c : O × O → R deﬁned in the preprocessor’s output space and an OT objective g, the optimal alignment between an expert trajectory oe and a behavior trajectory ob can be computed as µ∗ ∈ arg min µ∈M g(µ, fφ(ob), fφ(oe), c) (5) where M = {µ ∈ RT ×T : µ1 = µT 1 = 1 T 1} is the set of coupling matrices and the cost c can be the Euclidean or Cosine distance. In this work, inspired by [11], we use the entropic Wasserstein distance with cosine cost as our OT metric, which is given by the equation g(µ, fφ(ob), fφ(oe), c) = W 2(fφ(ob), fφ(oe)) T (cid:88) = t,t(cid:48)=1 Ct,t(cid:48) µt,t(cid:48) 13 (6) where the cost matrix Ct,t(cid:48) = c(fφ(ob), fφ(oe)). Using Eq. 6 and the optimal alignment µ∗ obtained by optimizing Eq. 5, a reward signal can be computed for each observation using the equation rOT (ob t ) = − T (cid:88) t(cid:48)=1 Ct,t(cid:48) µ∗ t,t(cid:48) (7) Intuitively, maximizing this reward encourages the imitating agent to produce trajectories that closely match demonstrated trajectories. Since solving Eq. 5 is computationally expensive, approximate solutions such as the Sinkhorn algorithm [63, 12] are used instead. B Issue with Fine-tuning Actor-Critic Frameworks In this paper, we use n-step DDPG proposed by Yarats et al. [8] as our RL optimizer for actor- critic based reward maximization. DDPG [23] concurrently learns a deterministic policy πφ using deterministic policy gradients (DPG) [15] and a Q-function Qθ by minimizing a n-step Bellman residual (for n-step DDPG). For a parameterized actor network πφ(s) and a critic function Qθ(s, a), the deterministic policy gradients (DPG) for updating the actor weights is given by ∇φJ ≈ Est∼ρβ = Est∼ρβ (cid:104) (cid:104) ∇φ Qθ(s, a)|s=st,a=πφ(st) (cid:105) ∇a Qθ(s, a)|s=st,a=πφ(st) ∇φ πφ(s)|s=st (cid:105) (8) Here, ρβ refers to the state visitation distribution of the data present in the replay buffer at time t. From Eq. 8, it is clear that the policy gradients in this framework depend on the gradients with respect to the critic value. Hence, as mentioned in [9, 10], naively initializing the actor with a pretrained policy while using a randomly initialized critic results in the untrained critic providing an exceedingly poor signal to the actor network during training. As a result, the actor performance drops immediately and the good behavior of the informed initialization of the policy gets forgotten. In this paper, we propose an adaptive regularization scheme that permits ﬁnetuning a pretrained actor policy in an actor-critic framework. As opposed to Rajeswaran et al. [16], Jena et al. [17] which employ on-policy learning, our method is off-policy and aims to leverage the sample efﬁcient characteristic of off-policy learning as compared to on-policy learning [7]. C Algorithmic Details C.1 Implementation Algorithm 1 describes our proposed algorithm, Regularized Optimal Transport (ROT), for sample efﬁcient imitation learning for continuous control tasks. Further implementation details are as follows: Algorithm and training procedure Our model consists of 3 primary neural networks - the encoder, the actor and the critic. During the BC pretraining phase, the encoder and the actor are trained using a mean squared error (MSE) on the expert demonstrations. Next, for ﬁnetuning, weights of the pretrained encoder and actor are loaded from memory and the critic is initialized randomly. We observed that the performance of the algorithm is not very sensitive to the value of α and we set it to 0.03 for all experiments in this paper. A copy of the pretrained encoder and actor are stored with ﬁxed weights to be used for computing λ(π) for soft Q-ﬁltering. Actor-critic based reward maximization We use a recent n-step DDPG proposed by Yarats et al. [8] as our RL backbone. The deterministic actor is trained using deterministic policy gradients (DPG) [15] given by Eq. 8. The critic is trained using clipped double Q-learning similar to Yarats et al. [8] in order to reduce the overestimation bias in the target value. This is done using two Q-functions, Qθ1 and Qθ2. The critic loss for each critic is given by the equation Lθk = E(s,a)∼Dβ (cid:2)(Qθk (s, a) − y)2(cid:3) ∀ k ∈ {1, 2} (9) 14 Algorithm 1 ROT: Regularized Optimal Transport Require: Expert Demonstrations T e ≡ {(ot, at)T Pretrained policy πBC Replay buffer D, Training steps T , Episode Length L Task environment env Parametric networks for RL backbone (e.g., the encoder, policy and critic function for DrQ-v2) A discriminator D for adversarial baselines t=0}N n=0 Algorithm: πROT ← πBC for each timestep t = 1...T do if done then r1:L = rewarderOT (episode) Update episode with r1:L and add (ot, at, ot+1, rt) to D ot = env.reset(), done = False, episode = [ ] (cid:46) Initialize with pretrained policy (cid:46) OT-based reward computation end if at = πROT (ot) ot+1, done = env.step(at) episode.append([ot, at, ot+1]) Update backbone-speciﬁc networks and reward-speciﬁc networks using D end for where Dβ is the replay buffer for online rollouts and y is the target value for n-step DDPG given by y = n−1 (cid:88) i=0 γirt+i + γn min k=1,2 Q¯θk (st+n, at+n) (10) Here, γ is the discount factor, r is the reward obtained using OT-based reward computation and ¯θ1, ¯θ2 are the slow moving weights of target Q-networks. Target feature processor to stabilize OT rewards The OT rewards are computed on the output of the feature processor fφ which is initialized with a parametric neural network. Hence, as the weights of fφ change during training, the rewards become non-stationary resulting in unstable training. In order to increase the stability of training, the OT rewards are computed using a target feature processor fφ(cid:48) [11] which is updated with the weights of fφ every Tupdate environment steps. For state-based observations, fφ corresponds to a ’trunk’ network which is a single layer neural network. For pixel-based observations, fφ includes DrQ-v2’s encoder followed by the ’trunk’ network. C.2 Hyperparameters The complete list of hyperparameters is provided in Table 1. Similar to Yarats et al. [8], there is a slight deviation from the given setting for the Walker Stand/Walk/Run task from the DeepMind Control suite where we use a mini-batch size of 512 and a n-step return of 1. D Environments Table 2 lists the different tasks that we experiment with from the DeepMind Control suite [18, 25], OpenAI Robotics suite [26] and the Meta-world suite [27] along with the number of training steps and the number of demonstrations used. For the tasks in the OpenAI Robotics suite, we ﬁx the goal while keeping the initial state randomized. No modiﬁcations are made in case of the DeepMind Control suite and the Meta-world suite. The episode length for all tasks in DeepMind Control is 1000 steps, for OpenAI Robotics is 50 steps and Meta-world is 125 steps (except bin picking which runs for 175 steps). 15 Method Common Parameter Replay buffer size Learning rate Discount γ n-step returns Action repeat Seed frames Mini-batch size Agent update frequency Critic soft-update rate Feature dim Hidden dim Optimizer ROT Exploration steps DDPG exploration schedule Target feature processor update frequency(steps) Reward scale factor Fixed weight α Value 150000 1e−4 0.99 3 2 12000 256 2 0.01 50 1024 Adam 0 0.1 20000 10 0.03 Linear decay schedule for λ(π) linear(1,0.1,20000) OT Exploration steps 2000 DDPG exploration schedule linear(1,0.1,500000) DAC Target feature processor update frequency(steps) Reward scale factor Exploration steps DDPG exploration schedule Gradient penalty coefﬁcient Table 1: List of hyperparameters. 20000 10 2000 linear(1,0.1,500000) 10 E Demonstrations For DeepMind Control tasks, we train expert policies using pixel-based DrQ-v2 [8] and collect 10 demonstrations for each task using this expert policy. The expert policy is trained using a stack of 3 consecutive RGB frames of size 84 × 84 with random crop augmentation. Each action in the environment is repeated 2 times. For OpenAI Robotics tasks, we train a state-based DrQ-v2 with hindsight experience replay [28] and collect 50 demonstrations for each task. The state representation comprises the observation from the environment appended with the desired goal location. For this, we did not do frame stacking and action repeat was set to 2. For Meta-World tasks, we use a single expert demonstration obtained using the task-speciﬁc hard-coded policies provided in their open-source implementation [27]. 16 Suite Tasks DeepMind Control Acrobot Swingup Allowed Steps 2 × 106 # Demonstrations 10 Cartpole Swingup Cheetah Run Finger Spin Hopper Stand Hopper Hop Quadruped Run Walker Stand Walker Walk Walker Run OpenAI Robotics Fetch Reach 1.5 × 106 50 1 1 Fetch Push Fetch Pick and Place Meta-World Hammer 1 × 106 xArm Robot 6 × 103 Drawer Close Door Open Bin Picking Button Press Topdown Door Unlock. Close Door Hang Hanger Erase Board Reach Hang Mug Hang Bag Turn Knob Stack Cups Press Switch Peg (Easy) Peg (Medium) Peg (Hard) Open Box Pour Table 2: List of tasks used for evaluation. F Robot Tasks In this section, we describe the suite of manipulation experiments carried out on a real robot in this paper. 17 Figure 7: Examples of different initializations for the real robot tasks. 18 r o o D e s o l C r e g n a H g n a H d r a o B e s a r E h c a e R g u M g n a H g a B g n a H b o n K n r u T s p u C k c a t S h c t i w S s s e r P ) y s a E ( g e P ) d e M ( g e P ) d r a H ( g e P x o B n e p O r u o P Figure 8: Example trajectories for selected real robot tasks. (a) Door Close: Here, the robot arm is supposed to close an open door by pushing it to the target. (b) Hang Hanger: While holding a hanger between the grippers, the robot arm is initialized at random position and is tasked with putting the hanger at a goal region on a closet rod. (c) Erase Board: While holding a board duster between the grippers, the robot arm is tasks with erasing marking drawn on the board while getting initialized from random positions. (d) Reach: The robot arm is required to reach a speciﬁc goal after being initialized at a random position. (e) Hang Mug: While holding a mug between the grippers, the robot arm is initialized at random position and is tasked with hanging the mug on a speciﬁc hook. (f) Hang Bag: While holding a tote between the grippers, the robot arm is initialized at random position and is tasked with hanging the tote bag on a speciﬁc hook. (g) Turn Knob: The robot arm is tasked with rotating a knob placed on the table by a certain angle after being initialized at a random position. We consider a 90 degree rotation as success. (h) Cup Stack: While holding a cup between the gripper, the robot arm is required to stack it into another cup placed on the table. (i) Press Switch: With the gripper kept closed, the robot arm is required to press a switch (with an LED light) placed on the table. (j) Peg (Easy, Medium, Hard): The robot arm is supposed to insert a peg, hanging by a string, into a bucket placed on the table. This task has 3 variants - Easy, Medium, Hard - with the size of the bucket decreasing from Easy to Hard. (k) Box Open: In this task, the robot arm is supposed to open the lid of a box placed on the table by lifting a handle provided in the front of the box. (l) Pour: Given a cup with some item place inside (in our case, almonds), the robot arm is supposed to move towards a cup place on the table and pour the item into the cup. Evaluation procedure For each task, we obtained a set of 20 random initializations and evaluate all of the methods (BC, RDAC and ROT) over 20 trajectories from the same set of initializations. These initializations are different for each task based on the limits of the observation space for the task. G Baselines Throughout the paper, we compare ROT with several prominent imitation learning and reinforcement learning methods. Here, we give a brief description of each of the baseline models that have been used. (a) Expert: For each task, the expert refers to the expert policy used to generate the demonstrations for the task (described in Appendix E). 19 d r a o B e s a r E g a B g n a H b o n K n r u T ) d r a H ( g e P x o B n e p O (b) Behavior Cloning (BC): This refers to the behavior cloned policy trained on expert demonstra- tions. (c) Adversarial IRL (DAC): Discriminator Actor Critic [7] is a state-of-the-art adversarial imi- tation learning method [6, 29, 7]. Since DAC outperforms prior work such as GAIL[6] and AIRL[30], it serves as our primary adversarial imitation baseline. (d) State-matching IRL (OT): Sinkhorn Imitation Learning [12, 13] is a state-of-the-art state- matching imitation learning method [31] that approximates OT matching through the Sinkhorn Knopp algorithm. Since ROT is derived from similar OT-based foundations, we use SIL as our primary state-matching imitation baseline. (e) RDAC: This is the same as ROT, but instead of using state-matching IRL (OT), adversarial IRL (DAC) is used. (f) Finetune with ﬁxed weight: This is similar to ROT where instead of using a time-varying adaptive weight λ(i), only the ﬁxed weight λ0 is used. λ0 is set to a ﬁxed value of 0.03. (g) Finetune with ﬁxed schedule: This is similar to ROT that uses both the ﬁxed weight λ0 and the time-varying adaptive weight λ1(i). However, instead of using Soft Q-ﬁltering to compute λ1(i), a hand-coded linear decay schedule is used. (h) DrQ-v2 (RL): DrQ-v2 [8] is a state-of-the-art algorithm for pixel-based RL. DrQ-v2 is assumed to have access to environment rewards as opposed to ROT which computes the reward using OT-based techniques. (i) Demo-DrQ-v2: This refers to DrQ-v2 but with access to both environment rewards and expert demonstrations. The model is initialized with a pretrained BC policy followed by RL ﬁnetuning with an adaptive regularization scheme like ROT. During RL ﬁnetuning, this baseline has access to environment rewards. (j) BC+OT: This is the same as the OT baseline but the policy is initialized with a pretrained BC policy. No adaptive regularization scheme is used while ﬁnetuning the pretrained policy. (k) OT+BC Reg.: This is the same as the OT baseline with randomly initialized networks but during training, the adaptive regularization scheme is added to the objective function. H Additional Experimental Results H.1 How efﬁcient is ROT for imitation learning? In addition to the results provided in Sec. 5.1, Fig. 9 and Fig. 10 shows the performance of ROT for pixel-based imitation on 10 tasks from the DeepMind Control suite, 3 tasks from the OpenAI Robotics suite and 7 tasks from the Meta-world suite. On all but one task, ROT is signiﬁcantly more sample efﬁcient than prior work. Finally, the improvements from ROT hold on state-based observations as well(see Fig. 11). Table 3 provides a comparison between the factor of speedup of ROT to reach 90% of expert performance compared to prior state-of-the-art [7, 11] methods. H.2 Does soft Q-ﬁltering improve imitation? Extending the results shown in Fig. 5, we provide training curves from representative tasks in each suite in Fig. 12. We observe that our adaptive soft-Q ﬁltering regularization is more stable compared to prior hand-tuned regularization schemes. ROT is on par and in some cases exceeds the efﬁciency of a hand-tuned decay schedule, while not having to hand-tune its regularization weights. H.3 How does ROT compare to standard reward-based RL? Extending the results shown in Fig. 6, we provide training curves from representative tasks in each suite in Fig. 13, thus showing that ROT can outperform standard RL that requires explicit task- reward. We also show that this RL method combined with our regularization scheme (represented by Demo-DrQ-v2 in Fig. 13 provides strong results. 20 Expert BC OT DAC ROT (Ours) Figure 9: Pixel-based continuous control learning on 10 DMC environments. Shaded region represents ±1 standard deviation across 5 seeds. We notice that ROT is signiﬁcantly more sample efﬁcient compared to prior work. H.4 How important are the design choices in ROT? Importance of pretraining and regularizing the IRL policy Fig. 14 compares the following variants of ROT on set of pixel-based tasks: (a) Training the IRL policy from scratch (OT); (b) Finetuning a pretrained BC policy without BC regularization (BC+OT); (c) Training the IRL policy from scratch with BC regularization (OT+BC Reg.). We observe that pretraining the IRL policy (BC+OT) does not provide a signiﬁcant difference without regularization. This can be attributed to the ‘forgetting behavior’ of pre-trained policies, studied in Nair et al. [9]. Interestingly, we see that even without BC pretraining, keeping the policy close to a behavior distribution (OT+BC Reg.) can yield improvements in efﬁciency over vanilla training from scratch. Our key takeaway from these experiments is that both pretraining and BC regularization are required to obtain sample-efﬁcient imitation learning. Choice of IRL method In ROT, we build on OT-based IRL instead of adversarial IRL. This is because adversarial IRL methods require iterative reward learning, which produces a highly non- stationary reward function for policy optimization. In Fig. 15, we compare ROT with adversarial 21 400 300 200 100 d r a w e r _ e d o s i p e 0 d r a w e r _ e d o s i p e 1000 800 600 400 200 0 d r a w e r _ e d o s i p e 1000 800 600 400 200 dmc_acrobot_swingup dmc_cartpole_swingup dmc_finger_spin d r a w e r _ e d o s i p e 1000 800 600 400 200 0 d r a w e r _ e d o s i p e 1200 1000 800 600 400 200 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 dmc_cheetah_run dmc_hopper_stand dmc_hopper_hop d r a w e r _ e d o s i p e 1000 800 600 400 200 0 200 300 200 100 d r a w e r _ e d o s i p e 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 dmc_walker_stand dmc_walker_walk dmc_walker_run d r a w e r _ e d o s i p e 1000 800 600 400 200 0 800 600 400 200 d r a w e r _ e d o s i p e 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 dmc_quadruped_run 600 400 200 d r a w e r _ e d o s i p e 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 Expert BC OT DAC ROT (Ours) Figure 10: Pixel-based continuous control learning on 3 OpenAI Gym Robotics and 7 Meta-World tasks. Shaded region represents ±1 standard deviation across 5 seeds. We notice that ROT is signiﬁcantly more sample efﬁcient compared to prior work. IRL methods that use our pretraining and adaptive BC regularization technique (RDAC). We ﬁnd that our soft Q-ﬁltering method does improve prior state-of-the-art adversarial IRL (RDAC vs. DAC in Fig. 15). However, our OT-based approach (ROT) is more stable and on average leads to more efﬁcient learning. 22 e g a t n e c r e p _ s s e c c u s e g a t n e c r e p _ s s e c c u s e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 1.25 1.00 0.75 0.50 0.25 0.00 0.25 1.00 0.75 0.50 0.25 0.00 0.25 fetch_reach fetch_push fetch_pick_and_place e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame metaworld_hammer metaworld_drawer_close metaworld_drawer_open e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 0.2 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 metaworld_door_open metaworld_bin_picking e g a t n e c r e p _ s s e c c u s 1.00 0.75 0.50 0.25 0.00 0.25 e g a t n e c r e p _ s s e c c u s e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 0.2 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 metaworld_button_press_topdown 1.0 0.8 0.6 0.4 0.2 0.0 0.2 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 metaworld_door_unlock e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 Expert BC OT DAC ROT (Ours) Figure 11: State-based continuous control learning on DMC and Meta-World tasks. We notice that ROT is signiﬁcantly more sample efﬁcient compared to prior work. 23 d r a w e r _ e d o s i p e 500 400 300 200 100 0 d r a w e r _ e d o s i p e 1000 800 600 400 200 0 200 d r a w e r _ e d o s i p e 1000 800 600 400 200 0 e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 dmc_acrobot_swingup dmc_cartpole_swingup dmc_finger_spin d r a w e r _ e d o s i p e 1000 800 600 400 200 0 d r a w e r _ e d o s i p e 1000 800 600 400 200 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 dmc_hopper_stand dmc_hopper_hop 300 200 100 d r a w e r _ e d o s i p e 0 dmc_walker_stand d r a w e r _ e d o s i p e 1200 1000 800 600 400 200 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 dmc_walker_walk dmc_walker_run dmc_quadruped_run d r a w e r _ e d o s i p e 800 600 400 200 0 600 400 200 d r a w e r _ e d o s i p e 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 metaworld_hammer metaworld_drawer_close metaworld_door_open e g a t n e c r e p _ s s e c c u s 1.00 0.75 0.50 0.25 0.00 e g a t n e c r e p _ s s e c c u s 1.00 0.75 0.50 0.25 0.00 0.25 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 metaworld_drawer_open metaworld_button_press_topdown metaworld_door_unlock e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 Suite Tasks ROT 2nd Best Model Speedup Factor DeepMind Control Acrobot Swingup Cartpole Swingup Finger Spin Cheetah Run Hopper Stand Hopper Hop Walker Stand Walker Walk Walker Run Quadruped Run OpenAI Robotics Fetch Reach 200k 100k 20k 400k 60k. 200k 80k 200k 320k 400k 300k 600k (OT) 350k (OT) 700k (OT) 2M (DAC) 750k (OT) >2M (DAC) 400k (DAC) 750k (DAC) >2M (OT) >2M (DAC) 1.1M (DAC) Fetch Push 1.1M 600k (DAC) Fetch Pick and Place Meta-World Hammer Drawer Close Drawer Open Door Open Bin Picking 750k 200k 20k >1M 400k 700k >1.5M (OT) >1M (DAC) >1M (OT) >1M (OT) >1M (OT) >1M (OT) Button Press Topdown >1M >1M (OT) Door Unlock 1M >1M (OT) 3 3.5 35 5 12.5 10 5 3.75 6.25 5 3.67 0.54 2 5 50 1 2.5 1.43 1 1 Table 3: Task-wise comparison between environment steps required to reach 90% of expert perfor- mance for pixel-based ROT compared to the strongest baseline for each task. 24 Expert BC Finetune with ﬁxed weight Finetune with ﬁxed schedule ROT (Ours) Figure 12: Pixel-based ablation analysis on the effect of varying BC regularization schemes. We observe that our adaptive soft-Q ﬁltering regularization is more stable compared to prior hand-tuned regularization schemes. 25 d r a w e r _ e d o s p e i 800 600 400 200 0 e g a t n e c r e p _ s s e c c u s 1.2 1.0 0.8 0.6 0.4 0.2 0.0 e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 dmc_cheetah_run dmc_hopper_hop dmc_quadruped_run 300 200 100 d r a w e r _ e d o s p e i 0 d r a w e r _ e d o s p e i 600 500 400 300 200 100 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 fetch_reach fetch_push fetch_pick_and_place e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 0.00 0.25 0.50 0.75 frame 1.00 1.25 1.50 1e6 0.00 0.25 0.50 0.75 frame 1.00 1.25 1.50 1e6 0.00 0.25 0.50 0.75 frame 1.00 1.25 1.50 1e6 metaworld_door_open metaworld_hammer metaworld_drawer_close e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 Expert BC OT DrQ-v2(RL) Demo-DrQ-v2 ROT (Ours) Figure 13: Pixel-based ablation analysis on the performance comparison of ROT against DrQ-v2, a reward-based RL method. Here we see that ROT can outperform plain RL that requires explicit task-reward. However, we also observe that this RL method combined with our regularization scheme provides strong results. 26 d r a w e r _ e d o s i p e 1000 800 600 400 200 0 e g a t n e c r e p _ s s e c c u s e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 1.25 1.00 0.75 0.50 0.25 0.00 0.25 dmc_finger_spin dmc_cheetah_run dmc_walker_run d r a w e r _ e d o s i p e 1000 800 600 400 200 0 d r a w e r _ e d o s i p e 1000 800 600 400 200 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 fetch_reach fetch_push fetch_pick_and_place 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame metaworld_door_open e g a t n e c r e p _ s s e c c u s e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 1.25 1.00 0.75 0.50 0.25 0.00 0.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame metaworld_bin_picking e g a t n e c r e p _ s s e c c u s e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 1.00 0.75 0.50 0.25 0.00 0.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame metaworld_hammer 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 BC OT BC+OT OT+BC Reg. ROT (Ours) Figure 14: Pixel-based ablation analysis on the importance of pretraining and regularizing the IRL policy. The key takeaway from these experiments is that both pretraining and BC regularization are required to obtain sample-efﬁcient imitation learning. 27 1200 1000 800 600 400 200 0 d r a w e r _ e d o s i p e e g a t n e c r e p _ s s e c c u s e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 1.00 0.75 0.50 0.25 0.00 0.25 dmc_finger_spin dmc_cheetah_run dmc_walker_run 800 600 400 200 d r a w e r _ e d o s i p e 0 800 d r a w e r _ e d o s i p e 600 400 200 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 fetch_reach fetch_push fetch_pick_and_place e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame metaworld_door_open metaworld_hammer e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 e g a t n e c r e p _ s s e c c u s e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame metaworld_button_press_topdown 1.25 1.00 0.75 0.50 0.25 0.00 0.25 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 Expert BC DAC OT RDAC ROT (Ours) Figure 15: Pixel-based ablation analysis on the choice of base IRL method. We ﬁnd that although adversarial methods beneﬁt from regularized BC, the gains seen are smaller compared to ROT. 28 d r a w e r _ e d o s i p e 1250 1000 750 500 250 0 250 e g a t n e c r e p _ s s e c c u s e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 1.00 0.75 0.50 0.25 0.00 0.25 dmc_finger_spin dmc_cheetah_run d r a w e r _ e d o s i p e 1000 800 600 400 200 0 dmc_walker_run 1000 d r a w e r _ e d o s i p e 800 600 400 200 0 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 0.0 0.5 1.0 frame 1.5 2.0 1e6 fetch_reach 1.2 1.0 0.8 0.6 0.4 0.2 0.0 e g a t n e c r e p _ s s e c c u s fetch_push fetch_pick_and_place e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1e6 frame metaworld_door_open metaworld_hammer metaworld_button_press_topdown e g a t n e c r e p _ s s e c c u s 1.25 1.00 0.75 0.50 0.25 0.00 0.25 e g a t n e c r e p _ s s e c c u s 1.0 0.8 0.6 0.4 0.2 0.0 0.2 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6 0.0 0.2 0.4 0.6 0.8 frame 1.0 1e6","['watch', 'match', 'supercharging', 'imitation', 'regularize', 'optimal', 'transport', 'siddhant', 'haldar1', 'rotrobotgithubio', 'abstract', 'imitation', 'learning', 'hold', 'tremendous', 'promise', 'learn', 'policy', 'efﬁciently', 'complex', 'decision', 'make', 'problem', 'current', 'stateoftheart', 'algorithm', 'often', 'use', 'inverse', 'reinforcement', 'learn', 'irl', 'give', 'set', 'expert', 'demonstration', 'agent', 'alternatively', 'infer', 'reward', 'function', 'associated', 'optimal', 'policy', 'however', 'irl', 'approach', 'often', 'require', 'substantial', 'online', 'interaction', 'complex', 'control', 'problem', 'work', 'present', 'regularize', 'optimal', 'transport', 'rot', 'new', 'imitation', 'learn', 'build', 'recent', 'advance', 'optimal', 'transport', 'base', 'trajectorymatche', 'key', 'technical', 'insight', 'adaptively', 'combine', 'trajectorymatching', 'reward', 'behavior', 'cloning', 'signiﬁcantly', 'accelerate', 'imitation', 'even', 'demonstration', 'experiment', 'visual', 'control', 'task', 'deepmind', 'control', 'suite', 'openai', 'robotic', 'suite', 'metaworld', 'benchmark', 'demonstrate', 'average', 'fast', 'imitation', 'reach', 'expert', 'performance', 'compare', 'prior', 'stateoftheart', 'method', 'robotic', 'manipulation', 'demonstration', 'hour', 'online', 'training', 'rot', 'achieve', 'average', 'success', 'rate', 'task', 'keyword', 'imitation', 'learn', 'manipulation', 'robotic', 'r', 'figure', 'top', 'regularize', 'optimal', 'transport', 'rot', 'new', 'imitation', 'learn', 'adaptively', 'combine', 'ofﬂine', 'behavior', 'clone', 'online', 'trajectorymatching', 'base', 'reward', 'enable', 'signiﬁcantly', 'fast', 'imitation', 'variety', 'simulated', 'real', 'robotic', 'task', 'compatible', 'highdimensional', 'visual', 'observation', 'bottom', 'rot', 'learn', 'visual', 'policy', 'single', 'human', 'demonstration', 'hour', 'online', 'training', 'sh6474nyuedu', 'open', 'box', 'hang', 'tote', 'bag', 'place', 'peg', 'box', 'pour', 'almond', 'n', 'e', 'r', 'e', 'p', 'e', 'πbc', 'πrot', 'reward', 'ot', 'computation', 'environment', 'environment', 'interaction', 'introduction', 'imitation', 'learn', 'rich', 'history', 'categorize', 'broad', 'paradigms', 'behavior', 'clone', 'inverse', 'reinforcement', 'learn', 'irl', 'use', 'supervised', 'learning', 'obtain', 'policy', 'maximize', 'likelihood', 'take', 'demonstrate', 'action', 'give', 'observation', 'demonstration', 'allow', 'training', 'online', 'interaction', 'suffer', 'distributional', 'mismatch', 'online', 'rollout', 'irl', 'hand', 'infer', 'underlying', 'reward', 'function', 'demonstrate', 'trajectory', 'employ', 'optimize', 'policy', 'online', 'environment', 'rollout', 'result', 'policy', 'robustly', 'solve', 'demonstrate', 'task', 'even', 'absence', 'taskspeciﬁc', 'reward', 'powerful', 'irl', 'method', 'suffer', 'signiﬁcant', 'drawback', 'require', 'numerous', 'expensive', 'online', 'interaction', 'environment', 'reason', 'infer', 'reward', 'function', 'often', 'highly', 'nonstationary', 'compromise', 'learning', 'associated', 'behavior', 'policy', 'b', 'even', 'reward', 'stationary', 'policy', 'learning', 'still', 'require', 'effective', 'exploration', 'maximize', 'reward', 'strong', 'prior', 'pretraine', 'apply', 'accelerate', 'policy', 'learning', 'ensue', 'update', 'policy', 'cause', 'distribution', 'shift', 'destabilize', 'train', 'combine', 'issue', 'manifest', 'empirical', 'benchmark', 'irl', 'method', 'poor', 'efﬁciency', 'compare', 'vanilla', 'method', 'hard', 'control', 'task', 'work', 'present', 'regularize', 'optimal', 'transport', 'rot', 'imitation', 'learn', 'new', 'method', 'conceptually', 'simple', 'compatible', 'highdimensional', 'observation', 'require', 'minimal', 'additional', 'hyperparameter', 'compare', 'standard', 'irl', 'approach', 'order', 'address', 'challenge', 'reward', 'nonstationarity', 'irl', 'build', 'recent', 'advance', 'use', 'optimal', 'transport', 'ot', 'reward', 'computation', 'use', 'nonparametric', 'trajectorymatche', 'function', 'alleviate', 'challenge', 'exploration', 'pretrain', 'irl', 'behavior', 'policy', 'use', 'expert', 'demonstration', 'reduce', 'need', 'imitation', 'agent', 'explore', 'scratch', 'however', 'even', 'otbase', 'reward', 'computation', 'pretraine', 'policy', 'obtain', 'marginal', 'gain', 'empirical', 'performance', 'reason', 'highvariance', 'irl', 'policy', 'gradi', 'ent', 'often', 'wipe', 'away', 'progress', 'make', 'ofﬂine', 'bc', 'pretraine', 'phenomenon', 'observe', 'online', 'ofﬂine', 'method', 'inspire', 'solution', 'present', 'work', 'stabilize', 'online', 'learning', 'process', 'regularize', 'irl', 'policy', 'stay', 'close', 'pretraine', 'policy', 'enable', 'develop', 'new', 'adaptive', 'weighing', 'scheme', 'call', 'soft', 'qﬁltering', 'automatically', 'set', 'regularization', 'prioritize', 'stay', 'close', 'policy', 'beginning', 'training', 'prioritizing', 'exploration', 'later', 'contrast', 'prior', 'policy', 'regularization', 'scheme', 'soft', 'qﬁltering', 'require', 'handspeciﬁcation', 'decay', 'schedule', 'demonstrate', 'effectiveness', 'rot', 'run', 'extensive', 'experiment', 'simulated', 'task', 'dm', 'control', 'openai', 'robotic', 'metaworld', 'robotic', 'manipulation', 'task', 'see', 'fig', 'main', 'ﬁnding', 'summarize', 'rot', 'outperform', 'prior', 'stateoftheart', 'imitation', 'method', 'reach', 'expert', 'performance', 'fast', 'strong', 'baseline', 'simulated', 'visual', 'control', 'benchmark', 'realworld', 'task', 'single', 'human', 'demonstration', 'hour', 'training', 'rot', 'achieve', 'average', 'success', 'rate', 'randomize', 'robot', 'initialization', 'image', 'observation', 'signiﬁcantly', 'high', 'behavior', 'clone', 'adversarial', 'irl', 'rot', 'exceed', 'performance', 'stateoftheart', 'train', 'reward', 'come', 'close', 'method', 'augment', 'demonstration', 'section', 'appendix', 'standard', 'method', 'rot', 'require', 'handspeciﬁcation', 'reward', 'function', 'ablation', 'study', 'demonstrate', 'importance', 'component', 'rot', 'particularly', 'role', 'soft', 'qﬁltering', 'play', 'stabilize', 'training', 'need', 'otbase', 'reward', 'online', 'learning', 'section', 'opensource', 'code', 'demonstration', 'datum', 'publicly', 'release', 'project', 'website', 'video', 'train', 'policy', 'see', 'rotrobotgithubio', 'figure', 'give', 'single', 'demonstration', 'avoid', 'grey', 'obstacle', 'reach', 'goal', 'location', 'unable', 'solve', 'task', 'finetune', 'policy', 'otbase', 'reward', 'also', 'fail', 'solve', 'task', 'rot', 'adaptive', 'regularization', 'otbased', 'irl', 'successfully', 'solve', 'task', 'even', 'rot', 'agent', 'initialize', 'randomly', 'able', 'solve', 'task', 'background', 'describe', 'method', 'detail', 'provide', 'brief', 'background', 'imitation', 'learn', 'optimal', 'transport', 'serve', 'backbone', 'method', 'formalism', 'relate', 'follow', 'convention', 'prior', 'work', 'describe', 't1n', 'imitation', 'learn', 'optimal', 'transport', 'goal', 'imitation', 'learning', 'learn', 'behavior', 'policy', 'πb', 'give', 'access', 'expert', 'policy', 'πe', 'trajectory', 'derive', 'expert', 'policy', 'e', 'multitude', 'setting', 'differ', 'level', 'access', 'expert', 'work', 'operate', 'setting', 'agent', 'access', 'observationbased', 'trajectory', 'e', 'n1', 'denote', 'number', 'trajectory', 'rollout', 'episode', 'timestep', 'respectively', 'inverse', 'reinforcement', 'learn', 'irl', 'tackle', 'problem', 'infer', 'reward', 'function', 'base', 'expert', 'trajectory', 'give', 'infer', 'reward', 'policy', 'optimization', 'use', 'derive', 'behavior', 'policy', 'πb', 'compute', 'new', 'line', 'otbase', 'approach', 'propose', 'intuitively', 'closeness', 'expert', 'trajectory', 'e', 'behavior', 'trajectory', 'b', 'compute', 'measure', 'optimal', 'transport', 'probability', 'mass', 'e', 'thus', 'give', 'cost', 'matrix', 'cttcid48', 'cob', 'tcid48', 'optimal', 'alignment', 'behavior', 'trajectory', 'expert', 'trajectory', 'oe', 'reward', 'signal', 'observation', 'compute', 'use', 'equation', 'oe', 'rot', '−', 'cttcid48', 'µ∗', 'ttcid48', 'detailed', 'account', 'formulation', 'provide', 'actorcritic', 'base', 'reward', 'maximization', 'give', 'reward', 'obtain', 'computation', 'efﬁ', 'cient', 'maximization', 'reward', 'achieve', 'offpolicy', 'learning', 'work', 'use', 'deep', 'deterministic', 'policy', 'gradient', 'ddpg', 'base', 'optimizer', 'actorcritic', 'algorithm', 'concurrently', 'learn', 'deterministic', 'policy', 'πφ', 'qfunction', 'qθ', 'however', 'instead', 'minimize', 'step', 'bellman', 'residual', 'vanilla', 'ddpg', 'use', 'recent', 'nstep', 'version', 'ddpg', 'yarat', 'achieve', 'high', 'performance', 'visual', 'control', 'problem', 'challenge', 'online', 'finetuning', 'pretraine', 'policy', 'section', 'study', 'challenge', 'ﬁnetune', 'pretraine', 'policy', 'online', 'interaction', 'environment', 'fig', 'illustrate', 'task', 'agent', 'suppose', 'navigate', 'environment', 'top', 'leave', 'bottom', 'dodge', 'obstacle', 'agent', 'access', 'single', 'expert', 'demonstration', 'use', 'learn', 'policy', 'task', 'fig', 'show', 'policy', 'though', 'close', 'expert', 'demonstration', 'perform', 'suboptimally', 'due', 'accumulate', 'error', 'outofdistribution', 'state', 'online', 'rollout', 'furth', 'fig', 'b', 'use', 'policy', 'expert', 'trajectory', 'start', 'location', 'goal', 'location', 'task', 'particle', 'reach', 'irl', 'finetune', 'reg', 'rot', 'rot', 'random', 'init', 'p', 'e', 'e', 'expert', 'trajectory', 'start', 'location', 'goal', 'location', 'initialization', 'naively', 'ﬁnetune', 'ot', 'reward', 'describe', 'section', 'naive', 'ﬁnetuning', 'pretraine', 'policy', 'actor', 'untrained', 'critic', 'actorcritic', 'framework', 'exhibit', 'forget', 'behavior', 'actor', 'result', 'performance', 'degradation', 'compare', 'pretraine', 'policy', 'phenomenon', 'also', 'report', 'provide', 'detailed', 'discussion', 'b', 'paper', 'propose', 'rot', 'address', 'issue', 'adaptively', 'keep', 'policy', 'close', 'behavior', 'datum', 'initial', 'phase', 'ﬁnetune', 'reduce', 'dependence', 'time', 'fig', 'c', 'demonstrate', 'performance', 'approach', 'ﬁnetuning', 'clearly', 'see', 'even', 'policy', 'suboptimal', 'propose', 'adaptive', 'regularization', 'scheme', 'quickly', 'improve', 'solve', 'task', 'drive', 'close', 'expert', 'demonstration', 'fig', 'demonstrate', 'even', 'agent', 'initialize', 'point', 'expert', 'trajectory', 'agent', 'still', 'able', 'learn', 'quickly', 'complete', 'task', 'generalization', 'start', 'state', 'possible', 'regular', 'regularize', 'optimal', 'transport', 'fundamental', 'challenge', 'imitation', 'learning', 'balance', 'ability', 'mimic', 'demonstrate', 'action', 'ability', 'recover', 'state', 'distribution', 'demonstrate', 'state', 'behavior', 'clone', 'specialize', 'mimic', 'demonstrate', 'action', 'supervised', 'learning', 'inverse', 'reinforcement', 'learn', 'irl', 'specialize', 'obtain', 'policy', 'recover', 'arbitrary', 'state', 'regularize', 'optimal', 'transport', 'rot', 'combine', 'good', 'world', 'adaptively', 'combine', 'objective', 'phase', 'ﬁrst', 'phase', 'randomly', 'initialize', 'policy', 'train', 'use', 'objective', 'expert', 'demonstrate', 'datum', 'bcpretraine', 'policy', 'serve', 'initialization', 'second', 'phase', 'second', 'phase', 'policy', 'allow', 'access', 'environment', 'train', 'use', 'irl', 'objective', 'accelerate', 'irl', 'training', 'loss', 'add', 'objective', 'adaptive', 'weight', 'detail', 'component', 'describe', 'additional', 'algorithmic', 'detail', 'phase', 'bc', 'pretraine', 'correspond', 'solve', 'maximum', 'likelihood', 'problem', 'show', 'eq', 'e', 'refer', 'expert', 'demonstration', 'parameterize', 'normal', 'distribution', 'ﬁxed', 'variance', 'objective', 'frame', 'regression', 'problem', 'give', 'input', 'πbc', 'need', 'output', 'train', 'enable', 'πbc', 'mimic', 'action', 'correspond', 'observation', 'see', 'demonstration', 'however', 'rollout', 'environment', 'small', 'error', 'action', 'prediction', 'lead', 'agent', 'visit', 'state', 'see', 'demonstration', 'distributional', 'mismatch', 'often', 'cause', 'πbc', 'fail', 'empirical', 'benchmark', 'see', 'fig', 'phase', 'online', 'finetune', 'irl', 'give', 'pretraine', 'πbc', 'model', 'begin', 'online', 'ﬁnetune', 'policy', 'πb', '≡', 'πrot', 'environment', 'operate', 'explicit', 'task', 'reward', 'use', 'reward', 'obtain', 'otbased', 'trajectory', 'matching', 'describe', 'section', 'otbase', 'reward', 'enable', 'use', 'standard', 'optimizer', 'maximize', 'cumulative', 'reward', 'πb', '≡', 'work', 'use', 'nstep', 'ddpg', 'deterministic', 'actorcritic', 'base', 'method', 'provide', 'highperformance', 'continuous', 'control', 'finetune', 'regularization', 'πbc', 'susceptible', 'distribution', 'shift', 'accumulation', 'error', 'online', 'rollout', 'directly', 'ﬁnetune', 'πbc', 'also', 'lead', 'performance', 'refer', 'fig', 'address', 'build', 'prior', 'work', 'guide', 'ofﬂine', 'regularize', 'training', 'πrot', 'combine', 'loss', 'see', 'eq', 'argmax', 'π', '−', 'λπesa∼dβ', 'represent', 'qvalue', 'critic', 'use', 'actorcritic', 'policy', 'optimization', 'ﬁxed', 'weight', 'policydependent', 'adaptive', 'weight', 'control', 'contribution', 'loss', 'term', 'dβ', 'refer', 'replay', 'buffer', 'online', 'rollout', 'regularization', 'soft', 'qﬁltering', 'prior', 'work', 'use', 'handtune', 'sche', 'ule', 'propose', 'new', 'adaptive', 'scheme', 'remove', 'need', 'tune', 'compare', 'performance', 'current', 'policy', 'πrot', 'pretraine', 'policy', 'πbc', 'batch', 'datum', 'sample', 'expert', 'replay', 'buffer', 'precisely', 'give', 'behavior', 'policy', 'πbcs', 'current', 'policy', 'πrot', 'qfunction', 'qs', 'replay', 'buffer', 'set', 'λπrot', 'strength', 'hence', 'depend', 'performance', 'current', 'policy', 'respect', 'behavior', 'policy', 'ﬁltere', 'strategy', 'inspire', 'instead', 'binary', 'hard', 'assignment', 'use', 'soft', 'continuous', 'weight', 'experimental', 'comparison', 'handtuned', 'decay', 'strategy', 'present', 'section', 'cid21qsπbc', 'cid3', 'consideration', 'imagebase', 'observation', 'interested', 'use', 'rot', 'high', 'dimensional', 'visual', 'observation', 'additional', 'machinery', 'require', 'ensure', 'compatibility', 'follow', 'prior', 'work', 'imagebase', 'rl', 'imitation', 'perform', 'datum', 'augmentation', 'visual', 'observation', 'feed', 'cnn', 'encoder', 'similar', 'cohen', 'use', 'target', 'encoder', 'averaging', 'obtain', 'representation', 'computation', 'necessary', 'reduce', 'nonstationarity', 'cause', 'learn', 'encoder', 'rot', 'imitation', 'process', 'implementation', 'detail', 'training', 'procedure', 'find', 'experiment', 'experiment', 'design', 'answer', 'follow', 'question', 'efﬁcient', 'rot', 'imitation', 'learn', 'b', 'rot', 'perform', 'realworld', 'task', 'c', 'important', 'choice', 'irl', 'method', 'soft', 'qﬁltering', 'improve', 'imitation', 'e', 'compare', 'standard', 'rewardbase', 'additional', 'result', 'analysis', 'provide', 'h', 'simulated', 'task', 'experiment', 'task', 'deepmind', 'control', 'task', 'openai', 'robotic', 'suite', 'task', 'metaworld', 'suite', 'deepmind', 'control', 'task', 'train', 'expert', 'policy', 'use', 'drqv2', 'collect', 'demonstration', 'task', 'use', 'policy', 'openai', 'robotic', 'task', 'train', 'statebase', 'drqv2', 'hindsight', 'experience', 'replay', 'collect', 'demonstration', 'task', 'metaworld', 'task', 'use', 'single', 'hardcoded', 'expert', 'demonstration', 'opensource', 'implementation', 'full', 'environment', 'detail', 'find', 'appendix', 'detail', 'variation', 'demonstration', 'initialization', 'condition', 'find', 'appendix', 'e', 'robot', 'task', 'real', 'world', 'setup', 'manipulation', 'task', 'see', 'fig', 'use', 'ufactory', 'xarm', 'robot', 'xarm', 'gripper', 'robot', 'platform', 'real', 'world', 'experiment', 'however', 'method', 'agnostic', 'speciﬁc', 'robot', 'hardware', 'observation', 'rgb', 'image', 'ﬁxed', 'camera', 'setup', 'use', 'single', 'expert', 'demonstration', 'collect', 'human', 'operator', 'joystick', 'limit', 'online', 'training', 'ﬁxed', 'period', 'hour', 'description', 'task', 'evaluation', 'procedure', 'primary', 'baseline', 'compare', 'rot', 'baseline', 'several', 'prominent', 'imitation', 'learning', 'method', 'full', 'description', 'baseline', 'appendix', 'brief', 'description', 'strong', 'one', 'follow', 'adversarial', 'irl', 'actor', 'critic', 'stateoftheart', 'adversarial', 'imitation', 'learning', 'method', 'dac', 'outperform', 'prior', 'work', 'airl', 'thus', 'serve', 'primary', 'adversarial', 'imitation', 'baseline', 'trajectorymatche', 'irl', 'sinkhorn', 'imitation', 'learn', 'stateoftheart', 'trajectorymatching', 'imitation', 'learning', 'method', 'approximate', 'match', 'sinkhorn', 'rot', 'derive', 'similar', 'otbased', 'foundation', 'use', 'sil', 'primary', 'statematche', 'imitation', 'baseline', 'expert', 'rot', 'figure', 'pixelbase', 'continuous', 'control', 'learning', 'select', 'environment', 'shade', 'region', 'represent', '±1', 'standard', 'deviation', 'seed', 'notice', 'rot', 'signiﬁcantly', 'sample', 'efﬁcient', 'compare', 'prior', 'work', 'efﬁcient', 'rot', 'imitation', 'learning', 'performance', 'rot', 'imagebase', 'imitation', 'depict', 'select', 'environment', 'fig', 'task', 'rot', 'train', 'signiﬁcantly', 'fast', 'prior', 'work', 'reach', 'expert', 'performance', 'rot', 'average', '87×', 'fast', 'deepmind', 'control', 'task', 'fast', 'openai', 'robotic', 'task', '89×', 'fast', 'metaworld', 'task', 'also', 'improvement', 'rot', 'apparent', 'hard', 'task', 'rightmost', 'column', 'fig', 'h1', 'show', 'result', 'simulated', 'task', 'experiment', 'exhibit', 'similar', 'improvement', 'statebase', 'setting', 'rot', 'perform', 'realworld', 'task', 'devise', 'set', 'manipulation', 'task', 'robot', 'compare', 'performance', 'rot', 'strong', 'baseline', 'rdac', 'adversarial', 'irl', 'method', 'combine', 'pretraining', 'regularization', 'scheme', 'policy', 'train', 'use', 'supervised', 'learning', 'single', 'expert', 'demonstration', 'collect', 'human', 'operator', 'rot', 'ﬁnetune', 'pretraine', 'policy', 'hour', 'online', 'training', 'amount', '∼', 'environment', 'step', 'demonstration', 'task', 'design', 'random', 'initialization', 'ﬁxed', 'goal', 'note', 'single', 'demonstration', 'demonstrate', 'solve', 'task', 'initial', 'condition', 'evaluation', 'result', 'different', 'initial', 'condition', 'see', 'fig', 'observe', 'rot', 'average', 'success', 'rate', 'evaluation', 'trajectory', 'task', 'compare', 'poor', 'performance', 'attribute', 'distributional', 'mismatch', 'accumulation', 'error', 'online', 'rollout', 'different', 'initial', 'condition', 'poor', 'performance', 'rdac', 'attribute', 'slow', 'learning', 'initial', 'phase', 'training', 'detailed', 'evaluation', 'rdac', 'simulated', 'environment', 'present', 'r', 'w', 'e', 'r', 'p', 'e', 'e', 'r', 'e', 'c', 'e', 'r', 'e', 'c', 'dmccheetahrun', 'dmchopperhop', 'dmcwalkerrun', 'r', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'fetchreach', 'fetchpush', 'fetchpickandplace', 'e', 'r', 'e', 'c', 'e', 'r', 'e', 'c', 'frame', 'frame', 'frame', 'metaworlddrawerclose', 'metaworldhammer', 'metaworlddooropen', 'e', 'r', 'e', 'c', 'e', 'r', 'e', 'c', 'frame', '1e6', 'frame', '1e6', 'frame', 'figure', 'top', 'rot', 'evaluate', 'set', 'robotic', 'manipulation', 'task', 'bottom', 'success', 'rate', 'task', 'compute', 'run', 'trajectory', 'vary', 'initial', 'condition', 'robot', 'rot', 'soft', 'qﬁltering', 'improve', 'imitation', 'understand', 'importance', 'soft', 'qﬁltering', 'compare', 'rot', 'variant', 'propose', 'regular', 'ization', 'scheme', 'tuned', 'ﬁxed', 'weight', 'ignore', 'eq', 'b', 'carefully', 'design', 'lineardecay', 'schedule', 'vary', 'environment', 'step', 'strate', 'fig', 'appendix', 'h2', 'rot', 'par', 'case', 'ex', 'ceed', 'efﬁciency', 'handtune', 'decay', 'schedule', 'handtune', 'regularization', 'weight', 'hypothesize', 'improvement', 'primarily', 'due', 'well', 'stability', 'adaptive', 'weighing', 'see', 'signiﬁcantly', 'small', 'standard', 'deviation', 'metaworld', 'task', 'figure', 'effect', 'various', 'regularization', 'scheme', 'pare', 'adaptive', 'softq', 'ﬁltere', 'regularization', 'finetune', 'ﬁxed', 'weight', 'finetune', 'ﬁxed', 'rot', 'schedule', 'important', 'choice', 'irl', 'method', 'build', 'otbase', 'irl', 'instead', 'adversarial', 'irl', 'adversarial', 'irl', 'method', 'require', 'iterative', 'reward', 'learning', 'produce', 'highly', 'nonstationary', 'reward', 'function', 'policy', 'optimization', 'fig', 'compare', 'rot', 'adversarial', 'irl', 'method', 'use', 'pretraining', 'adaptive', 'regularization', 'technique', 'rdac', 'soft', 'qﬁltering', 'method', 'improve', 'prior', 'stateoftheart', 'adversarial', 'irl', 'rdac', 'fig', 'however', 'otbase', 'approach', 'rot', 'stable', 'average', 'lead', 'efﬁcient', 'learn', 'compare', 'standard', 'rewardbase', 'compare', 'performance', 'rot', 'stateoftheart', 'algorithm', 'imagebase', 'oppose', 'rewardfree', 'setting', 'rot', 'operate', 'drqv2', 'access', 'environment', 'reward', 'result', 'fig', 'show', 'rot', 'handily', 'outperform', 'drqv2', 'clearly', 'demonstrate', 'close', 'door', 'hang', 'hanger', 'erase', 'board', 'reach', 'hang', 'mug', 'hang', 'tote', 'bag', 'turn', 'knob', 'stack', 'cup', 'press', 'switch', 'peg', 'box', 'easy', 'peg', 'box', 'med', 'peg', 'box', 'hard', 'open', 'box', 'pour', 'almond', 'dmchopperhop', 'metaworldhammer', 'r', 'w', 'e', 'r', 'e', 'p', 'e', 'frame', 'e', 'r', 'e', 'c', 'frame', '1e6', 'expert', 'rot', 'figure', 'ablation', 'analysis', 'choice', 'base', 'irl', 'method', 'ﬁnd', 'adversarial', 'method', 'beneﬁt', 'regularize', 'gain', 'see', 'small', 'compare', 'rot', 'also', 'see', 'rot', 'outperform', 'plain', 'rl', 'require', 'explicit', 'taskreward', 'usefulness', 'imitation', 'learn', 'domain', 'expert', 'demonstration', 'available', 'rewardbase', 'also', 'compare', 'demoassisted', 'variant', 'drqv2', 'agent', 'use', 'pretraining', 'regularization', 'scheme', 'rot', 'refer', 'appendix', 'interestingly', 'soft', 'qﬁltering', 'base', 'regularization', 'accelerate', 'learning', 'rl', 'task', 'reward', 'see', 'high', 'performance', 'demoassiste', 'variant', 'drqv2', 'relate', 'work', 'imitation', 'learn', 'refer', 'setting', 'agent', 'learn', 'demonstration', 'access', 'environment', 'reward', 'broadly', 'categorize', 'behavior', 'clone', 'inverse', 'reinforcement', 'learn', 'irl', 'solely', 'learn', 'ofﬂine', 'demonstration', 'suffer', 'outofdistribution', 'sample', 'irl', 'focus', 'learn', 'robust', 'reward', 'function', 'online', 'interaction', 'suffer', 'sample', 'inefﬁciency', 'deep', 'irl', 'method', 'far', 'divide', 'category', 'adversarial', 'learn', 'base', 'method', 'statematche', 'base', 'method', 'gail', 'adversarial', 'learning', 'base', 'formulation', 'inspire', 'gan', 'signiﬁcant', 'body', 'work', 'build', 'gail', 'propose', 'alternative', 'loss', 'enhance', 'sample', 'efﬁciency', 'port', 'offpolicy', 'setting', 'also', 'visual', 'extension', 'adversarial', 'learning', 'approach', 'however', 'adversarial', 'method', 'produce', 'competent', 'policy', 'inefﬁcient', 'nonstationarity', 'associate', 'iterative', 'reward', 'inference', 'optimal', 'transport', 'ot', 'tool', 'compare', 'probability', 'measure', 'include', 'geometry', 'space', 'context', 'compute', 'alignment', 'set', 'agent', 'expert', 'observation', 'use', 'distance', 'metric', 'sinkhorn', 'gromovwasserstein', 'gdtw', 'coot', 'many', 'distance', 'measure', 'associated', 'use', 'sinkhorn', 'use', 'greedy', 'use', 'gdtw', 'gwil', 'use', 'gromovwasserstein', 'recent', 'work', 'cohen', 'demonstrate', 'sinkhorn', 'distance', 'produce', 'efﬁcient', 'learning', 'discuss', 'metric', 'far', 'show', 'compatible', 'highdimensional', 'visual', 'observation', 'encode', 'representation', 'inspire', 'rot', 'adopt', 'sinkhorn', 'metric', 'reward', 'computation', 'improve', 'adaptive', 'behavior', 'regularization', 'behavior', 'regularize', 'control', 'behavior', 'regularization', 'widely', 'use', 'technique', 'ofﬂine', 'explicit', 'constraint', 'add', 'policy', 'improvement', 'update', 'avoid', 'bootstrappe', 'outofdistribution', 'action', 'online', 'setting', 'access', 'environment', 'reward', 'prior', 'work', 'show', 'behavior', 'regularization', 'use', 'boost', 'sample', 'efﬁciency', 'ﬁnetune', 'pretraine', 'policy', 'online', 'interaction', 'instance', 'jena', 'demonstrate', 'effectiveness', 'behavior', 'regularization', 'enhance', 'sample', 'efﬁciency', 'context', 'build', 'idea', 'extend', 'visual', 'observation', 'otbase', 'regularization', 'lead', 'improved', 'performance', 'see', 'h4', 'also', 'note', 'idea', 'use', 'adaptive', 'regularization', 'previously', 'explore', 'however', 'rot', 'use', 'soft', 'continuous', 'adaptive', 'scheme', 'initial', 'experiment', 'provide', 'signiﬁcantly', 'fast', 'learn', 'compare', 'hard', 'assignment', 'w', 'e', 'r', 'e', 'p', 'e', 'dmcwalkerrun', 'fetchpickandplace', 'metaworldhammer', 'e', 'r', 'e', 'c', 'e', 'r', 'e', 'c', 'frame', 'frame', 'frame', '1e6', 'conclusion', 'limitation', 'work', 'propose', 'new', 'imitation', 'learn', 'rot', 'demonstrate', 'improved', 'performance', 'compare', 'prior', 'stateoftheart', 'work', 'variety', 'simulated', 'robotic', 'domain', 'however', 'recognize', 'limitation', 'work', 'otbase', 'approach', 'align', 'agent', 'demonstration', 'taskspeciﬁc', 'reward', 'rely', 'demonstrator', 'expert', 'extend', 'rot', 'suboptimal', 'noisy', 'multimodal', 'demonstration', 'exciting', 'problem', 'tackle', 'perform', 'bc', 'pretraine', 'bcbased', 'regularization', 'require', 'access', 'expert', 'action', 'present', 'realworld', 'scenario', 'particularly', 'learn', 'human', 'recent', 'work', 'use', 'inverse', 'model', 'infer', 'action', 'give', 'observational', 'datum', 'alleviate', 'challenge', 'c', 'robotic', 'task', 'box', 'hard', 'press', 'switch', 'fig', 'rot', 'performance', 'drop', 'substantially', 'compare', 'task', 'lack', 'visual', 'feature', 'correspond', 'task', 'success', 'example', 'task', 'visually', 'difﬁcult', 'discriminate', 'peg', 'box', 'box', 'similarly', 'switch', 'task', 'difﬁcult', 'discern', 'button', 'press', 'limitation', 'address', 'integrate', 'sensory', 'modality', 'additional', 'camera', 'tactile', 'sensor', 'observation', 'space', 'acknowledgment', 'thank', 'thankaraj', 'valuable', 'feedback', 'discussion', 'work', 'support', 'grant', 'honda', 'onr', 'award', 'reference', 'pomerleau', 'autonomous', 'land', 'vehicle', 'neural', 'network', 'advance', 'neural', 'information', 'processing', 'system', 'andrychowicz', 'b', 'r', 'plappert', 'ray', 'dexterous', 'inhand', 'manipulation', 'interna', 'tional', 'journal', 'research', 'p', 'kolm', 'g', 'ritter', 'modern', 'perspective', 'reinforcement', 'learning', 'ﬁnance', 'modern', 'perspective', 'reinforcement', 'learning', 'finance', 'journal', 'machine', 'learning', 'finance', 'russell', 'et', 'algorithm', 'inverse', 'reinforcement', 'learning', 'icml', 'volume', 'page', 'ross', 'bagnell', 'reduction', 'imitation', 'learning', 'structured', 'prediction', 'noregret', 'online', 'learning', 'proceeding', 'fourteenth', 'international', 'conference', 'cial', 'intelligence', 'statistic', 'page', 'jmlr', 'workshop', 'conference', 'proceeding', 'generative', 'adversarial', 'imitation', 'learn', 'advance', 'neural', 'information', 'processing', 'system', 'tompson', 'discriminatoractorcritic', 'addressing', 'sample', 'inefﬁciency', 'reward', 'bias', 'adversarial', 'imitation', 'learn', 'preprint', 'yarat', 'r', 'fergus', 'lazaric', 'l', 'master', 'visual', 'continuous', 'control', 'improve', 'dataaugmented', 'reinforcement', 'learn', 'arxiv', 'preprint', 'nair', 'gupta', 'dalal', 'accelerate', 'online', 'reinforcement', 'learning', 'ofﬂine', 'dataset', 'preprint', 'uchendu', 'learn', 'arxiv', 'preprint', 'amos', 'henaff', 'e', 'vinitsky', 'yarat', 'imitation', 'learn', 'pixel', 'observation', 'continuous', 'control', 'forumidjlbxkhklcg6', 'g', 'papagianni', 'imitation', 'learn', 'sinkhorn', 'r', 'geist', 'pietquin', 'primal', 'wasserstein', 'imitation', 'learn', 'preprint', 'p', 'dhariwal', 'radford', 'klimov', 'proximal', 'policy', 'optimization', 'preprint', 'silver', 'g', 'lever', 'heess', 'degris', 'riedmiller', 'deterministic', 'policy', 'gradient', 'algorithm', 'international', 'conference', 'machine', 'learning', 'page', 'pmlr', 'rajeswaran', 'learn', 'complex', 'dexterous', 'manipulation', 'deep', 'reinforcement', 'learning', 'demonstration', 'arxiv', 'preprint', 'r', 'augment', 'gail', 'sample', 'efﬁcient', 'imitation', 'learn', 'arxiv', 'preprint', 'doron', 'muldal', 'budden', 'merel', 'lefrancq', 'preprint', 'brockman', 'pettersson', 'schneider', 'zaremba', 'gym', 'preprint', 'r', 'levine', 'metaworld', 'benchmark', 'evaluation', 'multitask', 'meta', 'reinforcement', 'learning', 'conference', 'robot', 'learning', 'page', 'pmlr', 'torabi', 'g', 'p', 'stone', 'recent', 'advance', 'imitation', 'learn', 'observation', 'arxiv', 'preprint', 'p', 'abbeel', 'apprenticeship', 'learn', 'inverse', 'reinforcement', 'learning', 'proceeding', 'twentyﬁrst', 'international', 'conference', 'machine', 'learning', 'page', 'lillicrap', 'pritzel', 'heess', 'erez', 'silver', 'wierstra', 'continuous', 'control', 'deep', 'reinforcement', 'learn', 'preprint', 'nair', 'b', 'mcgrew', 'p', 'abbeel', 'overcome', 'exploration', 'reinforcement', 'learn', 'demonstration', 'ieee', 'international', 'conference', 'robotic', 'automation', 'page', 'ieee', 'e', 'mujoco', 'physics', 'engine', 'modelbase', 'control', 'ieeersj', 'international', 'conference', 'intelligent', 'robot', 'system', 'page', 'ieee', 'plappert', 'ray', 'b', 'chociej', 'p', 'welinder', 'reinforcement', 'learn', 'challenging', 'robotic', 'environment', 'request', 'research', 'preprint', 'r', 'levine', 'metaworld', 'benchmark', 'evaluation', 'multitask', 'meta', 'reinforcement', 'learning', 'conference', 'robot', 'learn', 'corl', 'wolski', 'ray', 'schneider', 'r', 'welinder', 'b', 'pieter', 'abbeel', 'zaremba', 'hindsight', 'experience', 'replay', 'advance', 'neural', 'information', 'processing', 'system', 'torabi', 'g', 'p', 'stone', 'generative', 'adversarial', 'imitation', 'observation', 'preprint', 'levine', 'learn', 'robust', 'reward', 'adversarial', 'inverse', 'reinforcement', 'learn', 'arxiv', 'preprint', 'r', 'gu', 'divergence', 'minimization', 'perspective', 'imitation', 'learning', 'method', 'conference', 'robot', 'learning', 'page', 'pmlr', 'r', 'sinkhorn', 'p', 'knopp', 'concern', 'nonnegative', 'matrix', 'doubly', 'stochastic', 'matrix', 'paciﬁc', 'mathematic', '212343–348', 'computation', 'optimal', 'transport', 'advance', 'neural', 'information', 'processing', 'system', 'hussein', 'gaber', 'e', 'elyan', 'c', 'jayne', 'imitation', 'learn', 'survey', 'learn', 'method', 'acm', 'computing', 'survey', 'l', 'dexterous', 'imitation', 'make', 'easy', 'learning', 'base', 'framework', 'efﬁcient', 'dexterous', 'manipulation', 'preprint', 'l', 'surprising', 'effectiveness', 'representation', 'learn', 'visual', 'imitation', 'arxiv', 'preprint', 'goodfellow', 'bengio', 'generative', 'adversarial', 'net', 'advance', 'neural', 'information', 'processing', 'system', 'c', 'villani', 'optimal', 'transport', 'old', 'new', 'volume', 'springer', 'g', 'optimal', 'transport', 'application', 'datum', 'science', 'foundation', 'trend', '®', 'machine', 'learning', 'b', 'l', 'maas', 'bagnell', 'reinforce', 'ment', 'learn', 'page', 'h', 'h', 'linh', 'wasserstein', 'adversarial', 'imitation', 'learn', 'preprint', 'e', 'cetin', 'domainrobust', 'visual', 'imitation', 'learn', 'mutual', 'information', 'constraint', 'preprint', 'toyer', 'r', 'shah', 'critch', 'russell', 'magical', 'benchmark', 'robust', 'imitation', 'advance', 'neural', 'information', 'processing', 'system', 'r', 'rafailov', 'rajeswaran', 'finn', 'visual', 'adversarial', 'imitation', 'learning', 'use', 'variational', 'model', 'advance', 'neural', 'information', 'processing', 'system', 'g', 'kernel', 'distance', 'matrix', 'international', 'conference', 'machine', 'learning', 'page', 'pmlr', 'cohen', 'luise', 'terenin', 'b', 'amos', 'deisenroth', 'align', 'time', 'series', 'parable', 'space', 'international', 'conference', 'artiﬁcial', 'intelligence', 'statistic', 'page', 'pmlr', 'redko', 'vayer', 'r', 'courty', 'cooptimal', 'preprint', 'differentiable', 'loss', 'function', 'timeserie', 'tional', 'conference', 'machine', 'learning', 'page', 'pmlr', 'fickinger', 'cohen', 'b', 'amos', 'crossdomain', 'imitation', 'learning', 'optimal', 'transport', 'preprint', 'kumar', 'fu', 'ofﬂine', 'reinforcement', 'learn', 'tutorial', 'review', 'perspective', 'open', 'problem', 'preprint', 'fujimoto', 'minimalist', 'approach', 'ofﬂine', 'reinforcement', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'nachum', 'behavior', 'regularize', 'ofﬂine', 'reinforcement', 'learn', 'preprint', 'levine', 'nachum', 'opal', 'ofﬂine', 'primitive', 'discovery', 'international', 'conference', 'learn', 'accelerate', 'ofﬂine', 'reinforcement', 'learning', 'representation', 'tucker', 'levine', 'stabilize', 'offpolicy', 'qlearning', 'bootstrappe', 'error', 'reduction', 'advance', 'neural', 'information', 'processing', 'system', 'siegel', 'berkenkamp', 'abdolmaleki', 'lampe', 'r', 'hafner', 'heess', 'riedmiller', 'keep', 'work', 'behavioral', 'modelling', 'prior', 'ofﬂine', 'reinforcement', 'learn', 'preprint', 'fujimoto', 'offpolicy', 'deep', 'reinforcement', 'learn', 'explo', 'ration', 'international', 'conference', 'machine', 'learning', 'page', 'pmlr', 'stateonly', 'imitation', 'learn', 'dexterous', 'manipulation', 'ieeersj', 'international', 'conference', 'intelligent', 'robot', 'system', 'iro', 'page', 'ieee', 'r', 'bellman', 'markovian', 'decision', 'process', 'journal', 'mathematic', 'mechanic', 'page', 'r', 'reinforcement', 'learn', 'introduction', 'mit', 'press', 'v', 'silver', 'rusu', 'veness', 'g', 'bellemare', 'grave', 'riedmiller', 'fidjeland', 'ostrovski', 'humanlevel', 'control', 'deep', 'rein', 'forcement', 'learn', 'nature', 'p', 'abbeel', 'laskin', 'framework', 'efﬁcient', 'robotic', 'manipulation', 'preprint', 'young', 'tulsiani', 'gupta', 'p', 'abbeel', 'visual', 'imitation', 'make', 'easy', 'preprint', 'p', 'knight', 'sinkhorn', 'convergence', 'application', 'journal', 'matrix', 'analysis', 'application', 'background', 'reinforcement', 'learn', 'study', 'discounted', 'inﬁnitehorizon', 'markov', 'decision', 'process', 'mdp', 'pixel', 'observation', 'agent', 'state', 'approximate', 'stack', 'consecutive', 'frame', 'mdp', 'form', 'p', 'r', 'observation', 'space', 'action', 'space', 'p', '×', '∆o', 'transition', 'function', 'deﬁne', 'probability', 'distribution', 'next', 'state', 'give', 'current', 'state', 'action', 'r', '×', 'r', 'reward', 'function', 'discount', 'factor', 'd0', 'initial', 'state', 'distribution', 'goal', 'policy', 'maximize', 'expect', 'discount', 'sum', 'reward', 't0γtrot', '∼', '∼', 'πot', '∼', 'p', 'ot', 'imitation', 'learn', 'goal', 'imitation', 'learning', 'learn', 'behavior', 'policy', 'πb', 'give', 'access', 'expert', 'policy', 'πe', 'trajectory', 'derive', 'expert', 'policy', 'e', 'multitude', 'setting', 'differ', 'level', 'access', 'expert', 'work', 'operate', 'setting', 'agent', 'access', 'observationbased', 'trajectory', 'denote', 'number', 'trajectory', 'rollout', 'episode', 'timestep', 'respectively', 'choose', 'speciﬁc', 'set', 'obtain', 'observation', 'action', 'expert', 'nearexpert', 'demonstrator', 'feasible', 'realworld', 'setting', 'fall', 'line', 'recent', 'work', 'area', 'inverse', 'reinforcement', 'learn', 'irl', 'tackle', 'problem', 'infer', 'reward', 'function', 'base', 'expert', 'trajectory', 'give', 'infer', 'reward', 'policy', 'optimization', 'use', 'derive', 'behavior', 'policy', 'πb', 'prominent', 'algorithm', 'irl', 'require', 'alternate', 'inference', 'reward', 'optimization', 'policy', 'iterative', 'manner', 'practical', 'restricted', 'model', 'class', 'compatibility', 'expressive', 'deep', 'network', 'technique', 'adversarial', 'learning', 'optimaltransport', 'need', 'adversarial', 'learning', 'base', 'approach', 'tackle', 'problem', 'learn', 'discriminator', 'model', 'gap', 'expert', 'trajectory', 'e', 'behavior', 'trajectory', 'behavior', 'policy', 'optimize', 'minimize', 'gap', 'gapminimize', 'reward', 'training', 'procedure', 'prone', 'instability', 'update', 'iteration', 'hence', 'nonstationary', 'optimization', 'optimal', 'transport', 'imitation', 'learn', 'alleviate', 'nonstationary', 'reward', 'problem', 'adversarial', 'irl', 'framework', 'new', 'line', 'otbase', 'approach', 'recently', 'propose', 'intuitively', 'closeness', 'expert', 'trajectory', 'e', 'behavior', 'trajectory', 'b', 'compute', 'measure', 'optimal', 'transport', 'probability', 'mass', 'e', 'policy', 'learn', 'policy', 'πφ', 'encompass', 'feature', 'preprocessor', 'fφ', 'transform', 'observation', 'informative', 'state', 'representation', 'example', 'preprocessor', 'function', 'identity', 'function', 'meanvariance', 'scale', 'function', 'parametric', 'neural', 'network', 'work', 'use', 'parametric', 'neural', 'network', 'give', 'cost', 'function', 'c', '×', 'r', 'deﬁne', 'preprocessor', 'output', 'space', 'ot', 'objective', 'g', 'optimal', 'alignment', 'expert', 'trajectory', 'oe', 'behavior', 'trajectory', 'compute', 'µ∗', '∈', 'set', 'couple', 'matrix', 'cost', 'c', 'euclidean', 'cosine', 'distance', 'work', 'inspire', 'use', 'entropic', 'wasserstein', 'distance', 'cosine', 'cost', 'metric', 'give', 'equation', 'fφoe', 'cttcid48', 'µttcid48', 'cost', 'matrix', 'cttcid48', 'fφoe', 'use', 'eq', 'optimal', 'alignment', 'obtain', 'optimize', 'reward', 'signal', 'compute', 'observation', 'use', 'equation', 'rot', '−', 'cttcid48', 'µ∗', 'ttcid48', 'intuitively', 'maximize', 'reward', 'encourage', 'imitate', 'agent', 'produce', 'trajectory', 'closely', 'match', 'demonstrate', 'trajectory', 'solve', 'eq', 'computationally', 'expensive', 'approximate', 'solution', 'sinkhorn', 'use', 'instead', 'issue', 'finetune', 'actorcritic', 'framework', 'paper', 'use', 'nstep', 'ddpg', 'propose', 'yarat', 'rl', 'optimizer', 'actor', 'critic', 'base', 'maximization', 'ddpg', 'concurrently', 'learn', 'deterministic', 'policy', 'πφ', 'use', 'deterministic', 'policy', 'gradient', 'dpg', 'qfunction', 'qθ', 'minimize', 'nstep', 'bellman', 'residual', 'nstep', 'ddpg', 'parameterized', 'actor', 'network', 'πφs', 'critic', 'function', 'qθs', 'deterministic', 'policy', 'gradient', 'dpg', 'update', 'actor', 'weight', 'give', '∇φj', 'refer', 'state', 'visitation', 'distribution', 'datum', 'present', 'replay', 'buffer', 'time', 'eq', 'clear', 'policy', 'gradient', 'framework', 'depend', 'gradient', 'respect', 'critic', 'value', 'hence', 'mention', 'naively', 'initialize', 'actor', 'pretraine', 'policy', 'use', 'randomly', 'initialize', 'critic', 'result', 'untrained', 'critic', 'provide', 'exceedingly', 'poor', 'signal', 'actor', 'network', 'training', 'result', 'actor', 'performance', 'drop', 'immediately', 'good', 'behavior', 'informed', 'initialization', 'policy', 'forget', 'paper', 'propose', 'adaptive', 'regularization', 'scheme', 'permit', 'ﬁnetune', 'pretraine', 'actor', 'policy', 'actorcritic', 'framework', 'oppose', 'rajeswaran', 'jena', 'employ', 'onpolicy', 'learn', 'method', 'offpolicy', 'aim', 'leverage', 'sample', 'efﬁcient', 'characteristic', 'offpolicy', 'learning', 'compare', 'onpolicy', 'learning', 'c', 'algorithmic', 'detail', 'implementation', 'describe', 'propose', 'regularize', 'optimal', 'transport', 'rot', 'sample', 'efﬁcient', 'imitation', 'learn', 'continuous', 'control', 'task', 'implementation', 'detail', 'follow', 'training', 'procedure', 'model', 'consist', 'primary', 'neural', 'network', 'encoder', 'actor', 'critic', 'pretraine', 'phase', 'encoder', 'actor', 'train', 'use', 'mean', 'squared', 'error', 'mse', 'expert', 'demonstration', 'next', 'ﬁnetune', 'weight', 'pretraine', 'encoder', 'actor', 'load', 'memory', 'critic', 'initialize', 'randomly', 'observe', 'performance', 'sensitive', 'value', 'α', 'set', 'experiment', 'paper', 'copy', 'pretraine', 'encoder', 'actor', 'store', 'ﬁxed', 'weight', 'use', 'compute', 'soft', 'qﬁltere', 'actorcritic', 'base', 'reward', 'maximization', 'use', 'recent', 'nstep', 'ddpg', 'propose', 'yarat', 'rl', 'backbone', 'deterministic', 'actor', 'train', 'use', 'deterministic', 'policy', 'gradient', 'dpg', 'give', 'critic', 'train', 'use', 'clip', 'double', 'qlearne', 'similar', 'yarat', 'order', 'reduce', 'overestimation', 'bias', 'target', 'value', 'use', 'qfunction', 'qθ1', 'qθ2', 'critic', 'loss', 'critic', 'give', 'equation', 'lθk', '−', 'y2cid3', '∀', 'regularize', 'optimal', 'transport', 'require', 'expert', 'demonstration', 'e', 'pretraine', 'policy', 'πbc', 'replay', 'buffer', 'training', 'step', 'episode', 'length', 'l', 'task', 'environment', 'env', 'parametric', 'network', 'rl', 'backbone', 'eg', 'encoder', 'policy', 'critic', 'function', 'drqv2', 'discriminator', 'adversarial', 'baseline', 'πbc', 'timestep', 'rewarderot', 'episode', 'update', 'episode', 'add', 'ot', 'envreset', 'false', 'episode', 'initialize', 'pretraine', 'policy', 'otbase', 'reward', 'computation', 'end', 'envstepat', 'episodeappendot', 'update', 'backbonespeciﬁc', 'network', 'rewardspeciﬁc', 'network', 'use', 'end', 'dβ', 'replay', 'buffer', 'online', 'rollout', 'target', 'value', 'nstep', 'ddpg', 'give', 'i0', 'k12', 'atn', 'discount', 'factor', 'r', 'reward', 'obtain', 'use', 'otbased', 'reward', 'computation', '¯θ2', 'slow', 'move', 'weight', 'target', 'qnetwork', 'target', 'feature', 'processor', 'stabilize', 'reward', 'reward', 'compute', 'output', 'feature', 'processor', 'fφ', 'initialize', 'parametric', 'neural', 'network', 'hence', 'weight', 'fφ', 'change', 'training', 'reward', 'become', 'nonstationary', 'result', 'unstable', 'training', 'order', 'increase', 'stability', 'train', 'ot', 'reward', 'compute', 'use', 'target', 'feature', 'processor', 'fφcid48', 'update', 'weight', 'fφ', 'tupdate', 'environment', 'step', 'statebased', 'observation', 'correspond', 'trunk', 'network', 'single', 'layer', 'neural', 'network', 'pixelbase', 'observation', 'include', 'encoder', 'follow', 'trunk', 'network', 'hyperparameter', 'complete', 'list', 'hyperparameter', 'provide', 'table', 'similar', 'yarat', 'slight', 'deviation', 'give', 'setting', 'walker', 'task', 'deepmind', 'control', 'suite', 'use', 'minibatch', 'size', 'nstep', 'return', 'environment', 'table', 'list', 'different', 'task', 'experiment', 'deepmind', 'control', 'openai', 'robotic', 'suite', 'metaworld', 'suite', 'number', 'training', 'step', 'number', 'demonstration', 'use', 'task', 'openai', 'robotic', 'suite', 'ﬁx', 'goal', 'keep', 'initial', 'state', 'randomize', 'modiﬁcation', 'make', 'case', 'deepmind', 'control', 'suite', 'metaworld', 'suite', 'episode', 'length', 'task', 'deepmind', 'control', 'step', 'openai', 'robotic', 'step', 'metaworld', 'step', 'picking', 'run', 'step', 'method', 'common', 'parameter', 'replay', 'buffer', 'size', 'learning', 'rate', 'discount', 'nstep', 'return', 'action', 'repeat', 'seed', 'frame', 'minibatch', 'size', 'agent', 'update', 'frequency', 'critic', 'softupdate', 'rate', 'feature', 'dim', 'hide', 'dim', 'optimizer', 'rot', 'exploration', 'step', 'ddpg', 'exploration', 'schedule', 'target', 'feature', 'processor', 'update', 'frequencystep', 'reward', 'scale', 'factor', 'fix', 'weight', 'value', 'linear', 'schedule', 'ot', 'exploration', 'step', 'ddpg', 'exploration', 'schedule', 'target', 'feature', 'processor', 'update', 'frequencystep', 'reward', 'scale', 'factor', 'exploration', 'step', 'ddpg', 'exploration', 'schedule', 'gradient', 'penalty', 'coefﬁcient', 'table', 'list', 'hyperparameter', 'e', 'demonstration', 'deepmind', 'control', 'task', 'train', 'expert', 'policy', 'use', 'pixelbase', 'drqv2', 'collect', 'demonstration', 'task', 'use', 'expert', 'policy', 'expert', 'policy', 'train', 'use', 'stack', 'consecutive', 'rgb', 'frame', 'size', '×', 'random', 'crop', 'augmentation', 'action', 'environment', 'repeat', 'time', 'openai', 'robotic', 'task', 'train', 'statebase', 'drqv2', 'hindsight', 'experience', 'replay', 'collect', 'demonstration', 'task', 'state', 'representation', 'comprise', 'observation', 'environment', 'append', 'desire', 'goal', 'location', 'frame', 'stack', 'action', 'repeat', 'set', 'metaworld', 'task', 'use', 'single', 'expert', 'demonstration', 'obtain', 'use', 'taskspeciﬁc', 'hardcode', 'policy', 'provide', 'opensource', 'implementation', 'suite', 'task', 'deepmind', 'control', 'allow', 'step', '×', 'demonstration', 'cartpole', 'finger', 'spin', 'hopper', 'stand', 'hopper', 'quadrupe', 'run', 'stand', 'walker', 'run', 'openai', 'robotic', 'fetch', 'reach', '×', 'fetch', 'push', 'fetch', 'pick', 'place', 'metaworld', 'hammer', '×', 'robot', '×', 'drawer', 'close', 'door', 'open', 'bin', 'pick', 'button', 'press', 'door', 'close', 'door', 'reach', 'turn', 'knob', 'stack', 'cup', 'press', 'switch', 'peg', 'easy', 'peg', 'medium', 'hard', 'open', 'box', 'pour', 'table', 'list', 'task', 'use', 'evaluation', 'robot', 'task', 'section', 'describe', 'suite', 'manipulation', 'experiment', 'carry', 'real', 'robot', 'paper', 'figure', 'example', 'different', 'initialization', 'real', 'robot', 'task', 'r', 'e', 'l', 'c', 'r', 'e', 'g', 'h', 'g', 'n', 'h', 'r', 'b', 'e', 'r', 'e', 'h', 'c', 'e', 'r', 'g', 'g', 'h', 'g', 'b', 'g', 'n', 'h', 'b', 'r', 'p', 'h', 'c', 'e', 'p', 'g', 'p', 'g', 'p', 'h', 'g', 'e', 'p', 'x', 'b', 'e', 'p', 'r', 'u', 'p', 'figure', 'example', 'trajectory', 'select', 'real', 'robot', 'task', 'door', 'close', 'robot', 'arm', 'suppose', 'close', 'open', 'door', 'push', 'target', 'b', 'hang', 'hanger', 'hold', 'hanger', 'gripper', 'robot', 'arm', 'initialize', 'random', 'position', 'task', 'put', 'hanger', 'goal', 'region', 'closet', 'rod', 'board', 'hold', 'board', 'duster', 'gripper', 'robot', 'arm', 'task', 'erase', 'mark', 'draw', 'board', 'initialize', 'random', 'position', 'reach', 'robot', 'arm', 'require', 'reach', 'speciﬁc', 'goal', 'initialize', 'random', 'position', 'e', 'hold', 'mug', 'gripper', 'robot', 'arm', 'initialize', 'random', 'position', 'task', 'hang', 'mug', 'speciﬁc', 'hook', 'bag', 'hold', 'tote', 'gripper', 'robot', 'arm', 'initialize', 'random', 'position', 'task', 'hang', 'tote', 'bag', 'speciﬁc', 'hook', 'g', 'turn', 'knob', 'robot', 'arm', 'task', 'rotate', 'knob', 'place', 'table', 'certain', 'angle', 'initialize', 'random', 'position', 'consider', 'degree', 'rotation', 'success', 'stack', 'hold', 'cup', 'gripper', 'robot', 'arm', 'require', 'stack', 'cup', 'place', 'table', 'press', 'switch', 'gripper', 'keep', 'close', 'robot', 'arm', 'require', 'press', 'switch', 'lead', 'light', 'place', 'table', 'easy', 'medium', 'hard', 'robot', 'arm', 'suppose', 'insert', 'peg', 'hang', 'string', 'bucket', 'place', 'table', 'task', 'variant', 'easy', 'medium', 'hard', 'size', 'bucket', 'decrease', 'easy', 'open', 'task', 'robot', 'arm', 'suppose', 'open', 'lid', 'box', 'place', 'table', 'lift', 'handle', 'provide', 'front', 'box', 'pour', 'give', 'cup', 'item', 'place', 'inside', 'case', 'almond', 'robot', 'arm', 'suppose', 'move', 'cup', 'place', 'table', 'pour', 'item', 'cup', 'evaluation', 'procedure', 'task', 'obtain', 'set', 'random', 'initialization', 'evaluate', 'method', 'rot', 'trajectory', 'set', 'initialization', 'initialization', 'different', 'task', 'base', 'limit', 'observation', 'space', 'task', 'baseline', 'paper', 'compare', 'rot', 'several', 'prominent', 'imitation', 'learning', 'reinforcement', 'learning', 'method', 'give', 'brief', 'description', 'baseline', 'model', 'use', 'expert', 'task', 'expert', 'refer', 'expert', 'policy', 'use', 'generate', 'demonstration', 'task', 'describe', 'e', 'r', 'b', 'e', 'r', 'e', 'g', 'b', 'g', 'n', 'h', 'b', 'r', 'h', 'g', 'e', 'p', 'x', 'b', 'e', 'p', 'b', 'behavior', 'clone', 'refer', 'behavior', 'clone', 'policy', 'train', 'expert', 'tion', 'adversarial', 'irl', 'actor', 'critic', 'stateoftheart', 'adversarial', 'imi', 'tation', 'learning', 'method', 'outperform', 'prior', 'work', 'gail6', 'serve', 'primary', 'adversarial', 'imitation', 'baseline', 'statematche', 'irl', 'sinkhorn', 'imitation', 'learn', 'stateoftheart', 'state', 'matching', 'imitation', 'learning', 'method', 'approximate', 'match', 'sinkhorn', 'rot', 'derive', 'similar', 'otbased', 'foundation', 'use', 'sil', 'primary', 'statematche', 'imitation', 'baseline', 'e', 'rdac', 'rot', 'instead', 'use', 'statematche', 'irl', 'adversarial', 'irl', 'use', 'finetune', 'ﬁxed', 'weight', 'similar', 'rot', 'instead', 'use', 'timevarying', 'adaptive', 'weight', 'ﬁxed', 'weight', 'λ0', 'use', 'λ0', 'set', 'ﬁxed', 'value', 'ﬁxed', 'schedule', 'similar', 'rot', 'use', 'ﬁxed', 'weight', 'λ0', 'timevarying', 'adaptive', 'weight', 'however', 'instead', 'use', 'soft', 'qﬁltering', 'compute', 'handcoded', 'linear', 'decay', 'schedule', 'use', 'h', 'drqv2', 'stateoftheart', 'algorithm', 'pixelbase', 'drqv2', 'assume', 'access', 'environment', 'reward', 'oppose', 'rot', 'compute', 'reward', 'use', 'otbase', 'technique', 'demodrqv2', 'refer', 'drqv2', 'access', 'environment', 'reward', 'expert', 'demonstration', 'model', 'initialize', 'pretraine', 'policy', 'follow', 'rl', 'ﬁnetune', 'adaptive', 'regularization', 'scheme', 'rot', 'rl', 'ﬁnetune', 'baseline', 'access', 'environment', 'reward', 'bcot', 'baseline', 'policy', 'initialize', 'pretraine', 'policy', 'adaptive', 'regularization', 'scheme', 'use', 'ﬁnetune', 'pretraine', 'policy', 'baseline', 'randomly', 'initialize', 'network', 'train', 'adaptive', 'regularization', 'scheme', 'add', 'objective', 'function', 'h', 'additional', 'experimental', 'result', 'h1', 'efﬁcient', 'rot', 'imitation', 'learning', 'addition', 'result', 'provide', 'fig', 'fig', 'show', 'performance', 'rot', 'pixelbase', 'imitation', 'task', 'deepmind', 'control', 'suite', 'task', 'openai', 'robotic', 'suite', 'task', 'metaworld', 'suite', 'task', 'rot', 'signiﬁcantly', 'sample', 'efﬁcient', 'prior', 'work', 'finally', 'improvement', 'hold', 'statebase', 'observation', 'wellsee', 'fig', 'table', 'provide', 'comparison', 'factor', 'speedup', 'rot', 'reach', 'expert', 'performance', 'compare', 'prior', 'stateoftheart', 'method', 'h2', 'soft', 'qﬁltering', 'improve', 'imitation', 'extend', 'result', 'show', 'fig', 'provide', 'training', 'curve', 'representative', 'task', 'suite', 'fig', 'observe', 'adaptive', 'softq', 'ﬁltere', 'regularization', 'stable', 'compare', 'prior', 'handtune', 'regularization', 'scheme', 'rot', 'par', 'case', 'exceed', 'efﬁciency', 'handtune', 'decay', 'schedule', 'handtune', 'regularization', 'weight', 'compare', 'standard', 'rewardbased', 'extend', 'result', 'show', 'fig', 'provide', 'training', 'curve', 'representative', 'task', 'suite', 'fig', 'thus', 'show', 'rot', 'outperform', 'standard', 'require', 'explicit', 'task', 'reward', 'also', 'show', 'rl', 'method', 'combine', 'regularization', 'scheme', 'represent', 'demodrqv2', 'fig', 'provide', 'strong', 'result', 'expert', 'rot', 'figure', 'pixelbase', 'continuous', 'control', 'learning', 'dmc', 'environment', 'shade', 'region', 'represent', '±1', 'standard', 'deviation', 'seed', 'notice', 'rot', 'signiﬁcantly', 'sample', 'efﬁcient', 'compare', 'prior', 'work', 'h4', 'important', 'design', 'choice', 'rot', 'importance', 'pretraine', 'regularize', 'irl', 'policy', 'fig', 'compare', 'follow', 'variant', 'rot', 'set', 'pixelbase', 'task', 'training', 'irl', 'policy', 'finetune', 'pretraine', 'policy', 'train', 'irl', 'policy', 'scratch', 'observe', 'pretraine', 'irl', 'policy', 'bcot', 'provide', 'signiﬁcant', 'difference', 'regularization', 'attribute', 'forget', 'behavior', 'pretraine', 'policy', 'study', 'interestingly', 'see', 'even', 'pretraine', 'keep', 'policy', 'close', 'behavior', 'distribution', 'yield', 'improvement', 'efﬁciency', 'vanilla', 'training', 'scratch', 'key', 'takeaway', 'experiment', 'pretraine', 'require', 'obtain', 'sampleefﬁcient', 'imitation', 'learn', 'choice', 'irl', 'method', 'rot', 'build', 'otbase', 'irl', 'instead', 'adversarial', 'irl', 'adversarial', 'irl', 'method', 'require', 'iterative', 'reward', 'learning', 'produce', 'highly', 'non', 'stationary', 'reward', 'function', 'policy', 'optimization', 'fig', 'compare', 'rot', 'adversarial', 'r', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'dmcacrobotswingup', 'r', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'dmcwalkerstand', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'expert', 'rot', 'figure', 'pixelbase', 'continuous', 'control', 'learning', 'openai', 'gym', 'robotic', 'metaworld', 'task', 'shade', 'region', 'represent', '±1', 'standard', 'deviation', 'seed', 'notice', 'rot', 'signiﬁcantly', 'sample', 'efﬁcient', 'compare', 'prior', 'work', 'irl', 'method', 'use', 'pretraining', 'adaptive', 'regularization', 'technique', 'rdac', 'soft', 'qﬁltering', 'method', 'improve', 'prior', 'stateoftheart', 'adversarial', 'irl', 'rdac', 'fig', 'however', 'otbase', 'approach', 'rot', 'stable', 'average', 'lead', 'efﬁcient', 'learn', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'fetchreach', 'fetchpush', 'fetchpickandplace', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', 'frame', 'frame', 'metaworldhammer', 'metaworlddrawerclose', 'metaworlddraweropen', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'frame', '1e6', 'frame', '1e6', 'metaworlddooropen', 'metaworldbinpicking', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', 'frame', '1e6', 'frame', '1e6', 'frame', '1e6', 'metaworlddoorunlock', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', '1e6', 'expert', 'rot', 'figure', 'statebase', 'continuous', 'control', 'learning', 'metaworld', 'task', 'notice', 'rot', 'signiﬁcantly', 'sample', 'efﬁcient', 'compare', 'prior', 'work', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'r', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'r', 'w', 'e', 'r', 'p', 'e', 'dmcwalkerstand', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'dmcwalkerwalk', 'r', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'metaworldhammer', 'metaworlddooropen', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'frame', '1e6', 'frame', '1e6', 'frame', '1e6', 'metaworlddraweropen', 'metaworlddoorunlock', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', '1e6', 'frame', '1e6', 'frame', 'task', 'rot', '2nd', 'good', 'model', 'finger', 'spin', 'run', 'hopper', 'stand', 'stand', 'walker', 'run', 'quadrupe', 'run', 'openai', 'robotic', 'fetch', 'reach', '320k', 'ot', 'push', 'fetch', 'pick', 'place', 'metaworld', 'hammer', 'drawer', 'close', 'drawer', 'open', 'door', 'open', 'bin', 'pick', '20k', 'ot', 'button', 'press', 'door', 'unlock', 'ot', 'table', 'taskwise', 'comparison', 'environment', 'step', 'require', 'reach', 'expert', 'perfor', 'mance', 'pixelbase', 'rot', 'compare', 'strong', 'baseline', 'task', 'expert', 'ﬁxed', 'weight', 'finetune', 'ﬁxed', 'schedule', 'rot', 'figure', 'pixelbase', 'ablation', 'analysis', 'effect', 'vary', 'regularization', 'scheme', 'observe', 'adaptive', 'softq', 'ﬁltere', 'regularization', 'stable', 'compare', 'prior', 'handtune', 'regularization', 'scheme', 'w', 'e', 'r', 'p', 'e', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'dmccheetahrun', 'dmchopperhop', 'dmcquadrupedrun', 'r', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'fetchreach', 'fetchpush', 'fetchpickandplace', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', 'frame', 'frame', '1e6', 'metaworlddooropen', 'metaworldhammer', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'frame', '1e6', 'frame', '1e6', 'frame', '1e6', 'rot', 'figure', 'pixelbase', 'ablation', 'analysis', 'performance', 'comparison', 'rot', 'drqv2', 'rewardbase', 'rl', 'method', 'see', 'rot', 'outperform', 'plain', 'rl', 'require', 'explicit', 'taskreward', 'however', 'also', 'observe', 'rl', 'method', 'combine', 'regularization', 'scheme', 'provide', 'strong', 'result', 'w', 'e', 'r', 'p', 'e', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'dmcfingerspin', 'dmccheetahrun', 'dmcwalkerrun', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'fetchreach', 'fetchpush', 'frame', 'metaworlddooropen', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', 'metaworldbinpicking', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', 'metaworldhammer', 'frame', '1e6', 'frame', '1e6', 'frame', '1e6', 'rot', 'figure', 'pixelbase', 'ablation', 'analysis', 'importance', 'pretraine', 'regularize', 'irl', 'policy', 'key', 'takeaway', 'experiment', 'pretraine', 'require', 'obtain', 'sampleefﬁcient', 'imitation', 'learn', 'r', 'w', 'e', 'r', 'p', 'e', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'dmcfingerspin', 'dmccheetahrun', 'dmcwalkerrun', 'r', 'w', 'e', 'r', 'p', 'e', 'r', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'fetchreach', 'fetchpush', 'fetchpickandplace', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', 'frame', 'metaworlddooropen', 'metaworldhammer', 'e', 'e', 'r', 'p', 'e', 'c', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', 'metaworldbuttonpresstopdown', 'frame', '1e6', 'frame', '1e6', 'frame', '1e6', 'expert', 'rot', 'figure', 'pixelbase', 'ablation', 'analysis', 'choice', 'base', 'irl', 'method', 'ﬁnd', 'adversarial', 'method', 'beneﬁt', 'regularize', 'gain', 'see', 'small', 'compare', 'rot', 'w', 'e', 'r', 'p', 'e', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'e', 'e', 'r', 'p', 'e', 'c', 'dmcfingerspin', 'dmccheetahrun', 'r', 'w', 'e', 'r', 'p', 'e', 'dmcwalkerrun', 'w', 'e', 'r', 'p', 'e', 'frame', 'frame', 'frame', 'fetchreach', 'e', 'e', 'r', 'p', 'e', 'c', 'fetchpush', 'fetchpickandplace', 'e', 'e', 'r', 'p', 'e', 'c', 'frame', 'frame', 'metaworlddooropen', 'metaworldhammer', 'e', 'r', 'p', 'e', 'c', 'e', 'g', 'e', 'r', 'p', 'e', 'c', 'frame', '1e6', 'frame', '1e6', 'frame']"
"Personalized Showcases: Generating Multi-Modal Explanations for
  Recommendations","[{'href': 'http://arxiv.org/abs/2207.00422v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2207.00422v1', 'rel': 'related', 'type': 'application/pdf'}]",2022-06-30 01:43:58,"Denoised MDPs: Learning World Models Better Than the World Itself

Tongzhou Wang 1 Simon S. Du 2 Antonio Torralba 1 Phillip Isola 1 Amy Zhang 3 4 Yuandong Tian 4

2
2
0
2

l
u
J

1

]

G
L
.
s
c
[

2
v
7
7
4
5
1
.
6
0
2
2
:
v
i
X
r
a

Abstract

The ability to separate signal from noise, and
reason with clean abstractions, is critical to in-
telligence. With this ability, humans can efﬁ-
ciently perform real world tasks without consider-
ing all possible nuisance factors. How can artiﬁ-
cial agents do the same? What kind of information
can agents safely discard as noises? In this work,
we categorize information out in the wild into four
types based on controllability and relation with
reward, and formulate useful information as that
which is both controllable and reward-relevant.
This framework clariﬁes the kinds information
removed by various prior work on representation
learning in reinforcement learning (RL), and leads
to our proposed approach of learning a Denoised
MDP that explicitly factors out certain noise dis-
tractors. Extensive experiments on variants of
DeepMind Control Suite and RoboDesk demon-
strate superior performance of our denoised world
model over using raw observations alone, and
over prior works, across policy optimization con-
trol tasks as well as the non-control task of joint
position regression.

ssnl.github.io/denoised_mdp
Project Page:
Code: github.com/facebookresearch/denoised_mdp

1. Introduction

The real world provides us a plethora of information, from
microscopic physical interactions to abstracted semantic
signals such as the latest COVID-19 news. Fortunately,
processing each and every signal is unnecessary (and also
impossible). In fact, any particular reasoning or decision
often only relies on a small portion of information.

Imagine waking up and wanting to embrace some sunlight.
As you open the curtain, a nearby resting bird is scared

1MIT CSAIL 2University of Washington 3UC Berkeley 4Meta
AI. Correspondence to: Tongzhou Wang <tongzhou@mit.edu>.
Work done while Tongzhou Wang was an intern at Meta AI.

Proceedings of the 39 th International Conference on Machine
Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy-
right 2022 by the author(s).

Figure 1: Illustrative example: (a) Four distinct kinds of infor-
mation in the scenario described in Section 1, where the person
desires to increase the amount of sunlight let into the room. Their
opening of the curtain scares away the bird. (b) A denoised world
model only includes a small subset of all information.

away and you are pleasantly met with a beautiful sunny day.
Far away, a jet plane is slowly ﬂying across the sky.

This may seem a simple activity, but in fact highlights four
distinct types of information (see Figure 1), with respect to
the goal of letting in as much sunlight as possible:
• Controllable and reward-relevant: curtain, inﬂuenced

by actions and affecting incoming sunlight;

• Controllable and reward-irrelevant: bird, inﬂuenced

by actions but not affecting sunlight;

• Uncontrollable and reward-relevant: weather, inde-

pendent with actions but affecting sunlight;

• Uncontrollable and reward-irrelevant: plane, indepen-

dent with both actions and the sunlight.

Our optimal actions towards the goal, however, only in fact
depend on information that is controllable and reward-

Reward-
Relevant

Reward-
Irrelevant

Uncontrollable

Controllable

(a) GOAL: Letting in as much sunlight as possible.

Denoise

(b) Optimal control only relies on information that is both 

controllable and reward-relevant. Good world models 
should ignore other factors as noisy distractors.

 
 
 
 
 
 
Denoised MDPs

relevant, and the three other kinds of information are merely
noise distractors.
Indeed, no matter how much natural
sunlight there is outside, or how the plane and the bird
move, the best plan is always to open up the curtain.

When performing a particular task, we humans barely think
about the other three types of information, and usually only
plan on how our actions affect information that is control-
lable and reward-relevant. Our mental model is an ab-
stract and condensed version of the real world that is actually
better suited for the task.

The notion of better model/data is ubiquitous in data science
and machine learning. Algorithms rarely perform well on
raw noisy real data. The common approach is to perform
data cleaning and feature engineering, where we manually
select the useful signals based on prior knowledge and/or
heuristics. Years of research have identiﬁed ways to extract
good features for computer vision (Lowe, 1999; Donahue
et al., 2014), natural language processing (Elman, 1990;
Mikolov et al., 2013), reinforcement learning (RL) (Ma-
hadevan & Maggioni, 2007; Bellemare et al., 2019), etc.
Similarly, system identiﬁcation aligns real observation with
a predeﬁned set of abstract signals/states. Yet for tasks in the
wild (in the general form of (partially observable) Markov
Decision Processes), there can be very little prior knowledge
of the optimal set of signals. In this work, we ask: can we
infer and extract these signals automatically, in the form of
a learned world model?

The general idea of a mental world model have long been un-
der active research in philosophy and social science (Craik,
1952; Dennett, 1975), cognitive science, where an intuitive
physics model is hypothesized to be core in our planning
capabilities (Spelke & Kinzler, 2007), and in reinforcement
learning, where various methods investigate state abstrac-
tions for faster and better learning (Sutton, 1991; 1981).

In this work, we explore this idea within the context of
machine learning and reinforcement learning, where we
aim to make concrete the different types of information
in the wild, and automatically learn a world model that
removes noise distractors and is beneﬁcial for both control
(i.e., policy optimization) and non-control tasks. Toward
this goal, our contributions are

• We categorize information into four distinct kinds as in
Figure 1, and review prior approaches under this frame-
work (Section 2).

• Based on the above framework, we propose Denoised
MDPs, a method for learning world models with certain
distractors removed (Section 3).

• Through experiments in DeepMind Control Suite and
RoboDesk environments, we demonstrate superior per-
formance of policies learned our method, across many
distinct types of noise distractors (Sections 5.1 and 5.2).

• We show that Denoised MDP is also beneﬁcial beyond
control objectives, improving the supervised task of robot
joint position regression (Section 5.1).

2. Different Types of Information in the Wild

In Section 1, we illustrated the four types of information
available in the wild w.r.t. a task. Here we make these
notions more concrete, and relate them to existing works.

For generality, we consider tasks in the form of Markov
Decision Processes (MDPs), described in the usual manner:
M (cid:44) (S, A, R, P, ps0 ) (Puterman, 1994), where S is the
state space, A is the action space, R : S → ∆([0, rmax])
deﬁnes the reward random variable R(s(cid:48)) received for ar-
riving at state s(cid:48) ∈ S, P : S × A → ∆(S) is the transition
dynamics, and ps0 ∈ ∆(S) deﬁnes the distribution of initial
state. We use ∆(A) to denote the set of all distributions
over A. P and R deﬁne the most important components
of a MDP: the transition dynamics P[s(cid:48) | s, a] and the re-
ward function P[r | s(cid:48)]. Usually, the objective is to ﬁnd a
policy π : S → ∆(A) acting based on current state, that
maximizes the expected cumulative (discounted) reward.

Indeed, MDPs provide a general formulation that encom-
passes many tasks. In fact, the entire real world may be
viewed as an MDP with a rich state/observation space S
that contains all possible information/signal. For an artiﬁ-
cial agent to successfully perform real world tasks, it must
be able to process observations that are incredibly rich and
high-dimensional, such as visual or audio signals.

We characterize different types of information in such ob-
servations by considering two intuitive notions of “noisy
and irrelevant” signals: (1) uncontrollable information and
(2) reward-irrelevant information. Such factors can often be
ignored without affecting optimal control, and are referred
to as noise distractors.

To understand their roles in MDPs, we study different for-
mulations of the transition dynamics and reward functions,
and show how different structures naturally leads to decom-
positions that may help identify such distractors. Removing
these distractors can thus transform the original noisy MDP
to a clean denoised one, to be used in downstream tasks.

For starters, the most generic transition model in Figure 2a
has little to no structure. The state s can contain both the
useful signals and noise distractors. Therefore, it is not
directly useful for extracting important information.

2.1. Controllability

Intuitively, if something is not controllable, an agent might
be able to do well without considering it. Yet it is not enough
to only require some variable to be unaffected by actions
(e.g., wind directions should not be ignored while sailing).

Denoised MDPs

a

a

a

a

r

Rew

Rew

Ctrl

s

s(cid:48)

Ctrl

s

s

s

s

x

yR

yR

s

x(cid:48)

y(cid:48)
R

y(cid:48)
R

s(cid:48)

rx

ry

+

r

Rew

Rew

Ctrl

x
yR
yR

x
yR
yR

Ctrl

x
yR
yR

x
yR
yR

x

y

z

s

x(cid:48)

y(cid:48)

z(cid:48)

s(cid:48)

rx

ry

+

r

Rew

Rew

Ctrl

Ctrl

x

y

x

y

z

z

x

y

x

y

z

z

(b) Transition that factorizes out uncontrol-
lable information in yR and yR.

(a) Transition without useful structure.
s may contain any type of information.
Figure 2: MDP transition structures consisting of dynamics and reward functions. Unlike the regular structure of (a), (b, c) factorized (yet
still general) structures inherently separate information into controllable (Ctrl) versus uncontrollable (Ctrl), and reward-relevant (Rew)
versus reward-irrelevant (Rew). Presence of a variable in a cell means possible containing of respective information. E.g., in (c), z can
only contain reward-irrelevant information. In (b, c), the x dynamics form an MDP with less noise and sufﬁcient for optimal planning.
Our Denoised MDP (see Section 3) is based on these two factorizations.

(c) Transition that factorizes out uncontrol-
lable y and reward-irrelevant z.

Instead, we focus on factors that simply evolve on their own,
without inﬂuencing or being inﬂuenced by others.

Not all such information can be safely ignored, as they
still may affect reward (e.g., trafﬁc lights when driving).
Fortunately, in the usual objective of maximizing expected
return, we can ignore ones that only additively affect reward.

Concretely, if an MDP transition can be represented in the
form of Figure 2b, we say variables yR and yR are uncontrol-
lable information, as they evolve independently of actions
and do not affect controllable x. Here yR (additively) af-
fects reward, but can be ignored. One can safely discard
both yR and yR as noise distractors. Operating with the
compressed MDP of only x is sufﬁcient for optimal control.

2.2. Reward-Relevance

Among controllable information, there can still be some that
is completely unrelated to reward. In Figure 1, the bird is
affected by the opening curtain, but is irrelevant to the task
of letting in sunlight. In such cases, the information can be
safely discarded, as it does not affect the objective.

If an MDP transition can be represented in the form of
Figure 2c, we say z is reward-irrelevant because it evolves
by potentially using everything (i.e., all latent variables and
actions), but crucially does not affect anything but itself.

Similar to uncontrollable information, z (and y) is a noise
distractor that can be discarded. The compressed MDP of
only x contains all signals needed for optimal control.

2.3. Which Information Do Existing Methods Learn?

In RL, many prior work have explored state abstractions in
some form. Here we cast several representative ones under

Reconstruction-Based
Model-Based RL
(e.g., SLAC (Lee et al., 2019),
Dreamer (Hafner et al., 2019a))

Model-Based

Bisimulation
(e.g., Ferns et al. (2004),
Castro (2020), Zhang et al. (2020))

Model-Free

Task Informed
Abstractions (TIA)
(Fu et al., 2021)

Model-Based

Denoised MDP
(Figure 2b variant)
(Our method from Section 3)

Model-Based

Denoised MDP
(Figure 2c variant)
(Our method from Section 3)

Model-Based

RewRew
(cid:51) (cid:51)

(cid:51) (cid:51)

Ctrl

Ctrl

RewRew
(cid:51) (cid:55)

(cid:51) (cid:55)

Ctrl

Ctrl

RewRew
(cid:51) ?
(cid:51) ?

RewRew
(cid:51) (cid:51)

(cid:55)

(cid:55)

RewRew
(cid:51) (cid:55)

(cid:55)

(cid:55)

Ctrl

Ctrl

Ctrl

Ctrl

Ctrl

Ctrl

Information Grid Legend:

(cid:51) Kept

(cid:55) Reduced

? Depending on how the information
is integrated in observations

Figure 3: Categorization of information learned and removed by
various methods with distinct formulations.

the framework described above, and show which kinds of
information they learn to remove, summarized in Figure 3,
together with our proposed method (explained in Section 3).
Below we discuss each prior work in detail.

Reconstruction-Based Model-Based RL. Many model-
based RL methods learn via reconstruction from a single
latent code, often as a result of a variational formulation
(Hafner et al., 2019a;b; Lee et al., 2019). The latent code

Denoised MDPs

must try to compress all information present in the observa-
tion, and necessarily contains all types of information.

Bisimulation.
Bisimulation deﬁnes a state abstraction
where states aggregated together must have the same ex-
pected return and transition dynamics up to the abstrac-
tion (Givan et al., 2003), and is known to optimally ignore
reward-irrelevant information (Ferns et al., 2004). While its
continuous version, bisimilation metric, is gaining popular-
ity, learning them is computationally difﬁcult (Modi et al.,
2020). Even with many additional assumptions, it is gen-
erally only possible to learn an on-policy variant that loses
the above guarantee (Castro, 2020; Zhang et al., 2020).

Task Informed Abstractions (TIA).
TIA (Fu et al.,
2021) extends Dreamer by modelling two independent la-
tent MDPs, representing signal and noise. The noise latent
is enforced to be independent with reward and reconstruct
the observation as well as possible. Reconstructions from
each latent are composed together using an inferred mask
in pixel-space, to form the full reconstruction for the re-
construction loss. Because of its special structure, TIA can
remove reward-irrelevant noise distractors that are present
via pixel-wise composing two images from independent
processes (e.g., agent moving on a noisy background), but
not general ones (e.g., a shaky camera affecting both the
agent and the noisy background).

Predictive Information, Data Augmentation, etc. An-
other set of researches learn state representation that only
contains information useful for predicting future states (e.g.,
CPC (Oord et al., 2018) and PI-SAC (Lee et al., 2020)) or
augmented views of the current state (e.g., CURL (Laskin
et al., 2020b)). These methods do not guarantee removal of
any of the three redundant piece of information identiﬁed
above. Non-i.i.d. noises (e.g., people moving in background)
are predictive of future and may be kept by CPC and PI-
SAC. The performance of augmentation-based methods can
critically rely on speciﬁc types of augmentation used and
relevance to the tasks. As we show in experiments (see Sec-
tion 5), indeed they struggle to handle certain noise types.

2.4. Possible Extensions to Further Factorizations

The above framework is sufﬁcient for characterizing most
prior work and related tasks, and can also be readily ex-
tended with further factorized transition structures. E.g., if
an independent process confounds a signal process and a
noise process, ﬁtting the Figure 2c structure must group all
three processes into x (to properly model the dependencies).
However, a further factorization shows that only considering
the signal and the confounding processes is theoretically
sufﬁcient for control. We leave such extensions as future
work.

3. Denoised MDPs

Figures 2b and 2c show two special MDP structures that au-
tomatically identify certain information that can be ignored,
leaving x as the useful information (which also forms an
MDP). This suggests a naïve approach: directly ﬁtting such
structures to collected trajectories, and then extract x.

However, the same MDP dynamics and rewards can be
decomposed as Figures 2b and 2c in many different ways. In
the extreme case, x may even contain all information in the
raw state s, and such extraction may not help at all. Instead,
we desire a ﬁt with the minimal x, deﬁned as being least
informative of s (so that removal of the other latent variables
discards the most information possible). Concretely, we
aim for a ﬁt with least I({xt}T
t=1), the
mutual information x contains about s over T steps. Then
from this ﬁt, we can extract a minimal Denoised MDP of
only x. For notation simplicity, we use bold symbols to
denote variable sequences, and thus write, e.g., I(x; s | a).

t=1 | {at}T

t=1; {st}T

Practically, we consider regularizing model-ﬁtting with
I(x; s | a). As we show below, this amounts to a modiﬁ-
cation to the well-established variational objective (Hafner
et al., 2019a). The resulting method is easy-to-implement
yet effective, enabling clean removal of various noise distrac-
tors the original formulation cannot handle (see Section 5).

We instantiate this idea with the structure in Figure 2c. The
Figure 2b formulation can be obtained by simply removing
the z components and viewing y as combined yR and yR.
The transition structure is modeled with components:

p(xt)
θ

p(yt)
θ

p(zt)
θ

(cid:44) pθ(xt | xt−1, a)
pθ(rx | xt)
(cid:44) pθ(yt−1 | yt−1)
pθ(ry | yt)

(x dynamics)

(x reward)

(y dynamics)

(y reward)

(cid:44) pθ(zt | xt, yt, zt−1, a)
pθ(st | xt, yt, zt).

(z dynamics)

(obs. emission)

Consider training data in the form of trajectory segments
s, a, r sampled from some data distribution pdata (e.g.,
stored agent experiences from a replay buffer). We perform
model learning by minimizing the negative log likelihood:

LMLE(θ) (cid:44) −Es,a,r∼pdata

(cid:2) log pθ (s, r | a) (cid:3).

To obtain a tractable form, we jointly learn three variational
posterior components (i.e., encoders):

q(xt)
ψ
q(yt)
ψ
q(zt)
ψ

(cid:44) qψ(xt | xt−1, yt−1, zt−1, st, at)

(x posterior)

(cid:44) qψ(yt | xt−1, yt−1, zt−1, st, at)

(y posterior)

(cid:44) qψ(zt | xt, yt, st, at),

(z posterior)

Denoised MDPs

whose product deﬁnes the posterior qψ(x, y, z | s, a)1. We
choose this factorized form based on the forward (prior)
model structure of Figure 2c.

Then, the model can be optimized w.r.t. the standard varia-
tional bound on log likelihood:
(cid:20)

LMLE(θ) = min

ψ

Es,a,r

Ex,y,z∼
qψ (·|s,a,r)

− log pθ(s, r | x, y, z, a)
(cid:124)
(cid:123)(cid:122)
(cid:125)
(cid:44) Lrecon(θ, ψ)
T
(cid:88)

DKL

(cid:0)q(yt)

ψ

(cid:13)
(cid:13) p(yt)

θ

DKL

(cid:0)q(xt)

ψ

(cid:13)
(cid:13) p(xt)

θ

(cid:1)

+

(cid:123)(cid:122)
(cid:44) LKL-x(θ, ψ)
(cid:0)q(zt)

DKL

ψ

(cid:13)
(cid:13) p(zt)

θ

(cid:123)(cid:122)
(cid:44) LKL-z(θ, ψ)

t=1
(cid:124)

(cid:123)(cid:122)
(cid:44) LKL-y(θ, ψ)

(cid:125)

(cid:1)

(cid:125)

(cid:21)

,

(cid:1)

(cid:125)

(1)

+

+

T
(cid:88)

t=1
(cid:124)

T
(cid:88)

t=1
(cid:124)

where equality is attained by optimal qψ that is compatible
with pθ, i.e., qψ is the exact posterior of pθ.

The mutual information regularizer I(x; s | a), using a
variational formulation, can be written as

I(x; s | a) = min

θ

LKL-x(θ, ψ),

(2)

with equality attained when qψ and pθ are compatible. The
appendix describes this derivation in detail.

Therefore, for a regularizer weight of c ≥ 0, we can opti-
mize Equations (1) and (2) together as

min
θ
= min
θ,ψ

LMLE(θ) + c · I(x; s | a)

Lrecon(θ, ψ) + (1 + c) · LKL-x(θ, ψ)
+ LKL-y(θ, ψ) + LKL-z(θ, ψ).

(3)

Recall that we ﬁt to the true MDP with the structure of Fig-
ure 2c, which inherently guarantees all useful information
in the x latent variable. As the regularizer ensures learning
the minimal x latents, the learned model extracts an MDP of
condensed useful information with X as the denoised state
space, pθ(x(cid:48) | x, a) as the transition dynamics, pθ(rx | x(cid:48))
as the reward function. This MDP is called the Denoised
MDP, as it discards the noise distractors contained in y and
z. Additionally, we also obtain qψ(x | s, a) as the encoder
mapping from raw noisy observation s to the denoised x.

A loss variant for improved stability. When using a
large c ≥ 0 (e.g. when the environment is expected to be
very noisy), Equation (3) contains to a term with a large
weight. Thus Equation (3) often requires learning rates to
be tuned for different c. To avoid this, we use the following
loss form that empirically has better training stability and
does not require tuning learning rates w.r.t. other hyperpa-

1Following Dreamer (Hafner et al., 2019a), we deﬁne pos-
terior of ﬁrst-step latents qψ(x1, y1, z1 | s1) (cid:44) qψ( · , · , ·
|
0, 0, 0, s1, 0), where 0 is the all zeros vector of appropriate size.

Algorithm 1 Denoised MDP

Input: Model pθ. Posterior encoder qψ. Policy π : X → ∆(A).

Policy optimization algorithm PI-OPT.

Output: Denoised MDP of x in pθ; Encoder qψ; Policy π.
1: while training do
// Exploration
2:
Collect trajectories with π acting on qψ encoded outputs
3:
// Model learning
4:
Sample a batch of (s, a, r) segments from reply buffer
5:
Train pθ and qψ with Equation (4) on (s, a, r)
6:
// Policy optimization
7:
Sample x ∼ qψ(x | s, a); Compute rx = E [pθ(rx | x)]
8:
Train π by running PI-OPT on (x, a, rx)
9:
10: end while

rameters:

min
θ,ψ

Lrecon + α · (LKL-x + βLKL-y + βLKL-z) ,

(4)

where θ, ψ in arguments are omitted, and the hyperparame-
ters are α > 0 and 0 < β ≤ 1. Here β is bounded, where
β = 1 represents no regularization. α is also generally small
and simply chosen according to the state-space dimensional-
ity (see the appendix; α ∈ {1, 2} in our experiments). This
form is justiﬁed from the observation that in practice we
use isotropic Gaussians with ﬁxed variance to parameter-
ize the distributions of observation pθ(s | . . . ) and reward
pθ(r | . . . ), where scaling log likelihoods is essentially
changing the variance hyperparameter. Thus, Equation (4)
is effectively a scaled Equation (3) with different variance
hyperparameters.

Online algorithm with policy optimization.
The model
ﬁtting objective of Equation (4) can be used in various set-
tings, e.g., ofﬂine over a collected trajectory dataset. With-
out assuming existing data, we explore an online setting,
where the training process iteratively performs (1) explo-
ration, (2) model-ﬁtting, and (3) policy optimization, as
shown in Algorithm 1. The policy π : X → ∆(A) soley
operates on the Denoised MDP of x, which has all infor-
mation sufﬁcient for control. For policy optimization, the
learned posterior encoder qψ(x | s, a) is used to extract
x information from the raw trajectory (s, a, r), obtaining
transition sequences in X space. Paired with the pθ(rx | x)
rewards, we obtain (x, a, rx) as trajectories collected from
the Denoised MDP on x. Any general-purpose MDP policy
optimization algorithm may be employed on these data, such
as Stochastic Actor-Critic (SAC) (Haarnoja et al., 2018). We
can also utilize the learned differentiable Denoised MDP,
e.g., optimizing policy by backpropagating through addi-
tional roll-outs from the model, as is done in Dreamer.

While presented in the fully observable setting, Denoised
MDP readily handles partial observability without extra
changes. In the appendix, we discuss this point in details,
and provide a guideline for choosing hyperparameters α, β.

Denoised MDPs

4. Related Work

Model-Based Learning for Control
jointly learns a
world model and a policy. Such methods often enjoy good
sample efﬁciency on RL tasks with rich observations. Some
formulations rely on strong assumptions, e.g., determinis-
tic transition in DeepMDP (Gelada et al., 2019) and bilin-
ear transition in FLAMBE (Agarwal et al., 2020). Most
general-setting methods use a reconstruction-based objec-
tive (Hafner et al., 2019b; Kim et al., 2020; Ha & Schmidhu-
ber, 2018; Lee et al., 2019). Among them, Dreamer (Hafner
et al., 2019a) trains world models with a variational formu-
lation and optimizes policies by backpropagating through
latent-space rollouts. It has proven effective across a va-
riety of environments with image observations. However,
such reconstruction-based approaches can struggle with the
presence of noise distractors. TIA (Fu et al., 2021) partially
addresses this limitation (see Section 2.3) but can not handle
general distractors, unlike our method.

Representation Learning and Reinforcement Learning.
Our work automates selecting useful signals from noisy
MDPs by learning denoised world models, and can be
viewed as an approach for learning general representations
(Donahue et al., 2014; Mikolov et al., 2013; He et al., 2019;
Huh et al., 2016). In model-free RL, various methods learn
state embeddings that are related to value functions (Schaul
et al., 2015; Bellemare et al., 2019), transition dynamics
(Mahadevan & Maggioni, 2007; Lee et al., 2020), recent ac-
tion (Pathak et al., 2017), bisimulation structure (Ferns et al.,
2004; Castro, 2020; Zhang et al., 2020), data augmentations
(Laskin et al., 2020b) etc. Recently, Eysenbach et al. (2021)
proposes a regularizer similar to ours but for the different
purpose of robust compressed policies. The theoretical work
by Efroni et al. (2021) is closest to our setting but concerns
a more restricted set of distractors (ones both uncontrollable
and reward-irrelevant). Unlike Denoised MDP, their pro-
posed algorithm is largely impractical and does not produce
a generative model of observations (i.e., no decoder).

System Identiﬁcation.
Our work is related to system
identiﬁcation, where an algorithm infers from real world an
abstract state among a predeﬁned limited state space, e.g.,
pose estimation (Rıza Alp Güler, 2018; Yen-Chen et al.,
2021) and material estimation (Hahn et al., 2019). Such
results are useful for robotic manipulation (Manuelli et al.,
2019), image generation (Gu et al., 2019), etc. Our setting is
not limited to a predeﬁned abstract state space, but instead
focuses on automatic discovery of such valuable states.

5. Experiments

In this section, we contrast our method with existing ap-
proaches on environments with image observations and
many distinct types of noise distractors. Our experiments

are designed to include a variety of noise distractors and to
conﬁrm our analysis on various methods in Section 2.3.

Environments. We choose DeepMind Control (DMC)
Suite (Tunyasuvunakool et al., 2020) (Section 5.2) and
RoboDesk (Kannan et al., 2021) (Section 5.1) with image
observations, where we explore adding various noise dis-
tractors. Information types in all evaluated environments are
categorized in Table 2 of the appendix. Tasks include control
(policy optimization) and a non-control task of regressing
robot joint position from RoboDesk image observations.

Methods. We compare not only model-based RL meth-
ods, but also model-free algorithms and general representa-
tion learning approaches, when the task is suited:

• Model Learning: Denoised MDP (our method),
Dreamer (Hafner et al., 2019a), and TIA (Fu et al., 2021);
• Model-Free: DBC (Zhang et al., 2020), CURL (Laskin
et al., 2020b), PI-SAC (Lee et al., 2020) (without data
augmentation for a fair comparison of its core predictive
information regularization against other non-augmenting
methods), and SAC on true state-space (Haarnoja et al.,
this is
2018) (instead of using image observations,
roughly an “upper bound”);

• General Image Representation Learning for Non-
Control Tasks: Contrastive learning with the Align-
ment+Uniformity loss (Wang & Isola, 2020) (a form of
contrastive loss theoretically and empirically comparable
to the popular InfoNCE loss (Oord et al., 2018)).

Model-learning methods can be used in combination with
any policy optimization algorithm. For a complete com-
parison for general control, we compare the models trained
with these two policy learning choices: (1) backpropagating
via the learned dynamics and (2) SAC on the learned la-
tent space (which roughly recovers SLAC (Lee et al., 2019)
when used with an unfactorized model such as Dreamer).

Most compared methods do not apply data augmentations,
which is known to strongly boost performance (Yarats et al.,
2021; Laskin et al., 2020a). Therefore, for a fair comparison,
we run PI-SAC without augmentation to highlight its main
contribution—representation of only predictive information.

All results are aggregated from 5 runs, showing mean and
standard deviations. The appendix contains more details,
hyperparameter studies, and additional results. Our website
presents videos showing clearer video visualizations.

For Denoised MDP, we use the Figure 2b variant. Empiri-
cally, the Figure 2c variant leads to longer training time and
sometimes inferior performance (perhaps due to having to
optimize extra components and ﬁt a more complex model).
The appendix provides a comparison between them.

Denoised MDPs

Figure 4: Visualization of learned models for RoboDesk by using decoders to reconstruct from encoded latents. For TIA and Denoised
MDP, we visualize how they separate information as signal versus noise. In each row, what changes over frames is the information
modeled by the corresponding latent component. E.g., in the bottom row, only the TV content, camera pose and lighting condition change,
so Denoised MDP considers these factors as noises, while modelling the TV hue as signal. See our website for clearer video visualizations.

5.1. RoboDesk with Various noise distractors

We augment RoboDesk environment with many noise dis-
tractors that models realistic noises (e.g., ﬂickering lights
and shaky camera). Most importantly, we place a large TV
in the scene, which plays natural RGB videos. A green
button on the desk controls the TV’s hue (and a light on the
desk). The agent is tasked with using this button to shift the
TV to a green hue. Its reward is directly affected by how
green the TV image is. The ﬁrst row of Figure 4 shows a
trajectory with various distractors annotated. All four types
of information exist (see Table 2), with the controllable and
reward-relevant information being the robot arm, the green
button, the light on the desk, and the TV screen green-ness.

controllable and reward-relevant information as signals—
the Signal row only tracks changes in robot arms, green
button and light, and the TV screen green-ness. All other
information is modeled as noises (see the Noise row). We
recommend viewing video visualizations on our website.

Denoised models improve policy learning.
Figure 4
also shows the total episode return achieved by policies
learned with each of the three models, where the cleanest
model from Denoised MDP achieves the best performance.
Aggregating over 5 runs, the complete comparison in Fig-
ure 5 shows that Denoised MDP (with backpropagating via
dynamics) generally outperforms all baselines, suggesting
that its clean models are helpful for control.

Only Denoised MDP learns a clean denoised model.
Using learned decoders, Figure 4 visualizes how the mod-
els captures various information. As expected, Dreamer
model captures all information. TIA also fails to separate
any noise distractors out (the Noise row fails to capture
anything), likely due to its limited ability to model differ-
ent noises. In contrast, Denoised MDP cleanly extracts all

Denoised models beneﬁt non-control tasks. We evalu-
ate the learned representations on a supervised non-control
task—regressing the robot arm joint position from observed
images. Using various pretrained encoders, we ﬁnetune
on a labeled training set, and measure mean squared error
(MSE) on a heldout test set. In addition to RL methods, we
compare encoders learned via general contrastive learning

Blocks on Desk: 
Ctrl & Rew

TV Image Green-ness: 
Ctrl & Rew

Green Button & Light: 
Ctrl & Rew

Robot Joints: 
Ctrl & Rew

TV Semantic Content: 
Ctrl & Rew

Shaky/Flickering Camera & Lights:
Ctrl & Rew

Env. 
Rollout

Obs.

Reward

<latexit sha1_base64=""2Iv/3i2hbQBcJJvODDrynrkogxE="">AAACaHicjVHLSgMxFE3Hd321uhBxEyyCLiwzoqgLQRTBpYJVoR0kk96xwSQzJHekZZgP8Gvc6qf4C36Fae1CrYIXAodzziU5J1EqhUXffyt5Y+MTk1PTM+XZufmFxUp16dommeHQ4IlMzG3ELEihoYECJdymBpiKJNxED6d9/eYRjBWJvsJeCqFi91rEgjN01F2lttlSDDtRlJ8VzRZCF22cG8DM6CKkR3QvONxyLr/uD4aOgmAIamQ4F3fV0narnfBMgUYumbXNwE8xzJlBwSUU5VZmIWX8gd1D00HNFNgwH6Qp6IZj2jROjDsa6YD9upF3/2tkytqeipyzn9H+1PrkXxp21G9SM8P4IMyFTjMEzT/fEGeSYkL79dK2MMBR9hxg3AiXl/IOM4yj+4Rvl1irpXKexBau4OBnnaPgeqce7NX9y93a8cmw6mmyRtbJJgnIPjkm5+SCNAgnT+SZvJDX0rtX8Va81U+rVxruLJNv461/AAe3u44=</latexit>

Dreamer
(E[return] = 519)

Recon.

Recon.

<latexit sha1_base64=""detSQHFar06ldxZUdWoplWvpw3s="">AAACaHicjVHLSgMxFE3H97vVhYibYBF0YZnxvRFEEVwqWBXaQTLpnTaYZIbkjrQM8wF+jVv9FH/BrzCtXfgELwQO55xLck6iVAqLvv9a8kZGx8YnJqemZ2bn5hfKlcVrm2SGQ50nMjG3EbMghYY6CpRwmxpgKpJwE92f9vWbBzBWJPoKeymEirW1iAVn6Ki7cnWjqRh2oig/KxpNhC7aODeAmdFFSI/o7s7+pnP5NX8w9CcIhqBKhnNxVyltNVsJzxRo5JJZ2wj8FMOcGRRcQjHdzCykjN+zNjQc1EyBDfNBmoKuO6ZF48S4o5EO2M8befe/Rqas7anIOfsZ7XetT/6lYUf9JjUyjA/DXOg0Q9D84w1xJikmtF8vbQkDHGXPAcaNcHkp7zDDOLpP+HKJtVoq50ls4QoOvtf5E1xv14K9mn+5Wz0+GVY9SVbJGtkgATkgx+ScXJA64eSRPJFn8lJ688resrfyYfVKw50l8mW8tXcD9buM</latexit>

TIA
(E[return] = 436)

Signal

Noise

Recon.

Signal

Noise

Denoised
MDP
(E[return] = 628)

<latexit sha1_base64=""ftE/OHSJy3ovK5tqHIptkB9eUHM="">AAACaHicjVHLSgMxFE3H97vqQsRNaBF0YZkRXxtBFMGlgtVCO0gmvWODSWZI7ohlmA/wa9zqp/gLfoVp7UJbBS8EDuecS3JOolQKi77/XvLGxicmp6ZnZufmFxaXyssrNzbJDIc6T2RiGhGzIIWGOgqU0EgNMBVJuI0eznr67SMYKxJ9jd0UQsXutYgFZ+iou3J1q6UYdqIoPy+aLYQntHFuADOji5Ae04Pdo23n8mt+f+goCAagSgZzebdc2mm1E54p0Mgls7YZ+CmGOTMouIRitpVZSBl/YPfQdFAzBTbM+2kKuumYNo0T445G2me/b+RP/zUyZW1XRc7Zy2iHtR75l4Yd9ZvUzDA+CnOh0wxB8683xJmkmNBevbQtDHCUXQcYN8LlpbzDDOPoPuHHJdZqqZwnsYUrOBiucxTc7NaC/Zp/tVc9OR1UPU02SIVskYAckhNyQS5JnXDyTF7IK3krfXhlb81b/7J6pcHOKvkxXuUTCZu7jw==</latexit>

Denoised MDPs

Figure 5: Policy optimization on RoboDesk. We give state-space
SAC a less noisy reward so it can learn (see appendix).

Figure 6: Performance of ﬁnetuning various encoders to infer joint
position from RoboDesk image observation.

Policy Learning: Backprop via Dynamics Policy Learning: SAC (Latent-Space)

Denoised MDP

TIA

Dreamer Denoised MDP

TIA

Dreamer

DBC

PI-SAC
(No Aug.)

CURL
(Use Aug.)

State-Space SAC
(Upper Bound)

Noiseless

801.4 ± 96.6

769.7 ± 97.1 848.6 ± 137.1

587.1 ± 98.7

480.2 ± 125.5 575.4 ± 146.2 297.4 ± 72.5 246.4 ± 56.6

417.3 ± 183.2

910.3 ± 28.2

Video Background

597.7 ± 117.8

407.1 ± 225.4 227.8 ± 102.7

309.8 ± 153.0

318.1 ± 123.7 188.7 ± 78.2 188.0 ± 67.4 131.7 ± 20.1

478.0 ± 113.5

910.3 ± 28.2

Video Background
+ Noisy Sensor
Video Background
+ Camera Jittering

563.1 ± 143.0

261.2 ± 200.4 212.4 ± 89.7

288.2 ± 123.4

197.3 ± 124.2 218.2 ± 58.1

79.9 ± 36.0 152.5 ± 12.6

354.3 ± 119.9

919.8 ± 100.7

254.1 ± 114.2

151.7 ± 160.5

98.6 ± 27.7

186.8 ± 47.7

126.5 ± 125.6 105.2 ± 33.8

68.0 ± 38.4

91.6 ± 7.6

390.4 ± 64.9

910.3 ± 28.2

Table 1: DMC policy optimization results. For each variant, we aggregate performance across three tasks (Cheetah Run, Walker Walk,
Reacher Easy) by averaging. Denoised MDP performs well across all four variants with distinct noise types. Bold numbers show the
best model-learning result for speciﬁc policy learning choices, or the best overall result. On Camera Jittering, Denoised MDP greatly
outperforms all other methods except for CURL, which potentially beneﬁts from its speciﬁc data augmentation choice (random crop) on
this task, and can be seen as using extra information (i.e., knowing the noise distractor form). In fact, Denoised MDP is the only method
that consistently performs well across all tasks and noise variants, which can be seen from the full results in the appendix.

on the same amount of data. In Figure 6, Denoised MDP
representations lead to best converged solutions across a
wide range of training set sizes, achieve faster training, and
avoid overﬁtting when the training set is small. DBC, CURL
and PI-SAC encoders, which take in stacked frames, are not
directly comparable and thus absent from Figure 6. In the
appendix, we compare them with running Denoised MDP
encoder on each frame and concatenating the output fea-
tures, where Denoised MDP handily outperforms both DBC
and CURL by a large margin.
5.2. DeepMind Control Suite (DMC)

To evaluate a diverse set of noise distractors, we consider
four variants for each DMC task (see Figure 7 top row):

• Noiseless: Original environment without distractors.
• Video Background: Replacing noiseless background
with natural videos (Zhang et al., 2020) (Ctrl + Rew).
• Video Background + Sensor Noise: Imperfect sensors
sensitive to intensity of a background patch (Ctrl+Rew).
• Video Background + Camera Jittering: Shifting the
observation by a smooth random walk (Ctrl + Rew).

Denoised MDP consistently removes noise distractors.
In Figure 7, TIA struggles to learn clean separations in

many settings. Consistent with analysis in Section 2.3, it
cannot handle Sensor Noise or Camera Jittering, as the
former is reward-relevant noise that it cannot model, and the
latter (although reward-irrelevant) cannot be represented by
masking. Furthermore, it fails on Reacher Easy with Video
Background, where the reward is given by the distance
between the agent and a randomly-located ball. TIA encour-
ages its noise latent to be independent of reward, but does
not prevent it from capturing the controllable agent. These
failures lead to either TIA trying to model everything as
useful signals, or a badly-ﬁt model (e.g., wrong agent pose
in the last column). In contrast, Denoised MDP separates
out noise in all cases, obtaining a clean and accurate MDP
(its Signal rows only have the agent moving).

Denoised models consistently improve policy learning.
We evaluate the learned policies in Table 1, where results
are aggregated by the noise distractor variant. Other meth-
ods, while sometimes handling certain noise types well,
struggle to deal with all four distinct variants. TIA, as ex-
pected, greatly underperforms Denoised MDP under Noisy
Sensor or Camera Jittering. CURL, whose augmentation
choice potentially helps handling Camera Jittering, under-
performs in other three variants. In contrast, Denoised MDP

State-Space SAC with Modified Reward

Joint Position Regression
Final Test MSE vs. Training Set Size 

Joint Position Regression
Learning Curve for |Train Set|=104

Denoised MDPs

Figure 7: Visualization of the different DMC variants and factorizations learned by TIA and Denoised MDP. E.g., bottom Noise row often
shows a static agent but varying background, indicating that only the background is modeled as noises in Denoised MDP. Visualizations
of full reconstructions are in appendix. See our website for clearer video visualizations.

policies consistently perform well for all noisy variants and
also the noiseless setting, regardless of the policy optimizer.

Model-based approaches have a signiﬁcant lead over the
model-free ones, as seen from the DBC results in Table 1
and the well-known fact that direct model-free learning on
raw image observations usually fails (Laskin et al., 2020a;
Kostrikov et al., 2020; Yarats et al., 2021). These results
show that learning in a world model is useful, and that
learning in a denoised world model is even better.

6. Implications

In this work we explore learning denoised and compressed
world models in the presence of environment noises.

As a step towards better understanding of such noises, we
categorize of information in the wild into four types (Sec-
tion 2). This provides a framework to contrast and under-
stand various methods, highlighting where they may be
successful and where they will suffer (Section 2.3). Insights
gained this way empirically agrees with ﬁndings from exten-
sive experiments (Section 5). It can potentially assist better
algorithm design and analysis of new MDP representation
methods, as we have done in designing Denoised MDP
(Section 3). We believe that this categorization will be a
useful framework for investigation on learning under noises,
revealing not just the (conceptual) success scenarios, but
also the failure scenarios at the same time. Additionally, the
framework can be readily extended with more sophisticated
factorizations (Section 2.4), which can lead to correspond-
ing Denoised MDP variants and/or new algorithms.

Based on the framework, our proposed Denoised MDP nov-
elly can remove all noise distractors that are uncontrollable
or reward-irrelevant, in distinction to prior works. Empiri-
cally, it effectively identiﬁes and removes a diverse set of
noise types, obtaining clean denoised world models (Sec-
tion 5). It may serve as an important step towards efﬁcient
learning of general tasks in the noisy real world. Our ex-
periments also highlight beneﬁts of cleanly denoised world
models on both standard control tasks as well as non-control
tasks. The success in both cases highlights the general use-
fulness of such models. Given the generality of MDPs, this
opens up the possibility of casting non-RL tasks as MDPs
and automatically learn representations from denoised world
models, as an alternative to manual feature engineering.

Acknowledgements

We thank Jiaxi Chen for the beautiful Figure 1 illustration.
We thank Daniel Jiang and Yen-Chen Lin for their helpful
comments and suggestions. We are grateful to the following
organizations for providing computation resources to this
project: IBM’s MIT Satori cluster, MIT Supercloud cluster,
and Google Cloud Computing with credits gifted by Google
to MIT. We are very thankful to Alex Lamb for suggestions
and catching our typo in the conditioning of Equation (1).

Cheetah Run
Noiseless

Reacher Easy
Video Background

Walker Walk
Video Background
+ Noisy Sensor

Cheetah Run
Video Background
+ Camera Jittering

Env. 
Rollout

Obs.

Reward

TIA

Denoised
MDP

Signal

Noise

Signal

Noise

Denoised MDPs

References

Agarwal, A., Kakade, S., Krishnamurthy, A., and Sun,
FLAMBE: Structural complexity and represen-
arXiv preprint

W.
tation learning of low rank mdps.
arXiv:2006.10814, 2020.

Bellemare, M., Dabney, W., Dadashi, R., Ali Taiga, A.,
Castro, P. S., Le Roux, N., Schuurmans, D., Lattimore,
T., and Lyle, C. A geometric perspective on optimal
representations for reinforcement learning. Advances in
neural information processing systems, 32:4358–4369,
2019.

Castro, P. S. Scalable methods for computing state similarity
in deterministic markov decision processes. In Proceed-
ings of the AAAI Conference on Artiﬁcial Intelligence,
volume 34, pp. 10069–10076, 2020.

Coates, A., Ng, A., and Lee, H. An analysis of single-
layer networks in unsupervised feature learning. In Pro-
ceedings of the fourteenth international conference on
artiﬁcial intelligence and statistics, pp. 215–223, 2011.

Craik, K. J. W. The nature of explanation, volume 445. CUP

Archive, 1952.

Dennett, D. C. Why the law of effect will not go away.

Journal for the Theory of Social Behaviour, 1975.

Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N.,
Tzeng, E., and Darrell, T. Decaf: A deep convolutional
activation feature for generic visual recognition. In Inter-
national conference on machine learning, pp. 647–655.
PMLR, 2014.

Du, S., Krishnamurthy, A., Jiang, N., Agarwal, A., Dudik,
M., and Langford, J. Provably efﬁcient rl with rich obser-
vations via latent state decoding. In International Con-
ference on Machine Learning, pp. 1665–1674. PMLR,
2019.

Efroni, Y., Misra, D., Krishnamurthy, A., Agarwal, A.,
and Langford, J. Provable rl with exogenous distrac-
tors via multistep inverse dynamics. arXiv preprint
arXiv:2110.08847, 2021.

Elman, J. L. Finding structure in time. Cognitive science,

14(2):179–211, 1990.

Eysenbach, B., Salakhutdinov, R., and Levine, S. Robust
predictable control. arXiv preprint arXiv:2109.03214,
2021.

Ferns, N., Panangaden, P., and Precup, D. Metrics for ﬁnite
markov decision processes. In UAI, volume 4, pp. 162–
169, 2004.

Fu, X., Yang, G., Agrawal, P., and Jaakkola, T. Learning
task informed abstractions. In International Conference
on Machine Learning, pp. 3480–3491. PMLR, 2021.

Gelada, C., Kumar, S., Buckman, J., Nachum, O., and Belle-
mare, M. G. Deepmdp: Learning continuous latent space
models for representation learning. In International Con-
ference on Machine Learning, pp. 2170–2179. PMLR,
2019.

Givan, R., Dean, T., and Greig, M. Equivalence notions
and model minimization in markov decision processes.
Artiﬁcial Intelligence, 147(1-2):163–223, 2003.

Gu, S., Bao, J., Yang, H., Chen, D., Wen, F., and Yuan, L.
Mask-guided portrait editing with conditional gans. In
Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, pp. 3436–3445, 2019.

Ha, D. and Schmidhuber, J. World models. arXiv preprint

arXiv:1803.10122, 2018.

Haarnoja, T., Zhou, A., Hartikainen, K., Tucker, G., Ha,
S., Tan, J., Kumar, V., Zhu, H., Gupta, A., Abbeel, P.,
et al. Soft actor-critic algorithms and applications. arXiv
preprint arXiv:1812.05905, 2018.

Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M. Dream to
control: Learning behaviors by latent imagination. arXiv
preprint arXiv:1912.01603, 2019a.

Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D.,
Lee, H., and Davidson, J. Learning latent dynamics for
planning from pixels. In International Conference on
Machine Learning, pp. 2555–2565. PMLR, 2019b.

Hahn, D., Banzet, P., Bern, J. M., and Coros, S. Real2sim:
Visco-elastic parameter estimation from dynamic motion.
ACM Transactions on Graphics (TOG), 38(6):1–13, 2019.

He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. Mo-
mentum contrast for unsupervised visual representation
learning. arXiv preprint arXiv:1911.05722, 2019.

Huh, M., Agrawal, P., and Efros, A. A. What makes
arXiv preprint

imagenet good for transfer learning?
arXiv:1608.08614, 2016.

Kannan, H., Hafner, D., Finn, C., and Erhan, D. RoboDesk:
A multi-task reinforcement learning benchmark. https:
//github.com/google-research/robodesk, 2021.

Kim, S. W., Zhou, Y., Philion, J., Torralba, A., and Fidler,
S. Learning to Simulate Dynamic Environments with
GameGAN. In IEEE Conference on Computer Vision
and Pattern Recognition (CVPR), Jun. 2020.

Denoised MDPs

Kostrikov, I., Yarats, D., and Fergus, R. Image augmentation
is all you need: Regularizing deep reinforcement learning
from pixels. arXiv preprint arXiv:2004.13649, 2020.

Laskin, M., Lee, K., Stooke, A., Pinto, L., Abbeel, P., and
Srinivas, A. Reinforcement learning with augmented data.
Advances in Neural Information Processing Systems, 33:
19884–19895, 2020a.

Laskin, M., Srinivas, A., and Abbeel, P. Curl: Contrastive
unsupervised representations for reinforcement learning.
In International Conference on Machine Learning, pp.
5639–5650. PMLR, 2020b.

In International Conference on Machine Learning, pp.
5171–5180. PMLR, 2019.

Puterman, M. L. Markov Decision Processes: Discrete
Stochastic Dynamic Programming. John Wiley & Sons,
Inc., USA, 1st edition, 1994. ISBN 0471619779.

Rıza Alp Güler, Natalia Neverova, I. K. Densepose: Dense

human pose estimation in the wild. 2018.

Schaul, T., Horgan, D., Gregor, K., and Silver, D. Universal
value function approximators. In International conference
on machine learning, pp. 1312–1320. PMLR, 2015.

Lee, A. X., Nagabandi, A., Abbeel, P., and Levine,
S. Stochastic latent actor-critic: Deep reinforcement
learning with a latent variable model. arXiv preprint
arXiv:1907.00953, 2019.

Smaira, L., Carreira, J., Noland, E., Clancy, E., Wu, A.,
and Zisserman, A. A short note on the kinetics-700-2020
human action dataset. arXiv preprint arXiv:2010.10864,
2020.

Lee, K.-H., Fischer, I., Liu, A., Guo, Y., Lee, H., Canny, J.,
and Guadarrama, S. Predictive information accelerates
learning in rl. Advances in Neural Information Processing
Systems, 33:11890–11901, 2020.

Lowe, D. G. Object recognition from local scale-invariant
features. In Proceedings of the seventh IEEE interna-
tional conference on computer vision, volume 2, pp. 1150–
1157. Ieee, 1999.

Mahadevan, S. and Maggioni, M. Proto-value functions:
A laplacian framework for learning representation and
control in markov decision processes. Journal of Machine
Learning Research, 8(10), 2007.

Manuelli, L., Gao, W., Florence, P., and Tedrake, R. kpam:
Keypoint affordances for category-level robotic manipu-
lation. arXiv preprint arXiv:1903.06684, 2019.

Mikolov, T., Chen, K., Corrado, G., and Dean, J. Efﬁcient
estimation of word representations in vector space. arXiv
preprint arXiv:1301.3781, 2013.

Modi, A., Jiang, N., Tewari, A., and Singh, S. Sample com-
plexity of reinforcement learning using linearly combined
model ensembles. In International Conference on Artiﬁ-
cial Intelligence and Statistics, pp. 2010–2020. PMLR,
2020.

Oord, A. v. d., Li, Y., and Vinyals, O. Representation learn-
ing with contrastive predictive coding. arXiv preprint
arXiv:1807.03748, 2018.

Pathak, D., Agrawal, P., Efros, A. A., and Darrell, T.
Curiosity-driven exploration by self-supervised predic-
tion. In ICML, 2017.

Poole, B., Ozair, S., Van Den Oord, A., Alemi, A., and
Tucker, G. On variational bounds of mutual information.

Spelke, E. S. and Kinzler, K. D. Core knowledge. Develop-

mental science, 10(1):89–96, 2007.

Sutton, R. S. An adaptive network that constructs and uses
and internal model of its world. Cognition and Brain
Theory, 4(3):217–246, 1981.

Sutton, R. S. Dyna, an integrated architecture for learning,
planning, and reacting. ACM Sigart Bulletin, 2(4):160–
163, 1991.

Todorov, E., Erez, T., and Tassa, Y. Mujoco: A physics
engine for model-based control. In 2012 IEEE/RSJ Inter-
national Conference on Intelligent Robots and Systems,
pp. 5026–5033. IEEE, 2012.

Tunyasuvunakool, S., Muldal, A., Doron, Y., Liu, S., Bohez,
S., Merel, J., Erez, T., Lillicrap, T., Heess, N., and Tassa,
Y. dm_control: Software and tasks for continuous control.
Software Impacts, 6:100022, 2020.

Wang, T. and Isola, P. Understanding contrastive represen-
tation learning through alignment and uniformity on the
hypersphere. In Proceedings of the 37th International
Conference on Machine Learning, volume 119 of Pro-
ceedings of Machine Learning Research, pp. 9929–9939.
PMLR, 13–18 Jul 2020.

Yarats, D., Fergus, R., Lazaric, A., and Pinto, L. Mastering
visual continuous control: Improved data-augmented re-
inforcement learning. arXiv preprint arXiv:2107.09645,
2021.

Yen-Chen, L., Florence, P., Barron, J. T., Rodriguez, A.,
Isola, P., and Lin, T.-Y. iNeRF: Inverting neural radiance
ﬁelds for pose estimation. In IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS),
2021.

Denoised MDPs

Zhang, A., McAllister, R., Calandra, R., Gal, Y., and
Levine, S. Learning invariant representations for rein-
forcement learning without reconstruction. arXiv preprint
arXiv:2006.10742, 2020.

A. Denoised MDP Discussions

A.1. Loss Derivation

Denoised MDPs

To apply our mutual information regularizer I(x; s | a), we can consider a form using another variational distribution ρ
(see, e.g., Poole et al. (2019)),

I(x; s | a) = min

ρ EaEpθ(s|a) [DKL(pθ(x | s, a) (cid:107) ρ(x | a))]
ρ EaEqψ(s|a) [DKL(qψ(x | s, a) (cid:107) ρ(x | a))]

≈ min

= min

θ(cid:48)

LKL-x(ψ, θ(cid:48)).

(assume qψ is roughly the posterior of pθ)

(5)

The assumption that qψ is roughly the posterior of pθ is acceptable because it is the natural consequence of optimizing the
variational MLE objective in Equation (1) over θ, ψ.

Alternatively, we can consider the MI deﬁned by a joint conditional distribution P (x, s | a) not from the forward model pθ,
but from the data distribution and posterior model qψ(x | s, a). This is also sensible because the variational MLE objective
in Equation (1) optimizes for compatible pθ and qψ that both ﬁt data and consistently describe (conditionals of) the same
underlying distribution. Thus regularizing either can encourage a low MI. This approach leads to exactly Equation (5),
without approximation.

Then, the total loss in Equation (3) from combining Equations (1) and (5) is given by

min
θ

LMLE(θ) + c · I(x; s | a) = min
θ,θ(cid:48),ψ

Lrecon(θ, ψ) + LKL-x(θ, ψ) + LKL-y(θ, ψ) + LKL-z + c · +LKL-x(θ(cid:48), ψ)

= min
θ,ψ

Lrecon(θ, ψ) + (1 + c) · LKL-x(θ, ψ) + LKL-y(θ, ψ) + LKL-z(θ, ψ).

A.2. Discussions

We discuss some algorithmic choices of Denoised MDP below. Speciﬁc implementation details (e.g., architectures) can be
found at Appendix B.1.2.

Posterior distributions of rx and ry.
The pθ reward distributions pθ(rx | xt) and pθ(ry | yt) are modelled via Gaussians
(as is done usually in world models, such as Dreamer (Hafner et al., 2019a)). By the transition structure of Denoised MDPs,
these distributions are inherently independent. Recall that r = rx + ry. Therefore, we can easily compute the distribution of
pθ(r | xt, yt) and its log likelihoods. This enables easy optimization of the variational MLE objective, without requiring the
posterior model to also infer rx and ry from observed r subject to the addition relation.

Partial observability. Sections 2 and 3 discussions are mostly based in the fully observable setting. Yet most benchmarks
and real-world tasks are partially observable, e.g., robot joint speeds that can not be inferred from a single frame. Fortunately,
the transition models used in Denoised MDP are fully capable of handle such cases, as long as the encoder qψ is not
deterministic and the observation model pθ(s | . . . ) does not have the block structure (Du et al., 2019) (which would make
x, y, z fully determined from s). In practice, we let both components to be generic conditional distributions (parameterized
by regular deep neural networks). Therefore, Denoised MDP does not require full observability.

The loss in Equation (4) has two hyperparameters: α ∈ (0, ∞) and β ∈ (0, 1). To maintain
Hyperparameter choice.
relative ratio with the observation reconstruction loss, we recommend scaling α roughly proportionally with dimensionality
of the observation space, as is done in our experiments presented in this paper. A smaller β means stronger regularization.
Therefore, β can be chosen based on training stability and the level of noise distractors in the task.

B. Experiment Details

All code (including code for our environment variants and code for our Denoised MDP method) will be released upon
publication.

Denoised MDPs

Ctrl + Rew

Ctrl + Rew

Ctrl + Rew

Noiseless

Video Background

DMC

Video Background
+ Noisy Sensor

Video Background
+ Camera Jittering

Agent

Agent

Agent

Agent

—

—

—

—

—

—

Ctrl + Rew

—

Background

Background

—

—

Background,
Jittering camera

RoboDesk

Agent, Button,
Light on desk,
Green hue of TV

Blocks on desk,
Handle on desk,
Other movable objects

TV content,
Button sensor noise

Jittering and ﬂickering environment lighting,
Jittering camera

Table 2: Categorization of various information in the environments we evaluated with.

B.1. Implementation Details

B.1.1. ENVIRONMENTS AND TASKS

In all environments, trajectories are capped at 1000 timesteps. Table 2 shows a summary of what kinds of information exist
in each environment.

DeepMind Control Suite (DMC). Our Video Background implementation follows Deep Bisimulation for Control
(Zhang et al., 2020) on most environments, using Kinetics-400 grayscale videos (Smaira et al., 2020), and replacing pixels
where blue channel is strictly the greatest of three. This method, however, does not cleanly remove most of background in
the Walker Walk environment, where we use an improved mask that replaces all pixels where the blue channel is among the
greatest of three. For Camera Jittering, we shift the observation image according to a smooth random walk, implemented
as, at each step, Gaussian-perturbing acceleration, decaying velocity, and adding a pulling force if the position is too far away
from origin. For Sensor Noise, we select one sensor, and perturb it according to intensity of a patch of the natural video
background (i.e., adding average patch value − 0.5). We perturb the speed sensor for Cheetah Run, the torso_height
sensor for Walker Walk, and the normalized finger_to_target_dist sensor for Reacher Easy. These sensor values
undergo non-linear (mostly piece-wise linear) transforms to compute rewards. While they can not be perfectly modelled by
additive reward noise, such a model is usually sufﬁcient in most cases when the sensor values are not too extreme and stay
in one linear region.

RoboDesk. We modify the original RoboDesk environment by adding a TV screen and two neighboring desks. The TV
screen places (continuously horizontally shifting) natural RGB videos from the Kinetics-400 dataset (Smaira et al., 2020).
The environment has three light sources from the above, to which we added random jittering and ﬂickering. The viewing
camera is placed further to allow better view of the noise distractors. Resolution is increased from 64 × 64 to 96 × 96 to
compensate this change. Camera jittering is implemented by a 3D smooth random walk. Finally, the button sensor (i.e.,
detected value of how much the button is pressed) is also offset by a random walk. Each of the three button affects the
corresponding light on the desk. Additionally, pressing the green button also shifts the TV screen content to a green hue.
Following RoboDesk reward design, we reward the agent for (1) placing arm close to the button, (2) pressing the button, and
(3) how green the TV screen content is.

RoboDesk Joint Position Regression Datasets. To generate training and test set, we use four policies trained by state-
space SAC at different stages of training (which is not related to any of the compared methods) and a uniform random
actor, to obtain ﬁve policies of different qualities. For each policy, we sample 100 trajectories, each containing 1001 pairs
(from 1000 interactions) of image observation and groundtruth joint position (of dimension 9). This leads to a total of
500.5 × 103 samples from each policy. From these, 100 × 103 samples are randomly selected as test set. Training sets of
sizes 5 × 103, 10 × 103, 25 × 103, 50 × 103, 100 × 103, 150 × 103 are sampled from the rest. For all test sets and training
sets, we enforce each policy to strictly contribute an equal amount.

Denoised MDPs

Operator

Input
Shape

Kernel
Size

Stride

Padding

Operator

Input
Shape

Kernel
Size

Stride

Padding

Input

[3, 96, 96]

—

—

—

Input

[input_size]

Conv. + ReLU

[k, 47, 47]

Conv. + ReLU [2k, 22, 22]

Conv. + ReLU [4k, 10, 10]

Conv. + ReLU

Conv. + ReLU

[8k, 4, 4]

[8k, 2, 2]

4

4

4

4

3

2

2

2

2

1

0

0

0

0

0

Reshape + FC

[m]

—

—

—

FC + ReLU + Reshape

Conv. Transpose + ReLU

Conv. Transpose + ReLU

[m, 1, 1]

[4k, 3, 3]

[4k, 9, 9]

Conv. Transpose + ReLU

[2k, 21, 21]

Conv. Transpose + ReLU

Conv. Transpose + ReLU

[k, 46, 46]

[3, 96, 96]

—

—

5

5

5

6

6

—

—

2

2

2

2

2

—

—

0

0

0

0

0

Table 3: Encoder architecture for 96 × 96-resolution observa-
tion. The output of this encoder is then fed to other network
for inferring posteriors. m and k are two architectural hyper-
parameters. m controls the output size (unrelated to the actual
latent variable sizes). k controls the network width.

Table 4: Decoder architecture for 96 × 96-resolution observation. m
and k are two architectural hyperparameters. m controls width the fully
connected part. k controls width of the convolutional part. They are the
same values as in Table 3.

B.1.2. MODEL LEARNING METHODS

For all experiments, we let the algorithms use 106 environment steps. For PI-SAC and CURL, we follow the original
implementations (Laskin et al., 2020b; Lee et al., 2020) and use an action repeat of 4 for Cheetah Run and Reacher Easy,
and an action repeat of 2 for Walker Walk. For Denoised MDP, Dreamer, TIA and DBC, we always use an action repeat of
2, following prior works (Hafner et al., 2019a; Fu et al., 2021; Zhang et al., 2020).

Denoised MDP, Dreamer, and TIA. Both Dreamer and TIA use the same training schedule and the Recurrent State-Space
Model (RSSM) as the base architecture (Hafner et al., 2019b). Following them, Denoised MDP also uses these components,
and follow the same preﬁlling and training schedule (see Dreamer (Hafner et al., 2019b) for details). These three model
learning methods take in 64 × 64 RGB observations for DMC, and 96 × 96 RGB observations for RoboDesk. Dreamer only
implements encoder and decoder for the former resolution. To handle the increased resolution, we modify the 64 × 64
architectures and obtain convolutional encoder and decoder shown in Tables 3 and 4. For fair comparison, we ensure that
each method has roughly equal number of parameters by using different latent variable sizes, encoder output sizes (m of
Table 3) and convolutional net widths (k of Table 4). Details are shown in Table 5.

KL clipping (free nats). For Denoised MDP, we follow Dreamer (Hafner et al., 2019b;a) and TIA (Fu et al., 2021), and
allow 3 free nats for the LKL-x term. In other words, for each element of a batch, we do not optimize the KL term if it is less
than 3 (e.g., implemented via clipping). However, we do not allow this for the LKL-y and LKL-z terms, as these variables are
to be discarded and information is not allowed to hide in them unless permitted by the structure. An alternative strategy,
+ (1 − β) · LKL-x
which we ﬁnd also empirically effective, is to consider LKL-x = β · LKL-x
, and to allow free nats only for
(cid:124)
(cid:125)
(cid:123)(cid:122)
(cid:124)
(cid:125)
(cid:123)(cid:122)
VAE KL term
MI regularizer term

the ﬁrst term that is a part of the variational model ﬁtting objective. All results presented in this paper use the ﬁrst strategy.
Both strategies are implemented in our open source code repository: github.com/facebookresearch/denoised_mdp.

B.1.3. POLICY OPTIMIZATION ALGORITHMS USED WITH MODEL LEARNING

Backpropagate via Dynamics. We use the same setting as Dreamer (Hafner et al., 2019a), optimizing a λ-return over
15-step-long rollouts with λ = 0.95, clipping gradients with norm greater than 100. TIA uses the same strategy, except that
it groups different models together for gradient clipping. We strictly follow the ofﬁcial TIA implementation.

Latent-Space SAC. We use the regular SAC with automatic entropy tuning, without gradient clipping. This works well
for almost all settings, except for Walker Walk variant of DMC, where training often collapses after obtaining good return,
regardless of the model learning algorithm. To address instability in this case, we reduce learning rates from 3 × 10−4 to
1 × 10−4 and clip gradients with norm greater than 100 for all latent-space SAC run on these variants.

Denoised MDPs

DMC

RoboDesk

Latent Sizes

Dreamer
TIA
Denoised MDP

(220 + 33)
(120 + 20) + (120 + 20)
(120 + 20) + (120 + 20)

m

1024
490
1024

k

32
24
32

Total Number
of Parameters

Latent Sizes

7,479,789
7,475,567
7,478,826

(220 + 33)
(120 + 20) + (120 + 20)
(120 + 20) + (120 + 20)

m

1024
490
1024

k

32
24
32

Total Number
of Parameters

6,385,511
6,384,477
6,384,248

Table 5: The speciﬁc architecture parameters for model learning methods. Since RSSM uses a deterministic part and a stochastic part
to represent each latent variable, we use (deterministic_size + stochastic_size) to indicate size of a latent variable. TIA and
Denoised MDP have more than one latent variable. Note that while TIA has lower m and k, it has multiple encoder and decoders, whereas
Dreamer and Denoised MDP only have one encoder and one decoder. The total number of parameters is measured with the actor model,
but without any additional components from policy optimization algorithm (e.g., critics in SAC). Total number of parameters is lower for
RoboDesk as the encoder and decoder architecture is narrower than those of DMC for the purpose of reducing memory usage, despite
with a higher resolution.

B.1.4. MODEL-FREE METHODS

DBC. For DMC, we used 84 × 84-resolution observation following original work (even though other methods train on
64 × 64-resolution observations). For RoboDesk, DBC uses the encoder in Table 3 for 96 × 96-resolution observation,
for fair comparison with other methods. Following the original work, we stack 3 consecutive frames to approximate the
required full observability. In the robot arm joint position regression experiment Section 5.1, DBC encoders also see stacked
observations. For DMC evaluations, we use the data provided by Zhang et al. wherever possible, and run the ofﬁcial
repository for other cases.

State-Space SAC. The state space usually contains robot joint states, including position, velocity, etc. For DMC, when
Sensor Noise is present, this is not the true optimal state space, as we do not supply it with the noisy background that affects
the noisy reward. However, it still works well in practice. For RoboDesk, the TV’s effect on reward is likely stronger and
direct state-space SAC fails to learn. Since this evaluation is to obtain a rough “upper bound”, we train state-space SAC with
a modiﬁed reward with less noise— the agent is rewarded by pressing the button, independent of the TV content. This still
encourages the optimal strategy of the task allows achieving good policies.

B.1.5. NON-RL METHODS

Contrastive Learning. We used the Alignment+Uniformity contrastive learning loss from Wang & Isola (2020). The
hyperparameters and data augmentations strictly follow their experiments on STL-10 (Coates et al., 2011), which also is of
resolution 96 × 96. The exact loss form is Lalign(α = 2) + Luniform(t = 2), a high-performance setting for STL-10.

B.2. Compute Resources

All our experiments are run on a single GPU, requiring 8GB memory for DMC tasks, and 16GB memory for RoboDesk
tasks. We use NVIDIA GPUs of the following types: 1080 Ti, 2080 Ti, 3080 Ti, P100, V100, Titan XP, Titan RTX. For
MuJoCo (Todorov et al., 2012), we use the EGL rendering engine. Training time required for each run heavily depends on the
CPU speciﬁcation and availability. In general, a Denoised MDP run needs 12 ∼ 36 hours on DMC and 24 ∼ 50 hours on
RoboDesk. TIA uses about 1.5× of these times, due to the adversarial losses. For a comparison between the two Denoised
MDP variants, running the same DMC task on the same machine, the Figure 2b variant used 23 hours while the Figure 2c
variant used 26 hours.

B.3. Visualization Details

Visualizations of components in learned models. We use different methods to visualize signal and noise information
learned by TIA and Denoised MDP in Figures 4 and 7. For TIA, we used the reconstructions from the two latent (before
mask-composing them together as the full reconstruction). For Denoised MDP, we only have one decoder (instead of three
for TIA), and thus we decode (xt, const) and (const, yt) to visualize information contained in each variable, with const
chosen by visual clarity (usually as value of the other variable at a ﬁxed timestep). Due to the fundamental different ways to
obtain these visualizations, in DMC, TIA can prevent the agent from showing up in noise visualizations, while Denoised

Denoised MDPs

Figure 8: Effect of weight decay on RoboDesk joint position regres-
sion. The curves show ﬁnal test MSE for various training set sizes.
Weight decay generally helps when ﬁnetuning from a pretrained
encoder, but hurts when training from scratch.

Figure 9: Performance of all TIA settings on RoboDesk joint
position regression. Only using the signal encoder is necessary for
good performance.

Figure 10: Training curve comparisons for the RoboDesk joint position regression task across many training set sizes.

MDP cannot. However, as stated in Section 5.2, our focus should be on what evolves/changes in these images, rather
than what is visually present, as static components are essentially not modelled by the corresponding transition dynamics.
Visualizations in Figures 4 and 7 use trajectories generated by a policy trained with state-space SAC. To obtain diverse
behaviors, policy outputs are randomly perturbed before being used as actions. From the same trajectory, we use the above
described procedure to obtain visualizations. The speciﬁc used trajectory segments are chosen to showcase both the modiﬁed
environment and representative behavior of each method. Please see the supplementary video for clearer visualizations.

B.4. RoboDesk Result Details

Environment modiﬁcations. The agent controls a robotic arm placed in front of a desk and a TV, and is tasked to push
down the green button on the desk, which turns on a small green light and makes the TV display have a green hue. The
intensity of the TV image’s green channel is given to the agent as part of their reward, in addition to distance between
the arm to the button, and how much the button is pressed. Additionally, the environment contains other noise distractors,
including moveable blocks on the desk (Ctrl + Rew), ﬂickering environment light and camera jittering (Ctrl + Rew), TV
screen hue (Ctrl + Rew), TV content (Ctrl + Rew), and noisy button sensors (Ctrl + Rew).

RoboDesk has roughly twice as many pixels as DMC has. For Denoised MDP, we
Denoised MDP hyperparameters.
scale α with the observation space dimensionality (see Section 3) and use α = 2, with a ﬁxed β = 0.125. When using the
alternative KL free nats strategy discussed in Appendix B.1.2 (results not shown in paper), we ﬁnd α = 1 and β = 0.25 also
effective.

TIA hyperparameters. We follow recommendations in the TIA paper, setting λRadv = 25,000 to match reconstruction
loss in magnitude, and setting λOs = 2 where training is stable.

B.4.1. ROBOT ARM JOINT POSITION REGRESSION.

Training details. For this task, we jointly train the pre-trained backbone and a three-layer MLP head that has 256 hidden
units at each layer, with a learning rate of 8 × 10−5. For ﬁnetuning from pretrained encoders, we follow common ﬁnetuning
practice and apply a weight decay of 3 × 10−5 whenever it is helpful (all cases except CURL and training from scratch).

E
S
M

10 1

t
e
S

t
s
e
T

10 2

E
S
M

10 1

t
e
S

t
s
e
T

10 2

Denoised MDP

Dreamer

TIA

Contrastive

With Weight Decay
No Weight Decay

From Scratch

DBC
(Stacked Frames)

CURL
(Stacked Frames)

PI-SAC
without Augmentation
(Stacked Frames)

0.5

1.0

1.5

0.5

1.0

1.5

0.5

1.0

1.5

0.5

1.0

1.5

Training Set Size1e5

Training Set Size1e5

Training Set Size1e5

Training Set Size1e5

 
 
 
 
TIA

With Weight Decay + Only Signal Encoder
No Weight Decay + Only Signal Encoder
With Weight Decay + Both Encoders
No Weight Decay + Both Encoders

103

102

101

100

E
S
M

t
e
S

t
s
e
T

10 1

10 2

0.2

0.4

0.6
0.8
1.0
Training Set Size

1.2

1.4

1e5

 
 
Learning Curve for 104 Training Samples

Denoised MDP
TIA
Dreamer
Contrastive
From Scratch

0.25

0.24

0.23

0.22

0.21

0.20

0.19

0.18

0

20

40

60

80

100

Training Epoch

Learning Curve for 150 × 104 Training Samples

0.40

0.30

0.20

0.100
0.09

0

20

40

60

80

100

Training Epoch

Learning Curve for 50 × 104 Training Samples

0.24
0.22
0.20

0.18

0.16

0.14

0.12

0.100

0

20

40

60

80

100

Training Epoch

Learning Curve for 150 × 104 Training Samples

0.20

0.100
0.09
0.08
0.07
0.06
0.05

0.04

0

20

40

60

80

100

Training Epoch

Denoised MDPs

Figure 11: Performance comparison of ﬁnetuning from Denoised
MDP encoders and frame-stacked encoders that take in 3 consec-
utive frames. For Denoised MDP and training from scratch, the
encoders take in only a single frame and are applied for each of
the frame, with output concatenated together before feeding to the
prediction head.

Figure 12: Performance of all DBC settings on RoboDesk joint
position regression. Using the output features (after layer normal-
ization) is necessary for good performance.

Figure 13: Performance of all CURL settings on RoboDesk joint
position regression. Using the output features (after layer normal-
ization) is necessary for good performance.

Figure 14: Performance of all PI-SAC settings on RoboDesk joint
position regression. Using the activations before layer normaliza-
tion gives best performance.

See Figure 8 for comparisons for weight decay options over all methods.

• For model-based RL, we take encoders trained with backpropagating via dynamics as the policy optimization algorithm.
• In training the contrastive encoder, for a (more) fair comparison with RL-trained encoders that are optimized over 106
environment steps, we train contrastive encoders on 106 samples, obtained in the exact same method of the training sets
of this task. In a sense, these contrastive encoders have the advantage of training on the exact same distribution, and
seeing more samples (since RL-trained encoders use action repeat of 2 and thus only ever see 0.5 × 106 samples).

• TIA has two sets of encoders. Using concatenated latents from both unfortunately hurts performance greatly (see

Figure 9). So we use only the encoder for the signal latent.

We also compare training speeds over a wide range of training set sizes in Figure 10. Denoised MDP encoders lead to faster
and better training in all settings.

Additional comparison with frame-stacking encoders. Other pretrained encoders (DBC, CURL and PI-SAC) take in
stacked 3 consecutive frames, and are not directly comparable with the other methods. To compare, we also try running
Denoised MDP encoders on the 3 consecutive frames, whose feature vector is concatenated before feeding into the head.
The result in Figure 11 shows that our encoder outperforms all but PI-SAC encoders. Finally, for DBC, CURL and PI-SAC,
we attempted evaluating intermediate features, features before the ﬁnal layer normalization, and the output space, and ﬁnd
the last option best-performing for DBC and CURL, and the second option best-performing for PI-SAC (see Figures 12
to 14). Therefore, we use these respective spaces, which arguably gives a further edge to these methods, as we essentially
tune this additional option on test results. Notably, these respective choices are often the only one achieving relatively good
performance, highlighting the necessity of tuning for these methods.

10 1

E
S
M

t
e
S

t
s
e
T

10 2

Ours (Stacked Frames)
Ours (Single Frame)
DBC (Stacked Frames)
PI-SAC (Stacked Frames)
CURL (Stacked Frames)
From Scratch (Stacked Frames)

0.2

0.4

0.6
0.8
Training Set Size

1.0

1.2

1.4

1e5

 
 
DBC

With Weight Decay, Output Features
No Weight Decay, Output Features
With Weight Decay, No Layer Norm
No Weight Decay, No Layer Norm
With Weight Decay, Conv Features
No Weight Decay, Conv Features

103

102

101

100

E
S
M

t
e
S

t
s
e
T

10 1

0.2

0.4

0.6
0.8
1.0
Training Set Size

1.2

1.4

1e5

 
 
CURL

With Weight Decay, Output Features
No Weight Decay, Output Features
With Weight Decay, No Layer Norm
No Weight Decay, No Layer Norm
With Weight Decay, Conv Features
No Weight Decay, Conv Features

103

102

101

100

E
S
M

t
e
S

t
s
e
T

10 1

10 2

0.2

0.4

0.6
0.8
Training Set Size

1.0

1.2

1.4

1e5

 
 
PI-SAC

10 1

E
S
M

t
e
S

t
s
e
T

10 2

With Weight Decay, Output Features (Stacked Frames)
No Weight Decay, Output Features (Stacked Frames)
With Weight Decay, No Layer Norm (Stacked Frames)
No Weight Decay, No Layer Norm (Stacked Frames)
With Weight Decay, Conv Features (Stacked Frames)
No Weight Decay, Conv Features (Stacked Frames)

0.2

0.4

0.6
0.8
Training Set Size

1.0

1.2

1.4

1e5

 
 
B.5. DeepMind Control Suite (DMC) Result Details

Denoised MDPs

Full policy optimization results. Figure 15 presents the full results on each DMC environment (task + variant). For
environment, a comparison plot is made based on which policy learning algorithm is used with the model learning method
(with model-free baselines duplicated in both). Such separation is aimed to highlight the performance difference caused by
model structure (rather than policy learning algorithm). Across most noisy environments, Denoised MDP performs the best.
It also achieves high return on noiseless environments.

Visualization of learned models. Figure 16 is the extended version of Figure 7 in main text, with full reconstructions
from all three models. Please see the supplementary video for clearer visualizations.

Comparison between Denoised MDP variants. We compare the two Denoised MDP variants based Figures 2b and 2c
on Cheetah Run environments with policy trained by packpropagating via learned dynamics. The comparison is shown in
the top row of Figure 15, where we see the Figure 2b variant often performing a bit better. We hypothesize that this may due
to the more complex prior and posterior structure of Figure 2c, which may not learn as efﬁciently. This also makes Figure 2c
variant needing longer (wall-clock) time to optimize, as mentioned above in Appendix B.2.

TIA hyperparameters and instability. We strictly follow recommendations of the original paper, and use their suggested
value for each DMC task. We also note that TIA runs sometimes collapse during training, leading to sharp drops in rewards.
After closely inspecting the models before and after collapses, we note that in many cases, such collapses co-occur with
sudden spikes in TIA’s reward disassociation loss, which is implemented as an adversarial minimax loss, and the noise latent
space instantly becomes degenerate (i.e., not used in reconstruction). We hypothesize that this adversarial nature can cause
training instability. However, a few collapses do not co-occur with such loss spikes, which maybe alternatively due to that
TIA model structure cannot model the respective noise types and that better ﬁtting the model naturally means a degenerate
noise latent space.

PI-SAC hyperparameters. For each task, we use the hyperparameters detailed in the original paper (Lee et al., 2020).
PI-SAC is usually run with augmentations. However, unlike CURL, augmentation is not an integral part of the PI-SAC
algorithm and is completely optional. For a fair comparisons with other methods and to highlight the effect of the predictive
information regularizer, the main mechanism proposed by PI-SAC, we do not use augmentations for PI-SAC.

Denoised MDP hyperparameters. For DMC, we always use ﬁxed α = 1. β can be tune according to amount of noises in
environment, and to training stability. In Figure 17, we compare effects of choosing different β’s. On noiseless environments,
larger β (i.e., less regularization) performs often better. Whereas on noisy environments, sometimes stronger regularization
can boost performance. However, overall good performance can be obtained by usually several β values. In Table 6, we
summarize our β choices for each environment in Table 6.

Denoised MDPs

Figure 15: Policy optimization results on DMC. Each plot focuses on a single task variant, showing total episode return versus
environment steps taken. For three model-based approaches, we use two policy optimization choices to train on the learned model:
(top half) backpropagate via learned dynamics and (bottom half) SAC on the learned MDP. We also compare with DBC, a model-free
baseline. For an “upper bound” (not plotted due to presentation clarity), SAC on true state-space (i.e., optimal representation) in 106
environment steps reaches episode return ≈ 800 on Cheetah Run variants, ≈ 980 on Walker Walk variants, and ≈ 960 on Reacher Easy
variants. CURL’s speciﬁc augmentation choice (random crop) potentially helps signiﬁcantly for Reacher Easy (where the reacher and the
target appear in random spatial locations) and Camera Jittering. However, unlike Denoised MDP, it does not generally perform well
across all environments and noise variants.

n
o

i
t
a
z
i
m

i
t
p
O
y
c
i
l

o
P

e
t
a
g
a
p
o
r
p
k
c
a
B

s
c
i
m
a
n
y
D
a
v

i

n
o

i
t
a
z
i
m

i
t
p
O
y
c
i
l

o
P

)
e
c
a
p
S
-
t
n
e
t
a
L
(
C
A
S

 
 
 
 
 
 
Denoised MDPs

Figure 16: Complete visualization of the different DMC variants and factorizations learned by TIA and Denoised MDP. In addition to
visualizations of Figure 7, we also visualize full reconstructions from Dreamer, TIA, and Denoised MDP.

Cheetah Run
Noiseless

Reacher Easy
Video Background

Walker Walk
Video Background
+ Noisy Sensor

Cheetah Run
Video Background
+ Camera Jittering

Env. 
Rollout

Obs.

Reward

Dreamer

Recon.

Recon.

TIA

Signal

Noise

Recon.

Denoised
MDP

Signal

Noise

Denoised MDPs

Figure 17: Effect of choosing β in Denoised MDP on DMC policy optimization results. Setting β = 1 disables regularization and is only
run on noiseless variants.

Noiseless Video Background

Video Background
+ Noisy Sensor

Video Background
+ Camera Jittering

Policy Learning:
Backprop via Dynamics

Policy Learning:
SAC (Latent-Space)

Cheetah Run

Walker Walk

Reacher Easy

Cheetah Run

Walker Walk

Reacher Easy

1

1

1

1

1

1

0.125

0.25

0.25

0.125

0.25

0.125

0.25

0.25

0.25

0.125

0.125

0.25

0.25

0.5

0.25

0.25

0.5

0.25

Table 6: β choices for Denoised MDP results shown in Table 1 and Figure 15. We choose β = 1 (i.e., disabling regularization) for all
noiseless environments, and tuned others. However, as seen in Figure 17, the results often are not too sensitive to small β changes.

n
o

i
t
a
z
i
m

i
t
p
O
y
c
i
l

o
P

e
t
a
g
a
p
o
r
p
k
c
a
B

s
c
i
m
a
n
y
D
a
v

i

n
o

i
t
a
z
i
m

i
t
p
O
y
c
i
l

o
P

)
e
c
a
p
S
-
t
n
e
t
a
L
(
C
A
S

 
 
 
 
 
 
","Denoised MDPs: Learning World Models Better Than the World Itself Tongzhou Wang 1 Simon S. Du 2 Antonio Torralba 1 Phillip Isola 1 Amy Zhang 3 4 Yuandong Tian 4 2 2 0 2 l u J 1 ] G L . s c [ 2 v 7 7 4 5 1 . 6 0 2 2 : v i X r a Abstract The ability to separate signal from noise, and reason with clean abstractions, is critical to in- telligence. With this ability, humans can efﬁ- ciently perform real world tasks without consider- ing all possible nuisance factors. How can artiﬁ- cial agents do the same? What kind of information can agents safely discard as noises? In this work, we categorize information out in the wild into four types based on controllability and relation with reward, and formulate useful information as that which is both controllable and reward-relevant. This framework clariﬁes the kinds information removed by various prior work on representation learning in reinforcement learning (RL), and leads to our proposed approach of learning a Denoised MDP that explicitly factors out certain noise dis- tractors. Extensive experiments on variants of DeepMind Control Suite and RoboDesk demon- strate superior performance of our denoised world model over using raw observations alone, and over prior works, across policy optimization con- trol tasks as well as the non-control task of joint position regression. ssnl.github.io/denoised_mdp Project Page: Code: github.com/facebookresearch/denoised_mdp 1. Introduction The real world provides us a plethora of information, from microscopic physical interactions to abstracted semantic signals such as the latest COVID-19 news. Fortunately, processing each and every signal is unnecessary (and also impossible). In fact, any particular reasoning or decision often only relies on a small portion of information. Imagine waking up and wanting to embrace some sunlight. As you open the curtain, a nearby resting bird is scared 1MIT CSAIL 2University of Washington 3UC Berkeley 4Meta AI. Correspondence to: Tongzhou Wang <tongzhou@mit.edu>. Work done while Tongzhou Wang was an intern at Meta AI. Proceedings of the 39 th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy- right 2022 by the author(s). Figure 1: Illustrative example: (a) Four distinct kinds of infor- mation in the scenario described in Section 1, where the person desires to increase the amount of sunlight let into the room. Their opening of the curtain scares away the bird. (b) A denoised world model only includes a small subset of all information. away and you are pleasantly met with a beautiful sunny day. Far away, a jet plane is slowly ﬂying across the sky. This may seem a simple activity, but in fact highlights four distinct types of information (see Figure 1), with respect to the goal of letting in as much sunlight as possible: • Controllable and reward-relevant: curtain, inﬂuenced by actions and affecting incoming sunlight; • Controllable and reward-irrelevant: bird, inﬂuenced by actions but not affecting sunlight; • Uncontrollable and reward-relevant: weather, inde- pendent with actions but affecting sunlight; • Uncontrollable and reward-irrelevant: plane, indepen- dent with both actions and the sunlight. Our optimal actions towards the goal, however, only in fact depend on information that is controllable and reward- Reward- Relevant Reward- Irrelevant Uncontrollable Controllable (a) GOAL: Letting in as much sunlight as possible. Denoise (b) Optimal control only relies on information that is both controllable and reward-relevant. Good world models should ignore other factors as noisy distractors. Denoised MDPs relevant, and the three other kinds of information are merely noise distractors. Indeed, no matter how much natural sunlight there is outside, or how the plane and the bird move, the best plan is always to open up the curtain. When performing a particular task, we humans barely think about the other three types of information, and usually only plan on how our actions affect information that is control- lable and reward-relevant. Our mental model is an ab- stract and condensed version of the real world that is actually better suited for the task. The notion of better model/data is ubiquitous in data science and machine learning. Algorithms rarely perform well on raw noisy real data. The common approach is to perform data cleaning and feature engineering, where we manually select the useful signals based on prior knowledge and/or heuristics. Years of research have identiﬁed ways to extract good features for computer vision (Lowe, 1999; Donahue et al., 2014), natural language processing (Elman, 1990; Mikolov et al., 2013), reinforcement learning (RL) (Ma- hadevan & Maggioni, 2007; Bellemare et al., 2019), etc. Similarly, system identiﬁcation aligns real observation with a predeﬁned set of abstract signals/states. Yet for tasks in the wild (in the general form of (partially observable) Markov Decision Processes), there can be very little prior knowledge of the optimal set of signals. In this work, we ask: can we infer and extract these signals automatically, in the form of a learned world model? The general idea of a mental world model have long been un- der active research in philosophy and social science (Craik, 1952; Dennett, 1975), cognitive science, where an intuitive physics model is hypothesized to be core in our planning capabilities (Spelke & Kinzler, 2007), and in reinforcement learning, where various methods investigate state abstrac- tions for faster and better learning (Sutton, 1991; 1981). In this work, we explore this idea within the context of machine learning and reinforcement learning, where we aim to make concrete the different types of information in the wild, and automatically learn a world model that removes noise distractors and is beneﬁcial for both control (i.e., policy optimization) and non-control tasks. Toward this goal, our contributions are • We categorize information into four distinct kinds as in Figure 1, and review prior approaches under this frame- work (Section 2). • Based on the above framework, we propose Denoised MDPs, a method for learning world models with certain distractors removed (Section 3). • Through experiments in DeepMind Control Suite and RoboDesk environments, we demonstrate superior per- formance of policies learned our method, across many distinct types of noise distractors (Sections 5.1 and 5.2). • We show that Denoised MDP is also beneﬁcial beyond control objectives, improving the supervised task of robot joint position regression (Section 5.1). 2. Different Types of Information in the Wild In Section 1, we illustrated the four types of information available in the wild w.r.t. a task. Here we make these notions more concrete, and relate them to existing works. For generality, we consider tasks in the form of Markov Decision Processes (MDPs), described in the usual manner: M (cid:44) (S, A, R, P, ps0 ) (Puterman, 1994), where S is the state space, A is the action space, R : S → ∆([0, rmax]) deﬁnes the reward random variable R(s(cid:48)) received for ar- riving at state s(cid:48) ∈ S, P : S × A → ∆(S) is the transition dynamics, and ps0 ∈ ∆(S) deﬁnes the distribution of initial state. We use ∆(A) to denote the set of all distributions over A. P and R deﬁne the most important components of a MDP: the transition dynamics P[s(cid:48) | s, a] and the re- ward function P[r | s(cid:48)]. Usually, the objective is to ﬁnd a policy π : S → ∆(A) acting based on current state, that maximizes the expected cumulative (discounted) reward. Indeed, MDPs provide a general formulation that encom- passes many tasks. In fact, the entire real world may be viewed as an MDP with a rich state/observation space S that contains all possible information/signal. For an artiﬁ- cial agent to successfully perform real world tasks, it must be able to process observations that are incredibly rich and high-dimensional, such as visual or audio signals. We characterize different types of information in such ob- servations by considering two intuitive notions of “noisy and irrelevant” signals: (1) uncontrollable information and (2) reward-irrelevant information. Such factors can often be ignored without affecting optimal control, and are referred to as noise distractors. To understand their roles in MDPs, we study different for- mulations of the transition dynamics and reward functions, and show how different structures naturally leads to decom- positions that may help identify such distractors. Removing these distractors can thus transform the original noisy MDP to a clean denoised one, to be used in downstream tasks. For starters, the most generic transition model in Figure 2a has little to no structure. The state s can contain both the useful signals and noise distractors. Therefore, it is not directly useful for extracting important information. 2.1. Controllability Intuitively, if something is not controllable, an agent might be able to do well without considering it. Yet it is not enough to only require some variable to be unaffected by actions (e.g., wind directions should not be ignored while sailing). Denoised MDPs a a a a r Rew Rew Ctrl s s(cid:48) Ctrl s s s s x yR yR s x(cid:48) y(cid:48) R y(cid:48) R s(cid:48) rx ry + r Rew Rew Ctrl x yR yR x yR yR Ctrl x yR yR x yR yR x y z s x(cid:48) y(cid:48) z(cid:48) s(cid:48) rx ry + r Rew Rew Ctrl Ctrl x y x y z z x y x y z z (b) Transition that factorizes out uncontrol- lable information in yR and yR. (a) Transition without useful structure. s may contain any type of information. Figure 2: MDP transition structures consisting of dynamics and reward functions. Unlike the regular structure of (a), (b, c) factorized (yet still general) structures inherently separate information into controllable (Ctrl) versus uncontrollable (Ctrl), and reward-relevant (Rew) versus reward-irrelevant (Rew). Presence of a variable in a cell means possible containing of respective information. E.g., in (c), z can only contain reward-irrelevant information. In (b, c), the x dynamics form an MDP with less noise and sufﬁcient for optimal planning. Our Denoised MDP (see Section 3) is based on these two factorizations. (c) Transition that factorizes out uncontrol- lable y and reward-irrelevant z. Instead, we focus on factors that simply evolve on their own, without inﬂuencing or being inﬂuenced by others. Not all such information can be safely ignored, as they still may affect reward (e.g., trafﬁc lights when driving). Fortunately, in the usual objective of maximizing expected return, we can ignore ones that only additively affect reward. Concretely, if an MDP transition can be represented in the form of Figure 2b, we say variables yR and yR are uncontrol- lable information, as they evolve independently of actions and do not affect controllable x. Here yR (additively) af- fects reward, but can be ignored. One can safely discard both yR and yR as noise distractors. Operating with the compressed MDP of only x is sufﬁcient for optimal control. 2.2. Reward-Relevance Among controllable information, there can still be some that is completely unrelated to reward. In Figure 1, the bird is affected by the opening curtain, but is irrelevant to the task of letting in sunlight. In such cases, the information can be safely discarded, as it does not affect the objective. If an MDP transition can be represented in the form of Figure 2c, we say z is reward-irrelevant because it evolves by potentially using everything (i.e., all latent variables and actions), but crucially does not affect anything but itself. Similar to uncontrollable information, z (and y) is a noise distractor that can be discarded. The compressed MDP of only x contains all signals needed for optimal control. 2.3. Which Information Do Existing Methods Learn? In RL, many prior work have explored state abstractions in some form. Here we cast several representative ones under Reconstruction-Based Model-Based RL (e.g., SLAC (Lee et al., 2019), Dreamer (Hafner et al., 2019a)) Model-Based Bisimulation (e.g., Ferns et al. (2004), Castro (2020), Zhang et al. (2020)) Model-Free Task Informed Abstractions (TIA) (Fu et al., 2021) Model-Based Denoised MDP (Figure 2b variant) (Our method from Section 3) Model-Based Denoised MDP (Figure 2c variant) (Our method from Section 3) Model-Based RewRew (cid:51) (cid:51) (cid:51) (cid:51) Ctrl Ctrl RewRew (cid:51) (cid:55) (cid:51) (cid:55) Ctrl Ctrl RewRew (cid:51) ? (cid:51) ? RewRew (cid:51) (cid:51) (cid:55) (cid:55) RewRew (cid:51) (cid:55) (cid:55) (cid:55) Ctrl Ctrl Ctrl Ctrl Ctrl Ctrl Information Grid Legend: (cid:51) Kept (cid:55) Reduced ? Depending on how the information is integrated in observations Figure 3: Categorization of information learned and removed by various methods with distinct formulations. the framework described above, and show which kinds of information they learn to remove, summarized in Figure 3, together with our proposed method (explained in Section 3). Below we discuss each prior work in detail. Reconstruction-Based Model-Based RL. Many model- based RL methods learn via reconstruction from a single latent code, often as a result of a variational formulation (Hafner et al., 2019a;b; Lee et al., 2019). The latent code Denoised MDPs must try to compress all information present in the observa- tion, and necessarily contains all types of information. Bisimulation. Bisimulation deﬁnes a state abstraction where states aggregated together must have the same ex- pected return and transition dynamics up to the abstrac- tion (Givan et al., 2003), and is known to optimally ignore reward-irrelevant information (Ferns et al., 2004). While its continuous version, bisimilation metric, is gaining popular- ity, learning them is computationally difﬁcult (Modi et al., 2020). Even with many additional assumptions, it is gen- erally only possible to learn an on-policy variant that loses the above guarantee (Castro, 2020; Zhang et al., 2020). Task Informed Abstractions (TIA). TIA (Fu et al., 2021) extends Dreamer by modelling two independent la- tent MDPs, representing signal and noise. The noise latent is enforced to be independent with reward and reconstruct the observation as well as possible. Reconstructions from each latent are composed together using an inferred mask in pixel-space, to form the full reconstruction for the re- construction loss. Because of its special structure, TIA can remove reward-irrelevant noise distractors that are present via pixel-wise composing two images from independent processes (e.g., agent moving on a noisy background), but not general ones (e.g., a shaky camera affecting both the agent and the noisy background). Predictive Information, Data Augmentation, etc. An- other set of researches learn state representation that only contains information useful for predicting future states (e.g., CPC (Oord et al., 2018) and PI-SAC (Lee et al., 2020)) or augmented views of the current state (e.g., CURL (Laskin et al., 2020b)). These methods do not guarantee removal of any of the three redundant piece of information identiﬁed above. Non-i.i.d. noises (e.g., people moving in background) are predictive of future and may be kept by CPC and PI- SAC. The performance of augmentation-based methods can critically rely on speciﬁc types of augmentation used and relevance to the tasks. As we show in experiments (see Sec- tion 5), indeed they struggle to handle certain noise types. 2.4. Possible Extensions to Further Factorizations The above framework is sufﬁcient for characterizing most prior work and related tasks, and can also be readily ex- tended with further factorized transition structures. E.g., if an independent process confounds a signal process and a noise process, ﬁtting the Figure 2c structure must group all three processes into x (to properly model the dependencies). However, a further factorization shows that only considering the signal and the confounding processes is theoretically sufﬁcient for control. We leave such extensions as future work. 3. Denoised MDPs Figures 2b and 2c show two special MDP structures that au- tomatically identify certain information that can be ignored, leaving x as the useful information (which also forms an MDP). This suggests a naïve approach: directly ﬁtting such structures to collected trajectories, and then extract x. However, the same MDP dynamics and rewards can be decomposed as Figures 2b and 2c in many different ways. In the extreme case, x may even contain all information in the raw state s, and such extraction may not help at all. Instead, we desire a ﬁt with the minimal x, deﬁned as being least informative of s (so that removal of the other latent variables discards the most information possible). Concretely, we aim for a ﬁt with least I({xt}T t=1), the mutual information x contains about s over T steps. Then from this ﬁt, we can extract a minimal Denoised MDP of only x. For notation simplicity, we use bold symbols to denote variable sequences, and thus write, e.g., I(x; s | a). t=1 | {at}T t=1; {st}T Practically, we consider regularizing model-ﬁtting with I(x; s | a). As we show below, this amounts to a modiﬁ- cation to the well-established variational objective (Hafner et al., 2019a). The resulting method is easy-to-implement yet effective, enabling clean removal of various noise distrac- tors the original formulation cannot handle (see Section 5). We instantiate this idea with the structure in Figure 2c. The Figure 2b formulation can be obtained by simply removing the z components and viewing y as combined yR and yR. The transition structure is modeled with components: p(xt) θ p(yt) θ p(zt) θ (cid:44) pθ(xt | xt−1, a) pθ(rx | xt) (cid:44) pθ(yt−1 | yt−1) pθ(ry | yt) (x dynamics) (x reward) (y dynamics) (y reward) (cid:44) pθ(zt | xt, yt, zt−1, a) pθ(st | xt, yt, zt). (z dynamics) (obs. emission) Consider training data in the form of trajectory segments s, a, r sampled from some data distribution pdata (e.g., stored agent experiences from a replay buffer). We perform model learning by minimizing the negative log likelihood: LMLE(θ) (cid:44) −Es,a,r∼pdata (cid:2) log pθ (s, r | a) (cid:3). To obtain a tractable form, we jointly learn three variational posterior components (i.e., encoders): q(xt) ψ q(yt) ψ q(zt) ψ (cid:44) qψ(xt | xt−1, yt−1, zt−1, st, at) (x posterior) (cid:44) qψ(yt | xt−1, yt−1, zt−1, st, at) (y posterior) (cid:44) qψ(zt | xt, yt, st, at), (z posterior) Denoised MDPs whose product deﬁnes the posterior qψ(x, y, z | s, a)1. We choose this factorized form based on the forward (prior) model structure of Figure 2c. Then, the model can be optimized w.r.t. the standard varia- tional bound on log likelihood: (cid:20) LMLE(θ) = min ψ Es,a,r Ex,y,z∼ qψ (·|s,a,r) − log pθ(s, r | x, y, z, a) (cid:124) (cid:123)(cid:122) (cid:125) (cid:44) Lrecon(θ, ψ) T (cid:88) DKL (cid:0)q(yt) ψ (cid:13) (cid:13) p(yt) θ DKL (cid:0)q(xt) ψ (cid:13) (cid:13) p(xt) θ (cid:1) + (cid:123)(cid:122) (cid:44) LKL-x(θ, ψ) (cid:0)q(zt) DKL ψ (cid:13) (cid:13) p(zt) θ (cid:123)(cid:122) (cid:44) LKL-z(θ, ψ) t=1 (cid:124) (cid:123)(cid:122) (cid:44) LKL-y(θ, ψ) (cid:125) (cid:1) (cid:125) (cid:21) , (cid:1) (cid:125) (1) + + T (cid:88) t=1 (cid:124) T (cid:88) t=1 (cid:124) where equality is attained by optimal qψ that is compatible with pθ, i.e., qψ is the exact posterior of pθ. The mutual information regularizer I(x; s | a), using a variational formulation, can be written as I(x; s | a) = min θ LKL-x(θ, ψ), (2) with equality attained when qψ and pθ are compatible. The appendix describes this derivation in detail. Therefore, for a regularizer weight of c ≥ 0, we can opti- mize Equations (1) and (2) together as min θ = min θ,ψ LMLE(θ) + c · I(x; s | a) Lrecon(θ, ψ) + (1 + c) · LKL-x(θ, ψ) + LKL-y(θ, ψ) + LKL-z(θ, ψ). (3) Recall that we ﬁt to the true MDP with the structure of Fig- ure 2c, which inherently guarantees all useful information in the x latent variable. As the regularizer ensures learning the minimal x latents, the learned model extracts an MDP of condensed useful information with X as the denoised state space, pθ(x(cid:48) | x, a) as the transition dynamics, pθ(rx | x(cid:48)) as the reward function. This MDP is called the Denoised MDP, as it discards the noise distractors contained in y and z. Additionally, we also obtain qψ(x | s, a) as the encoder mapping from raw noisy observation s to the denoised x. A loss variant for improved stability. When using a large c ≥ 0 (e.g. when the environment is expected to be very noisy), Equation (3) contains to a term with a large weight. Thus Equation (3) often requires learning rates to be tuned for different c. To avoid this, we use the following loss form that empirically has better training stability and does not require tuning learning rates w.r.t. other hyperpa- 1Following Dreamer (Hafner et al., 2019a), we deﬁne pos- terior of ﬁrst-step latents qψ(x1, y1, z1 | s1) (cid:44) qψ( · , · , · | 0, 0, 0, s1, 0), where 0 is the all zeros vector of appropriate size. Algorithm 1 Denoised MDP Input: Model pθ. Posterior encoder qψ. Policy π : X → ∆(A). Policy optimization algorithm PI-OPT. Output: Denoised MDP of x in pθ; Encoder qψ; Policy π. 1: while training do // Exploration 2: Collect trajectories with π acting on qψ encoded outputs 3: // Model learning 4: Sample a batch of (s, a, r) segments from reply buffer 5: Train pθ and qψ with Equation (4) on (s, a, r) 6: // Policy optimization 7: Sample x ∼ qψ(x | s, a); Compute rx = E [pθ(rx | x)] 8: Train π by running PI-OPT on (x, a, rx) 9: 10: end while rameters: min θ,ψ Lrecon + α · (LKL-x + βLKL-y + βLKL-z) , (4) where θ, ψ in arguments are omitted, and the hyperparame- ters are α > 0 and 0 < β ≤ 1. Here β is bounded, where β = 1 represents no regularization. α is also generally small and simply chosen according to the state-space dimensional- ity (see the appendix; α ∈ {1, 2} in our experiments). This form is justiﬁed from the observation that in practice we use isotropic Gaussians with ﬁxed variance to parameter- ize the distributions of observation pθ(s | . . . ) and reward pθ(r | . . . ), where scaling log likelihoods is essentially changing the variance hyperparameter. Thus, Equation (4) is effectively a scaled Equation (3) with different variance hyperparameters. Online algorithm with policy optimization. The model ﬁtting objective of Equation (4) can be used in various set- tings, e.g., ofﬂine over a collected trajectory dataset. With- out assuming existing data, we explore an online setting, where the training process iteratively performs (1) explo- ration, (2) model-ﬁtting, and (3) policy optimization, as shown in Algorithm 1. The policy π : X → ∆(A) soley operates on the Denoised MDP of x, which has all infor- mation sufﬁcient for control. For policy optimization, the learned posterior encoder qψ(x | s, a) is used to extract x information from the raw trajectory (s, a, r), obtaining transition sequences in X space. Paired with the pθ(rx | x) rewards, we obtain (x, a, rx) as trajectories collected from the Denoised MDP on x. Any general-purpose MDP policy optimization algorithm may be employed on these data, such as Stochastic Actor-Critic (SAC) (Haarnoja et al., 2018). We can also utilize the learned differentiable Denoised MDP, e.g., optimizing policy by backpropagating through addi- tional roll-outs from the model, as is done in Dreamer. While presented in the fully observable setting, Denoised MDP readily handles partial observability without extra changes. In the appendix, we discuss this point in details, and provide a guideline for choosing hyperparameters α, β. Denoised MDPs 4. Related Work Model-Based Learning for Control jointly learns a world model and a policy. Such methods often enjoy good sample efﬁciency on RL tasks with rich observations. Some formulations rely on strong assumptions, e.g., determinis- tic transition in DeepMDP (Gelada et al., 2019) and bilin- ear transition in FLAMBE (Agarwal et al., 2020). Most general-setting methods use a reconstruction-based objec- tive (Hafner et al., 2019b; Kim et al., 2020; Ha & Schmidhu- ber, 2018; Lee et al., 2019). Among them, Dreamer (Hafner et al., 2019a) trains world models with a variational formu- lation and optimizes policies by backpropagating through latent-space rollouts. It has proven effective across a va- riety of environments with image observations. However, such reconstruction-based approaches can struggle with the presence of noise distractors. TIA (Fu et al., 2021) partially addresses this limitation (see Section 2.3) but can not handle general distractors, unlike our method. Representation Learning and Reinforcement Learning. Our work automates selecting useful signals from noisy MDPs by learning denoised world models, and can be viewed as an approach for learning general representations (Donahue et al., 2014; Mikolov et al., 2013; He et al., 2019; Huh et al., 2016). In model-free RL, various methods learn state embeddings that are related to value functions (Schaul et al., 2015; Bellemare et al., 2019), transition dynamics (Mahadevan & Maggioni, 2007; Lee et al., 2020), recent ac- tion (Pathak et al., 2017), bisimulation structure (Ferns et al., 2004; Castro, 2020; Zhang et al., 2020), data augmentations (Laskin et al., 2020b) etc. Recently, Eysenbach et al. (2021) proposes a regularizer similar to ours but for the different purpose of robust compressed policies. The theoretical work by Efroni et al. (2021) is closest to our setting but concerns a more restricted set of distractors (ones both uncontrollable and reward-irrelevant). Unlike Denoised MDP, their pro- posed algorithm is largely impractical and does not produce a generative model of observations (i.e., no decoder). System Identiﬁcation. Our work is related to system identiﬁcation, where an algorithm infers from real world an abstract state among a predeﬁned limited state space, e.g., pose estimation (Rıza Alp Güler, 2018; Yen-Chen et al., 2021) and material estimation (Hahn et al., 2019). Such results are useful for robotic manipulation (Manuelli et al., 2019), image generation (Gu et al., 2019), etc. Our setting is not limited to a predeﬁned abstract state space, but instead focuses on automatic discovery of such valuable states. 5. Experiments In this section, we contrast our method with existing ap- proaches on environments with image observations and many distinct types of noise distractors. Our experiments are designed to include a variety of noise distractors and to conﬁrm our analysis on various methods in Section 2.3. Environments. We choose DeepMind Control (DMC) Suite (Tunyasuvunakool et al., 2020) (Section 5.2) and RoboDesk (Kannan et al., 2021) (Section 5.1) with image observations, where we explore adding various noise dis- tractors. Information types in all evaluated environments are categorized in Table 2 of the appendix. Tasks include control (policy optimization) and a non-control task of regressing robot joint position from RoboDesk image observations. Methods. We compare not only model-based RL meth- ods, but also model-free algorithms and general representa- tion learning approaches, when the task is suited: • Model Learning: Denoised MDP (our method), Dreamer (Hafner et al., 2019a), and TIA (Fu et al., 2021); • Model-Free: DBC (Zhang et al., 2020), CURL (Laskin et al., 2020b), PI-SAC (Lee et al., 2020) (without data augmentation for a fair comparison of its core predictive information regularization against other non-augmenting methods), and SAC on true state-space (Haarnoja et al., this is 2018) (instead of using image observations, roughly an “upper bound”); • General Image Representation Learning for Non- Control Tasks: Contrastive learning with the Align- ment+Uniformity loss (Wang & Isola, 2020) (a form of contrastive loss theoretically and empirically comparable to the popular InfoNCE loss (Oord et al., 2018)). Model-learning methods can be used in combination with any policy optimization algorithm. For a complete com- parison for general control, we compare the models trained with these two policy learning choices: (1) backpropagating via the learned dynamics and (2) SAC on the learned la- tent space (which roughly recovers SLAC (Lee et al., 2019) when used with an unfactorized model such as Dreamer). Most compared methods do not apply data augmentations, which is known to strongly boost performance (Yarats et al., 2021; Laskin et al., 2020a). Therefore, for a fair comparison, we run PI-SAC without augmentation to highlight its main contribution—representation of only predictive information. All results are aggregated from 5 runs, showing mean and standard deviations. The appendix contains more details, hyperparameter studies, and additional results. Our website presents videos showing clearer video visualizations. For Denoised MDP, we use the Figure 2b variant. Empiri- cally, the Figure 2c variant leads to longer training time and sometimes inferior performance (perhaps due to having to optimize extra components and ﬁt a more complex model). The appendix provides a comparison between them. Denoised MDPs Figure 4: Visualization of learned models for RoboDesk by using decoders to reconstruct from encoded latents. For TIA and Denoised MDP, we visualize how they separate information as signal versus noise. In each row, what changes over frames is the information modeled by the corresponding latent component. E.g., in the bottom row, only the TV content, camera pose and lighting condition change, so Denoised MDP considers these factors as noises, while modelling the TV hue as signal. See our website for clearer video visualizations. 5.1. RoboDesk with Various noise distractors We augment RoboDesk environment with many noise dis- tractors that models realistic noises (e.g., ﬂickering lights and shaky camera). Most importantly, we place a large TV in the scene, which plays natural RGB videos. A green button on the desk controls the TV’s hue (and a light on the desk). The agent is tasked with using this button to shift the TV to a green hue. Its reward is directly affected by how green the TV image is. The ﬁrst row of Figure 4 shows a trajectory with various distractors annotated. All four types of information exist (see Table 2), with the controllable and reward-relevant information being the robot arm, the green button, the light on the desk, and the TV screen green-ness. controllable and reward-relevant information as signals— the Signal row only tracks changes in robot arms, green button and light, and the TV screen green-ness. All other information is modeled as noises (see the Noise row). We recommend viewing video visualizations on our website. Denoised models improve policy learning. Figure 4 also shows the total episode return achieved by policies learned with each of the three models, where the cleanest model from Denoised MDP achieves the best performance. Aggregating over 5 runs, the complete comparison in Fig- ure 5 shows that Denoised MDP (with backpropagating via dynamics) generally outperforms all baselines, suggesting that its clean models are helpful for control. Only Denoised MDP learns a clean denoised model. Using learned decoders, Figure 4 visualizes how the mod- els captures various information. As expected, Dreamer model captures all information. TIA also fails to separate any noise distractors out (the Noise row fails to capture anything), likely due to its limited ability to model differ- ent noises. In contrast, Denoised MDP cleanly extracts all Denoised models beneﬁt non-control tasks. We evalu- ate the learned representations on a supervised non-control task—regressing the robot arm joint position from observed images. Using various pretrained encoders, we ﬁnetune on a labeled training set, and measure mean squared error (MSE) on a heldout test set. In addition to RL methods, we compare encoders learned via general contrastive learning Blocks on Desk: Ctrl & Rew TV Image Green-ness: Ctrl & Rew Green Button & Light: Ctrl & Rew Robot Joints: Ctrl & Rew TV Semantic Content: Ctrl & Rew Shaky/Flickering Camera & Lights: Ctrl & Rew Env. Rollout Obs. Reward <latexit sha1_base64=""2Iv/3i2hbQBcJJvODDrynrkogxE="">AAACaHicjVHLSgMxFE3Hd321uhBxEyyCLiwzoqgLQRTBpYJVoR0kk96xwSQzJHekZZgP8Gvc6qf4C36Fae1CrYIXAodzziU5J1EqhUXffyt5Y+MTk1PTM+XZufmFxUp16dommeHQ4IlMzG3ELEihoYECJdymBpiKJNxED6d9/eYRjBWJvsJeCqFi91rEgjN01F2lttlSDDtRlJ8VzRZCF22cG8DM6CKkR3QvONxyLr/uD4aOgmAIamQ4F3fV0narnfBMgUYumbXNwE8xzJlBwSUU5VZmIWX8gd1D00HNFNgwH6Qp6IZj2jROjDsa6YD9upF3/2tkytqeipyzn9H+1PrkXxp21G9SM8P4IMyFTjMEzT/fEGeSYkL79dK2MMBR9hxg3AiXl/IOM4yj+4Rvl1irpXKexBau4OBnnaPgeqce7NX9y93a8cmw6mmyRtbJJgnIPjkm5+SCNAgnT+SZvJDX0rtX8Va81U+rVxruLJNv461/AAe3u44=</latexit> Dreamer (E[return] = 519) Recon. Recon. <latexit sha1_base64=""detSQHFar06ldxZUdWoplWvpw3s="">AAACaHicjVHLSgMxFE3H97vVhYibYBF0YZnxvRFEEVwqWBXaQTLpnTaYZIbkjrQM8wF+jVv9FH/BrzCtXfgELwQO55xLck6iVAqLvv9a8kZGx8YnJqemZ2bn5hfKlcVrm2SGQ50nMjG3EbMghYY6CpRwmxpgKpJwE92f9vWbBzBWJPoKeymEirW1iAVn6Ki7cnWjqRh2oig/KxpNhC7aODeAmdFFSI/o7s7+pnP5NX8w9CcIhqBKhnNxVyltNVsJzxRo5JJZ2wj8FMOcGRRcQjHdzCykjN+zNjQc1EyBDfNBmoKuO6ZF48S4o5EO2M8befe/Rqas7anIOfsZ7XetT/6lYUf9JjUyjA/DXOg0Q9D84w1xJikmtF8vbQkDHGXPAcaNcHkp7zDDOLpP+HKJtVoq50ls4QoOvtf5E1xv14K9mn+5Wz0+GVY9SVbJGtkgATkgx+ScXJA64eSRPJFn8lJ688resrfyYfVKw50l8mW8tXcD9buM</latexit> TIA (E[return] = 436) Signal Noise Recon. Signal Noise Denoised MDP (E[return] = 628) <latexit sha1_base64=""ftE/OHSJy3ovK5tqHIptkB9eUHM="">AAACaHicjVHLSgMxFE3H97vqQsRNaBF0YZkRXxtBFMGlgtVCO0gmvWODSWZI7ohlmA/wa9zqp/gLfoVp7UJbBS8EDuecS3JOolQKi77/XvLGxicmp6ZnZufmFxaXyssrNzbJDIc6T2RiGhGzIIWGOgqU0EgNMBVJuI0eznr67SMYKxJ9jd0UQsXutYgFZ+iou3J1q6UYdqIoPy+aLYQntHFuADOji5Ae04Pdo23n8mt+f+goCAagSgZzebdc2mm1E54p0Mgls7YZ+CmGOTMouIRitpVZSBl/YPfQdFAzBTbM+2kKuumYNo0T445G2me/b+RP/zUyZW1XRc7Zy2iHtR75l4Yd9ZvUzDA+CnOh0wxB8683xJmkmNBevbQtDHCUXQcYN8LlpbzDDOPoPuHHJdZqqZwnsYUrOBiucxTc7NaC/Zp/tVc9OR1UPU02SIVskYAckhNyQS5JnXDyTF7IK3krfXhlb81b/7J6pcHOKvkxXuUTCZu7jw==</latexit> Denoised MDPs Figure 5: Policy optimization on RoboDesk. We give state-space SAC a less noisy reward so it can learn (see appendix). Figure 6: Performance of ﬁnetuning various encoders to infer joint position from RoboDesk image observation. Policy Learning: Backprop via Dynamics Policy Learning: SAC (Latent-Space) Denoised MDP TIA Dreamer Denoised MDP TIA Dreamer DBC PI-SAC (No Aug.) CURL (Use Aug.) State-Space SAC (Upper Bound) Noiseless 801.4 ± 96.6 769.7 ± 97.1 848.6 ± 137.1 587.1 ± 98.7 480.2 ± 125.5 575.4 ± 146.2 297.4 ± 72.5 246.4 ± 56.6 417.3 ± 183.2 910.3 ± 28.2 Video Background 597.7 ± 117.8 407.1 ± 225.4 227.8 ± 102.7 309.8 ± 153.0 318.1 ± 123.7 188.7 ± 78.2 188.0 ± 67.4 131.7 ± 20.1 478.0 ± 113.5 910.3 ± 28.2 Video Background + Noisy Sensor Video Background + Camera Jittering 563.1 ± 143.0 261.2 ± 200.4 212.4 ± 89.7 288.2 ± 123.4 197.3 ± 124.2 218.2 ± 58.1 79.9 ± 36.0 152.5 ± 12.6 354.3 ± 119.9 919.8 ± 100.7 254.1 ± 114.2 151.7 ± 160.5 98.6 ± 27.7 186.8 ± 47.7 126.5 ± 125.6 105.2 ± 33.8 68.0 ± 38.4 91.6 ± 7.6 390.4 ± 64.9 910.3 ± 28.2 Table 1: DMC policy optimization results. For each variant, we aggregate performance across three tasks (Cheetah Run, Walker Walk, Reacher Easy) by averaging. Denoised MDP performs well across all four variants with distinct noise types. Bold numbers show the best model-learning result for speciﬁc policy learning choices, or the best overall result. On Camera Jittering, Denoised MDP greatly outperforms all other methods except for CURL, which potentially beneﬁts from its speciﬁc data augmentation choice (random crop) on this task, and can be seen as using extra information (i.e., knowing the noise distractor form). In fact, Denoised MDP is the only method that consistently performs well across all tasks and noise variants, which can be seen from the full results in the appendix. on the same amount of data. In Figure 6, Denoised MDP representations lead to best converged solutions across a wide range of training set sizes, achieve faster training, and avoid overﬁtting when the training set is small. DBC, CURL and PI-SAC encoders, which take in stacked frames, are not directly comparable and thus absent from Figure 6. In the appendix, we compare them with running Denoised MDP encoder on each frame and concatenating the output fea- tures, where Denoised MDP handily outperforms both DBC and CURL by a large margin. 5.2. DeepMind Control Suite (DMC) To evaluate a diverse set of noise distractors, we consider four variants for each DMC task (see Figure 7 top row): • Noiseless: Original environment without distractors. • Video Background: Replacing noiseless background with natural videos (Zhang et al., 2020) (Ctrl + Rew). • Video Background + Sensor Noise: Imperfect sensors sensitive to intensity of a background patch (Ctrl+Rew). • Video Background + Camera Jittering: Shifting the observation by a smooth random walk (Ctrl + Rew). Denoised MDP consistently removes noise distractors. In Figure 7, TIA struggles to learn clean separations in many settings. Consistent with analysis in Section 2.3, it cannot handle Sensor Noise or Camera Jittering, as the former is reward-relevant noise that it cannot model, and the latter (although reward-irrelevant) cannot be represented by masking. Furthermore, it fails on Reacher Easy with Video Background, where the reward is given by the distance between the agent and a randomly-located ball. TIA encour- ages its noise latent to be independent of reward, but does not prevent it from capturing the controllable agent. These failures lead to either TIA trying to model everything as useful signals, or a badly-ﬁt model (e.g., wrong agent pose in the last column). In contrast, Denoised MDP separates out noise in all cases, obtaining a clean and accurate MDP (its Signal rows only have the agent moving). Denoised models consistently improve policy learning. We evaluate the learned policies in Table 1, where results are aggregated by the noise distractor variant. Other meth- ods, while sometimes handling certain noise types well, struggle to deal with all four distinct variants. TIA, as ex- pected, greatly underperforms Denoised MDP under Noisy Sensor or Camera Jittering. CURL, whose augmentation choice potentially helps handling Camera Jittering, under- performs in other three variants. In contrast, Denoised MDP State-Space SAC with Modified Reward Joint Position Regression Final Test MSE vs. Training Set Size Joint Position Regression Learning Curve for |Train Set|=104 Denoised MDPs Figure 7: Visualization of the different DMC variants and factorizations learned by TIA and Denoised MDP. E.g., bottom Noise row often shows a static agent but varying background, indicating that only the background is modeled as noises in Denoised MDP. Visualizations of full reconstructions are in appendix. See our website for clearer video visualizations. policies consistently perform well for all noisy variants and also the noiseless setting, regardless of the policy optimizer. Model-based approaches have a signiﬁcant lead over the model-free ones, as seen from the DBC results in Table 1 and the well-known fact that direct model-free learning on raw image observations usually fails (Laskin et al., 2020a; Kostrikov et al., 2020; Yarats et al., 2021). These results show that learning in a world model is useful, and that learning in a denoised world model is even better. 6. Implications In this work we explore learning denoised and compressed world models in the presence of environment noises. As a step towards better understanding of such noises, we categorize of information in the wild into four types (Sec- tion 2). This provides a framework to contrast and under- stand various methods, highlighting where they may be successful and where they will suffer (Section 2.3). Insights gained this way empirically agrees with ﬁndings from exten- sive experiments (Section 5). It can potentially assist better algorithm design and analysis of new MDP representation methods, as we have done in designing Denoised MDP (Section 3). We believe that this categorization will be a useful framework for investigation on learning under noises, revealing not just the (conceptual) success scenarios, but also the failure scenarios at the same time. Additionally, the framework can be readily extended with more sophisticated factorizations (Section 2.4), which can lead to correspond- ing Denoised MDP variants and/or new algorithms. Based on the framework, our proposed Denoised MDP nov- elly can remove all noise distractors that are uncontrollable or reward-irrelevant, in distinction to prior works. Empiri- cally, it effectively identiﬁes and removes a diverse set of noise types, obtaining clean denoised world models (Sec- tion 5). It may serve as an important step towards efﬁcient learning of general tasks in the noisy real world. Our ex- periments also highlight beneﬁts of cleanly denoised world models on both standard control tasks as well as non-control tasks. The success in both cases highlights the general use- fulness of such models. Given the generality of MDPs, this opens up the possibility of casting non-RL tasks as MDPs and automatically learn representations from denoised world models, as an alternative to manual feature engineering. Acknowledgements We thank Jiaxi Chen for the beautiful Figure 1 illustration. We thank Daniel Jiang and Yen-Chen Lin for their helpful comments and suggestions. We are grateful to the following organizations for providing computation resources to this project: IBM’s MIT Satori cluster, MIT Supercloud cluster, and Google Cloud Computing with credits gifted by Google to MIT. We are very thankful to Alex Lamb for suggestions and catching our typo in the conditioning of Equation (1). Cheetah Run Noiseless Reacher Easy Video Background Walker Walk Video Background + Noisy Sensor Cheetah Run Video Background + Camera Jittering Env. Rollout Obs. Reward TIA Denoised MDP Signal Noise Signal Noise Denoised MDPs References Agarwal, A., Kakade, S., Krishnamurthy, A., and Sun, FLAMBE: Structural complexity and represen- arXiv preprint W. tation learning of low rank mdps. arXiv:2006.10814, 2020. Bellemare, M., Dabney, W., Dadashi, R., Ali Taiga, A., Castro, P. S., Le Roux, N., Schuurmans, D., Lattimore, T., and Lyle, C. A geometric perspective on optimal representations for reinforcement learning. Advances in neural information processing systems, 32:4358–4369, 2019. Castro, P. S. Scalable methods for computing state similarity in deterministic markov decision processes. In Proceed- ings of the AAAI Conference on Artiﬁcial Intelligence, volume 34, pp. 10069–10076, 2020. Coates, A., Ng, A., and Lee, H. An analysis of single- layer networks in unsupervised feature learning. In Pro- ceedings of the fourteenth international conference on artiﬁcial intelligence and statistics, pp. 215–223, 2011. Craik, K. J. W. The nature of explanation, volume 445. CUP Archive, 1952. Dennett, D. C. Why the law of effect will not go away. Journal for the Theory of Social Behaviour, 1975. Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., and Darrell, T. Decaf: A deep convolutional activation feature for generic visual recognition. In Inter- national conference on machine learning, pp. 647–655. PMLR, 2014. Du, S., Krishnamurthy, A., Jiang, N., Agarwal, A., Dudik, M., and Langford, J. Provably efﬁcient rl with rich obser- vations via latent state decoding. In International Con- ference on Machine Learning, pp. 1665–1674. PMLR, 2019. Efroni, Y., Misra, D., Krishnamurthy, A., Agarwal, A., and Langford, J. Provable rl with exogenous distrac- tors via multistep inverse dynamics. arXiv preprint arXiv:2110.08847, 2021. Elman, J. L. Finding structure in time. Cognitive science, 14(2):179–211, 1990. Eysenbach, B., Salakhutdinov, R., and Levine, S. Robust predictable control. arXiv preprint arXiv:2109.03214, 2021. Ferns, N., Panangaden, P., and Precup, D. Metrics for ﬁnite markov decision processes. In UAI, volume 4, pp. 162– 169, 2004. Fu, X., Yang, G., Agrawal, P., and Jaakkola, T. Learning task informed abstractions. In International Conference on Machine Learning, pp. 3480–3491. PMLR, 2021. Gelada, C., Kumar, S., Buckman, J., Nachum, O., and Belle- mare, M. G. Deepmdp: Learning continuous latent space models for representation learning. In International Con- ference on Machine Learning, pp. 2170–2179. PMLR, 2019. Givan, R., Dean, T., and Greig, M. Equivalence notions and model minimization in markov decision processes. Artiﬁcial Intelligence, 147(1-2):163–223, 2003. Gu, S., Bao, J., Yang, H., Chen, D., Wen, F., and Yuan, L. Mask-guided portrait editing with conditional gans. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 3436–3445, 2019. Ha, D. and Schmidhuber, J. World models. arXiv preprint arXiv:1803.10122, 2018. Haarnoja, T., Zhou, A., Hartikainen, K., Tucker, G., Ha, S., Tan, J., Kumar, V., Zhu, H., Gupta, A., Abbeel, P., et al. Soft actor-critic algorithms and applications. arXiv preprint arXiv:1812.05905, 2018. Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M. Dream to control: Learning behaviors by latent imagination. arXiv preprint arXiv:1912.01603, 2019a. Hafner, D., Lillicrap, T., Fischer, I., Villegas, R., Ha, D., Lee, H., and Davidson, J. Learning latent dynamics for planning from pixels. In International Conference on Machine Learning, pp. 2555–2565. PMLR, 2019b. Hahn, D., Banzet, P., Bern, J. M., and Coros, S. Real2sim: Visco-elastic parameter estimation from dynamic motion. ACM Transactions on Graphics (TOG), 38(6):1–13, 2019. He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. Mo- mentum contrast for unsupervised visual representation learning. arXiv preprint arXiv:1911.05722, 2019. Huh, M., Agrawal, P., and Efros, A. A. What makes arXiv preprint imagenet good for transfer learning? arXiv:1608.08614, 2016. Kannan, H., Hafner, D., Finn, C., and Erhan, D. RoboDesk: A multi-task reinforcement learning benchmark. https: //github.com/google-research/robodesk, 2021. Kim, S. W., Zhou, Y., Philion, J., Torralba, A., and Fidler, S. Learning to Simulate Dynamic Environments with GameGAN. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Jun. 2020. Denoised MDPs Kostrikov, I., Yarats, D., and Fergus, R. Image augmentation is all you need: Regularizing deep reinforcement learning from pixels. arXiv preprint arXiv:2004.13649, 2020. Laskin, M., Lee, K., Stooke, A., Pinto, L., Abbeel, P., and Srinivas, A. Reinforcement learning with augmented data. Advances in Neural Information Processing Systems, 33: 19884–19895, 2020a. Laskin, M., Srinivas, A., and Abbeel, P. Curl: Contrastive unsupervised representations for reinforcement learning. In International Conference on Machine Learning, pp. 5639–5650. PMLR, 2020b. In International Conference on Machine Learning, pp. 5171–5180. PMLR, 2019. Puterman, M. L. Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, Inc., USA, 1st edition, 1994. ISBN 0471619779. Rıza Alp Güler, Natalia Neverova, I. K. Densepose: Dense human pose estimation in the wild. 2018. Schaul, T., Horgan, D., Gregor, K., and Silver, D. Universal value function approximators. In International conference on machine learning, pp. 1312–1320. PMLR, 2015. Lee, A. X., Nagabandi, A., Abbeel, P., and Levine, S. Stochastic latent actor-critic: Deep reinforcement learning with a latent variable model. arXiv preprint arXiv:1907.00953, 2019. Smaira, L., Carreira, J., Noland, E., Clancy, E., Wu, A., and Zisserman, A. A short note on the kinetics-700-2020 human action dataset. arXiv preprint arXiv:2010.10864, 2020. Lee, K.-H., Fischer, I., Liu, A., Guo, Y., Lee, H., Canny, J., and Guadarrama, S. Predictive information accelerates learning in rl. Advances in Neural Information Processing Systems, 33:11890–11901, 2020. Lowe, D. G. Object recognition from local scale-invariant features. In Proceedings of the seventh IEEE interna- tional conference on computer vision, volume 2, pp. 1150– 1157. Ieee, 1999. Mahadevan, S. and Maggioni, M. Proto-value functions: A laplacian framework for learning representation and control in markov decision processes. Journal of Machine Learning Research, 8(10), 2007. Manuelli, L., Gao, W., Florence, P., and Tedrake, R. kpam: Keypoint affordances for category-level robotic manipu- lation. arXiv preprint arXiv:1903.06684, 2019. Mikolov, T., Chen, K., Corrado, G., and Dean, J. Efﬁcient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013. Modi, A., Jiang, N., Tewari, A., and Singh, S. Sample com- plexity of reinforcement learning using linearly combined model ensembles. In International Conference on Artiﬁ- cial Intelligence and Statistics, pp. 2010–2020. PMLR, 2020. Oord, A. v. d., Li, Y., and Vinyals, O. Representation learn- ing with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018. Pathak, D., Agrawal, P., Efros, A. A., and Darrell, T. Curiosity-driven exploration by self-supervised predic- tion. In ICML, 2017. Poole, B., Ozair, S., Van Den Oord, A., Alemi, A., and Tucker, G. On variational bounds of mutual information. Spelke, E. S. and Kinzler, K. D. Core knowledge. Develop- mental science, 10(1):89–96, 2007. Sutton, R. S. An adaptive network that constructs and uses and internal model of its world. Cognition and Brain Theory, 4(3):217–246, 1981. Sutton, R. S. Dyna, an integrated architecture for learning, planning, and reacting. ACM Sigart Bulletin, 2(4):160– 163, 1991. Todorov, E., Erez, T., and Tassa, Y. Mujoco: A physics engine for model-based control. In 2012 IEEE/RSJ Inter- national Conference on Intelligent Robots and Systems, pp. 5026–5033. IEEE, 2012. Tunyasuvunakool, S., Muldal, A., Doron, Y., Liu, S., Bohez, S., Merel, J., Erez, T., Lillicrap, T., Heess, N., and Tassa, Y. dm_control: Software and tasks for continuous control. Software Impacts, 6:100022, 2020. Wang, T. and Isola, P. Understanding contrastive represen- tation learning through alignment and uniformity on the hypersphere. In Proceedings of the 37th International Conference on Machine Learning, volume 119 of Pro- ceedings of Machine Learning Research, pp. 9929–9939. PMLR, 13–18 Jul 2020. Yarats, D., Fergus, R., Lazaric, A., and Pinto, L. Mastering visual continuous control: Improved data-augmented re- inforcement learning. arXiv preprint arXiv:2107.09645, 2021. Yen-Chen, L., Florence, P., Barron, J. T., Rodriguez, A., Isola, P., and Lin, T.-Y. iNeRF: Inverting neural radiance ﬁelds for pose estimation. In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2021. Denoised MDPs Zhang, A., McAllister, R., Calandra, R., Gal, Y., and Levine, S. Learning invariant representations for rein- forcement learning without reconstruction. arXiv preprint arXiv:2006.10742, 2020. A. Denoised MDP Discussions A.1. Loss Derivation Denoised MDPs To apply our mutual information regularizer I(x; s | a), we can consider a form using another variational distribution ρ (see, e.g., Poole et al. (2019)), I(x; s | a) = min ρ EaEpθ(s|a) [DKL(pθ(x | s, a) (cid:107) ρ(x | a))] ρ EaEqψ(s|a) [DKL(qψ(x | s, a) (cid:107) ρ(x | a))] ≈ min = min θ(cid:48) LKL-x(ψ, θ(cid:48)). (assume qψ is roughly the posterior of pθ) (5) The assumption that qψ is roughly the posterior of pθ is acceptable because it is the natural consequence of optimizing the variational MLE objective in Equation (1) over θ, ψ. Alternatively, we can consider the MI deﬁned by a joint conditional distribution P (x, s | a) not from the forward model pθ, but from the data distribution and posterior model qψ(x | s, a). This is also sensible because the variational MLE objective in Equation (1) optimizes for compatible pθ and qψ that both ﬁt data and consistently describe (conditionals of) the same underlying distribution. Thus regularizing either can encourage a low MI. This approach leads to exactly Equation (5), without approximation. Then, the total loss in Equation (3) from combining Equations (1) and (5) is given by min θ LMLE(θ) + c · I(x; s | a) = min θ,θ(cid:48),ψ Lrecon(θ, ψ) + LKL-x(θ, ψ) + LKL-y(θ, ψ) + LKL-z + c · +LKL-x(θ(cid:48), ψ) = min θ,ψ Lrecon(θ, ψ) + (1 + c) · LKL-x(θ, ψ) + LKL-y(θ, ψ) + LKL-z(θ, ψ). A.2. Discussions We discuss some algorithmic choices of Denoised MDP below. Speciﬁc implementation details (e.g., architectures) can be found at Appendix B.1.2. Posterior distributions of rx and ry. The pθ reward distributions pθ(rx | xt) and pθ(ry | yt) are modelled via Gaussians (as is done usually in world models, such as Dreamer (Hafner et al., 2019a)). By the transition structure of Denoised MDPs, these distributions are inherently independent. Recall that r = rx + ry. Therefore, we can easily compute the distribution of pθ(r | xt, yt) and its log likelihoods. This enables easy optimization of the variational MLE objective, without requiring the posterior model to also infer rx and ry from observed r subject to the addition relation. Partial observability. Sections 2 and 3 discussions are mostly based in the fully observable setting. Yet most benchmarks and real-world tasks are partially observable, e.g., robot joint speeds that can not be inferred from a single frame. Fortunately, the transition models used in Denoised MDP are fully capable of handle such cases, as long as the encoder qψ is not deterministic and the observation model pθ(s | . . . ) does not have the block structure (Du et al., 2019) (which would make x, y, z fully determined from s). In practice, we let both components to be generic conditional distributions (parameterized by regular deep neural networks). Therefore, Denoised MDP does not require full observability. The loss in Equation (4) has two hyperparameters: α ∈ (0, ∞) and β ∈ (0, 1). To maintain Hyperparameter choice. relative ratio with the observation reconstruction loss, we recommend scaling α roughly proportionally with dimensionality of the observation space, as is done in our experiments presented in this paper. A smaller β means stronger regularization. Therefore, β can be chosen based on training stability and the level of noise distractors in the task. B. Experiment Details All code (including code for our environment variants and code for our Denoised MDP method) will be released upon publication. Denoised MDPs Ctrl + Rew Ctrl + Rew Ctrl + Rew Noiseless Video Background DMC Video Background + Noisy Sensor Video Background + Camera Jittering Agent Agent Agent Agent — — — — — — Ctrl + Rew — Background Background — — Background, Jittering camera RoboDesk Agent, Button, Light on desk, Green hue of TV Blocks on desk, Handle on desk, Other movable objects TV content, Button sensor noise Jittering and ﬂickering environment lighting, Jittering camera Table 2: Categorization of various information in the environments we evaluated with. B.1. Implementation Details B.1.1. ENVIRONMENTS AND TASKS In all environments, trajectories are capped at 1000 timesteps. Table 2 shows a summary of what kinds of information exist in each environment. DeepMind Control Suite (DMC). Our Video Background implementation follows Deep Bisimulation for Control (Zhang et al., 2020) on most environments, using Kinetics-400 grayscale videos (Smaira et al., 2020), and replacing pixels where blue channel is strictly the greatest of three. This method, however, does not cleanly remove most of background in the Walker Walk environment, where we use an improved mask that replaces all pixels where the blue channel is among the greatest of three. For Camera Jittering, we shift the observation image according to a smooth random walk, implemented as, at each step, Gaussian-perturbing acceleration, decaying velocity, and adding a pulling force if the position is too far away from origin. For Sensor Noise, we select one sensor, and perturb it according to intensity of a patch of the natural video background (i.e., adding average patch value − 0.5). We perturb the speed sensor for Cheetah Run, the torso_height sensor for Walker Walk, and the normalized finger_to_target_dist sensor for Reacher Easy. These sensor values undergo non-linear (mostly piece-wise linear) transforms to compute rewards. While they can not be perfectly modelled by additive reward noise, such a model is usually sufﬁcient in most cases when the sensor values are not too extreme and stay in one linear region. RoboDesk. We modify the original RoboDesk environment by adding a TV screen and two neighboring desks. The TV screen places (continuously horizontally shifting) natural RGB videos from the Kinetics-400 dataset (Smaira et al., 2020). The environment has three light sources from the above, to which we added random jittering and ﬂickering. The viewing camera is placed further to allow better view of the noise distractors. Resolution is increased from 64 × 64 to 96 × 96 to compensate this change. Camera jittering is implemented by a 3D smooth random walk. Finally, the button sensor (i.e., detected value of how much the button is pressed) is also offset by a random walk. Each of the three button affects the corresponding light on the desk. Additionally, pressing the green button also shifts the TV screen content to a green hue. Following RoboDesk reward design, we reward the agent for (1) placing arm close to the button, (2) pressing the button, and (3) how green the TV screen content is. RoboDesk Joint Position Regression Datasets. To generate training and test set, we use four policies trained by state- space SAC at different stages of training (which is not related to any of the compared methods) and a uniform random actor, to obtain ﬁve policies of different qualities. For each policy, we sample 100 trajectories, each containing 1001 pairs (from 1000 interactions) of image observation and groundtruth joint position (of dimension 9). This leads to a total of 500.5 × 103 samples from each policy. From these, 100 × 103 samples are randomly selected as test set. Training sets of sizes 5 × 103, 10 × 103, 25 × 103, 50 × 103, 100 × 103, 150 × 103 are sampled from the rest. For all test sets and training sets, we enforce each policy to strictly contribute an equal amount. Denoised MDPs Operator Input Shape Kernel Size Stride Padding Operator Input Shape Kernel Size Stride Padding Input [3, 96, 96] — — — Input [input_size] Conv. + ReLU [k, 47, 47] Conv. + ReLU [2k, 22, 22] Conv. + ReLU [4k, 10, 10] Conv. + ReLU Conv. + ReLU [8k, 4, 4] [8k, 2, 2] 4 4 4 4 3 2 2 2 2 1 0 0 0 0 0 Reshape + FC [m] — — — FC + ReLU + Reshape Conv. Transpose + ReLU Conv. Transpose + ReLU [m, 1, 1] [4k, 3, 3] [4k, 9, 9] Conv. Transpose + ReLU [2k, 21, 21] Conv. Transpose + ReLU Conv. Transpose + ReLU [k, 46, 46] [3, 96, 96] — — 5 5 5 6 6 — — 2 2 2 2 2 — — 0 0 0 0 0 Table 3: Encoder architecture for 96 × 96-resolution observa- tion. The output of this encoder is then fed to other network for inferring posteriors. m and k are two architectural hyper- parameters. m controls the output size (unrelated to the actual latent variable sizes). k controls the network width. Table 4: Decoder architecture for 96 × 96-resolution observation. m and k are two architectural hyperparameters. m controls width the fully connected part. k controls width of the convolutional part. They are the same values as in Table 3. B.1.2. MODEL LEARNING METHODS For all experiments, we let the algorithms use 106 environment steps. For PI-SAC and CURL, we follow the original implementations (Laskin et al., 2020b; Lee et al., 2020) and use an action repeat of 4 for Cheetah Run and Reacher Easy, and an action repeat of 2 for Walker Walk. For Denoised MDP, Dreamer, TIA and DBC, we always use an action repeat of 2, following prior works (Hafner et al., 2019a; Fu et al., 2021; Zhang et al., 2020). Denoised MDP, Dreamer, and TIA. Both Dreamer and TIA use the same training schedule and the Recurrent State-Space Model (RSSM) as the base architecture (Hafner et al., 2019b). Following them, Denoised MDP also uses these components, and follow the same preﬁlling and training schedule (see Dreamer (Hafner et al., 2019b) for details). These three model learning methods take in 64 × 64 RGB observations for DMC, and 96 × 96 RGB observations for RoboDesk. Dreamer only implements encoder and decoder for the former resolution. To handle the increased resolution, we modify the 64 × 64 architectures and obtain convolutional encoder and decoder shown in Tables 3 and 4. For fair comparison, we ensure that each method has roughly equal number of parameters by using different latent variable sizes, encoder output sizes (m of Table 3) and convolutional net widths (k of Table 4). Details are shown in Table 5. KL clipping (free nats). For Denoised MDP, we follow Dreamer (Hafner et al., 2019b;a) and TIA (Fu et al., 2021), and allow 3 free nats for the LKL-x term. In other words, for each element of a batch, we do not optimize the KL term if it is less than 3 (e.g., implemented via clipping). However, we do not allow this for the LKL-y and LKL-z terms, as these variables are to be discarded and information is not allowed to hide in them unless permitted by the structure. An alternative strategy, + (1 − β) · LKL-x which we ﬁnd also empirically effective, is to consider LKL-x = β · LKL-x , and to allow free nats only for (cid:124) (cid:125) (cid:123)(cid:122) (cid:124) (cid:125) (cid:123)(cid:122) VAE KL term MI regularizer term the ﬁrst term that is a part of the variational model ﬁtting objective. All results presented in this paper use the ﬁrst strategy. Both strategies are implemented in our open source code repository: github.com/facebookresearch/denoised_mdp. B.1.3. POLICY OPTIMIZATION ALGORITHMS USED WITH MODEL LEARNING Backpropagate via Dynamics. We use the same setting as Dreamer (Hafner et al., 2019a), optimizing a λ-return over 15-step-long rollouts with λ = 0.95, clipping gradients with norm greater than 100. TIA uses the same strategy, except that it groups different models together for gradient clipping. We strictly follow the ofﬁcial TIA implementation. Latent-Space SAC. We use the regular SAC with automatic entropy tuning, without gradient clipping. This works well for almost all settings, except for Walker Walk variant of DMC, where training often collapses after obtaining good return, regardless of the model learning algorithm. To address instability in this case, we reduce learning rates from 3 × 10−4 to 1 × 10−4 and clip gradients with norm greater than 100 for all latent-space SAC run on these variants. Denoised MDPs DMC RoboDesk Latent Sizes Dreamer TIA Denoised MDP (220 + 33) (120 + 20) + (120 + 20) (120 + 20) + (120 + 20) m 1024 490 1024 k 32 24 32 Total Number of Parameters Latent Sizes 7,479,789 7,475,567 7,478,826 (220 + 33) (120 + 20) + (120 + 20) (120 + 20) + (120 + 20) m 1024 490 1024 k 32 24 32 Total Number of Parameters 6,385,511 6,384,477 6,384,248 Table 5: The speciﬁc architecture parameters for model learning methods. Since RSSM uses a deterministic part and a stochastic part to represent each latent variable, we use (deterministic_size + stochastic_size) to indicate size of a latent variable. TIA and Denoised MDP have more than one latent variable. Note that while TIA has lower m and k, it has multiple encoder and decoders, whereas Dreamer and Denoised MDP only have one encoder and one decoder. The total number of parameters is measured with the actor model, but without any additional components from policy optimization algorithm (e.g., critics in SAC). Total number of parameters is lower for RoboDesk as the encoder and decoder architecture is narrower than those of DMC for the purpose of reducing memory usage, despite with a higher resolution. B.1.4. MODEL-FREE METHODS DBC. For DMC, we used 84 × 84-resolution observation following original work (even though other methods train on 64 × 64-resolution observations). For RoboDesk, DBC uses the encoder in Table 3 for 96 × 96-resolution observation, for fair comparison with other methods. Following the original work, we stack 3 consecutive frames to approximate the required full observability. In the robot arm joint position regression experiment Section 5.1, DBC encoders also see stacked observations. For DMC evaluations, we use the data provided by Zhang et al. wherever possible, and run the ofﬁcial repository for other cases. State-Space SAC. The state space usually contains robot joint states, including position, velocity, etc. For DMC, when Sensor Noise is present, this is not the true optimal state space, as we do not supply it with the noisy background that affects the noisy reward. However, it still works well in practice. For RoboDesk, the TV’s effect on reward is likely stronger and direct state-space SAC fails to learn. Since this evaluation is to obtain a rough “upper bound”, we train state-space SAC with a modiﬁed reward with less noise— the agent is rewarded by pressing the button, independent of the TV content. This still encourages the optimal strategy of the task allows achieving good policies. B.1.5. NON-RL METHODS Contrastive Learning. We used the Alignment+Uniformity contrastive learning loss from Wang & Isola (2020). The hyperparameters and data augmentations strictly follow their experiments on STL-10 (Coates et al., 2011), which also is of resolution 96 × 96. The exact loss form is Lalign(α = 2) + Luniform(t = 2), a high-performance setting for STL-10. B.2. Compute Resources All our experiments are run on a single GPU, requiring 8GB memory for DMC tasks, and 16GB memory for RoboDesk tasks. We use NVIDIA GPUs of the following types: 1080 Ti, 2080 Ti, 3080 Ti, P100, V100, Titan XP, Titan RTX. For MuJoCo (Todorov et al., 2012), we use the EGL rendering engine. Training time required for each run heavily depends on the CPU speciﬁcation and availability. In general, a Denoised MDP run needs 12 ∼ 36 hours on DMC and 24 ∼ 50 hours on RoboDesk. TIA uses about 1.5× of these times, due to the adversarial losses. For a comparison between the two Denoised MDP variants, running the same DMC task on the same machine, the Figure 2b variant used 23 hours while the Figure 2c variant used 26 hours. B.3. Visualization Details Visualizations of components in learned models. We use different methods to visualize signal and noise information learned by TIA and Denoised MDP in Figures 4 and 7. For TIA, we used the reconstructions from the two latent (before mask-composing them together as the full reconstruction). For Denoised MDP, we only have one decoder (instead of three for TIA), and thus we decode (xt, const) and (const, yt) to visualize information contained in each variable, with const chosen by visual clarity (usually as value of the other variable at a ﬁxed timestep). Due to the fundamental different ways to obtain these visualizations, in DMC, TIA can prevent the agent from showing up in noise visualizations, while Denoised Denoised MDPs Figure 8: Effect of weight decay on RoboDesk joint position regres- sion. The curves show ﬁnal test MSE for various training set sizes. Weight decay generally helps when ﬁnetuning from a pretrained encoder, but hurts when training from scratch. Figure 9: Performance of all TIA settings on RoboDesk joint position regression. Only using the signal encoder is necessary for good performance. Figure 10: Training curve comparisons for the RoboDesk joint position regression task across many training set sizes. MDP cannot. However, as stated in Section 5.2, our focus should be on what evolves/changes in these images, rather than what is visually present, as static components are essentially not modelled by the corresponding transition dynamics. Visualizations in Figures 4 and 7 use trajectories generated by a policy trained with state-space SAC. To obtain diverse behaviors, policy outputs are randomly perturbed before being used as actions. From the same trajectory, we use the above described procedure to obtain visualizations. The speciﬁc used trajectory segments are chosen to showcase both the modiﬁed environment and representative behavior of each method. Please see the supplementary video for clearer visualizations. B.4. RoboDesk Result Details Environment modiﬁcations. The agent controls a robotic arm placed in front of a desk and a TV, and is tasked to push down the green button on the desk, which turns on a small green light and makes the TV display have a green hue. The intensity of the TV image’s green channel is given to the agent as part of their reward, in addition to distance between the arm to the button, and how much the button is pressed. Additionally, the environment contains other noise distractors, including moveable blocks on the desk (Ctrl + Rew), ﬂickering environment light and camera jittering (Ctrl + Rew), TV screen hue (Ctrl + Rew), TV content (Ctrl + Rew), and noisy button sensors (Ctrl + Rew). RoboDesk has roughly twice as many pixels as DMC has. For Denoised MDP, we Denoised MDP hyperparameters. scale α with the observation space dimensionality (see Section 3) and use α = 2, with a ﬁxed β = 0.125. When using the alternative KL free nats strategy discussed in Appendix B.1.2 (results not shown in paper), we ﬁnd α = 1 and β = 0.25 also effective. TIA hyperparameters. We follow recommendations in the TIA paper, setting λRadv = 25,000 to match reconstruction loss in magnitude, and setting λOs = 2 where training is stable. B.4.1. ROBOT ARM JOINT POSITION REGRESSION. Training details. For this task, we jointly train the pre-trained backbone and a three-layer MLP head that has 256 hidden units at each layer, with a learning rate of 8 × 10−5. For ﬁnetuning from pretrained encoders, we follow common ﬁnetuning practice and apply a weight decay of 3 × 10−5 whenever it is helpful (all cases except CURL and training from scratch). E S M 10 1 t e S t s e T 10 2 E S M 10 1 t e S t s e T 10 2 Denoised MDP Dreamer TIA Contrastive With Weight Decay No Weight Decay From Scratch DBC (Stacked Frames) CURL (Stacked Frames) PI-SAC without Augmentation (Stacked Frames) 0.5 1.0 1.5 0.5 1.0 1.5 0.5 1.0 1.5 0.5 1.0 1.5 Training Set Size1e5 Training Set Size1e5 Training Set Size1e5 Training Set Size1e5 TIA With Weight Decay + Only Signal Encoder No Weight Decay + Only Signal Encoder With Weight Decay + Both Encoders No Weight Decay + Both Encoders 103 102 101 100 E S M t e S t s e T 10 1 10 2 0.2 0.4 0.6 0.8 1.0 Training Set Size 1.2 1.4 1e5 Learning Curve for 104 Training Samples Denoised MDP TIA Dreamer Contrastive From Scratch 0.25 0.24 0.23 0.22 0.21 0.20 0.19 0.18 0 20 40 60 80 100 Training Epoch Learning Curve for 150 × 104 Training Samples 0.40 0.30 0.20 0.100 0.09 0 20 40 60 80 100 Training Epoch Learning Curve for 50 × 104 Training Samples 0.24 0.22 0.20 0.18 0.16 0.14 0.12 0.100 0 20 40 60 80 100 Training Epoch Learning Curve for 150 × 104 Training Samples 0.20 0.100 0.09 0.08 0.07 0.06 0.05 0.04 0 20 40 60 80 100 Training Epoch Denoised MDPs Figure 11: Performance comparison of ﬁnetuning from Denoised MDP encoders and frame-stacked encoders that take in 3 consec- utive frames. For Denoised MDP and training from scratch, the encoders take in only a single frame and are applied for each of the frame, with output concatenated together before feeding to the prediction head. Figure 12: Performance of all DBC settings on RoboDesk joint position regression. Using the output features (after layer normal- ization) is necessary for good performance. Figure 13: Performance of all CURL settings on RoboDesk joint position regression. Using the output features (after layer normal- ization) is necessary for good performance. Figure 14: Performance of all PI-SAC settings on RoboDesk joint position regression. Using the activations before layer normaliza- tion gives best performance. See Figure 8 for comparisons for weight decay options over all methods. • For model-based RL, we take encoders trained with backpropagating via dynamics as the policy optimization algorithm. • In training the contrastive encoder, for a (more) fair comparison with RL-trained encoders that are optimized over 106 environment steps, we train contrastive encoders on 106 samples, obtained in the exact same method of the training sets of this task. In a sense, these contrastive encoders have the advantage of training on the exact same distribution, and seeing more samples (since RL-trained encoders use action repeat of 2 and thus only ever see 0.5 × 106 samples). • TIA has two sets of encoders. Using concatenated latents from both unfortunately hurts performance greatly (see Figure 9). So we use only the encoder for the signal latent. We also compare training speeds over a wide range of training set sizes in Figure 10. Denoised MDP encoders lead to faster and better training in all settings. Additional comparison with frame-stacking encoders. Other pretrained encoders (DBC, CURL and PI-SAC) take in stacked 3 consecutive frames, and are not directly comparable with the other methods. To compare, we also try running Denoised MDP encoders on the 3 consecutive frames, whose feature vector is concatenated before feeding into the head. The result in Figure 11 shows that our encoder outperforms all but PI-SAC encoders. Finally, for DBC, CURL and PI-SAC, we attempted evaluating intermediate features, features before the ﬁnal layer normalization, and the output space, and ﬁnd the last option best-performing for DBC and CURL, and the second option best-performing for PI-SAC (see Figures 12 to 14). Therefore, we use these respective spaces, which arguably gives a further edge to these methods, as we essentially tune this additional option on test results. Notably, these respective choices are often the only one achieving relatively good performance, highlighting the necessity of tuning for these methods. 10 1 E S M t e S t s e T 10 2 Ours (Stacked Frames) Ours (Single Frame) DBC (Stacked Frames) PI-SAC (Stacked Frames) CURL (Stacked Frames) From Scratch (Stacked Frames) 0.2 0.4 0.6 0.8 Training Set Size 1.0 1.2 1.4 1e5 DBC With Weight Decay, Output Features No Weight Decay, Output Features With Weight Decay, No Layer Norm No Weight Decay, No Layer Norm With Weight Decay, Conv Features No Weight Decay, Conv Features 103 102 101 100 E S M t e S t s e T 10 1 0.2 0.4 0.6 0.8 1.0 Training Set Size 1.2 1.4 1e5 CURL With Weight Decay, Output Features No Weight Decay, Output Features With Weight Decay, No Layer Norm No Weight Decay, No Layer Norm With Weight Decay, Conv Features No Weight Decay, Conv Features 103 102 101 100 E S M t e S t s e T 10 1 10 2 0.2 0.4 0.6 0.8 Training Set Size 1.0 1.2 1.4 1e5 PI-SAC 10 1 E S M t e S t s e T 10 2 With Weight Decay, Output Features (Stacked Frames) No Weight Decay, Output Features (Stacked Frames) With Weight Decay, No Layer Norm (Stacked Frames) No Weight Decay, No Layer Norm (Stacked Frames) With Weight Decay, Conv Features (Stacked Frames) No Weight Decay, Conv Features (Stacked Frames) 0.2 0.4 0.6 0.8 Training Set Size 1.0 1.2 1.4 1e5 B.5. DeepMind Control Suite (DMC) Result Details Denoised MDPs Full policy optimization results. Figure 15 presents the full results on each DMC environment (task + variant). For environment, a comparison plot is made based on which policy learning algorithm is used with the model learning method (with model-free baselines duplicated in both). Such separation is aimed to highlight the performance difference caused by model structure (rather than policy learning algorithm). Across most noisy environments, Denoised MDP performs the best. It also achieves high return on noiseless environments. Visualization of learned models. Figure 16 is the extended version of Figure 7 in main text, with full reconstructions from all three models. Please see the supplementary video for clearer visualizations. Comparison between Denoised MDP variants. We compare the two Denoised MDP variants based Figures 2b and 2c on Cheetah Run environments with policy trained by packpropagating via learned dynamics. The comparison is shown in the top row of Figure 15, where we see the Figure 2b variant often performing a bit better. We hypothesize that this may due to the more complex prior and posterior structure of Figure 2c, which may not learn as efﬁciently. This also makes Figure 2c variant needing longer (wall-clock) time to optimize, as mentioned above in Appendix B.2. TIA hyperparameters and instability. We strictly follow recommendations of the original paper, and use their suggested value for each DMC task. We also note that TIA runs sometimes collapse during training, leading to sharp drops in rewards. After closely inspecting the models before and after collapses, we note that in many cases, such collapses co-occur with sudden spikes in TIA’s reward disassociation loss, which is implemented as an adversarial minimax loss, and the noise latent space instantly becomes degenerate (i.e., not used in reconstruction). We hypothesize that this adversarial nature can cause training instability. However, a few collapses do not co-occur with such loss spikes, which maybe alternatively due to that TIA model structure cannot model the respective noise types and that better ﬁtting the model naturally means a degenerate noise latent space. PI-SAC hyperparameters. For each task, we use the hyperparameters detailed in the original paper (Lee et al., 2020). PI-SAC is usually run with augmentations. However, unlike CURL, augmentation is not an integral part of the PI-SAC algorithm and is completely optional. For a fair comparisons with other methods and to highlight the effect of the predictive information regularizer, the main mechanism proposed by PI-SAC, we do not use augmentations for PI-SAC. Denoised MDP hyperparameters. For DMC, we always use ﬁxed α = 1. β can be tune according to amount of noises in environment, and to training stability. In Figure 17, we compare effects of choosing different β’s. On noiseless environments, larger β (i.e., less regularization) performs often better. Whereas on noisy environments, sometimes stronger regularization can boost performance. However, overall good performance can be obtained by usually several β values. In Table 6, we summarize our β choices for each environment in Table 6. Denoised MDPs Figure 15: Policy optimization results on DMC. Each plot focuses on a single task variant, showing total episode return versus environment steps taken. For three model-based approaches, we use two policy optimization choices to train on the learned model: (top half) backpropagate via learned dynamics and (bottom half) SAC on the learned MDP. We also compare with DBC, a model-free baseline. For an “upper bound” (not plotted due to presentation clarity), SAC on true state-space (i.e., optimal representation) in 106 environment steps reaches episode return ≈ 800 on Cheetah Run variants, ≈ 980 on Walker Walk variants, and ≈ 960 on Reacher Easy variants. CURL’s speciﬁc augmentation choice (random crop) potentially helps signiﬁcantly for Reacher Easy (where the reacher and the target appear in random spatial locations) and Camera Jittering. However, unlike Denoised MDP, it does not generally perform well across all environments and noise variants. n o i t a z i m i t p O y c i l o P e t a g a p o r p k c a B s c i m a n y D a v i n o i t a z i m i t p O y c i l o P ) e c a p S - t n e t a L ( C A S Denoised MDPs Figure 16: Complete visualization of the different DMC variants and factorizations learned by TIA and Denoised MDP. In addition to visualizations of Figure 7, we also visualize full reconstructions from Dreamer, TIA, and Denoised MDP. Cheetah Run Noiseless Reacher Easy Video Background Walker Walk Video Background + Noisy Sensor Cheetah Run Video Background + Camera Jittering Env. Rollout Obs. Reward Dreamer Recon. Recon. TIA Signal Noise Recon. Denoised MDP Signal Noise Denoised MDPs Figure 17: Effect of choosing β in Denoised MDP on DMC policy optimization results. Setting β = 1 disables regularization and is only run on noiseless variants. Noiseless Video Background Video Background + Noisy Sensor Video Background + Camera Jittering Policy Learning: Backprop via Dynamics Policy Learning: SAC (Latent-Space) Cheetah Run Walker Walk Reacher Easy Cheetah Run Walker Walk Reacher Easy 1 1 1 1 1 1 0.125 0.25 0.25 0.125 0.25 0.125 0.25 0.25 0.25 0.125 0.125 0.25 0.25 0.5 0.25 0.25 0.5 0.25 Table 6: β choices for Denoised MDP results shown in Table 1 and Figure 15. We choose β = 1 (i.e., disabling regularization) for all noiseless environments, and tuned others. However, as seen in Figure 17, the results often are not too sensitive to small β changes. n o i t a z i m i t p O y c i l o P e t a g a p o r p k c a B s c i m a n y D a v i n o i t a z i m i t p O y c i l o P ) e c a p S - t n e t a L ( C A S","['denoise', 'mdps', 'learn', 'world', 'model', 'well', 'world', 'antonio', 'torralba', 'phillip', 'isola', 'yuandong', 'tian', 'l', 'x', 'r', 'abstract', 'ability', 'separate', 'signal', 'noise', 'reason', 'clean', 'abstraction', 'critical', 'telligence', 'ability', 'human', 'ciently', 'perform', 'real', 'world', 'task', 'consider', 'e', 'possible', 'nuisance', 'factor', 'artiﬁ', 'cial', 'agent', 'kind', 'information', 'agent', 'safely', 'discard', 'noise', 'work', 'categorize', 'information', 'wild', 'type', 'base', 'controllability', 'relation', 'reward', 'formulate', 'useful', 'information', 'controllable', 'rewardrelevant', 'framework', 'clariﬁes', 'kind', 'information', 'remove', 'various', 'prior', 'work', 'representation', 'learn', 'reinforcement', 'learn', 'rl', 'lead', 'propose', 'approach', 'learn', 'denoised', 'mdp', 'explicitly', 'factor', 'certain', 'noise', 'tractor', 'extensive', 'experiment', 'variant', 'robodesk', 'performance', 'denoise', 'world', 'model', 'use', 'raw', 'observation', 'alone', 'prior', 'work', 'policy', 'optimization', 'con', 'trol', 'task', 'well', 'noncontrol', 'task', 'joint', 'position', 'regression', 'page', 'code', 'githubcomfacebookresearchdenoisedmdp', 'introduction', 'real', 'world', 'provide', 'plethora', 'information', 'microscopic', 'physical', 'interaction', 'abstract', 'semantic', 'signal', 'late', 'covid19', 'news', 'fortunately', 'process', 'signal', 'unnecessary', 'also', 'impossible', 'fact', 'particular', 'reasoning', 'decision', 'often', 'rely', 'small', 'portion', 'information', 'imagine', 'wake', 'want', 'embrace', 'sunlight', 'open', 'curtain', 'nearby', 'resting', 'bird', 'scared', 'csail', 'correspondence', 'work', 'intern', 'ai', 'proceeding', 'international', 'conference', 'machine', 'learn', 'copy', 'right', 'author', 'figure', 'illustrative', 'example', 'distinct', 'kind', 'mation', 'scenario', 'describe', 'section', 'person', 'desire', 'increase', 'amount', 'sunlight', 'let', 'room', 'opening', 'curtain', 'scare', 'away', 'bird', 'b', 'denoised', 'world', 'model', 'include', 'small', 'subset', 'information', 'away', 'pleasantly', 'meet', 'beautiful', 'sunny', 'day', 'far', 'away', 'jet', 'plane', 'slowly', 'ﬂye', 'sky', 'seem', 'simple', 'activity', 'fact', 'highlight', 'distinct', 'type', 'information', 'see', 'figure', 'respect', 'goal', 'let', 'much', 'sunlight', 'possible', 'controllable', 'rewardrelevant', 'curtain', 'inﬂuence', 'action', 'affect', 'incoming', 'sunlight', 'controllable', 'rewardirrelevant', 'bird', 'inﬂuence', 'action', 'affect', 'sunlight', 'uncontrollable', 'rewardrelevant', 'weather', 'inde', 'pendent', 'action', 'affect', 'sunlight', 'uncontrollable', 'rewardirrelevant', 'plane', 'indepen', 'dent', 'action', 'sunlight', 'optimal', 'action', 'goal', 'however', 'fact', 'depend', 'information', 'controllable', 'reward', 'reward', 'relevant', 'reward', 'irrelevant', 'uncontrollable', 'controllable', 'goal', 'let', 'much', 'sunlight', 'possible', 'denoise', 'optimal', 'control', 'rely', 'information', 'controllable', 'rewardrelevant', 'good', 'world', 'model', 'ignore', 'factor', 'noisy', 'distractor', 'denoise', 'mdps', 'relevant', 'kind', 'information', 'merely', 'noise', 'distractor', 'indeed', 'matter', 'much', 'natural', 'sunlight', 'outside', 'plane', 'bird', 'move', 'good', 'plan', 'always', 'open', 'curtain', 'perform', 'particular', 'task', 'human', 'barely', 'think', 'type', 'information', 'usually', 'plan', 'action', 'affect', 'information', 'control', 'lable', 'rewardrelevant', 'mental', 'model', 'stract', 'condense', 'version', 'real', 'world', 'actually', 'well', 'suit', 'task', 'notion', 'well', 'modeldata', 'ubiquitous', 'data', 'science', 'machine', 'learning', 'algorithm', 'rarely', 'perform', 'well', 'raw', 'noisy', 'real', 'datum', 'common', 'approach', 'perform', 'datum', 'cleaning', 'feature', 'engineering', 'manually', 'select', 'useful', 'signal', 'base', 'prior', 'knowledge', 'andor', 'heuristic', 'year', 'research', 'identiﬁe', 'way', 'extract', 'good', 'feature', 'computer', 'vision', 'lowe', 'et', 'natural', 'language', 'processing', 'elman', 'mikolov', 'et', 'reinforcement', 'learn', 'bellemare', 'similarly', 'system', 'identiﬁcation', 'align', 'real', 'observation', 'predeﬁne', 'set', 'abstract', 'signalsstate', 'yet', 'task', 'wild', 'general', 'form', 'partially', 'observable', 'markov', 'decision', 'process', 'little', 'prior', 'knowledge', 'optimal', 'set', 'signal', 'work', 'ask', 'infer', 'extract', 'signal', 'automatically', 'form', 'learn', 'world', 'model', 'general', 'idea', 'mental', 'world', 'model', 'long', 'der', 'active', 'research', 'philosophy', 'social', 'science', 'craik', 'cognitive', 'science', 'intuitive', 'physics', 'model', 'hypothesize', 'core', 'planning', 'capability', 'spelke', 'kinzler', 'reinforcement', 'learning', 'various', 'method', 'investigate', 'state', 'abstrac', 'tion', 'fast', 'well', 'learn', 'work', 'explore', 'idea', 'context', 'machine', 'learning', 'reinforcement', 'learning', 'aim', 'make', 'concrete', 'different', 'type', 'information', 'wild', 'automatically', 'learn', 'world', 'model', 'remove', 'noise', 'distractor', 'beneﬁcial', 'policy', 'optimization', 'noncontrol', 'task', 'goal', 'contribution', '•', 'categorize', 'information', 'distinct', 'kind', 'figure', 'review', 'prior', 'approach', 'frame', 'work', 'section', 'base', 'framework', 'propose', 'denoise', 'mdps', 'method', 'learn', 'world', 'model', 'certain', 'distractor', 'remove', 'section', '•', 'experiment', 'deepmind', 'control', 'robodesk', 'environment', 'demonstrate', 'superior', 'formance', 'policy', 'learn', 'method', 'many', 'distinct', 'type', 'noise', 'distractor', 'section', 'show', 'denoise', 'mdp', 'also', 'beneﬁcial', 'control', 'objective', 'improve', 'supervised', 'task', 'robot', 'joint', 'position', 'regression', 'section', 'different', 'type', 'information', 'wild', 'section', 'illustrate', 'type', 'information', 'available', 'wild', 'task', 'make', 'notion', 'concrete', 'relate', 'exist', 'work', 'generality', 'consider', 'task', 'form', 'markov', 'decision', 'process', 'mdps', 'describe', 'usual', 'manner', 'r', 'p', 'puterman', 'state', 'space', 'action', 'space', 'r', '∆0', 'rmax', 'deﬁne', 'reward', 'random', 'variable', 'rscid48', 'receive', 'ar', 'rive', 'state', 'scid48', '×', '∆s', 'transition', 'dynamic', '∈', '∆s', 'deﬁne', 'distribution', 'initial', 'state', 'use', 'denote', 'set', 'distribution', 'p', 'r', 'deﬁne', 'important', 'component', 'mdp', 'transition', 'dynamic', 'pscid48', 'scid48', 'usually', 'objective', 'policy', 'act', 'base', 'current', 'state', 'maximize', 'expect', 'cumulative', 'discount', 'reward', 'indeed', 'provide', 'general', 'formulation', 'pass', 'many', 'task', 'fact', 'entire', 'real', 'world', 'view', 'mdp', 'rich', 'stateobservation', 'space', 'contain', 'possible', 'informationsignal', 'cial', 'agent', 'successfully', 'perform', 'real', 'world', 'task', 'able', 'process', 'observation', 'incredibly', 'rich', 'highdimensional', 'visual', 'audio', 'signal', 'characterize', 'different', 'type', 'information', 'servation', 'consider', 'intuitive', 'notion', 'noisy', 'irrelevant', 'signal', 'uncontrollable', 'information', 'rewardirrelevant', 'information', 'factor', 'often', 'ignore', 'affect', 'optimal', 'control', 'refer', 'noise', 'distractor', 'understand', 'role', 'mdps', 'study', 'different', 'mulation', 'transition', 'dynamic', 'reward', 'function', 'show', 'different', 'structure', 'naturally', 'lead', 'position', 'help', 'identify', 'distractor', 'remove', 'distractor', 'thus', 'transform', 'original', 'noisy', 'mdp', 'clean', 'denoise', 'one', 'use', 'downstream', 'task', 'starter', 'generic', 'transition', 'model', 'figure', 'little', 'structure', 'state', 'contain', 'useful', 'signal', 'noise', 'distractor', 'therefore', 'directly', 'useful', 'extract', 'important', 'information', 'controllability', 'intuitively', 'controllable', 'agent', 'able', 'well', 'consider', 'enough', 'require', 'variable', 'unaffected', 'action', 'wind', 'direction', 'ignore', 'sailing', 'denoise', 'mdps', 'r', 'r', 'r', 'scid48', 'rx', 'r', 'yr', 'scid48', 'rx', 'r', 'b', 'transition', 'factorize', 'uncontrol', 'lable', 'information', 'yr', 'transition', 'useful', 'structure', 'contain', 'type', 'information', 'figure', 'mdp', 'transition', 'structure', 'consist', 'dynamic', 'reward', 'function', 'regular', 'structure', 'b', 'c', 'factorize', 'yet', 'still', 'general', 'structure', 'inherently', 'separate', 'information', 'controllable', 'ctrl', 'uncontrollable', 'ctrl', 'rewardrelevant', 'rew', 'rewardirrelevant', 'rew', 'presence', 'variable', 'cell', 'mean', 'possible', 'contain', 'respective', 'information', 'eg', 'contain', 'rewardirrelevant', 'information', 'c', 'x', 'dynamic', 'form', 'mdp', 'less', 'noise', 'sufﬁcient', 'optimal', 'planning', 'denoise', 'mdp', 'see', 'section', 'base', 'factorization', 'transition', 'factorize', 'uncontrol', 'rewardirrelevant', 'instead', 'focus', 'factor', 'simply', 'evolve', 'inﬂuence', 'inﬂuence', 'information', 'safely', 'ignore', 'still', 'affect', 'reward', 'light', 'drive', 'fortunately', 'usual', 'objective', 'maximize', 'expect', 'return', 'ignore', 'one', 'additively', 'affect', 'reward', 'concretely', 'mdp', 'transition', 'represent', 'form', 'figure', '2b', 'say', 'variable', 'yr', 'uncontrol', 'lable', 'information', 'evolve', 'independently', 'action', 'affect', 'controllable', 'additively', 'fect', 'reward', 'ignore', 'safely', 'discard', 'yr', 'noise', 'distractor', 'operate', 'compressed', 'mdp', 'sufﬁcient', 'optimal', 'control', 'rewardrelevance', 'controllable', 'information', 'still', 'completely', 'unrelated', 'reward', 'figure', 'bird', 'affect', 'opening', 'curtain', 'irrelevant', 'task', 'let', 'sunlight', 'case', 'information', 'safely', 'discard', 'affect', 'objective', 'mdp', 'transition', 'represent', 'form', 'figure', 'say', 'rewardirrelevant', 'evolve', 'potentially', 'use', 'latent', 'variable', 'action', 'crucially', 'affect', 'similar', 'uncontrollable', 'information', 'noise', 'distractor', 'discard', 'compressed', 'mdp', 'contain', 'signal', 'need', 'optimal', 'control', 'information', 'exist', 'method', 'learn', 'many', 'prior', 'work', 'explore', 'state', 'abstraction', 'form', 'cast', 'several', 'representative', 'one', 'reconstructionbase', 'modelbase', 'modelbase', 'bisimulation', 'fern', 'modelfree', 'task', 'inform', 'abstraction', 'tia', 'fu', 'modelbase', 'denoise', 'mdp', 'figure', 'variant', 'method', 'section', 'modelbase', 'denoise', 'mdp', 'figure', 'variant', 'method', 'section', 'modelbase', 'rewrew', 'cid51', 'cid51', 'cid51', 'cid51', 'ctrl', 'ctrl', 'rewrew', 'ctrl', 'ctrl', 'rewrew', 'cid51', 'rewrew', 'cid51', 'cid51', 'rewrew', 'ctrl', 'information', 'grid', 'legend', 'cid51', 'keep', 'reduce', 'depend', 'information', 'integrate', 'observation', 'figure', 'categorization', 'information', 'learn', 'remove', 'various', 'method', 'distinct', 'formulation', 'framework', 'describe', 'show', 'kind', 'information', 'learn', 'remove', 'summarize', 'figure', 'together', 'propose', 'method', 'explain', 'section', 'discuss', 'prior', 'work', 'detail', 'reconstructionbase', 'modelbase', 'many', 'model', 'base', 'method', 'learn', 'reconstruction', 'single', 'latent', 'code', 'often', 'result', 'variational', 'formulation', 'hafner', 'latent', 'code', 'denoise', 'mdps', 'try', 'compress', 'information', 'present', 'observa', 'tion', 'necessarily', 'contain', 'type', 'information', 'bisimulation', 'deﬁne', 'state', 'abstraction', 'state', 'aggregate', 'together', 'ex', 'pected', 'return', 'transition', 'dynamic', 'know', 'optimally', 'ignore', 'rewardirrelevant', 'information', 'fern', 'continuous', 'version', 'bisimilation', 'metric', 'gain', 'popular', 'ity', 'learn', 'computationally', 'difﬁcult', 'modi', 'even', 'many', 'additional', 'assumption', 'erally', 'possible', 'learn', 'onpolicy', 'variant', 'lose', 'task', 'inform', 'abstraction', 'tia', 'fu', 'extend', 'dreamer', 'model', 'independent', 'mdps', 'represent', 'signal', 'noise', 'noise', 'latent', 'enforce', 'independent', 'reward', 'reconstruct', 'observation', 'well', 'possible', 'reconstruction', 'latent', 'compose', 'together', 'use', 'infer', 'mask', 'pixelspace', 'form', 'full', 'reconstruction', 'construction', 'loss', 'special', 'structure', 'tia', 'remove', 'rewardirrelevant', 'noise', 'distractor', 'present', 'pixelwise', 'compose', 'image', 'independent', 'process', 'eg', 'agent', 'move', 'noisy', 'background', 'general', 'one', 'eg', 'shaky', 'camera', 'affect', 'agent', 'noisy', 'background', 'predictive', 'information', 'datum', 'augmentation', 'set', 'research', 'learn', 'state', 'representation', 'contain', 'information', 'useful', 'predict', 'future', 'state', 'pisac', 'augmented', 'view', 'current', 'state', 'laskin', 'method', 'guarantee', 'removal', 'redundant', 'piece', 'information', 'identiﬁe', 'noniid', 'noise', 'eg', 'people', 'move', 'background', 'predictive', 'future', 'keep', 'pi', 'sac', 'performance', 'augmentationbase', 'method', 'critically', 'rely', 'speciﬁc', 'type', 'augmentation', 'use', 'relevance', 'task', 'show', 'experiment', 'see', 'indeed', 'struggle', 'handle', 'certain', 'noise', 'type', 'possible', 'extension', 'far', 'factorization', 'framework', 'sufﬁcient', 'characterize', 'prior', 'work', 'related', 'task', 'also', 'readily', 'ex', 'tend', 'far', 'factorize', 'transition', 'structure', 'eg', 'independent', 'process', 'confound', 'signal', 'process', 'noise', 'process', 'ﬁtte', 'figure', 'structure', 'group', 'process', 'properly', 'model', 'dependency', 'however', 'factorization', 'show', 'consider', 'signal', 'confound', 'process', 'theoretically', 'sufﬁcient', 'control', 'leave', 'extension', 'future', 'work', 'denoise', 'mdps', 'figure', '2c', 'show', 'special', 'mdp', 'structure', 'tomatically', 'identify', 'certain', 'information', 'ignore', 'leave', 'useful', 'information', 'also', 'form', 'mdp', 'suggest', 'naïve', 'approach', 'directly', 'ﬁtte', 'structure', 'collect', 'trajectory', 'extract', 'however', 'mdp', 'dynamic', 'reward', 'decompose', 'figure', 'many', 'different', 'way', 'extreme', 'case', 'even', 'contain', 'information', 'raw', 'state', 'extraction', 'help', 'instead', 'desire', 'ﬁt', 'minimal', 'x', 'deﬁne', 'least', 'informative', 'removal', 'latent', 'variable', 'discard', 'information', 'possible', 'concretely', 'aim', 'ﬁt', 'least', 'ixtt', 't1', 'mutual', 'information', 'contain', 'step', 'extract', 'minimal', 'denoised', 'mdp', 'notation', 'simplicity', 'use', 'bold', 'symbol', 'denote', 'variable', 'sequence', 'thus', 'write', 't1', 't1', 'practically', 'consider', 'regularize', 'modelﬁtte', 'show', 'amount', 'modiﬁ', 'cation', 'wellestablished', 'variational', 'objective', 'hafner', 'result', 'method', 'easytoimplement', 'yet', 'effective', 'enable', 'clean', 'removal', 'various', 'noise', 'distrac', 'tor', 'original', 'formulation', 'handle', 'see', 'section', 'instantiate', 'idea', 'structure', 'figure', 'figure', 'formulation', 'obtain', 'simply', 'remove', 'z', 'component', 'view', 'combine', 'yr', 'transition', 'structure', 'model', 'component', 'pzt', 'θ', 'pθxt', 'xt−1', 'pθrx', 'pθry', 'yt', 'dynamic', 'reward', 'dynamic', 'reward', 'z', 'dynamic', 'emission', 'consider', 'training', 'datum', 'form', 'trajectory', 'segment', 'r', 'sample', 'datum', 'distribution', 'pdata', 'eg', 'store', 'agent', 'experience', 'replay', 'buffer', 'perform', 'model', 'learning', 'minimize', 'negative', 'log', 'likelihood', 'lmleθ', 'cid2', 'log', 'cid3', 'obtain', 'tractable', 'form', 'jointly', 'learn', 'variational', 'posterior', 'component', 'encoder', 'qψxt', 'posterior', 'posterior', 'posterior', 'denoise', 'mdps', 'product', 'deﬁne', 'posterior', 'choose', 'factorize', 'form', 'base', 'forward', 'prior', 'model', 'structure', 'figure', 'model', 'optimize', 'standard', 'varia', 'tional', 'bind', 'log', 'likelihood', 'esar', 'exyz∼', 'log', 'pθs', 'r', 'cid123cid122', 'dkl', 'ψ', 'pyt', 'dkl', 'cid0qxt', 'pxt', 'lklxθ', 'dkl', 'pzt', 't1', 'lklyθ', 'ψ', 'cid1', 'cid125', 'cid1', 'cid125', 't1', 't1', 'equality', 'attain', 'optimal', 'compatible', 'exact', 'posterior', 'pθ', 'mutual', 'information', 'regularizer', 'use', 'variational', 'formulation', 'write', 'equality', 'attain', 'pθ', 'compatible', 'appendix', 'describe', 'derivation', 'detail', 'therefore', 'regularizer', 'weight', 'equation', 'together', 'c', 'lklxθ', 'recall', 'ﬁt', 'true', 'mdp', 'structure', 'fig', 'inherently', 'guarantee', 'useful', 'information', 'latent', 'variable', 'regularizer', 'ensure', 'learn', 'minimal', 'latent', 'learned', 'model', 'extract', 'mdp', 'condense', 'useful', 'information', 'denoise', 'state', 'space', 'pθxcid48', 'transition', 'dynamic', 'xcid48', 'reward', 'function', 'mdp', 'call', 'denoised', 'mdp', 'discard', 'noise', 'distractor', 'contain', 'additionally', 'also', 'obtain', 'encoder', 'mapping', 'raw', 'noisy', 'observation', 'denoise', 'loss', 'variant', 'improved', 'stability', 'use', 'large', 'eg', 'environment', 'expect', 'noisy', 'equation', 'contain', 'term', 'large', 'weight', 'thus', 'equation', 'often', 'require', 'learn', 'rate', 'tune', 'different', 'c', 'avoid', 'use', 'following', 'loss', 'form', 'empirically', 'well', 'training', 'stability', 'require', 'tune', 'learn', 'rate', 'wrt', 'hyperpa', 'dreamer', 'hafner', 'deﬁne', 'pos', 'terior', 'ﬁrststep', 'latent', 'zero', 'vector', 'appropriate', 'size', 'denoise', 'mdp', 'input', 'model', 'pθ', 'posterior', 'encoder', 'policy', 'policy', 'optimization', 'piopt', 'output', 'denoise', 'mdp', 'pθ', 'encoder', 'policy', 'π', 'training', 'exploration', 'collect', 'trajectory', 'π', 'act', 'encode', 'output', 'model', 'learn', 'sample', 'batch', 'r', 'segment', 'reply', 'buffer', 'train', 'pθ', 'qψ', 'equation', 'r', 'policy', 'optimization', 'sample', 'compute', 'rx', 'pθrx', 'train', 'π', 'run', 'piopt', 'rx', 'end', 'rameter', 'min', 'βlkly', 'βlklz', 'ψ', 'argument', 'omit', 'hyperparame', 'ter', 'β', 'bound', 'represent', 'regularization', 'α', 'also', 'generally', 'small', 'simply', 'choose', 'accord', 'statespace', 'dimensional', 'ity', 'see', 'experiment', 'form', 'justiﬁe', 'observation', 'practice', 'use', 'isotropic', 'gaussian', 'ﬁxed', 'variance', 'parameter', 'ize', 'distribution', 'observation', 'reward', 'scale', 'log', 'likelihood', 'essentially', 'change', 'variance', 'hyperparameter', 'thus', 'equation', 'effectively', 'scale', 'equation', 'different', 'variance', 'hyperparameter', 'online', 'policy', 'optimization', 'model', 'ﬁtte', 'objective', 'equation', 'use', 'various', 'set', 'ting', 'eg', 'ofﬂine', 'collected', 'trajectory', 'dataset', 'assume', 'exist', 'datum', 'explore', 'online', 'setting', 'training', 'process', 'iteratively', 'perform', 'explo', 'ration', 'modelﬁtting', 'policy', 'optimization', 'show', 'policy', 'operate', 'denoised', 'mdp', 'infor', 'mation', 'sufﬁcient', 'control', 'policy', 'optimization', 'learn', 'posterior', 'encoder', 'use', 'extract', 'information', 'raw', 'trajectory', 'r', 'obtain', 'transition', 'sequence', 'x', 'space', 'pair', 'pθrx', 'reward', 'obtain', 'rx', 'trajectory', 'collect', 'denoise', 'mdp', 'generalpurpose', 'mdp', 'policy', 'optimization', 'employ', 'datum', 'stochastic', 'actorcritic', 'sac', 'haarnoja', 'also', 'utilize', 'learn', 'differentiable', 'denoise', 'mdp', 'optimize', 'policy', 'backpropagate', 'addi', 'tional', 'rollout', 'model', 'dreamer', 'present', 'fully', 'observable', 'setting', 'denoise', 'mdp', 'readily', 'handle', 'partial', 'observability', 'extra', 'change', 'appendix', 'discuss', 'point', 'detail', 'provide', 'guideline', 'choose', 'hyperparameter', 'denoise', 'mdps', 'relate', 'work', 'modelbase', 'learn', 'control', 'jointly', 'learn', 'world', 'model', 'policy', 'method', 'often', 'enjoy', 'good', 'sample', 'efﬁciency', 'task', 'rich', 'observation', 'formulation', 'rely', 'strong', 'assumption', 'tic', 'transition', 'transition', 'flambe', 'agarwal', 'et', 'generalsette', 'method', 'use', 'reconstructionbase', 'objec', 'tive', 'hafner', 'lee', 'dreamer', 'train', 'world', 'model', 'variational', 'formu', 'lation', 'optimize', 'policy', 'backpropagate', 'latentspace', 'rollout', 'prove', 'effective', 'riety', 'environment', 'image', 'observation', 'however', 'reconstructionbase', 'approach', 'struggle', 'presence', 'noise', 'distractor', 'partially', 'address', 'limitation', 'see', 'section', 'handle', 'general', 'distractor', 'method', 'representation', 'learning', 'reinforcement', 'learn', 'work', 'automate', 'select', 'useful', 'signal', 'noisy', 'mdps', 'learn', 'denoise', 'world', 'model', 'view', 'approach', 'learn', 'general', 'representation', 'et', 'mikolov', 'et', 'modelfree', 'various', 'method', 'learn', 'state', 'embedding', 'relate', 'value', 'function', 'schaul', 'bellemare', 'transition', 'dynamic', 'maggioni', 'lee', 'recent', 'bisimulation', 'structure', 'fern', 'datum', 'augmentation', 'laskin', 'recently', 'eysenbach', 'propose', 'regularizer', 'similar', 'different', 'purpose', 'robust', 'compressed', 'policy', 'theoretical', 'work', 'close', 'setting', 'concern', 'restricted', 'set', 'distractor', 'one', 'uncontrollable', 'rewardirrelevant', 'denoise', 'pro', 'pose', 'largely', 'impractical', 'produce', 'generative', 'model', 'observation', 'decoder', 'system', 'identiﬁcation', 'work', 'relate', 'system', 'identiﬁcation', 'algorithm', 'infer', 'real', 'world', 'abstract', 'state', 'predeﬁne', 'limited', 'state', 'space', 'pose', 'estimation', 'rıza', 'yenchen', 'material', 'estimation', 'result', 'useful', 'robotic', 'manipulation', 'image', 'generation', 'setting', 'limit', 'predeﬁne', 'abstract', 'state', 'space', 'instead', 'focus', 'automatic', 'discovery', 'valuable', 'state', 'experiment', 'section', 'contrast', 'method', 'exist', 'proache', 'environment', 'image', 'observation', 'many', 'distinct', 'type', 'noise', 'distractor', 'experiment', 'design', 'include', 'variety', 'noise', 'distractor', 'conﬁrm', 'analysis', 'various', 'method', 'section', 'environment', 'choose', 'tunyasuvunakool', 'section', 'section', 'image', 'observation', 'explore', 'add', 'various', 'noise', 'tractor', 'information', 'type', 'evaluate', 'environment', 'categorize', 'table', 'appendix', 'task', 'include', 'control', 'policy', 'optimization', 'noncontrol', 'task', 'regress', 'robot', 'joint', 'position', 'robodesk', 'image', 'observation', 'method', 'compare', 'modelbase', 'meth', 'od', 'also', 'modelfree', 'algorithm', 'general', 'representa', 'tion', 'learning', 'approach', 'task', 'suit', 'model', 'learning', 'denoise', 'method', 'dreamer', 'tia', 'fu', 'modelfree', 'et', 'laskin', 'pisac', 'data', 'augmentation', 'fair', 'comparison', 'core', 'predictive', 'information', 'regularization', 'nonaugmenting', 'method', 'sac', 'true', 'statespace', 'haarnoja', 'instead', 'use', 'image', 'observation', 'roughly', 'upper', 'bind', 'general', 'image', 'representation', 'learn', 'non', 'control', 'task', 'contrastive', 'learn', 'align', 'mentuniformity', 'loss', 'form', 'contrastive', 'loss', 'theoretically', 'empirically', 'comparable', 'popular', 'infonce', 'loss', 'oord', 'modellearning', 'method', 'use', 'combination', 'policy', 'optimization', 'algorithm', 'complete', 'com', 'parison', 'general', 'control', 'compare', 'model', 'train', 'policy', 'learning', 'choice', 'backpropagating', 'learn', 'dynamic', 'sac', 'learned', 'tent', 'space', 'roughly', 'recover', 'use', 'unfactorized', 'model', 'dreamer', 'compare', 'method', 'apply', 'data', 'augmentation', 'know', 'strongly', 'boost', 'performance', 'yarat', 'laskin', '2020a', 'therefore', 'fair', 'comparison', 'run', 'pisac', 'augmentation', 'highlight', 'main', 'contribution', 'representation', 'predictive', 'information', 'result', 'aggregate', 'run', 'show', 'mean', 'standard', 'deviation', 'appendix', 'contain', 'detail', 'hyperparameter', 'study', 'additional', 'result', 'website', 'present', 'video', 'show', 'clear', 'video', 'visualization', 'denoise', 'mdp', 'use', 'figure', 'variant', 'empiri', 'cally', 'figure', 'variant', 'lead', 'long', 'train', 'time', 'sometimes', 'inferior', 'performance', 'perhaps', 'due', 'optimize', 'extra', 'component', 'ﬁt', 'complex', 'model', 'appendix', 'provide', 'comparison', 'denoise', 'mdps', 'figure', 'visualization', 'learn', 'model', 'robodesk', 'use', 'decoder', 'reconstruct', 'encode', 'latent', 'tia', 'denoise', 'mdp', 'visualize', 'separate', 'information', 'signal', 'noise', 'row', 'change', 'frame', 'information', 'model', 'correspond', 'latent', 'component', 'eg', 'bottom', 'row', 'tv', 'content', 'camera', 'pose', 'lighting', 'condition', 'change', 'denoise', 'mdp', 'consider', 'factor', 'noise', 'model', 'tv', 'hue', 'see', 'website', 'clear', 'video', 'visualization', 'robodesk', 'various', 'noise', 'distractor', 'augment', 'robodesk', 'environment', 'many', 'noise', 'dis', 'tractor', 'model', 'realistic', 'noise', 'eg', 'ﬂickere', 'light', 'shaky', 'camera', 'importantly', 'place', 'large', 'tv', 'scene', 'play', 'natural', 'video', 'green', 'button', 'desk', 'control', 'tv', '’s', 'hue', 'light', 'desk', 'agent', 'task', 'use', 'button', 'shift', 'tv', 'green', 'hue', 'reward', 'directly', 'affect', 'green', 'tv', 'image', 'ﬁrst', 'row', 'figure', 'show', 'trajectory', 'various', 'distractor', 'annotate', 'type', 'information', 'exist', 'see', 'table', 'controllable', 'rewardrelevant', 'information', 'robot', 'arm', 'green', 'button', 'light', 'desk', 'tv', 'screen', 'greenness', 'controllable', 'rewardrelevant', 'information', 'signal', 'signal', 'row', 'track', 'change', 'robot', 'arm', 'green', 'button', 'light', 'tv', 'screen', 'greenness', 'information', 'model', 'noise', 'see', 'noise', 'row', 'recommend', 'view', 'video', 'visualization', 'website', 'denoise', 'model', 'improve', 'policy', 'learning', 'figure', 'also', 'show', 'total', 'episode', 'return', 'achieve', 'policy', 'learn', 'model', 'clean', 'model', 'denoised', 'mdp', 'achieve', 'good', 'performance', 'aggregate', 'run', 'complete', 'comparison', 'fig', 'show', 'denoise', 'mdp', 'backpropagate', 'dynamic', 'generally', 'outperform', 'baseline', 'suggest', 'clean', 'model', 'helpful', 'control', 'denoise', 'mdp', 'learn', 'clean', 'denoised', 'model', 'use', 'learn', 'decoder', 'figure', 'visualize', 'mod', 'el', 'capture', 'various', 'information', 'expect', 'dreamer', 'model', 'capture', 'information', 'tia', 'also', 'fail', 'separate', 'noise', 'distractor', 'noise', 'row', 'fail', 'capture', 'likely', 'limited', 'ability', 'model', 'differ', 'ent', 'noise', 'contrast', 'denoise', 'mdp', 'cleanly', 'extract', 'denoise', 'model', 'beneﬁt', 'noncontrol', 'task', 'eat', 'learn', 'representation', 'supervised', 'noncontrol', 'task', 'regress', 'robot', 'arm', 'joint', 'position', 'observed', 'image', 'use', 'various', 'pretraine', 'encoder', 'ﬁnetune', 'labeled', 'training', 'set', 'measure', 'mean', 'square', 'error', 'mse', 'heldout', 'test', 'set', 'addition', 'rl', 'method', 'compare', 'encoder', 'learn', 'general', 'contrastive', 'learning', 'block', 'desk', 'ctrl', 'tv', 'image', 'greenness', 'ctrl', 'light', 'robot', 'joint', 'ctrl', 'tv', 'semantic', 'content', 'rew', 'shakyflickere', 'camera', 'light', 'recon', 'recon', 'latexit', 'tia', 'signal', 'noise', 'recon', 'signal', 'noise', 'denoise', 'mdp', 'latexit', 'denoise', 'mdps', 'figure', 'policy', 'optimization', 'robodesk', 'give', 'sac', 'less', 'noisy', 'reward', 'learn', 'see', 'appendix', 'figure', 'performance', 'ﬁnetune', 'various', 'encoder', 'infer', 'joint', 'position', 'robodesk', 'image', 'observation', 'policy', 'learning', 'backprop', 'dynamic', 'policy', 'learning', 'sac', 'latentspace', 'denoise', 'tia', 'denoise', 'pisac', 'use', 'upper', 'bind', 'noiseless', '±', '±', '±', '±', '±', '±', '±', '±', '±', 'video', 'background', '±', '±', '±', '±', '±', '±', '±', '±', '±', 'video', 'background', 'noisy', 'sensor', 'video', 'background', 'camera', 'jittere', '±', '±', '±', '±', '±', '±', '±', '±', '±', '±', '±', '±', '±', '±', '±', '±', '±', '±', 'table', 'dmc', 'policy', 'optimization', 'result', 'variant', 'aggregate', 'performance', 'task', 'walker', 'walk', 'reacher', 'easy', 'average', 'denoise', 'mdp', 'perform', 'well', 'variant', 'distinct', 'noise', 'type', 'bold', 'number', 'show', 'good', 'modellearning', 'result', 'speciﬁc', 'policy', 'learning', 'choice', 'good', 'overall', 'result', 'camera', 'jittering', 'denoise', 'mdp', 'greatly', 'outperform', 'method', 'curl', 'potentially', 'beneﬁts', 'speciﬁc', 'data', 'augmentation', 'choice', 'random', 'crop', 'task', 'see', 'use', 'extra', 'information', 'know', 'noise', 'distractor', 'form', 'fact', 'denoise', 'mdp', 'method', 'consistently', 'perform', 'well', 'task', 'noise', 'variant', 'see', 'full', 'result', 'appendix', 'amount', 'datum', 'figure', 'denoise', 'mdp', 'representation', 'lead', 'well', 'converge', 'solution', 'wide', 'range', 'training', 'set', 'size', 'achieve', 'fast', 'training', 'avoid', 'overﬁtte', 'training', 'set', 'small', 'dbc', 'curl', 'pisac', 'encoder', 'take', 'stack', 'frame', 'directly', 'comparable', 'thus', 'absent', 'figure', 'appendix', 'compare', 'running', 'denoise', 'mdp', 'encoder', 'frame', 'concatenate', 'output', 'fea', 'ture', 'denoise', 'handily', 'outperform', 'dbc', 'curl', 'large', 'margin', 'deepmind', 'control', 'suite', 'evaluate', 'diverse', 'set', 'noise', 'distractor', 'consider', 'variant', 'dmc', 'task', 'see', 'figure', 'top', 'row', 'noiseless', 'original', 'environment', 'distractor', 'video', 'background', 'replace', 'noiseless', 'background', 'natural', 'video', 'rew', 'video', 'background', 'sensor', 'noise', 'imperfect', 'sensor', 'sensitive', 'intensity', 'background', 'patch', 'ctrlrew', 'video', 'background', 'camera', 'jittering', 'shift', 'observation', 'smooth', 'random', 'walk', 'ctrl', 'denoise', 'mdp', 'consistently', 'remove', 'noise', 'distractor', 'figure', 'tia', 'struggle', 'learn', 'clean', 'separation', 'many', 'setting', 'consistent', 'analysis', 'section', 'handle', 'sensor', 'noise', 'camera', 'jittering', 'former', 'rewardrelevant', 'noise', 'model', 'latter', 'rewardirrelevant', 'represent', 'mask', 'furthermore', 'fail', 'reacher', 'easy', 'video', 'background', 'reward', 'give', 'distance', 'agent', 'randomlylocated', 'ball', 'tia', 'encour', 'age', 'noise', 'latent', 'independent', 'reward', 'prevent', 'capture', 'controllable', 'agent', 'failure', 'lead', 'tia', 'try', 'model', 'useful', 'signal', 'badlyﬁt', 'model', 'wrong', 'agent', 'pose', 'last', 'column', 'contrast', 'denoise', 'mdp', 'separate', 'noise', 'case', 'obtain', 'clean', 'accurate', 'signal', 'row', 'agent', 'move', 'denoise', 'model', 'consistently', 'improve', 'policy', 'learning', 'evaluate', 'learn', 'policy', 'table', 'result', 'aggregate', 'noise', 'distractor', 'variant', 'meth', 'od', 'sometimes', 'handle', 'certain', 'noise', 'type', 'well', 'struggle', 'deal', 'distinct', 'variant', 'tia', 'pecte', 'greatly', 'underperform', 'denoise', 'mdp', 'noisy', 'sensor', 'camera', 'jittere', 'curl', 'augmentation', 'choice', 'potentially', 'help', 'handle', 'camera', 'jittere', 'perform', 'variant', 'contrast', 'denoise', 'statespace', 'sac', 'modify', 'reward', 'joint', 'position', 'regression', 'final', 'test', 'mse', 'training', 'set', 'size', 'joint', 'position', 'regression', 'learning', 'curve', 'train', 'denoise', 'mdps', 'figure', 'visualization', 'different', 'dmc', 'variant', 'factorization', 'learn', 'tia', 'denoise', 'mdp', 'bottom', 'noise', 'row', 'often', 'show', 'static', 'agent', 'vary', 'background', 'indicate', 'background', 'model', 'noise', 'denoise', 'mdp', 'visualization', 'full', 'reconstruction', 'see', 'website', 'clear', 'video', 'visualization', 'policy', 'consistently', 'perform', 'well', 'noisy', 'variant', 'also', 'noiseless', 'set', 'regardless', 'policy', 'optimizer', 'modelbase', 'approach', 'signiﬁcant', 'lead', 'modelfree', 'one', 'see', 'dbc', 'result', 'table', 'wellknown', 'fact', 'direct', 'modelfree', 'learning', 'raw', 'image', 'observation', 'usually', 'fail', 'laskin', 'yarat', 'result', 'show', 'learn', 'world', 'model', 'useful', 'learn', 'denoised', 'world', 'model', 'even', 'well', 'implication', 'work', 'explore', 'learn', 'denoise', 'compressed', 'world', 'model', 'presence', 'environment', 'noise', 'step', 'well', 'understanding', 'noise', 'categorize', 'information', 'wild', 'type', 'tion', 'provide', 'framework', 'contrast', 'stand', 'various', 'method', 'highlight', 'successful', 'suffer', 'section', 'insight', 'gain', 'way', 'empirically', 'agree', 'ﬁnding', 'exten', 'sive', 'experiment', 'section', 'potentially', 'assist', 'well', 'design', 'analysis', 'new', 'representation', 'method', 'design', 'denoise', 'mdp', 'section', 'believe', 'categorization', 'useful', 'framework', 'investigation', 'learn', 'noise', 'reveal', 'conceptual', 'success', 'scenario', 'also', 'failure', 'scenario', 'time', 'additionally', 'framework', 'readily', 'extend', 'sophisticated', 'factorization', 'section', 'lead', 'correspond', 'ing', 'denoise', 'variant', 'andor', 'new', 'algorithm', 'base', 'framework', 'propose', 'denoise', 'mdp', 'elly', 'remove', 'noise', 'distractor', 'uncontrollable', 'rewardirrelevant', 'distinction', 'prior', 'work', 'cally', 'effectively', 'identiﬁes', 'remove', 'diverse', 'set', 'noise', 'type', 'obtain', 'clean', 'denoise', 'world', 'model', 'serve', 'important', 'step', 'efﬁcient', 'learning', 'general', 'task', 'noisy', 'real', 'world', 'ex', 'periment', 'also', 'highlight', 'beneﬁts', 'cleanly', 'denoise', 'world', 'model', 'standard', 'control', 'task', 'well', 'noncontrol', 'task', 'success', 'case', 'highlight', 'general', 'use', 'fulness', 'model', 'give', 'generality', 'mdps', 'open', 'possibility', 'cast', 'nonrl', 'task', 'mdps', 'automatically', 'learn', 'representation', 'denoise', 'world', 'model', 'alternative', 'manual', 'feature', 'engineering', 'acknowledgement', 'thank', 'beautiful', 'figure', 'illustration', 'thank', 'helpful', 'comment', 'suggestion', 'grateful', 'follow', 'organization', 'provide', 'computation', 'resource', 'project', 'mit', 'satori', 'cluster', 'mit', 'compute', 'credit', 'gift', 'mit', 'thankful', 'suggestion', 'catch', 'typo', 'conditioning', 'equation', 'run', 'noiseless', 'reacher', 'easy', 'video', 'background', 'walker', 'walk', 'video', 'background', 'noisy', 'sensor', 'run', 'video', 'background', 'camera', 'jittere', 'env', 'rollout', 'denoise', 'noise', 'signal', 'noise', 'denoise', 'mdps', 'reference', 'agarwal', 'kakade', 'krishnamurthy', 'sun', 'flambe', 'structural', 'complexity', 'preprint', 'tation', 'learning', 'low', 'rank', 'mdps', 'bellemare', 'n', 'schuurman', 'lattimore', 'geometric', 'perspective', 'optimal', 'representation', 'reinforcement', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'p', 'scalable', 'method', 'compute', 'state', 'similarity', 'deterministic', 'markov', 'decision', 'process', 'proceed', 'ing', 'conference', 'artiﬁcial', 'intelligence', 'volume', 'coate', 'analysis', 'single', 'layer', 'network', 'unsupervised', 'feature', 'learning', 'pro', 'ceeding', 'fourteenth', 'international', 'conference', 'artiﬁcial', 'intelligence', 'statistic', 'nature', 'explanation', 'c', 'law', 'effect', 'go', 'away', 'journal', 'theory', 'social', 'behaviour', 'decaf', 'deep', 'convolutional', 'activation', 'feature', 'generic', 'visual', 'recognition', 'national', 'conference', 'machine', 'learning', 'pmlr', 'agarwal', 'dudik', 'langford', 'provably', 'efﬁcient', 'rich', 'obser', 'vation', 'latent', 'state', 'decode', 'international', 'con', 'ference', 'machine', 'learn', 'pmlr', 'efroni', 'krishnamurthy', 'agarwal', 'langford', 'j', 'provable', 'rl', 'exogenous', 'distrac', 'tor', 'multistep', 'dynamic', 'preprint', 'elman', 'find', 'structure', 'time', 'cognitive', 'science', '142179–211', 'eysenbach', 'b', 'salakhutdinov', 'r', 'robust', 'predictable', 'control', 'preprint', 'fern', 'p', 'metric', 'ﬁnite', 'markov', 'decision', 'process', 'volume', 'learn', 'task', 'inform', 'abstraction', 'international', 'conference', 'machine', 'learning', 'pmlr', 'deepmdp', 'learn', 'continuous', 'latent', 'space', 'model', 'representation', 'learn', 'international', 'con', 'ference', 'machine', 'learning', 'pmlr', 'equivalence', 'notion', 'model', 'minimization', 'markov', 'decision', 'process', 'artiﬁcial', 'intelligence', '14712163–223', 'yuan', 'l', 'maskguided', 'portrait', 'editing', 'conditional', 'gan', 'proceeding', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'schmidhuber', 'world', 'model', 'preprint', 'hartikainen', 'abbeel', 'p', 'soft', 'actorcritic', 'algorithm', 'application', 'preprint', 'hafner', 'dream', 'control', 'learn', 'behavior', 'latent', 'imagination', 'preprint', 'fischer', 'villegas', 'davidson', 'learn', 'latent', 'dynamic', 'plan', 'pixel', 'international', 'conference', 'machine', 'learning', 'pmlr', 'bern', 'parameter', 'estimation', 'dynamic', 'motion', 'acm', 'transaction', 'graphic', 'tog', 'contrast', 'unsupervised', 'visual', 'representation', 'learn', 'preprint', 'efro', 'make', 'preprint', 'imagenet', 'good', 'transfer', 'learn', 'robodesk', 'multitask', 'reinforcement', 'learn', 'philion', 'learn', 'simulate', 'dynamic', 'environment', 'ieee', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'cvpr', 'denoise', 'mdps', 'kostrikov', 'yarat', 'fergus', 'r', 'image', 'augmentation', 'need', 'regularize', 'deep', 'reinforcement', 'learn', 'preprint', 'stooke', 'l', 'abbeel', 'srinivas', 'reinforcement', 'learning', 'augmented', 'datum', 'advance', 'neural', 'information', 'processing', 'system', '2020a', 'laskin', 'abbeel', 'p', 'curl', 'contrastive', 'unsupervised', 'representation', 'reinforcement', 'learning', 'international', 'conference', 'machine', 'learning', 'pmlr', '2020b', 'international', 'conference', 'machine', 'learning', 'pmlr', 'puterman', 'decision', 'process', 'discrete', 'stochastic', 'dynamic', 'programming', 'isbn', 'rıza', 'densepose', 'dense', 'human', 'pose', 'estimation', 'wild', 'schaul', 'silver', 'universal', 'value', 'function', 'approximator', 'international', 'conference', 'machine', 'learning', 'pmlr', 'nagabandi', 'abbeel', 'p', 'actorcritic', 'deep', 'reinforcement', 'learn', 'latent', 'variable', 'model', 'preprint', 'clancy', 'zisserman', 'short', 'note', 'human', 'preprint', 'fischer', 'guo', 'h', 'predictive', 'information', 'accelerate', 'learn', 'advance', 'neural', 'information', 'processing', 'system', 'lowe', 'g', 'object', 'recognition', 'local', 'scaleinvariant', 'feature', 'proceeding', 'seventh', 'ieee', 'interna', 'tional', 'conference', 'computer', 'vision', 'volume', 'pp', 'ieee', 'maggioni', 'protovalue', 'function', 'laplacian', 'framework', 'learn', 'representation', 'control', 'markov', 'decision', 'process', 'journal', 'machine', 'learn', 'research', 'florence', 'p', 'tedrake', 'r', 'kpam', 'keypoint', 'affordance', 'categorylevel', 'robotic', 'preprint', 'mikolov', 'efﬁcient', 'estimation', 'word', 'representation', 'vector', 'space', 'preprint', 'modi', 'sample', 'com', 'plexity', 'reinforcement', 'learning', 'use', 'linearly', 'combine', 'model', 'ensemble', 'international', 'conference', 'cial', 'intelligence', 'statistic', 'pmlr', 'oord', 'v', 'vinyal', 'representation', 'learn', 'e', 'contrastive', 'predictive', 'code', 'arxiv', 'preprint', 'pathak', 'efro', 'exploration', 'selfsupervise', 'predic', 'tion', 'icml', 'poole', 'ozair', 'tucker', 'variational', 'bound', 'mutual', 'information', 'spelke', 'core', 'knowledge', 'develop', 'mental', 'science', 'r', 'adaptive', 'network', 'construct', 'use', 'internal', 'model', 'world', 'cognition', 'brain', 'theory', 'r', 'dyna', 'integrate', 'architecture', 'learn', 'planning', 'react', 'acm', 'sigart', 'bulletin', 'todorov', 'tassa', 'physics', 'engine', 'modelbase', 'control', 'ieeersj', 'inter', 'national', 'conference', 'intelligent', 'robot', 'system', 'ieee', 'tunyasuvunakool', 'muldal', 'doron', 'heess', 'n', 'tassa', 'dmcontrol', 'software', 'task', 'continuous', 'control', 'software', 'impact', 'isola', 'p', 'understand', 'contrastive', 'represen', 'tation', 'learn', 'alignment', 'uniformity', 'hypersphere', 'proceeding', '37th', 'international', 'conference', 'machine', 'learning', 'volume', 'pro', 'ceeding', 'machine', 'learning', 'research', 'pmlr', 'yarat', 'fergus', 'r', 'lazaric', 'l', 'master', 'visual', 'continuous', 'control', 'improve', 'dataaugmente', 'inforcement', 'learn', 'arxiv', 'preprint', 'yenchen', 'l', 'florence', 'barron', 'rodriguez', 'isola', 'p', 'inerf', 'invert', 'neural', 'radiance', 'ﬁeld', 'pose', 'estimation', 'ieeersj', 'international', 'conference', 'intelligent', 'robot', 'system', 'iro', 'denoise', 'mcallister', 'r', 'learn', 'invariant', 'representation', 'rein', 'forcement', 'learning', 'reconstruction', 'preprint', 'denoise', 'mdp', 'discussion', 'loss', 'derivation', 'denoise', 'mdps', 'apply', 'mutual', 'information', 'regularizer', 'consider', 'form', 'use', 'variational', 'distribution', 'see', 'poole', 'min', 'dklpθx', 'cid107', 'ρx', 'ρ', 'eaeqψsa', 'dklqψx', 'cid107', 'ρx', 'θcid48', 'θcid48', 'assume', 'roughly', 'posterior', 'assumption', 'roughly', 'posterior', 'pθ', 'acceptable', 'natural', 'consequence', 'optimize', 'variational', 'objective', 'equation', 'alternatively', 'consider', 'mi', 'deﬁne', 'joint', 'conditional', 'distribution', 'p', 'forward', 'model', 'pθ', 'datum', 'distribution', 'posterior', 'model', 'also', 'sensible', 'variational', 'objective', 'equation', 'optimize', 'compatible', 'pθ', 'qψ', 'ﬁt', 'datum', 'consistently', 'describe', 'conditional', 'underlying', 'distribution', 'thus', 'regularize', 'encourage', 'low', 'mi', 'approach', 'lead', 'exactly', 'equation', 'approximation', 'total', 'loss', 'equation', 'combine', 'equation', 'give', 'lklz', 'lklxθcid48', 'c', 'lklxθ', 'discussion', 'discuss', 'algorithmic', 'choice', 'denoise', 'mdp', 'speciﬁc', 'implementation', 'detail', 'eg', 'architecture', 'find', 'posterior', 'distribution', 'rx', 'pθ', 'reward', 'distribution', 'xt', 'pθry', 'model', 'gaussian', 'usually', 'world', 'model', 'dreamer', 'transition', 'structure', 'denoise', 'mdps', 'distribution', 'inherently', 'independent', 'recall', 'r', 'rx', 'ry', 'therefore', 'easily', 'compute', 'distribution', 'log', 'likelihood', 'enable', 'easy', 'optimization', 'variational', 'objective', 'require', 'posterior', 'model', 'also', 'infer', 'rx', 'ry', 'observed', 'r', 'subject', 'addition', 'relation', 'partial', 'observability', 'section', 'discussion', 'mostly', 'base', 'fully', 'observable', 'setting', 'benchmark', 'realworld', 'task', 'partially', 'observable', 'robot', 'joint', 'speed', 'infer', 'single', 'frame', 'fortunately', 'transition', 'model', 'use', 'denoised', 'mdp', 'fully', 'capable', 'handle', 'case', 'long', 'encoder', 'deterministic', 'observation', 'model', 'block', 'structure', 'make', 'fully', 'determine', 'practice', 'let', 'component', 'generic', 'conditional', 'distribution', 'parameterize', 'regular', 'deep', 'neural', 'network', 'therefore', 'denoise', 'mdp', 'require', 'full', 'observability', 'loss', 'equation', 'hyperparameter', 'maintain', 'hyperparameter', 'choice', 'relative', 'ratio', 'observation', 'reconstruction', 'loss', 'recommend', 'scale', 'roughly', 'proportionally', 'dimensionality', 'observation', 'space', 'experiment', 'present', 'paper', 'small', 'β', 'mean', 'strong', 'regularization', 'therefore', 'choose', 'base', 'training', 'stability', 'level', 'noise', 'distractor', 'task', 'b', 'experiment', 'detail', 'code', 'include', 'code', 'environment', 'variant', 'code', 'denoise', 'mdp', 'method', 'release', 'publication', 'denoise', 'mdps', 'ctrl', 'video', 'background', 'dmc', 'video', 'background', 'noisy', 'sensor', 'video', 'background', 'camera', 'jittere', 'agent', 'agent', 'agent', 'agent', 'rew', 'background', 'background', 'background', 'jittere', 'camera', 'robodesk', 'agent', 'button', 'light', 'desk', 'green', 'hue', 'tv', 'block', 'desk', 'handle', 'desk', 'movable', 'object', 'tv', 'content', 'button', 'sensor', 'noise', 'jittere', 'ﬂickere', 'environment', 'light', 'jittere', 'camera', 'table', 'categorization', 'various', 'information', 'environment', 'evaluate', 'b1', 'implementation', 'detail', 'b11', 'environment', 'task', 'environment', 'trajectory', 'cap', 'timestep', 'table', 'show', 'summary', 'kind', 'information', 'exist', 'environment', 'deepmind', 'control', 'dmc', 'video', 'background', 'implementation', 'follow', 'deep', 'bisimulation', 'control', 'environment', 'use', 'video', 'smaira', 'replace', 'pixel', 'blue', 'channel', 'strictly', 'great', 'method', 'however', 'cleanly', 'remove', 'background', 'walker', 'walk', 'environment', 'use', 'improved', 'mask', 'replace', 'pixel', 'blue', 'channel', 'great', 'camera', 'jittering', 'shift', 'observation', 'image', 'accord', 'smooth', 'random', 'walk', 'implement', 'step', 'gaussianperturbe', 'acceleration', 'decay', 'velocity', 'add', 'pull', 'force', 'position', 'far', 'away', 'origin', 'sensor', 'noise', 'select', 'sensor', 'perturb', 'accord', 'intensity', 'patch', 'natural', 'video', 'background', 'add', 'average', 'patch', 'value', 'perturb', 'speed', 'sensor', 'run', 'torsoheight', 'sensor', 'walk', 'normalized', 'fingertotargetdist', 'sensor', 'reacher', 'easy', 'sensor', 'value', 'undergo', 'nonlinear', 'mostly', 'linear', 'transform', 'compute', 'reward', 'perfectly', 'model', 'additive', 'reward', 'noise', 'model', 'usually', 'sufﬁcient', 'case', 'sensor', 'value', 'extreme', 'stay', 'linear', 'region', 'robodesk', 'modify', 'original', 'robodesk', 'environment', 'add', 'tv', 'screen', 'neighboring', 'desk', 'tv', 'screen', 'place', 'continuously', 'horizontally', 'shift', 'natural', 'video', 'environment', 'light', 'source', 'add', 'random', 'jittering', 'ﬂickere', 'view', 'camera', 'place', 'far', 'allow', 'well', 'view', 'noise', 'distractor', 'resolution', 'increase', '×', '×', 'compensate', 'change', 'camera', 'jittering', 'implement', 'smooth', 'random', 'walk', 'finally', 'button', 'sensor', 'detect', 'value', 'much', 'button', 'press', 'also', 'offset', 'random', 'walk', 'button', 'affect', 'corresponding', 'light', 'desk', 'additionally', 'press', 'green', 'button', 'also', 'shift', 'tv', 'screen', 'content', 'green', 'hue', 'follow', 'robodesk', 'reward', 'design', 'reward', 'agent', 'place', 'arm', 'close', 'button', 'press', 'button', 'green', 'tv', 'screen', 'content', 'robodesk', 'joint', 'position', 'regression', 'dataset', 'generate', 'training', 'test', 'set', 'use', 'policy', 'train', 'state', 'space', 'sac', 'different', 'stage', 'training', 'relate', 'compare', 'method', 'uniform', 'random', 'actor', 'obtain', 'ﬁve', 'policy', 'different', 'quality', 'policy', 'sample', 'trajectory', 'contain', 'pair', 'interaction', 'image', 'observation', 'groundtruth', 'joint', 'position', 'dimension', 'lead', 'total', '×', 'sample', 'policy', '×', 'sample', 'randomly', 'select', 'test', 'set', 'training', 'set', 'size', '×', '×', '×', '×', '×', '×', 'sample', 'rest', 'test', 'set', 'training', 'set', 'enforce', 'policy', 'strictly', 'contribute', 'equal', 'amount', 'denoise', 'mdps', 'operator', 'input', 'shape', 'kernel', 'size', 'stride', 'padding', 'operator', 'input', 'shape', 'kernel', 'size', 'stride', 'padding', 'input', 'input', 'inputsize', 'relu', 'relu', 'relu', 'relu', 'reshape', 'relu', 'reshape', 'relu', 'relu', 'relu', 'relu', 'relu', 'table', 'encod', 'architecture', '×', '96resolution', 'observa', 'tion', 'output', 'encoder', 'feed', 'network', 'infer', 'posterior', 'architectural', 'hyper', 'parameter', 'control', 'output', 'size', 'unrelated', 'actual', 'latent', 'variable', 'size', 'control', 'network', 'width', 'table', 'decoder', 'architecture', '×', 'observation', 'architectural', 'hyperparameter', 'control', 'width', 'fully', 'connected', 'part', 'control', 'width', 'convolutional', 'part', 'value', 'table', 'b12', 'model', 'learning', 'method', 'experiment', 'let', 'algorithm', 'use', 'environment', 'step', 'pisac', 'curl', 'follow', 'original', 'implementation', 'laskin', 'use', 'action', 'repeat', 'run', 'reacher', 'easy', 'action', 'repeat', 'walker', 'walk', 'denoise', 'mdp', 'dreamer', 'tia', 'dbc', 'always', 'use', 'action', 'repeat', 'follow', 'prior', 'work', 'hafner', 'denoise', 'mdp', 'dreamer', 'tia', 'dreamer', 'tia', 'use', 'training', 'schedule', 'recurrent', 'model', 'base', 'architecture', 'hafner', 'follow', 'denoise', 'mdp', 'also', 'use', 'component', 'follow', 'preﬁlling', 'training', 'schedule', 'see', 'dreamer', 'hafner', 'detail', 'model', 'learning', 'method', 'take', '×', 'observation', '×', 'rgb', 'observation', 'robodesk', 'dreamer', 'implement', 'encoder', 'decoder', 'former', 'resolution', 'handle', 'increase', 'resolution', 'modify', '×', 'architecture', 'obtain', 'convolutional', 'encoder', 'decoder', 'show', 'table', 'fair', 'comparison', 'ensure', 'method', 'roughly', 'equal', 'number', 'parameter', 'use', 'different', 'latent', 'variable', 'size', 'encod', 'output', 'size', 'table', 'convolutional', 'net', 'width', 'k', 'table', 'detail', 'show', 'table', 'kl', 'clip', 'free', 'nat', 'denoise', 'mdp', 'follow', 'dreamer', 'tia', 'fu', 'et', 'allow', 'free', 'nat', 'lklx', 'term', 'word', 'element', 'batch', 'optimize', 'kl', 'term', 'less', 'eg', 'implement', 'clip', 'however', 'allow', 'lkly', 'lklz', 'term', 'variable', 'discard', 'information', 'allow', 'hide', 'permit', 'structure', 'alternative', 'strategy', 'β', 'lklx', 'ﬁnd', 'also', 'empirically', 'effective', 'consider', 'allow', 'free', 'nat', 'vae', 'regularizer', 'term', 'ﬁrst', 'term', 'part', 'variational', 'model', 'ﬁtte', 'objective', 'result', 'present', 'paper', 'use', 'ﬁrst', 'strategy', 'strategy', 'implement', 'open', 'source', 'code', 'repository', 'githubcomfacebookresearchdenoisedmdp', 'b13', 'policy', 'optimization', 'algorithm', 'use', 'model', 'learning', 'backpropagate', 'dynamic', 'use', 'setting', 'dreamer', 'optimize', 'λreturn', 'rollout', 'clip', 'gradient', 'norm', 'great', 'tia', 'use', 'strategy', 'group', 'different', 'model', 'together', 'gradient', 'clip', 'strictly', 'follow', 'ofﬁcial', 'tia', 'implementation', 'latentspace', 'sac', 'use', 'regular', 'sac', 'automatic', 'tuning', 'gradient', 'clip', 'work', 'well', 'almost', 'setting', 'walker', 'walk', 'variant', 'training', 'often', 'collapse', 'obtain', 'good', 'return', 'regardless', 'model', 'learn', 'address', 'instability', 'case', 'reduce', 'learn', 'rate', '×', '×', 'clip', 'gradient', 'norm', 'great', 'latentspace', 'sac', 'run', 'variant', 'denoise', 'mdps', 'robodesk', 'latent', 'size', 'dreamer', 'tia', 'denoise', 'mdp', 'k', 'total', 'number', 'parameter', 'latent', 'size', 'k', 'total', 'number', 'parameter', 'table', 'speciﬁc', 'architecture', 'parameter', 'model', 'learning', 'method', 'use', 'deterministic', 'part', 'stochastic', 'part', 'represent', 'latent', 'variable', 'use', 'deterministicsize', 'stochasticsize', 'indicate', 'size', 'latent', 'variable', 'tia', 'denoise', 'mdp', 'latent', 'variable', 'note', 'tia', 'low', 'multiple', 'encoder', 'decoder', 'dreamer', 'denoise', 'mdp', 'encoder', 'decoder', 'total', 'number', 'parameter', 'measure', 'actor', 'model', 'additional', 'component', 'policy', 'optimization', 'eg', 'critic', 'sac', 'total', 'number', 'parameter', 'low', 'robodesk', 'encoder', 'decoder', 'architecture', 'narrow', 'purpose', 'reduce', 'memory', 'usage', 'high', 'resolution', 'b14', 'modelfree', 'method', 'dbc', 'use', '×', 'observation', 'follow', 'original', 'work', 'even', 'method', 'train', '×', 'observation', 'robodesk', 'dbc', 'use', 'encoder', 'table', '×', '96resolution', 'observation', 'fair', 'comparison', 'method', 'follow', 'original', 'work', 'stack', 'consecutive', 'frame', 'approximate', 'required', 'full', 'observability', 'robot', 'arm', 'joint', 'position', 'regression', 'experiment', 'section', 'dbc', 'encoder', 'also', 'see', 'stack', 'observation', 'dmc', 'evaluation', 'use', 'datum', 'provide', 'et', 'possible', 'run', 'ofﬁcial', 'repository', 'case', 'statespace', 'sac', 'state', 'space', 'usually', 'contain', 'robot', 'joint', 'state', 'include', 'position', 'velocity', 'sensor', 'noise', 'present', 'true', 'optimal', 'state', 'space', 'supply', 'noisy', 'background', 'affect', 'noisy', 'reward', 'however', 'still', 'work', 'well', 'practice', 'robodesk', 'tv', 'effect', 'reward', 'likely', 'strong', 'direct', 'statespace', 'sac', 'fail', 'learn', 'evaluation', 'obtain', 'rough', 'upper', 'bound', 'train', 'statespace', 'sac', 'modiﬁed', 'reward', 'less', 'noise', 'agent', 'reward', 'press', 'button', 'independent', 'tv', 'content', 'still', 'encourage', 'optimal', 'strategy', 'task', 'allow', 'achieve', 'good', 'policy', 'b15', 'method', 'contrastive', 'learn', 'use', 'alignmentuniformity', 'contrastive', 'learning', 'loss', 'hyperparameter', 'datum', 'augmentation', 'strictly', 'follow', 'experiment', 'coate', 'also', 'resolution', '×', 'exact', 'loss', 'form', 'luniformt', 'highperformance', 'set', 'compute', 'resource', 'experiment', 'run', 'single', 'gpu', 'require', 'memory', 'dmc', 'task', 'memory', 'robodesk', 'task', 'use', 'follow', 'type', 'ti', 'ti', 'ti', 'use', 'egl', 'rendering', 'engine', 'training', 'time', 'require', 'run', 'heavily', 'depend', 'cpu', 'speciﬁcation', 'availability', 'general', 'denoise', 'mdp', 'run', 'need', '∼', 'hour', '∼', 'hour', 'robodesk', 'tia', 'use', 'time', 'adversarial', 'loss', 'comparison', 'denoise', 'mdp', 'variant', 'run', 'dmc', 'task', 'machine', 'figure', 'variant', 'use', 'hour', 'figure', 'variant', 'use', 'hour', 'visualization', 'detail', 'visualization', 'component', 'learned', 'model', 'use', 'different', 'method', 'visualize', 'signal', 'noise', 'information', 'learn', 'tia', 'denoise', 'mdp', 'figure', 'tia', 'use', 'reconstruction', 'latent', 'maskcompose', 'together', 'full', 'reconstruction', 'denoised', 'mdp', 'decoder', 'instead', 'tia', 'thus', 'const', 'visualize', 'information', 'contain', 'variable', 'const', 'choose', 'visual', 'clarity', 'usually', 'value', 'variable', 'ﬁxed', 'timestep', 'fundamental', 'different', 'way', 'obtain', 'visualization', 'tia', 'prevent', 'agent', 'show', 'noise', 'visualization', 'denoise', 'denoise', 'mdps', 'figure', 'effect', 'weight', 'decay', 'robodesk', 'joint', 'position', 'regre', 'sion', 'curve', 'show', 'ﬁnal', 'test', 'mse', 'various', 'training', 'set', 'size', 'weight', 'decay', 'generally', 'help', 'ﬁnetune', 'pretraine', 'encoder', 'hurt', 'train', 'scratch', 'figure', 'performance', 'tia', 'setting', 'robodesk', 'joint', 'position', 'regression', 'use', 'signal', 'encoder', 'necessary', 'good', 'performance', 'figure', 'training', 'curve', 'comparison', 'robodesk', 'joint', 'position', 'regression', 'task', 'many', 'training', 'set', 'size', 'mdp', 'however', 'state', 'section', 'focus', 'evolveschange', 'image', 'rather', 'visually', 'present', 'static', 'component', 'essentially', 'model', 'correspond', 'transition', 'dynamic', 'visualization', 'figure', 'use', 'trajectory', 'generate', 'policy', 'train', 'sac', 'obtain', 'diverse', 'behavior', 'policy', 'output', 'randomly', 'perturb', 'use', 'action', 'trajectory', 'use', 'describe', 'procedure', 'obtain', 'visualization', 'speciﬁc', 'use', 'trajectory', 'segment', 'choose', 'showcase', 'modiﬁed', 'environment', 'representative', 'behavior', 'method', 'see', 'supplementary', 'video', 'clear', 'visualization', 'b4', 'robodesk', 'result', 'detail', 'environment', 'modiﬁcation', 'agent', 'control', 'robotic', 'arm', 'place', 'front', 'desk', 'tv', 'task', 'push', 'green', 'button', 'desk', 'turn', 'small', 'green', 'light', 'make', 'tv', 'display', 'green', 'hue', 'intensity', 'tv', 'image', 'green', 'channel', 'give', 'agent', 'part', 'reward', 'addition', 'distance', 'arm', 'button', 'much', 'button', 'press', 'additionally', 'environment', 'contain', 'noise', 'distractor', 'include', 'moveable', 'block', 'desk', 'rew', 'ﬂickere', 'environment', 'light', 'camera', 'jittering', 'rew', 'tv', 'screen', 'hue', 'tv', 'content', 'noisy', 'button', 'sensor', 'roughly', 'twice', 'many', 'pixel', 'denoise', 'mdp', 'denoise', 'mdp', 'hyperparameter', 'scale', 'α', 'observation', 'space', 'dimensionality', 'see', 'section', 'use', 'ﬁxed', 'use', 'alternative', 'kl', 'free', 'nat', 'strategy', 'discuss', 'b12', 'result', 'show', 'paper', 'also', 'effective', 'tia', 'hyperparameter', 'follow', 'recommendation', 'tia', 'paper', 'setting', 'λradv', 'match', 'reconstruction', 'loss', 'magnitude', 'set', 'λos', 'training', 'stable', 'b41', 'robot', 'arm', 'joint', 'position', 'regression', 'training', 'detail', 'task', 'jointly', 'train', 'pretraine', 'backbone', 'threelayer', 'head', 'hide', 'unit', 'layer', 'learning', 'rate', '×', 'ﬁnetune', 'pretraine', 'encoder', 'follow', 'common', 'ﬁnetune', 'practice', 'apply', 'weight', 'decay', '×', 'helpful', 'case', 'curl', 'training', 'scratch', 'e', 'e', 'e', 'e', 'denoise', 'dreamer', 'tia', 'contrastive', 'weight', 'decay', 'weight', 'decay', 'scratch', 'dbc', 'stack', 'frame', 'curl', 'stack', 'frame', 'pisac', 'augmentation', 'stack', 'frame', 'training', 'set', 'size1e5', 'training', 'set', 'size1e5', 'training', 'set', 'size1e5', 'training', 'set', 'size1e5', 'tia', 'weight', 'decay', 'signal', 'encod', 'weight', 'decay', 'signal', 'encoder', 'weight', 'decay', 'encoder', 'weight', 'decay', 'encoder', 'e', 'e', 'training', 'set', 'size', '1e5', 'learning', 'curve', 'training', 'sample', 'denoise', 'tia', 'dreamer', 'contrastive', 'scratch', 'training', 'epoch', 'learning', 'curve', '×', 'training', 'sample', 'training', 'epoch', 'learning', 'curve', '×', 'training', 'sample', 'training', 'epoch', 'learning', 'curve', '×', 'training', 'sample', 'training', 'epoch', 'denoise', 'mdps', 'figure', 'performance', 'comparison', 'ﬁnetune', 'denoised', 'mdp', 'encoder', 'framestacke', 'encoder', 'take', 'consec', 'utive', 'frame', 'denoise', 'mdp', 'training', 'scratch', 'encoder', 'take', 'single', 'frame', 'apply', 'frame', 'output', 'concatenate', 'together', 'feed', 'prediction', 'head', 'figure', 'performance', 'dbc', 'setting', 'robodesk', 'joint', 'position', 'regression', 'use', 'output', 'feature', 'layer', 'normal', 'ization', 'necessary', 'good', 'performance', 'figure', 'performance', 'curl', 'setting', 'robodesk', 'joint', 'position', 'regression', 'use', 'output', 'feature', 'layer', 'normal', 'ization', 'necessary', 'good', 'performance', 'figure', 'performance', 'pisac', 'setting', 'robodesk', 'joint', 'position', 'regression', 'use', 'activation', 'layer', 'normaliza', 'tion', 'give', 'good', 'performance', 'see', 'figure', 'comparison', 'weight', 'decay', 'option', 'method', 'modelbase', 'take', 'encoder', 'train', 'backpropagate', 'dynamic', 'policy', 'optimization', 'train', 'contrastive', 'encoder', 'fair', 'comparison', 'rltraine', 'encoder', 'optimize', 'environment', 'step', 'train', 'contrastive', 'encoder', 'sample', 'obtain', 'exact', 'method', 'training', 'set', 'task', 'sense', 'contrastive', 'encoder', 'advantage', 'training', 'exact', 'distribution', 'see', 'sample', 'rltraine', 'encoder', 'use', 'action', 'repeat', 'thus', 'ever', 'see', '×', 'sample', 'tia', 'set', 'encoder', 'use', 'concatenate', 'latent', 'unfortunately', 'hurt', 'performance', 'greatly', 'see', 'figure', 'use', 'encoder', 'signal', 'latent', 'also', 'compare', 'training', 'speed', 'wide', 'range', 'training', 'set', 'size', 'figure', 'denoise', 'mdp', 'encoder', 'lead', 'fast', 'well', 'training', 'setting', 'additional', 'comparison', 'framestacke', 'encoder', 'pretraine', 'encoder', 'dbc', 'pisac', 'take', 'stack', 'consecutive', 'frame', 'directly', 'comparable', 'method', 'compare', 'also', 'try', 'run', 'denoise', 'mdp', 'encoder', 'consecutive', 'frame', 'feature', 'vector', 'concatenate', 'feed', 'head', 'result', 'figure', 'show', 'encoder', 'outperform', 'pisac', 'encoder', 'finally', 'dbc', 'curl', 'pisac', 'attempt', 'evaluate', 'intermediate', 'feature', 'feature', 'ﬁnal', 'layer', 'normalization', 'output', 'space', 'last', 'option', 'bestperforme', 'dbc', 'curl', 'second', 'option', 'bestperforme', 'pisac', 'see', 'figure', 'therefore', 'use', 'respective', 'space', 'arguably', 'give', 'edge', 'method', 'essentially', 'tune', 'additional', 'option', 'test', 'result', 'notably', 'respective', 'choice', 'often', 'achieve', 'relatively', 'good', 'performance', 'highlight', 'necessity', 'tune', 'method', 'e', 'e', 'stack', 'frame', 'single', 'frame', 'dbc', 'stack', 'frame', 'pisac', 'stack', 'frame', 'curl', 'stack', 'frame', 'scratch', 'stack', 'frame', 'training', 'set', 'size', '1e5', 'dbc', 'weight', 'decay', 'output', 'feature', 'weight', 'decay', 'output', 'feature', 'weight', 'decay', 'layer', 'norm', 'weight', 'decay', 'layer', 'norm', 'weight', 'decay', 'feature', 'weight', 'decay', 'feature', 'e', 'e', 'training', 'set', 'size', '1e5', 'curl', 'weight', 'decay', 'output', 'feature', 'weight', 'decay', 'output', 'feature', 'weight', 'decay', 'layer', 'norm', 'weight', 'decay', 'layer', 'norm', 'weight', 'decay', 'feature', 'weight', 'decay', 'feature', 'e', 'e', 'training', 'set', 'size', '1e5', 'pisac', 'e', 'e', 'weight', 'decay', 'output', 'feature', 'stack', 'frame', 'weight', 'decay', 'output', 'feature', 'stack', 'frame', 'weight', 'decay', 'layer', 'norm', 'stack', 'frame', 'weight', 'decay', 'layer', 'norm', 'stack', 'frame', 'weight', 'decay', 'feature', 'stack', 'frame', 'weight', 'decay', 'feature', 'stack', 'frame', 'training', 'set', 'size', '1e5', 'result', 'detail', 'denoise', 'mdps', 'full', 'policy', 'optimization', 'result', 'figure', 'present', 'full', 'result', 'dmc', 'environment', 'task', 'variant', 'environment', 'comparison', 'plot', 'make', 'base', 'policy', 'learn', 'use', 'model', 'learning', 'method', 'modelfree', 'baseline', 'duplicate', 'separation', 'aim', 'highlight', 'performance', 'difference', 'cause', 'model', 'structure', 'rather', 'policy', 'learn', 'noisy', 'environment', 'denoise', 'mdp', 'perform', 'good', 'also', 'achieve', 'high', 'return', 'noiseless', 'environment', 'visualization', 'learned', 'model', 'figure', 'extended', 'version', 'figure', 'main', 'text', 'full', 'reconstruction', 'model', 'see', 'supplementary', 'video', 'clear', 'visualization', 'comparison', 'denoise', 'mdp', 'variant', 'compare', 'denoise', 'variant', 'base', 'figure', 'run', 'environment', 'policy', 'train', 'packpropagate', 'learn', 'dynamic', 'comparison', 'show', 'top', 'row', 'figure', 'see', 'figure', 'variant', 'often', 'perform', 'bit', 'well', 'hypothesize', 'complex', 'prior', 'posterior', 'structure', 'figure', 'learn', 'efﬁciently', 'also', 'make', 'figure', 'variant', 'need', 'long', 'wallclock', 'time', 'optimize', 'mention', 'tia', 'hyperparameter', 'instability', 'strictly', 'follow', 'recommendation', 'original', 'paper', 'use', 'suggested', 'value', 'dmc', 'task', 'also', 'note', 'tia', 'run', 'sometimes', 'collapse', 'training', 'lead', 'sharp', 'drop', 'reward', 'closely', 'inspect', 'model', 'collapse', 'note', 'many', 'case', 'collapse', 'cooccur', 'sudden', 'spike', 'tia', 'reward', 'disassociation', 'loss', 'implement', 'adversarial', 'minimax', 'loss', 'noise', 'latent', 'space', 'instantly', 'become', 'degenerate', 'use', 'reconstruction', 'hypothesize', 'adversarial', 'nature', 'cause', 'training', 'instability', 'however', 'collapse', 'cooccur', 'loss', 'spike', 'maybe', 'alternatively', 'tia', 'model', 'structure', 'model', 'respective', 'noise', 'type', 'well', 'ﬁtte', 'model', 'naturally', 'mean', 'degenerate', 'noise', 'latent', 'space', 'pisac', 'hyperparameter', 'task', 'use', 'hyperparameter', 'detail', 'original', 'paper', 'pisac', 'usually', 'run', 'augmentation', 'however', 'curl', 'augmentation', 'integral', 'part', 'pisac', 'completely', 'optional', 'fair', 'comparison', 'method', 'highlight', 'effect', 'predictive', 'information', 'regularizer', 'main', 'mechanism', 'propose', 'pisac', 'use', 'augmentation', 'pisac', 'denoise', 'mdp', 'hyperparameter', 'always', 'use', 'ﬁxe', 'β', 'tune', 'accord', 'amount', 'noise', 'environment', 'train', 'stability', 'figure', 'compare', 'effect', 'choose', 'different', 'β', '’s', 'noiseless', 'environment', 'large', 'less', 'regularization', 'perform', 'often', 'well', 'noisy', 'environment', 'sometimes', 'strong', 'regularization', 'boost', 'performance', 'however', 'overall', 'good', 'performance', 'obtain', 'usually', 'several', 'β', 'value', 'table', 'summarize', 'β', 'choice', 'environment', 'table', 'denoise', 'mdps', 'figure', 'policy', 'optimization', 'result', 'plot', 'focus', 'single', 'task', 'variant', 'show', 'total', 'episode', 'return', 'environment', 'step', 'take', 'modelbase', 'approach', 'use', 'policy', 'optimization', 'choice', 'train', 'learn', 'model', 'top', 'half', 'backpropagate', 'learn', 'dynamic', 'bottom', 'half', 'sac', 'learn', 'mdp', 'also', 'compare', 'dbc', 'modelfree', 'baseline', 'upper', 'bound', 'plot', 'presentation', 'clarity', 'sac', 'true', 'optimal', 'representation', 'environment', 'step', 'reach', 'episode', 'return', '≈', 'run', 'variant', 'walk', 'variant', 'reacher', 'speciﬁc', 'augmentation', 'choice', 'random', 'crop', 'potentially', 'help', 'signiﬁcantly', 'reacher', 'easy', 'reacher', 'target', 'appear', 'random', 'spatial', 'location', 'camera', 'jittering', 'however', 'denoise', 'generally', 'perform', 'well', 'environment', 'noise', 'variant', 'z', 'p', 'l', 'p', 'e', 'g', 'p', 'r', 'p', 'b', 'c', 'n', 'v', 'z', 'p', 'l', 'p', 'c', 'p', 'e', 'c', 'denoise', 'mdps', 'figure', 'complete', 'visualization', 'different', 'dmc', 'variant', 'factorization', 'learn', 'tia', 'denoise', 'mdp', 'addition', 'visualization', 'figure', 'also', 'visualize', 'full', 'reconstruction', 'dreamer', 'tia', 'denoise', 'mdp', 'run', 'noiseless', 'reacher', 'easy', 'video', 'background', 'walker', 'walk', 'video', 'background', 'noisy', 'sensor', 'run', 'video', 'background', 'camera', 'jittere', 'env', 'rollout', 'tia', 'signal', 'noise', 'recon', 'denoise', 'mdp', 'signal', 'noise', 'denoise', 'mdps', 'figure', 'effect', 'choose', 'denoised', 'mdp', 'policy', 'optimization', 'result', 'set', 'disable', 'regularization', 'run', 'noiseless', 'variant', 'noiseless', 'video', 'background', 'video', 'background', 'noisy', 'sensor', 'video', 'background', 'camera', 'jittere', 'policy', 'learn', 'backprop', 'dynamic', 'policy', 'learning', 'sac', 'latentspace', 'walk', 'reacher', 'easy', 'walker', 'walk', 'reacher', 'easy', 'table', 'β', 'choice', 'denoise', 'mdp', 'result', 'show', 'table', 'figure', 'choose', 'disable', 'regularization', 'noiseless', 'environment', 'tune', 'however', 'see', 'figure', 'result', 'often', 'sensitive', 'small', 'β', 'change', 'z', 'p', 'l', 'p', 'e', 'g', 'p', 'r', 'p', 'b', 'c', 'n', 'v', 'z', 'p', 'l', 'p', 'c', 'p', 'e', 'c']"
