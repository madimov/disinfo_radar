title,url,date,text,cleaning,tokens
"Action Inference by Maximising Evidence: Zero-Shot Imitation from
  Observation with World Models","[{'href': 'http://arxiv.org/abs/2312.02019v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2312.02019v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-12-04 16:43:36,"Google Tag Manager: Hidden Data Leaks and its Potential
Violations under EU Data Protection Law
Nataliia Bielova
Centre Inria d’Université Côte d’Azur
Sophia Antipolis, France
nataliia.bielova@inria.fr

Gilles Mertens
Centre Inria de l’Université
Grenoble-Alpes
Grenoble, France
gilles.mertens@inria.fr

Vincent Roca
Centre Inria de l’Université
Grenoble-Alpes
Grenoble, France
vincent.roca@inria.fr

3
2
0
2

c
e
D
4
1

]

R
C
.
s
c
[

1
v
6
0
8
8
0
.
2
1
3
2
:
v
i
X
r
a

Cristiana Santos
Utrecht University
Utrecht, The Netherlands
c.teixeirasantos@uu.nl

Michael Toth
Centre Inria de l’Université
Grenoble-Alpes
Grenoble, France
michael.toth@inria.fr

ABSTRACT
Tag Management Systems were developed in order to support web-
site publishers in installing multiple third-party JavaScript scripts
(Tags) on their websites. In 2012, Google developed its own TMS
called “Google Tag Manager” (GTM) that is currently present on
28 million live websites. In 2020, a new “Server-side” GTM was
introduced, allowing publishers to include Tags directly on the
server. However, neither version of GTM has yet been thoroughly
evaluated by the academic research community.

In this work, we study, for the first time, the two versions of the
Google Tag Management (GTM) architectures: Client- and Server-
side GTM. By analyzing these systems with 78 Client-side Tags, 8
Server-side Tags and two Consent Management Platforms (CMPs)
from the inside, we discover multiple hidden data leaks, Tags bypass-
ing GTM permission system to inject scripts, and consent enabled
by default. With a legal expert, we perform an in-depth legal anal-
ysis of GTM and its actors to identify potential legal violations
and their liabilities. We provide recommendations and propose
numerous improvements for GTM to facilitate legal compliance.

KEYWORDS
online tracking, server-side tracking, privacy, consent, GDPR com-
pliance, website publishers, data controller, potential legal violation

1 INTRODUCTION
Today’s modern websites continuously collect their visitors’ data
for various purposes, such as targeted advertising, and rely on third
parties for such collection. Over the last decade, researchers have
demonstrated that third-parties collect users’ data with the help
of third-party JavaScript scripts [62]. These scripts, invisible to the
users, are silently executed in the webpage’s background and are
often called “tags” by the web marketing industry [46]. Initially, to
install a tag on the webpage, the website publisher only needed

This work is licensed under the Creative Commons Attribu-
tion 4.0 International License. To view a copy of this license
visit https://creativecommons.org/licenses/by/4.0/ or send a
letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.
Proceedings on Privacy Enhancing Technologies YYYY(X), 1–17
© YYYY Copyright held by the owner/author(s).
https://doi.org/XXXXXXX.XXXXXXX

1

to copy and paste an external JavaScript library reference to the
webpage’s source code. However, as publishers were installing more
and more tags1, manual tag management became challenging and,
as a result, “Tag Management Systems” (TMS) were developed by
the industry. TMS allow publishers to install and configure tags in
a centralized manner without tinkering with the website source
code. Once installed on a website, TMS takes care of handling the
installation, configuration and execution of third-party tags.

In 2012, Google developed its own TMS called “Google Tag
Manager” (GTM). It is currently the most installed TMS on the
market, currently present on 28 million live websites according
to BuiltWith [7]. GTM is a free service, offering a graphical inter-
face and supporting a seamless inclusion of major marketing and
analytic third-party scripts. GTM also benefits from a community
of contributors, creating tags for services that are not officially
supported by Google. Tags rely on the ability of browsers to com-
municate directly with third-party domains to download scripts, set
cookies and send users’ data. Figure 1a shows the first GTM archi-
tecture proposed by Google that we call “Client-side GTM” since it
loads all the tags inside the user’s browser. In the recent years, this
architecture became crippled by measures taken by browser ven-
dors. Many popular Web browsers, such as Safari, Firefox and Brave,
already actively block third-party tracking scripts and cookies to
defend users against Web tracking [6, 49, 58]. Moreover, Google’s
own plan of phasing out third-party cookies in Chrome [52] will
render a lot of tags that rely on third-party cookies ineffective.

As a result, an alternative version of Google Tag Manager was
created in 2020, officially called “GTM Server Container” [45]. This
new architecture, shown in Figure 1b, loads and executes tags in
a remote server, making it look like no third parties are present
on the website. When the user’s data is collected with the GTM
Web Container, there is only one data flow exiting the browser, and
therefore, the final destination of data is impossible to trace for
researchers and auditors that analyze outgoing browser requests.
This architecture, called “Server-side GTM”, bypasses any browser
restrictions and security measures, such as CSP [59] to control and
secure third-party scripts and allows tags, that are now run on the
server, to invisibly share users’ data to other third parties.

1In 2016, Engelhard and Narayanan [19] measured that on average, a website contains
18 third-parties.

 
 
 
 
 
 
Proceedings on Privacy Enhancing Technologies YYYY(X)

G. Mertens et al.

the closest areas: online tracking detection and measurement, legal
requirements on consent for online tracking, and non-academic
literature, such as blog posts, regarding GTM.
Online tracking measurement and prevalence of Google Mul-
tiple works have detected and measured web tracking practices
over the last decade, identifying Google’s massive prevalence in
the tracking ecosystem. In 2009, Krishnamurthy and Wills [53]
conducted a longitudinal study of the collection and aggregation
of personal data of end users by third parties – they highlight a
small number of actors in the tracking ecosystem, and the rapid
growth of Google, with requests to Google-owned servers being
observed on 60% of the domains. In 2015, by analyzing third-party
HTTP requests on the Alexa top 1 million sites, Libert [56] con-
cluded that Google could track users on up to 80% of sites. In 2016,
Englehardt and Narayanan [20] confirmed the extent of this track-
ing by conducting an automated analysis of stateful and stateless
techniques on 1 million sites, showing that Google owned the five
most detected third-party domains. In 2020, Fouad et al. [28] con-
firmed again the prevalence of Google – they found the presence
of tracking by Google domains on more than 85% websites.
Tag management and GTM No academic research appears to
have studied tag management systems to date. However, several
people close to AdTech circles share their experience and publish
screenshots and other analyses of these tools on the web, either to
help publishers in their deployment or to point out legal or techni-
cal issues. The IT and digital marketing expert Julius Fedorovicius
publishes courses and ebooks on GTM on his website Analytics
Mania [51]. He has published a how-to on configuring server-side
GTM [50], summarizing the essential benefits and problems of the
technology. The analytics developer Simo Ahava tests and com-
ments on new functionalities in SEO and digital marketing tools. He
maintains an extensive documentation on GTM [73], and in a recent
article [72], discusses GTM’s limitations and problems regarding
transparency and user control. The blogger Pixel de tracking [66]
explores surveillance issues on the web. They have published sev-
eral articles on Web Tracking Technologies, including GA4 and
server-side GTM, focusing on the implications on the impact on
content blockers [15]. A number of books have been published
on the subject of GTM, attempting to guide website publishers in
their use of the tool [8, 76]. They cover registration, configuration,
tagging and integration with popular CMS such as WordPress.
Summary Most of the previous works either focus on Web Track-
ing Technologies in general, or just describe the functionalities of
GTM or server-side tag management. The recent content published
by industry experts identify risks for privacy. However, no work
so far seems to have evaluated if GTM can be leveraged to deploy
offensive configurations at scale, nor seems to have assessed the
complexity of consent management in GTM for publishers in the
GDPR context. It is these gaps that our work aims to fill.

3 STUDY I: THE INTERNALS OF GTM
In Study I, we experimented with both the Client- and Server-side
GTM to identify their components and how they work in a typical
GTM installation. Our goal was to evaluate what and how user
data is collected and which actors access it. We examined GTM’s

2

(a) Client-side GTM

(b) Server-side GTM

Figure 1: Google Tag Management (GTM) architecture. Red
arrows represent the flows of users’ data to third parties.

In this work, we study two versions of the Google Tag Manage-
ment (GTM) architectures – Client- and Server-side GTM – from
inside. Differently from other approaches to measure Web track-
ing [28, 30, 55, 67], we deploy the idea of Toth et al. [75] to analyze
the system by installing it on an empty website that we fully con-
trol. We then perform two separate studies: Study I that focuses on
the internal functioning of GTM and Study II that analyzes legal
implications of Study I. In Study I (§3), our first contribution con-
sists in the methodology we built to analyze the internals of Client-
and Server-side GTM, by installing 78 Tags one-by-one and two
popular consent banner solutions. This allows us to capture script
injections, hidden data flows, study GTM permission system and its
integrated “Consent Mode”. We discovered 6 technical findings, in-
cluding the fact that “Google Tag” aims at ensuring communication
between Client- and Server-side, collects multiple types of users’
data without their consent; “Pinterest Tag” collects a significant
amount of users’ data without disclosing it to the Publisher; 11
out of 78 official Client-side tags inject a third-party script into
the DOM [60] bypassing the GTM permission system; and GTM
“Consent Mode” enables some of the consent purposes by default,
even before the user has interacted with the consent banner.

Study II in §4 is written together with a legal expert and co-
author of this paper. Therein we explain the EU Data Protection
legal background relevant to the GTM ecosystem. We then provide
an in-depth legal analysis where we identify the legal role of each
actor, detect 8 potential violations of the General Data Protection
Regulation (GDPR) [31] and ePrivacy Directive [21], and thereby we
identify each actor’s liability. Finally, we make recommendations
to further improve GTM to facilitate legal compliance across all in-
volved actors. Finally, we discuss other potential legal implications
of this GTM ecosystem (§5) and conclude the paper.

2 RELATED WORKS
GTM has become a popular tool for managing tags on websites in
recent years. However, to the best of our knowledge, no scientific
study has analyzed tag managers or the GTM Framework in partic-
ular, neither its client- nor its server-side tagging version from a
privacy viewpoint. In this section we present the related works in

a.com

b.com

c.com

Browser

GTM web container

tag a

tag b

tag c

personnal data

a.com

b.com

c.com

Cloud

GTM server
container

tag a

tag b

tag c

Browser

GTM web container

personnal data

Google Tag Manager: Hidden Data Leaks and its Potential Violations under EU Data Protection Law

Proceedings on Privacy Enhancing Technologies YYYY(X)

“Consent Mode”, a toolset to render GTM compliant, in order to
assess its effectiveness in managing consent.

3.1 Methodology
To conduct experiments and set up the GTM infrastructure, we
bought a domain – we call it example.com here – and created a
public website containing one basic webpage with a paragraph
of text and an HTML login form. We have included a login form
since Senol et al. [71] have recently found that user input is often
leaked from the forms, so we decided to test whether Tags may
be responsible for such leakage. The website and the Server-side
GTM infrastructure were hosted on a virtual machine we rented
on the Microsoft Azure cloud computing platform located in a data
center in the EU. We conducted this study between September
and November 2023 on the Chromium browser [9] in version 111,
from the Flathub repository [10], using the default settings and
installed on a GNU/Linux operating system (kernel version 6.1.x-
lts). We used the “profiles” functionality of the browser to start
every experiment in a fresh environment, devoid from cookies,
local storage and other technologies than maintain a state. The
browser, visiting the website, was run on a computer connected
to the Internet through an institutional network in the EU. To
create Client- and Server-side GTM installations, we created a new
Google account, logged into it and followed the suggested steps in
the official GTM documentation [43]. We explain the installation
process in detail below. Note that the terms we use can slightly differ
from that of the official GTM documentation for clarity reasons.

3.1.1 Client-side GTM. Selecting Tags. GTM supports 78 official
Tags that are directly accessible through its interface to the website
publisher. Nevertheless, a community of developers created Tags for
services that are not officially supported by Google, and such tags
are available through the GTM-integrated template gallery [44]. To
understand what type of user’s personal data Tags can collect, and to
monitor how it flows through the Client-side GTM installation, we
decided to select and test 3 Tags. To select Tags, we decided to pick
representative Tags of three typical functionalities of third parties:
analytics/statistics, advertisement effectiveness, and assessment
of user interaction. Our selection procedure focuses on the list of
official Tags and was informed by the popularity of the company
that receives the data collected by the Tag (we call such company
Data Collector, see §4.2.3). For the popularity criteria, we followed
the ranking of popularity of third parties according to Binns et
al. [5], who measured the inclusion of third parties on 100k websites.
The three selected Tags are shown in Table 1a2. For the selected
Tags to function properly, we registered on the Data Collector’s
website and configured the Tag according to its instructions.
Installing GTM on our Website. When the publisher has chosen
and configured Tags to be included on its website, GTM generates
a “Web Container” in the form of an external JavaScript library
called gtm.js [37], which contains all the selected tags. We did it
and copy-pasted the small script provided by GTM in our website
source page, which prompts the browser to fetch the gtm.js script.
Capturing Script injection, Data Flows and Availability of
Collected Data. We manually installed all the officially available

2For clarity, we will refer to the “Hotjar Tracking Code” tag as the “Hotjar Tag”.

3

tags individually in our Web Container, opened our website in a new
browser profile and analyzed the traffic using the Chromium debug
tools. For each tag we identified whether additional scripts were
downloaded and for the 3 tags selected in Table 1a, we inspected
the GET parameters, POST bodies and data exchanged through
the WebSocket protocol of outgoing requests to identify the data
collected. In order to identify personal data collected, we investigate
firstly by using an empirical method: by looking at the key/value
pairs, in GET parameters or JSON data, in search for obvious key
names like screen_resolution or obvious key/value pairs such
as sr=1920x1080 for a FullHD screen; and secondly by using the
available documentation for each Tag [40, 47, 64]. Finally, we logged
on the Data Collector’s website, searched for the personal data
previously identified and compared it with data identified in the
outgoing requests. For the Google Tag, in Google Analytics, we
visited the “Report” page; for Pinterest, in the “Conversion” section,
we clicked on the “Event history” page; for Hotjar we went to the
“Recordings” page to see the individual recorded user interactions.
Figure 2a summarizes our analysis method.
Tag Permission System. For non-official tags, GTM shows the
permissions of the tag in a popup, to review them before confirming
the installation. By analyzing the network communications with
our browser while being in the Web Container configuration in-
terface, in the template gallery section, we found a JSON file that
contains the tag information displayed in the interface. This file
contains information such as the tag’s author, a description of the
tag, the link to the source code of the tag and the list of permis-
sions. The names of permissions and configurations (e.g., for the
set_cookies permission, the configuration would be the cookie
name) corresponds to the official documentation [36].

For official tags however, the GTM configuration interface does
not show any permission and no official documentation mentions
any permission system either. However, by analyzing network com-
munications while browsing the official tags section, we found a
similar JSON file containing the list of permissions in the same
format. From this file we extracted the list of tags having the in-
ject_script permission to compare it with the actual behavior of
the tags regarding script injection. We conclude that official tags
have a permission system similar to the non-official tags.
Consent Configuration. Next, assisted by a legal scholar coauthor
of this paper, we integrated consent management on our website
in such a way that it is compliant with the EU legal framework.
We used the GTM “Consent Mode” feature, added in 2020 in Web
Containers, and still marked as a beta feature in the GTM config-
uration interface during the writing of this paper. This consent
system is based on “consent variables”, and GTM proposes: ad_-
storage , analytics_storage , functionality_storage , per-
sonalization_storage and security_storage (Table 3). They
take two values, “granted” or “denied”, according to the documen-
tation. We found that variables can also be in “undefined” state,
with serious consequences (see Technical finding 4). In this sys-
tem, the Consent Management Platforms (CMPs), which provides
consent banners [57], are integrated in the Web Container as Tags.
CMPs communicate the user’s consent choices made in the consent
banner, expressed through these consent variables, to the Web Con-
tainer [34]. Then, in the GTM interface, we, as Publisher, need to

Proceedings on Privacy Enhancing Technologies YYYY(X)

G. Mertens et al.

Tag name
(ranking [5])
Google Tag (1)

Data
Collector
Google

Pinterest Tag
(66)

Pinterest

Hotjar
Tracking Code
(105)

Hotjar

Goals of the service/tag

provide statistics on users and
their behavior on websites

measure advertisement cam-
paigns effectiveness; become
a Pinterest Verified merchant

provide videos of user interac-
tions with websites to detect
bugs and improve the website

Tag name
(ranking [5])
Google Analytics:
GA4 (1)

Conversions API
Tag (3)

Data
Collector
Google

Goals of the service/tag

provide statistics on users and
their behavior on websites

Facebook measure advertisement cam-
paigns effectiveness; provide
statistics about website usage

Mixpanel (32)

Mixpanel

gather data on user interac-
tions with the website to gain
insights into their behavior

(a) Client-side GTM tags.

(b) Server-side GTM tags.

Table 1: Tags selected for further study in Client- and Server-side GTM.

(a) Client-side GTM.

(b) Server-side GTM.

Figure 2: Pipelines of the analysis of collected data and tag behavior on Client- and Server-side GTM.

associate none, one or more consent variables to each Tag. Accord-
ing to documentation [39], before executing a Tag, GTM checks
the associated consent variables and proceeds only if all the con-
sent variables are “granted”; otherwise GTM prevents the tag from
running. Some tags support a feature called “built-in consent” [35]
which allows them, when being executed, to check the values of the
consent variables by themselves and adapt their behavior depend-
ing on users’ choices. If trusted, the Publisher does not associate any
consent variable with such tags that are always executed. We tested
the two CMPs marked as compatible with Consent Mode and put
forward in the GTM interface, namely Consentmanager [11] and
Cookiebot [13]. They both include a scanner to detect cookies and/or
tracking technologies and classify the trackers and associated pur-
poses (we further analyze scanners in section 4.2.1). For each CMP,
we created an account on their website, let the CMP scanner scan
our website, and installed the CMP tag in the GTM configuration
interface. For Consentmanager, according to the documentation,
we enabled “Send Google Consent Mode” in the settings of the
CMP’s website. We then used the results of the CMP scanner to
configure the consent settings of each tag. To study the behavior of
the Web Container, the CMP and the Tags, we visited our website
several times, using a new browser profile and a different consent
option in the consent banner each time: “accept all”, “decline all”,

“only analytics” and “only advertisement”. After making our choice,
we stayed on the page for 20 seconds, reloaded it and used it for
another 20 seconds. We used both the debugger provided by GTM
to know when tags run, and the browser’s debugger to capture
outgoing traffic (figure 2a). Finally, we compared collected data in
each case with data collected without consent configuration.

Server-Side GTM. Selecting tags. Similarly to Client-side
3.1.2
GTM, we selected three tags with the same representative func-
tionalities of third parties: analytics/statistics, advertisement effec-
tiveness, and assessment of user interaction. Here, GTM officially
supports only eight tags, all related to Google services, from which
we selected Google Analytics. Then, from the template gallery
where developers propose additional, non-officially supported tags,
and for the remaining two functionalities we are interested in, we
chose the most popular ones, based on the ranking of the Data
Collector as in Binns et al. [5], namely Facebook Conversion API
and Mixpanel (Table 1b). We also observed that in the template
gallery, the company that provides the tag (we call it Tag Provider,
see §4.2.4) and the Data Collector are not necessarily the same.
GTM Server Container Installation. In the GTM interface for
Publishers, we created a “GTM Server Container”, which is a Node.js
program running on a server, that contains in particular the selected
“Server Tags”. Two options are proposed: “Automatic provisioning”,

4

https://example.com

GTM Web Container
(gtm.js)

user data

Google Tag

user data

Pinterest Tag

user data

Hotjar Tag

consent
variables

click ""accept all""

click ""deny all""

Chrome
debugger

example.com

googletagmanager.com

Data Collectors

Google Analytics

User statistics

Pinterest

Number of clicks

Hotjar

Recorded user sessions

https://example.com

Chrome
debugger

example.com

GTM Web Container 
(gtm.js) 

user data

Google Tag 
(Collector Tag) 

consent
variables

consent

GTM Server Container
(server.js)

GTM: Web Container 
(Client Adaptor) 

GA4 
(Client Adaptor)

Server
Instrum-
entation

Google Analytics 

Facebook
Conversion API 

Mixpanel

googletag 
manager.com

Data Collectors

Google Analytics

User data

Facebook pixel

User data

Mixpanel

User data

Google Tag Manager: Hidden Data Leaks and its Potential Violations under EU Data Protection Law

Proceedings on Privacy Enhancing Technologies YYYY(X)

that automatically installs the Server Container on a Google Server,
and “Manual installation”, for which the Publisher provides the
server. We chose the manual installation to have total control over
the server and be able to analyze the Server Container incoming
and outgoing information flows. We used the provided Docker
image and configured the Server Container to be accessible us-
ing HTTPS. Finally, we created A and AAAA DNS records for the
gtm.example.com subdomain pointing to our server and avoided
using CNAME records as recommended. We provide the configuration
files of our setup in the artifacts (§3.1.3).
Connection Between the browser and the Server Container.
To connect the browser and the Server Container to collect the end-
user data, we first created a new GTM Web Container (figure 2b).
Following the GTM documentation, we installed the “Google Tag”
in the Web Container, specifying the https://gtm.example.com
URL of our Server Container in the transport_url field, in the tag
configuration. It instructs the Google Tag to send collected data
to our Server Container, instead of the Google Analytics servers,
which is the default behavior of this tag. This “Google Tag” is
what we call a “Collector Tag”. In the GTM Server Container, a
component that we call “Client Adaptor”, receives data, decodes it
and makes it available to server tags. This Client Adaptor needs
to be compatible with the Collector Tag and for this, we used the
default “GA4 Client” (or simply, GA4), preinstalled on the Server
Container and compatible with our Collector Tag.
Capturing traffic in the Browser. We visited our website in a new
browser profile and used the Chromium debug tools to capture traf-
fic between the Collector Tag and the Client Adaptor. We analyzed
the outgoing traffic similarly to the Client-side study (§3.1.1).
Capturing Data Flows and Availability of Collected Data. To
analyze the outgoing traffic of the Server Container, we instru-
mented our server to capture network exchanges and decrypted
them by starting the Node.js interpreter, which runs the Server
Container, with the --tls-keylog option [63]. This option in-
structs Node.js to export encryption keys. We used Wireshark [77]
to collect traffic and imported the encryption keys previously ex-
ported to decrypt it. Similarly to the Client-side experiments, we
identified data sent by Server Tags to Data Collectors using our
server instrumentation. We finally compared our observations with
the data items visible on the websites that received the user’s data.
Consent Management. To assess the ease of making the Server-
side GTM architecture GDPR-compliant, we searched for official
documentation on this matter and only found a relatively basic
page [38]. In order to have concrete results, we added a CMP to the
Web Container. We chose Cookiebot because it is compatible with
Consent Mode in Client-side GTM (Server-side is not mentioned)
and because it maps well to the consent variables (see Table 4).
We then observed the behavior of the server tags according to the
end-user consent, using the same traffic analysis methods as before.

Figure 3: Client-side GTM: The Hotjar tag downloads an ar-
bitrary script and injects it in the page.

3.2 Results
In this section, we present our findings for the Client- and Server-
side GTM, selected Tags, and of Google Consent Mode.

Technical finding 1. Hidden data leaks by the Tags on the
Client- and Server-side GTM. By analyzing data sent by the Tags
and comparing with data visible to the Publisher in the Data Col-
lector’s website, we found that certain Data Collectors do not show
what data they collect. Table 2a shows the data sent by the three
Tags that we tested in Client-side GTM without any installation of
consent solutions. We observe that the data sent by the Pinterest
Tag is not visible to the Publisher on the Pinterest website, where
we logged in to observe Pinterest’s disclosure about collected data.
Moreover, we find that the data collected by the Google Tag about
form interaction is not shown in the Google Analytics dashboard.
This finding demonstrates that for such Tags, Publishers are not
aware of the data collected by the Tags that they select.

For Server-side GTM, Table 2b shows the data sent by the three
selected Tags. Similarly, some collected data is not visible to the
Publisher on the Data Collector’s website. The Google Analytics
Tag collects data about interaction with forms and the truncated
IP address of the end user. None of this is shown to the Publisher
through the Google Analytics report pages. Mixpanel receives the
complete IP address of the end user and URL of visited webpage,
but does not show it to the Publisher. We found out that with
Server-side GTM, the end-user IP address collection is necessarily
deliberate: it requires the Client Adaptor to copy the IP address
from the browser’s packets to data shared with all the server Tags,
which is what the GA4 Client Adaptor does. In case of Mixpanel
and Facebook Conversion API, moreover, the Tags send the IP
address received from GA4 to Mixpanel and Facebook. Finally,
Facebook did not allow us to review the collected data since when
we created a new account, it was flagged as suspicious and we were
blocked from accessing the data collection dashboard. Therefore,
in both Client- and Server-side GTM, these hidden data leaks raise
transparency concerns since Publishers are not aware of the data
collection implications when they select a particular Tag. We further
analyze its legal implications in Section 4.

3.1.3 Artifacts and Responsible Disclosures. Artifacts associated to
this work are available in an anonymous repository [74]. Addition-
ally, two responsible disclosures are in progress, one with Google
and another one with the Consentmanager CMP. An update will
be added to this article in case of feedback from the companies.

Technical finding 2. 56 Client-side Tags insert scripts that
have full access to the browser APIs and page DOM. In Web
Containers, tags run in a sandbox which restricts them to a lim-
ited set of the JavaScript functionalities [42]. This sandbox imple-
ments the GTM permission system that controls tags’ access to
browser features, such as setting cookies or collecting other data

5

browser visiting example.com

GTM web container
(gtm.js)

Hotjar

user data

script

googletagmanager.com

hotjar.com

Proceedings on Privacy Enhancing Technologies YYYY(X)

Data Google Tag Pinterest Hotjar

✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓

URL of current page
browser and version
screen dimensions
computer architecture
operating system
OS version
engagement time
preferred language
title of current page
number of visits
forms interacted with
scrolling actions
browser windows size
clicks with position
typing in a form
submitting a form
precise mouse moves

✓
✓
✓
✓
✓
✓

✓
✓

✓
✓

✓
✓
✓
✓
✓
✓

(a) Client-side experiments.

Facebook
Conversion
API
✓*

✓*
✓*

G. Mertens et al.

Mixpanel

✓

✓
✓
✓

✓

Data Google

IP address of the user

URL of current page
browser and version
screen dimensions
computer architecture
operating system
OS version
engagement time
preferred language
title of current page
number of visits
forms interacted with

Ana-
lytics
✓
(trun-
cated)
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓

(b) Server-side experiments. Note that the Google Analytics tag trun-
cates the last byte of the IP address claiming to anonymize it.

Table 2: Data collected by the Tags. ✓indicates the data type that is collected by the Data Collector and made visible to the
Publisher via the Data Collector’s website. ✓indicates data type that is collected but not visible, and ✓* indicates it is sent to a
blocked account.

with browser APIs. One of such permission is called “inject_-
script ” which allows a tag to download and execute an arbitrary
script outside of the Web Container. When a tag is granted the
inject_script permission, it can inject such arbitrary script, thus
bypassing the GTM permission system that controls access to fea-
tures, accessing to the all the browser APIs and DOM within the
same origin, according to the Same-Origin Policy [61]. By analyzing
78 officially supported Client-side Tags (§3.1.1), we found that 56
tags inject such scripts. Figure 3 illustrates how Hotjar Tag injects
its own script in the example.com page. Within the GTM permis-
sion system, the Hotjar Tag has the permission to read and write in
two global JavaScript variables (hj and hj.q) and to inject a script.
We find out that it collects all the data shown in Table 2a, including
data that could not be accessed from the sandbox, such as precise
mouse movements. Surprisingly, we found that 5 Tags owned by
Google itself3 bypass its own GTM permission system and inject
scripts in the same way as Hotjar Tag4.

Technical finding 3. GTM permission system allows injection
of arbitrary scripts. By analyzing the presence of inject_script
permission for all 78 Client-side Tags, we have detected 11 Tags
that do not have this permission, but still inject arbitrary scripts.
Out of these 11 Tags, 7 Tags are provided by Google5. This finding
shows that the GTM permission system implemented in the Web
Container sandbox allows Tags to insert arbitrary, uncontrolled
scripts, thus opening potential security and privacy vulnerabilities

3“Google Ads”, “Google Analytics”, “Google Surveys”, “Google Tag”, “G. Trusted Stores”
4The full list of scripts is available in Supplemental Materials [74].
5Google owned Tags: “google tag”, “google ads calls from website conversion”, “google
ads conversion tracking”, “google ads remarketing”, “google analytics: classic”, “google
analytics: ga4 event”, “g. analytics: universal analytics”. Other Tags: “eulerian analytics”,
“lytics js tag”, “tradedoubler lead conversion”, “tradedoubler sale conversion”.

6

to the website. We have disclosed this finding to Google via their
Bug Bounty online system (§3.1.3).

Technical finding 4. “He who says nothing agrees”: unde-
fined consent variables are granted by default. In our experi-
ments on consent mode and CMPs for Client-side GTM (see §3.1.1),
we found that consent variables are in an undefined state when the
CMP is loaded in the webpage. Though CMPs are expected to set
default values to all such variables, we found out that some CMPs
do not explicitly do that. Surprisingly, in this case, GTM considers
all such undefined variables to be accepted by the end user, even
though the end user has not interacted with the consent banner of
the CMP yet. Among two CMPs tested (see §3.1.1), we detected this
behavior for the Consentmanager CMP. This CMP sets a default
value to only two consent variables – analytics_storage and
ad_storage – leaving three GTM consent variables – security_-
storage , personalization_storage functionality_storage –
and consent variables specific to this CMP – e.g., cmp_purpose_c56
which corresponds to the “Social Media” purpose – in undefined
state. These extra variables are hence considered granted by GTM.
As a result, all the Tags that depend on these four consent variables
get executed even without user consent. We note that this default
behavior of undefined variables cannot be changed and discuss its
legal implications in the Potential violation 5 in Study II.

Technical finding 5. Data collected by the Google Tag without
consent. With built-in consent, tags always get executed and since
they are aware of the consent choices of the user, they should adapt
their behavior, and not collect any data related to purposes refused
by the end user. When we tested the Google Tag, which has built-in
consent with various consent decisions (accept all, decline all, only
analytics, only advertisement), we found out that this Tag always

Google Tag Manager: Hidden Data Leaks and its Potential Violations under EU Data Protection Law

Proceedings on Privacy Enhancing Technologies YYYY(X)

sends the user’s data shown in Table 2a, independently of the user’s
consent choice. We found in the GTM documentation that when
the ad_storage or analytics_storage built-in consent variables
are refused, the data collected by Google is “... never used to track
individual users across apps or websites, build remarketing lists, or
generate user profiles” [32].

Technical finding 6. Lack of consent tools in Server-side
GTM. Contrary to Web Containers, the Server Container configu-
ration interface does not provide consent configuration tools such
as the association of consent variables to tags. We however found
that the values of two consent variables, ad_storage and analyt-
ics_storage , are sent to our server container and provided to the
Server Tags. The documentation on consent in Server Containers
tells that “Google product tags in the server are consent-aware and
adjust the amount and kind of data they send based on the user’s
preferences.” As such, we deduce the server tags can implement a
similar mechanism to built-in consent. However the Publisher can-
not see on which consent variable the tag will change its behavior.
Finally, for the three tags tested, we found that declining consent
did not impact the transmission of data items identified in Table 2b.

4 STUDY II: LEGAL ANALYSIS OF GTM
In this section, written together with a legal expert and co-author,
we first explain the legal background on EU Data Protection law
relevant to the GTM ecosystem. We then provide a legal analysis
by identifying the legal role of each actor as it is crucial for further
evaluation of each actor’s compliance and liability [31, Recital 79].

4.1 Legal Background
The General Data Protection Regulation (GDPR) [31] applies to the
processing of personal data [26] and imposes obligations on those
actors who processes it paired with heavy fines for non-compliance.
The ePrivacy Directive (ePD) [21] provides supplementary rules to
the GDPR in particular for the use of tracking technologies. When-
ever cookies and other tracking technologies are stored and read
from the user’s device, the ePD [21, Art.5(3)] requires organiza-
tions to request consent for the storage of such trackers for certain
purposes for processing data, such as advertising [17, 18]. Some pur-
poses are exempted of consent, e.g, functional or technical purposes
required for a website requested by a user to operate [21, Recital 66].
The only way to assess with certainty whether consent is required
is to analyze the purpose of each tracker on a given website [16, 29].

4.1.1 Personal data. It is “any information relating to an identified
or identifiable natural person (’data subject’). An identifiable nat-
ural person is one who can be identified, directly or indirectly [31,
Art.4(11)]. In order to determine whether a person is identifiable,
account should be taken of all the means likely reasonably to be
used by any actor to identify that person. Accordingly, if certain
data, alone, is not personal data, it becomes personal data as regards
to someone who reasonably has the means of enabling that data to
be associated with a specific person [2, para. 46]. GDPR Recital 30
asserts that online identifiers provided by their devices, such as IP
addresses, can be associated to a person, thus making them identi-
fiable. This identification does not require that all the information
enabling that person to be identified should be in the hands of a

7

single entity [1, para. 42, 43]. Processing of personal data consists of
‘any operation(s) performed on personal data, such as collecting,
sharing, using, making available, accessing, combining [31, Article
4(2)]. In practice, this means that almost any imaginable handling
of personal data constitutes processing [4, 25].

4.1.2 Data Controller and Data Processor. According to European
Data Protection Board (EDPB) opinion [4], to determine whether
an actor is a Data Controller, its factual roles and activities have to
be evaluated in a specific situation. An actor is a Data Controller if
it is responsible for determining the purposes, and the means of the
processing of personal data [31, Art. 4(7)].

“Determines” means having the “decision-making power” [4,
23, 27] or “independent control” [48] over the purposes and means
of the processing [27]. The Court of Justice of the EU (CJEU), Data
Protection Authorities (DPAs) and the EDPB describe that such
control can be derived from: professional competence (legal or im-
plicit) [4]; factual influence, based on the real circumstances sur-
rounding the processing; image given to data subjects and their
reasonable expectations on the basis of this visibility [4]; which ac-
tor “organizes, coordinates and encourages” data processing [23, para
70-71]; and interpretation or independent judgement exercised to per-
form a professional service [48]. “Purposes” refers to “why” data is
processed. Purposes need to be explicit, specified and legitimate [31,
Art. 5(1)(b)]. “Means” refers to the how the objectives of process-
ing are achieved. The EDPB distinguishes between “essential” and
“non-essential means” and provides examples thereof [4, 27]: Es-
sential means are closely linked to the purpose and the scope of
the processing and are inherently reserved to the controller. Ex-
amples of essential means are: determining the type of personal
data processed; duration of processing, recipients of personal data,
or categories of data subjects. Non-essential means may be dele-
gated to the Data Processor, involving practical implementations,
like hardware or software selection, security measures, or data
storage/retrieval methods.

An actor is a Data Processor when it processes personal data on
behalf of the data controller [31, Art. 4(8)]. An actor is a processor
when: i) it is dependent on the controller’s instructions regard-
ing processing activities [4][27], (Art. 28(3)(a)), Recital 81); and ii)
complies with those instructions [27].

Joint Controllership. Where two or more controllers jointly
4.1.3
determine the purposes and means of processing, they shall be
joint controllers [31, Art. 26(1)]. Joint participation can take the
form of common or converging decisions on purposes and essen-
tial means [27]. Decisions can be considered as converging if they
complement each other and are necessary for the processing to
take place in such manner that they have a tangible impact on the
determination of the purposes and means of the processing. An
important criterion to identify converging decisions is whether the
processing would not be possible without both parties’ participation
in the sense that the processing by each party is inseparable, i.e.,
inextricably linked [27]. Joint controllership requires an agreement
pursuant to GDPR Article 26. However, there is no requirement for
both parties to share responsibility equally [24, para 43]. Similarly
to Data Controllers, each of the both parties do not need to have
access to personal data to be considered a controller[24, para 38].

Proceedings on Privacy Enhancing Technologies YYYY(X)

G. Mertens et al.

4.1.4 GDPR obligations for Data controllers and Data processors. If
an actor is established as a data processor, it can be held liable and
fined if it fails to comply with its obligations under the GDPR [31,
Art. 28(3)(f), 32-36]. Compliance with the GDPR is enforced by the
EU Data Protection Authorities (DPAs), which monitor and super-
vise the application of the GDPR [31, Art.55-57]. Data controllers
must comply with the following principles:

• Purpose limitation: collect personal data for specific, detailed
and explicit purposes and not further processed for incom-
patible purposes [31, (Art. 5(1)(b)];

• Minimization: collect personal data that is adequate, relevant
and limited to what is necessary in relation to the purposes
for which data are processed [31, (Art. 5(1)(c)];

• Lawfulness: collect personal data only when it is legitimized
with one legal basis [31, Art. 5(1)(a)]. In case this legal basis
is consent, the consent must be prior to any data collec-
tion, freely given, specific, informed, unambiguous, readable,
accessible, and revocable [31, Art.4(11), Art. 7] [69];

• Transparency: collect personal data when it informs the end
user about the purposes, third party recipients, legal basis,
among other information [31, Art. 5(1)(a), 13, 14].

• Security: ensure appropriate security of the personal data
including protection against unauthorized or unlawful pro-
cessing [31, Art. 5(1)(f), 32].

• Data Protection by Default: ensure that personal data is pro-
cessed with the highest privacy protection so that by default
personal data isn’t made accessible to an indefinite number
of persons [31, Art. 25(1)(2)].

• Accountability [31, Art.5(2)]: the controller must be able to
demonstrate compliance to each principle at any time;

4.2 Legal Analysis of Client-Side GTM
In this section we analyze the roles of the actors involved in client-
side GTM: GTM Provider, CMPs, Data Collectors and Tag Providers
since they raise potential violations to the GDPR and ePrivacy
directive. We start our legal analysis by identifying whether these
GTM actors process personal data. According to our results, both
GTM Provider and Data Collector process the IP address of the end
user because they receive incoming HTTP requests on their servers.
Following the arguments of Santos et al. [70], if an IP address is
combined with additional user data, then the IP address receiver has
the means and information reasonably likely to indirectly render a
user identifiable [31, Recital 26]. Since the Publisher’s role does not
trigger potential violations, we refer to its role in the Appendix 6.
Figure 4 depicts the GTM actors and their relationships.

4.2.1 Consent Management Platforms (CMPs). The website Pub-
lisher selects a CMP to manage end-user’s consent (see step (3)
in Figure 4). To integrate the consent banner with GTM, the CMP
needs to be compatible with the Google Consent Mode. The two
CMPs tested during this study – Consentmanager and Cookiebot –
offer a scanning service that automatically detects the cookies on
the Publisher’s website and third parties with whom these cookies
are shared [70, Fig.3]. The scanner then classifies the third parties
and associates purposes.

8

Consent variable

ad_storage

analytics_storage

functionality_-
storage

personalization_-
storage
security_storage

Description provided by GTM
Enables storage (such as cookies) re-
lated to advertising
Enables storage (such as cookies) re-
lated to analytics e.g. visit duration
Enables storage that supports the func-
tionality of the website or app e.g. lan-
guage settings
Enables storage related to personaliza-
tion e.g. video recommendations
Enables storage related to security such
as authentication functionality, fraud
prevention, and other user protection

Table 3: GTM consent variables and their descriptions.

Determination of Purposes. Through this scanning activity, the
CMP extracts the purposes of the trackers from the Publisher’s web-
site as shown in step (4a) of Figure 4. From reading the provided
scanning report, the Publisher configures those purposes for each
tag in the GTM interface as shown in step (5a) of Figure 4. As such,
the Publisher determines the purposes for processing together with
the CMP’s help. Notably, CMPs are argued to be recognized as Data
Controllers, following the arguments of Santos et al. [70, Section
4.3]. We posit that the final decision on the needed purposes for the
Tag in question is a converging decision between Publishers and cho-
sen CMPs (see §4.1.3), where both decisions to hire the CMP by the
Publisher, and to identify the purposes by the CMP complement each
other and are necessary for the processing to take place. Therefore,
this decision (joint decision by the Publisher and the CMP) has a
tangible impact on the determination of purposes of processing.
Determination of means. When CMPs provide their services
and tooling (besides consent management), such as scanning, such
CMPs define the means for processing.

Legal role: Publisher and CMP are Joint Data Controllers.

Potential violation 1. CMP scanners often miss purposes.
During our experimentation on Client-side GTM (see §3.1.1), we
installed the Google Tag that contains two specific built-in purposes
– ad_storage and analytics_storage . We found out that when
Cookiebot and Consentmanager scanners run, they report only
analytics purposes and miss the advertising purpose of this tag.
Publishers that rely on these scanners without further reading Data
Collector’s Terms&Conditions face the risk to misconfigure consent
requirements of Tags. Furthermore, as third-party cookies are being
phased out by all major browsers, CMP scanners only relying on
cookie scanning such as Cookiebot risk under-reporting purposes
for installed tags, as demonstrated by Toth et al. [75].
Recommendation CMPs should either provide a comprehensive
scanning service including all purposes both from stateless and
stateful tracking technologies or avoid providing any scanner at all.
Relatedly, we recommend GTM to provide to the CMP/Publisher
the list of tags installed in the GTM Web and Server Containers so
that CMPs will be able to reliably detect the Data Collectors and
map the purposes of such tags.

Google Tag Manager: Hidden Data Leaks and its Potential Violations under EU Data Protection Law

Proceedings on Privacy Enhancing Technologies YYYY(X)

Figure 4: client-side GTM configuration by a Publisher and usage by an end user

Cookiebot Purpose
Statistics
Marketing
Necessary
Preferences

GTM consent variable(s)

analytics_storage
ad_storage
security_storage
personalization_storage
functionality_storage

Table 4: Cookiebot purposes and corresponding GTM consent
variables.

Potential violation 2. Mapping CMP purposes to GTM con-
sent variables is not compliant. CMPs need to map GTM’s con-
sent variables to the purposes shown in their consent banner. No-
tably, such mappings are not documented anywhere by CMPs nor
by GTM. Furthermore, these mappings are subject to the legal issues
identified in Potential Violation 3 and 4. When installing CookieBot
and Consentmanager CMPs (claimed to be GTM compatible [33])
on our website, we could infer the mappings of purposes (presented
in Appendix Table 4 and 8). Herein we report several problems
concerning such mappings: First, these CMPs use different names
for purposes rather than the ones used by GTM. For example, the
consent variable analytics_storage is called “Statistics” by Cook-
iebot, and “Measurement” by Consentmanager. The Publisher might
not be aware that the purpose “Measurement” in the Consentman-
ager CMP banner corresponds to the analytics_storage consent
variable in the GTM interface, and might have difficulty to configure
tags that depend on this purpose. Second, certain CMPs merge multi-
ple GTM purposes altogether, as displayed in Table 4. GTM consent
variables functionality_storage and personalization_stor-
age are merged into one category called “Preferences”. A Publisher

does not know that the “Preferences” purpose in the Cookiebot
refers to two different purposes in GTM which are personaliza-
tion_storage and functionality_storage . Third, in our exper-
iments we ascertained that Consentmanager only partially maps
its purposes to GTM consent variables, as displayed in Table 8.
Consentmanager does not map any of its own purposes to the
ad_storage consent variable. If a user agrees to the marketing
purpose shown in the consent banner, as there is no default consent
variable that is associated with marketing purpose, a new variable
(not included by default in GTM) is created within GTM. A Pub-
lisher might not be aware of this lack of mapping, neither of the
need to configure such consent variable to a Tag. For instance, this
means that a Publisher that uses the personalization_storage
variable to configure a Tag, will see that this Tag will always run
independently of user choices (see Technical finding 4).
Recommendation We recommend that GTM and CMPs agree on
purpose names, descriptions and matching of purposes.

4.2.2 GTM Provider. This actor6 provides the GTM service with
its Tag management functionalities to website Publishers.
Determination of purposes. This actor is involved in the deter-
mination of purposes for two reasons. First, it defines five default
consent variables in GTM “Consent Mode”: ad_storage , ana-
lytics_storage , security_storage , functionality_storage
, and personalization_storage , presented in Table 3. We claim
that these consent variables correspond to personal data process-
ing purposes within the meaning of Article 5(1)(b) of the GDPR. A
Publisher then needs to associate each Tag to one or more of these
mentioned purposes, when purposes are not built-in. Second, we
argue that GTM “organizes and coordinates” data processing [23,

6The provider of GTM is Google at the time of our experiment.

9

 (2b) identifies Google Analytics Collector associated to Google Tag

(1) selects and installs Pinterest Tag and Google Tag

GTM Web Container Configuration Interface 

Publisher's website

GTM Consent Variables

Purposes of the Tags

GTM Web Container (gtm.js)

(0) Provides

GTM 
Provider

ad_storage
analytics_storage
functionnality_storage
personalization_storage
security_storage

Pinterest Tag

Google Tag

Extracted purposes: 
 • “Social Media”         
    purpose

Built-in Consent: 
• ad_storage 
• analytics_storage

(5a) configures purposes for Pinterest Tag

(5b) purposes  
extracted by GTM

(4a) runs a CMP scanner to extract
purposes for Pinterest Tag

CMP scanner

Publisher

(3) selects the CMP

(8) end-user's data

(0) Provides

Google Tag with built-in
consent

if ad_storage then
  send Data1 to collector
if analytics_storage then
  send Data2 to collector
else 
  send Data3 to collector

Pinterest Tag without built-in
consent

< Code that does not      
invoke GTM built-in 
consent >

CMP

End-user

(7) accepts/rejects consent

CMP consent banner

(6) configure CMP purposes

 (2a) identifies Pinterest Collector associated to Pinterest Tag

(4b) extracts purposes of Pinterest Collector

Google Analytics
Collector

Terms and
Conditions

(9a) end-user's data

(0) Provides
Tag's code

Tag Provider of 
Google Tag

(0) Provides
Tag's code

Tag provider of  
Pinterest Tag

(9b) end-user's data

Pinterest Collector

Terms and Conditions

• Social Media"" purpose

 
Proceedings on Privacy Enhancing Technologies YYYY(X)

G. Mertens et al.

paragraphs 70, 71], since it enables the orchestration of data collec-
tion and sharing through several actors - the Publisher, Tag Provider
and the Data Collector. Hence, GTM Provider’s platform is the
placeholder that coordinates the Tags for collecting data. GTM also
encourages data processing by proposing the tags to Publishers.
Determination of means The GTM Provider generates Web Con-
tainers and provides the configuration interface wherein the Pub-
lisher configures GTM Containers and their components (e.g., Tags).
As such, it determines non-essential means for data to be processed.

Legal role: Provider of the GTM service is a Data Controller.

Potential violation 3. GTM purposes are limited to client-
side storage. All consent variables definitions in GTM (Table 3)
are storage-based. The technologies that do not explicitly store any
information in the user’s terminal equipment, known as “stateless”
technologies, such as browser fingerprinting [30, 54], are hence
excluded and therefore not covered by the GTM Provider by default.
This means that if a Publisher installs a given Tag in the GTM
interface which uses a stateless technology, it will not be covered
by the purposes defined by GTM. Therefore, there is no way for
Publishers to be compliant with the ePrivacy Directive [22] when
using stateless tracking technologies in the Web Containers, since
this directive requires consent for all non-necessary purposes of
these tracking technologies. We reason that both Publishers and
Tag Providers (when they decide to include built-in consent) might
become confused when mapping consent variables to Tags. Because
of this limitation, they cannot ensure compliance for their websites
and Tags when using stateless technologies that require consent.
Recommendation GTM should define purposes regardless of the
type of technology used (stateless or stateful).

Potential violation 4. GTM purposes are not specific nor
explicit. The GTM Provider, as a data controller, is obliged to pro-
vide specific, detailed and explicit purposes, according to the GDPR
Purpose limitation principle (see Section 4.1.4). The description of
the personalization_storage consent variable that says “stor-
age related to personalization e.g. video recommendations” is not
clear enough to understand to what final goal such personalization
applies to - for example, if it is used for targeted advertising, it
would require consent. These short and vague descriptions make it
difficult for Publishers to conclude whether a purpose is exempted
of consent (in case such purpose is functional or technical, see §4.1).
Consequently, CMPs might run the risk to require consent for pur-
poses exempted thereof. For example, Cookiebot requests consent
for non-necessary purposes of “Preferences”, “Statistics” and “Mar-
keting” in its consent banner. However, the “Preferences” purpose
(see Table 9) seems to be necessary for a website to function, and
hence, should be exempted of consent [21, Art. 5(3)]). As Cookiebot
maps this purpose to the GTM consent variables personaliza-
tion_storage and functionality_storage , according to their
description in Table 3, it requests consent for this purpose.
Recommendation GTM should employ purpose-specific and ex-
plicit consent variables. Additionally, CMPs should not request
consent for unnecessary purposes.

Potential violation 5. Defaulting consent variables to “ac-
cepted” means that Tags run without consent. As described

10

in the Technical Finding 4, the Web Container considers both “ac-
cepted” and “not defined” variables as accepted by the user, by
default. We also discovered a case where the Consentmanager CMP
allows some consent variables to be undefined. As such, the tags
installed in the Web Container will run and collect user’s data
without their due consent. This practice renders any processing
of personal data potentially illegal [31, Article 6(1)(a)]. Notably,
Consentmanager declares in its documentation that some consent
mode functions are limited and not recommended for Publishers
to use [12]. We argue that their disclaimer on the ""experimental
mode"" does not exempt them of accountability obligations [31, Ar-
ticle 5(2)]. Nevertheless, GTM still recommends to use this CMP
without any warning, and it further states: “Discover featured CMP
templates that deeply integrate with GTM’s consent configuration” in
the interface. By doing so, GTM pushes Publishers to use a flawed
CMP that might enable tags to run independently of consent, and
thus enabling processing of personal data without legal basis.
Recommendation GTM should treat undefined consent variables
as “not accepted” by default, and prohibit tags from collecting data
before consent has been obtained to comply with the Privacy by
default GDPR principle [31, Art. 25(2)]. GTM should validate rec-
ommended CMPs or explicitly warn about their limitations.

4.2.3 Data Collector. Data Collectors receive the data collected by
tags from the Publisher’s website (Step (9a) and (9b) in Figure 4).
Collection of personal data Data Collectors have the means to
combine the IP address with additional collected data, as shown in
Table 2. Following our arguments in the beginning of Section 4.2,
the combination of IP address with these data can render a user
identifiable, and thus this data is considered to be personal data.
Determination of Purposes The Data Collector, through the
Terms and Conditions (T&Cs) or Privacy Policy it provides to the
Publishers, decides upon the purposes and other conditions of pro-
cessing, as shown in step (4b) in Figure 4. Examples for two specific
case studies on two popular Data Collectors show how they commu-
nicate purposes to Publishers through T&Cs. In the documentation
for Pinterest Tag, we found only one and very specific purpose of
“online behavioural advertising” in the Advertising Guidelines[65].
On its page, Pinterest says: “(...) information will be shared with third
parties for online behavioural advertising”. In HotJar’s documenta-
tion, we found information about the purposes of the collected
data in its data processing agreement [14]. In our interpretation, it
pertains to the purposes of analytics and aggregated user behavior:
“Hotjar allows its users to analyze and understand the behavioral
patterns of their visitors (...). We reason there is a pluralistic control
exercised by both the Data Collector and the Publisher: there is
a common and complementary decision from both Publisher and
Data Collector to process data, from the very moment in which
the Publisher contractualizes with the Data Collector, derives the
purposes from its T&Cs (Step 4b Fig. 4) and relies on the means of
processing from the Data Collector. The processing would not be
possible without the participation of both parties. This interdepen-
dence of the Publisher on the definition of purposes and means of
the Data Collectors renders both actors joint controllers.
Determination of Means Data Collectors receive users’ data from
the Tag and provide a service to the Publisher by processing the data.
For example, Google Analytics provides a dashboard with statistics

Google Tag Manager: Hidden Data Leaks and its Potential Violations under EU Data Protection Law

Proceedings on Privacy Enhancing Technologies YYYY(X)

Is a Collector?

S1
S2
S3

✗
✗
✓

Has built-in
consent?

✗
✓
not relevant

Legal Role of the Tag
Provider
none
none
Data Controller

Table 5: Legal role of the Tag Provider depending on whether
it is a Data Collector or the tag has built-in consent.

about the Publisher’s website users. As a result, the Data Collector
defines the means of processing since it decides how to process the
received data and what algorithms to use on the received data to
obtain the service requested by the Publisher.

Legal role: Publisher and Data Collector are Joint Data Con-
trollers.

4.2.4 Tag Provider. This actor merely writes the code of a tag,
and such tag consists in the means to collect and send the data to
the Data Collector. In general, Tag Provider does not receive nor
store data from end users. The Tag Provider is aware that, at some
point, some Publisher will use its Tag, without necessarily knowing
the identity of the Publisher. The Tag Provider can include built-
in consent in the Tag (e.g., Google Tag in Figure 4, see “Consent
Configuration” 3.1.1). As shown in step (5b) of Figure 4, GTM
extracts the purposes used by every tag using built-in consent
functionality and displays them in GTM consent configuration.

In Client-side GTM, it is common that a given company plays
two roles at the same time: Tag Provider and Data Collector. We
have identified 3 scenarios (S1, S2, S3) shown in Table 5 that we
use to reason about the role of the Tag Provider.
S1: When the company behind the Tag Provider is not the same as
the Data Collector, and there is no built-in consent in the Tag , it
seems that there is no contract or agreement that could link the
Publisher to the Tag Provider. The Tag Provider still defines, in
the Tag, to whom the user’s data will be sent (so, who are the
Data Collectors). This entails that the Tag Provider determines
essential means of processing. However, the Tag Provider is not a
Data Controller because it is missing the determination of purposes,
i.e., there is no built-in consent in the Tag that pre-defines purposes.
The Tag Provider is neither a Data Processor, since it does not follow
instructions from the Publisher nor from the Data Collector – it
does not process personal data on behalf of these actors, since it
is missing the dependence on the controller’s instructions regarding
processing activities which defines the role between a processor and
a controller (see §4.1). Hence, Tag Providers, under this scenario,
are just service providers, with no GDPR obligations.
S2: When the company behind the Tag Provider is not the same as
the Data Collector, and the tag contains built-in consent, the Tag
Provider includes the purposes for collecting data inside of the
Tag’s code. This inclusion of predefined purposes in the Tag could
qualify the Tag Provider as a Data Controller, since it seems to
define the purposes itself. Even though the Tag Provider develops
a data-collecting Tag by itself, which is released to the public and
enables the collection of data, these facts are not enough to reveal a
factual influence over the definition of purposes of personal data [3].
We reason that by embedding the built-in consent in the tag, the

11

Tag Provider might not relate to the processing of personal data in
itself; it just consists of a prior step to the processing of personal
data [3], it does not provide enough elements of a factual nature
that the Tag Provider exercises an actual influence with regards to
the “purposes and means” of processing data [3]. Also, this actor
does not process personal data. Hence, Tag Providers, under this
scenario, are just service providers, with no GDPR obligations.
S3: When the company behind a given Tag Provider is the same as a
Data Collector it is possible to conclude that a Tag Provider/Data
Collector, jointly with a given Publisher, can be considered as Joint
Controllers, since Data Collectors and Publishers are Joint Con-
trollers, as already established in Section A.1. This qualification
holds regardless of whether there is built-in consent or not in the
Tag, since the Data Collector determines already the purposes of
processing in the T&C or contractual services.

Legal role: Tag Provider’s role depends on whether it is a Data
Collector. See Table 5 for a summary of their role.

Potential violation 6. Google Tag sends data independently
of user’s consent decisions. Our Technical Finding 5, Google
Tag always sends user’s data to Google even when the user has re-
jected all built-in purposes, thereby processing user’s data without
a lawful legal basis, infringing the Lawfulness principle. Moreover,
when user’s data is sent to Google, the Security principle is violated
because of an unauthorized disclosure with Google (§4.1). As a Data
Controller, Google is liable for these potential violations.
Recommendations Google, as Tag Provider and Data Collector,
must change its “Google Tag” behavior to respect user’s choices in
order to be compliant.

Potential violation 7. GTM allows Tag Providers to inject
scripts exposing end users to security risks. In Technical Find-
ing 2, we found that GTM contains a special inject_script per-
mission, allowing Tags to inject arbitrary JavaScript code in the
website’s page (see Figure 3). We found 56 Client-side Tags that
inject such scripts which are not subject to any security measures
implemented in Web browsers, such Same-Origin Policy [61], to
protect users from script-based Web attacks. This practice, allowed
by GTM and executed by Tags, potentially infringes the Security
principle (§4.1.4). The Provider of the GTM service, as a Data Con-
troller, is liable for these potential violations. Additionally, the Tag
Providers of these 56 Tags are Data Collectors, when they are Data
Controllers, are also liable for such violations.
Recommendations GTM should not allow Tag Providers to in-
clude arbitrary scripts in the website’s pages without adopting any
security safeguards. Tag Providers should not use this loophole of
GTM to inject arbitrary scripts.

4.3 Legal analysis of Server-Side GTM
In this section we describe the actors involved in Server-side GTM.
We reproduce the same legal reasoning about some of the roles of
the actors held on Section 4.2 regarding the Publisher (appendix
§A.1), Data Collector (§4.2.3) and GTM Service Provider (§4.2.2). As
such, herein we focus on the Provider of Collector Tag and Client
Adaptor, the Server Provider and Server Tag Provider. Since the
Server Provider’s role does not trigger potential violations, we refer
to it in the Appendix (A.2). After analyzing the Provider of Collector

Proceedings on Privacy Enhancing Technologies YYYY(X)

G. Mertens et al.

Actor
Publisher
Data Collector
CMP
Tag Provider
GTM Provider
Server Provider
Provider of
Collector Tag and
Client Adaptor

Client-side
Data Controller
Data Controller
Data Controller

Server-side
Data Controller
Data Controller
N/A

Depends, see Tab.5 Depends, see Tab.5

Data Controller
N/A
N/A

Data Controller
Data Processor
No legal role

Table 6: Summary of the legal roles of the actors.

Tag and Client Adaptor functions, we concluded it has no GDPR
legal role. We found that this actor presents similarities with the
Tag Provider in client-side GTM (when it is not a Data Collector)
since it merely develops and provides software without processing
personal data and without following instructions from any other
actors. Table 6 outlines server-side roles for each GTM actor.

The processing of personal data on the Server-side needs to be
assessed on a case-by-case basis. The Server Provider processes the
IP address of end users since it receives incoming HTTP requests
on its servers; the Data Collector will sometimes receive personal
information (see Table 2b for specific Data Collectors that receive
the IP address of end users).

Server Tag Provider. This actor presents similar functions
4.3.1
as to the Tag Provider on client side 4.2.4. On server-side GTM,
the absence of the built-in function does not change its legal role
as a Data Controller when the Server Tag Provider is also a Data
Collector.

Legal role: Tag Provider’s legal role depends on whether the
Data Collector is the same company.

Potential violation 8. Server Tag Providers that are also Data
Collectors are aware that lawful data collection is not possi-
ble. A Server Tag Provider, who provides the code of a tag, knows
how the GTM Server Container functions (see Figure 2b) and thus
is aware that no consent management tool is available on the Server
Container. A Server Tag Provider also knows that the Publisher
cannot conveniently configure the Server Container to match GTM
consent variables to Server Tags (see §5). Nonetheless, Server Tag
Provider still provides Server Tags. When a Server Tag Provider
directly receives users’ personal data, it has a legal role of a Data
Collector, and therefore becomes a Data Controller (see Table 5).
Moreover, it is a Joint Controller with the Publisher (see §4.2.3), and
therefore has the responsibility to ensure lawful data processing.
Recommendation Server Tag Providers that are Data Collectors
should not provide Server Tags until the GTM does not have the
consent management functionality on the Server-side.

5 DISCUSSION
In this section, we discuss other findings and reflect upon the diffi-
culty to comply with the EU Data Protection framework for various
actors within the Client- and Server-side GTM and provide further
recommendations for improvement of GTM.

12

Complying with data subject rights is hard for the Publisher. Within
both Client- and Server-Side GTM, the Publisher is left alone to
comply with users’ rights, like data requests, due to the absence
of a dedicated system for this functionality. For example, if a user
requests access to her data (under Article 15 GDPR), the Publisher
would probably need to find the contact of every Data Collector and
compile it manually to then answer to the user – a task confirmed
to be problematic as studied by Samarin et al. [68]. GTM should
furnish Publishers with a common interface to identify all Data
Collectors, and a streamlined tool from Data Collectors to facilitate
users’ data requests.

Built-in consent raises trust issues. When the Publisher uses Tags
with built-in consent (such as “Google Tag” in Potential Violation 6),
it relies on the Tag Provider to properly implement the built-in
consent in its code. However, the Tag Provider can declare to rely
on some built-in consent purposes, but completely ignore them in
the Tag code, and send the user’s data even if the corresponding
purposes were rejected by the user. The only way a Publisher can
ensure proper consent management is to review the Tag’s code. This
in only possible for non-official Tags, whose code is available on
the template gallery. However, code reviewing is not possible for
official Tags, that are implemented as sandboxed code inside the
gtm.js , and it requires heavy reverse engineering. Publishers can
also ignore built-in consent and manually add consent variables
(Step (5a) in Figure 4). In this case, the Tag will only run when
all the consent variables associated with the tag are granted. GTM
should allow Publishers to access the code of the Tags for auditing
and should facilitate Publishers to understand the Tags’ code.

Server-side GTM is invisible for regulatory monitoring and au-
diting. Server-side GTM obstructs compliance auditing endeavors
from regulators, data protection officers, and researchers, since
data collection occurs remotely on a server, whereas traditionally
it happens in the browser. For example, while only the Collector
Tag is detectable, the tags chosen by a Publisher remain invisible.
It is possible to monitor the data collected and transmitted to the
GTM Server Container; however, discerning which Collectors have
access to such data remains unknown. Moreover, auditing and mon-
itoring is exclusively attainable by only contacting the Publisher
to grant access to the configuration of the GTM Server Container.
Furthermore, the Publisher is able to change the configuration of
the GTM Server Container at any point in time (e.g., before any
regulatory investigation), masking any compliance check.

Consent is hard to configure on GTM Server Containers. While
Google advertises: “respect user consent choices with Google Tag
Manager” [41], consent management tools are limited to client-
side GTM and it is challenging to render consent compliant on the
server-side. The lack of consent management tools in GTM Server
Container raises the following two problems: First, CMPs scanners
can only detect tags in GTM Web Containers but are not able to de-
tect tags on GTM Server Containers; this impossibility entails that
CMPs cannot display the purposes and the Data Collectors in the
consent banner to end users. This type of information disclosure is
mandatory for an end-user informed consent and transparent pro-
cessing of personal data [31, Art. 4(11), 5(1)(a)]. Second, Publishers
that wish to be compliant on the Server-side, need to make complex

Google Tag Manager: Hidden Data Leaks and its Potential Violations under EU Data Protection Law

Proceedings on Privacy Enhancing Technologies YYYY(X)

configurations such as writing code to decode consent information
and create filtering rules in respect to the given consent in the
GTM Server Container since there is no interface to configure con-
sent. Furthermore, since Server Container does not support consent
mode, Publishers cannot associate tags with purposes. GTM should
implement consent management tools in GTM Server Containers
and provide the list of installed Tags to CMPs.

6 CONCLUSION
This work is the first to study both versions of Google Tag Manager:
Client-side and Server-side. We analyzed these systems with 78
Client-side Tags, 8 Server-side Tags and two Consent Management
Platforms (CMPs) and performed an in-depth technical and legal
analysis of GTM, determining the responsibilities and potential
legal violations of each actor. Our results show that GTM has many
pitfalls, such as flaws in its security system and non-compliant
defaults. We conclude that GTM in its current state introduces
more legal issues than solving, while making compliance difficult
to achieve for various actors and complex for regulators to monitor.

ACKNOWLEDGMENTS
This work has been supported by the ANR 22-PECY-0002 IPoP
(Interdisciplinary Project on Privacy) project of the Cybersecurity
PEPR. The authors would like to thank Javiera Bermudez Alegria,
from Universidad de Chile, who contributed to the initial work.

REFERENCES
[1] 2016. Case 582/14 – Patrick Breyer v Germany. Court of Justice of the European

Union ECLI:EU:C:2016:779.

[2] 2023.

C-319/22 Scania case.

ECLI:EU:C:2023:837.

Court of Justice of the European Union

[3] 2023.

the Advocate General on the case Case C-683/2,
Opinion of
https://curia.europa.eu/juris/document/document.
ECLI:EU:C:2023:376.
jsf?text=&docid=273310&pageIndex=0&doclang=EN&mode=req&dir=&occ=
first&part=1

[4] 29 Working Party. 2010. Opinion 1/2010 on the concepts of “controller” and
https://ec.europa.eu/justice/article-29/documentation/

“processor” WP 169.
opinion-recommendation/files/2010/wp169_en.pdf.

[5] Reuben Binns, Jun Zhao, Max Van Kleek, and Nigel Shadbolt. 2018. Measuring
Third-party Tracker Power across Web and Mobile. ACM Transactions on Internet
Technology 18, 4 (Nov. 2018), 1–22. https://doi.org/10.1145/3176246 Supple-
mentary materials were consulted on June the 7th, 2023 at https://arxiv.org/e-
print/1802.02507..

[6] Brave Software, Inc. n.d.. Brave Shields. https://brave.com/shields/ (Consulted

on June 27th 2023)..

[7] BuiltWith® Pty Ltd. n.d.. Google Tag Manager Usage Statistics.

https:
//trends.builtwith.com/widgets/Google-Tag-Manager (Consulted on November
20th 2023)..

[8] Ronan Chardonneau. 2015. Google Tag Manager – Optimisez Le Tracking De Votre

Site Web. Éditions ENI, FRA.

[9] chromium-browser n.d.. Chromium. https://www.chromium.org/Home/ (Con-

sulted on November 28th 2023)..

[10] chromium-flatpak n.d.. Chromium Web Browser. https://flathub.org/apps/org.

chromium.Chromium (Consulted on June 29th 2023)..
[11] Consentmanager. n.d. Consent Management Provider.
consentmanager.net/ (Consulted on June 15th 2023)..

https://www.

[12] Consentmanager. n.d.. Working with Google Consent Mode.

https://help.

consentmanager.net/books/cmp/page/working-with-google-consent-mode
(Consulted on November 7th 2023)..

[13] Cookiebot. 2020. Google Tag Manager and cookie consent | Compliance with
Cookiebot CMP. https://www.cookiebot.com/en/google-tag-manager/ (Con-
sulted on June 15th 2023)..

[16] European Data Protection Board (EDPB). 2012. Opinion 04/2012 on Cookie

Consent Exemption (WP 194).

[17] European Data Protection Board (EDPB). 2013. Opinion 03/2013 on purpose limita-
tion (WP 203). Available at https://ec.europa.eu/justice/article-29/documentation/
opinion-recommendation/files/2013/wp203_en.pdf.

[18] European Data Protection Board (EDPB). 2013. Working Document 02/2013
providing guidance on obtaining consent for cookies, adopted on 2 October 2013.
Available at https://www.pdpjournals.com/docs/88135.pdf.

[19] Steven Englehardt and Arvind Narayanan. 2016. Online Tracking: A 1-million-site
Measurement and Analysis. In Proceedings of the 2016 ACM SIGSAC Conference
on Computer and Communications Security. ACM, Vienna Austria, 1388–1401.
https://doi.org/10.1145/2976749.2978313

[20] Steven Englehardt and Arvind Narayanan. 2016. Online Tracking: A 1-million-site
Measurement and Analysis. In Proceedings of the 2016 ACM SIGSAC Conference
on Computer and Communications Security, Vienna, Austria, October 24-28, 2016,
Edgar R. Weippl, Stefan Katzenbeisser, Christopher Kruegel, Andrew C. Myers,
and Shai Halevi (Eds.). ACM, 1388–1401. https://doi.org/10.1145/2976749.2978313
[21] ePD-09 2009. Directive 2009/136/EC of the European Parliament and of the
Council of 25 November 2009. https://eur-lex.europa.eu/legal-content/EN/TXT/
?uri=celex%3A32009L0136, accessed on 2019.10.31.

[22] ePD-09 2009. Directive 2009/136/EC of the European Parliament and of the
https://eur-lex.europa.eu/eli/dir/2002/58/oj,

Council of 25 November 2009.
accessed on October 30th 2023.

[23] European Court of

Justice. 2018.

Case 25/17 Jehovan todistajat,

ECLI:EU:C:2018:551.

[24] European Court of Justice. 2018. Case C-210/16 Wirtschaftsakademie Schleswig-

Holstein, ECLI:EU:C:2018:388.
[25] European Court of Justice. 2023.

ECLI:EU:C:2023:745.

C-659/22, Ministerstvo zdravotnictví,

[26] European Data Protection Board. 2007. Opinion 4/2007 on the concept of personal
https://ec.europa.eu/justice/article-

data (WP 136), adopted on 20.06.2007.
29/documentation/opinionrecommendation/files/2007/wp136_en.pdf.

[27] European Data Protection Board. 2020. Guidelines 07/2020 on the concepts of
controller and processor in the GDPR Version 1.0. https://edpb.europa.eu/our-
work-tools/public-consultations-art-704/2020/guidelines-072020-concepts-
controller-and-processor_en.

[28] Imane Fouad, Nataliia Bielova, Arnaud Legout, and Natasa Sarafijanovic-Djukic.
2020. Missed by Filter Lists: Detecting Unknown Third-Party Trackers with Invis-
ible Pixels. In Proceedings on Privacy Enhancing Technologies (PoPETs), Vol. 2020.
499–518. Issue 2. https://doi.org/10.2478/popets-2020-0038 Published online: 08
May 2020, https://doi.org/10.2478/popets-2020-0038.

[29] Imane Fouad, Cristiana Santos, Feras Al Kassar, Nataliia Bielova, and Stefano
Calzavara. 2020. On Compliance of Cookie Purposes with the Purpose Specifi-
cation Principle. In Proc. International Workshop on Privacy Engineering (IWPE).
https://hal.inria.fr/hal-02567022

[30] Imane Fouad, Cristiana Santos, Arnaud Legout, and Nataliia Bielova. 2022. My
Cookie is a phoenix: detection, measurement, and lawfulness of cookie respawn-
ing with browser fingerprinting. Proceedings on Privacy Enhancing Technologies
(PoPETs) 2022 (2022), 79–98. Issue 3. https://petsymposium.org/popets/2022/
popets-2022-0063.pdf.

[31] GDPR 2016. Regulation (EU) 2016/679 of the European Parliament and of the
Council of 27 April 2016 on the protection of natural persons with regard to
the processing of personal data and on the free movement of such data, and
repealing Directive 95/46/EC (General Data Protection Regulation) (Text with
EEA relevance). https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex:
32016R0679.

[32] Google. n.d.. About consent mode. https://support.google.com/google-ads/
answer/10548233?sjid=6259837766651858133-EU (Consulted on November 27th
2023)..

[33] Google. n.d.. Consent management platform integrations. https://support.google.
com/tagmanager/answer/10718549?hl=en#cmp-integrations (Consulted on June
29th 2023)..

[34] Google. n.d.. Create a Consent Mode template. https://developers.google.com/
tag-platform/tag-manager/templates/consent-apis (Consulted on October 27th
2023)..

[35] Google. n.d.. Custom template APIs. https://developers.google.com/tag-platform/
tag-manager/templates/api#isconsentgranted (Consulted on October 16th 2023)..
[36] Google. n.d.. Custom template permissions. https://developers.google.com/tag-
platform/tag-manager/templates/permissions (Consulted on October 31st 2023)..

[37] Google. n.d.. Google Tag Manager. https://tagmanager.google.com/#/home.
[38] Google. n.d..

Implement consent mode with server-side Tag Man-
https://developers.google.com/tag-platform/tag-manager/server-side/

ager.
consent-mode (Consulted on October 25th 2023)..

[14] Data Processing Agreement. n.d.. Data Processing Agreement. https://www.

[39] Google. n.d.. Manage consent settings (web). https://developers.google.com/tag-

hotjar.com/legal/support/dpa/ (Consulted on June 28th 2023)..

[15] Pixel de Tracking. 2020.

Google Tag Manager, the new anti-adblock
weapon. https://chromium.woolyss.com/f/HTML-Google-Tag-Manager-the-
new-anti-adblock-weapon.html (English translated version).

platform/security/guides/consent (Consulted on September 14th 2023)..

[40] Google. n.d.. Measurement Protocol Parameter Reference. https://developers.
google.com/analytics/devguides/collection/protocol/v1/parameters (Consulted
on October 16th 2023)..

13

Proceedings on Privacy Enhancing Technologies YYYY(X)

G. Mertens et al.

[41] Google. n.d..

Respect user consent choices with Google Tag Man-
ager. https://blog.google/products/ads-commerce/respect-user-consent-choices-
google-tag-manager/ (Consulted on June 16th 2023)..

[42] Google. n.d.. Sandboxed JavaScript. https://developers.google.com/tag-platform/
tag-manager/templates/sandboxed-javascript (Consulted on July the 7th 2023)..
https://support.google.com/

[43] Google. n.d.. Set up and install Tag Manager.

tagmanager/answer/6103696 (Consulted on July the 4th 2023)..

[44] Google. n.d.. Submit a template to the Community Template Gallery. https://
developers.google.com/tag-platform/tag-manager/templates/gallery (Consulted
on June 28th 2023)..

[45] Google. n.d.. Tag Manager > Server-side. https://developers.google.com/tag-

platform/tag-manager/server-side (Consulted on July 3rd 2023)..

[46] Google. n.d.. Tag platform overview.

https://developers.google.com/tag-

platform/devguides (Consulted on June 12th 2023)..

[47] Hotjar. n.d.. hotjar-protocol-documentation.

https://help.hotjar.com/hc/en-

us/articles/13052816995991 (Consulted on November 20th 2023)..

[48] Information Commissioner’s Office. 2018. Data controllers and data pro-
cessors: what
the governance implications
are. https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-
general-data-protection-regulation-gdpr/controllers-and-processors/.

the difference is and what

[49] John Wilander. 2019. Intelligent Tracking Prevention. https://webkit.org/blog/

7675/intelligent-tracking-prevention/ (Consulted on June 27th 2023)..

[50] Julius Fedorovicius. 2023.

Introduction to Google Tag Manager Server-side
Tagging. https://www.analyticsmania.com/post/introduction-to-google-tag-
manager-server-side-tagging/ (Consulted on 24 Feb 2023)..

[51] Julius Fedorovicius. n.d.. Analytics Mania – Google Tag Manager and Google
Analytics Blog. https://www.analyticsmania.com/ (Consulted on 24 Feb 2023)..
[52] Justin Schuh. 2020. Building a more private web: A path towards making third
https://blog.chromium.org/2020/01/building-more-

party cookies obsolete.
private-web-path-towards.html (Consulted on June 28th 2023)..

[53] Balachander Krishnamurthy and Craig E. Wills. 2009. Privacy diffusion on the
web: a longitudinal perspective. In Proceedings of the 18th International Conference
on World Wide Web, WWW 2009, Madrid, Spain, April 20-24, 2009, Juan Quemada,
Gonzalo León, Yoëlle S. Maarek, and Wolfgang Nejdl (Eds.). ACM, 541–550.
https://doi.org/10.1145/1526709.1526782

[54] Pierre Laperdrix, Nataliia Bielova, Benoit Baudry, and Gildas Avoine. 2020.
Browser Fingerprinting: A Survey. ACM Transactions on the Web (TWEB) 14, 2
(2020), 8:1–8:33. https://dl.acm.org/doi/10.1145/3386040.

[55] Adam Lerner, Anna Kornfeld Simpson, Tadayoshi Kohno, and Franziska Roesner.
2016. Internet Jones and the Raiders of the Lost Trackers: An Archaeological
Study of Web Tracking from 1996 to 2016. In 25th USENIX Security Symposium
(USENIX Security 16). USENIX Association.

[56] Timothy Libert. 2015. Exposing the Invisible Web: An Analysis of Third-Party
HTTP Requests on 1 Million Websites. International Journal of Communication 9,
0 (2015).

[57] Célestin Matte, Nataliia Bielova, and Cristiana Santos. 2020. Do Cookie Banners
Respect my Choice? Measuring Legal Compliance of Banners from IAB Europe’s
Transparency and Consent Framework. In IEEE Symposium on Security and
Privacy (IEEE S&P). https://hal.inria.fr/hal-03117294

[58] Mozilla Corporation. n.d.. Enhanced Tracking Protection in Firefox for desk-
https://support.mozilla.org/en-US/kb/enhanced-tracking-protection-

top.
firefox-desktop (Consulted on June 27th 2023)..

[59] mozilla.org contributors. n.d.. Content Security Policy. https://developer.mozilla.

org/en-US/docs/Web/HTTP/CSP (Consulted on November 29th 2023)..

[60] mozilla.org contributors. n.d.. Document Object Model. https://developer.mozilla.
org/en-US/docs/Web/API/Document_Object_Model (Consulted on November
29th 2023)..

[61] mozilla.org contributors. n.d.. Same-origin policy. https://developer.mozilla.org/

en-US/docs/Web/Security/Same-origin_policy.

[62] Nick Nikiforakis, Luca Invernizzi, Alexandros Kapravelos, Steven Van Acker,
Wouter Joosen, Christopher Kruegel, Frank Piessens, and Giovanni Vigna. 2012.
You are what you include: large-scale evaluation of remote javascript inclusions.
In Proceedings of the 2012 ACM conference on Computer and communications
security. ACM, Raleigh North Carolina USA, 736–747. https://doi.org/10.1145/
2382196.2382274

[63] Node.js. n.d.. Node.js v14.21.3 documentation. https://nodejs.org/docs/latest-
v14.x/api/cli.html#cli_tls_keylog_file (Consulted on September 14th 2023)..
[64] Pinterest. n.d.. Add event codes. https://help.pinterest.com/en/business/article/

add-event-codes (Consulted on November 20th 2023)..

[65] Pinterest. n.d.. Advertising Guidelines.

https://policy.pinterest.com/en-gb/

advertising-guidelines (Consulted on June 28th 2023)..

[66] PixeldeTracking-website n.d.. Pixel de tracking – Notes sur l’extension du do-
maine de la surveillance (personal website). https://www.pixeldetracking.com/
(Consulted on 22 Feb 2023)..

[67] Franziska Roesner, Tadayoshi Kohno, and David Wetherall. 2012. Detecting and
Defending Against Third-Party Tracking on the Web. In Proceedings of the 9th
USENIX Symposium on Networked Systems Design and Implementation, NSDI 2012.
155–168.

[68] Nikita Samarin, Shayna Kothari, Zaina Siyed, Oscar Bjorkman, Reena Yuan,
Primal Wijesekera, Noura Alomar, Jordan Fischer, Chris Hoofnagle, and Serge
Egelman. 2023. Lessons in VCR Repair: Compliance of Android App Developers
with the California Consumer Privacy Act (CCPA). Proceedings on Privacy Enhanc-
ing Technologies 2023, 3 (July 2023), 103–121. https://doi.org/10.56553/popets-
2023-0072

[69] Cristiana Santos, Nataliia Bielova, and Célestin Matte. 2020. Are cookie banners
indeed compliant with the law? Deciphering EU legal requirements on consent
and technical means to verify compliance of cookie banners. Technology and
Regulation (TechReg) (2020), 91–135. https://doi.org/10.26116/techreg.2020.009
[70] Cristiana Santos, Midas Nouwens, Michael Toth, Nataliia Bielova, and Vincent
Roca. 2021. Consent Management Platforms under the GDPR: processors and/or
controllers?. In Annual Privacy Forum (APF). https://hal.inria.fr/hal-03169436

[71] Asuman Senol, Gunes Acar, Mathias Humbert, and Frederik Zuiderveen Borge-
sius. 2022. Leaky Forms: A Study of Email and Password Exfiltration Before Form
Submission. Proceedings of the 31st USENIX Security Symposium (USENIX)
(2022).

[72] Simo Ahava. 2022. Agency, Transparency, And Control: Unsolved Problems
https://www.simoahava.com/analytics/agency-
With Server-side Tagging .
transparency-control-unsolved-problems-server-side-tagging/ (Consulted on 24
Feb 2023)..

[73] Simo Ahava. n.d.. Tags / Google Tag Manager. https://www.simoahava.com/

tags/google-tag-manager/ (Consulted on 22 Feb 2023)..

[74] supplementary-materials n.d.. Anonymous GitHub - Supplementary Mate-
https://anonymous.4open.science/r/Google-Tag-Manager-Hidden-

rials.
Data-Leaks-and-its-Potential-Violations-under-EU-Data-Protection-Law-
A8E4/README.md.

[75] Michael Toth, Nataliia Bielova, and Vincent Roca. 2022. On dark patterns and
manipulation of website publishers by CMPs. Proceedings on Privacy Enhancing
Technologies 2022, 3 (July 2022), 478–497. https://doi.org/10.56553/popets-2022-
0082

[76] Jonathan Weber. 2015. Practical Google Analytics and Google Tag Manager for

Developers (1st ed.). Apress, USA.

[77] Wireshark Foundation. n.d.. Wireshark. https://www.wireshark.org/.

A ACTORS
A.1 Publisher on the Client and Server-side
The Publisher uses GTM to include a dedicated service in their
website. When a Publisher chooses the Data Collector or its tag
as shown in step (1) of Figure 4, it needs to accept the Terms and
Conditions (T&Cs) related to this contractual service of the Data
Collector.

Determination of purposes. The selection of the Data Collector
has a determinant consequence on the qualification of the Pub-
lisher in the determination of purposes. Firstly, the Data Collector
establishes the purposes (Step (4b) in Figure 4) for processing data
because it explicitly mentions them (e.g. analytics, among others)
in the T&C or other policy documents. Since the Publisher agrees
to the purposes defined in the T&Cs by the Data Collector, these are
the purposes that the Publisher presents to the end-users. This pre-
sentation of purposes given to data subjects, and their reasonable
expectations on the basis of this visibility [4], reflects the determi-
nant power that Publishers have regarding purposes.

Determination of means. Because of the acceptance of the Data
Collector’s T&C, the Publisher agrees with the means of the process-
ing that were established by the Collector, such as how to process
the received data, what algorithms to use and what code to run on
the received data. Accordingly, the Publisher determines the means
for data processing.

Legal role: Publisher is a Controller.

14

Google Tag Manager: Hidden Data Leaks and its Potential Violations under EU Data Protection Law

Proceedings on Privacy Enhancing Technologies YYYY(X)

denied. In examples given by GTM in the documentation, consent
variables are used to represent purposes for data collection and
processing. For instance, a hypothetical “targeted_advertising”
consent variable could represent the consent or refusal of the end
user to let their data be used to display targeted ads. Tags can be
configured to have different behaviors (regarding data collection)
depending on the state of these variables.
Built-in consent is a feature that tags can implement. A tag sup-
ports this feature is able to adjust its behavior based on the state of
consent variables. For instance, when a end user only accepts that
their data to be used for analytics purposes but not for advertise-
ment purposes, a tag supporting built in consent and collecting data
for both purposes can limit its data collection to analytic purposes
only. Technically, a tag implementing built-in consent uses the GTM
provided isConsentGranted API to check the status (accepted or
declined) of each of the purposes.We provide an example of code of
a tag implementing built-in consent in Appendix Figure ??.
Manual consent configuration is the process by which the Pub-
lisher associate consent variables to the tags installed in the GTM
Web Container. A tag that is manually associated with one or more
consent variables will be prevented from running by the GTM Web
Container until all its associated variables are set to granted. For
instance, in this case, when a user only accepts that their data
to be used for analytics purposes but not for advertisement pur-
poses, a tag configured with manual consent for both analytics and
advertisement purposes will not run.

C SERVER SIDE TERMINOLOGY
A Server Tag is a component written in “sandboxed JavaScript” [42]
that runs exclusively on the server. It can process and send the data
that is received, by the GTM Server Container, to a third party server.
Server Tags can store first-party cookies in the user’s browser.
A Client adaptor is a plugin, embedded in the server container. It
decodes data arriving to the GTM server Container and converts
them into events.
An Event is something that happened (e.g., the user clicked on a
button) and it’s associated data (e.g., the button’s name, its position
on the page).
A Collector tag tag is a tag running in the browser that collects
data and send it through the network to a GTM Server Container.

A.2 Server Provider on Server-side
This actor provides to the Publisher the hardware for a given soft-
ware (e.g. the GTM Server Container) to run. Two types of Server
Providers exist: i) the “GTM-server service provider” which pre-
installs the GTM server software, and also manages the security of
the server; and ii) the “simple server provider” that provides only a
generic server, and allows any given Publisher to install the GTM
server software themselves. In this paper we only analysed point
ii), a “simple server provider”. The service provided (i.e. the hard-
ware for the server to run) is usually a service a Publisher needs
to pay for. The Publisher hires a given Server Provider to provide
the server and a contract is performed between the Publisher and
such Server Provider. The Publisher will use the server to install the
GTM Server Container software and consequently gives instruc-
tions the this Server on how to run it in order to process personal
data. Accordingly, there is a functional dependence of the Server
Provider on the Publisher’s instructions with renders this actor a
data processor.

Determination of purposes. By only providing the infrastructural
hardware service, the Server Provider does not determine purposes.

Determination of means. The Server Provider provides the means
for a Publisher to run the GTM Server Container software, such
as the hardware used and security of the system. These factual
activities regarding the practical implementation of the server con-
sist of “non-essential means”. Since the hardware provided by the
Server Provider runs the GTM Server Container software – which
processes personal data –the Server Provider is a data processor.

Legal role: Server Provider is a Data Processor
We did not find compliance issues of this actor.

B CLIENT SIDE TERMINOLOGY
A Tag is a JavaScript library usually developed by marketing com-
panies, analytics companies, independent developers or, less fre-
quently, publishers themselves. The role of a tag is to collect in-
formation about the user or its device and send the collected data
to a third-party service. In GTM specifically, a tag is a software
component written in “sandboxed JavaScript” which is a limited
version of JavaScript created by Google [42]. In GTM, Tags also pro-
vide functionalities (e.g., implement consent banners). GTM has a
permission system for tags [36] to let them access to functionalities
such as sending requests to third party servers or access cookies.
A GTM Web Container is a group of tags and their associated
configuration rules. Technically, a container is a JavaScript program
generated automatically by Google and downloaded by the user’s
browser as a file called gtm.js from the https://googletagmanager.com.
It embeds the tags selected by the publisher and their configuration
as well as an interpreter that executes the “sandboxed JavaScript”
code the tags are written in.
Container configuration is the process by which the Publisher
selects the tags and configures them.using the configuration web
interface, provided by Google at https://tagmanager.google.com.
Consent Variables store the consent of the end user in the GTM
Web Container. They can be in three states: undefined, granted or

15

Proceedings on Privacy Enhancing Technologies YYYY(X)

G. Mertens et al.

Figure 5: Summary of the legal role of the Publisher as a
Joint Controller with other actors of the GTM ecosystem. In
Figure 5 we summarise the legal roles of the Publisher in
relation to: i) the Collector (always join controllers), ii) CMPs
(joint controllers), iii) Tag Providers (when the Tag Provider
is the Data Collector).

Cookie detected Purpose

associated
is_eu Necessary
CookieConsent Necessary

_hjRecordingEnabled
_hjRecordingLastActivity
hjViewportId
hjActiveViewportIds
_hjCookieTest
_ga_#
_ga
_hjSessionUser_#
_hjFirstSeen
_hjIncludedInSessionSample_#
_hjSession_#
_hjAbsoluteSessionInProgress

Statistics
Statistics
Statistics
Statistics
Statistics
Statistics
Statistics
Statistics
Statistics
Statistics
Statistics
Statistics

ar_debug Marketing
_pinterest_ct_ua Marketing
v3/ Marketing
_pin_unauth Marketing

Tag creating the
cookie
Pinterest
Cookiebot
Hotjar
Hotjar
Hotjar
Hotjar
Hotjar
Google Analytics
Google Analytics
Hotjar
Hotjar
Hotjar
Hotjar
Hotjar
Pinterest
Pinterest
Pinterest
Pinterest

Table 7: Results of the Cookiebot scanner. We deduct which
tag that is responsible for the cookie creation by reading
the description of the cookie and the provider shown in the
report.

Consentmanager purpose
Measurement
N/A
N/A
N/A
N/A
Marketing
Function
Preferences
Other
Social Media

GTM consent variable

analytics_storage
ad_storage
security_storage
personalization_storage
functionality_storage
N/A
N/A
N/A
N/A
N/A

Table 8: Correspondence between Consentmanager purposes
and GTM purposes. Not all GTM purposes are used by Con-
sentmanager and some Consentmanager purposes are not
mapped to GTM consent mode purposes.

16

Joint C ontrollers 

GTM Service
Provider 

Joint Controllers 

Joint C

w

the D

hen Tag Provider is
ontrollers
ollector

ata C

Publisher

t

i

n
o
J

s
r
e

l
l

o
r
t
n
o
C

CMP

Tag Provider 

Collector

 
Google Tag Manager: Hidden Data Leaks and its Potential Violations under EU Data Protection Law

Proceedings on Privacy Enhancing Technologies YYYY(X)

Cookiebot Purpose Description

Necessary

Preferences

Statistics

Marketing

Necessary cookies help make a website usable by enabling basic functions like page navigation and access to
secure areas of the website. The website cannot function properly without these cookies.

Preference cookies enable a website to remember information that changes the way the website behaves or
looks, like your preferred language or the region that you are in.

Statistic cookies help website owners to understand how visitors interact with websites by collecting and
reporting information anonymously.

Marketing cookies are used to track visitors across websites. The intention is to display ads that are relevant
and engaging for the individual user and thereby more valuable for publishers and third party advertisers.

Table 9: Purposes defined by Cookiebot with their description

Figure 6: Confirmation window when installing a tag from
the Community template Gallery. Permissions (or capabili-
ties) of the tag are explicitely listed.

17

","Google Tag Manager : Hidden Data Leaks and its Potential Violations under EU Data Protection Law Nataliia Bielova Centre Inria d ’ Université Côte d ’ Azur Sophia Antipolis , France nataliia.bielova @ inria.fr Gilles Mertens Centre Inria de l ’ Université Grenoble-Alpes Grenoble , France gilles.mertens @ inria.fr Vincent Roca Centre Inria de l ’ Université Grenoble-Alpes Grenoble , France vincent.roca @ inria.fr 3 2 0 2 c e D 4 1 ] R C . s c [ 1 v 6 0 8 8 0 . 2 1 3 2 : v i X r a Cristiana Santos Utrecht University Utrecht , The Netherlands c.teixeirasantos @ uu.nl Michael Toth Centre Inria de l ’ Université Grenoble-Alpes Grenoble , France michael.toth @ inria.fr ABSTRACT Tag Management Systems were developed in order to support web- site publishers in installing multiple third-party JavaScript scripts ( Tags ) on their websites . In 2012 , Google developed its own TMS called “ Google Tag Manager ” ( GTM ) that is currently present on 28 million live websites . In 2020 , a new “ Server-side ” GTM was introduced , allowing publishers to include Tags directly on the server . However , neither version of GTM has yet been thoroughly evaluated by the academic research community . In this work , we study , for the first time , the two versions of the Google Tag Management ( GTM ) architectures : Client- and Server- side GTM . By analyzing these systems with 78 Client-side Tags , 8 Server-side Tags and two Consent Management Platforms ( CMPs ) from the inside , we discover multiple hidden data leaks , Tags bypass- ing GTM permission system to inject scripts , and consent enabled by default . With a legal expert , we perform an in-depth legal anal- ysis of GTM and its actors to identify potential legal violations and their liabilities . We provide recommendations and propose numerous improvements for GTM to facilitate legal compliance . KEYWORDS online tracking , server-side tracking , privacy , consent , GDPR com- pliance , website publishers , data controller , potential legal violation 1 INTRODUCTION Today ’ s modern websites continuously collect their visitors ’ data for various purposes , such as targeted advertising , and rely on third parties for such collection . Over the last decade , researchers have demonstrated that third-parties collect users ’ data with the help of third-party JavaScript scripts [ 62 ] . These scripts , invisible to the users , are silently executed in the webpage ’ s background and are often called “ tags ” by the web marketing industry [ 46 ] . Initially , to install a tag on the webpage , the website publisher only needed This work is licensed under the Creative Commons Attribu- tion 4.0 International License . To view a copy of this license visit https : or send a letter to Creative Commons , PO Box 1866 , Mountain View , CA 94042 , USA . Proceedings on Privacy Enhancing Technologies YYYY ( X ) , 1–17 © YYYY Copyright held by the owner/author ( s ) . https : //doi.org/XXXXXXX.XXXXXXX 1 to copy and paste an external JavaScript library reference to the webpage ’ s source code . However , as publishers were installing more and more tags1 , manual tag management became challenging and , as a result , “ Tag Management Systems ” ( TMS ) were developed by the industry . TMS allow publishers to install and configure tags in a centralized manner without tinkering with the website source code . Once installed on a website , TMS takes care of handling the installation , configuration and execution of third-party tags . In 2012 , Google developed its own TMS called “ Google Tag Manager ” ( GTM ) . It is currently the most installed TMS on the market , currently present on 28 million live websites according to BuiltWith [ 7 ] . GTM is a free service , offering a graphical inter- face and supporting a seamless inclusion of major marketing and analytic third-party scripts . GTM also benefits from a community of contributors , creating tags for services that are not officially supported by Google . Tags rely on the ability of browsers to com- municate directly with third-party domains to download scripts , set cookies and send users ’ data . Figure 1a shows the first GTM archi- tecture proposed by Google that we call “ Client-side GTM ” since it loads all the tags inside the user ’ s browser . In the recent years , this architecture became crippled by measures taken by browser ven- dors . Many popular Web browsers , such as Safari , Firefox and Brave , already actively block third-party tracking scripts and cookies to defend users against Web tracking [ 6 , 49 , 58 ] . Moreover , Google ’ s own plan of phasing out third-party cookies in Chrome [ 52 ] will render a lot of tags that rely on third-party cookies ineffective . As a result , an alternative version of Google Tag Manager was created in 2020 , officially called “ GTM Server Container ” [ 45 ] . This new architecture , shown in Figure 1b , loads and executes tags in a remote server , making it look like no third parties are present on the website . When the user ’ s data is collected with the GTM Web Container , there is only one data flow exiting the browser , and therefore , the final destination of data is impossible to trace for researchers and auditors that analyze outgoing browser requests . This architecture , called “ Server-side GTM ” , bypasses any browser restrictions and security measures , such as CSP [ 59 ] to control and secure third-party scripts and allows tags , that are now run on the server , to invisibly share users ’ data to other third parties . 1In 2016 , Engelhard and Narayanan [ 19 ] measured that on average , a website contains 18 third-parties . Proceedings on Privacy Enhancing Technologies YYYY ( X ) G. Mertens et al . the closest areas : online tracking detection and measurement , legal requirements on consent for online tracking , and non-academic literature , such as blog posts , regarding GTM . Online tracking measurement and prevalence of Google Mul- tiple works have detected and measured web tracking practices over the last decade , identifying Google ’ s massive prevalence in the tracking ecosystem . In 2009 , Krishnamurthy and Wills [ 53 ] conducted a longitudinal study of the collection and aggregation of personal data of end users by third parties – they highlight a small number of actors in the tracking ecosystem , and the rapid growth of Google , with requests to Google-owned servers being observed on 60 % of the domains . In 2015 , by analyzing third-party HTTP requests on the Alexa top 1 million sites , Libert [ 56 ] con- cluded that Google could track users on up to 80 % of sites . In 2016 , Englehardt and Narayanan [ 20 ] confirmed the extent of this track- ing by conducting an automated analysis of stateful and stateless techniques on 1 million sites , showing that Google owned the five most detected third-party domains . In 2020 , Fouad et al . [ 28 ] con- firmed again the prevalence of Google – they found the presence of tracking by Google domains on more than 85 % websites . Tag management and GTM No academic research appears to have studied tag management systems to date . However , several people close to AdTech circles share their experience and publish screenshots and other analyses of these tools on the web , either to help publishers in their deployment or to point out legal or techni- cal issues . The IT and digital marketing expert Julius Fedorovicius publishes courses and ebooks on GTM on his website Analytics Mania [ 51 ] . He has published a how-to on configuring server-side GTM [ 50 ] , summarizing the essential benefits and problems of the technology . The analytics developer Simo Ahava tests and com- ments on new functionalities in SEO and digital marketing tools . He maintains an extensive documentation on GTM [ 73 ] , and in a recent article [ 72 ] , discusses GTM ’ s limitations and problems regarding transparency and user control . The blogger Pixel de tracking [ 66 ] explores surveillance issues on the web . They have published sev- eral articles on Web Tracking Technologies , including GA4 and server-side GTM , focusing on the implications on the impact on content blockers [ 15 ] . A number of books have been published on the subject of GTM , attempting to guide website publishers in their use of the tool [ 8 , 76 ] . They cover registration , configuration , tagging and integration with popular CMS such as WordPress . Summary Most of the previous works either focus on Web Track- ing Technologies in general , or just describe the functionalities of GTM or server-side tag management . The recent content published by industry experts identify risks for privacy . However , no work so far seems to have evaluated if GTM can be leveraged to deploy offensive configurations at scale , nor seems to have assessed the complexity of consent management in GTM for publishers in the GDPR context . It is these gaps that our work aims to fill . 3 STUDY I : THE INTERNALS OF GTM In Study I , we experimented with both the Client- and Server-side GTM to identify their components and how they work in a typical GTM installation . Our goal was to evaluate what and how user data is collected and which actors access it . We examined GTM ’ s 2 ( a ) Client-side GTM ( b ) Server-side GTM Figure 1 : Google Tag Management ( GTM ) architecture . Red arrows represent the flows of users ’ data to third parties . In this work , we study two versions of the Google Tag Manage- ment ( GTM ) architectures – Client- and Server-side GTM – from inside . Differently from other approaches to measure Web track- ing [ 28 , 30 , 55 , 67 ] , we deploy the idea of Toth et al . [ 75 ] to analyze the system by installing it on an empty website that we fully con- trol . We then perform two separate studies : Study I that focuses on the internal functioning of GTM and Study II that analyzes legal implications of Study I . In Study I ( §3 ) , our first contribution con- sists in the methodology we built to analyze the internals of Client- and Server-side GTM , by installing 78 Tags one-by-one and two popular consent banner solutions . This allows us to capture script injections , hidden data flows , study GTM permission system and its integrated “ Consent Mode ” . We discovered 6 technical findings , in- cluding the fact that “ Google Tag ” aims at ensuring communication between Client- and Server-side , collects multiple types of users ’ data without their consent ; “ Pinterest Tag ” collects a significant amount of users ’ data without disclosing it to the Publisher ; 11 out of 78 official Client-side tags inject a third-party script into the DOM [ 60 ] bypassing the GTM permission system ; and GTM “ Consent Mode ” enables some of the consent purposes by default , even before the user has interacted with the consent banner . Study II in §4 is written together with a legal expert and co- author of this paper . Therein we explain the EU Data Protection legal background relevant to the GTM ecosystem . We then provide an in-depth legal analysis where we identify the legal role of each actor , detect 8 potential violations of the General Data Protection Regulation ( GDPR ) [ 31 ] and ePrivacy Directive [ 21 ] , and thereby we identify each actor ’ s liability . Finally , we make recommendations to further improve GTM to facilitate legal compliance across all in- volved actors . Finally , we discuss other potential legal implications of this GTM ecosystem ( §5 ) and conclude the paper . 2 RELATED WORKS GTM has become a popular tool for managing tags on websites in recent years . However , to the best of our knowledge , no scientific study has analyzed tag managers or the GTM Framework in partic- ular , neither its client- nor its server-side tagging version from a privacy viewpoint . In this section we present the related works in a.com b.com c.com Browser GTM web container tag a tag b tag c personnal data a.com b.com c.com Cloud GTM server container tag a tag b tag c Browser GTM web container personnal data Google Tag Manager : Hidden Data Leaks and its Potential Violations under EU Data Protection Law Proceedings on Privacy Enhancing Technologies YYYY ( X ) “ Consent Mode ” , a toolset to render GTM compliant , in order to assess its effectiveness in managing consent . 3.1 Methodology To conduct experiments and set up the GTM infrastructure , we bought a domain – we call it example.com here – and created a public website containing one basic webpage with a paragraph of text and an HTML login form . We have included a login form since Senol et al . [ 71 ] have recently found that user input is often leaked from the forms , so we decided to test whether Tags may be responsible for such leakage . The website and the Server-side GTM infrastructure were hosted on a virtual machine we rented on the Microsoft Azure cloud computing platform located in a data center in the EU . We conducted this study between September and November 2023 on the Chromium browser [ 9 ] in version 111 , from the Flathub repository [ 10 ] , using the default settings and installed on a GNU/Linux operating system ( kernel version 6.1.x- lts ) . We used the “ profiles ” functionality of the browser to start every experiment in a fresh environment , devoid from cookies , local storage and other technologies than maintain a state . The browser , visiting the website , was run on a computer connected to the Internet through an institutional network in the EU . To create Client- and Server-side GTM installations , we created a new Google account , logged into it and followed the suggested steps in the official GTM documentation [ 43 ] . We explain the installation process in detail below . Note that the terms we use can slightly differ from that of the official GTM documentation for clarity reasons . 3.1.1 Client-side GTM . Selecting Tags . GTM supports 78 official Tags that are directly accessible through its interface to the website publisher . Nevertheless , a community of developers created Tags for services that are not officially supported by Google , and such tags are available through the GTM-integrated template gallery [ 44 ] . To understand what type of user ’ s personal data Tags can collect , and to monitor how it flows through the Client-side GTM installation , we decided to select and test 3 Tags . To select Tags , we decided to pick representative Tags of three typical functionalities of third parties : analytics/statistics , advertisement effectiveness , and assessment of user interaction . Our selection procedure focuses on the list of official Tags and was informed by the popularity of the company that receives the data collected by the Tag ( we call such company Data Collector , see §4.2.3 ) . For the popularity criteria , we followed the ranking of popularity of third parties according to Binns et al . [ 5 ] , who measured the inclusion of third parties on 100k websites . The three selected Tags are shown in Table 1a2 . For the selected Tags to function properly , we registered on the Data Collector ’ s website and configured the Tag according to its instructions . Installing GTM on our Website . When the publisher has chosen and configured Tags to be included on its website , GTM generates a “ Web Container ” in the form of an external JavaScript library called gtm.js [ 37 ] , which contains all the selected tags . We did it and copy-pasted the small script provided by GTM in our website source page , which prompts the browser to fetch the gtm.js script . Capturing Script injection , Data Flows and Availability of Collected Data . We manually installed all the officially available 2For clarity , we will refer to the “ Hotjar Tracking Code ” tag as the “ Hotjar Tag ” . 3 tags individually in our Web Container , opened our website in a new browser profile and analyzed the traffic using the Chromium debug tools . For each tag we identified whether additional scripts were downloaded and for the 3 tags selected in Table 1a , we inspected the GET parameters , POST bodies and data exchanged through the WebSocket protocol of outgoing requests to identify the data collected . In order to identify personal data collected , we investigate firstly by using an empirical method : by looking at the key/value pairs , in GET parameters or JSON data , in search for obvious key names like screen_resolution or obvious key/value pairs such as sr=1920x1080 for a FullHD screen ; and secondly by using the available documentation for each Tag [ 40 , 47 , 64 ] . Finally , we logged on the Data Collector ’ s website , searched for the personal data previously identified and compared it with data identified in the outgoing requests . For the Google Tag , in Google Analytics , we visited the “ Report ” page ; for Pinterest , in the “ Conversion ” section , we clicked on the “ Event history ” page ; for Hotjar we went to the “ Recordings ” page to see the individual recorded user interactions . Figure 2a summarizes our analysis method . Tag Permission System . For non-official tags , GTM shows the permissions of the tag in a popup , to review them before confirming the installation . By analyzing the network communications with our browser while being in the Web Container configuration in- terface , in the template gallery section , we found a JSON file that contains the tag information displayed in the interface . This file contains information such as the tag ’ s author , a description of the tag , the link to the source code of the tag and the list of permis- sions . The names of permissions and configurations ( e.g. , for the set_cookies permission , the configuration would be the cookie name ) corresponds to the official documentation [ 36 ] . For official tags however , the GTM configuration interface does not show any permission and no official documentation mentions any permission system either . However , by analyzing network com- munications while browsing the official tags section , we found a similar JSON file containing the list of permissions in the same format . From this file we extracted the list of tags having the in- ject_script permission to compare it with the actual behavior of the tags regarding script injection . We conclude that official tags have a permission system similar to the non-official tags . Consent Configuration . Next , assisted by a legal scholar coauthor of this paper , we integrated consent management on our website in such a way that it is compliant with the EU legal framework . We used the GTM “ Consent Mode ” feature , added in 2020 in Web Containers , and still marked as a beta feature in the GTM config- uration interface during the writing of this paper . This consent system is based on “ consent variables ” , and GTM proposes : ad_- storage , analytics_storage , functionality_storage , per- sonalization_storage and security_storage ( Table 3 ) . They take two values , “ granted ” or “ denied ” , according to the documen- tation . We found that variables can also be in “ undefined ” state , with serious consequences ( see Technical finding 4 ) . In this sys- tem , the Consent Management Platforms ( CMPs ) , which provides consent banners [ 57 ] , are integrated in the Web Container as Tags . CMPs communicate the user ’ s consent choices made in the consent banner , expressed through these consent variables , to the Web Con- tainer [ 34 ] . Then , in the GTM interface , we , as Publisher , need to Proceedings on Privacy Enhancing Technologies YYYY ( X ) G. Mertens et al . Tag name ( ranking [ 5 ] ) Google Tag ( 1 ) Data Collector Google Pinterest Tag ( 66 ) Pinterest Hotjar Tracking Code ( 105 ) Hotjar Goals of the service/tag provide statistics on users and their behavior on websites measure advertisement cam- paigns effectiveness ; become a Pinterest Verified merchant provide videos of user interac- tions with websites to detect bugs and improve the website Tag name ( ranking [ 5 ] ) Google Analytics : GA4 ( 1 ) Conversions API Tag ( 3 ) Data Collector Google Goals of the service/tag provide statistics on users and their behavior on websites Facebook measure advertisement cam- paigns effectiveness ; provide statistics about website usage Mixpanel ( 32 ) Mixpanel gather data on user interac- tions with the website to gain insights into their behavior ( a ) Client-side GTM tags . ( b ) Server-side GTM tags . Table 1 : Tags selected for further study in Client- and Server-side GTM . ( a ) Client-side GTM . ( b ) Server-side GTM . Figure 2 : Pipelines of the analysis of collected data and tag behavior on Client- and Server-side GTM . associate none , one or more consent variables to each Tag . Accord- ing to documentation [ 39 ] , before executing a Tag , GTM checks the associated consent variables and proceeds only if all the con- sent variables are “ granted ” ; otherwise GTM prevents the tag from running . Some tags support a feature called “ built-in consent ” [ 35 ] which allows them , when being executed , to check the values of the consent variables by themselves and adapt their behavior depend- ing on users ’ choices . If trusted , the Publisher does not associate any consent variable with such tags that are always executed . We tested the two CMPs marked as compatible with Consent Mode and put forward in the GTM interface , namely Consentmanager [ 11 ] and Cookiebot [ 13 ] . They both include a scanner to detect cookies and/or tracking technologies and classify the trackers and associated pur- poses ( we further analyze scanners in section 4.2.1 ) . For each CMP , we created an account on their website , let the CMP scanner scan our website , and installed the CMP tag in the GTM configuration interface . For Consentmanager , according to the documentation , we enabled “ Send Google Consent Mode ” in the settings of the CMP ’ s website . We then used the results of the CMP scanner to configure the consent settings of each tag . To study the behavior of the Web Container , the CMP and the Tags , we visited our website several times , using a new browser profile and a different consent option in the consent banner each time : “ accept all ” , “ decline all ” , “ only analytics ” and “ only advertisement ” . After making our choice , we stayed on the page for 20 seconds , reloaded it and used it for another 20 seconds . We used both the debugger provided by GTM to know when tags run , and the browser ’ s debugger to capture outgoing traffic ( figure 2a ) . Finally , we compared collected data in each case with data collected without consent configuration . Server-Side GTM . Selecting tags . Similarly to Client-side 3.1.2 GTM , we selected three tags with the same representative func- tionalities of third parties : analytics/statistics , advertisement effec- tiveness , and assessment of user interaction . Here , GTM officially supports only eight tags , all related to Google services , from which we selected Google Analytics . Then , from the template gallery where developers propose additional , non-officially supported tags , and for the remaining two functionalities we are interested in , we chose the most popular ones , based on the ranking of the Data Collector as in Binns et al . [ 5 ] , namely Facebook Conversion API and Mixpanel ( Table 1b ) . We also observed that in the template gallery , the company that provides the tag ( we call it Tag Provider , see §4.2.4 ) and the Data Collector are not necessarily the same . GTM Server Container Installation . In the GTM interface for Publishers , we created a “ GTM Server Container ” , which is a Node.js program running on a server , that contains in particular the selected “ Server Tags ” . Two options are proposed : “ Automatic provisioning ” , 4 https : //example.com GTM Web Container ( gtm.js ) user data Google Tag user data Pinterest Tag user data Hotjar Tag consent variables click `` accept all '' click `` deny all '' Chrome debugger example.com googletagmanager.com Data Collectors Google Analytics User statistics Pinterest Number of clicks Hotjar Recorded user sessions https : //example.com Chrome debugger example.com GTM Web Container ( gtm.js ) user data Google Tag ( Collector Tag ) consent variables consent GTM Server Container ( server.js ) GTM : Web Container ( Client Adaptor ) GA4 ( Client Adaptor ) Server Instrum- entation Google Analytics Facebook Conversion API Mixpanel googletag manager.com Data Collectors Google Analytics User data Facebook pixel User data Mixpanel User data Google Tag Manager : Hidden Data Leaks and its Potential Violations under EU Data Protection Law Proceedings on Privacy Enhancing Technologies YYYY ( X ) that automatically installs the Server Container on a Google Server , and “ Manual installation ” , for which the Publisher provides the server . We chose the manual installation to have total control over the server and be able to analyze the Server Container incoming and outgoing information flows . We used the provided Docker image and configured the Server Container to be accessible us- ing HTTPS . Finally , we created A and AAAA DNS records for the gtm.example.com subdomain pointing to our server and avoided using CNAME records as recommended . We provide the configuration files of our setup in the artifacts ( §3.1.3 ) . Connection Between the browser and the Server Container . To connect the browser and the Server Container to collect the end- user data , we first created a new GTM Web Container ( figure 2b ) . Following the GTM documentation , we installed the “ Google Tag ” in the Web Container , specifying the https : //gtm.example.com URL of our Server Container in the transport_url field , in the tag configuration . It instructs the Google Tag to send collected data to our Server Container , instead of the Google Analytics servers , which is the default behavior of this tag . This “ Google Tag ” is what we call a “ Collector Tag ” . In the GTM Server Container , a component that we call “ Client Adaptor ” , receives data , decodes it and makes it available to server tags . This Client Adaptor needs to be compatible with the Collector Tag and for this , we used the default “ GA4 Client ” ( or simply , GA4 ) , preinstalled on the Server Container and compatible with our Collector Tag . Capturing traffic in the Browser . We visited our website in a new browser profile and used the Chromium debug tools to capture traf- fic between the Collector Tag and the Client Adaptor . We analyzed the outgoing traffic similarly to the Client-side study ( §3.1.1 ) . Capturing Data Flows and Availability of Collected Data . To analyze the outgoing traffic of the Server Container , we instru- mented our server to capture network exchanges and decrypted them by starting the Node.js interpreter , which runs the Server Container , with the -- tls-keylog option [ 63 ] . This option in- structs Node.js to export encryption keys . We used Wireshark [ 77 ] to collect traffic and imported the encryption keys previously ex- ported to decrypt it . Similarly to the Client-side experiments , we identified data sent by Server Tags to Data Collectors using our server instrumentation . We finally compared our observations with the data items visible on the websites that received the user ’ s data . Consent Management . To assess the ease of making the Server- side GTM architecture GDPR-compliant , we searched for official documentation on this matter and only found a relatively basic page [ 38 ] . In order to have concrete results , we added a CMP to the Web Container . We chose Cookiebot because it is compatible with Consent Mode in Client-side GTM ( Server-side is not mentioned ) and because it maps well to the consent variables ( see Table 4 ) . We then observed the behavior of the server tags according to the end-user consent , using the same traffic analysis methods as before . Figure 3 : Client-side GTM : The Hotjar tag downloads an ar- bitrary script and injects it in the page . 3.2 Results In this section , we present our findings for the Client- and Server- side GTM , selected Tags , and of Google Consent Mode . Technical finding 1 . Hidden data leaks by the Tags on the Client- and Server-side GTM . By analyzing data sent by the Tags and comparing with data visible to the Publisher in the Data Col- lector ’ s website , we found that certain Data Collectors do not show what data they collect . Table 2a shows the data sent by the three Tags that we tested in Client-side GTM without any installation of consent solutions . We observe that the data sent by the Pinterest Tag is not visible to the Publisher on the Pinterest website , where we logged in to observe Pinterest ’ s disclosure about collected data . Moreover , we find that the data collected by the Google Tag about form interaction is not shown in the Google Analytics dashboard . This finding demonstrates that for such Tags , Publishers are not aware of the data collected by the Tags that they select . For Server-side GTM , Table 2b shows the data sent by the three selected Tags . Similarly , some collected data is not visible to the Publisher on the Data Collector ’ s website . The Google Analytics Tag collects data about interaction with forms and the truncated IP address of the end user . None of this is shown to the Publisher through the Google Analytics report pages . Mixpanel receives the complete IP address of the end user and URL of visited webpage , but does not show it to the Publisher . We found out that with Server-side GTM , the end-user IP address collection is necessarily deliberate : it requires the Client Adaptor to copy the IP address from the browser ’ s packets to data shared with all the server Tags , which is what the GA4 Client Adaptor does . In case of Mixpanel and Facebook Conversion API , moreover , the Tags send the IP address received from GA4 to Mixpanel and Facebook . Finally , Facebook did not allow us to review the collected data since when we created a new account , it was flagged as suspicious and we were blocked from accessing the data collection dashboard . Therefore , in both Client- and Server-side GTM , these hidden data leaks raise transparency concerns since Publishers are not aware of the data collection implications when they select a particular Tag . We further analyze its legal implications in Section 4 . 3.1.3 Artifacts and Responsible Disclosures . Artifacts associated to this work are available in an anonymous repository [ 74 ] . Addition- ally , two responsible disclosures are in progress , one with Google and another one with the Consentmanager CMP . An update will be added to this article in case of feedback from the companies . Technical finding 2 . 56 Client-side Tags insert scripts that have full access to the browser APIs and page DOM . In Web Containers , tags run in a sandbox which restricts them to a lim- ited set of the JavaScript functionalities [ 42 ] . This sandbox imple- ments the GTM permission system that controls tags ’ access to browser features , such as setting cookies or collecting other data 5 browser visiting example.com GTM web container ( gtm.js ) Hotjar user data script googletagmanager.com hotjar.com Proceedings on Privacy Enhancing Technologies YYYY ( X ) Data Google Tag Pinterest Hotjar ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ URL of current page browser and version screen dimensions computer architecture operating system OS version engagement time preferred language title of current page number of visits forms interacted with scrolling actions browser windows size clicks with position typing in a form submitting a form precise mouse moves ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ( a ) Client-side experiments . Facebook Conversion API ✓ * ✓ * ✓ * G. Mertens et al . Mixpanel ✓ ✓ ✓ ✓ ✓ Data Google IP address of the user URL of current page browser and version screen dimensions computer architecture operating system OS version engagement time preferred language title of current page number of visits forms interacted with Ana- lytics ✓ ( trun- cated ) ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ( b ) Server-side experiments . Note that the Google Analytics tag trun- cates the last byte of the IP address claiming to anonymize it . Table 2 : Data collected by the Tags . ✓indicates the data type that is collected by the Data Collector and made visible to the Publisher via the Data Collector ’ s website . ✓indicates data type that is collected but not visible , and ✓ * indicates it is sent to a blocked account . with browser APIs . One of such permission is called “ inject_- script ” which allows a tag to download and execute an arbitrary script outside of the Web Container . When a tag is granted the inject_script permission , it can inject such arbitrary script , thus bypassing the GTM permission system that controls access to fea- tures , accessing to the all the browser APIs and DOM within the same origin , according to the Same-Origin Policy [ 61 ] . By analyzing 78 officially supported Client-side Tags ( §3.1.1 ) , we found that 56 tags inject such scripts . Figure 3 illustrates how Hotjar Tag injects its own script in the example.com page . Within the GTM permis- sion system , the Hotjar Tag has the permission to read and write in two global JavaScript variables ( hj and hj.q ) and to inject a script . We find out that it collects all the data shown in Table 2a , including data that could not be accessed from the sandbox , such as precise mouse movements . Surprisingly , we found that 5 Tags owned by Google itself3 bypass its own GTM permission system and inject scripts in the same way as Hotjar Tag4 . Technical finding 3 . GTM permission system allows injection of arbitrary scripts . By analyzing the presence of inject_script permission for all 78 Client-side Tags , we have detected 11 Tags that do not have this permission , but still inject arbitrary scripts . Out of these 11 Tags , 7 Tags are provided by Google5 . This finding shows that the GTM permission system implemented in the Web Container sandbox allows Tags to insert arbitrary , uncontrolled scripts , thus opening potential security and privacy vulnerabilities 3 “ Google Ads ” , “ Google Analytics ” , “ Google Surveys ” , “ Google Tag ” , “ G . Trusted Stores ” 4The full list of scripts is available in Supplemental Materials [ 74 ] . 5Google owned Tags : “ google tag ” , “ google ads calls from website conversion ” , “ google ads conversion tracking ” , “ google ads remarketing ” , “ google analytics : classic ” , “ google analytics : ga4 event ” , “ g . analytics : universal analytics ” . Other Tags : “ eulerian analytics ” , “ lytics js tag ” , “ tradedoubler lead conversion ” , “ tradedoubler sale conversion ” . 6 to the website . We have disclosed this finding to Google via their Bug Bounty online system ( §3.1.3 ) . Technical finding 4 . “ He who says nothing agrees ” : unde- fined consent variables are granted by default . In our experi- ments on consent mode and CMPs for Client-side GTM ( see §3.1.1 ) , we found that consent variables are in an undefined state when the CMP is loaded in the webpage . Though CMPs are expected to set default values to all such variables , we found out that some CMPs do not explicitly do that . Surprisingly , in this case , GTM considers all such undefined variables to be accepted by the end user , even though the end user has not interacted with the consent banner of the CMP yet . Among two CMPs tested ( see §3.1.1 ) , we detected this behavior for the Consentmanager CMP . This CMP sets a default value to only two consent variables – analytics_storage and ad_storage – leaving three GTM consent variables – security_- storage , personalization_storage functionality_storage – and consent variables specific to this CMP – e.g. , cmp_purpose_c56 which corresponds to the “ Social Media ” purpose – in undefined state . These extra variables are hence considered granted by GTM . As a result , all the Tags that depend on these four consent variables get executed even without user consent . We note that this default behavior of undefined variables can not be changed and discuss its legal implications in the Potential violation 5 in Study II . Technical finding 5 . Data collected by the Google Tag without consent . With built-in consent , tags always get executed and since they are aware of the consent choices of the user , they should adapt their behavior , and not collect any data related to purposes refused by the end user . When we tested the Google Tag , which has built-in consent with various consent decisions ( accept all , decline all , only analytics , only advertisement ) , we found out that this Tag always Google Tag Manager : Hidden Data Leaks and its Potential Violations under EU Data Protection Law Proceedings on Privacy Enhancing Technologies YYYY ( X ) sends the user ’ s data shown in Table 2a , independently of the user ’ s consent choice . We found in the GTM documentation that when the ad_storage or analytics_storage built-in consent variables are refused , the data collected by Google is “ ... never used to track individual users across apps or websites , build remarketing lists , or generate user profiles ” [ 32 ] . Technical finding 6 . Lack of consent tools in Server-side GTM . Contrary to Web Containers , the Server Container configu- ration interface does not provide consent configuration tools such as the association of consent variables to tags . We however found that the values of two consent variables , ad_storage and analyt- ics_storage , are sent to our server container and provided to the Server Tags . The documentation on consent in Server Containers tells that “ Google product tags in the server are consent-aware and adjust the amount and kind of data they send based on the user ’ s preferences. ” As such , we deduce the server tags can implement a similar mechanism to built-in consent . However the Publisher can- not see on which consent variable the tag will change its behavior . Finally , for the three tags tested , we found that declining consent did not impact the transmission of data items identified in Table 2b . 4 STUDY II : LEGAL ANALYSIS OF GTM In this section , written together with a legal expert and co-author , we first explain the legal background on EU Data Protection law relevant to the GTM ecosystem . We then provide a legal analysis by identifying the legal role of each actor as it is crucial for further evaluation of each actor ’ s compliance and liability [ 31 , Recital 79 ] . 4.1 Legal Background The General Data Protection Regulation ( GDPR ) [ 31 ] applies to the processing of personal data [ 26 ] and imposes obligations on those actors who processes it paired with heavy fines for non-compliance . The ePrivacy Directive ( ePD ) [ 21 ] provides supplementary rules to the GDPR in particular for the use of tracking technologies . When- ever cookies and other tracking technologies are stored and read from the user ’ s device , the ePD [ 21 , Art.5 ( 3 ) ] requires organiza- tions to request consent for the storage of such trackers for certain purposes for processing data , such as advertising [ 17 , 18 ] . Some pur- poses are exempted of consent , e.g , functional or technical purposes required for a website requested by a user to operate [ 21 , Recital 66 ] . The only way to assess with certainty whether consent is required is to analyze the purpose of each tracker on a given website [ 16 , 29 ] . 4.1.1 Personal data . It is “ any information relating to an identified or identifiable natural person ( ’ data subject ’ ) . An identifiable nat- ural person is one who can be identified , directly or indirectly [ 31 , Art.4 ( 11 ) ] . In order to determine whether a person is identifiable , account should be taken of all the means likely reasonably to be used by any actor to identify that person . Accordingly , if certain data , alone , is not personal data , it becomes personal data as regards to someone who reasonably has the means of enabling that data to be associated with a specific person [ 2 , para . 46 ] . GDPR Recital 30 asserts that online identifiers provided by their devices , such as IP addresses , can be associated to a person , thus making them identi- fiable . This identification does not require that all the information enabling that person to be identified should be in the hands of a 7 single entity [ 1 , para . 42 , 43 ] . Processing of personal data consists of ‘ any operation ( s ) performed on personal data , such as collecting , sharing , using , making available , accessing , combining [ 31 , Article 4 ( 2 ) ] . In practice , this means that almost any imaginable handling of personal data constitutes processing [ 4 , 25 ] . 4.1.2 Data Controller and Data Processor . According to European Data Protection Board ( EDPB ) opinion [ 4 ] , to determine whether an actor is a Data Controller , its factual roles and activities have to be evaluated in a specific situation . An actor is a Data Controller if it is responsible for determining the purposes , and the means of the processing of personal data [ 31 , Art . 4 ( 7 ) ] . “ Determines ” means having the “ decision-making power ” [ 4 , 23 , 27 ] or “ independent control ” [ 48 ] over the purposes and means of the processing [ 27 ] . The Court of Justice of the EU ( CJEU ) , Data Protection Authorities ( DPAs ) and the EDPB describe that such control can be derived from : professional competence ( legal or im- plicit ) [ 4 ] ; factual influence , based on the real circumstances sur- rounding the processing ; image given to data subjects and their reasonable expectations on the basis of this visibility [ 4 ] ; which ac- tor “ organizes , coordinates and encourages ” data processing [ 23 , para 70-71 ] ; and interpretation or independent judgement exercised to per- form a professional service [ 48 ] . “ Purposes ” refers to “ why ” data is processed . Purposes need to be explicit , specified and legitimate [ 31 , Art . 5 ( 1 ) ( b ) ] . “ Means ” refers to the how the objectives of process- ing are achieved . The EDPB distinguishes between “ essential ” and “ non-essential means ” and provides examples thereof [ 4 , 27 ] : Es- sential means are closely linked to the purpose and the scope of the processing and are inherently reserved to the controller . Ex- amples of essential means are : determining the type of personal data processed ; duration of processing , recipients of personal data , or categories of data subjects . Non-essential means may be dele- gated to the Data Processor , involving practical implementations , like hardware or software selection , security measures , or data storage/retrieval methods . An actor is a Data Processor when it processes personal data on behalf of the data controller [ 31 , Art . 4 ( 8 ) ] . An actor is a processor when : i ) it is dependent on the controller ’ s instructions regard- ing processing activities [ 4 ] [ 27 ] , ( Art . 28 ( 3 ) ( a ) ) , Recital 81 ) ; and ii ) complies with those instructions [ 27 ] . Joint Controllership . Where two or more controllers jointly 4.1.3 determine the purposes and means of processing , they shall be joint controllers [ 31 , Art . 26 ( 1 ) ] . Joint participation can take the form of common or converging decisions on purposes and essen- tial means [ 27 ] . Decisions can be considered as converging if they complement each other and are necessary for the processing to take place in such manner that they have a tangible impact on the determination of the purposes and means of the processing . An important criterion to identify converging decisions is whether the processing would not be possible without both parties ’ participation in the sense that the processing by each party is inseparable , i.e. , inextricably linked [ 27 ] . Joint controllership requires an agreement pursuant to GDPR Article 26 . However , there is no requirement for both parties to share responsibility equally [ 24 , para 43 ] . Similarly to Data Controllers , each of the both parties do not need to have access to personal data to be considered a controller [ 24 , para 38 ] . Proceedings on Privacy Enhancing Technologies YYYY ( X ) G. Mertens et al . 4.1.4 GDPR obligations for Data controllers and Data processors . If an actor is established as a data processor , it can be held liable and fined if it fails to comply with its obligations under the GDPR [ 31 , Art . 28 ( 3 ) ( f ) , 32-36 ] . Compliance with the GDPR is enforced by the EU Data Protection Authorities ( DPAs ) , which monitor and super- vise the application of the GDPR [ 31 , Art.55-57 ] . Data controllers must comply with the following principles : • Purpose limitation : collect personal data for specific , detailed and explicit purposes and not further processed for incom- patible purposes [ 31 , ( Art . 5 ( 1 ) ( b ) ] ; • Minimization : collect personal data that is adequate , relevant and limited to what is necessary in relation to the purposes for which data are processed [ 31 , ( Art . 5 ( 1 ) ( c ) ] ; • Lawfulness : collect personal data only when it is legitimized with one legal basis [ 31 , Art . 5 ( 1 ) ( a ) ] . In case this legal basis is consent , the consent must be prior to any data collec- tion , freely given , specific , informed , unambiguous , readable , accessible , and revocable [ 31 , Art.4 ( 11 ) , Art . 7 ] [ 69 ] ; • Transparency : collect personal data when it informs the end user about the purposes , third party recipients , legal basis , among other information [ 31 , Art . 5 ( 1 ) ( a ) , 13 , 14 ] . • Security : ensure appropriate security of the personal data including protection against unauthorized or unlawful pro- cessing [ 31 , Art . 5 ( 1 ) ( f ) , 32 ] . • Data Protection by Default : ensure that personal data is pro- cessed with the highest privacy protection so that by default personal data isn ’ t made accessible to an indefinite number of persons [ 31 , Art . 25 ( 1 ) ( 2 ) ] . • Accountability [ 31 , Art.5 ( 2 ) ] : the controller must be able to demonstrate compliance to each principle at any time ; 4.2 Legal Analysis of Client-Side GTM In this section we analyze the roles of the actors involved in client- side GTM : GTM Provider , CMPs , Data Collectors and Tag Providers since they raise potential violations to the GDPR and ePrivacy directive . We start our legal analysis by identifying whether these GTM actors process personal data . According to our results , both GTM Provider and Data Collector process the IP address of the end user because they receive incoming HTTP requests on their servers . Following the arguments of Santos et al . [ 70 ] , if an IP address is combined with additional user data , then the IP address receiver has the means and information reasonably likely to indirectly render a user identifiable [ 31 , Recital 26 ] . Since the Publisher ’ s role does not trigger potential violations , we refer to its role in the Appendix 6 . Figure 4 depicts the GTM actors and their relationships . 4.2.1 Consent Management Platforms ( CMPs ) . The website Pub- lisher selects a CMP to manage end-user ’ s consent ( see step ( 3 ) in Figure 4 ) . To integrate the consent banner with GTM , the CMP needs to be compatible with the Google Consent Mode . The two CMPs tested during this study – Consentmanager and Cookiebot – offer a scanning service that automatically detects the cookies on the Publisher ’ s website and third parties with whom these cookies are shared [ 70 , Fig.3 ] . The scanner then classifies the third parties and associates purposes . 8 Consent variable ad_storage analytics_storage functionality_- storage personalization_- storage security_storage Description provided by GTM Enables storage ( such as cookies ) re- lated to advertising Enables storage ( such as cookies ) re- lated to analytics e.g . visit duration Enables storage that supports the func- tionality of the website or app e.g . lan- guage settings Enables storage related to personaliza- tion e.g . video recommendations Enables storage related to security such as authentication functionality , fraud prevention , and other user protection Table 3 : GTM consent variables and their descriptions . Determination of Purposes . Through this scanning activity , the CMP extracts the purposes of the trackers from the Publisher ’ s web- site as shown in step ( 4a ) of Figure 4 . From reading the provided scanning report , the Publisher configures those purposes for each tag in the GTM interface as shown in step ( 5a ) of Figure 4 . As such , the Publisher determines the purposes for processing together with the CMP ’ s help . Notably , CMPs are argued to be recognized as Data Controllers , following the arguments of Santos et al . [ 70 , Section 4.3 ] . We posit that the final decision on the needed purposes for the Tag in question is a converging decision between Publishers and cho- sen CMPs ( see §4.1.3 ) , where both decisions to hire the CMP by the Publisher , and to identify the purposes by the CMP complement each other and are necessary for the processing to take place . Therefore , this decision ( joint decision by the Publisher and the CMP ) has a tangible impact on the determination of purposes of processing . Determination of means . When CMPs provide their services and tooling ( besides consent management ) , such as scanning , such CMPs define the means for processing . Legal role : Publisher and CMP are Joint Data Controllers . Potential violation 1 . CMP scanners often miss purposes . During our experimentation on Client-side GTM ( see §3.1.1 ) , we installed the Google Tag that contains two specific built-in purposes – ad_storage and analytics_storage . We found out that when Cookiebot and Consentmanager scanners run , they report only analytics purposes and miss the advertising purpose of this tag . Publishers that rely on these scanners without further reading Data Collector ’ s Terms & Conditions face the risk to misconfigure consent requirements of Tags . Furthermore , as third-party cookies are being phased out by all major browsers , CMP scanners only relying on cookie scanning such as Cookiebot risk under-reporting purposes for installed tags , as demonstrated by Toth et al . [ 75 ] . Recommendation CMPs should either provide a comprehensive scanning service including all purposes both from stateless and stateful tracking technologies or avoid providing any scanner at all . Relatedly , we recommend GTM to provide to the CMP/Publisher the list of tags installed in the GTM Web and Server Containers so that CMPs will be able to reliably detect the Data Collectors and map the purposes of such tags . Google Tag Manager : Hidden Data Leaks and its Potential Violations under EU Data Protection Law Proceedings on Privacy Enhancing Technologies YYYY ( X ) Figure 4 : client-side GTM configuration by a Publisher and usage by an end user Cookiebot Purpose Statistics Marketing Necessary Preferences GTM consent variable ( s ) analytics_storage ad_storage security_storage personalization_storage functionality_storage Table 4 : Cookiebot purposes and corresponding GTM consent variables . Potential violation 2 . Mapping CMP purposes to GTM con- sent variables is not compliant . CMPs need to map GTM ’ s con- sent variables to the purposes shown in their consent banner . No- tably , such mappings are not documented anywhere by CMPs nor by GTM . Furthermore , these mappings are subject to the legal issues identified in Potential Violation 3 and 4 . When installing CookieBot and Consentmanager CMPs ( claimed to be GTM compatible [ 33 ] ) on our website , we could infer the mappings of purposes ( presented in Appendix Table 4 and 8 ) . Herein we report several problems concerning such mappings : First , these CMPs use different names for purposes rather than the ones used by GTM . For example , the consent variable analytics_storage is called “ Statistics ” by Cook- iebot , and “ Measurement ” by Consentmanager . The Publisher might not be aware that the purpose “ Measurement ” in the Consentman- ager CMP banner corresponds to the analytics_storage consent variable in the GTM interface , and might have difficulty to configure tags that depend on this purpose . Second , certain CMPs merge multi- ple GTM purposes altogether , as displayed in Table 4 . GTM consent variables functionality_storage and personalization_stor- age are merged into one category called “ Preferences ” . A Publisher does not know that the “ Preferences ” purpose in the Cookiebot refers to two different purposes in GTM which are personaliza- tion_storage and functionality_storage . Third , in our exper- iments we ascertained that Consentmanager only partially maps its purposes to GTM consent variables , as displayed in Table 8 . Consentmanager does not map any of its own purposes to the ad_storage consent variable . If a user agrees to the marketing purpose shown in the consent banner , as there is no default consent variable that is associated with marketing purpose , a new variable ( not included by default in GTM ) is created within GTM . A Pub- lisher might not be aware of this lack of mapping , neither of the need to configure such consent variable to a Tag . For instance , this means that a Publisher that uses the personalization_storage variable to configure a Tag , will see that this Tag will always run independently of user choices ( see Technical finding 4 ) . Recommendation We recommend that GTM and CMPs agree on purpose names , descriptions and matching of purposes . 4.2.2 GTM Provider . This actor6 provides the GTM service with its Tag management functionalities to website Publishers . Determination of purposes . This actor is involved in the deter- mination of purposes for two reasons . First , it defines five default consent variables in GTM “ Consent Mode ” : ad_storage , ana- lytics_storage , security_storage , functionality_storage , and personalization_storage , presented in Table 3 . We claim that these consent variables correspond to personal data process- ing purposes within the meaning of Article 5 ( 1 ) ( b ) of the GDPR . A Publisher then needs to associate each Tag to one or more of these mentioned purposes , when purposes are not built-in . Second , we argue that GTM “ organizes and coordinates ” data processing [ 23 , 6The provider of GTM is Google at the time of our experiment . 9 ( 2b ) identifies Google Analytics Collector associated to Google Tag ( 1 ) selects and installs Pinterest Tag and Google Tag GTM Web Container Configuration Interface Publisher 's website GTM Consent Variables Purposes of the Tags GTM Web Container ( gtm.js ) ( 0 ) Provides GTM Provider ad_storage analytics_storage functionnality_storage personalization_storage security_storage Pinterest Tag Google Tag Extracted purposes : • “ Social Media ” purpose Built-in Consent : • ad_storage • analytics_storage ( 5a ) configures purposes for Pinterest Tag ( 5b ) purposes extracted by GTM ( 4a ) runs a CMP scanner to extract purposes for Pinterest Tag CMP scanner Publisher ( 3 ) selects the CMP ( 8 ) end-user 's data ( 0 ) Provides Google Tag with built-in consent if ad_storage then send Data1 to collector if analytics_storage then send Data2 to collector else send Data3 to collector Pinterest Tag without built-in consent < Code that does not invoke GTM built-in consent > CMP End-user ( 7 ) accepts/rejects consent CMP consent banner ( 6 ) configure CMP purposes ( 2a ) identifies Pinterest Collector associated to Pinterest Tag ( 4b ) extracts purposes of Pinterest Collector Google Analytics Collector Terms and Conditions ( 9a ) end-user 's data ( 0 ) Provides Tag 's code Tag Provider of Google Tag ( 0 ) Provides Tag's code Tag provider of Pinterest Tag ( 9b ) end-user 's data Pinterest Collector Terms and Conditions • Social Media '' purpose Proceedings on Privacy Enhancing Technologies YYYY ( X ) G. Mertens et al . paragraphs 70 , 71 ] , since it enables the orchestration of data collec- tion and sharing through several actors - the Publisher , Tag Provider and the Data Collector . Hence , GTM Provider ’ s platform is the placeholder that coordinates the Tags for collecting data . GTM also encourages data processing by proposing the tags to Publishers . Determination of means The GTM Provider generates Web Con- tainers and provides the configuration interface wherein the Pub- lisher configures GTM Containers and their components ( e.g. , Tags ) . As such , it determines non-essential means for data to be processed . Legal role : Provider of the GTM service is a Data Controller . Potential violation 3 . GTM purposes are limited to client- side storage . All consent variables definitions in GTM ( Table 3 ) are storage-based . The technologies that do not explicitly store any information in the user ’ s terminal equipment , known as “ stateless ” technologies , such as browser fingerprinting [ 30 , 54 ] , are hence excluded and therefore not covered by the GTM Provider by default . This means that if a Publisher installs a given Tag in the GTM interface which uses a stateless technology , it will not be covered by the purposes defined by GTM . Therefore , there is no way for Publishers to be compliant with the ePrivacy Directive [ 22 ] when using stateless tracking technologies in the Web Containers , since this directive requires consent for all non-necessary purposes of these tracking technologies . We reason that both Publishers and Tag Providers ( when they decide to include built-in consent ) might become confused when mapping consent variables to Tags . Because of this limitation , they can not ensure compliance for their websites and Tags when using stateless technologies that require consent . Recommendation GTM should define purposes regardless of the type of technology used ( stateless or stateful ) . Potential violation 4 . GTM purposes are not specific nor explicit . The GTM Provider , as a data controller , is obliged to pro- vide specific , detailed and explicit purposes , according to the GDPR Purpose limitation principle ( see Section 4.1.4 ) . The description of the personalization_storage consent variable that says “ stor- age related to personalization e.g . video recommendations ” is not clear enough to understand to what final goal such personalization applies to - for example , if it is used for targeted advertising , it would require consent . These short and vague descriptions make it difficult for Publishers to conclude whether a purpose is exempted of consent ( in case such purpose is functional or technical , see §4.1 ) . Consequently , CMPs might run the risk to require consent for pur- poses exempted thereof . For example , Cookiebot requests consent for non-necessary purposes of “ Preferences ” , “ Statistics ” and “ Mar- keting ” in its consent banner . However , the “ Preferences ” purpose ( see Table 9 ) seems to be necessary for a website to function , and hence , should be exempted of consent [ 21 , Art . 5 ( 3 ) ] ) . As Cookiebot maps this purpose to the GTM consent variables personaliza- tion_storage and functionality_storage , according to their description in Table 3 , it requests consent for this purpose . Recommendation GTM should employ purpose-specific and ex- plicit consent variables . Additionally , CMPs should not request consent for unnecessary purposes . Potential violation 5 . Defaulting consent variables to “ ac- cepted ” means that Tags run without consent . As described 10 in the Technical Finding 4 , the Web Container considers both “ ac- cepted ” and “ not defined ” variables as accepted by the user , by default . We also discovered a case where the Consentmanager CMP allows some consent variables to be undefined . As such , the tags installed in the Web Container will run and collect user ’ s data without their due consent . This practice renders any processing of personal data potentially illegal [ 31 , Article 6 ( 1 ) ( a ) ] . Notably , Consentmanager declares in its documentation that some consent mode functions are limited and not recommended for Publishers to use [ 12 ] . We argue that their disclaimer on the `` experimental mode '' does not exempt them of accountability obligations [ 31 , Ar- ticle 5 ( 2 ) ] . Nevertheless , GTM still recommends to use this CMP without any warning , and it further states : “ Discover featured CMP templates that deeply integrate with GTM ’ s consent configuration ” in the interface . By doing so , GTM pushes Publishers to use a flawed CMP that might enable tags to run independently of consent , and thus enabling processing of personal data without legal basis . Recommendation GTM should treat undefined consent variables as “ not accepted ” by default , and prohibit tags from collecting data before consent has been obtained to comply with the Privacy by default GDPR principle [ 31 , Art . 25 ( 2 ) ] . GTM should validate rec- ommended CMPs or explicitly warn about their limitations . 4.2.3 Data Collector . Data Collectors receive the data collected by tags from the Publisher ’ s website ( Step ( 9a ) and ( 9b ) in Figure 4 ) . Collection of personal data Data Collectors have the means to combine the IP address with additional collected data , as shown in Table 2 . Following our arguments in the beginning of Section 4.2 , the combination of IP address with these data can render a user identifiable , and thus this data is considered to be personal data . Determination of Purposes The Data Collector , through the Terms and Conditions ( T & Cs ) or Privacy Policy it provides to the Publishers , decides upon the purposes and other conditions of pro- cessing , as shown in step ( 4b ) in Figure 4 . Examples for two specific case studies on two popular Data Collectors show how they commu- nicate purposes to Publishers through T & Cs . In the documentation for Pinterest Tag , we found only one and very specific purpose of “ online behavioural advertising ” in the Advertising Guidelines [ 65 ] . On its page , Pinterest says : “ ( ... ) information will be shared with third parties for online behavioural advertising ” . In HotJar ’ s documenta- tion , we found information about the purposes of the collected data in its data processing agreement [ 14 ] . In our interpretation , it pertains to the purposes of analytics and aggregated user behavior : “ Hotjar allows its users to analyze and understand the behavioral patterns of their visitors ( ... ) . We reason there is a pluralistic control exercised by both the Data Collector and the Publisher : there is a common and complementary decision from both Publisher and Data Collector to process data , from the very moment in which the Publisher contractualizes with the Data Collector , derives the purposes from its T & Cs ( Step 4b Fig . 4 ) and relies on the means of processing from the Data Collector . The processing would not be possible without the participation of both parties . This interdepen- dence of the Publisher on the definition of purposes and means of the Data Collectors renders both actors joint controllers . Determination of Means Data Collectors receive users ’ data from the Tag and provide a service to the Publisher by processing the data . For example , Google Analytics provides a dashboard with statistics Google Tag Manager : Hidden Data Leaks and its Potential Violations under EU Data Protection Law Proceedings on Privacy Enhancing Technologies YYYY ( X ) Is a Collector ? S1 S2 S3 ✗ ✗ ✓ Has built-in consent ? ✗ ✓ not relevant Legal Role of the Tag Provider none none Data Controller Table 5 : Legal role of the Tag Provider depending on whether it is a Data Collector or the tag has built-in consent . about the Publisher ’ s website users . As a result , the Data Collector defines the means of processing since it decides how to process the received data and what algorithms to use on the received data to obtain the service requested by the Publisher . Legal role : Publisher and Data Collector are Joint Data Con- trollers . 4.2.4 Tag Provider . This actor merely writes the code of a tag , and such tag consists in the means to collect and send the data to the Data Collector . In general , Tag Provider does not receive nor store data from end users . The Tag Provider is aware that , at some point , some Publisher will use its Tag , without necessarily knowing the identity of the Publisher . The Tag Provider can include built- in consent in the Tag ( e.g. , Google Tag in Figure 4 , see “ Consent Configuration ” 3.1.1 ) . As shown in step ( 5b ) of Figure 4 , GTM extracts the purposes used by every tag using built-in consent functionality and displays them in GTM consent configuration . In Client-side GTM , it is common that a given company plays two roles at the same time : Tag Provider and Data Collector . We have identified 3 scenarios ( S1 , S2 , S3 ) shown in Table 5 that we use to reason about the role of the Tag Provider . S1 : When the company behind the Tag Provider is not the same as the Data Collector , and there is no built-in consent in the Tag , it seems that there is no contract or agreement that could link the Publisher to the Tag Provider . The Tag Provider still defines , in the Tag , to whom the user ’ s data will be sent ( so , who are the Data Collectors ) . This entails that the Tag Provider determines essential means of processing . However , the Tag Provider is not a Data Controller because it is missing the determination of purposes , i.e. , there is no built-in consent in the Tag that pre-defines purposes . The Tag Provider is neither a Data Processor , since it does not follow instructions from the Publisher nor from the Data Collector – it does not process personal data on behalf of these actors , since it is missing the dependence on the controller ’ s instructions regarding processing activities which defines the role between a processor and a controller ( see §4.1 ) . Hence , Tag Providers , under this scenario , are just service providers , with no GDPR obligations . S2 : When the company behind the Tag Provider is not the same as the Data Collector , and the tag contains built-in consent , the Tag Provider includes the purposes for collecting data inside of the Tag ’ s code . This inclusion of predefined purposes in the Tag could qualify the Tag Provider as a Data Controller , since it seems to define the purposes itself . Even though the Tag Provider develops a data-collecting Tag by itself , which is released to the public and enables the collection of data , these facts are not enough to reveal a factual influence over the definition of purposes of personal data [ 3 ] . We reason that by embedding the built-in consent in the tag , the 11 Tag Provider might not relate to the processing of personal data in itself ; it just consists of a prior step to the processing of personal data [ 3 ] , it does not provide enough elements of a factual nature that the Tag Provider exercises an actual influence with regards to the “ purposes and means ” of processing data [ 3 ] . Also , this actor does not process personal data . Hence , Tag Providers , under this scenario , are just service providers , with no GDPR obligations . S3 : When the company behind a given Tag Provider is the same as a Data Collector it is possible to conclude that a Tag Provider/Data Collector , jointly with a given Publisher , can be considered as Joint Controllers , since Data Collectors and Publishers are Joint Con- trollers , as already established in Section A.1 . This qualification holds regardless of whether there is built-in consent or not in the Tag , since the Data Collector determines already the purposes of processing in the T & C or contractual services . Legal role : Tag Provider ’ s role depends on whether it is a Data Collector . See Table 5 for a summary of their role . Potential violation 6 . Google Tag sends data independently of user ’ s consent decisions . Our Technical Finding 5 , Google Tag always sends user ’ s data to Google even when the user has re- jected all built-in purposes , thereby processing user ’ s data without a lawful legal basis , infringing the Lawfulness principle . Moreover , when user ’ s data is sent to Google , the Security principle is violated because of an unauthorized disclosure with Google ( §4.1 ) . As a Data Controller , Google is liable for these potential violations . Recommendations Google , as Tag Provider and Data Collector , must change its “ Google Tag ” behavior to respect user ’ s choices in order to be compliant . Potential violation 7 . GTM allows Tag Providers to inject scripts exposing end users to security risks . In Technical Find- ing 2 , we found that GTM contains a special inject_script per- mission , allowing Tags to inject arbitrary JavaScript code in the website ’ s page ( see Figure 3 ) . We found 56 Client-side Tags that inject such scripts which are not subject to any security measures implemented in Web browsers , such Same-Origin Policy [ 61 ] , to protect users from script-based Web attacks . This practice , allowed by GTM and executed by Tags , potentially infringes the Security principle ( §4.1.4 ) . The Provider of the GTM service , as a Data Con- troller , is liable for these potential violations . Additionally , the Tag Providers of these 56 Tags are Data Collectors , when they are Data Controllers , are also liable for such violations . Recommendations GTM should not allow Tag Providers to in- clude arbitrary scripts in the website ’ s pages without adopting any security safeguards . Tag Providers should not use this loophole of GTM to inject arbitrary scripts . 4.3 Legal analysis of Server-Side GTM In this section we describe the actors involved in Server-side GTM . We reproduce the same legal reasoning about some of the roles of the actors held on Section 4.2 regarding the Publisher ( appendix §A.1 ) , Data Collector ( §4.2.3 ) and GTM Service Provider ( §4.2.2 ) . As such , herein we focus on the Provider of Collector Tag and Client Adaptor , the Server Provider and Server Tag Provider . Since the Server Provider ’ s role does not trigger potential violations , we refer to it in the Appendix ( A.2 ) . After analyzing the Provider of Collector Proceedings on Privacy Enhancing Technologies YYYY ( X ) G. Mertens et al . Actor Publisher Data Collector CMP Tag Provider GTM Provider Server Provider Provider of Collector Tag and Client Adaptor Client-side Data Controller Data Controller Data Controller Server-side Data Controller Data Controller N/A Depends , see Tab.5 Depends , see Tab.5 Data Controller N/A N/A Data Controller Data Processor No legal role Table 6 : Summary of the legal roles of the actors . Tag and Client Adaptor functions , we concluded it has no GDPR legal role . We found that this actor presents similarities with the Tag Provider in client-side GTM ( when it is not a Data Collector ) since it merely develops and provides software without processing personal data and without following instructions from any other actors . Table 6 outlines server-side roles for each GTM actor . The processing of personal data on the Server-side needs to be assessed on a case-by-case basis . The Server Provider processes the IP address of end users since it receives incoming HTTP requests on its servers ; the Data Collector will sometimes receive personal information ( see Table 2b for specific Data Collectors that receive the IP address of end users ) . Server Tag Provider . This actor presents similar functions 4.3.1 as to the Tag Provider on client side 4.2.4 . On server-side GTM , the absence of the built-in function does not change its legal role as a Data Controller when the Server Tag Provider is also a Data Collector . Legal role : Tag Provider ’ s legal role depends on whether the Data Collector is the same company . Potential violation 8 . Server Tag Providers that are also Data Collectors are aware that lawful data collection is not possi- ble . A Server Tag Provider , who provides the code of a tag , knows how the GTM Server Container functions ( see Figure 2b ) and thus is aware that no consent management tool is available on the Server Container . A Server Tag Provider also knows that the Publisher can not conveniently configure the Server Container to match GTM consent variables to Server Tags ( see §5 ) . Nonetheless , Server Tag Provider still provides Server Tags . When a Server Tag Provider directly receives users ’ personal data , it has a legal role of a Data Collector , and therefore becomes a Data Controller ( see Table 5 ) . Moreover , it is a Joint Controller with the Publisher ( see §4.2.3 ) , and therefore has the responsibility to ensure lawful data processing . Recommendation Server Tag Providers that are Data Collectors should not provide Server Tags until the GTM does not have the consent management functionality on the Server-side . 5 DISCUSSION In this section , we discuss other findings and reflect upon the diffi- culty to comply with the EU Data Protection framework for various actors within the Client- and Server-side GTM and provide further recommendations for improvement of GTM . 12 Complying with data subject rights is hard for the Publisher . Within both Client- and Server-Side GTM , the Publisher is left alone to comply with users ’ rights , like data requests , due to the absence of a dedicated system for this functionality . For example , if a user requests access to her data ( under Article 15 GDPR ) , the Publisher would probably need to find the contact of every Data Collector and compile it manually to then answer to the user – a task confirmed to be problematic as studied by Samarin et al . [ 68 ] . GTM should furnish Publishers with a common interface to identify all Data Collectors , and a streamlined tool from Data Collectors to facilitate users ’ data requests . Built-in consent raises trust issues . When the Publisher uses Tags with built-in consent ( such as “ Google Tag ” in Potential Violation 6 ) , it relies on the Tag Provider to properly implement the built-in consent in its code . However , the Tag Provider can declare to rely on some built-in consent purposes , but completely ignore them in the Tag code , and send the user ’ s data even if the corresponding purposes were rejected by the user . The only way a Publisher can ensure proper consent management is to review the Tag ’ s code . This in only possible for non-official Tags , whose code is available on the template gallery . However , code reviewing is not possible for official Tags , that are implemented as sandboxed code inside the gtm.js , and it requires heavy reverse engineering . Publishers can also ignore built-in consent and manually add consent variables ( Step ( 5a ) in Figure 4 ) . In this case , the Tag will only run when all the consent variables associated with the tag are granted . GTM should allow Publishers to access the code of the Tags for auditing and should facilitate Publishers to understand the Tags ’ code . Server-side GTM is invisible for regulatory monitoring and au- diting . Server-side GTM obstructs compliance auditing endeavors from regulators , data protection officers , and researchers , since data collection occurs remotely on a server , whereas traditionally it happens in the browser . For example , while only the Collector Tag is detectable , the tags chosen by a Publisher remain invisible . It is possible to monitor the data collected and transmitted to the GTM Server Container ; however , discerning which Collectors have access to such data remains unknown . Moreover , auditing and mon- itoring is exclusively attainable by only contacting the Publisher to grant access to the configuration of the GTM Server Container . Furthermore , the Publisher is able to change the configuration of the GTM Server Container at any point in time ( e.g. , before any regulatory investigation ) , masking any compliance check . Consent is hard to configure on GTM Server Containers . While Google advertises : “ respect user consent choices with Google Tag Manager ” [ 41 ] , consent management tools are limited to client- side GTM and it is challenging to render consent compliant on the server-side . The lack of consent management tools in GTM Server Container raises the following two problems : First , CMPs scanners can only detect tags in GTM Web Containers but are not able to de- tect tags on GTM Server Containers ; this impossibility entails that CMPs can not display the purposes and the Data Collectors in the consent banner to end users . This type of information disclosure is mandatory for an end-user informed consent and transparent pro- cessing of personal data [ 31 , Art . 4 ( 11 ) , 5 ( 1 ) ( a ) ] . Second , Publishers that wish to be compliant on the Server-side , need to make complex Google Tag Manager : Hidden Data Leaks and its Potential Violations under EU Data Protection Law Proceedings on Privacy Enhancing Technologies YYYY ( X ) configurations such as writing code to decode consent information and create filtering rules in respect to the given consent in the GTM Server Container since there is no interface to configure con- sent . Furthermore , since Server Container does not support consent mode , Publishers can not associate tags with purposes . GTM should implement consent management tools in GTM Server Containers and provide the list of installed Tags to CMPs . 6 CONCLUSION This work is the first to study both versions of Google Tag Manager : Client-side and Server-side . We analyzed these systems with 78 Client-side Tags , 8 Server-side Tags and two Consent Management Platforms ( CMPs ) and performed an in-depth technical and legal analysis of GTM , determining the responsibilities and potential legal violations of each actor . Our results show that GTM has many pitfalls , such as flaws in its security system and non-compliant defaults . We conclude that GTM in its current state introduces more legal issues than solving , while making compliance difficult to achieve for various actors and complex for regulators to monitor . ACKNOWLEDGMENTS This work has been supported by the ANR 22-PECY-0002 IPoP ( Interdisciplinary Project on Privacy ) project of the Cybersecurity PEPR . The authors would like to thank Javiera Bermudez Alegria , from Universidad de Chile , who contributed to the initial work . REFERENCES [ 1 ] 2016 . Case 582/14 – Patrick Breyer v Germany . Court of Justice of the European Union ECLI : EU : C:2016:779 . [ 2 ] 2023 . C-319/22 Scania case . ECLI : EU : C:2023:837 . Court of Justice of the European Union [ 3 ] 2023. the Advocate General on the case Case C-683/2 , Opinion of https : . ECLI : EU : C:2023:376. jsf ? text= & docid=273310 & pageIndex=0 & doclang=EN & mode=req & dir= & occ= first & part=1 [ 4 ] 29 Working Party . 2010 . Opinion 1/2010 on the concepts of “ controller ” and https : “ processor ” WP 169. . [ 5 ] Reuben Binns , Jun Zhao , Max Van Kleek , and Nigel Shadbolt . 2018 . Measuring Third-party Tracker Power across Web and Mobile . ACM Transactions on Internet Technology 18 , 4 ( Nov. 2018 ) , 1–22 . https : //doi.org/10.1145/3176246 Supple- mentary materials were consulted on June the 7th , 2023 at https : //arxiv.org/e- print/1802.02507 .. [ 6 ] Brave Software , Inc. n.d .. Brave Shields . https : //brave.com/shields/ ( Consulted on June 27th 2023 ) .. [ 7 ] BuiltWith® Pty Ltd. n.d .. Google Tag Manager Usage Statistics . https : ( Consulted on November 20th 2023 ) .. [ 8 ] Ronan Chardonneau . 2015 . Google Tag Manager – Optimisez Le Tracking De Votre Site Web . Éditions ENI , FRA . [ 9 ] chromium-browser n.d .. Chromium . https : //www.chromium.org/Home/ ( Con- sulted on November 28th 2023 ) .. [ 10 ] chromium-flatpak n.d .. Chromium Web Browser . https : //flathub.org/apps/org . chromium.Chromium ( Consulted on June 29th 2023 ) .. [ 11 ] Consentmanager . n.d . Consent Management Provider . consentmanager.net/ ( Consulted on June 15th 2023 ) .. https : //www . [ 12 ] Consentmanager . n.d .. Working with Google Consent Mode . https : //help . ( Consulted on November 7th 2023 ) .. [ 13 ] Cookiebot . 2020 . Google Tag Manager and cookie consent | Compliance with Cookiebot CMP . https : ( Con- sulted on June 15th 2023 ) .. [ 16 ] European Data Protection Board ( EDPB ) . 2012 . Opinion 04/2012 on Cookie Consent Exemption ( WP 194 ) . [ 17 ] European Data Protection Board ( EDPB ) . 2013 . Opinion 03/2013 on purpose limita- tion ( WP 203 ) . Available at https : . [ 18 ] European Data Protection Board ( EDPB ) . 2013 . Working Document 02/2013 providing guidance on obtaining consent for cookies , adopted on 2 October 2013 . Available at https : . [ 19 ] Steven Englehardt and Arvind Narayanan . 2016 . Online Tracking : A 1-million-site Measurement and Analysis . In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security . ACM , Vienna Austria , 1388–1401 . https : //doi.org/10.1145/2976749.2978313 [ 20 ] Steven Englehardt and Arvind Narayanan . 2016 . Online Tracking : A 1-million-site Measurement and Analysis . In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security , Vienna , Austria , October 24-28 , 2016 , Edgar R. Weippl , Stefan Katzenbeisser , Christopher Kruegel , Andrew C. Myers , and Shai Halevi ( Eds. ) . ACM , 1388–1401 . https : //doi.org/10.1145/2976749.2978313 [ 21 ] ePD-09 2009 . Directive 2009/136/EC of the European Parliament and of the Council of 25 November 2009. https : ? uri=celex % 3A32009L0136 , accessed on 2019.10.31 . [ 22 ] ePD-09 2009 . Directive 2009/136/EC of the European Parliament and of the https : , Council of 25 November 2009. accessed on October 30th 2023 . [ 23 ] European Court of Justice . 2018 . Case 25/17 Jehovan todistajat , ECLI : EU : C:2018:551 . [ 24 ] European Court of Justice . 2018 . Case C-210/16 Wirtschaftsakademie Schleswig- Holstein , ECLI : EU : C:2018:388 . [ 25 ] European Court of Justice . 2023 . ECLI : EU : C:2023:745 . C-659/22 , Ministerstvo zdravotnictví , [ 26 ] European Data Protection Board . 2007 . Opinion 4/2007 on the concept of personal https : //ec.europa.eu/justice/article- data ( WP 136 ) , adopted on 20.06.2007 . . [ 27 ] European Data Protection Board . 2020 . Guidelines 07/2020 on the concepts of controller and processor in the GDPR Version 1.0. https : //edpb.europa.eu/our- controller-and-processor_en . [ 28 ] Imane Fouad , Nataliia Bielova , Arnaud Legout , and Natasa Sarafijanovic-Djukic . 2020 . Missed by Filter Lists : Detecting Unknown Third-Party Trackers with Invis- ible Pixels . In Proceedings on Privacy Enhancing Technologies ( PoPETs ) , Vol . 2020 . 499–518 . Issue 2. https : //doi.org/10.2478/popets-2020-0038 Published online : 08 May 2020 , https : //doi.org/10.2478/popets-2020-0038 . [ 29 ] Imane Fouad , Cristiana Santos , Feras Al Kassar , Nataliia Bielova , and Stefano Calzavara . 2020 . On Compliance of Cookie Purposes with the Purpose Specifi- cation Principle . In Proc . International Workshop on Privacy Engineering ( IWPE ) . https : //hal.inria.fr/hal-02567022 [ 30 ] Imane Fouad , Cristiana Santos , Arnaud Legout , and Nataliia Bielova . 2022 . My Cookie is a phoenix : detection , measurement , and lawfulness of cookie respawn- ing with browser fingerprinting . Proceedings on Privacy Enhancing Technologies ( PoPETs ) 2022 ( 2022 ) , 79–98 . Issue 3. https : //petsymposium.org/popets/2022/ popets-2022-0063.pdf . [ 31 ] GDPR 2016 . Regulation ( EU ) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data , and repealing Directive 95/46/EC ( General Data Protection Regulation ) ( Text with EEA relevance ) . https : ? uri=celex : 32016R0679 . [ 32 ] Google . n.d .. About consent mode . https : //support.google.com/google-ads/ answer/10548233 ? sjid=6259837766651858133-EU ( Consulted on November 27th 2023 ) .. [ 33 ] Google . n.d .. Consent management platform integrations . https : //support.google . com/tagmanager/answer/10718549 ? hl=en # cmp-integrations ( Consulted on June 29th 2023 ) .. [ 34 ] Google . n.d .. Create a Consent Mode template . https : //developers.google.com/ ( Consulted on October 27th 2023 ) .. [ 35 ] Google . n.d .. Custom template APIs . https : tag-manager/templates/api # isconsentgranted ( Consulted on October 16th 2023 ) .. [ 36 ] Google . n.d .. Custom template permissions . https : //developers.google.com/tag- ( Consulted on October 31st 2023 ) .. [ 37 ] Google . n.d .. Google Tag Manager . https : //tagmanager.google.com/ # /home . [ 38 ] Google . n.d .. Implement consent mode with server-side Tag Man- https : ager . consent-mode ( Consulted on October 25th 2023 ) .. [ 14 ] Data Processing Agreement . n.d .. Data Processing Agreement . https : //www . [ 39 ] Google . n.d .. Manage consent settings ( web ) . https : //developers.google.com/tag- hotjar.com/legal/support/dpa/ ( Consulted on June 28th 2023 ) .. [ 15 ] Pixel de Tracking . 2020 . Google Tag Manager , the new anti-adblock weapon . https : new-anti-adblock-weapon.html ( English translated version ) . platform/security/guides/consent ( Consulted on September 14th 2023 ) .. [ 40 ] Google . n.d .. Measurement Protocol Parameter Reference . https : //developers . ( Consulted on October 16th 2023 ) .. 13 Proceedings on Privacy Enhancing Technologies YYYY ( X ) G. Mertens et al . [ 41 ] Google . n.d .. Respect user consent choices with Google Tag Man- ager . https : google-tag-manager/ ( Consulted on June 16th 2023 ) .. [ 42 ] Google . n.d .. Sandboxed JavaScript . https : ( Consulted on July the 7th 2023 ) .. https : //support.google.com/ [ 43 ] Google . n.d .. Set up and install Tag Manager . tagmanager/answer/6103696 ( Consulted on July the 4th 2023 ) .. [ 44 ] Google . n.d .. Submit a template to the Community Template Gallery . https : // ( Consulted on June 28th 2023 ) .. [ 45 ] Google . n.d .. Tag Manager > Server-side . https : //developers.google.com/tag- platform/tag-manager/server-side ( Consulted on July 3rd 2023 ) .. [ 46 ] Google . n.d .. Tag platform overview . https : //developers.google.com/tag- platform/devguides ( Consulted on June 12th 2023 ) .. [ 47 ] Hotjar . n.d .. hotjar-protocol-documentation . https : //help.hotjar.com/hc/en- us/articles/13052816995991 ( Consulted on November 20th 2023 ) .. [ 48 ] Information Commissioner ’ s Office . 2018 . Data controllers and data pro- cessors : what the governance implications are . https : . the difference is and what [ 49 ] John Wilander . 2019 . Intelligent Tracking Prevention . https : //webkit.org/blog/ ( Consulted on June 27th 2023 ) .. [ 50 ] Julius Fedorovicius . 2023 . Introduction to Google Tag Manager Server-side Tagging . https : manager-server-side-tagging/ ( Consulted on 24 Feb 2023 ) .. [ 51 ] Julius Fedorovicius . n.d .. Analytics Mania – Google Tag Manager and Google Analytics Blog . https : //www.analyticsmania.com/ ( Consulted on 24 Feb 2023 ) .. [ 52 ] Justin Schuh . 2020 . Building a more private web : A path towards making third https : party cookies obsolete . private-web-path-towards.html ( Consulted on June 28th 2023 ) .. [ 53 ] Balachander Krishnamurthy and Craig E. Wills . 2009 . Privacy diffusion on the web : a longitudinal perspective . In Proceedings of the 18th International Conference on World Wide Web , WWW 2009 , Madrid , Spain , April 20-24 , 2009 , Juan Quemada , Gonzalo León , Yoëlle S. Maarek , and Wolfgang Nejdl ( Eds. ) . ACM , 541–550 . https : //doi.org/10.1145/1526709.1526782 [ 54 ] Pierre Laperdrix , Nataliia Bielova , Benoit Baudry , and Gildas Avoine . 2020 . Browser Fingerprinting : A Survey . ACM Transactions on the Web ( TWEB ) 14 , 2 ( 2020 ) , 8:1–8:33. https : //dl.acm.org/doi/10.1145/3386040 . [ 55 ] Adam Lerner , Anna Kornfeld Simpson , Tadayoshi Kohno , and Franziska Roesner . 2016 . Internet Jones and the Raiders of the Lost Trackers : An Archaeological Study of Web Tracking from 1996 to 2016 . In 25th USENIX Security Symposium ( USENIX Security 16 ) . USENIX Association . [ 56 ] Timothy Libert . 2015 . Exposing the Invisible Web : An Analysis of Third-Party HTTP Requests on 1 Million Websites . International Journal of Communication 9 , 0 ( 2015 ) . [ 57 ] Célestin Matte , Nataliia Bielova , and Cristiana Santos . 2020 . Do Cookie Banners Respect my Choice ? Measuring Legal Compliance of Banners from IAB Europe ’ s Transparency and Consent Framework . In IEEE Symposium on Security and Privacy ( IEEE S & P ) . https : //hal.inria.fr/hal-03117294 [ 58 ] Mozilla Corporation . n.d .. Enhanced Tracking Protection in Firefox for desk- https : top . firefox-desktop ( Consulted on June 27th 2023 ) .. [ 59 ] mozilla.org contributors . n.d .. Content Security Policy . https : //developer.mozilla . org/en-US/docs/Web/HTTP/CSP ( Consulted on November 29th 2023 ) .. [ 60 ] mozilla.org contributors . n.d .. Document Object Model . https : //developer.mozilla . ( Consulted on November 29th 2023 ) .. [ 61 ] mozilla.org contributors . n.d .. Same-origin policy . https : //developer.mozilla.org/ . [ 62 ] Nick Nikiforakis , Luca Invernizzi , Alexandros Kapravelos , Steven Van Acker , Wouter Joosen , Christopher Kruegel , Frank Piessens , and Giovanni Vigna . 2012 . You are what you include : large-scale evaluation of remote javascript inclusions . In Proceedings of the 2012 ACM conference on Computer and communications security . ACM , Raleigh North Carolina USA , 736–747 . https : //doi.org/10.1145/ 2382196.2382274 [ 63 ] Node.js . n.d .. Node.js v14.21.3 documentation . https : //nodejs.org/docs/latest- v14.x/api/cli.html # cli_tls_keylog_file ( Consulted on September 14th 2023 ) .. [ 64 ] Pinterest . n.d .. Add event codes . https : add-event-codes ( Consulted on November 20th 2023 ) .. [ 65 ] Pinterest . n.d .. Advertising Guidelines . https : //policy.pinterest.com/en-gb/ advertising-guidelines ( Consulted on June 28th 2023 ) .. [ 66 ] PixeldeTracking-website n.d .. Pixel de tracking – Notes sur l ’ extension du do- maine de la surveillance ( personal website ) . https : //www.pixeldetracking.com/ ( Consulted on 22 Feb 2023 ) .. [ 67 ] Franziska Roesner , Tadayoshi Kohno , and David Wetherall . 2012 . Detecting and Defending Against Third-Party Tracking on the Web . In Proceedings of the 9th USENIX Symposium on Networked Systems Design and Implementation , NSDI 2012 . 155–168 . [ 68 ] Nikita Samarin , Shayna Kothari , Zaina Siyed , Oscar Bjorkman , Reena Yuan , Primal Wijesekera , Noura Alomar , Jordan Fischer , Chris Hoofnagle , and Serge Egelman . 2023 . Lessons in VCR Repair : Compliance of Android App Developers with the California Consumer Privacy Act ( CCPA ) . Proceedings on Privacy Enhanc- ing Technologies 2023 , 3 ( July 2023 ) , 103–121 . https : //doi.org/10.56553/popets- 2023-0072 [ 69 ] Cristiana Santos , Nataliia Bielova , and Célestin Matte . 2020 . Are cookie banners indeed compliant with the law ? Deciphering EU legal requirements on consent and technical means to verify compliance of cookie banners . Technology and Regulation ( TechReg ) ( 2020 ) , 91–135 . https : [ 70 ] Cristiana Santos , Midas Nouwens , Michael Toth , Nataliia Bielova , and Vincent Roca . 2021 . Consent Management Platforms under the GDPR : processors and/or controllers ? . In Annual Privacy Forum ( APF ) . https : //hal.inria.fr/hal-03169436 [ 71 ] Asuman Senol , Gunes Acar , Mathias Humbert , and Frederik Zuiderveen Borge- sius . 2022 . Leaky Forms : A Study of Email and Password Exfiltration Before Form Submission . Proceedings of the 31st USENIX Security Symposium ( USENIX ) ( 2022 ) . [ 72 ] Simo Ahava . 2022 . Agency , Transparency , And Control : Unsolved Problems https : With Server-side Tagging . ( Consulted on 24 Feb 2023 ) .. [ 73 ] Simo Ahava . n.d .. Tags / Google Tag Manager . https : //www.simoahava.com/ tags/google-tag-manager/ ( Consulted on 22 Feb 2023 ) .. [ 74 ] supplementary-materials n.d .. Anonymous GitHub - Supplementary Mate- https : rials . A8E4/README.md . [ 75 ] Michael Toth , Nataliia Bielova , and Vincent Roca . 2022 . On dark patterns and manipulation of website publishers by CMPs . Proceedings on Privacy Enhancing Technologies 2022 , 3 ( July 2022 ) , 478–497 . https : //doi.org/10.56553/popets-2022- 0082 [ 76 ] Jonathan Weber . 2015 . Practical Google Analytics and Google Tag Manager for Developers ( 1st ed. ) . Apress , USA . [ 77 ] Wireshark Foundation . n.d .. Wireshark . https : //www.wireshark.org/ . A ACTORS A.1 Publisher on the Client and Server-side The Publisher uses GTM to include a dedicated service in their website . When a Publisher chooses the Data Collector or its tag as shown in step ( 1 ) of Figure 4 , it needs to accept the Terms and Conditions ( T & Cs ) related to this contractual service of the Data Collector . Determination of purposes . The selection of the Data Collector has a determinant consequence on the qualification of the Pub- lisher in the determination of purposes . Firstly , the Data Collector establishes the purposes ( Step ( 4b ) in Figure 4 ) for processing data because it explicitly mentions them ( e.g . analytics , among others ) in the T & C or other policy documents . Since the Publisher agrees to the purposes defined in the T & Cs by the Data Collector , these are the purposes that the Publisher presents to the end-users . This pre- sentation of purposes given to data subjects , and their reasonable expectations on the basis of this visibility [ 4 ] , reflects the determi- nant power that Publishers have regarding purposes . Determination of means . Because of the acceptance of the Data Collector ’ s T & C , the Publisher agrees with the means of the process- ing that were established by the Collector , such as how to process the received data , what algorithms to use and what code to run on the received data . Accordingly , the Publisher determines the means for data processing . Legal role : Publisher is a Controller . 14 Google Tag Manager : Hidden Data Leaks and its Potential Violations under EU Data Protection Law Proceedings on Privacy Enhancing Technologies YYYY ( X ) denied . In examples given by GTM in the documentation , consent variables are used to represent purposes for data collection and processing . For instance , a hypothetical “ targeted_advertising ” consent variable could represent the consent or refusal of the end user to let their data be used to display targeted ads . Tags can be configured to have different behaviors ( regarding data collection ) depending on the state of these variables . Built-in consent is a feature that tags can implement . A tag sup- ports this feature is able to adjust its behavior based on the state of consent variables . For instance , when a end user only accepts that their data to be used for analytics purposes but not for advertise- ment purposes , a tag supporting built in consent and collecting data for both purposes can limit its data collection to analytic purposes only . Technically , a tag implementing built-in consent uses the GTM provided isConsentGranted API to check the status ( accepted or declined ) of each of the purposes.We provide an example of code of a tag implementing built-in consent in Appendix Figure ? ? . Manual consent configuration is the process by which the Pub- lisher associate consent variables to the tags installed in the GTM Web Container . A tag that is manually associated with one or more consent variables will be prevented from running by the GTM Web Container until all its associated variables are set to granted . For instance , in this case , when a user only accepts that their data to be used for analytics purposes but not for advertisement pur- poses , a tag configured with manual consent for both analytics and advertisement purposes will not run . C SERVER SIDE TERMINOLOGY A Server Tag is a component written in “ sandboxed JavaScript ” [ 42 ] that runs exclusively on the server . It can process and send the data that is received , by the GTM Server Container , to a third party server . Server Tags can store first-party cookies in the user ’ s browser . A Client adaptor is a plugin , embedded in the server container . It decodes data arriving to the GTM server Container and converts them into events . An Event is something that happened ( e.g. , the user clicked on a button ) and it ’ s associated data ( e.g. , the button ’ s name , its position on the page ) . A Collector tag tag is a tag running in the browser that collects data and send it through the network to a GTM Server Container . A.2 Server Provider on Server-side This actor provides to the Publisher the hardware for a given soft- ware ( e.g . the GTM Server Container ) to run . Two types of Server Providers exist : i ) the “ GTM-server service provider ” which pre- installs the GTM server software , and also manages the security of the server ; and ii ) the “ simple server provider ” that provides only a generic server , and allows any given Publisher to install the GTM server software themselves . In this paper we only analysed point ii ) , a “ simple server provider ” . The service provided ( i.e . the hard- ware for the server to run ) is usually a service a Publisher needs to pay for . The Publisher hires a given Server Provider to provide the server and a contract is performed between the Publisher and such Server Provider . The Publisher will use the server to install the GTM Server Container software and consequently gives instruc- tions the this Server on how to run it in order to process personal data . Accordingly , there is a functional dependence of the Server Provider on the Publisher ’ s instructions with renders this actor a data processor . Determination of purposes . By only providing the infrastructural hardware service , the Server Provider does not determine purposes . Determination of means . The Server Provider provides the means for a Publisher to run the GTM Server Container software , such as the hardware used and security of the system . These factual activities regarding the practical implementation of the server con- sist of “ non-essential means ” . Since the hardware provided by the Server Provider runs the GTM Server Container software – which processes personal data –the Server Provider is a data processor . Legal role : Server Provider is a Data Processor We did not find compliance issues of this actor . B CLIENT SIDE TERMINOLOGY A Tag is a JavaScript library usually developed by marketing com- panies , analytics companies , independent developers or , less fre- quently , publishers themselves . The role of a tag is to collect in- formation about the user or its device and send the collected data to a third-party service . In GTM specifically , a tag is a software component written in “ sandboxed JavaScript ” which is a limited version of JavaScript created by Google [ 42 ] . In GTM , Tags also pro- vide functionalities ( e.g. , implement consent banners ) . GTM has a permission system for tags [ 36 ] to let them access to functionalities such as sending requests to third party servers or access cookies . A GTM Web Container is a group of tags and their associated configuration rules . Technically , a container is a JavaScript program generated automatically by Google and downloaded by the user ’ s browser as a file called gtm.js from the https : //googletagmanager.com . It embeds the tags selected by the publisher and their configuration as well as an interpreter that executes the “ sandboxed JavaScript ” code the tags are written in . Container configuration is the process by which the Publisher selects the tags and configures them.using the configuration web interface , provided by Google at https : //tagmanager.google.com . Consent Variables store the consent of the end user in the GTM Web Container . They can be in three states : undefined , granted or 15 Proceedings on Privacy Enhancing Technologies YYYY ( X ) G. Mertens et al . Figure 5 : Summary of the legal role of the Publisher as a Joint Controller with other actors of the GTM ecosystem . In Figure 5 we summarise the legal roles of the Publisher in relation to : i ) the Collector ( always join controllers ) , ii ) CMPs ( joint controllers ) , iii ) Tag Providers ( when the Tag Provider is the Data Collector ) . Cookie detected Purpose associated is_eu Necessary CookieConsent Necessary _hjRecordingEnabled _hjRecordingLastActivity hjViewportId hjActiveViewportIds _hjCookieTest _ga_ # _ga _hjSessionUser_ # _hjFirstSeen _hjIncludedInSessionSample_ # _hjSession_ # _hjAbsoluteSessionInProgress Statistics Statistics Statistics Statistics Statistics Statistics Statistics Statistics Statistics Statistics Statistics Statistics ar_debug Marketing _pinterest_ct_ua Marketing v3/ Marketing _pin_unauth Marketing Tag creating the cookie Pinterest Cookiebot Hotjar Hotjar Hotjar Hotjar Hotjar Google Analytics Google Analytics Hotjar Hotjar Hotjar Hotjar Hotjar Pinterest Pinterest Pinterest Pinterest Table 7 : Results of the Cookiebot scanner . We deduct which tag that is responsible for the cookie creation by reading the description of the cookie and the provider shown in the report . Consentmanager purpose Measurement N/A N/A N/A N/A Marketing Function Preferences Other Social Media GTM consent variable analytics_storage ad_storage security_storage personalization_storage functionality_storage N/A N/A N/A N/A N/A Table 8 : Correspondence between Consentmanager purposes and GTM purposes . Not all GTM purposes are used by Con- sentmanager and some Consentmanager purposes are not mapped to GTM consent mode purposes . 16 Joint C ontrollers GTM Service Provider Joint Controllers Joint C w the D hen Tag Provider is ontrollers ollector ata C Publisher t i n o J s r e l l o r t n o C CMP Tag Provider Collector Google Tag Manager : Hidden Data Leaks and its Potential Violations under EU Data Protection Law Proceedings on Privacy Enhancing Technologies YYYY ( X ) Cookiebot Purpose Description Necessary Preferences Statistics Marketing Necessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website . The website can not function properly without these cookies . Preference cookies enable a website to remember information that changes the way the website behaves or looks , like your preferred language or the region that you are in . Statistic cookies help website owners to understand how visitors interact with websites by collecting and reporting information anonymously . Marketing cookies are used to track visitors across websites . The intention is to display ads that are relevant and engaging for the individual user and thereby more valuable for publishers and third party advertisers . Table 9 : Purposes defined by Cookiebot with their description Figure 6 : Confirmation window when installing a tag from the Community template Gallery . Permissions ( or capabili- ties ) of the tag are explicitely listed . 17","['manager', 'hide', 'datum', 'leak', 'potential', 'violation', 'protection', 'nataliia', 'inria', 'inriafr', 'gille', 'inria', 'grenoble', 'gillesmerten', 'inriafr', 'grenoble', 'inriafr', 'c', 'e', 'r', 'c', 'c', 'r', 'cteixeirasanto', 'uunl', 'grenoble', 'inriafr', 'abstract', 'tag', 'management', 'system', 'develop', 'order', 'support', 'web', 'site', 'publisher', 'instal', 'multiple', 'thirdparty', 'javascript', 'script', 'tag', 'website', 'develop', 'tms', 'call', 'tag', 'manager', 'currently', 'present', 'live', 'website', 'new', 'serverside', 'introduce', 'allow', 'publisher', 'include', 'tag', 'directly', 'server', 'however', 'version', 'yet', 'thoroughly', 'evaluate', 'academic', 'research', 'community', 'work', 'study', 'first', 'time', 'version', 'management', 'architecture', 'client', 'server', 'side', 'analyze', 'system', 'clientside', 'tag', 'serverside', 'tag', 'consent', 'management', 'platform', 'cmp', 'inside', 'discover', 'multiple', 'hidden', 'datum', 'leak', 'tag', 'bypass', 'ing', 'gtm', 'permission', 'system', 'inject', 'script', 'consent', 'enable', 'default', 'legal', 'expert', 'perform', 'indepth', 'legal', 'anal', 'ysis', 'gtm', 'actor', 'identify', 'potential', 'legal', 'violation', 'liability', 'provide', 'recommendation', 'propose', 'numerous', 'improvement', 'facilitate', 'legal', 'compliance', 'keyword', 'online', 'track', 'serverside', 'track', 'privacy', 'consent', 'gdpr', 'com', 'pliance', 'website', 'publisher', 'datum', 'controller', 'potential', 'legal', 'violation', 'introduction', 'today', 'modern', 'website', 'continuously', 'collect', 'visitor', 'datum', 'various', 'purpose', 'target', 'advertising', 'rely', 'third', 'party', 'collection', 'last', 'decade', 'researcher', 'demonstrate', 'thirdpartie', 'collect', 'user', 'datum', 'help', 'javascript', 'script', 'script', 'invisible', 'user', 'silently', 'execute', 'webpage', 'background', 'often', 'call', 'tag', 'web', 'marketing', 'industry', 'initially', 'install', 'tag', 'webpage', 'website', 'publisher', 'need', 'work', 'license', 'creative', 'common', 'attribu', 'tion', 'international', 'license', 'view', 'copy', 'license', 'visit', 'https', 'send', 'letter', 'creative', 'mountain', 'view', 'proceeding', 'privacy', 'enhance', 'technology', 'yyyy', 'copyright', 'hold', 'ownerauthor', 'https', 'doiorgxxxxxxxxxxxxxx', 'copy', 'paste', 'external', 'javascript', 'library', 'reference', 'webpage', 'source', 'code', 'however', 'publisher', 'instal', 'tags1', 'manual', 'tag', 'management', 'become', 'challenging', 'result', 'tag', 'management', 'system', 'tms', 'develop', 'industry', 'tms', 'allow', 'publisher', 'install', 'configure', 'tag', 'centralized', 'manner', 'tinker', 'website', 'source', 'code', 'instal', 'website', 'tms', 'take', 'care', 'handle', 'installation', 'configuration', 'execution', 'thirdparty', 'tag', 'develop', 'tms', 'call', 'tag', 'manager', 'currently', 'instal', 'tms', 'market', 'currently', 'present', 'live', 'website', 'accord', 'free', 'service', 'offer', 'graphical', 'inter', 'face', 'support', 'seamless', 'inclusion', 'major', 'marketing', 'analytic', 'thirdparty', 'script', 'also', 'benefit', 'community', 'contributor', 'create', 'tag', 'service', 'officially', 'support', 'tag', 'rely', 'ability', 'browser', 'com', 'municate', 'directly', 'thirdparty', 'domain', 'download', 'script', 'set', 'cookie', 'send', 'user', 'datum', 'figure', '1a', 'show', 'first', 'tecture', 'propose', 'call', 'clientside', 'load', 'tag', 'user', 'browser', 'recent', 'year', 'architecture', 'become', 'crippled', 'measure', 'take', 'browser', 'dor', 'many', 'popular', 'web', 'browser', 'safari', 'brave', 'already', 'actively', 'block', 'thirdparty', 'tracking', 'script', 'cookie', 'defend', 'user', 'web', 'tracking', 'moreover', 'plan', 'phase', 'thirdparty', 'cookie', 'chrome', 'render', 'lot', 'tag', 'rely', 'cookie', 'ineffective', 'result', 'alternative', 'version', 'tag', 'manager', 'create', 'officially', 'call', 'gtm', 'server', 'container', 'new', 'architecture', 'show', 'figure', 'load', 'execute', 'tag', 'remote', 'server', 'make', 'look', 'third', 'party', 'present', 'website', 'user', 'datum', 'collect', 'web', 'container', 'datum', 'flow', 'exit', 'browser', 'therefore', 'final', 'destination', 'datum', 'impossible', 'trace', 'researcher', 'auditor', 'analyze', 'outgoing', 'browser', 'request', 'architecture', 'call', 'serverside', 'bypass', 'browser', 'restriction', 'security', 'measure', 'control', 'secure', 'thirdparty', 'script', 'allow', 'tag', 'run', 'server', 'invisibly', 'share', 'user', 'datum', 'third', 'party', 'engelhard', 'measure', 'average', 'website', 'contain', 'thirdpartie', 'proceeding', 'privacy', 'enhance', 'technology', 'close', 'area', 'online', 'tracking', 'detection', 'measurement', 'legal', 'requirement', 'consent', 'online', 'tracking', 'nonacademic', 'literature', 'blog', 'post', 'regard', 'online', 'tracking', 'measurement', 'prevalence', 'work', 'detect', 'measured', 'web', 'tracking', 'practice', 'last', 'decade', 'identify', 'massive', 'prevalence', 'tracking', 'ecosystem', 'krishnamurthy', 'conduct', 'longitudinal', 'study', 'collection', 'aggregation', 'personal', 'datum', 'end', 'user', 'third', 'party', 'highlight', 'small', 'number', 'actor', 'tracking', 'ecosystem', 'rapid', 'growth', 'request', 'googleowned', 'server', 'observe', 'domain', 'analyze', 'thirdparty', 'http', 'request', 'alexa', 'top', 'site', 'libert', 'clude', 'track', 'user', 'site', 'englehardt', 'confirm', 'extent', 'track', 'e', 'conduct', 'automate', 'analysis', 'stateful', 'stateless', 'technique', 'site', 'show', 'detect', 'thirdparty', 'domain', 'fouad', 'et', 'firm', 'prevalence', 'find', 'presence', 'track', 'domain', 'website', 'tag', 'management', 'academic', 'research', 'appear', 'study', 'tag', 'management', 'system', 'date', 'however', 'several', 'people', 'close', 'adtech', 'circle', 'share', 'experience', 'publish', 'screenshot', 'analysis', 'tool', 'web', 'help', 'publisher', 'deployment', 'point', 'legal', 'cal', 'issue', 'digital', 'marketing', 'expert', 'fedorovicius', 'publish', 'course', 'ebook', 'website', 'analytic', 'mania', 'publish', 'howto', 'configure', 'serverside', 'summarize', 'essential', 'benefit', 'problem', 'technology', 'analytic', 'developer', 'test', 'com', 'ment', 'new', 'functionality', 'seo', 'digital', 'marketing', 'tool', 'maintain', 'extensive', 'documentation', 'recent', 'article', 'discuss', 'limitation', 'problem', 'regard', 'transparency', 'user', 'control', 'track', 'explore', 'surveillance', 'issue', 'web', 'publish', 'eral', 'article', 'web', 'tracking', 'technology', 'include', 'ga4', 'serverside', 'focus', 'implication', 'impact', 'content', 'blocker', 'number', 'book', 'publish', 'subject', 'gtm', 'attempt', 'guide', 'website', 'publisher', 'use', 'tool', 'cover', 'registration', 'configuration', 'tagging', 'integration', 'popular', 'cms', 'wordpress', 'summary', 'previous', 'work', 'focus', 'web', 'track', 'technology', 'general', 'describe', 'functionality', 'serverside', 'tag', 'management', 'recent', 'content', 'publish', 'industry', 'expert', 'identify', 'risk', 'privacy', 'however', 'work', 'far', 'seem', 'evaluate', 'leverage', 'deploy', 'offensive', 'configuration', 'scale', 'seem', 'assess', 'complexity', 'consent', 'management', 'publisher', 'gdpr', 'context', 'gap', 'work', 'aim', 'fill', 'study', 'internal', 'study', 'experiment', 'client', 'serverside', 'gtm', 'identify', 'component', 'work', 'typical', 'gtm', 'installation', 'goal', 'evaluate', 'user', 'datum', 'collect', 'actor', 'access', 'examine', 'clientside', 'b', 'serverside', 'figure', 'tag', 'management', 'architecture', 'red', 'arrow', 'represent', 'flow', 'user', 'datum', 'third', 'party', 'work', 'study', 'version', 'tag', 'manage', 'ment', 'architecture', 'client', 'serverside', 'differently', 'approach', 'measure', 'web', 'track', 'deploy', 'idea', 'toth', 'analyze', 'system', 'instal', 'empty', 'website', 'fully', 'con', 'trol', 'perform', 'separate', 'study', 'study', 'focus', 'internal', 'functioning', 'study', 'analyze', 'legal', 'implication', 'study', 'study', 'first', 'contribution', 'con', 'sist', 'methodology', 'build', 'analyze', 'internal', 'client', 'serverside', 'instal', 'tag', 'onebyone', 'popular', 'consent', 'banner', 'solution', 'allow', 'capture', 'script', 'injection', 'hide', 'datum', 'flow', 'study', 'permission', 'system', 'integrated', 'consent', 'mode', 'discover', 'technical', 'finding', 'clude', 'fact', 'tag', 'aim', 'ensure', 'communication', 'client', 'serverside', 'collect', 'multiple', 'type', 'user', 'datum', 'consent', 'pinter', 'tag', 'collect', 'significant', 'amount', 'user', 'datum', 'disclose', 'publisher', 'official', 'clientside', 'tag', 'inject', 'thirdparty', 'script', 'dom', 'bypass', 'gtm', 'permission', 'system', 'consent', 'mode', 'enable', 'consent', 'purpose', 'default', 'even', 'user', 'interact', 'consent', 'banner', 'write', 'together', 'legal', 'expert', 'co', 'author', 'paper', 'therein', 'explain', 'protection', 'legal', 'background', 'relevant', 'ecosystem', 'provide', 'indepth', 'legal', 'analysis', 'identify', 'legal', 'role', 'actor', 'detect', 'potential', 'violation', 'general', 'datum', 'protection', 'regulation', 'gdpr', 'eprivacy', 'directive', 'thereby', 'identify', 'actor', 'liability', 'finally', 'make', 'recommendation', 'far', 'improve', 'facilitate', 'legal', 'compliance', 'volved', 'actor', 'finally', 'discuss', 'potential', 'legal', 'implication', 'gtm', 'ecosystem', 'conclude', 'paper', 'relate', 'work', 'become', 'popular', 'tool', 'manage', 'tag', 'website', 'recent', 'year', 'however', 'good', 'knowledge', 'scientific', 'study', 'analyze', 'tag', 'manager', 'gtm', 'framework', 'partic', 'ular', 'client', 'serverside', 'tag', 'version', 'privacy', 'viewpoint', 'section', 'present', 'relate', 'work', 'web', 'container', 'tag', 'tag', 'b', 'tag', 'c', 'personnal', 'datum', 'server', 'container', 'tag', 'tag', 'b', 'tag', 'web', 'container', 'personnal', 'datum', 'tag', 'manager', 'hide', 'datum', 'leak', 'potential', 'violation', 'protection', 'law', 'proceeding', 'privacy', 'enhance', 'technology', 'consent', 'mode', 'toolset', 'render', 'compliant', 'order', 'assess', 'effectiveness', 'manage', 'consent', 'methodology', 'conduct', 'experiment', 'set', 'infrastructure', 'buy', 'domain', 'call', 'examplecom', 'create', 'public', 'website', 'contain', 'basic', 'webpage', 'paragraph', 'text', 'html', 'login', 'form', 'include', 'login', 'form', 'senol', 'recently', 'find', 'user', 'input', 'often', 'leak', 'form', 'decide', 'test', 'tag', 'responsible', 'leakage', 'website', 'serverside', 'infrastructure', 'host', 'virtual', 'machine', 'rent', 'azure', 'cloud', 'computing', 'platform', 'locate', 'datum', 'center', 'conduct', 'study', 'chromium', 'browser', 'version', 'repository', 'use', 'default', 'setting', 'instal', 'gnulinux', 'operating', 'system', 'kernel', 'version', 'lts', 'use', 'profile', 'functionality', 'browser', 'start', 'experiment', 'fresh', 'environment', 'devoid', 'cookie', 'local', 'storage', 'technology', 'maintain', 'state', 'browser', 'visit', 'website', 'run', 'computer', 'connect', 'internet', 'institutional', 'network', 'create', 'client', 'serverside', 'installation', 'create', 'new', 'account', 'log', 'follow', 'suggest', 'step', 'official', 'documentation', 'explain', 'installation', 'process', 'detail', 'note', 'term', 'use', 'slightly', 'differ', 'official', 'gtm', 'documentation', 'clarity', 'reason', 'clientside', 'select', 'tag', 'support', 'official', 'tag', 'directly', 'accessible', 'interface', 'website', 'publisher', 'nevertheless', 'community', 'developer', 'create', 'tag', 'service', 'officially', 'support', 'tag', 'available', 'gtmintegrate', 'template', 'gallery', 'understand', 'type', 'user', 'personal', 'datum', 'tag', 'collect', 'monitor', 'flow', 'clientside', 'installation', 'decide', 'select', 'test', 'tag', 'select', 'tag', 'decide', 'pick', 'representative', 'tag', 'typical', 'functionality', 'third', 'party', 'analyticsstatistic', 'advertisement', 'effectiveness', 'assessment', 'user', 'interaction', 'selection', 'procedure', 'focus', 'list', 'official', 'tag', 'inform', 'popularity', 'company', 'receive', 'datum', 'collect', 'tag', 'call', 'company', 'datum', 'collector', 'see', 'popularity', 'criterion', 'follow', 'ranking', 'popularity', 'third', 'party', 'accord', 'binn', 'measure', 'inclusion', 'third', 'party', 'website', 'select', 'tag', 'show', 'table', 'select', 'tag', 'function', 'properly', 'register', 'datum', 'collector', 'website', 'configure', 'tag', 'accord', 'instruction', 'instal', 'website', 'publisher', 'choose', 'configure', 'tag', 'include', 'website', 'generate', 'web', 'container', 'form', 'external', 'javascript', 'library', 'call', 'gtmj', 'contain', 'select', 'tag', 'copypaste', 'small', 'script', 'provide', 'website', 'source', 'page', 'prompt', 'browser', 'fetch', 'gtmj', 'script', 'capturing', 'script', 'injection', 'datum', 'flow', 'availability', 'collect', 'datum', 'manually', 'instal', 'officially', 'available', 'clarity', 'refer', 'hotjar', 'track', 'code', 'tag', 'hotjar', 'tag', 'tag', 'individually', 'web', 'container', 'open', 'website', 'new', 'browser', 'profile', 'analyze', 'traffic', 'use', 'chromium', 'debug', 'tool', 'tag', 'identify', 'additional', 'script', 'download', 'tag', 'select', 'table', '1a', 'inspect', 'get', 'parameter', 'post', 'body', 'datum', 'exchange', 'websocket', 'protocol', 'outgoing', 'request', 'identify', 'datum', 'collect', 'order', 'identify', 'personal', 'datum', 'collect', 'investigate', 'firstly', 'use', 'empirical', 'method', 'look', 'pair', 'get', 'parameter', 'json', 'datum', 'search', 'obvious', 'key', 'name', 'screenresolution', 'obvious', 'keyvalue', 'pair', 'sr1920x1080', 'fullhd', 'screen', 'secondly', 'use', 'available', 'documentation', 'tag', 'finally', 'log', 'datum', 'collector', 'website', 'search', 'personal', 'datum', 'previously', 'identify', 'compare', 'datum', 'identify', 'outgoing', 'request', 'tag', 'analytic', 'visit', 'report', 'page', 'conversion', 'section', 'click', 'event', 'history', 'page', 'hotjar', 'go', 'recording', 'page', 'see', 'individual', 'record', 'user', 'interaction', 'figure', 'summarize', 'analysis', 'method', 'tag', 'permission', 'system', 'nonofficial', 'tag', 'show', 'permission', 'tag', 'popup', 'review', 'confirm', 'installation', 'analyze', 'network', 'communication', 'browser', 'web', 'container', 'configuration', 'terface', 'template', 'gallery', 'section', 'find', 'json', 'file', 'contain', 'tag', 'information', 'display', 'interface', 'file', 'contain', 'information', 'tag', 'author', 'description', 'tag', 'link', 'source', 'code', 'tag', 'list', 'permis', 'sion', 'name', 'permission', 'configuration', 'setcookie', 'permission', 'configuration', 'cookie', 'name', 'correspond', 'official', 'documentation', 'official', 'tag', 'however', 'configuration', 'interface', 'show', 'permission', 'official', 'documentation', 'mention', 'permission', 'system', 'however', 'analyze', 'network', 'com', 'munication', 'browse', 'official', 'tag', 'section', 'find', 'similar', 'json', 'file', 'contain', 'list', 'permission', 'format', 'file', 'extract', 'list', 'tag', 'jectscript', 'permission', 'compare', 'actual', 'behavior', 'tag', 'regard', 'script', 'injection', 'conclude', 'official', 'tag', 'permission', 'system', 'similar', 'nonofficial', 'tag', 'consent', 'configuration', 'next', 'assist', 'legal', 'scholar', 'coauthor', 'paper', 'integrate', 'consent', 'management', 'website', 'way', 'compliant', 'legal', 'framework', 'use', 'gtm', 'consent', 'mode', 'feature', 'add', 'web', 'container', 'still', 'mark', 'beta', 'feature', 'uration', 'interface', 'writing', 'paper', 'consent', 'system', 'base', 'consent', 'variable', 'propose', 'ad', 'storage', 'analyticsstorage', 'functionalitystorage', 'sonalizationstorage', 'securitystorage', 'table', 'take', 'value', 'grant', 'deny', 'accord', 'documan', 'tation', 'find', 'variable', 'also', 'undefined', 'state', 'serious', 'consequence', 'see', 'technical', 'finding', 'sys', 'tem', 'consent', 'management', 'platform', 'cmp', 'provide', 'consent', 'banner', 'integrate', 'web', 'container', 'tag', 'cmp', 'communicate', 'user', 'consent', 'choice', 'make', 'consent', 'banner', 'express', 'consent', 'variable', 'web', 'con', 'tainer', 'interface', 'publisher', 'need', 'proceeding', 'privacy', 'enhance', 'technology', 'tag', 'name', 'rank', 'tag', 'datum', 'collector', 'tag', 'pinter', 'hotjar', 'track', 'code', 'hotjar', 'goal', 'servicetag', 'provide', 'statistic', 'user', 'behavior', 'website', 'measure', 'advertisement', 'cam', 'paign', 'effectiveness', 'become', 'pinterest', 'verify', 'merchant', 'provide', 'video', 'user', 'interac', 'tion', 'website', 'detect', 'bug', 'improve', 'website', 'tag', 'name', 'rank', 'analytic', 'ga4', 'conversion', 'api', 'tag', 'datum', 'collector', 'goal', 'servicetag', 'provide', 'statistic', 'user', 'behavior', 'website', 'facebook', 'measure', 'advertisement', 'cam', 'paign', 'effectiveness', 'provide', 'statistic', 'website', 'usage', 'mixpanel', 'mixpanel', 'gather', 'datum', 'user', 'interac', 'tion', 'website', 'gain', 'insight', 'behavior', 'clientside', 'tag', 'b', 'serverside', 'tag', 'table', 'tag', 'select', 'study', 'client', 'serverside', 'clientside', 'b', 'serverside', 'figure', 'pipeline', 'analysis', 'collect', 'datum', 'tag', 'behavior', 'client', 'serverside', 'associate', 'none', 'consent', 'variable', 'tag', 'accord', 'documentation', 'execute', 'tag', 'check', 'associate', 'consent', 'variable', 'proceed', 'con', 'send', 'variable', 'grant', 'otherwise', 'prevent', 'tag', 'run', 'tag', 'support', 'feature', 'call', 'builtin', 'consent', 'allow', 'execute', 'check', 'value', 'consent', 'variable', 'adapt', 'behavior', 'depend', 'ing', 'user', 'choice', 'trust', 'publisher', 'associate', 'consent', 'variable', 'tag', 'always', 'execute', 'test', 'cmp', 'mark', 'compatible', 'consent', 'mode', 'put', 'forward', 'interface', 'namely', 'consentmanager', 'cookiebot', 'include', 'scanner', 'detect', 'cookie', 'andor', 'track', 'technology', 'classify', 'tracker', 'associate', 'pose', 'far', 'analyze', 'scanner', 'section', 'cmp', 'create', 'account', 'website', 'let', 'cmp', 'scanner', 'scan', 'website', 'instal', 'cmp', 'tag', 'configuration', 'interface', 'consentmanager', 'accord', 'documentation', 'enable', 'send', 'consent', 'mode', 'setting', 'website', 'use', 'result', 'cmp', 'scanner', 'configure', 'consent', 'setting', 'tag', 'study', 'behavior', 'web', 'container', 'cmp', 'tag', 'visit', 'website', 'several', 'time', 'use', 'new', 'browser', 'profile', 'different', 'consent', 'option', 'consent', 'banner', 'time', 'accept', 'decline', 'analytic', 'advertisement', 'make', 'choice', 'stay', 'page', 'second', 'reload', 'use', 'second', 'use', 'debugger', 'provide', 'know', 'tag', 'run', 'browser', 'debugger', 'capture', 'outgoing', 'traffic', 'figure', 'finally', 'compare', 'collect', 'datum', 'case', 'datum', 'collect', 'consent', 'configuration', 'serverside', 'select', 'tag', 'similarly', 'clientside', 'select', 'tag', 'representative', 'func', 'tionalitie', 'third', 'party', 'analyticsstatistic', 'advertisement', 'effec', 'tiveness', 'assessment', 'user', 'interaction', 'officially', 'support', 'tag', 'related', 'service', 'select', 'analytic', 'template', 'gallery', 'developer', 'propose', 'additional', 'nonofficially', 'support', 'tag', 'remain', 'functionality', 'interested', 'choose', 'popular', 'one', 'base', 'ranking', 'datum', 'collector', 'binn', 'namely', 'conversion', 'api', 'mixpanel', 'table', 'also', 'observe', 'template', 'gallery', 'company', 'provide', 'tag', 'call', 'tag', 'provider', 'see', 'datum', 'collector', 'necessarily', 'gtm', 'server', 'container', 'installation', 'interface', 'publisher', 'create', 'gtm', 'server', 'container', 'nodejs', 'program', 'run', 'server', 'contain', 'particular', 'select', 'server', 'tag', 'option', 'propose', 'automatic', 'provisioning', 'https', 'web', 'container', 'gtmj', 'user', 'datum', 'user', 'datum', 'pinterest', 'tag', 'user', 'datum', 'tag', 'consent', 'variable', 'accept', 'click', 'deny', 'collector', 'analytic', 'user', 'statistic', 'pinterest', 'number', 'click', 'record', 'user', 'session', 'https', 'web', 'container', 'gtmj', 'user', 'datum', 'tag', 'collector', 'tag', 'consent', 'variable', 'consent', 'server', 'container', 'web', 'container', 'client', 'adaptor', 'ga4', 'client', 'adaptor', 'server', 'instrum', 'entation', 'conversion', 'api', 'mixpanel', 'googletag', 'managercom', 'datum', 'collector', 'user', 'user', 'user', 'datum', 'tag', 'manager', 'hide', 'datum', 'leak', 'potential', 'violation', 'protection', 'law', 'proceeding', 'privacy', 'enhance', 'technology', 'automatically', 'install', 'server', 'container', 'server', 'manual', 'installation', 'publisher', 'provide', 'server', 'choose', 'manual', 'installation', 'total', 'control', 'server', 'able', 'analyze', 'server', 'container', 'incoming', 'outgoing', 'information', 'flow', 'use', 'provide', 'docker', 'image', 'configure', 'server', 'container', 'accessible', 'ing', 'https', 'finally', 'create', 'aaaa', 'dns', 'record', 'subdomain', 'pointing', 'server', 'avoid', 'use', 'cname', 'record', 'recommend', 'provide', 'configuration', 'file', 'setup', 'artifact', 'connection', 'browser', 'server', 'container', 'connect', 'browser', 'server', 'container', 'collect', 'end', 'user', 'datum', 'first', 'create', 'new', 'web', 'container', 'figure', '2b', 'follow', 'gtm', 'documentation', 'instal', 'tag', 'web', 'container', 'specify', 'server', 'container', 'transporturl', 'field', 'tag', 'configuration', 'instruct', 'tag', 'send', 'collect', 'datum', 'server', 'container', 'instead', 'server', 'default', 'behavior', 'tag', 'tag', 'call', 'collector', 'tag', 'server', 'container', 'component', 'call', 'client', 'adaptor', 'receive', 'data', 'decode', 'make', 'available', 'server', 'tag', 'client', 'adaptor', 'need', 'compatible', 'collector', 'tag', 'use', 'default', 'ga4', 'client', 'simply', 'ga4', 'preinstalle', 'server', 'container', 'compatible', 'collector', 'tag', 'capture', 'traffic', 'browser', 'visit', 'website', 'new', 'browser', 'profile', 'use', 'chromium', 'debug', 'tool', 'capture', 'traf', 'fic', 'collector', 'tag', 'client', 'adaptor', 'analyze', 'outgoing', 'traffic', 'similarly', 'clientside', 'study', 'capturing', 'datum', 'flow', 'availability', 'collect', 'datum', 'analyze', 'outgoing', 'traffic', 'server', 'container', 'mente', 'server', 'capture', 'network', 'exchange', 'decrypt', 'start', 'interpreter', 'run', 'server', 'container', 'tlskeylog', 'option', 'option', 'struct', 'nodejs', 'export', 'encryption', 'key', 'use', 'wireshark', 'collect', 'traffic', 'import', 'encryption', 'key', 'previously', 'port', 'decrypt', 'similarly', 'clientside', 'experiment', 'identify', 'datum', 'send', 'server', 'tag', 'data', 'collector', 'use', 'server', 'instrumentation', 'finally', 'compare', 'observation', 'datum', 'item', 'visible', 'website', 'receive', 'user', 'data', 'consent', 'management', 'assess', 'ease', 'make', 'server', 'side', 'gtm', 'architecture', 'gdprcompliant', 'search', 'official', 'documentation', 'matter', 'find', 'relatively', 'basic', 'page', 'order', 'concrete', 'result', 'add', 'cmp', 'web', 'container', 'choose', 'cookiebot', 'compatible', 'consent', 'mode', 'clientside', 'serverside', 'mention', 'map', 'well', 'consent', 'variable', 'see', 'table', 'observe', 'behavior', 'server', 'tag', 'accord', 'enduser', 'consent', 'use', 'traffic', 'analysis', 'method', 'figure', 'clientside', 'hotjar', 'tag', 'download', 'ar', 'bitrary', 'script', 'inject', 'page', 'result', 'section', 'present', 'finding', 'client', 'server', 'side', 'select', 'tag', 'consent', 'mode', 'technical', 'finding', 'hide', 'datum', 'leak', 'tag', 'client', 'serverside', 'analyze', 'datum', 'send', 'tag', 'compare', 'datum', 'visible', 'publisher', 'datum', 'website', 'find', 'certain', 'datum', 'collector', 'show', 'datum', 'collect', 'table', 'show', 'datum', 'send', 'tag', 'test', 'clientside', 'installation', 'consent', 'solution', 'observe', 'datum', 'send', 'pinterest', 'tag', 'visible', 'publisher', 'pinterest', 'website', 'log', 'observe', 'disclosure', 'collect', 'datum', 'moreover', 'find', 'datum', 'collect', 'tag', 'form', 'interaction', 'show', 'dashboard', 'finding', 'demonstrate', 'tag', 'publisher', 'aware', 'datum', 'collect', 'tag', 'select', 'serverside', 'table', 'show', 'datum', 'send', 'select', 'tag', 'similarly', 'collect', 'datum', 'visible', 'publisher', 'datum', 'collector', 'website', 'analytic', 'tag', 'collect', 'datum', 'interaction', 'form', 'truncated', 'ip', 'address', 'end', 'user', 'none', 'show', 'publisher', 'analytic', 'report', 'page', 'mixpanel', 'receive', 'complete', 'ip', 'address', 'end', 'user', 'visit', 'webpage', 'show', 'publisher', 'find', 'serverside', 'ip', 'address', 'collection', 'necessarily', 'deliberate', 'require', 'client', 'adaptor', 'copy', 'ip', 'address', 'browser', 'packet', 'datum', 'share', 'server', 'tag', 'ga4', 'client', 'adaptor', 'case', 'mixpanel', 'conversion', 'api', 'moreover', 'tag', 'send', 'ip', 'address', 'receive', 'ga4', 'mixpanel', 'facebook', 'finally', 'facebook', 'allow', 'review', 'collect', 'datum', 'create', 'new', 'account', 'flag', 'suspicious', 'block', 'access', 'datum', 'collection', 'dashboard', 'therefore', 'client', 'serverside', 'hide', 'datum', 'leak', 'raise', 'transparency', 'concern', 'publisher', 'aware', 'datum', 'collection', 'implication', 'select', 'particular', 'tag', 'far', 'analyze', 'legal', 'implication', 'section', 'artifact', 'responsible', 'disclosure', 'artifact', 'associate', 'work', 'available', 'anonymous', 'repository', 'addition', 'ally', 'responsible', 'disclosure', 'progress', 'one', 'consentmanager', 'cmp', 'update', 'add', 'article', 'case', 'feedback', 'company', 'technical', 'finding', 'clientside', 'tag', 'insert', 'script', 'full', 'access', 'browser', 'apis', 'page', 'dom', 'web', 'container', 'tag', 'run', 'sandbox', 'restrict', 'ite', 'set', 'javascript', 'functionality', 'sandbox', 'imple', 'ment', 'gtm', 'permission', 'system', 'control', 'tag', 'access', 'browser', 'feature', 'set', 'cookie', 'collect', 'datum', 'browser', 'visit', 'web', 'container', 'gtmj', 'hotjar', 'user', 'script', 'proceeding', 'privacy', 'enhance', 'technology', 'datum', 'hotjar', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', 'url', 'current', 'page', 'browser', 'version', 'screen', 'dimension', 'computer', 'architecture', 'operating', 'system', 'version', 'engagement', 'time', 'prefer', 'language', 'title', 'current', 'page', 'number', 'visit', 'form', 'interact', 'scroll', 'action', 'browser', 'window', 'size', 'click', 'position', 'type', 'form', 'submit', 'form', 'precise', 'mouse', 'move', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', 'clientside', 'experiment', 'conversion', 'api', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', 'datum', 'address', 'user', 'current', 'page', 'browser', 'version', 'screen', 'dimension', 'computer', 'architecture', 'operating', 'system', 'version', 'engagement', 'time', 'prefer', 'language', 'title', 'current', 'page', 'number', 'visit', 'form', 'interact', 'lytic', '✓', 'trun', 'cat', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', '✓', 'b', 'serverside', 'experiment', 'note', 'analytic', 'trun', 'cat', 'last', 'byte', 'ip', 'address', 'claim', 'anonymize', 'table', 'datum', 'collect', 'tag', 'indicate', 'data', 'type', 'collect', 'datum', 'collector', 'make', 'visible', 'publisher', 'collector', 'website', 'indicate', 'data', 'type', 'collect', 'visible', 'indicate', 'send', 'block', 'account', 'browser', 'permission', 'call', 'inject', 'script', 'allow', 'tag', 'download', 'execute', 'arbitrary', 'script', 'web', 'container', 'tag', 'grant', 'injectscript', 'permission', 'inject', 'arbitrary', 'script', 'thus', 'bypass', 'gtm', 'permission', 'system', 'control', 'access', 'ture', 'access', 'browser', 'apis', 'dom', 'origin', 'accord', 'sameorigin', 'policy', 'analyze', 'officially', 'support', 'clientside', 'tag', 'find', 'tag', 'inject', 'script', 'figure', 'illustrate', 'hotjar', 'tag', 'inject', 'script', 'examplecom', 'page', 'sion', 'system', 'hotjar', 'tag', 'permission', 'read', 'write', 'global', 'javascript', 'variable', 'inject', 'script', 'find', 'collect', 'datum', 'show', 'table', 'include', 'datum', 'access', 'sandbox', 'precise', 'mouse', 'movement', 'surprisingly', 'find', 'tag', 'gtm', 'permission', 'system', 'inject', 'script', 'way', 'hotjar', 'technical', 'finding', 'gtm', 'permission', 'system', 'allow', 'injection', 'arbitrary', 'script', 'analyze', 'presence', 'injectscript', 'permission', 'clientside', 'tag', 'detect', 'tag', 'permission', 'still', 'inject', 'arbitrary', 'script', 'tag', 'tag', 'provide', 'google5', 'finding', 'show', 'gtm', 'permission', 'system', 'implement', 'web', 'container', 'sandbox', 'allow', 'tag', 'insert', 'arbitrary', 'uncontrolled', 'script', 'thus', 'open', 'potential', 'security', 'privacy', 'vulnerability', 'ad', 'analytic', 'survey', 'tag', 'g', 'trust', 'store', 'full', 'list', 'script', 'available', 'supplemental', 'material', 'tag', 'tag', 'ad', 'call', 'website', 'conversion', 'ad', 'conversion', 'track', 'ad', 'remarkete', 'analytic', 'classic', 'analytic', 'ga4', 'event', 'analytic', 'universal', 'analytic', 'tag', 'eulerian', 'analytic', 'lytic', 'tag', 'tradedoubler', 'lead', 'conversion', 'tradedoubler', 'sale', 'conversion', 'website', 'disclose', 'finding', 'google', 'bug', 'bounty', 'online', 'system', 'technical', 'finding', 'say', 'agree', 'unde', 'fine', 'consent', 'variable', 'grant', 'default', 'experi', 'ment', 'consent', 'mode', 'cmp', 'clientside', 'see', 'find', 'consent', 'variable', 'undefined', 'state', 'cmp', 'load', 'webpage', 'cmp', 'expect', 'set', 'default', 'value', 'variable', 'find', 'cmp', 'explicitly', 'surprisingly', 'case', 'consider', 'undefined', 'variable', 'accept', 'end', 'user', 'even', 'end', 'user', 'interact', 'consent', 'banner', 'cmp', 'yet', 'cmp', 'test', 'see', 'detect', 'behavior', 'consentmanager', 'cmp', 'cmp', 'set', 'default', 'value', 'consent', 'variable', 'analyticsstorage', 'adstorage', 'leave', 'gtm', 'consent', 'variable', 'security', 'storage', 'personalizationstorage', 'functionalitystorage', 'consent', 'variable', 'specific', 'cmp', 'cmppurposec56', 'correspond', 'social', 'medium', 'purpose', 'undefined', 'state', 'extra', 'variable', 'hence', 'consider', 'grant', 'result', 'tag', 'depend', 'consent', 'variable', 'execute', 'even', 'user', 'consent', 'note', 'default', 'behavior', 'undefined', 'variable', 'change', 'discuss', 'legal', 'implication', 'potential', 'violation', 'technical', 'find', 'datum', 'collect', 'tag', 'consent', 'builtin', 'consent', 'tag', 'always', 'execute', 'aware', 'consent', 'choice', 'user', 'adapt', 'behavior', 'collect', 'datum', 'relate', 'purpose', 'refuse', 'end', 'user', 'test', 'tag', 'builtin', 'consent', 'various', 'consent', 'decision', 'accept', 'decline', 'analytic', 'advertisement', 'find', 'tag', 'always', 'tag', 'manager', 'hide', 'datum', 'leak', 'potential', 'violation', 'protection', 'law', 'proceeding', 'privacy', 'enhance', 'technology', 'send', 'user', 'datum', 'show', 'table', '2a', 'independently', 'user', 'consent', 'choice', 'find', 'gtm', 'documentation', 'adstorage', 'analyticsstorage', 'builtin', 'consent', 'variable', 'refuse', 'datum', 'collect', 'never', 'use', 'track', 'individual', 'user', 'app', 'website', 'build', 'remarkete', 'list', 'generate', 'user', 'profile', 'technical', 'finding', 'lack', 'consent', 'tool', 'serverside', 'contrary', 'web', 'container', 'server', 'container', 'ration', 'interface', 'provide', 'consent', 'configuration', 'tool', 'association', 'consent', 'variable', 'tag', 'however', 'find', 'value', 'consent', 'variable', 'adstorage', 'analyt', 'icsstorage', 'send', 'server', 'container', 'provide', 'server', 'tag', 'documentation', 'consent', 'server', 'container', 'tell', 'product', 'tag', 'server', 'consentaware', 'adjust', 'amount', 'kind', 'datum', 'send', 'base', 'user', 'preference', 'deduce', 'server', 'tag', 'implement', 'similar', 'mechanism', 'builtin', 'consent', 'however', 'publisher', 'see', 'consent', 'variable', 'tag', 'change', 'behavior', 'finally', 'tag', 'test', 'find', 'decline', 'consent', 'impact', 'transmission', 'data', 'item', 'identify', 'table', 'study', 'legal', 'analysis', 'gtm', 'section', 'write', 'together', 'legal', 'expert', 'coauthor', 'first', 'explain', 'legal', 'background', 'protection', 'law', 'relevant', 'ecosystem', 'provide', 'legal', 'analysis', 'identify', 'legal', 'role', 'actor', 'crucial', 'evaluation', 'actor', 'compliance', 'liability', 'recital', 'legal', 'background', 'general', 'datum', 'protection', 'regulation', 'gdpr', 'apply', 'processing', 'personal', 'datum', 'impose', 'obligation', 'actor', 'process', 'pair', 'heavy', 'fine', 'noncompliance', 'eprivacy', 'directive', 'epd', 'provide', 'supplementary', 'rule', 'gdpr', 'particular', 'use', 'track', 'technology', 'ever', 'cookie', 'tracking', 'technology', 'store', 'read', 'user', 'device', 'art5', 'require', 'organiza', 'tion', 'request', 'consent', 'storage', 'tracker', 'certain', 'purpose', 'process', 'datum', 'advertising', 'pur', 'pose', 'exempt', 'consent', 'functional', 'technical', 'purpose', 'require', 'website', 'request', 'user', 'operate', 'recital', 'way', 'assess', 'certainty', 'consent', 'require', 'analyze', 'purpose', 'tracker', 'give', 'website', 'personal', 'datum', 'information', 'relate', 'identified', 'identifiable', 'natural', 'person', 'datum', 'subject', 'identifiable', 'nat', 'ural', 'person', 'identify', 'directly', 'indirectly', 'art4', 'order', 'determine', 'person', 'identifiable', 'account', 'take', 'mean', 'likely', 'reasonably', 'use', 'actor', 'identify', 'person', 'accordingly', 'certain', 'datum', 'alone', 'personal', 'datum', 'become', 'personal', 'datum', 'regard', 'reasonably', 'mean', 'enable', 'datum', 'associate', 'specific', 'person', 'para', 'gdpr', 'recital', 'assert', 'online', 'identifier', 'provide', 'device', 'ip', 'address', 'associate', 'person', 'thus', 'make', 'identi', 'fiable', 'identification', 'require', 'information', 'enable', 'person', 'identify', 'hand', 'single', 'entity', 'para', 'processing', 'personal', 'datum', 'consist', 'operation', 'perform', 'personal', 'datum', 'collect', 'sharing', 'use', 'make', 'available', 'accessing', 'combine', 'article', 'practice', 'mean', 'almost', 'imaginable', 'handling', 'personal', 'datum', 'constitute', 'process', 'datum', 'controller', 'data', 'processor', 'accord', 'european', 'board', 'edpb', 'opinion', 'determine', 'actor', 'data', 'controller', 'factual', 'role', 'activity', 'evaluate', 'specific', 'situation', 'actor', 'data', 'controller', 'responsible', 'determine', 'purpose', 'mean', 'processing', 'personal', 'datum', 'art', 'determine', 'mean', 'decisionmake', 'power', 'independent', 'control', 'purpose', 'mean', 'processing', 'court', 'justice', 'cjeu', 'datum', 'protection', 'authority', 'dpas', 'edpb', 'describe', 'control', 'derive', 'professional', 'competence', 'legal', 'plicit', 'factual', 'influence', 'base', 'real', 'circumstance', 'round', 'processing', 'image', 'give', 'data', 'subject', 'reasonable', 'expectation', 'basis', 'visibility', 'tor', 'organize', 'coordinate', 'encourage', 'datum', 'processing', 'para', 'interpretation', 'independent', 'judgement', 'exercise', 'form', 'professional', 'service', 'purpose', 'refer', 'datum', 'process', 'purpose', 'need', 'explicit', 'specify', 'legitimate', 'art', 'b', 'mean', 'refer', 'objective', 'process', 'achieve', 'edpb', 'distinguishe', 'essential', 'nonessential', 'mean', 'provide', 'example', 'thereof', 'sential', 'mean', 'closely', 'link', 'purpose', 'scope', 'processing', 'inherently', 'reserve', 'controller', 'ex', 'ample', 'essential', 'mean', 'determine', 'type', 'personal', 'datum', 'process', 'duration', 'processing', 'recipient', 'personal', 'datum', 'category', 'data', 'subject', 'nonessential', 'mean', 'gate', 'data', 'processor', 'involve', 'practical', 'implementation', 'hardware', 'software', 'selection', 'security', 'measure', 'datum', 'storageretrieval', 'method', 'actor', 'data', 'processor', 'process', 'personal', 'datum', 'behalf', 'data', 'controller', 'art', 'actor', 'processor', 'dependent', 'controller', 'instruction', 'regard', 'ing', 'processing', 'activity', 'art', 'recital', 'comply', 'instruction', 'joint', 'controllership', 'controller', 'jointly', 'determine', 'purpose', 'mean', 'processing', 'joint', 'controller', 'art', 'joint', 'participation', 'take', 'form', 'common', 'converging', 'decision', 'purpose', 'essen', 'tial', 'mean', 'decision', 'consider', 'converging', 'complement', 'necessary', 'processing', 'take', 'place', 'manner', 'tangible', 'impact', 'determination', 'purpose', 'mean', 'processing', 'important', 'criterion', 'identify', 'converging', 'decision', 'processing', 'possible', 'party', 'participation', 'sense', 'processing', 'party', 'inseparable', 'inextricably', 'link', 'joint', 'controllership', 'require', 'agreement', 'pursuant', 'gdpr', 'article', 'however', 'requirement', 'party', 'share', 'responsibility', 'equally', 'para', 'similarly', 'data', 'controller', 'party', 'need', 'access', 'personal', 'datum', 'consider', 'controller', 'para', 'proceeding', 'privacy', 'enhance', 'technology', 'gdpr', 'obligation', 'datum', 'controller', 'datum', 'processor', 'actor', 'establish', 'data', 'processor', 'hold', 'liable', 'fine', 'fail', 'comply', 'obligation', 'gdpr', 'art', 'compliance', 'gdpr', 'enforce', 'protection', 'authority', 'dpas', 'monitor', 'super', 'vise', 'application', 'gdpr', 'art5557', 'datum', 'controller', 'comply', 'follow', 'principle', 'purpose', 'limitation', 'collect', 'personal', 'datum', 'specific', 'detailed', 'explicit', 'purpose', 'far', 'process', 'patible', 'purpose', 'art', 'b', 'minimization', 'collect', 'personal', 'datum', 'adequate', 'relevant', 'limited', 'necessary', 'relation', 'purpose', 'datum', 'process', 'art', 'c', 'lawfulness', 'collect', 'personal', 'datum', 'legitimize', 'legal', 'basis', 'art', 'case', 'legal', 'basis', 'consent', 'consent', 'prior', 'datum', 'collec', 'tion', 'freely', 'give', 'specific', 'informed', 'unambiguous', 'readable', 'accessible', 'revocable', 'art4', 'art', 'transparency', 'collect', 'personal', 'datum', 'inform', 'end', 'user', 'purpose', 'third', 'party', 'recipient', 'legal', 'basis', 'information', 'art', 'security', 'ensure', 'appropriate', 'security', 'personal', 'datum', 'include', 'protection', 'unauthorized', 'unlawful', 'pro', 'cesse', 'art', 'f', 'datum', 'protection', 'default', 'ensure', 'personal', 'datum', 'pro', 'cesse', 'high', 'privacy', 'protection', 'default', 'personal', 'datum', 'make', 'accessible', 'indefinite', 'number', 'person', 'art', 'accountability', 'art5', 'controller', 'able', 'demonstrate', 'compliance', 'principle', 'time', 'legal', 'analysis', 'clientside', 'section', 'analyze', 'role', 'actor', 'involve', 'client', 'side', 'provider', 'cmp', 'datum', 'collector', 'tag', 'provider', 'raise', 'potential', 'violation', 'gdpr', 'eprivacy', 'directive', 'start', 'legal', 'analysis', 'identify', 'gtm', 'actor', 'process', 'personal', 'datum', 'accord', 'result', 'provider', 'datum', 'collector', 'process', 'ip', 'address', 'end', 'user', 'receive', 'incoming', 'http', 'request', 'server', 'follow', 'argument', 'santo', 'ip', 'address', 'combine', 'additional', 'user', 'datum', 'ip', 'address', 'receiver', 'mean', 'information', 'reasonably', 'likely', 'indirectly', 'render', 'user', 'identifiable', 'recital', 'publisher', 'role', 'trigger', 'potential', 'violation', 'refer', 'role', 'figure', 'depict', 'gtm', 'actor', 'relationship', 'consent', 'management', 'platform', 'cmp', 'website', 'pub', 'select', 'cmp', 'manage', 'endus', 'consent', 'see', 'step', 'figure', 'integrate', 'consent', 'banner', 'need', 'compatible', 'consent', 'mode', 'cmp', 'test', 'study', 'consentmanager', 'cookiebot', 'offer', 'scanning', 'service', 'automatically', 'detect', 'cookie', 'publisher', 'website', 'third', 'party', 'cookie', 'share', 'fig3', 'scanner', 'classify', 'third', 'party', 'associate', 'purpose', 'consent', 'variable', 'adstorage', 'analyticsstorage', 'functionality', 'storage', 'personalization', 'storage', 'securitystorage', 'description', 'provide', 'enable', 'storage', 'cookie', 'late', 'advertising', 'enable', 'storage', 'cookie', 'late', 'analytic', 'eg', 'visit', 'duration', 'enable', 'storage', 'support', 'func', 'tionality', 'website', 'guage', 'setting', 'enable', 'storage', 'relate', 'personaliza', 'tion', 'video', 'recommendation', 'enable', 'storage', 'relate', 'security', 'authentication', 'functionality', 'fraud', 'prevention', 'user', 'protection', 'table', 'gtm', 'consent', 'variable', 'description', 'determination', 'purpose', 'scan', 'activity', 'cmp', 'extract', 'purpose', 'tracker', 'publisher', 'web', 'site', 'show', 'step', 'figure', 'read', 'provide', 'scan', 'report', 'publisher', 'configure', 'purpose', 'tag', 'interface', 'show', 'step', 'figure', 'publisher', 'determine', 'purpose', 'process', 'together', 'cmp', 'help', 'notably', 'cmp', 'argue', 'recognize', 'data', 'controller', 'follow', 'argument', 'santo', 'section', 'posit', 'final', 'decision', 'need', 'purpose', 'tag', 'question', 'converging', 'decision', 'publisher', 'cmp', 'see', 'decision', 'hire', 'cmp', 'publisher', 'identify', 'purpose', 'complement', 'necessary', 'processing', 'take', 'place', 'therefore', 'decision', 'joint', 'decision', 'publisher', 'cmp', 'tangible', 'impact', 'determination', 'purpose', 'processing', 'determination', 'mean', 'cmp', 'provide', 'service', 'tooling', 'consent', 'management', 'scan', 'cmp', 'define', 'mean', 'process', 'legal', 'role', 'publisher', 'cmp', 'joint', 'data', 'controller', 'potential', 'violation', 'cmp', 'scanner', 'often', 'miss', 'purpose', 'experimentation', 'clientside', 'see', 'instal', 'tag', 'contain', 'specific', 'builtin', 'purpose', 'adstorage', 'analyticsstorage', 'find', 'cookiebot', 'consentmanager', 'scanner', 'run', 'report', 'analytic', 'purpose', 'miss', 'advertising', 'purpose', 'tag', 'publisher', 'rely', 'scanner', 'read', 'datum', 'collector', 'term', 'condition', 'face', 'risk', 'misconfigure', 'consent', 'requirement', 'tag', 'furthermore', 'thirdparty', 'cookie', 'phase', 'major', 'browser', 'cmp', 'scanner', 'rely', 'cookie', 'scan', 'cookiebot', 'risk', 'underreporte', 'purpose', 'instal', 'tag', 'demonstrate', 'recommendation', 'cmp', 'provide', 'comprehensive', 'scanning', 'service', 'include', 'purpose', 'stateless', 'stateful', 'tracking', 'technology', 'avoid', 'provide', 'scanner', 'relatedly', 'recommend', 'provide', 'cmppublisher', 'list', 'tag', 'instal', 'web', 'server', 'container', 'cmp', 'able', 'reliably', 'detect', 'datum', 'collector', 'map', 'purpose', 'tag', 'tag', 'manager', 'hide', 'datum', 'leak', 'potential', 'violation', 'protection', 'law', 'proceeding', 'privacy', 'enhance', 'technology', 'figure', 'clientside', 'configuration', 'publisher', 'usage', 'end', 'user', 'cookiebot', 'purpose', 'statistic', 'market', 'necessary', 'preference', 'consent', 'variable', 'analyticsstorage', 'adstorage', 'securitystorage', 'personalizationstorage', 'functionalitystorage', 'table', 'cookiebot', 'purpose', 'correspond', 'gtm', 'consent', 'variable', 'potential', 'violation', 'mapping', 'cmp', 'purpose', 'gtm', 'send', 'variable', 'compliant', 'cmp', 'need', 'map', 'send', 'variable', 'purpose', 'show', 'consent', 'banner', 'tably', 'mapping', 'document', 'anywhere', 'cmp', 'furthermore', 'mapping', 'subject', 'legal', 'issue', 'identify', 'potential', 'violation', 'instal', 'cookiebot', 'consentmanager', 'cmp', 'claim', 'compatible', 'website', 'infer', 'mapping', 'purpose', 'present', 'table', 'herein', 'report', 'several', 'problem', 'concern', 'mapping', 'first', 'cmp', 'use', 'different', 'name', 'purpose', 'rather', 'one', 'use', 'example', 'consent', 'variable', 'analyticsstorage', 'call', 'statistic', 'cook', 'measurement', 'consentmanager', 'publisher', 'aware', 'purpose', 'measurement', 'consentman', 'ager', 'banner', 'correspond', 'analyticsstorage', 'consent', 'variable', 'interface', 'difficulty', 'configure', 'tag', 'depend', 'purpose', 'second', 'certain', 'cmp', 'merge', 'purpose', 'altogether', 'display', 'table', 'gtm', 'consent', 'variable', 'functionalitystorage', 'personalizationstor', 'age', 'merge', 'category', 'call', 'preference', 'publisher', 'know', 'preference', 'purpose', 'cookiebot', 'refer', 'different', 'purpose', 'personaliza', 'tionstorage', 'functionalitystorage', 'third', 'exper', 'iment', 'ascertain', 'consentmanager', 'partially', 'map', 'purpose', 'gtm', 'consent', 'variable', 'display', 'table', 'consentmanager', 'map', 'purpose', 'adstorage', 'consent', 'variable', 'user', 'agree', 'marketing', 'purpose', 'show', 'consent', 'banner', 'default', 'consent', 'variable', 'associate', 'marketing', 'purpose', 'new', 'variable', 'include', 'default', 'create', 'pub', 'lisher', 'aware', 'lack', 'mapping', 'need', 'configure', 'consent', 'variable', 'tag', 'instance', 'mean', 'publisher', 'use', 'personalizationstorage', 'variable', 'configure', 'tag', 'see', 'tag', 'always', 'run', 'independently', 'user', 'choice', 'see', 'technical', 'find', 'recommendation', 'recommend', 'cmp', 'agree', 'purpose', 'name', 'description', 'matching', 'purpose', 'gtm', 'provider', 'actor6', 'provide', 'gtm', 'service', 'tag', 'management', 'functionality', 'website', 'publisher', 'determination', 'purpose', 'actor', 'involve', 'deter', 'mination', 'purpose', 'reason', 'first', 'define', 'default', 'consent', 'variable', 'gtm', 'consent', 'mode', 'adstorage', 'securitystorage', 'functionalitystorage', 'personalizationstorage', 'present', 'table', 'claim', 'consent', 'variable', 'correspond', 'personal', 'data', 'process', 'purpose', 'meaning', 'article', 'b', 'gdpr', 'publisher', 'need', 'associate', 'tag', 'mention', 'purpose', 'purpose', 'builtin', 'second', 'argue', 'organize', 'coordinate', 'datum', 'process', 'provider', 'time', 'experiment', 'identify', 'analytic', 'collector', 'associate', 'select', 'install', 'pinterest', 'tag', 'web', 'container', 'configuration', 'interface', 'website', 'consent', 'variable', 'purpose', 'tag', 'web', 'container', 'gtmj', 'provide', 'provider', 'adstorage', 'analyticsstorage', 'functionnalitystorage', 'personalizationstorage', 'securitystorage', 'tag', 'extract', 'purpose', 'social', 'medium', 'purpose', 'builtin', 'consent', 'adstorage', 'analyticsstorage', 'configure', 'purpose', 'pinterest', 'tag', 'purpose', 'extract', 'run', 'cmp', 'scanner', 'extract', 'purpose', 'pinterest', 'tag', 'cmp', 'scanner', 'publisher', 'select', 'cmp', 'enduser', 'provide', 'tag', 'consent', 'adstorage', 'send', 'data1', 'collector', 'analyticsstorage', 'send', 'data2', 'collector', 'else', 'send', 'data3', 'collector', 'pinterest', 'tag', 'builtin', 'consent', 'code', 'invoke', 'consent', 'acceptsreject', 'consent', 'banner', 'configure', 'cmp', 'purpose', 'identify', 'pinterest', 'collector', 'associate', 'tag', 'extract', 'purpose', 'pinterest', 'collector', 'collector', 'term', 'condition', 'data', 'provide', 'tag', 'code', 'tag', 'provider', 'tag', 'provide', 'tag', 'code', 'tag', 'provider', 'pinterest', 'tag', 'datum', 'pinterest', 'collector', 'term', 'condition', 'social', 'medium', 'purpose', 'proceeding', 'privacy', 'enhance', 'technology', 'paragraph', 'enable', 'orchestration', 'datum', 'collec', 'tion', 'share', 'several', 'actor', 'publisher', 'tag', 'provider', 'datum', 'collector', 'hence', 'provider', 'platform', 'placeholder', 'coordinate', 'tag', 'collect', 'datum', 'also', 'encourage', 'datum', 'processing', 'propose', 'tag', 'publisher', 'determination', 'mean', 'provider', 'generate', 'web', 'con', 'tainer', 'provide', 'configuration', 'interface', 'pub', 'lisher', 'container', 'component', 'eg', 'tag', 'determine', 'nonessential', 'mean', 'datum', 'process', 'legal', 'role', 'provider', 'gtm', 'service', 'data', 'controller', 'potential', 'violation', 'purpose', 'limit', 'client', 'side', 'storage', 'consent', 'variable', 'definition', 'gtm', 'table', 'storagebase', 'technology', 'explicitly', 'store', 'information', 'user', 'terminal', 'equipment', 'know', 'stateless', 'technology', 'browser', 'hence', 'exclude', 'therefore', 'cover', 'provider', 'default', 'mean', 'publisher', 'install', 'give', 'tag', 'interface', 'use', 'stateless', 'technology', 'cover', 'purpose', 'define', 'therefore', 'way', 'publisher', 'compliant', 'eprivacy', 'directive', 'use', 'stateless', 'tracking', 'technology', 'web', 'container', 'directive', 'require', 'consent', 'nonnecessary', 'purpose', 'tracking', 'technology', 'reason', 'publisher', 'tag', 'provider', 'decide', 'include', 'builtin', 'consent', 'become', 'confused', 'mapping', 'consent', 'variable', 'tag', 'limitation', 'ensure', 'compliance', 'website', 'tag', 'use', 'stateless', 'technology', 'require', 'consent', 'recommendation', 'gtm', 'define', 'purpose', 'regardless', 'type', 'technology', 'use', 'stateless', 'stateful', 'potential', 'violation', 'purpose', 'specific', 'explicit', 'provider', 'data', 'controller', 'oblige', 'pro', 'vide', 'specific', 'detailed', 'explicit', 'purpose', 'accord', 'gdpr', 'purpose', 'limitation', 'principle', 'see', 'section', 'description', 'personalizationstorage', 'consent', 'variable', 'say', 'stor', 'age', 'relate', 'personalization', 'video', 'recommendation', 'clear', 'enough', 'understand', 'final', 'goal', 'personalization', 'apply', 'example', 'use', 'targeted', 'advertising', 'require', 'consent', 'short', 'vague', 'description', 'make', 'difficult', 'publisher', 'conclude', 'purpose', 'exempt', 'consent', 'case', 'purpose', 'functional', 'technical', 'see', 'consequently', 'cmp', 'run', 'risk', 'require', 'consent', 'pose', 'exempt', 'thereof', 'example', 'cookiebot', 'request', 'consent', 'nonnecessary', 'purpose', 'preference', 'statistic', 'kete', 'consent', 'banner', 'however', 'preference', 'purpose', 'see', 'table', 'seem', 'necessary', 'website', 'function', 'hence', 'exempt', 'consent', 'art', 'cookiebot', 'map', 'purpose', 'gtm', 'consent', 'variable', 'personaliza', 'tionstorage', 'functionalitystorage', 'accord', 'description', 'table', 'request', 'consent', 'purpose', 'recommendation', 'gtm', 'employ', 'purposespecific', 'ex', 'plicit', 'consent', 'variable', 'additionally', 'cmp', 'request', 'consent', 'unnecessary', 'purpose', 'potential', 'violation', 'defaulting', 'consent', 'variable', 'cepte', 'mean', 'tag', 'run', 'consent', 'describe', 'technical', 'finding', 'web', 'container', 'consider', 'cepte', 'define', 'variable', 'accept', 'user', 'default', 'also', 'discover', 'case', 'consentmanager', 'cmp', 'allow', 'consent', 'variable', 'undefined', 'tag', 'instal', 'web', 'container', 'run', 'collect', 'user', 'datum', 'due', 'consent', 'practice', 'render', 'processing', 'personal', 'datum', 'potentially', 'illegal', 'article', 'notably', 'consentmanager', 'declare', 'documentation', 'consent', 'mode', 'function', 'limited', 'recommend', 'publisher', 'use', 'argue', 'disclaimer', 'experimental', 'mode', 'exempt', 'accountability', 'obligation', 'ar', 'ticle', 'nevertheless', 'still', 'recommend', 'use', 'cmp', 'warning', 'state', 'discover', 'feature', 'cmp', 'template', 'deeply', 'integrate', 'consent', 'configuration', 'interface', 'push', 'publisher', 'use', 'flawed', 'cmp', 'enable', 'tag', 'run', 'independently', 'consent', 'thus', 'enable', 'processing', 'personal', 'datum', 'legal', 'basis', 'recommendation', 'gtm', 'treat', 'undefined', 'consent', 'variable', 'accept', 'default', 'prohibit', 'tag', 'collect', 'datum', 'consent', 'obtain', 'comply', 'privacy', 'default', 'gdpr', 'principle', 'art', 'validate', 'ommende', 'cmp', 'explicitly', 'warn', 'limitation', 'datum', 'collector', 'datum', 'collector', 'receive', 'datum', 'collect', 'tag', 'publisher', 'website', 'step', 'figure', 'collection', 'personal', 'datum', 'datum', 'collector', 'mean', 'combine', 'ip', 'address', 'additional', 'collect', 'datum', 'show', 'table', 'follow', 'argument', 'beginning', 'section', 'combination', 'ip', 'address', 'datum', 'render', 'user', 'identifiable', 'thus', 'datum', 'consider', 'personal', 'data', 'determination', 'purpose', 'data', 'collector', 'term', 'condition', 'privacy', 'policy', 'provide', 'publisher', 'decide', 'purpose', 'condition', 'pro', 'cesse', 'show', 'step', 'figure', 'example', 'specific', 'case', 'study', 'popular', 'datum', 'collector', 'show', 'commu', 'nicate', 'purpose', 'publisher', 'documentation', 'pinterest', 'tag', 'find', 'specific', 'purpose', 'online', 'behavioural', 'advertising', 'advertising', 'guideline', 'page', 'say', 'information', 'share', 'third', 'party', 'online', 'behavioural', 'advertising', 'documenta', 'tion', 'find', 'information', 'purpose', 'collect', 'datum', 'datum', 'processing', 'agreement', 'interpretation', 'pertain', 'purpose', 'analytic', 'aggregate', 'user', 'behavior', 'hotjar', 'allow', 'user', 'analyze', 'understand', 'behavioral', 'pattern', 'visitor', 'reason', 'pluralistic', 'control', 'exercise', 'datum', 'collector', 'publisher', 'common', 'complementary', 'decision', 'publisher', 'datum', 'collector', 'process', 'datum', 'moment', 'publisher', 'contractualize', 'data', 'collector', 'derive', 'purpose', 'cs', 'step', 'fig', 'rely', 'mean', 'processing', 'data', 'collector', 'processing', 'possible', 'participation', 'party', 'interdepen', 'dence', 'publisher', 'definition', 'purpose', 'mean', 'datum', 'collector', 'render', 'actor', 'joint', 'controller', 'determination', 'mean', 'datum', 'collector', 'receive', 'user', 'datum', 'tag', 'provide', 'service', 'publisher', 'process', 'datum', 'example', 'analytic', 'provide', 'dashboard', 'statistic', 'tag', 'manager', 'hide', 'datum', 'leak', 'potential', 'violation', 'protection', 'law', 'proceeding', 'privacy', 'enhance', 'technology', 'collector', '✗', 'builtin', 'consent', '✗', '✓', 'relevant', 'legal', 'role', 'tag', 'provider', 'none', 'none', 'datum', 'controller', 'table', 'legal', 'role', 'tag', 'provider', 'depend', 'data', 'collector', 'tag', 'builtin', 'consent', 'publisher', 'website', 'user', 'result', 'datum', 'collector', 'define', 'mean', 'processing', 'decide', 'process', 'receive', 'datum', 'algorithm', 'use', 'receive', 'datum', 'obtain', 'service', 'request', 'publisher', 'legal', 'role', 'publisher', 'datum', 'collector', 'joint', 'datum', 'con', 'troller', 'tag', 'provider', 'actor', 'merely', 'write', 'code', 'tag', 'tag', 'consist', 'mean', 'collect', 'send', 'datum', 'datum', 'collector', 'general', 'tag', 'provider', 'receive', 'store', 'datum', 'end', 'user', 'tag', 'provider', 'aware', 'point', 'publisher', 'use', 'tag', 'necessarily', 'know', 'identity', 'publisher', 'tag', 'provider', 'build', 'consent', 'tag', 'tag', 'figure', 'see', 'consent', 'configuration', 'show', 'step', 'figure', 'extract', 'purpose', 'use', 'tag', 'use', 'builtin', 'consent', 'functionality', 'display', 'gtm', 'consent', 'configuration', 'clientside', 'common', 'give', 'company', 'play', 'role', 'time', 'tag', 'provider', 'datum', 'collector', 'identify', 'scenario', 'show', 'table', 'use', 'reason', 'role', 'tag', 'provider', 's1', 'company', 'tag', 'provider', 'data', 'collector', 'builtin', 'consent', 'tag', 'seem', 'contract', 'agreement', 'link', 'publisher', 'tag', 'provider', 'tag', 'provider', 'still', 'define', 'tag', 'user', 'datum', 'send', 'datum', 'collector', 'entail', 'tag', 'provider', 'determine', 'essential', 'mean', 'processing', 'however', 'tag', 'provider', 'data', 'controller', 'miss', 'determination', 'purpose', 'builtin', 'consent', 'tag', 'predefine', 'purpose', 'tag', 'provider', 'data', 'processor', 'follow', 'instruction', 'publisher', 'datum', 'collector', 'process', 'personal', 'datum', 'behalf', 'actor', 'miss', 'dependence', 'controller', 'instruction', 'regard', 'processing', 'activity', 'define', 'role', 'processor', 'controller', 'see', 'hence', 'tag', 'provider', 'scenario', 'service', 'provider', 'gdpr', 'obligation', 'company', 'tag', 'provider', 'data', 'collector', 'tag', 'contain', 'builtin', 'consent', 'tag', 'provider', 'include', 'purpose', 'collect', 'datum', 'inside', 'tag', 'code', 'inclusion', 'predefine', 'purpose', 'tag', 'qualify', 'tag', 'provider', 'data', 'controller', 'seem', 'define', 'purpose', 'even', 'tag', 'provider', 'develop', 'datacollecting', 'tag', 'release', 'public', 'enable', 'collection', 'datum', 'fact', 'enough', 'reveal', 'factual', 'influence', 'definition', 'purpose', 'personal', 'datum', 'reason', 'embed', 'builtin', 'consent', 'tag', 'tag', 'provider', 'relate', 'processing', 'personal', 'datum', 'consist', 'prior', 'step', 'processing', 'personal', 'datum', 'provide', 'enough', 'element', 'factual', 'nature', 'tag', 'provider', 'exercise', 'actual', 'influence', 'regard', 'purpose', 'mean', 'process', 'datum', 'also', 'actor', 'process', 'personal', 'datum', 'hence', 'tag', 'provider', 'scenario', 'service', 'provider', 'gdpr', 'obligation', 'company', 'give', 'tag', 'provider', 'data', 'collector', 'possible', 'conclude', 'tag', 'providerdata', 'collector', 'jointly', 'give', 'publisher', 'consider', 'joint', 'controller', 'data', 'collector', 'publisher', 'joint', 'con', 'troller', 'already', 'establish', 'section', 'qualification', 'hold', 'regardless', 'builtin', 'consent', 'tag', 'datum', 'collector', 'determine', 'already', 'purpose', 'processing', 'c', 'contractual', 'service', 'legal', 'role', 'tag', 'provider', 'role', 'depend', 'data', 'collector', 'see', 'table', 'summary', 'role', 'potential', 'violation', 'tag', 'send', 'datum', 'independently', 'user', 'consent', 'decision', 'technical', 'finding', 'tag', 'always', 'send', 'user', 'datum', 'google', 'even', 'user', 'jecte', 'builtin', 'purpose', 'thereby', 'process', 'user', 'datum', 'lawful', 'legal', 'basis', 'infringe', 'lawfulness', 'principle', 'moreover', 'user', 'datum', 'send', 'security', 'principle', 'violate', 'unauthorized', 'disclosure', 'data', 'controller', 'liable', 'potential', 'violation', 'recommendation', 'tag', 'provider', 'datum', 'collector', 'change', 'tag', 'behavior', 'respect', 'user', 'choice', 'order', 'compliant', 'potential', 'violation', 'allow', 'tag', 'provider', 'inject', 'script', 'expose', 'end', 'user', 'security', 'risk', 'technical', 'find', 'find', 'contain', 'special', 'injectscript', 'mission', 'allow', 'tag', 'inject', 'arbitrary', 'javascript', 'code', 'website', 'page', 'see', 'figure', 'find', 'clientside', 'tag', 'inject', 'script', 'subject', 'security', 'measure', 'implement', 'web', 'browser', 'sameorigin', 'policy', 'protect', 'user', 'scriptbase', 'web', 'attack', 'practice', 'allow', 'execute', 'tag', 'potentially', 'infringe', 'security', 'principle', 'provider', 'gtm', 'service', 'data', 'con', 'troller', 'liable', 'potential', 'violation', 'additionally', 'tag', 'provider', 'tag', 'data', 'collector', 'data', 'controller', 'also', 'liable', 'violation', 'recommendation', 'allow', 'tag', 'provider', 'clude', 'arbitrary', 'script', 'website', 'page', 'adopt', 'security', 'safeguard', 'tag', 'provider', 'use', 'loophole', 'inject', 'arbitrary', 'script', 'legal', 'analysis', 'serverside', 'section', 'describe', 'actor', 'involve', 'serverside', 'reproduce', 'legal', 'reasoning', 'role', 'actor', 'hold', 'section', 'regard', 'publisher', 'datum', 'collector', 'service', 'provider', 'herein', 'focus', 'provider', 'collector', 'tag', 'client', 'adaptor', 'server', 'provider', 'server', 'tag', 'provider', 'server', 'provider', 'role', 'trigger', 'potential', 'violation', 'refer', 'analyze', 'provider', 'collector', 'proceeding', 'privacy', 'enhance', 'technology', 'actor', 'publisher', 'collector', 'provider', 'provider', 'server', 'provider', 'provider', 'collector', 'tag', 'client', 'adaptor', 'clientside', 'controller', 'controller', 'controller', 'serverside', 'controller', 'datum', 'controller', 'depend', 'see', 'depend', 'see', 'tab5', 'datum', 'controller', 'data', 'controller', 'datum', 'processor', 'legal', 'role', 'table', 'summary', 'legal', 'role', 'actor', 'tag', 'client', 'adaptor', 'function', 'conclude', 'gdpr', 'legal', 'role', 'find', 'actor', 'present', 'similarity', 'tag', 'provider', 'clientside', 'data', 'collector', 'merely', 'develop', 'provide', 'software', 'process', 'personal', 'datum', 'follow', 'instruction', 'actor', 'table', 'outline', 'serverside', 'role', 'gtm', 'actor', 'processing', 'personal', 'datum', 'serverside', 'need', 'assess', 'casebycase', 'basis', 'server', 'provider', 'process', 'ip', 'address', 'end', 'user', 'receive', 'incoming', 'http', 'request', 'server', 'datum', 'collector', 'sometimes', 'receive', 'personal', 'information', 'see', 'table', 'specific', 'data', 'collector', 'receive', 'ip', 'address', 'end', 'user', 'server', 'tag', 'provider', 'actor', 'present', 'similar', 'function', 'tag', 'provider', 'client', 'side', 'serverside', 'absence', 'builtin', 'function', 'change', 'legal', 'role', 'data', 'controller', 'server', 'tag', 'provider', 'also', 'data', 'collector', 'legal', 'role', 'tag', 'provider', 'legal', 'role', 'depend', 'data', 'collector', 'company', 'potential', 'violation', 'server', 'tag', 'provider', 'also', 'datum', 'collector', 'aware', 'lawful', 'datum', 'collection', 'possi', 'ble', 'server', 'tag', 'provider', 'provide', 'code', 'tag', 'know', 'gtm', 'server', 'container', 'function', 'see', 'figure', 'thus', 'aware', 'consent', 'management', 'tool', 'available', 'server', 'container', 'server', 'tag', 'provider', 'also', 'know', 'publisher', 'conveniently', 'configure', 'server', 'container', 'match', 'consent', 'variable', 'server', 'tag', 'see', 'nonetheless', 'server', 'tag', 'provider', 'still', 'provide', 'server', 'tag', 'server', 'tag', 'provider', 'directly', 'receive', 'user', 'personal', 'datum', 'legal', 'role', 'data', 'collector', 'therefore', 'become', 'data', 'controller', 'see', 'table', 'moreover', 'joint', 'controller', 'publisher', 'see', 'therefore', 'responsibility', 'ensure', 'lawful', 'datum', 'process', 'recommendation', 'server', 'tag', 'provider', 'data', 'collector', 'provide', 'server', 'tag', 'gtm', 'consent', 'management', 'functionality', 'serverside', 'discussion', 'section', 'discuss', 'finding', 'reflect', 'diffi', 'culty', 'comply', 'protection', 'framework', 'various', 'actor', 'client', 'serverside', 'provide', 'recommendation', 'improvement', 'gtm', 'comply', 'datum', 'subject', 'right', 'hard', 'publisher', 'client', 'serverside', 'publisher', 'leave', 'alone', 'comply', 'user', 'right', 'data', 'request', 'absence', 'dedicated', 'system', 'functionality', 'example', 'user', 'request', 'access', 'datum', 'article', 'gdpr', 'publisher', 'probably', 'need', 'find', 'contact', 'datum', 'collector', 'compile', 'manually', 'answer', 'user', 'task', 'confirm', 'problematic', 'study', 'samarin', 'gtm', 'furnish', 'publisher', 'common', 'interface', 'identify', 'datum', 'collector', 'streamlined', 'tool', 'data', 'collector', 'facilitate', 'user', 'datum', 'request', 'builtin', 'consent', 'raise', 'trust', 'issue', 'publisher', 'use', 'tag', 'builtin', 'consent', 'tag', 'potential', 'violation', 'rely', 'tag', 'provider', 'properly', 'implement', 'builtin', 'consent', 'code', 'however', 'tag', 'provider', 'declare', 'rely', 'builtin', 'consent', 'purpose', 'completely', 'ignore', 'tag', 'code', 'send', 'user', 'datum', 'even', 'corresponding', 'purpose', 'reject', 'user', 'way', 'publisher', 'ensure', 'proper', 'consent', 'management', 'review', 'tag', 'code', 'possible', 'nonofficial', 'tag', 'code', 'available', 'template', 'gallery', 'however', 'code', 'reviewing', 'possible', 'official', 'tag', 'implement', 'sandboxe', 'code', 'gtmj', 'require', 'heavy', 'reverse', 'engineering', 'publisher', 'also', 'ignore', 'builtin', 'consent', 'manually', 'add', 'consent', 'variable', 'step', 'figure', 'case', 'tag', 'run', 'consent', 'variable', 'associate', 'tag', 'grant', 'allow', 'publisher', 'access', 'code', 'tag', 'auditing', 'facilitate', 'publisher', 'understand', 'tag', 'code', 'serverside', 'invisible', 'regulatory', 'monitoring', 'au', 'dite', 'serverside', 'obstruct', 'compliance', 'audit', 'endeavor', 'regulator', 'datum', 'protection', 'officer', 'researcher', 'datum', 'collection', 'occur', 'remotely', 'server', 'traditionally', 'happen', 'browser', 'example', 'collector', 'tag', 'detectable', 'tag', 'choose', 'publisher', 'remain', 'invisible', 'possible', 'monitor', 'datum', 'collect', 'transmit', 'server', 'container', 'however', 'discerning', 'collector', 'access', 'datum', 'remain', 'unknown', 'moreover', 'auditing', 'mon', 'itoring', 'exclusively', 'attainable', 'contact', 'publisher', 'grant', 'access', 'configuration', 'server', 'container', 'furthermore', 'publisher', 'able', 'change', 'configuration', 'server', 'container', 'point', 'time', 'eg', 'regulatory', 'investigation', 'mask', 'compliance', 'check', 'consent', 'hard', 'configure', 'gtm', 'server', 'container', 'advertise', 'respect', 'user', 'consent', 'choice', 'tag', 'manager', 'consent', 'management', 'tool', 'limit', 'client', 'side', 'challenge', 'render', 'consent', 'compliant', 'serverside', 'lack', 'consent', 'management', 'tool', 'server', 'container', 'raise', 'follow', 'problem', 'first', 'cmp', 'scanner', 'detect', 'tag', 'gtm', 'web', 'container', 'able', 'tect', 'tag', 'gtm', 'server', 'container', 'impossibility', 'entail', 'cmp', 'display', 'purpose', 'datum', 'collector', 'consent', 'banner', 'end', 'user', 'type', 'information', 'disclosure', 'mandatory', 'informed', 'consent', 'transparent', 'pro', 'cessing', 'personal', 'datum', 'art', 'second', 'publisher', 'wish', 'compliant', 'serverside', 'need', 'make', 'complex', 'tag', 'manager', 'hide', 'datum', 'leak', 'potential', 'violation', 'protection', 'law', 'proceeding', 'privacy', 'enhance', 'technology', 'configuration', 'write', 'code', 'decode', 'consent', 'information', 'create', 'filter', 'rule', 'respect', 'give', 'consent', 'server', 'container', 'interface', 'configure', 'send', 'furthermore', 'server', 'container', 'support', 'consent', 'mode', 'publisher', 'associate', 'tag', 'purpose', 'implement', 'consent', 'management', 'tool', 'gtm', 'server', 'container', 'provide', 'list', 'instal', 'tag', 'cmp', 'conclusion', 'work', 'first', 'study', 'version', 'tag', 'manager', 'clientside', 'serverside', 'analyze', 'system', 'clientside', 'tag', 'serverside', 'tag', 'consent', 'management', 'platform', 'cmp', 'perform', 'indepth', 'technical', 'legal', 'analysis', 'gtm', 'determine', 'responsibility', 'potential', 'legal', 'violation', 'actor', 'result', 'show', 'many', 'pitfall', 'flaw', 'security', 'system', 'noncompliant', 'default', 'conclude', 'current', 'state', 'introduce', 'legal', 'issue', 'solve', 'make', 'compliance', 'difficult', 'achieve', 'various', 'actor', 'complex', 'regulator', 'monitor', 'acknowledgment', 'work', 'support', 'anr', 'ipop', 'interdisciplinary', 'project', 'privacy', 'project', 'cybersecurity', 'pepr', 'author', 'like', 'thank', 'contribute', 'initial', 'work', 'reference', 'case', 'court', 'justice', 'c31922', 'scania', 'case', 'court', 'justice', 'advocate', 'general', 'case', 'case', 'opinion', 'https', 'text', 'pageindex0', 'modereq', 'occ', 'first', 'part1', 'work', 'party', 'opinion', 'concept', 'controller', 'https', 'processor', 'wp', 'binn', 'jun', 'shadbolt', 'measure', 'thirdparty', 'tracker', 'power', 'web', 'mobile', 'acm', 'transaction', 'internet', 'technology', 'https', 'supple', 'mentary', 'material', 'consult', '7th', 'https', 'arxivorge', 'brave', 'software', 'brave', 'shield', 'https', 'bravecomshield', 'consult', '27th', 'tag', 'manager', 'usage', 'statistic', 'https', 'consult', '20th', 'tag', 'manager', 'optimisez', 'track', 'votre', 'site', 'web', 'édition', 'chromiumbrowser', 'chromium', 'https', 'wwwchromiumorghome', 'sulte', 'chromiumflatpak', 'chromium', 'web', 'browser', 'https', 'flathuborgappsorg', 'chromiumchromium', 'consult', '29th', 'consentmanager', 'nd', 'consent', 'management', 'provider', 'consentmanagernet', 'consult', '15th', 'https', 'www', 'consentmanager', 'nd', 'work', 'consent', 'mode', 'https', 'help', 'consult', '7th', 'cookiebot', 'tag', 'manager', 'cookie', 'consent', 'compliance', 'cookiebot', 'sulte', '15th', 'board', 'edpb', 'opinion', 'cookie', 'consent', 'exemption', 'board', 'edpb', 'opinion', 'purpose', 'tion', 'available', 'https', 'board', 'edpb', 'work', 'document', 'provide', 'guidance', 'obtain', 'consent', 'cookie', 'adopt', 'available', 'https', 'steven', 'englehardt', 'online', 'track', 'measurement', 'analysis', 'proceeding', 'acm', 'sigsac', 'conference', 'computer', 'communication', 'security', 'acm', 'https', 'steven', 'englehardt', 'online', 'track', 'measurement', 'analysis', 'proceeding', 'acm', 'sigsac', 'conference', 'computer', 'communication', 'security', 'edgar', 'r', 'ed', 'acm', 'https', 'directive', '2009136ec', 'european', 'council', 'https', 'uricelex', 'access', 'directive', '2009136ec', 'european', 'https', 'council', 'access', 'european', 'justice', 'case', 'jehovan', 'todistajat', 'european', 'justice', 'case', 'european', 'justice', 'opinion', 'concept', 'personal', 'https', 'eceuropaeujusticearticle', 'datum', 'adopt', 'european', 'guideline', 'concept', 'controller', 'processor', 'gdpr', 'version', 'https', 'edpbeuropaeuour', 'controllerandprocessoren', 'imane', 'fouad', 'nataliia', 'legout', 'miss', 'filter', 'list', 'detect', 'unknown', 'thirdparty', 'tracker', 'pixel', 'proceeding', 'privacy', 'enhance', 'technology', 'popet', 'vol', 'issue', 'https', 'publish', 'online', 'https', 'imane', 'fouad', 'santo', 'fera', 'nataliia', 'compliance', 'cookie', 'purpose', 'purpose', 'specifi', 'principle', 'proc', 'international', 'workshop', 'privacy', 'engineering', 'iwpe', 'https', 'halinriafrhal02567022', 'imane', 'fouad', 'santo', 'legout', 'nataliia', 'cookie', 'phoenix', 'detection', 'measurement', 'lawfulness', 'cookie', 'respawn', 'browser', 'fingerprinting', 'proceeding', 'privacy', 'enhance', 'technology', 'popet', 'issue', 'https', 'petsymposiumorgpopets2022', 'popets20220063pdf', 'gdpr', 'regulation', 'european', 'council', 'protection', 'natural', 'person', 'regard', 'processing', 'personal', 'datum', 'free', 'movement', 'datum', 'repeal', 'directive', '9546ec', 'general', 'datum', 'protection', 'regulation', 'text', 'eea', 'relevance', 'uricelex', 'nd', 'consent', 'mode', 'https', 'supportgooglecomgooglead', 'answer10548233', 'sjid6259837766651858133eu', 'consult', '27th', 'nd', 'consent', 'management', 'platform', 'integration', 'https', 'supportgoogle', 'hlen', 'cmpintegration', 'consult', '29th', 'nd', 'create', 'consent', 'mode', 'template', 'https', 'consult', '27th', 'nd', 'custom', 'template', 'https', 'tagmanagertemplatesapi', 'isconsentgrante', 'consult', '16th', 'nd', 'custom', 'template', 'permission', 'https', 'developersgooglecomtag', 'consult', '31st', 'nd', 'tag', 'manager', 'tagmanagergooglecom', 'home', 'nd', 'implement', 'consent', 'mode', 'serverside', 'tag', 'man', 'ager', 'consult', '25th', 'datum', 'processing', 'agreement', 'nd', 'datum', 'processing', 'agreement', 'https', 'www', 'nd', 'manage', 'consent', 'setting', 'web', 'https', 'developersgooglecomtag', 'hotjarcomlegalsupportdpa', 'consult', '28th', 'track', 'tag', 'manager', 'new', 'antiadblock', 'weapon', 'translate', 'version', 'platformsecurityguidesconsent', 'consult', 'nd', 'measurement', 'protocol', 'parameter', 'reference', 'https', 'developer', 'consult', '16th', 'proceeding', 'privacy', 'enhance', 'technology', 'nd', 'respect', 'user', 'consent', 'choice', 'man', 'ager', 'https', 'googletagmanager', 'consult', '16th', 'nd', 'sandboxe', 'javascript', 'https', 'consult', '7th', 'https', 'nd', 'set', 'install', 'tag', 'manager', 'tagmanageranswer6103696', 'consult', '4th', 'nd', 'submit', 'template', 'community', 'template', 'gallery', 'https', 'consult', '28th', 'nd', 'tag', 'manager', 'serverside', 'https', 'developersgooglecomtag', 'platformtagmanagerserverside', 'consult', '3rd', 'nd', 'tag', 'platform', 'overview', 'https', 'developersgooglecomtag', 'platformdevguide', 'consult', '12th', 'hotjar', 'nd', 'hotjarprotocoldocumentation', 'https', 'helphotjarcomhcen', 'consult', '20th', 'information', 'commissioner', 'office', 'datum', 'controller', 'datum', 'pro', 'cessor', 'governance', 'implication', 'https', 'difference', 'intelligent', 'tracking', 'prevention', 'https', 'webkitorgblog', 'consult', '27th', 'fedorovicius', 'introduction', 'manager', 'serverside', 'tag', 'https', 'managerserversidetagge', 'consult', 'feb', 'fedorovicius', 'nd', 'analytic', 'tag', 'manager', 'blog', 'https', 'wwwanalyticsmaniacom', 'consult', 'feb', 'build', 'private', 'web', 'path', 'make', 'third', 'https', 'party', 'cookie', 'obsolete', 'privatewebpathtowardshtml', 'consult', '28th', 'balachander', 'krishnamurthy', 'privacy', 'diffusion', 'web', 'longitudinal', 'perspective', 'proceeding', '18th', 'international', 'conference', 'world', 'wide', 'web', 'www', 'maarek', 'ed', 'acm', 'https', 'laperdrix', 'nataliia', 'benoit', 'gilda', 'browser', 'fingerprint', 'survey', 'acm', 'transaction', 'web', 'https', 'lerner', 'roesner', 'internet', 'raider', 'lose', 'tracker', 'archaeological', 'study', 'web', 'tracking', '25th', 'usenix', 'security', 'symposium', 'usenix', 'security', 'usenix', 'association', 'expose', 'invisible', 'web', 'analysis', 'thirdparty', 'http', 'request', 'website', 'international', 'journal', 'communication', 'célestin', 'matte', 'nataliia', 'santo', 'cookie', 'banner', 'respect', 'choice', 'measure', 'legal', 'compliance', 'banner', 'transparency', 'consent', 'framework', 'ieee', 'symposium', 'security', 'privacy', 'ieee', 'p', 'https', 'corporation', 'nd', 'enhance', 'tracking', 'protection', 'desk', 'top', 'firefoxdesktop', 'consult', '27th', 'mozillaorg', 'contributor', 'nd', 'content', 'security', 'policy', 'https', 'developermozilla', 'orgenusdocswebhttpcsp', 'consult', '29th', 'mozillaorg', 'contributor', 'nd', 'document', 'object', 'model', 'https', 'developermozilla', 'consult', '29th', 'mozillaorg', 'contributor', 'nd', 'sameorigin', 'policy', 'https', 'developermozillaorg', 'acker', 'piessen', 'vigna', 'include', 'largescale', 'evaluation', 'remote', 'javascript', 'inclusion', 'proceeding', 'acm', 'conference', 'computer', 'communication', 'security', 'acm', 'raleigh', 'https', 'nodejs', 'nd', 'nodejs', 'v14213', 'documentation', 'https', 'nodejsorgdocslat', 'clitlskeylogfile', 'consult', 'pinter', 'nd', 'add', 'event', 'code', 'https', 'addeventcode', 'consult', '20th', 'pinter', 'nd', 'advertising', 'guideline', 'https', 'policypinterestcomengb', 'advertisingguideline', 'consult', '28th', 'pixeldetrackingwebsite', 'tracking', 'note', 'extension', 'surveillance', 'personal', 'website', 'https', 'consult', 'feb', 'roesner', 'detect', 'defend', 'thirdparty', 'tracking', 'web', 'proceeding', '9th', 'usenix', 'symposium', 'networked', 'system', 'design', 'implementation', 'nsdi', 'siye', 'bjorkman', 'primal', 'wijesekera', 'noura', 'hoofnagle', 'serge', 'egelman', 'lesson', 'vcr', 'repair', 'compliance', 'android', 'app', 'developer', 'act', 'ccpa', 'proceeding', 'privacy', 'enhanc', 'technology', 'https', 'doiorg1056553popet', 'santo', 'nataliia', 'bielova', 'célestin', 'matte', 'cookie', 'banner', 'indeed', 'compliant', 'law', 'decipher', 'legal', 'requirement', 'consent', 'technical', 'mean', 'verify', 'compliance', 'cookie', 'banner', 'technology', 'regulation', 'techreg', 'https', 'nataliia', 'bielova', 'roca', 'consent', 'management', 'platform', 'gdpr', 'processor', 'andor', 'controller', 'annual', 'privacy', 'forum', 'apf', 'https', 'senol', 'gune', 'acar', 'mathia', 'frederik', 'borge', 'sius', 'leaky', 'form', 'study', 'email', 'password', 'exfiltration', 'form', 'submission', 'proceeding', '31st', 'usenix', 'security', 'symposium', 'usenix', 'simo', 'agency', 'transparency', 'control', 'unsolved', 'problem', 'serverside', 'tagging', 'consult', 'feb', 'simo', 'nd', 'tag', 'tag', 'manager', 'tagsgoogletagmanager', 'consult', 'feb', 'supplementarymaterial', 'nd', 'anonymous', 'supplementary', 'mate', 'https', 'rial', 'nataliia', 'bielova', 'roca', 'dark', 'pattern', 'manipulation', 'website', 'publisher', 'cmp', 'proceeding', 'privacy', 'enhance', 'technology', 'https', 'doiorg1056553popets2022', 'practical', 'google', 'analytic', 'tag', 'manager', 'developer', '1st', 'ed', 'nd', 'wireshark', 'wwwwiresharkorg', 'actor', 'publisher', 'client', 'serverside', 'publisher', 'use', 'include', 'dedicated', 'service', 'website', 'publisher', 'choose', 'datum', 'collector', 'tag', 'show', 'step', 'figure', 'need', 'accept', 'term', 'condition', 'relate', 'contractual', 'service', 'datum', 'collector', 'determination', 'purpose', 'selection', 'datum', 'collector', 'determinant', 'consequence', 'qualification', 'pub', 'lisher', 'determination', 'purpose', 'firstly', 'datum', 'collector', 'establish', 'purpose', 'step', 'figure', 'process', 'datum', 'explicitly', 'mention', 'analytic', 'c', 'policy', 'document', 'publisher', 'agree', 'purpose', 'define', 'datum', 'collector', 'purpose', 'publisher', 'present', 'enduser', 'pre', 'sentation', 'purpose', 'give', 'data', 'subject', 'reasonable', 'expectation', 'basis', 'visibility', 'reflect', 'determi', 'nant', 'power', 'publisher', 'regard', 'purpose', 'determination', 'mean', 'acceptance', 'datum', 'collector', 'c', 'publisher', 'agree', 'mean', 'process', 'establish', 'collector', 'process', 'receive', 'datum', 'algorithm', 'use', 'code', 'run', 'receive', 'datum', 'accordingly', 'publisher', 'determine', 'mean', 'datum', 'process', 'legal', 'role', 'publisher', 'controller', 'tag', 'manager', 'hide', 'datum', 'leak', 'potential', 'violation', 'protection', 'law', 'proceeding', 'privacy', 'enhance', 'technology', 'deny', 'example', 'give', 'documentation', 'consent', 'variable', 'use', 'represent', 'purpose', 'datum', 'collection', 'processing', 'instance', 'hypothetical', 'targetedadvertising', 'consent', 'variable', 'represent', 'consent', 'refusal', 'end', 'user', 'let', 'datum', 'use', 'display', 'target', 'ad', 'tag', 'configure', 'different', 'behavior', 'regard', 'data', 'collection', 'depend', 'state', 'variable', 'builtin', 'consent', 'feature', 'tag', 'implement', 'tag', 'sup', 'port', 'feature', 'able', 'adjust', 'behavior', 'base', 'state', 'consent', 'variable', 'instance', 'end', 'user', 'accept', 'datum', 'use', 'analytic', 'purpose', 'advertise', 'ment', 'purpose', 'tag', 'support', 'build', 'consent', 'collect', 'datum', 'purpose', 'limit', 'datum', 'collection', 'analytic', 'purpose', 'technically', 'tag', 'implement', 'builtin', 'consent', 'use', 'provide', 'isconsentgrante', 'api', 'check', 'status', 'accept', 'decline', 'purposeswe', 'provide', 'example', 'code', 'tag', 'implement', 'builtin', 'consent', 'figure', 'manual', 'consent', 'configuration', 'process', 'pub', 'lisher', 'associate', 'consent', 'variable', 'tag', 'instal', 'web', 'container', 'tag', 'manually', 'associate', 'consent', 'variable', 'prevent', 'run', 'web', 'container', 'associated', 'variable', 'set', 'grant', 'instance', 'case', 'user', 'accept', 'datum', 'use', 'analytic', 'purpose', 'advertisement', 'pur', 'pose', 'tag', 'configure', 'manual', 'consent', 'analytic', 'advertisement', 'purpose', 'run', 'c', 'server', 'side', 'terminology', 'server', 'tag', 'component', 'write', 'sandboxe', 'javascript', 'run', 'exclusively', 'server', 'process', 'send', 'datum', 'receive', 'server', 'container', 'third', 'party', 'server', 'server', 'tag', 'store', 'firstparty', 'cookie', 'user', 'browser', 'client', 'adaptor', 'plugin', 'embed', 'server', 'container', 'decode', 'datum', 'arrive', 'server', 'container', 'convert', 'event', 'event', 'happen', 'user', 'click', 'button', 'associate', 'datum', 'name', 'position', 'page', 'collector', 'tag', 'tag', 'tag', 'run', 'browser', 'collect', 'datum', 'send', 'network', 'gtm', 'server', 'container', 'a2', 'server', 'provider', 'serverside', 'actor', 'provide', 'publisher', 'hardware', 'give', 'soft', 'ware', 'server', 'container', 'run', 'type', 'server', 'provider', 'exist', 'gtmserver', 'service', 'provider', 'install', 'server', 'software', 'also', 'manage', 'security', 'server', 'simple', 'server', 'provider', 'provide', 'generic', 'server', 'allow', 'give', 'publisher', 'install', 'server', 'software', 'paper', 'analyse', 'point', 'simple', 'server', 'provider', 'service', 'provide', 'hard', 'ware', 'server', 'run', 'usually', 'service', 'publisher', 'need', 'pay', 'publisher', 'hire', 'give', 'server', 'provider', 'provide', 'server', 'contract', 'perform', 'publisher', 'server', 'provider', 'publisher', 'use', 'server', 'install', 'server', 'container', 'software', 'consequently', 'give', 'tion', 'server', 'run', 'order', 'process', 'personal', 'datum', 'accordingly', 'functional', 'dependence', 'server', 'provider', 'publisher', 'instruction', 'render', 'actor', 'data', 'processor', 'determination', 'purpose', 'provide', 'infrastructural', 'hardware', 'service', 'server', 'provider', 'determine', 'purpose', 'determination', 'mean', 'server', 'provider', 'provide', 'mean', 'publisher', 'run', 'server', 'container', 'software', 'hardware', 'use', 'security', 'system', 'factual', 'activity', 'regard', 'practical', 'implementation', 'server', 'con', 'sist', 'nonessential', 'mean', 'hardware', 'provide', 'server', 'provider', 'run', 'gtm', 'server', 'container', 'software', 'process', 'personal', 'datum', 'server', 'provider', 'data', 'processor', 'legal', 'role', 'server', 'provider', 'data', 'processor', 'find', 'compliance', 'issue', 'actor', 'client', 'side', 'terminology', 'tag', 'javascript', 'library', 'usually', 'develop', 'marketing', 'com', 'panie', 'analytic', 'company', 'independent', 'developer', 'less', 'fre', 'quently', 'publisher', 'role', 'tag', 'collect', 'formation', 'user', 'device', 'send', 'collect', 'datum', 'thirdparty', 'service', 'specifically', 'tag', 'software', 'component', 'write', 'sandboxe', 'javascript', 'limited', 'version', 'javascript', 'create', 'gtm', 'tag', 'also', 'pro', 'vide', 'functionality', 'implement', 'consent', 'banner', 'permission', 'system', 'tag', 'let', 'access', 'functionality', 'send', 'request', 'third', 'party', 'server', 'access', 'cookie', 'web', 'container', 'group', 'tag', 'associate', 'configuration', 'rule', 'technically', 'container', 'javascript', 'program', 'generate', 'automatically', 'download', 'user', 'browser', 'file', 'call', 'gtmj', 'https', 'embed', 'tag', 'select', 'publisher', 'configuration', 'well', 'interpreter', 'execute', 'sandboxe', 'javascript', 'code', 'tag', 'write', 'container', 'configuration', 'process', 'publisher', 'select', 'tag', 'configure', 'themuse', 'configuration', 'web', 'interface', 'provide', 'tagmanagergooglecom', 'consent', 'variable', 'store', 'consent', 'end', 'user', 'web', 'container', 'state', 'undefine', 'grant', 'proceeding', 'privacy', 'enhance', 'technology', 'figure', 'summary', 'legal', 'role', 'publisher', 'joint', 'controller', 'actor', 'ecosystem', 'figure', 'summarise', 'legal', 'role', 'publisher', 'relation', 'collector', 'always', 'join', 'controller', 'cmp', 'joint', 'controller', 'tag', 'provider', 'tag', 'provider', 'datum', 'collector', 'cookie', 'detect', 'purpose', 'associate', 'iseu', 'necessary', 'cookieconsent', 'necessary', 'hjrecordingenable', 'hjrecordinglastactivity', 'hjviewportid', 'hjactiveviewportid', 'hjincludedinsessionsample', 'hjsession', 'hjabsolutesessioninprogress', 'statistic', 'statistic', 'statistic', 'statistic', 'statistic', 'statistic', 'statistic', 'statistic', 'statistic', 'statistic', 'marketing', 'pinterestctua', 'marketing', 'marketing', 'pinunauth', 'marketing', 'tag', 'create', 'cookie', 'pinter', 'pinterest', 'pinterest', 'pinterest', 'table', 'result', 'cookiebot', 'scanner', 'deduct', 'tag', 'responsible', 'cookie', 'creation', 'read', 'description', 'cookie', 'provider', 'show', 'report', 'consentmanager', 'purpose', 'measurement', 'na', 'marketing', 'function', 'preference', 'social', 'medium', 'consent', 'variable', 'analyticsstorage', 'adstorage', 'securitystorage', 'personalizationstorage', 'functionalitystorage', 'na', 'table', 'correspondence', 'consentmanager', 'purpose', 'purpose', 'purpose', 'use', 'sentmanager', 'consentmanager', 'purpose', 'map', 'consent', 'mode', 'purpose', 'joint', 'c', 'ontroller', 'service', 'provider', 'joint', 'controller', 'joint', 'hen', 'tag', 'provider', 'ontroller', 'ollector', 'publisher', 'n', 'r', 'e', 'r', 'c', 'provider', 'collector', 'manager', 'hide', 'datum', 'leak', 'potential', 'violation', 'protection', 'law', 'proceeding', 'privacy', 'enhance', 'technology', 'cookiebot', 'purpose', 'description', 'necessary', 'preference', 'statistic', 'market', 'necessary', 'cookie', 'help', 'make', 'website', 'usable', 'enable', 'basic', 'function', 'page', 'navigation', 'access', 'secure', 'area', 'website', 'website', 'function', 'properly', 'cookie', 'preference', 'cookie', 'enable', 'website', 'remember', 'information', 'change', 'way', 'website', 'behave', 'look', 'preferred', 'language', 'region', 'statistic', 'cookie', 'help', 'website', 'owner', 'understand', 'visitor', 'interact', 'website', 'collect', 'report', 'information', 'anonymously', 'marketing', 'cookie', 'use', 'track', 'visitor', 'website', 'intention', 'display', 'ad', 'relevant', 'engage', 'individual', 'user', 'thereby', 'valuable', 'publisher', 'third', 'party', 'advertiser', 'table', 'purpose', 'define', 'cookiebot', 'description', 'figure', 'confirmation', 'window', 'instal', 'tag', 'community', 'template', 'gallery', 'permission', 'capabili', 'tie', 'tag', 'explicitely', 'list']"
"A Reliable Representation with Bidirectional Transition Model for Visual
  Reinforcement Learning Generalization","[{'href': 'http://arxiv.org/abs/2312.01915v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2312.01915v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-12-04 14:19:36,"3
2
0
2

c
e
D
4

]

G
L
.
s
c
[

1
v
9
1
0
2
0
.
2
1
3
2
:
v
i
X
r
a

Action Inference by Maximising Evidence: Zero-Shot
Imitation from Observation with World Models

Xingyuan Zhang1, 2∗, Philip Becker-Ehmck1, Patrick van der Smagt1,3, Maximilian Karl1
1Machine Learning Research Lab, Volkswagen Group, 2Technical University of Munich,
3Eötvös Loránd University Budapest
{xingyuan.zhang,philip.becker-ehmck,maximilian.karl}@volkswagen.de

Abstract

Unlike most reinforcement learning agents which require an unrealistic amount
of environment interactions to learn a new behaviour, humans excel at learning
quickly by merely observing and imitating others. This ability highly depends
on the fact that humans have a model of their own embodiment that allows them
to infer the most likely actions that led to the observed behaviour. In this paper,
we propose Action Inference by Maximising Evidence (AIME) to replicate this
behaviour using world models. AIME consists of two distinct phases. In the
first phase, the agent learns a world model from its past experience to understand
its own body by maximising the evidence lower bound (ELBO). While in the
second phase, the agent is given some observation-only demonstrations of an
expert performing a novel task and tries to imitate the expert’s behaviour. AIME
achieves this by defining a policy as an inference model and maximising the
evidence of the demonstration under the policy and world model. Our method
is ""zero-shot"" in the sense that it does not require further training for the world
model or online interactions with the environment after given the demonstration.
We empirically validate the zero-shot imitation performance of our method on
the Walker and Cheetah embodiment of the DeepMind Control Suite and find it
outperforms the state-of-the-art baselines. Code is available at: https://github.
com/argmax-ai/aime.

1

Introduction

In recent years, deep reinforcement learning (DRL) has enabled intelligent decision-making agents
to thrive in multiple fields [1, 2, 3, 4, 5, 6]. However, one of the biggest issues of DRL is sample
inefficiency. The dominant framework in DRL is learning from scratch [7]. Thus, most algorithms
require an incredible amount of interactions with the environment [1, 2, 3].

In contrast, cortical animals such as humans are able to quickly learn new tasks through just a few
trial-and-error attempts, and can further accelerate their learning process by observing others. An
important difference between biological learning and the DRL framework is that the former uses
past experience for new tasks. When we try a novel task, we use previously learnt components and
generalise to solve the new problem efficiently. This process is augmented by imitation learning [8],
which allows us to replicate similar behaviours without direct observation of the underlying muscle
movements. If the DRL agents could similarly harness observational data, such as the abundant
online video data, the sample efficiency may be dramatically improved [9]. The goal of the problem is
related to the traditional well-established Learning from Demonstration (LfD) field from the robotics
community [10, 11], but instead of relying on knowledge from the engineers and researchers, e.g.
mathematical model of robot’s dynamic or primitives, we aim to let the robots learn by itself.

∗Corresponding author.

37th Conference on Neural Information Processing Systems (NeurIPS 2023).

 
 
 
 
 
 
Figure 1: Overview of AIME algorithm. In phase 1, both observations and actions are provided by
the embodiment dataset and the agent learns a variational world model to model the evidence of
observations conditioned on the actions. Then the learnt model weights are frozen and transferred to
phase 2. In phase 2, only the observations are provided by the demonstration dataset, so the agent
needs to infer both states and actions. The action inference is achieved by the policy model which
samples actions given a state. The grey lines indicate the world model parameters are frozen in phase
2. Both phases are optimised toward the same objective, i.e. the ELBO.

However, directly learning a model from observation-only sequences [12, 13] is insufficient for both
biological and technical systems. Without knowing the actions that lead to the observations, the
observation sequences are highly stochastic and multi-modal [14]. Trying to infer these unknown
actions without prior knowledge of the world is difficult due to the problem of attributing which parts
of the observations are influenced by the actions and which parts are governed by normal system
evolution or noise.

Therefore, in this work, we hypothesise that in order to make best use of observation-only sequences,
an agent has to first understand the notion of an action. This can be achieved by learning a model
from an agent’s past experiences where both the actions and their consequences, i.e. observations, are
available. Given such a learnt model which includes a causal model of actions and their effects, it
becomes feasible for an agent to infer an action sequence leading to given observation-only data.

In this work, we propose a novel algorithm, Action Inference by Maximising Evidence (AIME), to
try to replicate the imitation ability of humans. The agent first learns a world model from its past
experience by maximising the evidence of these experiences. After receiving some observation-only
demonstrations of a novel task, the agent tries to mimic the demonstrator by finding an action sequence
that makes the demonstration most likely under the learnt model. This procedure is shown in Figure 1.

Our contribution can be summarised as follows:

• We propose AIME, a novel method for imitation from observation. AIME first learns a
world model by maximising the evidence of its past experience, then considers the policy as
an action inference model and imitates by maximising the evidence of demonstration.

• We conduct experiments with a variety of datasets and tasks to demonstrate the superior
performance of AIME compared with other state-of-the-art methods. The results showcase
the zero-shot transferability of a learnt world model.

2 Problem formulation

Consider an MDP problem defined by the tuple {S, A, T, R}, where S is the state space, A is the
action space, T : S × A → S is the dynamic function and R : S → R is the reward function. A
POMDP adds partial observability upon an MDP with two components: the observation space O and
the emission function Ω : S → O. The six components of a POMDP can be categorised into three
groups: S, A and T define the embodiment of our agent, O and Ω define the sensors of our agent and

2

Phase 1: Model Learning

Transfer Parameters 

𝜙𝜙, 𝜃𝜃

Phase 2: Imitation Learning

𝑜𝑜𝑡𝑡
𝑜𝑜𝑡𝑡

𝑜𝑜𝑡𝑡+1
𝑜𝑜𝑡𝑡+1

𝑜𝑜𝑡𝑡+2

𝑜𝑜𝑡𝑡

𝑜𝑜𝑡𝑡+1

𝑜𝑜𝑡𝑡+2

Embodiment 
dataset

{𝑜𝑜1, 𝑎𝑎1, 𝑜𝑜2, 𝑎𝑎2 … }

𝑎𝑎𝑡𝑡
𝑎𝑎𝑡𝑡

𝑎𝑎𝑡𝑡+1

Demonstration 
dataset

{𝑜𝑜1, 𝑜𝑜2, 𝑜𝑜3 … }

𝑎𝑎𝑡𝑡

𝑎𝑎𝑡𝑡+1

𝑠𝑠𝑡𝑡

𝑠𝑠𝑡𝑡+1

𝑠𝑠𝑡𝑡+2

𝑠𝑠𝑡𝑡

𝑠𝑠𝑡𝑡+1

𝑠𝑠𝑡𝑡+2

𝑞𝑞𝜙𝜙
𝑝𝑝𝜃𝜃
𝜋𝜋𝜓𝜓

∇𝜙𝜙,𝜃𝜃𝐽𝐽

∇𝜓𝜓𝐽𝐽

𝐽𝐽 𝑜𝑜1:𝑇𝑇, 𝑠𝑠0:𝑇𝑇, 𝑎𝑎0:𝑇𝑇−1 = 𝐽𝐽𝑟𝑟𝑟𝑟𝑟𝑟(𝑜𝑜1:𝑇𝑇, 𝑠𝑠0:𝑇𝑇, 𝑎𝑎0:𝑇𝑇−1) + 𝐽𝐽𝐾𝐾𝐾𝐾(𝑜𝑜1:𝑇𝑇, 𝑠𝑠0:𝑇𝑇, 𝑎𝑎0:𝑇𝑇−1)

R itself defines the task. The goal is to find a policy π : S → A which maximises the accumulated
reward, i.e. (cid:80)
In this paper, we want to study imitation learning within a fixed embodiment across different tasks.
We presume the existence of two datasets for the same embodiment:

t rt.

• Embodiment dataset Dbody contains trajectories {o0, a0, o1, a1 . . . } that represent past
experiences of interacting with the environment. This dataset provides information about
the embodiment for the algorithm to learn a model. For example, in this paper, the dataset is
a replay buffer filled while solving some tasks with the same embodiment. But in general, it
may be any collection of past experiences of the embodiment.

• Demonstration dataset Ddemo contains a few expert trajectories {o0, o1, o2 . . . } of the
embodiment solving a certain task defined by Rdemo. The crucial difference between this
dataset and the embodiment dataset is that the actions are not provided anymore since they
are not observable from a third-person perspective.

The goal of our agent is to use information in Dbody to learn a policy π from Ddemo which can solve
the task defined by Rdemo as well as the expert who generated Ddemo. For simplicity, we assume
that the two datasets share the same observation space O and the emission model Ω.

3 Methodology

In this section, we describe our proposed method, AIME, in detail. AIME consists of two phases. In
the first phase, the knowledge of the embodiment is learnt through a form of world model; while in
the second phase, this knowledge is used to imitate the expert.

3.1 Phase 1: Model Learning

In the first phase, we need to learn a model to understand our embodiment. We achieve this by
learning a world model. As an analogy to a language model, we define a world model as a probability
distribution over sequences of observations. The model can be either unconditioned or conditioned
on other factors such as previous observations or actions. For phase 1, the model needs to be the
conditional distribution, i.e. p(o1:T |a0:T −1), to model the effect of the actions. When given an
observation sequence, the likelihood of this sequence under the model is referred to as evidence.

In this paper, we consider variational world models where the observation is governed by a Markovian
hidden state. In the literature, this type of model is also referred to as a state-space model (SSM)
[15, 16, 17, 18, 19, 20]. Such a variational world model involves four components, namely

encoder zt = fϕ(ot),
posterior st ∼ qϕ(st|st−1, at−1, zt),
prior st ∼ pθ(st|st−1, at−1),

decoder ot ∼ pθ(ot|st).

fϕ(ot) is the encoder to extract the features from the observation; qϕ(st|st−1, at−1, zt) and
pθ(st|st−1, at−1) are the posterior and the prior of the latent state variable; while pθ(ot|st) is
the decoder that decodes the observation distribution from the state. ϕ and θ represent the parameters
of the inference model and the generative model respectively.

Typically, a variational world model is trained by maximising the ELBO which is a lower bound
of the log-likelihood, or evidence, of the observation sequence, i.e. log pθ(o1:T |a0:T −1). Given a
sequence of observations, actions, and states, the objective function can be computed as

J(o1:T , s0:T , a0:T −1) = Jrec(o1:T , s0:T , a0:T −1) + JKL(o1:T , s0:T , a0:T −1),

(1)

(2)

where Jrec(o1:T , s0:T , a0:T −1) =

JKL(o1:T , s0:T , a0:T −1) =

T
(cid:88)

t=1

T
(cid:88)

t=1

log pθ(ot|st),

−DKL[qϕ(st|st−1, at−1, fϕ(ot))||pθ(st|st−1, at−1)].

(3)

3

The objective function is composed of two terms: the first term Jrec is the likelihood of the observation
under the inferred state, which is usually called the reconstruction loss; while the second term JKL is
the KL divergence between the posterior and the prior distributions of the latent state. To compute
the objective function, we use the re-parameterisation trick [21, 22] to autoregressively sample the
inferred states from the observation and action sequence.

Combining all these, we formally define the optimisation problem for this phase as

ϕ∗, θ∗ = argmax

ϕ,θ

E{o1:T ,a0:T −1}∼Dbody,s0:T ∼qϕ[J(o1:T , s0:T , a0:T −1)].

(4)

3.2 Phase 2: Imitation Learning

In the second phase, we want to utilise the knowledge of the world model from the first phase to
imitate the expert behaviour from the demonstration dataset Ddemo in which only sequences of
observations but no actions are available. We derive our algorithm from two different perspectives.

The Bayesian derivation Since the actions are unknown in the demonstration, instead of modelling
the conditional evidence in phase 1, we need to model the unconditional evidence, i.e. log pθ(o1:T ).
Thus, we also need to model the actions as latent variables together with the states. In this way, the
reconstruction term Jrec will stay the same as eq. (2), while the KL term will be defined on the joint
distribution of states and actions, i.e.

JKL(o1:T , s0:T , a0:T −1) =

T
(cid:88)

t=1

−DKL[qϕ,ψ(st, at−1|st−1, fϕ(ot))||pθ,ψ(st, at−1|st−1)].

(5)

If we choose the action inference model in the form of a policy, i.e. πψ(at|st), and share it in both
posterior and prior, then the new posterior and prior can be factorised as

qϕ,ψ(st, at−1|st−1, fϕ(ot)) = πψ(at−1|st−1)qϕ(st|st−1, at−1, fϕ(ot))

and pθ,ψ(st, at−1|st−1) = πψ(at−1|st−1)pθ(st|st−1, at−1)

(6)
(7)

respectively. When we plug them into the eq. (5), the policy term cancels and we will get a similar
optimisation problem with phase 1 as

ψ∗ = argmax

ψ

Eo1:T ∼Ddemo,{s0:T ,a0:T −1}∼qϕ∗ ,ψ [J(o1:T , s0:T , a0:T −1)].

(8)

The main difference between eq. (4) and eq. (8) is where the action sequence is coming from. In
phase 1, the action sequence is coming from the embodiment dataset, while in phase 2, it is sampled
from the policy instead since it is not available in the demonstration dataset.

The control derivation From another perspective, we can view phase 2 as a control problem. One
crucial observation is that, as shown in eq. (1), given a trained world model, we can evaluate the
lower bound of the evidence of any observation sequence given an associated action sequence as the
condition. In a deterministic environment where the inverse dynamics model is injective, the true
action sequence that leads to the observation sequence is the most likely under the true model. In
general, the true action sequence may not necessarily be the most likely under the model. This is,
however, a potential benefit of our approach. We are mainly interested in mimicking the expert’s
demonstration and may be better able to do so with a different action sequence.

Thus, for each observation sequence that we get from the demonstration dataset, finding the missing
action sequence can be considered as a trajectory-tracking problem and can be tackled by planning.
To be specific, we can find the missing action sequence by solving the optimisation problem

a∗
0:T −1 = argmax
a0:T −1

Eo1:T ∼Ddemo,s0:T ∼qϕ∗ [J(o1:T , s0:T , a0:T −1)].

(9)

If we solve the above optimisation problem for every sequence in the demonstration dataset, the
problem will be converted to a normal imitation learning problem and can be solved with standard
techniques such as behavioural cloning. We can also view this as forming an implicit inverse dynamics
model (IDM) by inverting a forward model w.r.t. the actions.

To make it more efficient, we use amortised inference. We directly define a policy πψ(at|st) under
the latent state of the world model. By composing the learnt world model and the policy, we can form

4

Algorithm 1: AIME
Data: Embodiment dataset Dbody, Demonstration dataset Ddemo, Learning rate α
# Phase 1: Model Learning
Initialise world model parameters ϕ and θ
while model has not converged do
{o1:T , a0:T −1} ∼ Dbody
s0 ← 0
for t = 1 : T do

st ∼ qϕ(st|st−1, at−1, fϕ(ot))

Compute objective function J from eq. (1)
Update model parameters ϕ ← ϕ + α∇ϕJ, θ ← θ + α∇θJ

# Phase 2: Imitation Learning
Initialise policy parameters ψ
while policy has not converged do

o1:T ∼ Ddemo
s0 ← 0
for t = 1 : T do

at−1 ∼ πψ(at−1|st−1)
st ∼ qϕ(st|st−1, at−1, fϕ(ot))

Compute objective function J from eq. (1)
Update policy parameters ψ ← ψ + α∇ψJ

a new generative model of the state sequence by the chain of st → at → st+1 → at+1 . . . → sT .
Then we will get the same optimisation problem as eq. (8).

To sum up, in AIME, we use the same objective function – the ELBO – in both phases with the only
difference being the source of the action sequence. We provide the pseudo-code for the algorithm in
Algorithm 1 with the colour highlighting the different origins of the actions between the two phases.

4 Experiments

To test our method, we need multiple environments sharing an embodiment while posing different
tasks. Therefore, we consider Walker and Cheetah embodiment from the DeepMind Control Suite
(DMC Suite) [23]. Officially, the Walker embodiment has three tasks: stand, walk and run. While the
Cheetah embodiment only has one task, run, we add three new tasks, namely run backwards, flip and
flip backwards, inspired by previous work [24]. Following the common practice in the benchmark
[19], we repeat every action two times when interacting with the environment. For both embodiments,
the true state includes both the position and the velocity of each joint and the centre of mass of the
body. In order to study the influence of different observation modalities, we consider three settings for
each environment: MDP uses the true state as the observation; Visual uses images as the observation;
LPOMDP uses only the position part of the state as the observation, so that information-wise it is
identical to the Visual setting but the information is densely represented in a low-dimensional form.

To generate the embodiment and demonstration datasets, we train a Dreamer [19] agent in the
Visual setting for each of the tasks for 1M environment steps. We take the replay buffer of these
trained agents as the embodiment datasets Dbody, which contain 1000 trajectories, and consider
the converged policy as the expert to collect another 1000 trajectories as the demonstration dataset
Ddemo. We only use 100 trajectories for the main experiments, and the remaining trajectories are
used for an ablation study. The performance of the policy is measured by accumulated reward. The
exact performance of the demonstration dataset can be found in Appendix D. Besides the above
embodiment datasets, we also study two datasets generated by purely exploratory behaviour. First,
we use a random policy that samples uniformly from the action space to collect 1000 trajectories, and
we call this the random dataset. Second, we train a Plan2Explore [24] agent for 1000 trajectories and
label its replay buffer as the p2e dataset. Moreover, for the Walker embodiment, we also merge all the
above datasets except the run dataset to form a mix dataset. This resembles a practical setting where
one possesses a lot of experience with one embodiment and uses all of it to train a single foundational
world model.

5

Figure 2: Performances on Walker. Each column indicates one task and its associated demonstration
dataset, while each row indicates the embodiment datasets used to train the model. The title of each
figure is named according to Dbody → Ddemo. Numbers are computed by averaging among 100
trials and then normalised to the percentage of the expert’s performance. Error bars are showing one
standard deviation. The last row and column are averaged over the corresponding task or dataset. The
error bar is large for them due to aggregating performance distributed in a large range.

4.1 Benchmark results

We mainly compare our method with BCO(0) [25]. BCO(0) first trains an IDM from the embodiment
dataset and then used the trained IDM to label the demonstration dataset and then uses Behavioural
Cloning (BC) to recover the policy. We do not compare with other methods since they either require
further environment interactions [26, 27] or use a goal-conditional setting [28] which does not suit the
locomotion tasks. More details about related works can be found in Section 5. The implementation
details can be found in Appendix B.

The main results of our comparison are shown in Figure 2 and Figure 3. Overall, we can see that
AIME largely outperforms BCO(0) in all the environment settings on Walker and on POMDP settings
on Cheetah. AIME typically achieves the lowest performance on the Visual setting, but even that is
comparable with BCO(0)-MDP which can access the true states. We attribute the good performance
of AIME to two reasons. First, the world model has a better data utilisation rate than the IDM because
the world model is trained to reconstruct whole observation sequences, while the IDM only takes

6

Figure 3: Performances on Cheetah. Each column indicates one task and its associated demonstration
dataset, while each row indicates the embodiment datasets used to train the model. The title of each
figure is named according to Dbody → Ddemo. runb and flipb are short hands for run backwards and
flip backwards. Numbers are computed by averaging among 100 trials and then normalised to the
percentage of the expert’s performance. Error bars are showing one standard deviation. The last row
and column are averaged over the corresponding task or dataset. The error bar is large for them due
to aggregating performance distributed in a large range.

short clips of the sequence and only predicts the actions. Thus, the world model has less chance to
overfit, learns better representations and provides better generalisation. Second, by maximising the
evidence, our method strives to find an action sequence that leads to the same outcome, not to recover
the true actions. For many systems, the dynamics are not fully invertible. For example, if a human
applies force to the wall, since the wall does not move, one cannot tell how much force is applied
by visual observation. The same situation applies to the Walker and Cheetah when certain joints are
locked due to the singular pose. This same phenomenon is also discussed in [28].

We also find that, comparing with the Walker experiments, the performance on Cheetah is lower and
the improvement offered by AIME is smaller. We think it is because the setup for Cheetah is much
harder than Walker. Although the tasks sound similar from the names, e.g. flip and flip backward,
due to the asymmetrical structure of the embodiment, the behaviour for solving the tasks can be quite
different. The difference limits the amount of knowledge that can be transferred from the embodiment
dataset to the demonstrations. Moreover, some tasks are built to be hard for imitation. For example,
in the demonstration of the flip tasks, the cheetah is ""flying"" in the air and the actions taken there is
not relevant for solving the tasks. That leaves only a few actions in the sequence that are actually
essential for solving the task. We think this is more challenging for AIME since it needs to infer
a sequence of actions, while BCO(0) is operating on point estimation. That is, when the first few
actions cannot output reasonable actions to start the flip, then the later actions will create a very noisy

7

gradient since none of them can explain the ""flying"". In general, poorly modelled regions of the world
may lead to noisy gradients for the time steps before it. On the other hand, we can also find most
variants achieve a good performance on the run backward demonstration dataset, which is mainly
due to low expert performance (see Appendix D) for the task that makes imitation easy. Last but
not least, since we follow the common practise for the benchmark [19], the Cheetah embodiment is
operated on 50Hz which is much higher than the 20Hz used in Walker. Higher frequency of operation
makes the effect of each individual action, i.e. change in the observation, more subtle and harder to
distinguish, which poses an additional challenge for the algorithms.

Influence of different datasets As expected, for almost all the variants of methods, transferring within
the same task is better than transferring between different tasks. In these settings, BCO(0)-MDP is
comparable with AIME. However, AIME shines in cross-task transfer. Especially when transferring
between run and walk tasks and transferring from stand to run on Walker, AIME outperforms the
baselines by a large margin, which indicates the strong generalisability of a forward model over
an inverse model. We also find that AIME makes substantially better use of exploratory data. On
Walker, AIME largely outperforms baselines when using the p2e dataset as the embodiment dataset
and outperforms most variants when using the random dataset as the embodiment dataset. Moreover,
when transferring from the mix dataset, except for the MDP version, AIME outperforms other
variants that train the world model on just any single individual task dataset of the mixed dataset.
This showcases the scalability of a world model to be trained on a diverse set of experiences, which
could be more valuable in real-world scenarios.

Influence of observation modality Compared with BCO(0), AIME is quite robust to the choice of
observation modality. We can see a clear ladder pattern with BCO(0) when changing the setting from
hard to easy, while for AIME the result is similar for each modality. However, we can still notice
a small difference when comparing LPOMDP and Visual settings. Although these observations
provide the same information, we find AIME in the LPOMDP setting performs better than in the
Visual setting in most test cases. We attribute it to the fact that low-dimension signals have denser
information and offer a smoother landscape in the evidence space than the pixels so that it can
provide a more useful gradient to guide the action inference. Surprisingly, although having access to
more information, AIME-MDP performs worse than AIME-LPOMDP on average. The biggest gaps
happen when transferring from exploratory datasets, i.e. the p2e dataset on Walker and the random
dataset on Cheetah. We conjecture this to the fact the world model is not trained well with the default
hyper-parameters, but we defer further investigation to future work.

4.2 Ablation studies

In this section, we conduct some ablation studies to investigate how AIME’s performance is influenced
by different components and design choices. We will mainly focus on using the mix embodiment
dataset and transfer to run task, which represents a more realistic setting where we want to use
experience from multiple tasks to transfer to a new task.

Sample efficiency and scalability To test these properties, we vary the number of demonstrations
within {1, 2, 5, 10, 20, 50, 100, 200, 500, 1000}. We also include BC with the true action as an
oracle baseline. The results are shown in Figure 4. BCO(0) struggles with low-data scenarios and
typically needs at least 10 to 20 demonstrations to surpass the performance of a random policy. In
contrast, AIME demonstrates continual improvement with as few as 2 trajectories. And surprisingly,
thanks to the generalisation ability of the world model, AIME even outperforms oracle BC when
the demonstrations are limited. These demonstrate the superior sample efficiency of the method.
Moreover, the performance of AIME keeps increasing as more trajectories are provided beyond 100,
which showcases the scalability of the method.

Objective function The objective function, i.e. ELBO, consists of two terms, the reconstruction
term Jrec and the KL term JKL. To investigate the role that each term plays in AIME, we retrain two
variants of AIME by removing either of the terms. As we can see from Figure 5, removing either
term will negatively impact the results. When we compare the two variants, only using the KL term
is better in settings with low-dimensional signals, while using only the reconstruction term yields a
slightly better result for the high-dimensional image signal. But on all settings, the performance of
using only the KL term is very close to the one that use both terms. This suggests that the latent state
in the world model has already mostly captured the essential part of the environment. Although it is

8

Figure 4: Ablation of the number of demonstrations on mix → run transfer on the Walker embodiment.
The performance is shown as the normalised returns over 3 seeds and 100 trials for each seed. The
shaded region represents one standard deviation.

Figure 5: Ablation studies on mix → run transfer on the Walker embodiment. Numbers are computed
by averaging among 3 seeds and 100 trials for each seed, and then normalised to the percentage of
the expert’s performance. Error bars are showing one standard deviation.

still worse than using both terms, it sheds some light on the potential of incorporating decoder-free
models [29] into the AIME framework.

Components Compared with the BCO(0) baseline, AIME consists of two distinct modifications:
one is to use an SSM to integrate sequences and train the policy upon its latent representation; the
other is to form an implicit IDM via gradients rather than training an IDM explicitly. We design two
baselines to investigate the two components. First, to remove the SSM, we train a forward dynamics
model directly on the observations of the embodiment dataset and use that as an implicit IDM for
imitation on the demonstration dataset. We term this variant IIDM. Second, we train a separate
IDM upon the trained latent state of the world model and use that to guide the policy learning in
phase 2. The detailed derivation of the IDM formulation can be found in Appendix C. Figure 5
clearly demonstrates the significance of the latent representation for performance. Without the latent
representation, the results are severely compromised across all settings. However, when compared to
BCO(0), the IIDM does provide assistance in the high-dimensional Visual setting, where training
an IDM directly from the observation space can be extremely challenging. While having IDM on
the latent representation leads to a better performance comparing with BCO(0), but it still performs
worse than AIME, especially on the POMDP settings.

5 Related works

Imitation learning from observations Most previous works on imitation learning from only ob-
servation can be roughly categorised into two groups, one based on IDMs [25, 9, 30, 28] and one
based on generative adversarial imitation learning (GAIL) [31, 26, 27]. The core component of the
first group is to learn an IDM that maps a state transition pair to the action that caused the transition.
[25, 9] use the IDM to label the expert’s observation sequences, then solve the imitation learning
problem with standard BC. [30, 28] extend the IDM to a goal-conditioned setting in which the IDM
is trained to be conditioned on a future frame as the goal instead of only the next frame. During
deployment, the task is communicated on the fly by the user in the form of key-frames as goals. The

9

120

MDP

s
n
r
u
t
e
R
d
e
s
i
l

a
m
r
o
N

100

80

60

40

20

0

BC (oracle)
BCO(0)
AIME
random

100

101

102

103

Number of Demonstrations

 
120

LPOMDP

s
n
r
u
t
e
R
d
e
s
i
l

a
m
r
o
N

100

80

60

40

20

0

BC (oracle)
BCO(0)
AIME
random

100

101

102

103

Number of Demonstrations

 
120

Visual

s
n
r
u
t
e
R
d
e
s
i
l

a
m
r
o
N

100

80

60

40

20

0

BC (oracle)
BCO(0)
AIME
random

100

101

102

103

Number of Demonstrations

 
100

s
n
r
u
t
e
R
d
e
s
i
l

a
m
r
o
N

80

60

40

20

0

BCO(0)
AIME
AIME w/o Rec
AIME w/o KL
IIDM
AIME w/ IDM

MDP

LPOMDP

Visual

 
setup mainly suits for the robot manipulation tasks in their paper since the user can easily specify
the goals by doing the manipulation himself, but not suits for the locomotion tasks, in which it is
not clear what a long-term goal of observation is and also not practical set the next observation as
the goal and demonstrate that in a high frequency by the user. Different from these methods, our
approach uses a forward model to capture the knowledge of the embodiment. In the second group
of approaches, the core component is a discriminator that distinguishes the demonstrator’s and the
agent’s observation trajectories. Then the discriminator serves as a reward function, and the agent’s
policy is trained by RL [31]. As a drawback, in order to train this discriminator the agent has to
constantly interact with the environment to produce negative samples. Different from these methods,
our method does not require further interactions with the environment, enabling zero-shot imitation
from the demonstration dataset. Besides the majority, there are also works [32, 33] don’t strictly
fit to the two groups. [32] also use forward model like us by learning a latent action policy and a
forward dynamic based on the latent action. However, it still needs online environment interactions to
calibrate the latent actions to the real actions. [33] is hybrid method that uses both of the components
and focus on a setting that the demonstrations are coming from a different embodiment.

Reusing learnt components in decision-making Although transferring pre-trained models has
become a dominant approach in natural language processing (NLP) [34, 35, 36] and has been getting
more popular in computer vision (CV) [37, 36], reusing learnt components is less studied in the
field of decision-making [7]. Most existing works focus on transferring policies [38, 9, 7]. On
the other hand, the world model, a type of powerful perception model, that is purely trained by
self-supervised learning lies behind the recent progress of model-based reinforcement learning
[39, 17, 19, 40, 41, 42, 43, 44]. However, the transferability of these world models is not well-studied.
[24] learns a policy by using a pre-trained world model from exploration data and demonstrates
superior zero-shot and few-shot abilities. We improve upon this direction by studying a different
setting, i.e. imitation learning. In particular, we communicate the task to the model by observing the
expert while [24] communicates the task by a ground truth reward function which is less accessible
in a real-world setting.

6 Discussion & conclusion

In this paper, we present AIME, a model-based method for imitation from observations. The core of
the method exploits the power of a pre-trained world model and inverses it w.r.t. action inputs by
taking the gradients. On the Walker and Cheetah embodiments from the DMC Suite, we demonstrate
superior performance compared to baselines, even when some baselines can access the true state. The
results showcase the zero-shot ability of the learnt world model.

Although AIME performs well, there are still limitations. First, humans mostly observe others with
vision. Although AIME works quite well in the Visual setting, there is still a gap compared with
the LPOMDP setting where the low-dimensional signals are observed. We attribute this to the fact
that the loss surface of the pixel reconstruction loss may not be smooth enough to allow the gradient
method to find an equally good solution. Second, in this paper, we only study the simplest setting
where both the embodiment and sensor layout are fixed across tasks. On the other hand, humans
observe others in a third-person perspective and can also imitate animals whose body is not even
similar to humans’. Relaxing these assumptions will open up possibilities to transfer across different
embodiments and even directly from human videos. Third, for some tasks, even humans cannot
achieve zero-shot imitation by only watching others. This may be due to the task’s complexity or
completely unfamiliar skills. So, even with proper instruction, humans still need to practise in the
environment and learn something new to solve some tasks. This motivates an online learning phase 3
as an extension to our framework. We defer these topics to future work.

We hope this paper demonstrates the great potential of transferring a learnt world model, incentivises
more people to work in this direction and encourages researchers to also share their learnt world
model to contribute to the community.

Acknowledgments and Disclosure of Funding

We want to acknowledge Elie Aljalbout for the insightful discussion during the initial stage of the
project and Botond Cseke for mathematical support.

10

References

[1] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G.
Bellemare, Alex Graves, Martin Riedmiller, Andreas K. Fidjeland, Georg Ostrovski, Stig Pe-
tersen, Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan
Wierstra, Shane Legg, and Demis Hassabis. Human-level control through deep reinforcement
learning. Nature, 518(7540):529–533, 2015.

[2] David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van den Driess-
che, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander
Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap,
Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. Mastering the
game of Go with deep neural networks and tree search. Nature, 529(7587):484–489, 2016.

[3] Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, Michaël Mathieu, Andrew Dudzik,
Junyoung Chung, David H. Choi, Richard Powell, Timo Ewalds, Petko Georgiev, Junhyuk Oh,
Dan Horgan, Manuel Kroiss, Ivo Danihelka, Aja Huang, Laurent Sifre, Trevor Cai, John P.
Agapiou, Max Jaderberg, Alexander S. Vezhnevets, Rémi Leblond, Tobias Pohlen, Valentin
Dalibard, David Budden, Yury Sulsky, James Molloy, Tom L. Paine, Caglar Gulcehre, Ziyu
Wang, Tobias Pfaff, Yuhuai Wu, Roman Ring, Dani Yogatama, Dario Wünsch, Katrina McKin-
ney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Koray Kavukcuoglu, Demis Hassabis, Chris
Apps, and David Silver. Grandmaster level in StarCraft II using multi-agent reinforcement
learning. Nature, 575(7782):350–354, 2019.

[4] Suyoung Choi, Gwanghyeon Ji, Jeongsoo Park, Hyeongjun Kim, Juhyeok Mun, Jeong Hyun
Lee, and Jemin Hwangbo. Learning quadrupedal locomotion on deformable terrain. Science
Robotics, 8(74):eade2256, 2023.

[5] OpenAI, Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew,
Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas, Jonas Schneider,
Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng, Qiming Yuan, Wojciech Zaremba,
and Lei Zhang. Solving rubik’s cube with a robot hand, 2019.

[6] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,
Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob Hilton,
Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano,
Jan Leike, and Ryan Lowe. Training language models to follow instructions with human
feedback. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors,
Advances in Neural Information Processing Systems, 2022.

[7] Rishabh Agarwal, Max Schwarzer, Pablo Samuel Castro, Aaron Courville, and Marc G Belle-
mare. Reincarnating reinforcement learning: Reusing prior computation to accelerate progress.
In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in
Neural Information Processing Systems, 2022.

[8] Marco Iacoboni.
60:653–70, 2008.

Imitation, empathy, and mirror neurons. Annual review of psychology,

[9] Bowen Baker, Ilge Akkaya, Peter Zhokov, Joost Huizinga, Jie Tang, Adrien Ecoffet, Brandon
Houghton, Raul Sampedro, and Jeff Clune. Video pretraining (VPT): Learning to act by
watching unlabeled online videos. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and
Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.

[10] Yezhou Yang, Yi Li, Cornelia Fermuller, and Yiannis Aloimonos. Robot learning manipulation
action plans by ""watching""; unconstrained videos from the world wide web. Proceedings of the
AAAI Conference on Artificial Intelligence, 29(1), 2015.

[11] Y. Kuniyoshi, M. Inaba, and H. Inoue. Learning by watching: extracting reusable task knowledge
from visual observation of human performance. IEEE Transactions on Robotics and Automation,
10(6):799–822, 1994.

11

[12] Younggyo Seo, Kimin Lee, Stephen L James, and Pieter Abbeel. Reinforcement learning
with action-free pre-training from videos. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song,
Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International
Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research,
pages 19561–19579. PMLR, 2022.

[13] Alejandro Escontrela, Ademi Adeniji, Wilson Yan, Ajay Jain, Xue Bin Peng, Ken Goldberg,
Youngwoon Lee, Danijar Hafner, and Pieter Abbeel. Video Prediction Models as Rewards for
Reinforcement Learning, 2023.

[14] Mohammad Babaeizadeh, Chelsea Finn, Dumitru Erhan, Roy H. Campbell, and Sergey Levine.
Stochastic variational video prediction. In International Conference on Learning Representa-
tions, 2018.

[15] Manuel Watter, Jost Springenberg, Joschka Boedecker, and Martin Riedmiller. Embed to
control: A locally linear latent dynamics model for control from raw images. Advances in
neural information processing systems, 28, 2015.

[16] Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt. Deep variational
bayes filters: Unsupervised learning of state space models from raw data. In International
Conference on Learning Representations, 2017.

[17] Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee,
and James Davidson. Learning latent dynamics for planning from pixels. In International
Conference on Machine Learning, pages 2555–2565, 2019.

[18] Philip Becker-Ehmck, Jan Peters, and Patrick Van Der Smagt. Switching linear dynamics for
variational Bayes filtering. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceed-
ings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of
Machine Learning Research, pages 553–562. PMLR, 2019.

[19] Danijar Hafner, Timothy Lillicrap, Jimmy Ba, and Mohammad Norouzi. Dream to control:
Learning behaviors by latent imagination. In International Conference on Learning Representa-
tions, 2020.

[20] Alexej Klushyn, Richard Kurle, Maximilian Soelch, Botond Cseke, and Patrick van der Smagt.
Latent matters: Learning deep state-space models. Advances in Neural Information Processing
Systems, 34:10234–10245, 2021.

[21] Diederik P. Kingma and Max Welling. Auto-Encoding Variational Bayes. In 2nd International
Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014,
Conference Track Proceedings, 2014.

[22] Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation
and approximate inference in deep generative models.
In Eric P. Xing and Tony Jebara,
editors, Proceedings of the 31st International Conference on Machine Learning, volume 32 of
Proceedings of Machine Learning Research, pages 1278–1286, Bejing, China, 22–24 Jun 2014.
PMLR.

[23] Saran Tunyasuvunakool, Alistair Muldal, Yotam Doron, Siqi Liu, Steven Bohez, Josh Merel,
Tom Erez, Timothy Lillicrap, Nicolas Heess, and Yuval Tassa. dm_control: Software and tasks
for continuous control. Software Impacts, 6:100022, 2020.

[24] Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar Hafner, and Deepak

Pathak. Planning to explore via self-supervised world models. In ICML, 2020.

[25] Faraz Torabi, Garrett Warnell, and Peter Stone. Behavioral cloning from observation.
International Joint Conferences on Artificial Intelligence, pages 4950–4957, 2018.

In

[26] Faraz Torabi, Garrett Warnell, and Peter Stone. Generative adversarial imitation from observa-

tion, 2018.

12

[27] Chenhao Li, Marin Vlastelica, Sebastian Blaes, Jonas Frey, Felix Grimminger, and Georg
Martius. Learning agile skills via adversarial imitation of rough partial demonstrations. In 6th
Annual Conference on Robot Learning, 2022.

[28] Deepak Pathak, Parsa Mahmoudieh, Guanghao Luo, Pulkit Agrawal, Dian Chen, Yide Shentu,
Evan Shelhamer, Jitendra Malik, Alexei A. Efros, and Trevor Darrell. Zero-shot visual imitation.
In ICLR, 2018.

[29] Nicklas A Hansen, Hao Su, and Xiaolong Wang. Temporal difference learning for model
predictive control. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang
Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine
Learning, volume 162 of Proceedings of Machine Learning Research, pages 8387–8406. PMLR,
2022.

[30] Ashvin Nair, Dian Chen, Pulkit Agrawal, Phillip Isola, Pieter Abbeel, Jitendra Malik, and Sergey
Levine. Combining self-supervised learning and imitation for vision-based rope manipulation.
In 2017 IEEE International Conference on Robotics and Automation (ICRA), page 2146–2153.
IEEE Press, 2017.

[31] Jonathan Ho and Stefano Ermon. Generative adversarial imitation learning.

In D. Lee,
M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information
Processing Systems, volume 29. Curran Associates, Inc., 2016.

[32] Ashley Edwards, Himanshu Sahni, Yannick Schroecker, and Charles Isbell. Imitating latent
policies from observation. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceed-
ings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of
Machine Learning Research, pages 1755–1763. PMLR, 2019.

[33] Karl Schmeckpeper, Oleh Rybkin, Kostas Daniilidis, Sergey Levine, and Chelsea Finn. Re-
inforcement learning with videos: Combining offline observations with interaction. In Jens
Kober, Fabio Ramos, and Claire Tomlin, editors, Proceedings of the 2020 Conference on Robot
Learning, volume 155 of Proceedings of Machine Learning Research, pages 339–354. PMLR,
2021.

[34] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of
deep bidirectional transformers for language understanding. In Jill Burstein, Christy Doran, and
Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT
2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages
4171–4186. Association for Computational Linguistics, 2019.

[35] Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language

models are unsupervised multitask learners. 2019.

[36] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx,
Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, Erik Brynjolfsson,
Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji, Annie Chen, Kathleen Creel,
Jared Quincy Davis, Dora Demszky, Chris Donahue, Moussa Doumbouya, Esin Durmus, Stefano
Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, Trevor Gale, Lauren
Gillespie, Karan Goel, Noah Goodman, Shelby Grossman, Neel Guha, Tatsunori Hashimoto,
Peter Henderson, John Hewitt, Daniel E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas
Icard, Saahil Jain, Dan Jurafsky, Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling,
Fereshte Khani, Omar Khattab, Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi,
Ananya Kumar, Faisal Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa
Li, Xuechen Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric
Mitchell, Zanele Munyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman,
Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray Ogut, Laurel Orr,
Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher Potts, Aditi
Raghunathan, Rob Reich, Hongyu Ren, Frieda Rong, Yusuf Roohani, Camilo Ruiz, Jack
Ryan, Christopher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam, Andy Shih, Krishnan
Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian Tramèr, Rose E. Wang,
William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael Xie, Michihiro Yasunaga,

13

Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang, Xikun Zhang, Yuhui Zhang, Lucia
Zheng, Kaitlyn Zhou, and Percy Liang. On the opportunities and risks of foundation models,
2021.

[37] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollár, and Ross Girshick. Masked
autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pages 16000–16009, 2022.

[38] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adap-
tation of deep networks. In Doina Precup and Yee Whye Teh, editors, Proceedings of the
34th International Conference on Machine Learning, volume 70 of Proceedings of Machine
Learning Research, pages 1126–1135. PMLR, 2017.

[39] David Ha and Jürgen Schmidhuber. Recurrent world models facilitate policy evolution. In
S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors,
Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.

[40] Philip Becker-Ehmck, Maximilian Karl, Jan Peters, and Patrick van der Smagt. Learning to fly
via deep model-based reinforcement learning. arXiv preprint arXiv:2003.08876, 2020.

[41] Danijar Hafner, Timothy P Lillicrap, Mohammad Norouzi, and Jimmy Ba. Mastering atari with
discrete world models. In International Conference on Learning Representations, 2021.

[42] Danijar Hafner, Jurgis Pasukonis, Jimmy Ba, and Timothy Lillicrap. Mastering diverse domains

through world models, 2023.

[43] Łukasz Kaiser, Mohammad Babaeizadeh, Piotr Miłos, Bła˙zej Osi´nski, Roy H Campbell, Konrad
Czechowski, Dumitru Erhan, Chelsea Finn, Piotr Kozakowski, Sergey Levine, Afroz Mohiuddin,
Ryan Sepassi, George Tucker, and Henryk Michalewski. Model based reinforcement learning
for atari. In International Conference on Learning Representations, 2020.

[44] Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Si-
mon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis, Thore Graepel, et al. Mastering
atari, go, chess and shogi by planning with a learned model. Nature, 588(7839):604–609, 2020.

[45] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-
performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alché-
Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems,
volume 32. Curran Associates, Inc., 2019.

[46] Junyoung Chung, Çaglar Gülçehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation

of gated recurrent neural networks on sequence modeling. 2014.

[47] Maximilian Seitzer, Arash Tavakoli, Dimitrije Antic, and Georg Martius. On the pitfalls of
heteroscedastic uncertainty estimation with probabilistic neural networks. In International
Conference on Learning Representations, 2022.

[48] Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and accurate deep network

learning by exponential linear units (elus), 2015.

[49] Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft actor-critic: Off-
policy maximum entropy deep reinforcement learning with a stochastic actor. In International
conference on machine learning, pages 1861–1870. PMLR, 2018.

[50] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. Layer normalization, 2016.

[51] Cong Lu, Philip J. Ball, Tim G. J. Rudner, Jack Parker-Holder, Michael A. Osborne, and
Yee Whye Teh. Challenges and Opportunities in Offline Reinforcement Learning from Visual
Observations. Transactions on Machine Learning Research, 2023.

[52] Rishabh Agarwal, Max Schwarzer, Pablo Samuel Castro, Aaron C Courville, and Marc Belle-
mare. Deep reinforcement learning at the edge of the statistical precipice. Advances in Neural
Information Processing Systems, 34, 2021.

14

A Computational resources

On a GTX 1080Ti graphics card, AIME typically requires 10 hours of training for phase 1 and 5
hours of training for phase 2 with MDP and LPOMDP setups. The required time nearly doubled
when running with Visual settings, due to heavier visual backbones and rendering. We conduct
experiments on a shared local cluster which uses A100 and RTX8000 GPUs. The newer GPUs can
slightly improve the training speeds but not much since the main computational bottleneck is the
recurrent structure. In terms of one GTX 1080Ti, it will require roughly 50 GPU days to produce the
benchmark results.

B Implementation and training details

We implement all listed methods in PyTorch [45].

For the world model, we use RSSM [17, 19], which offers state-of-the-art performances by splitting
the latent state to be a combination of deterministic and stochastic components. The RSSM implemen-
tation is largely following Dreamer-v1 [19] with continuous stochastic and deterministic variables.
Although newer versions of Dreamer [41, 42] offer some new tricks to improve performance, we
initially choose not to use them for the sake of simplicity. We use a slightly larger state space for
our experiment with 512 deterministic and 128 stochastic dimensions and find it generally eases
the policy training process to collect the datasets. For the Visual setting, the encoder and decoder
are implemented with CNNs. The decoder output a Gaussian distribution with the mean output by
CNN and a fixed variance of 1. For the low-dimensional settings, the encoder is implemented as
an identity function while the decoders are Gaussian distributions with both the mean and variance
parameterised by MLPs. The deterministic part of the state is implemented as a GRU cell [46]. For
the default hyper-parameters, we do not use any free nats [19], KL scaling [19] and KL balancing
[41] tricks in the literature to relax the constraint of the KL term. When decoding low-dimensional
signals, we sometimes observed the decoder yielding a degenerate solution as found in [47]. We use
their β-nll to remedy this problem, and since it re-weights the reconstruction term, we re-weight the
KL term accordingly to maintain the balance.

Without further mention, all the CNN encoders and decoders above are implemented as in [39, 17],
while all the MLPs are with 2 hidden layers and 128 units of each layer with ELU [48] activation
function. All the components are trained with Adam optimiser with a learning rate of 1e−3. For the
stochastic policy, the output distribution is modelled by a TanhGaussian distribution [49] with both
the mean and variance parameterised by neural networks.

For AIME, we consider 100 gradient steps as an epoch. For phase 1, the model is trained for 1000
epochs, while for phase 2 we train the policy for 500 epochs. Both the final model and policy are
from the last epoch without any early stopping criteria.

When training the world model on the Cheetah dataset, we find the default hyper-parameters cannot
stably train a good world model. Thus, we adapt the implementation to exactly the same network
structure as the origin repository. Specifically, the decoders of low-dimensional observations are also
with a fixed variance of 1 and all the MLPs are widened to 512 neurons in each hidden layer and
equipped with Layer Normalisation [50]. For the hyper-parameters, the learning rate is decreased
to 3e−4, and we use free nats of 1.0 and KL balancing of 0.8 to mitigate the collapse and unstable
problem of the KL term. For the LPOMDP setting, we also set the KL scaling parameter β = 0.0002
to relax the constraint. One thing that needs to mention is, while the tricks about the KL term are
helpful for model training, they hurt the results in phase 2. It could be because, in phase 2, the model
is frozen, so that no-more stability issues will be encountered. So in this case it is better to optimise
the policy with the true ELBO.

To be strict with our setup of the two phases, we retrain the world model after data collection for all
the experiments. However, one can also directly use the world model from the trained dreamer agent.
We empirically find these models yield similar results with the world model retrained afterwards on
the same reply buffer. One caveat is that, although it is tempting to also reuse the trained policy as
initialisation in phase 2, we found it is actually harmful to the performance. We conjecture that it is
due to learnt policies being stuck in some local minima that they are unable to escape.

15

For the BCO(0) baseline, the IDM and policy are built by using the same network architecture with
the world model to make a fair comparison. The observations are first processed by the encoder
network, and then get stacked to deal with the temporal information. An MLP is used to decode the
stacked representation to the output distribution. We stack 5 consecutive in this work. We did a grid
search about the width, depth of the MLP and also the number of stacking frames and didn’t find any
increase of the performance. Following the original paper, we split the datasets by 7 : 3, and choose
the finial model based on the validation loss.

C AIME with IDM

In this section, we introduce an alternative variant of AIME which also uses IDM. Recall that in the
Bayesian derivation, we factorised both the posterior and prior of the joint distribution of state and
action with a shared policy network, as in eq. (6) and eq. (7). Alternatively, we can re-factorise the
posterior with IDM, that is

qϕ,θ(st, at−1|st−1, fϕ(ot)) = qϕ(at−1|st−1, fϕ(ot))qϕ(st|st−1, at−1, fϕ(ot)).

(10)

One thing that needs to be noticed here is that the IDM is not in the familiar form of qϕ(at−1|st−1, st).
This is because the latent state in the world model is action dependent so the familiar form is non-
casual in the world model. But we should highlight here that this non-casual structure is a result of
the model we used in phase 1 since we want to reuse the knowledge learnt there. For example, one
can also factorise the joint posterior as

qϕ(st, at−1|st−1, fϕ(ot)) = qϕ(at−1|st−1, st)qϕ(st|st−1, fϕ(ot)).

(11)

However, in this case, the model is different for phase 1.
In this section, we stick to using
the factorisation in eq. (10). Since a new IDM component is introduced, the objective of both
phase 1 and phase 2 need to be modified. For phase 1, since actions are available in the dataset,
the IDM can be treated as a decoder and trained by maximising likelihood. That is, we add
IDM(τ (T )) = (cid:80)T −1
J p1
t=0 log qϕ(at|st, fϕ(ot+1)) to the objective function. For phase 2, since actions
are not available, the IDM serves as the posterior and guides the prior policy through a KL divergence,
i.e. J p2

t=0 −DKL[qϕ(at|st, fϕ(ot+1))||πψ(at|st)].

IDM(τ (T )) = (cid:80)T −1

One caveat about this formulation is that, in phase 1, the IDM forms a loop on the graphical model. In
order to stabilise the training process, we detach the gradient from the IDM to the rest of the network.

D Dataset details

Here we provide extra information about the datasets. The expert return which we normalised against
is shown in Table 1 and Table 2.

Table 1: Average expert return of each demonstration dataset of Walker.

Ddemo

stand
walk
run

Average return

957.87 (max: 1000)
943.79 (max: 1000)
604.10 (max: 1000)

Table 2: Average expert return of each demonstration dataset of Cheetah.

Ddemo

Average return

run
run backwards
flip
flip backwards

888.65 (max: 1000)
218.50 (max: 500)
485.79 (max: 500)
379.91 (max: 500)

16

Table 3: Result on V-D4RL main datasets. Embodiment datasets are marked on the left, and the
demonstration datasets are chosen to be the expert dataset for each task in the origin environment.
Values are averaged over 100 trajectories and reported as accumulated reward divided by 10, as
suggested in the V-D4RL paper.

BCO(0)

AIME

walker-random
walker-medium_replay
walker-mix

2.11 ± 0.91
6.54 ± 6.56
5.32 ± 5.23

12.36 ± 4.69
10.18 ± 4.33
8.49 ± 3.60

cheetah-random
cheetah-medium_replay
cheetah-mix

0.01 ± 0.01
15.47 ± 7.38
16.08 ± 6.61

9.48 ± 4.72
31.47 ± 16.14
40.27 ± 11.52

E Experiments on V-D4RL datasets

We provide here some additional results of AIME on V-D4RL datasets [51] to showcase that AIME
can also work with datasets collected by non-model-based methods. V-D4RL provides multiple
different datasets for the Walker and Cheetah embodiments from DMC Suite, and it is original
designed for offline RL with visual inputs. The datasets are collected by running a few model-free
RL methods and either keep the replay buffer or rollout from a policy checkpoints. Since our setting
requires a bit more exploration in the embodiment datasets to understand the embodiment, we choose
to use their random and medium_replay datasets as the embodiment datasets. The expert datasets are
used as the demonstration datasets. Same as what we did for the Walker embodiment in the main text,
we also mix the two embodiment datasets for each embodiment to form a mix dataset.

The results on these datasets are shown in Table 3. We can see that the performance of both BCO(0)
and AIME is generally low, but AIME still outperform BCO(0) which proves AIME can also handle
datasets generated by model-free methods. The low performance is due to a more constrained setup of
the task, i.e. less amount of embodiment data and less diversity. Except the cheetah-medium_replay
having 400 trajectories, the other three datasets provided by V-D4RL have only 200 trajectories,
which is much less than the 1000 trajectories in the main experiments. Moreover, it is already shown
from Figure 2 and Figure 3 that random datasets do not help much in learning a model, and intuitively
the medium_replay dataset is better but still does not contain enough information to solve the task.

We also conduct experiments on the V-D4RL distracting datasets, to test the performance of AIME
on distracting datasets. For the Walker embodiment, the benchmark provides random datasets with a
distraction level of easy, medium, and hard. We also merge these three levels to form a mix dataset.
Moreover, we also merge this mix dataset with the mix dataset in the second experiment to form a
total_mix dataset. We treat these five datasets as the embodiment dataset and the expert dataset as the
demonstration dataset. For the Cheetah embodiment, the benchmark provides medium and expert
datasets with a distraction level of easy, medium, and hard. We subsample the medium datasets to get
200 trajectories from each level, then merge that with the mix dataset in the second experiment to
form a total_mix dataset. Then the algorithms are using this total_mix dataset as the embodiment
dataset and the expert dataset as the demonstration dataset.

As we can see from the result from Table 4, although we still outperform the BCO(0) baseline, AIME
is impacted significantly by the distractions. This behaviour is expected since the world model is
trained with reconstruction loss. It is not easy to handle observations with distractions. A potential
solution to this problem is to freeze only the dynamics part of the world model and allowing encoders
and decoders to fine-tune their parameters in the second phase. We leave these improvements for our
future works.

F Additional plots

In this section, we will present some additional plots to complement the main text and provide further
insights.

17

Table 4: Result on V-D4RL distracting datasets. Embodiment datasets are marked on the left, and the
demonstration datasets are chosen to be the expert dataset for each task in the origin environment.
Values are averaged over 100 trajectories and reported as accumulated reward divided by 10, as
suggested in the V-D4RL paper.

walker-easy
walker-medium
walker-hard
walker-mix
walker-total_mix

BCO(0)

AIME

2.10 ± 0.88
2.15 ± 0.87
2.15 ± 0.97
2.12 ± 0.86
2.15 ± 0.71

4.73 ± 2.54
3.94 ± 0.99
4.16 ± 1.98
3.81 ± 2.07
12.66 ± 4.51

cheetah-total_mix

16.61 ± 7.28

32.40 ± 14.52

Additional to Figure 2 and Figure 3, we also provide detailed profile plots in Figure 6 and Figure 7
as recommended in [52]. We can see that AIME is normally more stable w.r.t. the performance by
having a smaller decay region. It is clearly shown on such tasks as walk → walk and run → run on
Walker where BCO(0)-MDP has some trails with very low performance, while all variants of AIME
maintain decent performance.

Figure 6: Performance distributions of each method on Walker tasks.

We also present some representative training curves of AIME’s phase 2 from our experiments in
Figure 8. The first three figures show the transfer from the mix dataset to the run task in the three
settings which are the typical success cases of AIME. During the course of training, ELBO is
maximised towards convergence and the MSE between the generated actions and the true actions
decreases. We can also see that for the MDP and LPOMDP settings, the converged ELBO is lower
than the ELBO when evaluated with the true action sequence, indicating there is still space for
improvement. However, for the Visual setting, the converged ELBO exceeds the one with true actions,
which should be attributed to the over-fitting of the world model from phase 1. The last three figures

18

100

50

0

100

50

0

100

50

0

100

50

0

100

50

0

100

50

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

0

0

 random -->  stand

 random -->  walk

 random -->  run

 p2e -->  stand

 p2e -->  walk

 p2e -->  run

 stand -->  stand

 stand -->  walk

 stand -->  run

 walk -->  stand

 walk -->  walk

 walk -->  run

 run -->  stand

 run -->  walk

 run -->  run

 mix -->  stand

 mix -->  walk

 mix -->  run

20
80
Relative expert performance (p)

40

60

100

0

20
80
Relative expert performance (p)

60

40

100

0

20
80
Relative expert performance (p)

60

40

Method

BCO(0)-Visual
BCO(0)-LPOMDP
BCO(0)-MDP
AIME-Visual
AIME-LPOMDP
AIME-MDP

100

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7: Performance distributions of each method on Cheetah tasks.

show the transfer from the random dataset to the three tasks in the Visual settings which we consider
as failure cases. For the stand and walk tasks, none of the metrics are converging. For the run task,
we can observe a severe over-fitting starting from the beginning of the training, and the MSE keeps
increasing. We conjecture these are all due to the less well-trained world models.

19

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

p
>
s
l
a
i
r
t

#

100

50

0

100

50

0

100

50

0

100

50

0

100

50

0

100

50

0

 random -->  run

 random -->  runb

 random -->  flip

 random -->  flipb

 p2e -->  run

 p2e -->  runb

 p2e -->  flip

 p2e -->  flipb

 run -->  run

 run -->  runb

 run -->  flip

 run -->  flipb

 runb -->  run

 runb -->  runb

 runb -->  flip

 runb -->  flipb

Method

BCO(0)-Visual
BCO(0)-LPOMDP
BCO(0)-MDP
AIME-Visual
AIME-LPOMDP
AIME-MDP

 flip -->  run

 flip -->  runb

 flip -->  flip

 flip -->  flipb

 flipb -->  run

 flipb -->  runb

 flipb -->  flip

 flipb -->  flipb

0

20

40

60

80

100

0

20

40

60

80

100

0

20

40

60

80

100

0

20

40

60

80

100

Relative expert performance (p)

Relative expert performance (p)

Relative expert performance (p)

Relative expert performance (p)

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 8: Samples of training curve in phase 2 of AIME. The first three showcase the typical
successful training curves, while the remaining three demonstrate the failure cases. The true_action
is referring to evaluating the trajectories with the true action sequence.

20

ELBO

rec term

KL term

action mse

AIME-MDP mix -> run training curve

0

500

1000

1500

1600

1400

1200

1000

800

AIME
true_action

1600

1800

2000

2200

2400

AIME
true_action

0.70

0.65

0.60

0.55

0.50

0.45

AIME
true_action

normalised returns

AIME

AIME

100

80

60

40

20

0

200

400

0

200

400

0

200

400

0

200

400

0

0

200

400

ELBO

rec term

KL term

action mse

normalised returns

AIME-LPOMDP mix -> run training curve

1500

1000

500

0

2300

2200

2100

2000

1900

AIME
true_action

AIME
true_action

0

100

200

300

400

500

0

100

200

300

400

500

800

1000

1200

1400

1600

1800

2000

0.75

0.70

0.65

0.60

0.55

AIME
true_action

AIME

AIME

80

60

40

20

0

0

100

200

300

400

500

0

100

200

300

400

500

0

100

200

300

400

500

AIME-Visual mix -> run training curve

KL term

action mse

normalised returns

1e5

ELBO

1e5

5.6515

rec term

5.657

5.658

5.659

5.660

5.661

5.662

5.6520

5.6525

5.6530

AIME
true_action

AIME
true_action

500

600

700

800

900

0.85

0.80

0.75

0.70

AIME
true_action

0

200

400

0

200

400

0

200

400

0

200

400

AIME

AIME

80

60

40

20

0

0

200

400

AIME-Visual random -> stand training curve

1e5

ELBO

1e5

rec term

KL term

5.678

5.680

5.682

5.684

5.686

5.688

5.674

5.676

5.678

5.680

5.682

AIME
true_action

400

500

600

700

800

AIME
true_action

AIME
true_action

action mse

normalised returns

AIME

AIME

40

30

20

10

2.0

1.8

1.6

1.4

1.2

1.0

0.8

0

200

400

0

200

400

0

200

400

0

200

400

0

200

400

AIME-Visual random -> walk training curve

1e5

ELBO

AIME
true_action

5.680

5.682

5.684

5.686

5.688

5.674

5.675

5.676

5.677

5.678

5.679

5.680

1e5

rec term

KL term

AIME
true_action

500

600

700

800

900

AIME
true_action

2.0

1.8

1.6

1.4

1.2

1.0

action mse

normalised returns

AIME

AIME

15.0

12.5

10.0

7.5

5.0

2.5

0

200

400

0

200

400

0

200

400

0

200

400

0

200

400

1e5

ELBO

1e5

5.6715

rec term

KL term

action mse

AIME-Visual random -> run training curve

5.680

5.682

5.684

5.686

5.688

AIME
true_action

5.6720

5.6725

5.6730

5.6735

5.6740

5.6745

AIME
true_action

800

1000

1200

1400

AIME
true_action

1.55

1.50

1.45

1.40

1.35

normalised returns

AIME

12

10

8

6

4

AIME

0

200

400

0

200

400

0

200

400

0

200

400

0

200

400

","3 2 0 2 c e D 4 ] G L . s c [ 1 v 9 1 0 2 0 . 2 1 3 2 : v i X r a Action Inference by Maximising Evidence : Zero-Shot Imitation from Observation with World Models Xingyuan Zhang1 , 2∗ , Philip Becker-Ehmck1 , Patrick van der Smagt1,3 , Maximilian Karl1 1Machine Learning Research Lab , Volkswagen Group , 2Technical University of Munich , 3Eötvös Loránd University Budapest { xingyuan.zhang , philip.becker-ehmck , maximilian.karl } @ volkswagen.de Abstract Unlike most reinforcement learning agents which require an unrealistic amount of environment interactions to learn a new behaviour , humans excel at learning quickly by merely observing and imitating others . This ability highly depends on the fact that humans have a model of their own embodiment that allows them to infer the most likely actions that led to the observed behaviour . In this paper , we propose Action Inference by Maximising Evidence ( AIME ) to replicate this behaviour using world models . AIME consists of two distinct phases . In the first phase , the agent learns a world model from its past experience to understand its own body by maximising the evidence lower bound ( ELBO ) . While in the second phase , the agent is given some observation-only demonstrations of an expert performing a novel task and tries to imitate the expert ’ s behaviour . AIME achieves this by defining a policy as an inference model and maximising the evidence of the demonstration under the policy and world model . Our method is `` zero-shot '' in the sense that it does not require further training for the world model or online interactions with the environment after given the demonstration . We empirically validate the zero-shot imitation performance of our method on the Walker and Cheetah embodiment of the DeepMind Control Suite and find it outperforms the state-of-the-art baselines . Code is available at : https : //github . com/argmax-ai/aime . 1 Introduction In recent years , deep reinforcement learning ( DRL ) has enabled intelligent decision-making agents to thrive in multiple fields [ 1 , 2 , 3 , 4 , 5 , 6 ] . However , one of the biggest issues of DRL is sample inefficiency . The dominant framework in DRL is learning from scratch [ 7 ] . Thus , most algorithms require an incredible amount of interactions with the environment [ 1 , 2 , 3 ] . In contrast , cortical animals such as humans are able to quickly learn new tasks through just a few trial-and-error attempts , and can further accelerate their learning process by observing others . An important difference between biological learning and the DRL framework is that the former uses past experience for new tasks . When we try a novel task , we use previously learnt components and generalise to solve the new problem efficiently . This process is augmented by imitation learning [ 8 ] , which allows us to replicate similar behaviours without direct observation of the underlying muscle movements . If the DRL agents could similarly harness observational data , such as the abundant online video data , the sample efficiency may be dramatically improved [ 9 ] . The goal of the problem is related to the traditional well-established Learning from Demonstration ( LfD ) field from the robotics community [ 10 , 11 ] , but instead of relying on knowledge from the engineers and researchers , e.g . mathematical model of robot ’ s dynamic or primitives , we aim to let the robots learn by itself . ∗Corresponding author . 37th Conference on Neural Information Processing Systems ( NeurIPS 2023 ) . Figure 1 : Overview of AIME algorithm . In phase 1 , both observations and actions are provided by the embodiment dataset and the agent learns a variational world model to model the evidence of observations conditioned on the actions . Then the learnt model weights are frozen and transferred to phase 2 . In phase 2 , only the observations are provided by the demonstration dataset , so the agent needs to infer both states and actions . The action inference is achieved by the policy model which samples actions given a state . The grey lines indicate the world model parameters are frozen in phase 2 . Both phases are optimised toward the same objective , i.e . the ELBO . However , directly learning a model from observation-only sequences [ 12 , 13 ] is insufficient for both biological and technical systems . Without knowing the actions that lead to the observations , the observation sequences are highly stochastic and multi-modal [ 14 ] . Trying to infer these unknown actions without prior knowledge of the world is difficult due to the problem of attributing which parts of the observations are influenced by the actions and which parts are governed by normal system evolution or noise . Therefore , in this work , we hypothesise that in order to make best use of observation-only sequences , an agent has to first understand the notion of an action . This can be achieved by learning a model from an agent ’ s past experiences where both the actions and their consequences , i.e . observations , are available . Given such a learnt model which includes a causal model of actions and their effects , it becomes feasible for an agent to infer an action sequence leading to given observation-only data . In this work , we propose a novel algorithm , Action Inference by Maximising Evidence ( AIME ) , to try to replicate the imitation ability of humans . The agent first learns a world model from its past experience by maximising the evidence of these experiences . After receiving some observation-only demonstrations of a novel task , the agent tries to mimic the demonstrator by finding an action sequence that makes the demonstration most likely under the learnt model . This procedure is shown in Figure 1 . Our contribution can be summarised as follows : • We propose AIME , a novel method for imitation from observation . AIME first learns a world model by maximising the evidence of its past experience , then considers the policy as an action inference model and imitates by maximising the evidence of demonstration . • We conduct experiments with a variety of datasets and tasks to demonstrate the superior performance of AIME compared with other state-of-the-art methods . The results showcase the zero-shot transferability of a learnt world model . 2 Problem formulation Consider an MDP problem defined by the tuple { S , A , T , R } , where S is the state space , A is the action space , T : S × A → S is the dynamic function and R : S → R is the reward function . A POMDP adds partial observability upon an MDP with two components : the observation space O and the emission function Ω : S → O . The six components of a POMDP can be categorised into three groups : S , A and T define the embodiment of our agent , O and Ω define the sensors of our agent and 2 Phase 1 : Model Learning Transfer Parameters 𝜙𝜙 , 𝜃𝜃 Phase 2 : Imitation Learning 𝑜𝑜𝑡𝑡 𝑜𝑜𝑡𝑡 𝑜𝑜𝑡𝑡+1 𝑜𝑜𝑡𝑡+1 𝑜𝑜𝑡𝑡+2 𝑜𝑜𝑡𝑡 𝑜𝑜𝑡𝑡+1 𝑜𝑜𝑡𝑡+2 Embodiment dataset { 𝑜𝑜1 , 𝑎𝑎1 , 𝑜𝑜2 , 𝑎𝑎2 … } 𝑎𝑎𝑡𝑡 𝑎𝑎𝑡𝑡 𝑎𝑎𝑡𝑡+1 Demonstration dataset { 𝑜𝑜1 , 𝑜𝑜2 , 𝑜𝑜3 … } 𝑎𝑎𝑡𝑡 𝑎𝑎𝑡𝑡+1 𝑠𝑠𝑡𝑡 𝑠𝑠𝑡𝑡+1 𝑠𝑠𝑡𝑡+2 𝑠𝑠𝑡𝑡 𝑠𝑠𝑡𝑡+1 𝑠𝑠𝑡𝑡+2 𝑞𝑞𝜙𝜙 𝑝𝑝𝜃𝜃 𝜋𝜋𝜓𝜓 ∇𝜙𝜙 , 𝜃𝜃𝐽𝐽 ∇𝜓𝜓𝐽𝐽 𝐽𝐽 𝑜𝑜1 : 𝑇𝑇 , 𝑠𝑠0 : 𝑇𝑇 , 𝑎𝑎0 : 𝑇𝑇−1 = 𝐽𝐽𝑟𝑟𝑟𝑟𝑟𝑟 ( 𝑜𝑜1 : 𝑇𝑇 , 𝑠𝑠0 : 𝑇𝑇 , 𝑎𝑎0 : 𝑇𝑇−1 ) + 𝐽𝐽𝐾𝐾𝐾𝐾 ( 𝑜𝑜1 : 𝑇𝑇 , 𝑠𝑠0 : 𝑇𝑇 , 𝑎𝑎0 : 𝑇𝑇−1 ) R itself defines the task . The goal is to find a policy π : S → A which maximises the accumulated reward , i.e . ( cid:80 ) In this paper , we want to study imitation learning within a fixed embodiment across different tasks . We presume the existence of two datasets for the same embodiment : t rt . • Embodiment dataset Dbody contains trajectories { o0 , a0 , o1 , a1 . . . } that represent past experiences of interacting with the environment . This dataset provides information about the embodiment for the algorithm to learn a model . For example , in this paper , the dataset is a replay buffer filled while solving some tasks with the same embodiment . But in general , it may be any collection of past experiences of the embodiment . • Demonstration dataset Ddemo contains a few expert trajectories { o0 , o1 , o2 . . . } of the embodiment solving a certain task defined by Rdemo . The crucial difference between this dataset and the embodiment dataset is that the actions are not provided anymore since they are not observable from a third-person perspective . The goal of our agent is to use information in Dbody to learn a policy π from Ddemo which can solve the task defined by Rdemo as well as the expert who generated Ddemo . For simplicity , we assume that the two datasets share the same observation space O and the emission model Ω . 3 Methodology In this section , we describe our proposed method , AIME , in detail . AIME consists of two phases . In the first phase , the knowledge of the embodiment is learnt through a form of world model ; while in the second phase , this knowledge is used to imitate the expert . 3.1 Phase 1 : Model Learning In the first phase , we need to learn a model to understand our embodiment . We achieve this by learning a world model . As an analogy to a language model , we define a world model as a probability distribution over sequences of observations . The model can be either unconditioned or conditioned on other factors such as previous observations or actions . For phase 1 , the model needs to be the conditional distribution , i.e . p ( o1 : T |a0 : T −1 ) , to model the effect of the actions . When given an observation sequence , the likelihood of this sequence under the model is referred to as evidence . In this paper , we consider variational world models where the observation is governed by a Markovian hidden state . In the literature , this type of model is also referred to as a state-space model ( SSM ) [ 15 , 16 , 17 , 18 , 19 , 20 ] . Such a variational world model involves four components , namely encoder zt = fϕ ( ot ) , posterior st ∼ qϕ ( st|st−1 , at−1 , zt ) , prior st ∼ pθ ( st|st−1 , at−1 ) , decoder ot ∼ pθ ( ot|st ) . fϕ ( ot ) is the encoder to extract the features from the observation ; qϕ ( st|st−1 , at−1 , zt ) and pθ ( st|st−1 , at−1 ) are the posterior and the prior of the latent state variable ; while pθ ( ot|st ) is the decoder that decodes the observation distribution from the state . ϕ and θ represent the parameters of the inference model and the generative model respectively . Typically , a variational world model is trained by maximising the ELBO which is a lower bound of the log-likelihood , or evidence , of the observation sequence , i.e . log pθ ( o1 : T |a0 : T −1 ) . Given a sequence of observations , actions , and states , the objective function can be computed as J ( o1 : T , s0 : T , a0 : T −1 ) = Jrec ( o1 : T , s0 : T , a0 : T −1 ) + JKL ( o1 : T , s0 : T , a0 : T −1 ) , ( 1 ) ( 2 ) where Jrec ( o1 : T , s0 : T , a0 : T −1 ) = JKL ( o1 : T , s0 : T , a0 : T −1 ) = T ( cid:88 ) t=1 T ( cid:88 ) t=1 log pθ ( ot|st ) , −DKL [ qϕ ( st|st−1 , at−1 , fϕ ( ot ) ) ||pθ ( st|st−1 , at−1 ) ] . ( 3 ) 3 The objective function is composed of two terms : the first term Jrec is the likelihood of the observation under the inferred state , which is usually called the reconstruction loss ; while the second term JKL is the KL divergence between the posterior and the prior distributions of the latent state . To compute the objective function , we use the re-parameterisation trick [ 21 , 22 ] to autoregressively sample the inferred states from the observation and action sequence . Combining all these , we formally define the optimisation problem for this phase as ϕ∗ , θ∗ = argmax ϕ , θ E { o1 : T , a0 : T −1 } ∼Dbody , s0 : T ∼qϕ [ J ( o1 : T , s0 : T , a0 : T −1 ) ] . ( 4 ) 3.2 Phase 2 : Imitation Learning In the second phase , we want to utilise the knowledge of the world model from the first phase to imitate the expert behaviour from the demonstration dataset Ddemo in which only sequences of observations but no actions are available . We derive our algorithm from two different perspectives . The Bayesian derivation Since the actions are unknown in the demonstration , instead of modelling the conditional evidence in phase 1 , we need to model the unconditional evidence , i.e . log pθ ( o1 : T ) . Thus , we also need to model the actions as latent variables together with the states . In this way , the reconstruction term Jrec will stay the same as eq . ( 2 ) , while the KL term will be defined on the joint distribution of states and actions , i.e . JKL ( o1 : T , s0 : T , a0 : T −1 ) = T ( cid:88 ) t=1 −DKL [ qϕ , ψ ( st , at−1|st−1 , fϕ ( ot ) ) ||pθ , ψ ( st , at−1|st−1 ) ] . ( 5 ) If we choose the action inference model in the form of a policy , i.e . πψ ( at|st ) , and share it in both posterior and prior , then the new posterior and prior can be factorised as qϕ , ψ ( st , at−1|st−1 , fϕ ( ot ) ) = πψ ( at−1|st−1 ) qϕ ( st|st−1 , at−1 , fϕ ( ot ) ) and pθ , ψ ( st , at−1|st−1 ) = πψ ( at−1|st−1 ) pθ ( st|st−1 , at−1 ) ( 6 ) ( 7 ) respectively . When we plug them into the eq . ( 5 ) , the policy term cancels and we will get a similar optimisation problem with phase 1 as ψ∗ = argmax ψ Eo1 : T ∼Ddemo , { s0 : T , a0 : T −1 } ∼qϕ∗ , ψ [ J ( o1 : T , s0 : T , a0 : T −1 ) ] . ( 8 ) The main difference between eq . ( 4 ) and eq . ( 8 ) is where the action sequence is coming from . In phase 1 , the action sequence is coming from the embodiment dataset , while in phase 2 , it is sampled from the policy instead since it is not available in the demonstration dataset . The control derivation From another perspective , we can view phase 2 as a control problem . One crucial observation is that , as shown in eq . ( 1 ) , given a trained world model , we can evaluate the lower bound of the evidence of any observation sequence given an associated action sequence as the condition . In a deterministic environment where the inverse dynamics model is injective , the true action sequence that leads to the observation sequence is the most likely under the true model . In general , the true action sequence may not necessarily be the most likely under the model . This is , however , a potential benefit of our approach . We are mainly interested in mimicking the expert ’ s demonstration and may be better able to do so with a different action sequence . Thus , for each observation sequence that we get from the demonstration dataset , finding the missing action sequence can be considered as a trajectory-tracking problem and can be tackled by planning . To be specific , we can find the missing action sequence by solving the optimisation problem a∗ 0 : T −1 = argmax a0 : T −1 Eo1 : T ∼Ddemo , s0 : T ∼qϕ∗ [ J ( o1 : T , s0 : T , a0 : T −1 ) ] . ( 9 ) If we solve the above optimisation problem for every sequence in the demonstration dataset , the problem will be converted to a normal imitation learning problem and can be solved with standard techniques such as behavioural cloning . We can also view this as forming an implicit inverse dynamics model ( IDM ) by inverting a forward model w.r.t . the actions . To make it more efficient , we use amortised inference . We directly define a policy πψ ( at|st ) under the latent state of the world model . By composing the learnt world model and the policy , we can form 4 Algorithm 1 : AIME Data : Embodiment dataset Dbody , Demonstration dataset Ddemo , Learning rate α # Phase 1 : Model Learning Initialise world model parameters ϕ and θ while model has not converged do { o1 : T , a0 : T −1 } ∼ Dbody s0 ← 0 for t = 1 : T do st ∼ qϕ ( st|st−1 , at−1 , fϕ ( ot ) ) Compute objective function J from eq . ( 1 ) Update model parameters ϕ ← ϕ + α∇ϕJ , θ ← θ + α∇θJ # Phase 2 : Imitation Learning Initialise policy parameters ψ while policy has not converged do o1 : T ∼ Ddemo s0 ← 0 for t = 1 : T do at−1 ∼ πψ ( at−1|st−1 ) st ∼ qϕ ( st|st−1 , at−1 , fϕ ( ot ) ) Compute objective function J from eq . ( 1 ) Update policy parameters ψ ← ψ + α∇ψJ a new generative model of the state sequence by the chain of st → at → st+1 → at+1 . . . → sT . Then we will get the same optimisation problem as eq . ( 8 ) . To sum up , in AIME , we use the same objective function – the ELBO – in both phases with the only difference being the source of the action sequence . We provide the pseudo-code for the algorithm in Algorithm 1 with the colour highlighting the different origins of the actions between the two phases . 4 Experiments To test our method , we need multiple environments sharing an embodiment while posing different tasks . Therefore , we consider Walker and Cheetah embodiment from the DeepMind Control Suite ( DMC Suite ) [ 23 ] . Officially , the Walker embodiment has three tasks : stand , walk and run . While the Cheetah embodiment only has one task , run , we add three new tasks , namely run backwards , flip and flip backwards , inspired by previous work [ 24 ] . Following the common practice in the benchmark [ 19 ] , we repeat every action two times when interacting with the environment . For both embodiments , the true state includes both the position and the velocity of each joint and the centre of mass of the body . In order to study the influence of different observation modalities , we consider three settings for each environment : MDP uses the true state as the observation ; Visual uses images as the observation ; LPOMDP uses only the position part of the state as the observation , so that information-wise it is identical to the Visual setting but the information is densely represented in a low-dimensional form . To generate the embodiment and demonstration datasets , we train a Dreamer [ 19 ] agent in the Visual setting for each of the tasks for 1M environment steps . We take the replay buffer of these trained agents as the embodiment datasets Dbody , which contain 1000 trajectories , and consider the converged policy as the expert to collect another 1000 trajectories as the demonstration dataset Ddemo . We only use 100 trajectories for the main experiments , and the remaining trajectories are used for an ablation study . The performance of the policy is measured by accumulated reward . The exact performance of the demonstration dataset can be found in Appendix D. Besides the above embodiment datasets , we also study two datasets generated by purely exploratory behaviour . First , we use a random policy that samples uniformly from the action space to collect 1000 trajectories , and we call this the random dataset . Second , we train a Plan2Explore [ 24 ] agent for 1000 trajectories and label its replay buffer as the p2e dataset . Moreover , for the Walker embodiment , we also merge all the above datasets except the run dataset to form a mix dataset . This resembles a practical setting where one possesses a lot of experience with one embodiment and uses all of it to train a single foundational world model . 5 Figure 2 : Performances on Walker . Each column indicates one task and its associated demonstration dataset , while each row indicates the embodiment datasets used to train the model . The title of each figure is named according to Dbody → Ddemo . Numbers are computed by averaging among 100 trials and then normalised to the percentage of the expert ’ s performance . Error bars are showing one standard deviation . The last row and column are averaged over the corresponding task or dataset . The error bar is large for them due to aggregating performance distributed in a large range . 4.1 Benchmark results We mainly compare our method with BCO ( 0 ) [ 25 ] . BCO ( 0 ) first trains an IDM from the embodiment dataset and then used the trained IDM to label the demonstration dataset and then uses Behavioural Cloning ( BC ) to recover the policy . We do not compare with other methods since they either require further environment interactions [ 26 , 27 ] or use a goal-conditional setting [ 28 ] which does not suit the locomotion tasks . More details about related works can be found in Section 5 . The implementation details can be found in Appendix B . The main results of our comparison are shown in Figure 2 and Figure 3 . Overall , we can see that AIME largely outperforms BCO ( 0 ) in all the environment settings on Walker and on POMDP settings on Cheetah . AIME typically achieves the lowest performance on the Visual setting , but even that is comparable with BCO ( 0 ) -MDP which can access the true states . We attribute the good performance of AIME to two reasons . First , the world model has a better data utilisation rate than the IDM because the world model is trained to reconstruct whole observation sequences , while the IDM only takes 6 Figure 3 : Performances on Cheetah . Each column indicates one task and its associated demonstration dataset , while each row indicates the embodiment datasets used to train the model . The title of each figure is named according to Dbody → Ddemo . runb and flipb are short hands for run backwards and flip backwards . Numbers are computed by averaging among 100 trials and then normalised to the percentage of the expert ’ s performance . Error bars are showing one standard deviation . The last row and column are averaged over the corresponding task or dataset . The error bar is large for them due to aggregating performance distributed in a large range . short clips of the sequence and only predicts the actions . Thus , the world model has less chance to overfit , learns better representations and provides better generalisation . Second , by maximising the evidence , our method strives to find an action sequence that leads to the same outcome , not to recover the true actions . For many systems , the dynamics are not fully invertible . For example , if a human applies force to the wall , since the wall does not move , one can not tell how much force is applied by visual observation . The same situation applies to the Walker and Cheetah when certain joints are locked due to the singular pose . This same phenomenon is also discussed in [ 28 ] . We also find that , comparing with the Walker experiments , the performance on Cheetah is lower and the improvement offered by AIME is smaller . We think it is because the setup for Cheetah is much harder than Walker . Although the tasks sound similar from the names , e.g . flip and flip backward , due to the asymmetrical structure of the embodiment , the behaviour for solving the tasks can be quite different . The difference limits the amount of knowledge that can be transferred from the embodiment dataset to the demonstrations . Moreover , some tasks are built to be hard for imitation . For example , in the demonstration of the flip tasks , the cheetah is `` flying '' in the air and the actions taken there is not relevant for solving the tasks . That leaves only a few actions in the sequence that are actually essential for solving the task . We think this is more challenging for AIME since it needs to infer a sequence of actions , while BCO ( 0 ) is operating on point estimation . That is , when the first few actions can not output reasonable actions to start the flip , then the later actions will create a very noisy 7 gradient since none of them can explain the `` flying '' . In general , poorly modelled regions of the world may lead to noisy gradients for the time steps before it . On the other hand , we can also find most variants achieve a good performance on the run backward demonstration dataset , which is mainly due to low expert performance ( see Appendix D ) for the task that makes imitation easy . Last but not least , since we follow the common practise for the benchmark [ 19 ] , the Cheetah embodiment is operated on 50Hz which is much higher than the 20Hz used in Walker . Higher frequency of operation makes the effect of each individual action , i.e . change in the observation , more subtle and harder to distinguish , which poses an additional challenge for the algorithms . Influence of different datasets As expected , for almost all the variants of methods , transferring within the same task is better than transferring between different tasks . In these settings , BCO ( 0 ) -MDP is comparable with AIME . However , AIME shines in cross-task transfer . Especially when transferring between run and walk tasks and transferring from stand to run on Walker , AIME outperforms the baselines by a large margin , which indicates the strong generalisability of a forward model over an inverse model . We also find that AIME makes substantially better use of exploratory data . On Walker , AIME largely outperforms baselines when using the p2e dataset as the embodiment dataset and outperforms most variants when using the random dataset as the embodiment dataset . Moreover , when transferring from the mix dataset , except for the MDP version , AIME outperforms other variants that train the world model on just any single individual task dataset of the mixed dataset . This showcases the scalability of a world model to be trained on a diverse set of experiences , which could be more valuable in real-world scenarios . Influence of observation modality Compared with BCO ( 0 ) , AIME is quite robust to the choice of observation modality . We can see a clear ladder pattern with BCO ( 0 ) when changing the setting from hard to easy , while for AIME the result is similar for each modality . However , we can still notice a small difference when comparing LPOMDP and Visual settings . Although these observations provide the same information , we find AIME in the LPOMDP setting performs better than in the Visual setting in most test cases . We attribute it to the fact that low-dimension signals have denser information and offer a smoother landscape in the evidence space than the pixels so that it can provide a more useful gradient to guide the action inference . Surprisingly , although having access to more information , AIME-MDP performs worse than AIME-LPOMDP on average . The biggest gaps happen when transferring from exploratory datasets , i.e . the p2e dataset on Walker and the random dataset on Cheetah . We conjecture this to the fact the world model is not trained well with the default hyper-parameters , but we defer further investigation to future work . 4.2 Ablation studies In this section , we conduct some ablation studies to investigate how AIME ’ s performance is influenced by different components and design choices . We will mainly focus on using the mix embodiment dataset and transfer to run task , which represents a more realistic setting where we want to use experience from multiple tasks to transfer to a new task . Sample efficiency and scalability To test these properties , we vary the number of demonstrations within { 1 , 2 , 5 , 10 , 20 , 50 , 100 , 200 , 500 , 1000 } . We also include BC with the true action as an oracle baseline . The results are shown in Figure 4 . BCO ( 0 ) struggles with low-data scenarios and typically needs at least 10 to 20 demonstrations to surpass the performance of a random policy . In contrast , AIME demonstrates continual improvement with as few as 2 trajectories . And surprisingly , thanks to the generalisation ability of the world model , AIME even outperforms oracle BC when the demonstrations are limited . These demonstrate the superior sample efficiency of the method . Moreover , the performance of AIME keeps increasing as more trajectories are provided beyond 100 , which showcases the scalability of the method . Objective function The objective function , i.e . ELBO , consists of two terms , the reconstruction term Jrec and the KL term JKL . To investigate the role that each term plays in AIME , we retrain two variants of AIME by removing either of the terms . As we can see from Figure 5 , removing either term will negatively impact the results . When we compare the two variants , only using the KL term is better in settings with low-dimensional signals , while using only the reconstruction term yields a slightly better result for the high-dimensional image signal . But on all settings , the performance of using only the KL term is very close to the one that use both terms . This suggests that the latent state in the world model has already mostly captured the essential part of the environment . Although it is 8 Figure 4 : Ablation of the number of demonstrations on mix → run transfer on the Walker embodiment . The performance is shown as the normalised returns over 3 seeds and 100 trials for each seed . The shaded region represents one standard deviation . Figure 5 : Ablation studies on mix → run transfer on the Walker embodiment . Numbers are computed by averaging among 3 seeds and 100 trials for each seed , and then normalised to the percentage of the expert ’ s performance . Error bars are showing one standard deviation . still worse than using both terms , it sheds some light on the potential of incorporating decoder-free models [ 29 ] into the AIME framework . Components Compared with the BCO ( 0 ) baseline , AIME consists of two distinct modifications : one is to use an SSM to integrate sequences and train the policy upon its latent representation ; the other is to form an implicit IDM via gradients rather than training an IDM explicitly . We design two baselines to investigate the two components . First , to remove the SSM , we train a forward dynamics model directly on the observations of the embodiment dataset and use that as an implicit IDM for imitation on the demonstration dataset . We term this variant IIDM . Second , we train a separate IDM upon the trained latent state of the world model and use that to guide the policy learning in phase 2 . The detailed derivation of the IDM formulation can be found in Appendix C. Figure 5 clearly demonstrates the significance of the latent representation for performance . Without the latent representation , the results are severely compromised across all settings . However , when compared to BCO ( 0 ) , the IIDM does provide assistance in the high-dimensional Visual setting , where training an IDM directly from the observation space can be extremely challenging . While having IDM on the latent representation leads to a better performance comparing with BCO ( 0 ) , but it still performs worse than AIME , especially on the POMDP settings . 5 Related works Imitation learning from observations Most previous works on imitation learning from only ob- servation can be roughly categorised into two groups , one based on IDMs [ 25 , 9 , 30 , 28 ] and one based on generative adversarial imitation learning ( GAIL ) [ 31 , 26 , 27 ] . The core component of the first group is to learn an IDM that maps a state transition pair to the action that caused the transition . [ 25 , 9 ] use the IDM to label the expert ’ s observation sequences , then solve the imitation learning problem with standard BC . [ 30 , 28 ] extend the IDM to a goal-conditioned setting in which the IDM is trained to be conditioned on a future frame as the goal instead of only the next frame . During deployment , the task is communicated on the fly by the user in the form of key-frames as goals . The 9 120 MDP s n r u t e R d e s i l a m r o N 100 80 60 40 20 0 BC ( oracle ) BCO ( 0 ) AIME random 100 101 102 103 Number of Demonstrations 120 LPOMDP s n r u t e R d e s i l a m r o N 100 80 60 40 20 0 BC ( oracle ) BCO ( 0 ) AIME random 100 101 102 103 Number of Demonstrations 120 Visual s n r u t e R d e s i l a m r o N 100 80 60 40 20 0 BC ( oracle ) BCO ( 0 ) AIME random 100 101 102 103 Number of Demonstrations 100 s n r u t e R d e s i l a m r o N 80 60 40 20 0 BCO ( 0 ) AIME AIME w/o Rec AIME w/o KL IIDM AIME w/ IDM MDP LPOMDP Visual setup mainly suits for the robot manipulation tasks in their paper since the user can easily specify the goals by doing the manipulation himself , but not suits for the locomotion tasks , in which it is not clear what a long-term goal of observation is and also not practical set the next observation as the goal and demonstrate that in a high frequency by the user . Different from these methods , our approach uses a forward model to capture the knowledge of the embodiment . In the second group of approaches , the core component is a discriminator that distinguishes the demonstrator ’ s and the agent ’ s observation trajectories . Then the discriminator serves as a reward function , and the agent ’ s policy is trained by RL [ 31 ] . As a drawback , in order to train this discriminator the agent has to constantly interact with the environment to produce negative samples . Different from these methods , our method does not require further interactions with the environment , enabling zero-shot imitation from the demonstration dataset . Besides the majority , there are also works [ 32 , 33 ] don ’ t strictly fit to the two groups . [ 32 ] also use forward model like us by learning a latent action policy and a forward dynamic based on the latent action . However , it still needs online environment interactions to calibrate the latent actions to the real actions . [ 33 ] is hybrid method that uses both of the components and focus on a setting that the demonstrations are coming from a different embodiment . Reusing learnt components in decision-making Although transferring pre-trained models has become a dominant approach in natural language processing ( NLP ) [ 34 , 35 , 36 ] and has been getting more popular in computer vision ( CV ) [ 37 , 36 ] , reusing learnt components is less studied in the field of decision-making [ 7 ] . Most existing works focus on transferring policies [ 38 , 9 , 7 ] . On the other hand , the world model , a type of powerful perception model , that is purely trained by self-supervised learning lies behind the recent progress of model-based reinforcement learning [ 39 , 17 , 19 , 40 , 41 , 42 , 43 , 44 ] . However , the transferability of these world models is not well-studied . [ 24 ] learns a policy by using a pre-trained world model from exploration data and demonstrates superior zero-shot and few-shot abilities . We improve upon this direction by studying a different setting , i.e . imitation learning . In particular , we communicate the task to the model by observing the expert while [ 24 ] communicates the task by a ground truth reward function which is less accessible in a real-world setting . 6 Discussion & conclusion In this paper , we present AIME , a model-based method for imitation from observations . The core of the method exploits the power of a pre-trained world model and inverses it w.r.t . action inputs by taking the gradients . On the Walker and Cheetah embodiments from the DMC Suite , we demonstrate superior performance compared to baselines , even when some baselines can access the true state . The results showcase the zero-shot ability of the learnt world model . Although AIME performs well , there are still limitations . First , humans mostly observe others with vision . Although AIME works quite well in the Visual setting , there is still a gap compared with the LPOMDP setting where the low-dimensional signals are observed . We attribute this to the fact that the loss surface of the pixel reconstruction loss may not be smooth enough to allow the gradient method to find an equally good solution . Second , in this paper , we only study the simplest setting where both the embodiment and sensor layout are fixed across tasks . On the other hand , humans observe others in a third-person perspective and can also imitate animals whose body is not even similar to humans ’ . Relaxing these assumptions will open up possibilities to transfer across different embodiments and even directly from human videos . Third , for some tasks , even humans can not achieve zero-shot imitation by only watching others . This may be due to the task ’ s complexity or completely unfamiliar skills . So , even with proper instruction , humans still need to practise in the environment and learn something new to solve some tasks . This motivates an online learning phase 3 as an extension to our framework . We defer these topics to future work . We hope this paper demonstrates the great potential of transferring a learnt world model , incentivises more people to work in this direction and encourages researchers to also share their learnt world model to contribute to the community . Acknowledgments and Disclosure of Funding We want to acknowledge Elie Aljalbout for the insightful discussion during the initial stage of the project and Botond Cseke for mathematical support . 10 References [ 1 ] Volodymyr Mnih , Koray Kavukcuoglu , David Silver , Andrei A. Rusu , Joel Veness , Marc G. Bellemare , Alex Graves , Martin Riedmiller , Andreas K. Fidjeland , Georg Ostrovski , Stig Pe- tersen , Charles Beattie , Amir Sadik , Ioannis Antonoglou , Helen King , Dharshan Kumaran , Daan Wierstra , Shane Legg , and Demis Hassabis . Human-level control through deep reinforcement learning . Nature , 518 ( 7540 ) :529–533 , 2015 . [ 2 ] David Silver , Aja Huang , Chris J. Maddison , Arthur Guez , Laurent Sifre , George van den Driess- che , Julian Schrittwieser , Ioannis Antonoglou , Veda Panneershelvam , Marc Lanctot , Sander Dieleman , Dominik Grewe , John Nham , Nal Kalchbrenner , Ilya Sutskever , Timothy Lillicrap , Madeleine Leach , Koray Kavukcuoglu , Thore Graepel , and Demis Hassabis . Mastering the game of Go with deep neural networks and tree search . Nature , 529 ( 7587 ) :484–489 , 2016 . [ 3 ] Oriol Vinyals , Igor Babuschkin , Wojciech M. Czarnecki , Michaël Mathieu , Andrew Dudzik , Junyoung Chung , David H. Choi , Richard Powell , Timo Ewalds , Petko Georgiev , Junhyuk Oh , Dan Horgan , Manuel Kroiss , Ivo Danihelka , Aja Huang , Laurent Sifre , Trevor Cai , John P. Agapiou , Max Jaderberg , Alexander S. Vezhnevets , Rémi Leblond , Tobias Pohlen , Valentin Dalibard , David Budden , Yury Sulsky , James Molloy , Tom L. Paine , Caglar Gulcehre , Ziyu Wang , Tobias Pfaff , Yuhuai Wu , Roman Ring , Dani Yogatama , Dario Wünsch , Katrina McKin- ney , Oliver Smith , Tom Schaul , Timothy Lillicrap , Koray Kavukcuoglu , Demis Hassabis , Chris Apps , and David Silver . Grandmaster level in StarCraft II using multi-agent reinforcement learning . Nature , 575 ( 7782 ) :350–354 , 2019 . [ 4 ] Suyoung Choi , Gwanghyeon Ji , Jeongsoo Park , Hyeongjun Kim , Juhyeok Mun , Jeong Hyun Lee , and Jemin Hwangbo . Learning quadrupedal locomotion on deformable terrain . Science Robotics , 8 ( 74 ) : eade2256 , 2023 . [ 5 ] OpenAI , Ilge Akkaya , Marcin Andrychowicz , Maciek Chociej , Mateusz Litwin , Bob McGrew , Arthur Petron , Alex Paino , Matthias Plappert , Glenn Powell , Raphael Ribas , Jonas Schneider , Nikolas Tezak , Jerry Tworek , Peter Welinder , Lilian Weng , Qiming Yuan , Wojciech Zaremba , and Lei Zhang . Solving rubik ’ s cube with a robot hand , 2019 . [ 6 ] Long Ouyang , Jeffrey Wu , Xu Jiang , Diogo Almeida , Carroll Wainwright , Pamela Mishkin , Chong Zhang , Sandhini Agarwal , Katarina Slama , Alex Gray , John Schulman , Jacob Hilton , Fraser Kelton , Luke Miller , Maddie Simens , Amanda Askell , Peter Welinder , Paul Christiano , Jan Leike , and Ryan Lowe . Training language models to follow instructions with human feedback . In Alice H. Oh , Alekh Agarwal , Danielle Belgrave , and Kyunghyun Cho , editors , Advances in Neural Information Processing Systems , 2022 . [ 7 ] Rishabh Agarwal , Max Schwarzer , Pablo Samuel Castro , Aaron Courville , and Marc G Belle- mare . Reincarnating reinforcement learning : Reusing prior computation to accelerate progress . In Alice H. Oh , Alekh Agarwal , Danielle Belgrave , and Kyunghyun Cho , editors , Advances in Neural Information Processing Systems , 2022 . [ 8 ] Marco Iacoboni . 60:653–70 , 2008 . Imitation , empathy , and mirror neurons . Annual review of psychology , [ 9 ] Bowen Baker , Ilge Akkaya , Peter Zhokov , Joost Huizinga , Jie Tang , Adrien Ecoffet , Brandon Houghton , Raul Sampedro , and Jeff Clune . Video pretraining ( VPT ) : Learning to act by watching unlabeled online videos . In Alice H. Oh , Alekh Agarwal , Danielle Belgrave , and Kyunghyun Cho , editors , Advances in Neural Information Processing Systems , 2022 . [ 10 ] Yezhou Yang , Yi Li , Cornelia Fermuller , and Yiannis Aloimonos . Robot learning manipulation action plans by `` watching '' ; unconstrained videos from the world wide web . Proceedings of the AAAI Conference on Artificial Intelligence , 29 ( 1 ) , 2015 . [ 11 ] Y. Kuniyoshi , M. Inaba , and H. Inoue . Learning by watching : extracting reusable task knowledge from visual observation of human performance . IEEE Transactions on Robotics and Automation , 10 ( 6 ) :799–822 , 1994 . 11 [ 12 ] Younggyo Seo , Kimin Lee , Stephen L James , and Pieter Abbeel . Reinforcement learning with action-free pre-training from videos . In Kamalika Chaudhuri , Stefanie Jegelka , Le Song , Csaba Szepesvari , Gang Niu , and Sivan Sabato , editors , Proceedings of the 39th International Conference on Machine Learning , volume 162 of Proceedings of Machine Learning Research , pages 19561–19579 . PMLR , 2022 . [ 13 ] Alejandro Escontrela , Ademi Adeniji , Wilson Yan , Ajay Jain , Xue Bin Peng , Ken Goldberg , Youngwoon Lee , Danijar Hafner , and Pieter Abbeel . Video Prediction Models as Rewards for Reinforcement Learning , 2023 . [ 14 ] Mohammad Babaeizadeh , Chelsea Finn , Dumitru Erhan , Roy H. Campbell , and Sergey Levine . Stochastic variational video prediction . In International Conference on Learning Representa- tions , 2018 . [ 15 ] Manuel Watter , Jost Springenberg , Joschka Boedecker , and Martin Riedmiller . Embed to control : A locally linear latent dynamics model for control from raw images . Advances in neural information processing systems , 28 , 2015 . [ 16 ] Maximilian Karl , Maximilian Soelch , Justin Bayer , and Patrick van der Smagt . Deep variational bayes filters : Unsupervised learning of state space models from raw data . In International Conference on Learning Representations , 2017 . [ 17 ] Danijar Hafner , Timothy Lillicrap , Ian Fischer , Ruben Villegas , David Ha , Honglak Lee , and James Davidson . Learning latent dynamics for planning from pixels . In International Conference on Machine Learning , pages 2555–2565 , 2019 . [ 18 ] Philip Becker-Ehmck , Jan Peters , and Patrick Van Der Smagt . Switching linear dynamics for variational Bayes filtering . In Kamalika Chaudhuri and Ruslan Salakhutdinov , editors , Proceed- ings of the 36th International Conference on Machine Learning , volume 97 of Proceedings of Machine Learning Research , pages 553–562 . PMLR , 2019 . [ 19 ] Danijar Hafner , Timothy Lillicrap , Jimmy Ba , and Mohammad Norouzi . Dream to control : Learning behaviors by latent imagination . In International Conference on Learning Representa- tions , 2020 . [ 20 ] Alexej Klushyn , Richard Kurle , Maximilian Soelch , Botond Cseke , and Patrick van der Smagt . Latent matters : Learning deep state-space models . Advances in Neural Information Processing Systems , 34:10234–10245 , 2021 . [ 21 ] Diederik P. Kingma and Max Welling . Auto-Encoding Variational Bayes . In 2nd International Conference on Learning Representations , ICLR 2014 , Banff , AB , Canada , April 14-16 , 2014 , Conference Track Proceedings , 2014 . [ 22 ] Danilo Jimenez Rezende , Shakir Mohamed , and Daan Wierstra . Stochastic backpropagation and approximate inference in deep generative models . In Eric P. Xing and Tony Jebara , editors , Proceedings of the 31st International Conference on Machine Learning , volume 32 of Proceedings of Machine Learning Research , pages 1278–1286 , Bejing , China , 22–24 Jun 2014 . PMLR . [ 23 ] Saran Tunyasuvunakool , Alistair Muldal , Yotam Doron , Siqi Liu , Steven Bohez , Josh Merel , Tom Erez , Timothy Lillicrap , Nicolas Heess , and Yuval Tassa . dm_control : Software and tasks for continuous control . Software Impacts , 6:100022 , 2020 . [ 24 ] Ramanan Sekar , Oleh Rybkin , Kostas Daniilidis , Pieter Abbeel , Danijar Hafner , and Deepak Pathak . Planning to explore via self-supervised world models . In ICML , 2020 . [ 25 ] Faraz Torabi , Garrett Warnell , and Peter Stone . Behavioral cloning from observation . International Joint Conferences on Artificial Intelligence , pages 4950–4957 , 2018 . In [ 26 ] Faraz Torabi , Garrett Warnell , and Peter Stone . Generative adversarial imitation from observa- tion , 2018 . 12 [ 27 ] Chenhao Li , Marin Vlastelica , Sebastian Blaes , Jonas Frey , Felix Grimminger , and Georg Martius . Learning agile skills via adversarial imitation of rough partial demonstrations . In 6th Annual Conference on Robot Learning , 2022 . [ 28 ] Deepak Pathak , Parsa Mahmoudieh , Guanghao Luo , Pulkit Agrawal , Dian Chen , Yide Shentu , Evan Shelhamer , Jitendra Malik , Alexei A. Efros , and Trevor Darrell . Zero-shot visual imitation . In ICLR , 2018 . [ 29 ] Nicklas A Hansen , Hao Su , and Xiaolong Wang . Temporal difference learning for model predictive control . In Kamalika Chaudhuri , Stefanie Jegelka , Le Song , Csaba Szepesvari , Gang Niu , and Sivan Sabato , editors , Proceedings of the 39th International Conference on Machine Learning , volume 162 of Proceedings of Machine Learning Research , pages 8387–8406 . PMLR , 2022 . [ 30 ] Ashvin Nair , Dian Chen , Pulkit Agrawal , Phillip Isola , Pieter Abbeel , Jitendra Malik , and Sergey Levine . Combining self-supervised learning and imitation for vision-based rope manipulation . In 2017 IEEE International Conference on Robotics and Automation ( ICRA ) , page 2146–2153 . IEEE Press , 2017 . [ 31 ] Jonathan Ho and Stefano Ermon . Generative adversarial imitation learning . In D. Lee , M. Sugiyama , U. Luxburg , I. Guyon , and R. Garnett , editors , Advances in Neural Information Processing Systems , volume 29 . Curran Associates , Inc. , 2016 . [ 32 ] Ashley Edwards , Himanshu Sahni , Yannick Schroecker , and Charles Isbell . Imitating latent policies from observation . In Kamalika Chaudhuri and Ruslan Salakhutdinov , editors , Proceed- ings of the 36th International Conference on Machine Learning , volume 97 of Proceedings of Machine Learning Research , pages 1755–1763 . PMLR , 2019 . [ 33 ] Karl Schmeckpeper , Oleh Rybkin , Kostas Daniilidis , Sergey Levine , and Chelsea Finn . Re- inforcement learning with videos : Combining offline observations with interaction . In Jens Kober , Fabio Ramos , and Claire Tomlin , editors , Proceedings of the 2020 Conference on Robot Learning , volume 155 of Proceedings of Machine Learning Research , pages 339–354 . PMLR , 2021 . [ 34 ] Jacob Devlin , Ming-Wei Chang , Kenton Lee , and Kristina Toutanova . BERT : pre-training of deep bidirectional transformers for language understanding . In Jill Burstein , Christy Doran , and Thamar Solorio , editors , Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics : Human Language Technologies , NAACL-HLT 2019 , Minneapolis , MN , USA , June 2-7 , 2019 , Volume 1 ( Long and Short Papers ) , pages 4171–4186 . Association for Computational Linguistics , 2019 . [ 35 ] Alec Radford , Jeff Wu , Rewon Child , David Luan , Dario Amodei , and Ilya Sutskever . Language models are unsupervised multitask learners . 2019 . [ 36 ] Rishi Bommasani , Drew A. Hudson , Ehsan Adeli , Russ Altman , Simran Arora , Sydney von Arx , Michael S. Bernstein , Jeannette Bohg , Antoine Bosselut , Emma Brunskill , Erik Brynjolfsson , Shyamal Buch , Dallas Card , Rodrigo Castellon , Niladri Chatterji , Annie Chen , Kathleen Creel , Jared Quincy Davis , Dora Demszky , Chris Donahue , Moussa Doumbouya , Esin Durmus , Stefano Ermon , John Etchemendy , Kawin Ethayarajh , Li Fei-Fei , Chelsea Finn , Trevor Gale , Lauren Gillespie , Karan Goel , Noah Goodman , Shelby Grossman , Neel Guha , Tatsunori Hashimoto , Peter Henderson , John Hewitt , Daniel E. Ho , Jenny Hong , Kyle Hsu , Jing Huang , Thomas Icard , Saahil Jain , Dan Jurafsky , Pratyusha Kalluri , Siddharth Karamcheti , Geoff Keeling , Fereshte Khani , Omar Khattab , Pang Wei Koh , Mark Krass , Ranjay Krishna , Rohith Kuditipudi , Ananya Kumar , Faisal Ladhak , Mina Lee , Tony Lee , Jure Leskovec , Isabelle Levent , Xiang Lisa Li , Xuechen Li , Tengyu Ma , Ali Malik , Christopher D. Manning , Suvir Mirchandani , Eric Mitchell , Zanele Munyikwa , Suraj Nair , Avanika Narayan , Deepak Narayanan , Ben Newman , Allen Nie , Juan Carlos Niebles , Hamed Nilforoshan , Julian Nyarko , Giray Ogut , Laurel Orr , Isabel Papadimitriou , Joon Sung Park , Chris Piech , Eva Portelance , Christopher Potts , Aditi Raghunathan , Rob Reich , Hongyu Ren , Frieda Rong , Yusuf Roohani , Camilo Ruiz , Jack Ryan , Christopher Ré , Dorsa Sadigh , Shiori Sagawa , Keshav Santhanam , Andy Shih , Krishnan Srinivasan , Alex Tamkin , Rohan Taori , Armin W. Thomas , Florian Tramèr , Rose E. Wang , William Wang , Bohan Wu , Jiajun Wu , Yuhuai Wu , Sang Michael Xie , Michihiro Yasunaga , 13 Jiaxuan You , Matei Zaharia , Michael Zhang , Tianyi Zhang , Xikun Zhang , Yuhui Zhang , Lucia Zheng , Kaitlyn Zhou , and Percy Liang . On the opportunities and risks of foundation models , 2021 . [ 37 ] Kaiming He , Xinlei Chen , Saining Xie , Yanghao Li , Piotr Dollár , and Ross Girshick . Masked autoencoders are scalable vision learners . In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 16000–16009 , 2022 . [ 38 ] Chelsea Finn , Pieter Abbeel , and Sergey Levine . Model-agnostic meta-learning for fast adap- tation of deep networks . In Doina Precup and Yee Whye Teh , editors , Proceedings of the 34th International Conference on Machine Learning , volume 70 of Proceedings of Machine Learning Research , pages 1126–1135 . PMLR , 2017 . [ 39 ] David Ha and Jürgen Schmidhuber . Recurrent world models facilitate policy evolution . In S. Bengio , H. Wallach , H. Larochelle , K. Grauman , N. Cesa-Bianchi , and R. Garnett , editors , Advances in Neural Information Processing Systems , volume 31 . Curran Associates , Inc. , 2018 . [ 40 ] Philip Becker-Ehmck , Maximilian Karl , Jan Peters , and Patrick van der Smagt . Learning to fly via deep model-based reinforcement learning . arXiv preprint arXiv:2003.08876 , 2020 . [ 41 ] Danijar Hafner , Timothy P Lillicrap , Mohammad Norouzi , and Jimmy Ba . Mastering atari with discrete world models . In International Conference on Learning Representations , 2021 . [ 42 ] Danijar Hafner , Jurgis Pasukonis , Jimmy Ba , and Timothy Lillicrap . Mastering diverse domains through world models , 2023 . [ 43 ] Łukasz Kaiser , Mohammad Babaeizadeh , Piotr Miłos , Bła˙zej Osi´nski , Roy H Campbell , Konrad Czechowski , Dumitru Erhan , Chelsea Finn , Piotr Kozakowski , Sergey Levine , Afroz Mohiuddin , Ryan Sepassi , George Tucker , and Henryk Michalewski . Model based reinforcement learning for atari . In International Conference on Learning Representations , 2020 . [ 44 ] Julian Schrittwieser , Ioannis Antonoglou , Thomas Hubert , Karen Simonyan , Laurent Sifre , Si- mon Schmitt , Arthur Guez , Edward Lockhart , Demis Hassabis , Thore Graepel , et al . Mastering atari , go , chess and shogi by planning with a learned model . Nature , 588 ( 7839 ) :604–609 , 2020 . [ 45 ] Adam Paszke , Sam Gross , Francisco Massa , Adam Lerer , James Bradbury , Gregory Chanan , Trevor Killeen , Zeming Lin , Natalia Gimelshein , Luca Antiga , Alban Desmaison , Andreas Kopf , Edward Yang , Zachary DeVito , Martin Raison , Alykhan Tejani , Sasank Chilamkurthy , Benoit Steiner , Lu Fang , Junjie Bai , and Soumith Chintala . Pytorch : An imperative style , high- performance deep learning library . In H. Wallach , H. Larochelle , A. Beygelzimer , F. d'Alché- Buc , E. Fox , and R. Garnett , editors , Advances in Neural Information Processing Systems , volume 32 . Curran Associates , Inc. , 2019 . [ 46 ] Junyoung Chung , Çaglar Gülçehre , KyungHyun Cho , and Yoshua Bengio . Empirical evaluation of gated recurrent neural networks on sequence modeling . 2014 . [ 47 ] Maximilian Seitzer , Arash Tavakoli , Dimitrije Antic , and Georg Martius . On the pitfalls of heteroscedastic uncertainty estimation with probabilistic neural networks . In International Conference on Learning Representations , 2022 . [ 48 ] Djork-Arné Clevert , Thomas Unterthiner , and Sepp Hochreiter . Fast and accurate deep network learning by exponential linear units ( elus ) , 2015 . [ 49 ] Tuomas Haarnoja , Aurick Zhou , Pieter Abbeel , and Sergey Levine . Soft actor-critic : Off- policy maximum entropy deep reinforcement learning with a stochastic actor . In International conference on machine learning , pages 1861–1870 . PMLR , 2018 . [ 50 ] Jimmy Lei Ba , Jamie Ryan Kiros , and Geoffrey E. Hinton . Layer normalization , 2016 . [ 51 ] Cong Lu , Philip J . Ball , Tim G. J. Rudner , Jack Parker-Holder , Michael A. Osborne , and Yee Whye Teh . Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations . Transactions on Machine Learning Research , 2023 . [ 52 ] Rishabh Agarwal , Max Schwarzer , Pablo Samuel Castro , Aaron C Courville , and Marc Belle- mare . Deep reinforcement learning at the edge of the statistical precipice . Advances in Neural Information Processing Systems , 34 , 2021 . 14 A Computational resources On a GTX 1080Ti graphics card , AIME typically requires 10 hours of training for phase 1 and 5 hours of training for phase 2 with MDP and LPOMDP setups . The required time nearly doubled when running with Visual settings , due to heavier visual backbones and rendering . We conduct experiments on a shared local cluster which uses A100 and RTX8000 GPUs . The newer GPUs can slightly improve the training speeds but not much since the main computational bottleneck is the recurrent structure . In terms of one GTX 1080Ti , it will require roughly 50 GPU days to produce the benchmark results . B Implementation and training details We implement all listed methods in PyTorch [ 45 ] . For the world model , we use RSSM [ 17 , 19 ] , which offers state-of-the-art performances by splitting the latent state to be a combination of deterministic and stochastic components . The RSSM implemen- tation is largely following Dreamer-v1 [ 19 ] with continuous stochastic and deterministic variables . Although newer versions of Dreamer [ 41 , 42 ] offer some new tricks to improve performance , we initially choose not to use them for the sake of simplicity . We use a slightly larger state space for our experiment with 512 deterministic and 128 stochastic dimensions and find it generally eases the policy training process to collect the datasets . For the Visual setting , the encoder and decoder are implemented with CNNs . The decoder output a Gaussian distribution with the mean output by CNN and a fixed variance of 1 . For the low-dimensional settings , the encoder is implemented as an identity function while the decoders are Gaussian distributions with both the mean and variance parameterised by MLPs . The deterministic part of the state is implemented as a GRU cell [ 46 ] . For the default hyper-parameters , we do not use any free nats [ 19 ] , KL scaling [ 19 ] and KL balancing [ 41 ] tricks in the literature to relax the constraint of the KL term . When decoding low-dimensional signals , we sometimes observed the decoder yielding a degenerate solution as found in [ 47 ] . We use their β-nll to remedy this problem , and since it re-weights the reconstruction term , we re-weight the KL term accordingly to maintain the balance . Without further mention , all the CNN encoders and decoders above are implemented as in [ 39 , 17 ] , while all the MLPs are with 2 hidden layers and 128 units of each layer with ELU [ 48 ] activation function . All the components are trained with Adam optimiser with a learning rate of 1e−3 . For the stochastic policy , the output distribution is modelled by a TanhGaussian distribution [ 49 ] with both the mean and variance parameterised by neural networks . For AIME , we consider 100 gradient steps as an epoch . For phase 1 , the model is trained for 1000 epochs , while for phase 2 we train the policy for 500 epochs . Both the final model and policy are from the last epoch without any early stopping criteria . When training the world model on the Cheetah dataset , we find the default hyper-parameters can not stably train a good world model . Thus , we adapt the implementation to exactly the same network structure as the origin repository . Specifically , the decoders of low-dimensional observations are also with a fixed variance of 1 and all the MLPs are widened to 512 neurons in each hidden layer and equipped with Layer Normalisation [ 50 ] . For the hyper-parameters , the learning rate is decreased to 3e−4 , and we use free nats of 1.0 and KL balancing of 0.8 to mitigate the collapse and unstable problem of the KL term . For the LPOMDP setting , we also set the KL scaling parameter β = 0.0002 to relax the constraint . One thing that needs to mention is , while the tricks about the KL term are helpful for model training , they hurt the results in phase 2 . It could be because , in phase 2 , the model is frozen , so that no-more stability issues will be encountered . So in this case it is better to optimise the policy with the true ELBO . To be strict with our setup of the two phases , we retrain the world model after data collection for all the experiments . However , one can also directly use the world model from the trained dreamer agent . We empirically find these models yield similar results with the world model retrained afterwards on the same reply buffer . One caveat is that , although it is tempting to also reuse the trained policy as initialisation in phase 2 , we found it is actually harmful to the performance . We conjecture that it is due to learnt policies being stuck in some local minima that they are unable to escape . 15 For the BCO ( 0 ) baseline , the IDM and policy are built by using the same network architecture with the world model to make a fair comparison . The observations are first processed by the encoder network , and then get stacked to deal with the temporal information . An MLP is used to decode the stacked representation to the output distribution . We stack 5 consecutive in this work . We did a grid search about the width , depth of the MLP and also the number of stacking frames and didn ’ t find any increase of the performance . Following the original paper , we split the datasets by 7 : 3 , and choose the finial model based on the validation loss . C AIME with IDM In this section , we introduce an alternative variant of AIME which also uses IDM . Recall that in the Bayesian derivation , we factorised both the posterior and prior of the joint distribution of state and action with a shared policy network , as in eq . ( 6 ) and eq . ( 7 ) . Alternatively , we can re-factorise the posterior with IDM , that is qϕ , θ ( st , at−1|st−1 , fϕ ( ot ) ) = qϕ ( at−1|st−1 , fϕ ( ot ) ) qϕ ( st|st−1 , at−1 , fϕ ( ot ) ) . ( 10 ) One thing that needs to be noticed here is that the IDM is not in the familiar form of qϕ ( at−1|st−1 , st ) . This is because the latent state in the world model is action dependent so the familiar form is non- casual in the world model . But we should highlight here that this non-casual structure is a result of the model we used in phase 1 since we want to reuse the knowledge learnt there . For example , one can also factorise the joint posterior as qϕ ( st , at−1|st−1 , fϕ ( ot ) ) = qϕ ( at−1|st−1 , st ) qϕ ( st|st−1 , fϕ ( ot ) ) . ( 11 ) However , in this case , the model is different for phase 1 . In this section , we stick to using the factorisation in eq . ( 10 ) . Since a new IDM component is introduced , the objective of both phase 1 and phase 2 need to be modified . For phase 1 , since actions are available in the dataset , the IDM can be treated as a decoder and trained by maximising likelihood . That is , we add IDM ( τ ( T ) ) = ( cid:80 ) T −1 J p1 t=0 log qϕ ( at|st , fϕ ( ot+1 ) ) to the objective function . For phase 2 , since actions are not available , the IDM serves as the posterior and guides the prior policy through a KL divergence , i.e . J p2 t=0 −DKL [ qϕ ( at|st , fϕ ( ot+1 ) ) ||πψ ( at|st ) ] . IDM ( τ ( T ) ) = ( cid:80 ) T −1 One caveat about this formulation is that , in phase 1 , the IDM forms a loop on the graphical model . In order to stabilise the training process , we detach the gradient from the IDM to the rest of the network . D Dataset details Here we provide extra information about the datasets . The expert return which we normalised against is shown in Table 1 and Table 2 . Table 1 : Average expert return of each demonstration dataset of Walker . Ddemo stand walk run Average return 957.87 ( max : 1000 ) 943.79 ( max : 1000 ) 604.10 ( max : 1000 ) Table 2 : Average expert return of each demonstration dataset of Cheetah . Ddemo Average return run run backwards flip flip backwards 888.65 ( max : 1000 ) 218.50 ( max : 500 ) 485.79 ( max : 500 ) 379.91 ( max : 500 ) 16 Table 3 : Result on V-D4RL main datasets . Embodiment datasets are marked on the left , and the demonstration datasets are chosen to be the expert dataset for each task in the origin environment . Values are averaged over 100 trajectories and reported as accumulated reward divided by 10 , as suggested in the V-D4RL paper . BCO ( 0 ) AIME walker-random walker-medium_replay walker-mix 2.11 ± 0.91 6.54 ± 6.56 5.32 ± 5.23 12.36 ± 4.69 10.18 ± 4.33 8.49 ± 3.60 cheetah-random cheetah-medium_replay cheetah-mix 0.01 ± 0.01 15.47 ± 7.38 16.08 ± 6.61 9.48 ± 4.72 31.47 ± 16.14 40.27 ± 11.52 E Experiments on V-D4RL datasets We provide here some additional results of AIME on V-D4RL datasets [ 51 ] to showcase that AIME can also work with datasets collected by non-model-based methods . V-D4RL provides multiple different datasets for the Walker and Cheetah embodiments from DMC Suite , and it is original designed for offline RL with visual inputs . The datasets are collected by running a few model-free RL methods and either keep the replay buffer or rollout from a policy checkpoints . Since our setting requires a bit more exploration in the embodiment datasets to understand the embodiment , we choose to use their random and medium_replay datasets as the embodiment datasets . The expert datasets are used as the demonstration datasets . Same as what we did for the Walker embodiment in the main text , we also mix the two embodiment datasets for each embodiment to form a mix dataset . The results on these datasets are shown in Table 3 . We can see that the performance of both BCO ( 0 ) and AIME is generally low , but AIME still outperform BCO ( 0 ) which proves AIME can also handle datasets generated by model-free methods . The low performance is due to a more constrained setup of the task , i.e . less amount of embodiment data and less diversity . Except the cheetah-medium_replay having 400 trajectories , the other three datasets provided by V-D4RL have only 200 trajectories , which is much less than the 1000 trajectories in the main experiments . Moreover , it is already shown from Figure 2 and Figure 3 that random datasets do not help much in learning a model , and intuitively the medium_replay dataset is better but still does not contain enough information to solve the task . We also conduct experiments on the V-D4RL distracting datasets , to test the performance of AIME on distracting datasets . For the Walker embodiment , the benchmark provides random datasets with a distraction level of easy , medium , and hard . We also merge these three levels to form a mix dataset . Moreover , we also merge this mix dataset with the mix dataset in the second experiment to form a total_mix dataset . We treat these five datasets as the embodiment dataset and the expert dataset as the demonstration dataset . For the Cheetah embodiment , the benchmark provides medium and expert datasets with a distraction level of easy , medium , and hard . We subsample the medium datasets to get 200 trajectories from each level , then merge that with the mix dataset in the second experiment to form a total_mix dataset . Then the algorithms are using this total_mix dataset as the embodiment dataset and the expert dataset as the demonstration dataset . As we can see from the result from Table 4 , although we still outperform the BCO ( 0 ) baseline , AIME is impacted significantly by the distractions . This behaviour is expected since the world model is trained with reconstruction loss . It is not easy to handle observations with distractions . A potential solution to this problem is to freeze only the dynamics part of the world model and allowing encoders and decoders to fine-tune their parameters in the second phase . We leave these improvements for our future works . F Additional plots In this section , we will present some additional plots to complement the main text and provide further insights . 17 Table 4 : Result on V-D4RL distracting datasets . Embodiment datasets are marked on the left , and the demonstration datasets are chosen to be the expert dataset for each task in the origin environment . Values are averaged over 100 trajectories and reported as accumulated reward divided by 10 , as suggested in the V-D4RL paper . walker-easy walker-medium walker-hard walker-mix walker-total_mix BCO ( 0 ) AIME 2.10 ± 0.88 2.15 ± 0.87 2.15 ± 0.97 2.12 ± 0.86 2.15 ± 0.71 4.73 ± 2.54 3.94 ± 0.99 4.16 ± 1.98 3.81 ± 2.07 12.66 ± 4.51 cheetah-total_mix 16.61 ± 7.28 32.40 ± 14.52 Additional to Figure 2 and Figure 3 , we also provide detailed profile plots in Figure 6 and Figure 7 as recommended in [ 52 ] . We can see that AIME is normally more stable w.r.t . the performance by having a smaller decay region . It is clearly shown on such tasks as walk → walk and run → run on Walker where BCO ( 0 ) -MDP has some trails with very low performance , while all variants of AIME maintain decent performance . Figure 6 : Performance distributions of each method on Walker tasks . We also present some representative training curves of AIME ’ s phase 2 from our experiments in Figure 8 . The first three figures show the transfer from the mix dataset to the run task in the three settings which are the typical success cases of AIME . During the course of training , ELBO is maximised towards convergence and the MSE between the generated actions and the true actions decreases . We can also see that for the MDP and LPOMDP settings , the converged ELBO is lower than the ELBO when evaluated with the true action sequence , indicating there is still space for improvement . However , for the Visual setting , the converged ELBO exceeds the one with true actions , which should be attributed to the over-fitting of the world model from phase 1 . The last three figures 18 100 50 0 100 50 0 100 50 0 100 50 0 100 50 0 100 50 p > s l a i r t # p > s l a i r t # p > s l a i r t # p > s l a i r t # p > s l a i r t # p > s l a i r t # 0 0 random -- > stand random -- > walk random -- > run p2e -- > stand p2e -- > walk p2e -- > run stand -- > stand stand -- > walk stand -- > run walk -- > stand walk -- > walk walk -- > run run -- > stand run -- > walk run -- > run mix -- > stand mix -- > walk mix -- > run 20 80 Relative expert performance ( p ) 40 60 100 0 20 80 Relative expert performance ( p ) 60 40 100 0 20 80 Relative expert performance ( p ) 60 40 Method BCO ( 0 ) -Visual BCO ( 0 ) -LPOMDP BCO ( 0 ) -MDP AIME-Visual AIME-LPOMDP AIME-MDP 100 Figure 7 : Performance distributions of each method on Cheetah tasks . show the transfer from the random dataset to the three tasks in the Visual settings which we consider as failure cases . For the stand and walk tasks , none of the metrics are converging . For the run task , we can observe a severe over-fitting starting from the beginning of the training , and the MSE keeps increasing . We conjecture these are all due to the less well-trained world models . 19 p > s l a i r t # p > s l a i r t # p > s l a i r t # p > s l a i r t # p > s l a i r t # p > s l a i r t # 100 50 0 100 50 0 100 50 0 100 50 0 100 50 0 100 50 0 random -- > run random -- > runb random -- > flip random -- > flipb p2e -- > run p2e -- > runb p2e -- > flip p2e -- > flipb run -- > run run -- > runb run -- > flip run -- > flipb runb -- > run runb -- > runb runb -- > flip runb -- > flipb Method BCO ( 0 ) -Visual BCO ( 0 ) -LPOMDP BCO ( 0 ) -MDP AIME-Visual AIME-LPOMDP AIME-MDP flip -- > run flip -- > runb flip -- > flip flip -- > flipb flipb -- > run flipb -- > runb flipb -- > flip flipb -- > flipb 0 20 40 60 80 100 0 20 40 60 80 100 0 20 40 60 80 100 0 20 40 60 80 100 Relative expert performance ( p ) Relative expert performance ( p ) Relative expert performance ( p ) Relative expert performance ( p ) Figure 8 : Samples of training curve in phase 2 of AIME . The first three showcase the typical successful training curves , while the remaining three demonstrate the failure cases . The true_action is referring to evaluating the trajectories with the true action sequence . 20 ELBO rec term KL term action mse AIME-MDP mix - > run training curve 0 500 1000 1500 1600 1400 1200 1000 800 AIME true_action 1600 1800 2000 2200 2400 AIME true_action 0.70 0.65 0.60 0.55 0.50 0.45 AIME true_action normalised returns AIME AIME 100 80 60 40 20 0 200 400 0 200 400 0 200 400 0 200 400 0 0 200 400 ELBO rec term KL term action mse normalised returns AIME-LPOMDP mix - > run training curve 1500 1000 500 0 2300 2200 2100 2000 1900 AIME true_action AIME true_action 0 100 200 300 400 500 0 100 200 300 400 500 800 1000 1200 1400 1600 1800 2000 0.75 0.70 0.65 0.60 0.55 AIME true_action AIME AIME 80 60 40 20 0 0 100 200 300 400 500 0 100 200 300 400 500 0 100 200 300 400 500 AIME-Visual mix - > run training curve KL term action mse normalised returns 1e5 ELBO 1e5 5.6515 rec term 5.657 5.658 5.659 5.660 5.661 5.662 5.6520 5.6525 5.6530 AIME true_action AIME true_action 500 600 700 800 900 0.85 0.80 0.75 0.70 AIME true_action 0 200 400 0 200 400 0 200 400 0 200 400 AIME AIME 80 60 40 20 0 0 200 400 AIME-Visual random - > stand training curve 1e5 ELBO 1e5 rec term KL term 5.678 5.680 5.682 5.684 5.686 5.688 5.674 5.676 5.678 5.680 5.682 AIME true_action 400 500 600 700 800 AIME true_action AIME true_action action mse normalised returns AIME AIME 40 30 20 10 2.0 1.8 1.6 1.4 1.2 1.0 0.8 0 200 400 0 200 400 0 200 400 0 200 400 0 200 400 AIME-Visual random - > walk training curve 1e5 ELBO AIME true_action 5.680 5.682 5.684 5.686 5.688 5.674 5.675 5.676 5.677 5.678 5.679 5.680 1e5 rec term KL term AIME true_action 500 600 700 800 900 AIME true_action 2.0 1.8 1.6 1.4 1.2 1.0 action mse normalised returns AIME AIME 15.0 12.5 10.0 7.5 5.0 2.5 0 200 400 0 200 400 0 200 400 0 200 400 0 200 400 1e5 ELBO 1e5 5.6715 rec term KL term action mse AIME-Visual random - > run training curve 5.680 5.682 5.684 5.686 5.688 AIME true_action 5.6720 5.6725 5.6730 5.6735 5.6740 5.6745 AIME true_action 800 1000 1200 1400 AIME true_action 1.55 1.50 1.45 1.40 1.35 normalised returns AIME 12 10 8 6 4 AIME 0 200 400 0 200 400 0 200 400 0 200 400 0 200 400","['c', 'e', 'l', 'c', 'v', 'r', 'action', 'inference', 'maximise', 'evidence', 'zeroshot', 'imitation', 'observation', 'world', 'model', 'smagt13', 'learn', 'research', 'lab', 'group', 'loránd', 'university', 'abstract', 'reinforcement', 'learn', 'agent', 'require', 'unrealistic', 'amount', 'environment', 'interaction', 'learn', 'new', 'behaviour', 'human', 'excel', 'learn', 'quickly', 'merely', 'observe', 'imitate', 'ability', 'highly', 'depend', 'fact', 'human', 'model', 'embodiment', 'allow', 'infer', 'likely', 'action', 'lead', 'observed', 'behaviour', 'paper', 'propose', 'action', 'inference', 'maximise', 'evidence', 'aime', 'replicate', 'behaviour', 'use', 'world', 'model', 'aime', 'consist', 'distinct', 'phase', 'first', 'phase', 'agent', 'learn', 'world', 'model', 'past', 'experience', 'understand', 'body', 'maximise', 'evidence', 'lower', 'bind', 'second', 'phase', 'agent', 'give', 'observationonly', 'demonstration', 'expert', 'perform', 'novel', 'task', 'try', 'imitate', 'expert', 'behaviour', 'aime', 'achieve', 'define', 'policy', 'inference', 'model', 'maximise', 'evidence', 'demonstration', 'policy', 'world', 'model', 'method', 'zeroshot', 'sense', 'require', 'training', 'world', 'model', 'online', 'interaction', 'environment', 'give', 'demonstration', 'empirically', 'validate', 'zeroshot', 'imitation', 'performance', 'method', 'walker', 'embodiment', 'deepmind', 'control', 'suite', 'find', 'outperform', 'stateoftheart', 'baseline', 'code', 'available', 'comargmaxaiaime', 'introduction', 'recent', 'year', 'deep', 'reinforcement', 'learn', 'enable', 'intelligent', 'decisionmake', 'agent', 'thrive', 'multiple', 'field', 'however', 'big', 'issue', 'drl', 'sample', 'inefficiency', 'dominant', 'framework', 'learn', 'thus', 'algorithm', 'require', 'incredible', 'amount', 'interaction', 'environment', 'contrast', 'cortical', 'animal', 'human', 'able', 'quickly', 'learn', 'new', 'task', 'trialanderror', 'attempt', 'far', 'accelerate', 'learning', 'process', 'observe', 'important', 'difference', 'biological', 'learning', 'drl', 'framework', 'former', 'use', 'past', 'experience', 'new', 'task', 'try', 'novel', 'task', 'use', 'previously', 'learn', 'component', 'generalise', 'solve', 'new', 'problem', 'efficiently', 'process', 'augment', 'imitation', 'learn', 'allow', 'replicate', 'similar', 'behaviour', 'direct', 'observation', 'underlie', 'muscle', 'movement', 'drl', 'agent', 'similarly', 'harness', 'observational', 'datum', 'abundant', 'online', 'video', 'datum', 'sample', 'efficiency', 'dramatically', 'improve', 'goal', 'problem', 'relate', 'traditional', 'wellestablished', 'learning', 'demonstration', 'field', 'robotic', 'community', 'instead', 'rely', 'knowledge', 'engineer', 'researcher', 'mathematical', 'model', 'robot', 'dynamic', 'primitive', 'aim', 'let', 'robot', 'learn', '∗corresponde', 'author', '37th', 'conference', 'neural', 'information', 'processing', 'system', 'neurip', 'figure', 'overview', 'phase', 'observation', 'action', 'provide', 'embodiment', 'dataset', 'agent', 'learn', 'variational', 'world', 'model', 'model', 'evidence', 'observation', 'condition', 'action', 'learnt', 'model', 'weight', 'freeze', 'transfer', 'phase', 'phase', 'observation', 'provide', 'demonstration', 'dataset', 'agent', 'need', 'infer', 'state', 'action', 'action', 'inference', 'achieve', 'policy', 'model', 'sample', 'action', 'give', 'state', 'grey', 'line', 'indicate', 'world', 'model', 'parameter', 'freeze', 'phase', 'phase', 'optimise', 'objective', 'however', 'directly', 'learn', 'model', 'observationonly', 'sequence', 'insufficient', 'biological', 'technical', 'system', 'know', 'action', 'lead', 'observation', 'observation', 'sequence', 'highly', 'stochastic', 'multimodal', 'try', 'infer', 'unknown', 'action', 'prior', 'knowledge', 'world', 'difficult', 'problem', 'attribute', 'part', 'observation', 'influence', 'action', 'part', 'govern', 'normal', 'system', 'evolution', 'noise', 'therefore', 'work', 'hypothesise', 'order', 'make', 'good', 'use', 'observationonly', 'sequence', 'agent', 'first', 'understand', 'notion', 'action', 'achieve', 'learn', 'model', 'agent', 'past', 'experience', 'action', 'consequence', 'observation', 'available', 'give', 'learnt', 'model', 'include', 'causal', 'model', 'action', 'effect', 'become', 'feasible', 'agent', 'infer', 'action', 'sequence', 'lead', 'give', 'observationonly', 'datum', 'work', 'propose', 'novel', 'action', 'inference', 'maximise', 'evidence', 'aime', 'try', 'replicate', 'imitation', 'ability', 'human', 'agent', 'first', 'learn', 'world', 'model', 'past', 'experience', 'maximise', 'evidence', 'experience', 'receive', 'observationonly', 'demonstration', 'novel', 'task', 'agent', 'try', 'mimic', 'demonstrator', 'find', 'action', 'sequence', 'make', 'demonstration', 'likely', 'learnt', 'model', 'procedure', 'show', 'figure', 'contribution', 'summarise', 'follow', '•', 'propose', 'aime', 'novel', 'method', 'imitation', 'observation', 'aime', 'first', 'learn', 'world', 'model', 'maximise', 'evidence', 'past', 'experience', 'consider', 'policy', 'action', 'inference', 'model', 'imitate', 'maximise', 'evidence', 'demonstration', '•', 'conduct', 'experiment', 'variety', 'dataset', 'task', 'demonstrate', 'superior', 'performance', 'aime', 'compare', 'stateoftheart', 'method', 'result', 'showcase', 'zeroshot', 'transferability', 'learnt', 'world', 'model', 'problem', 'formulation', 'consider', 'mdp', 'problem', 'define', 'tuple', 'r', 'state', 'space', 'action', 'space', '×', 'dynamic', 'function', 'r', 'r', 'reward', 'function', 'pomdp', 'add', 'partial', 'observability', 'mdp', 'component', 'observation', 'space', 'emission', 'function', 'ω', 'component', 'pomdp', 'categorise', 'group', 'define', 'embodiment', 'agent', 'ω', 'define', 'sensor', 'agent', 'phase', 'model', 'learn', 'transfer', 'parameter', 'phase', 'imitation', 'learn', '𝑜𝑜1', '𝑎𝑎1', '𝑜𝑜2', '𝑎𝑎2', '𝑎𝑎𝑡𝑡', '𝑎𝑎𝑡𝑡', 'demonstration', 'dataset', '𝑜𝑜1', '𝑜𝑜2', '𝑜𝑜3', '𝑎𝑎𝑡𝑡', '𝑠𝑠𝑡𝑡1', '𝑠𝑠𝑡𝑡1', '𝜋𝜋𝜓𝜓', '∇𝜙𝜙', '𝜃𝜃𝐽𝐽', '𝑜𝑜1', '𝑠𝑠0', '𝑎𝑎0', '𝑜𝑜1', '𝑠𝑠0', '𝑎𝑎0', '𝑜𝑜1', '𝑠𝑠0', '𝑎𝑎0', 'r', 'define', 'task', 'goal', 'find', 'policy', 'π', 'maximise', 'accumulate', 'reward', 'paper', 'want', 'study', 'imitation', 'learn', 'fix', 'embodiment', 'different', 'task', 'presume', 'existence', 'dataset', 'embodiment', 'embodiment', 'dataset', 'dbody', 'contain', 'trajectory', 'o1', 'represent', 'past', 'experience', 'interact', 'environment', 'dataset', 'provide', 'information', 'embodiment', 'learn', 'model', 'example', 'paper', 'dataset', 'replay', 'buffer', 'fill', 'solve', 'task', 'embodiment', 'general', 'collection', 'past', 'experience', 'embodiment', 'demonstration', 'dataset', 'ddemo', 'contain', 'expert', 'trajectory', 'o0', 'o1', 'embodiment', 'solve', 'certain', 'task', 'define', 'rdemo', 'crucial', 'difference', 'dataset', 'embodiment', 'dataset', 'action', 'provide', 'anymore', 'observable', 'thirdperson', 'perspective', 'goal', 'agent', 'use', 'information', 'dbody', 'learn', 'policy', 'π', 'ddemo', 'solve', 'task', 'define', 'rdemo', 'well', 'expert', 'generate', 'ddemo', 'simplicity', 'assume', 'dataset', 'share', 'observation', 'space', 'emission', 'model', 'methodology', 'section', 'describe', 'propose', 'method', 'aime', 'detail', 'aime', 'consist', 'phase', 'first', 'phase', 'knowledge', 'embodiment', 'learn', 'form', 'world', 'model', 'second', 'phase', 'knowledge', 'use', 'imitate', 'expert', 'phase', 'model', 'learn', 'first', 'phase', 'need', 'learn', 'model', 'understand', 'embodiment', 'achieve', 'learn', 'world', 'model', 'analogy', 'language', 'model', 'define', 'world', 'model', 'probability', 'distribution', 'sequence', 'observation', 'model', 'unconditione', 'condition', 'factor', 'previous', 'observation', 'action', 'phase', 'model', 'need', 'conditional', 'distribution', 'p', 'o1', '−1', 'model', 'effect', 'action', 'give', 'observation', 'sequence', 'likelihood', 'sequence', 'model', 'refer', 'evidence', 'paper', 'consider', 'variational', 'world', 'model', 'observation', 'govern', 'markovian', 'hide', 'state', 'literature', 'type', 'model', 'also', 'refer', 'statespace', 'model', 'variational', 'world', 'model', 'involve', 'component', 'namely', 'encoder', 'prior', '∼', 'pθ', 'decoder', '∼', 'otst', 'ot', 'encoder', 'extract', 'feature', 'observation', 'pθ', 'posterior', 'prior', 'latent', 'state', 'variable', 'pθ', 'otst', 'decoder', 'decode', 'observation', 'distribution', 'state', 'represent', 'parameter', 'inference', 'model', 'generative', 'model', 'respectively', 'typically', 'variational', 'world', 'model', 'train', 'maximise', 'elbo', 'lower', 'bind', 'loglikelihood', 'evidence', 'observation', 'sequence', 'log', 'pθ', 'o1', '−1', 'give', 'sequence', 'observation', 'action', 'state', 'objective', 'function', 'compute', 'j', 'o1', '−1', '−1', 'jkl', 'o1', '−1', '−1', 'jkl', 'o1', '−1', 'log', 'otst', 'ot', 'pθ', 'objective', 'function', 'compose', 'term', 'first', 'term', 'likelihood', 'observation', 'infer', 'state', 'usually', 'call', 'reconstruction', 'loss', 'second', 'term', 'jkl', 'kl', 'divergence', 'posterior', 'prior', 'distribution', 'latent', 'state', 'compute', 'objective', 'function', 'use', 'reparameterisation', 'trick', 'autoregressively', 'sample', 'infer', 'state', 'observation', 'action', 'sequence', 'combine', 'formally', 'define', 'optimisation', 'problem', 'phase', 'ϕ∗', 'θ∗', 'argmax', 'e', 'o1', '−1', '∼dbody', 'j', 'o1', '−1', 'phase', 'imitation', 'learn', 'second', 'phase', 'want', 'utilise', 'knowledge', 'world', 'model', 'first', 'phase', 'imitate', 'expert', 'behaviour', 'demonstration', 'dataset', 'ddemo', 'sequence', 'observation', 'action', 'available', 'derive', 'different', 'perspective', 'bayesian', 'derivation', 'action', 'unknown', 'demonstration', 'instead', 'model', 'conditional', 'evidence', 'phase', 'need', 'model', 'unconditional', 'evidence', 'log', 'pθ', 'o1', 'thus', 'also', 'need', 'model', 'action', 'latent', 'variable', 'together', 'state', 'way', 'reconstruction', 'term', 'jrec', 'stay', 'kl', 'term', 'define', 'joint', 'distribution', 'state', 'action', 'jkl', 'o1', '−1', '−dkl', 'ot', 'choose', 'action', 'inference', 'model', 'form', 'policy', 'atst', 'share', 'posterior', 'prior', 'new', 'posterior', 'prior', 'factorise', 'ot', 'ot', 'pθ', 'pθ', 'respectively', 'plug', 'eq', 'policy', 'term', 'cancel', 'get', 'similar', 'optimisation', 'problem', 'phase', 'ψ∗', 'argmax', '∼ddemo', 's0', '−1', 'o1', '−1', 'main', 'difference', 'eq', 'action', 'sequence', 'come', 'phase', 'action', 'sequence', 'come', 'embodiment', 'dataset', 'phase', 'sample', 'policy', 'instead', 'available', 'demonstration', 'dataset', 'control', 'derivation', 'perspective', 'view', 'phase', 'control', 'problem', 'crucial', 'observation', 'show', 'give', 'train', 'world', 'model', 'evaluate', 'low', 'bind', 'evidence', 'observation', 'sequence', 'give', 'associate', 'action', 'sequence', 'condition', 'deterministic', 'environment', 'inverse', 'dynamic', 'model', 'injective', 'true', 'action', 'sequence', 'lead', 'observation', 'sequence', 'likely', 'true', 'model', 'general', 'true', 'action', 'sequence', 'necessarily', 'likely', 'model', 'however', 'potential', 'benefit', 'approach', 'mainly', 'interested', 'mimic', 'expert', 'demonstration', 'well', 'able', 'different', 'action', 'sequence', 'thus', 'observation', 'sequence', 'get', 'demonstration', 'dataset', 'find', 'miss', 'action', 'sequence', 'consider', 'trajectorytracking', 'problem', 'tackle', 'plan', 'specific', 'find', 'miss', 'action', 'sequence', 'solve', 'optimisation', 'problem', '−1', 'argmax', '−1', 'eo1', '∼ddemo', 's0', '∼qϕ∗', 'o1', '−1', 'solve', 'optimisation', 'problem', 'sequence', 'demonstration', 'dataset', 'problem', 'convert', 'normal', 'imitation', 'learn', 'problem', 'solve', 'standard', 'technique', 'behavioural', 'cloning', 'also', 'view', 'form', 'implicit', 'inverse', 'dynamic', 'model', 'idm', 'invert', 'forward', 'model', 'action', 'make', 'efficient', 'use', 'amortised', 'inference', 'directly', 'define', 'policy', 'atst', 'latent', 'state', 'world', 'model', 'compose', 'learnt', 'world', 'model', 'policy', 'form', 'aime', 'datum', 'embodiment', 'dataset', 'dbody', 'demonstration', 'dataset', 'ddemo', 'learning', 'rate', 'phase', 'model', 'learn', 'world', 'model', 'parameter', 'θ', 'model', 'converge', 'o1', '−1', 'dbody', 'ot', 'compute', 'objective', 'function', 'j', 'update', 'model', 'parameter', 'α∇θj', 'phase', 'imitation', 'learn', 'initialise', 'policy', 'parameter', 'policy', 'converge', 'o1', '∼', 'ddemo', 'ot', 'compute', 'objective', 'function', 'j', 'update', 'policy', 'parameter', 'new', 'generative', 'model', 'state', 'sequence', 'chain', 'st1', 'at1', 'get', 'optimisation', 'problem', 'sum', 'aime', 'use', 'objective', 'function', 'phase', 'difference', 'source', 'action', 'sequence', 'provide', 'pseudocode', 'colour', 'highlight', 'different', 'origin', 'action', 'phase', 'experiment', 'test', 'method', 'need', 'multiple', 'environment', 'share', 'embodiment', 'pose', 'different', 'task', 'therefore', 'consider', 'walker', 'deepmind', 'control', 'suite', 'officially', 'walker', 'embodiment', 'task', 'stand', 'walk', 'run', 'embodiment', 'task', 'run', 'add', 'new', 'task', 'namely', 'run', 'backwards', 'flip', 'flip', 'backwards', 'inspire', 'previous', 'work', 'follow', 'common', 'practice', 'benchmark', 'repeat', 'action', 'time', 'interact', 'environment', 'embodiment', 'true', 'state', 'include', 'position', 'velocity', 'joint', 'centre', 'mass', 'body', 'order', 'study', 'influence', 'different', 'observation', 'modality', 'consider', 'setting', 'environment', 'use', 'true', 'state', 'observation', 'visual', 'use', 'image', 'observation', 'lpomdp', 'use', 'position', 'part', 'state', 'observation', 'informationwise', 'identical', 'visual', 'setting', 'information', 'densely', 'represent', 'lowdimensional', 'form', 'generate', 'embodiment', 'demonstration', 'dataset', 'train', 'dreamer', 'agent', 'visual', 'setting', 'task', 'environment', 'step', 'take', 'replay', 'buffer', 'train', 'agent', 'embodiment', 'dataset', 'dbody', 'contain', 'trajectory', 'consider', 'converge', 'policy', 'expert', 'collect', 'trajectory', 'demonstration', 'dataset', 'ddemo', 'use', 'trajectory', 'main', 'experiment', 'remain', 'trajectory', 'use', 'ablation', 'study', 'performance', 'policy', 'measure', 'accumulate', 'reward', 'exact', 'performance', 'demonstration', 'dataset', 'find', 'embodiment', 'dataset', 'also', 'study', 'dataset', 'generate', 'purely', 'exploratory', 'behaviour', 'first', 'use', 'random', 'policy', 'sample', 'uniformly', 'action', 'space', 'collect', 'trajectory', 'call', 'random', 'dataset', 'second', 'train', 'agent', 'trajectory', 'label', 'replay', 'buffer', 'dataset', 'moreover', 'walker', 'embodiment', 'also', 'merge', 'dataset', 'run', 'dataset', 'form', 'mix', 'dataset', 'resemble', 'practical', 'setting', 'possess', 'lot', 'experience', 'embodiment', 'use', 'train', 'single', 'foundational', 'world', 'model', 'figure', 'performance', 'walker', 'column', 'indicate', 'task', 'associate', 'demonstration', 'dataset', 'row', 'indicate', 'embodiment', 'dataset', 'use', 'train', 'model', 'title', 'figure', 'name', 'accord', 'dbody', 'ddemo', 'number', 'compute', 'average', 'trial', 'normalise', 'percentage', 'expert', 'performance', 'error', 'bar', 'show', 'standard', 'deviation', 'last', 'row', 'column', 'average', 'correspond', 'task', 'dataset', 'error', 'bar', 'large', 'aggregate', 'performance', 'distribute', 'large', 'range', 'benchmark', 'result', 'mainly', 'compare', 'method', 'bco', 'bco', 'first', 'train', 'idm', 'embodiment', 'dataset', 'use', 'train', 'idm', 'label', 'demonstration', 'dataset', 'use', 'behavioural', 'cloning', 'recover', 'policy', 'compare', 'method', 'require', 'environment', 'interaction', 'use', 'goalconditional', 'setting', 'suit', 'locomotion', 'task', 'detail', 'related', 'work', 'find', 'section', 'implementation', 'detail', 'find', 'main', 'result', 'comparison', 'show', 'figure', 'figure', 'overall', 'see', 'aime', 'largely', 'outperform', 'bco', 'environment', 'setting', 'walker', 'pomdp', 'setting', 'aime', 'typically', 'achieve', 'low', 'performance', 'visual', 'setting', 'even', 'comparable', 'bco', 'mdp', 'access', 'true', 'state', 'attribute', 'good', 'performance', 'aime', 'reason', 'first', 'world', 'model', 'well', 'datum', 'utilisation', 'rate', 'idm', 'world', 'model', 'train', 'reconstruct', 'whole', 'observation', 'sequence', 'idm', 'take', 'figure', 'performance', 'column', 'indicate', 'task', 'associate', 'demonstration', 'dataset', 'row', 'indicate', 'embodiment', 'dataset', 'use', 'train', 'model', 'title', 'figure', 'name', 'accord', 'dbody', 'ddemo', 'runb', 'flipb', 'short', 'hand', 'run', 'backwards', 'flip', 'backwards', 'number', 'compute', 'average', 'trial', 'normalise', 'percentage', 'expert', 'performance', 'error', 'bar', 'show', 'standard', 'deviation', 'last', 'row', 'column', 'average', 'correspond', 'task', 'dataset', 'error', 'bar', 'large', 'aggregate', 'performance', 'distribute', 'large', 'range', 'short', 'clip', 'sequence', 'predict', 'action', 'thus', 'world', 'model', 'less', 'chance', 'overfit', 'learn', 'well', 'representation', 'provide', 'well', 'generalisation', 'second', 'maximise', 'evidence', 'method', 'strive', 'find', 'action', 'sequence', 'lead', 'outcome', 'recover', 'true', 'action', 'many', 'system', 'dynamic', 'fully', 'invertible', 'example', 'human', 'apply', 'force', 'wall', 'wall', 'move', 'tell', 'much', 'force', 'apply', 'visual', 'observation', 'situation', 'apply', 'walker', 'certain', 'joint', 'lock', 'singular', 'pose', 'phenomenon', 'also', 'discuss', 'also', 'find', 'compare', 'walker', 'experiment', 'performance', 'low', 'improvement', 'offer', 'aime', 'small', 'think', 'setup', 'much', 'hard', 'walker', 'task', 'sound', 'similar', 'name', 'eg', 'flip', 'flip', 'backward', 'asymmetrical', 'structure', 'embodiment', 'behaviour', 'solve', 'task', 'quite', 'different', 'difference', 'limit', 'amount', 'knowledge', 'transfer', 'embodiment', 'dataset', 'demonstration', 'moreover', 'task', 'build', 'hard', 'imitation', 'example', 'demonstration', 'flip', 'task', 'fly', 'air', 'action', 'take', 'relevant', 'solve', 'task', 'leave', 'action', 'sequence', 'actually', 'essential', 'solve', 'task', 'think', 'challenging', 'aime', 'need', 'infer', 'sequence', 'action', 'bco', 'operate', 'point', 'estimation', 'first', 'action', 'output', 'reasonable', 'action', 'start', 'flip', 'later', 'action', 'create', 'noisy', 'gradient', 'none', 'explain', 'flying', 'general', 'poorly', 'model', 'region', 'world', 'lead', 'noisy', 'gradient', 'time', 'step', 'hand', 'also', 'find', 'variant', 'achieve', 'good', 'performance', 'run', 'backward', 'demonstration', 'dataset', 'mainly', 'due', 'low', 'expert', 'performance', 'see', 'task', 'make', 'imitation', 'easy', 'last', 'least', 'follow', 'common', 'practise', 'benchmark', 'embodiment', 'operate', '50hz', 'much', 'high', '20hz', 'use', 'walker', 'high', 'frequency', 'operation', 'make', 'effect', 'individual', 'action', 'change', 'observation', 'subtle', 'hard', 'distinguish', 'pose', 'additional', 'challenge', 'algorithms', 'influence', 'different', 'dataset', 'expect', 'almost', 'variant', 'method', 'transfer', 'task', 'well', 'transfer', 'different', 'task', 'setting', 'bco', 'comparable', 'aime', 'however', 'aime', 'shine', 'crosstask', 'especially', 'transfer', 'run', 'walk', 'task', 'transfer', 'stand', 'run', 'walker', 'aime', 'outperform', 'baseline', 'large', 'margin', 'indicate', 'strong', 'generalisability', 'forward', 'model', 'inverse', 'model', 'also', 'find', 'aime', 'make', 'substantially', 'well', 'use', 'exploratory', 'datum', 'walker', 'aime', 'largely', 'outperform', 'baseline', 'use', 'dataset', 'embodiment', 'dataset', 'outperform', 'variant', 'use', 'random', 'dataset', 'embodiment', 'dataset', 'moreover', 'transfer', 'mix', 'dataset', 'version', 'aime', 'outperform', 'variant', 'train', 'world', 'model', 'single', 'individual', 'task', 'dataset', 'mixed', 'dataset', 'showcase', 'scalability', 'world', 'model', 'train', 'diverse', 'set', 'experience', 'valuable', 'realworld', 'scenario', 'influence', 'observation', 'modality', 'compare', 'bco', 'aime', 'quite', 'robust', 'choice', 'observation', 'modality', 'see', 'clear', 'ladder', 'pattern', 'bco', 'change', 'setting', 'hard', 'easy', 'aime', 'result', 'similar', 'modality', 'however', 'still', 'notice', 'small', 'difference', 'compare', 'lpomdp', 'visual', 'setting', 'observation', 'provide', 'information', 'find', 'aime', 'lpomdp', 'setting', 'perform', 'well', 'visual', 'setting', 'test', 'case', 'attribute', 'fact', 'lowdimension', 'signal', 'information', 'offer', 'smoother', 'landscape', 'evidence', 'space', 'pixel', 'provide', 'useful', 'gradient', 'guide', 'action', 'inference', 'surprisingly', 'access', 'information', 'aimemdp', 'perform', 'bad', 'aimelpomdp', 'average', 'big', 'gap', 'happen', 'transfer', 'exploratory', 'dataset', 'dataset', 'walker', 'random', 'dataset', 'conjecture', 'fact', 'world', 'model', 'train', 'well', 'default', 'hyperparameter', 'defer', 'investigation', 'future', 'work', 'ablation', 'study', 'section', 'conduct', 'ablation', 'study', 'investigate', 'aime', 'performance', 'influence', 'different', 'component', 'design', 'choice', 'mainly', 'focus', 'use', 'mix', 'embodiment', 'dataset', 'transfer', 'run', 'task', 'represent', 'realistic', 'setting', 'want', 'use', 'experience', 'multiple', 'task', 'transfer', 'new', 'task', 'sample', 'efficiency', 'scalability', 'test', 'property', 'vary', 'number', 'demonstration', 'also', 'include', 'true', 'action', 'oracle', 'baseline', 'result', 'show', 'figure', 'bco', 'struggle', 'lowdata', 'scenario', 'typically', 'need', 'least', 'demonstration', 'surpass', 'performance', 'random', 'policy', 'contrast', 'aime', 'demonstrate', 'continual', 'improvement', 'trajectory', 'surprisingly', 'thank', 'generalisation', 'ability', 'world', 'model', 'aime', 'even', 'outperform', 'demonstration', 'limit', 'demonstrate', 'superior', 'sample', 'efficiency', 'method', 'moreover', 'performance', 'aime', 'keep', 'increase', 'trajectory', 'provide', 'showcase', 'scalability', 'method', 'objective', 'function', 'objective', 'function', 'consist', 'term', 'reconstruction', 'term', 'jrec', 'term', 'jkl', 'investigate', 'role', 'term', 'play', 'aime', 'retrain', 'variant', 'aime', 'remove', 'term', 'see', 'figure', 'remove', 'term', 'negatively', 'impact', 'result', 'compare', 'variant', 'use', 'term', 'well', 'setting', 'lowdimensional', 'signal', 'use', 'reconstruction', 'term', 'yield', 'slightly', 'well', 'result', 'highdimensional', 'image', 'signal', 'setting', 'performance', 'use', 'kl', 'term', 'close', 'one', 'use', 'term', 'suggest', 'latent', 'state', 'world', 'model', 'already', 'mostly', 'capture', 'essential', 'part', 'environment', 'figure', 'ablation', 'number', 'demonstration', 'mix', 'run', 'transfer', 'walker', 'embodiment', 'performance', 'show', 'normalise', 'return', 'seed', 'trial', 'seed', 'shaded', 'region', 'represent', 'standard', 'deviation', 'figure', 'ablation', 'study', 'mix', 'run', 'transfer', 'walker', 'embodiment', 'number', 'compute', 'average', 'seed', 'trial', 'seed', 'normalise', 'percentage', 'expert', 'performance', 'error', 'bar', 'show', 'standard', 'deviation', 'still', 'bad', 'use', 'term', 'shed', 'light', 'potential', 'incorporate', 'decoderfree', 'model', 'aime', 'framework', 'component', 'compare', 'bco', 'baseline', 'aime', 'consist', 'distinct', 'modification', 'one', 'use', 'ssm', 'integrate', 'sequence', 'train', 'policy', 'latent', 'representation', 'form', 'implicit', 'idm', 'gradient', 'rather', 'train', 'idm', 'explicitly', 'design', 'baseline', 'investigate', 'component', 'first', 'remove', 'train', 'forward', 'dynamic', 'model', 'directly', 'observation', 'embodiment', 'dataset', 'use', 'implicit', 'idm', 'imitation', 'demonstration', 'dataset', 'term', 'variant', 'iidm', 'second', 'train', 'separate', 'idm', 'train', 'latent', 'state', 'world', 'model', 'use', 'guide', 'policy', 'learning', 'phase', 'detailed', 'derivation', 'idm', 'formulation', 'find', 'c', 'figure', 'clearly', 'demonstrate', 'significance', 'latent', 'representation', 'performance', 'latent', 'representation', 'result', 'severely', 'compromise', 'setting', 'however', 'compare', 'bco', 'iidm', 'provide', 'assistance', 'highdimensional', 'visual', 'setting', 'train', 'idm', 'directly', 'observation', 'space', 'extremely', 'challenging', 'idm', 'latent', 'representation', 'lead', 'well', 'performance', 'compare', 'bco', 'still', 'perform', 'bad', 'aime', 'especially', 'pomdp', 'setting', 'relate', 'work', 'imitation', 'learn', 'observation', 'previous', 'work', 'imitation', 'learn', 'servation', 'roughly', 'categorise', 'group', 'base', 'base', 'generative', 'adversarial', 'imitation', 'learn', 'gail', 'core', 'component', 'first', 'group', 'learn', 'idm', 'map', 'state', 'transition', 'pair', 'action', 'cause', 'transition', 'use', 'idm', 'label', 'expert', 'observation', 'sequence', 'solve', 'imitation', 'learn', 'problem', 'extend', 'idm', 'goalconditione', 'setting', 'idm', 'train', 'condition', 'future', 'frame', 'goal', 'instead', 'next', 'frame', 'deployment', 'task', 'communicate', 'fly', 'user', 'form', 'keyframe', 'goal', 'e', 'r', 'e', 'l', 'r', 'n', 'oracle', 'bco', 'aime', 'random', 'number', 'demonstration', 'lpomdp', 'r', 'e', 'r', 'e', 'l', 'r', 'n', 'oracle', 'bco', 'aime', 'random', 'number', 'demonstration', 'visual', 'r', 'e', 'r', 'e', 'l', 'r', 'n', 'oracle', 'bco', 'aime', 'random', 'number', 'demonstration', 'r', 'e', 'r', 'e', 'l', 'r', 'n', 'bco', 'aime', 'aime', 'rec', 'aime', 'lpomdp', 'visual', 'setup', 'mainly', 'suit', 'robot', 'manipulation', 'task', 'paper', 'user', 'easily', 'specify', 'goal', 'manipulation', 'suit', 'locomotion', 'task', 'clear', 'longterm', 'goal', 'observation', 'also', 'practical', 'set', 'next', 'observation', 'goal', 'demonstrate', 'high', 'frequency', 'user', 'different', 'method', 'approach', 'use', 'forward', 'model', 'capture', 'knowledge', 'embodiment', 'second', 'group', 'approach', 'core', 'component', 'discriminator', 'distinguish', 'demonstrator', 'agent', 'observation', 'trajectory', 'discriminator', 'serve', 'reward', 'function', 'agent', 'policy', 'train', 'drawback', 'order', 'train', 'discriminator', 'agent', 'constantly', 'interact', 'environment', 'produce', 'negative', 'sample', 'different', 'method', 'method', 'require', 'interaction', 'environment', 'enable', 'zeroshot', 'imitation', 'demonstration', 'dataset', 'majority', 'also', 'work', 'strictly', 'fit', 'group', 'also', 'use', 'forward', 'model', 'learn', 'latent', 'action', 'policy', 'forward', 'dynamic', 'base', 'latent', 'action', 'however', 'still', 'need', 'online', 'environment', 'interaction', 'calibrate', 'latent', 'action', 'real', 'action', 'hybrid', 'method', 'use', 'component', 'focus', 'setting', 'demonstration', 'come', 'different', 'embodiment', 'reuse', 'learn', 'component', 'decisionmake', 'transfer', 'pretraine', 'model', 'become', 'dominant', 'approach', 'natural', 'language', 'processing', 'nlp', 'get', 'popular', 'computer', 'vision', 'reuse', 'learn', 'component', 'less', 'study', 'field', 'decisionmake', 'exist', 'work', 'focus', 'transfer', 'policy', 'hand', 'world', 'model', 'type', 'powerful', 'perception', 'model', 'purely', 'train', 'selfsupervise', 'learn', 'lie', 'recent', 'progress', 'modelbase', 'reinforcement', 'learning', 'however', 'transferability', 'world', 'model', 'wellstudie', 'learn', 'policy', 'use', 'pretraine', 'world', 'model', 'exploration', 'datum', 'demonstrate', 'superior', 'zeroshot', 'fewshot', 'ability', 'improve', 'direction', 'study', 'different', 'setting', 'imitation', 'learn', 'particular', 'communicate', 'task', 'model', 'observe', 'expert', 'communicate', 'task', 'ground', 'truth', 'reward', 'function', 'less', 'accessible', 'realworld', 'set', 'discussion', 'conclusion', 'paper', 'present', 'aime', 'modelbase', 'method', 'imitation', 'observation', 'core', 'method', 'exploit', 'power', 'pretraine', 'world', 'model', 'inverse', 'action', 'input', 'take', 'gradient', 'walker', 'embodiment', 'dmc', 'suite', 'demonstrate', 'superior', 'performance', 'compare', 'baseline', 'even', 'baseline', 'access', 'true', 'state', 'result', 'showcase', 'zeroshot', 'ability', 'learnt', 'world', 'model', 'aime', 'perform', 'well', 'still', 'limitation', 'first', 'human', 'mostly', 'observe', 'vision', 'aime', 'work', 'quite', 'well', 'visual', 'setting', 'still', 'gap', 'compare', 'lpomdp', 'set', 'lowdimensional', 'signal', 'observe', 'attribute', 'fact', 'loss', 'surface', 'pixel', 'reconstruction', 'loss', 'smooth', 'enough', 'allow', 'gradient', 'method', 'find', 'equally', 'good', 'solution', 'second', 'paper', 'study', 'simple', 'setting', 'embodiment', 'sensor', 'layout', 'fix', 'task', 'hand', 'human', 'observe', 'thirdperson', 'perspective', 'also', 'imitate', 'animal', 'body', 'even', 'similar', 'human', 'relax', 'assumption', 'open', 'possibility', 'transfer', 'different', 'embodiment', 'even', 'directly', 'human', 'video', 'third', 'task', 'even', 'human', 'achieve', 'zeroshot', 'imitation', 'watch', 'due', 'task', 'complexity', 'completely', 'unfamiliar', 'skill', 'even', 'proper', 'instruction', 'human', 'still', 'need', 'practise', 'environment', 'learn', 'new', 'solve', 'task', 'motivate', 'online', 'learning', 'phase', 'extension', 'framework', 'defer', 'topic', 'future', 'work', 'hope', 'paper', 'demonstrate', 'great', 'potential', 'transfer', 'learnt', 'world', 'model', 'incentivise', 'people', 'work', 'direction', 'encourage', 'researcher', 'also', 'share', 'learnt', 'world', 'model', 'contribute', 'community', 'acknowledgment', 'disclosure', 'funding', 'want', 'acknowledge', 'aljalbout', 'insightful', 'discussion', 'initial', 'stage', 'project', 'botond', 'cseke', 'mathematical', 'support', 'reference', 'andrei', 'grave', 'georg', 'ostrovski', 'sadik', 'ioannis', 'antonoglou', 'king', 'shane', 'legg', 'demis', 'hassabis', 'humanlevel', 'control', 'deep', 'reinforcement', 'learning', 'nature', 'aja', 'maddison', 'schrittwieser', 'ioannis', 'lanctot', 'sand', 'dieleman', 'nal', 'kalchbrenner', 'ilya', 'sutskever', 'thore', 'graepel', 'demis', 'master', 'game', 'go', 'deep', 'neural', 'network', 'tree', 'search', 'nature', 'oriol', 'vinyal', 'igor', 'babuschkin', 'horgan', 'aja', 'laurent', 'sifre', 'trevor', 'vezhnevet', 'rémi', 'leblond', 'tobia', 'pohlen', 'budden', 'yury', 'sulsky', 'paine', 'caglar', 'gulcehre', 'ziyu', 'tobia', 'ring', 'dani', 'app', 'grandmaster', 'level', 'use', 'multiagent', 'reinforcement', 'learning', 'nature', 'suyoung', 'learn', 'quadrupedal', 'locomotion', 'deformable', 'terrain', 'science', 'robotic', 'paino', 'matthia', 'plappert', 'schneider', 'welinder', 'qime', 'yuan', 'solve', 'cube', 'robot', 'hand', 'long', 'sandhini', 'askell', 'welinder', 'ryan', 'lowe', 'training', 'language', 'model', 'follow', 'instruction', 'human', 'feedback', 'h', 'alekh', 'editor', 'advance', 'neural', 'information', 'processing', 'system', 'schwarzer', 'pablo', 'courville', 'reincarnate', 'reinforcement', 'learning', 'reuse', 'prior', 'computation', 'accelerate', 'progress', 'h', 'alekh', 'editor', 'advance', 'neural', 'information', 'processing', 'system', 'marco', 'imitation', 'empathy', 'mirror', 'neuron', 'annual', 'review', 'psychology', 'bowen', 'joost', 'huizinga', 'raul', 'clune', 'video', 'pretraining', 'vpt', 'learn', 'act', 'watch', 'unlabeled', 'online', 'video', 'h', 'alekh', 'editor', 'advance', 'neural', 'information', 'processing', 'system', 'cornelia', 'fermuller', 'aloimonos', 'robot', 'learn', 'manipulation', 'action', 'plan', 'watch', 'unconstrained', 'video', 'world', 'wide', 'web', 'proceeding', 'conference', 'artificial', 'intelligence', 'learn', 'watch', 'extract', 'reusable', 'task', 'knowledge', 'visual', 'observation', 'human', 'performance', 'ieee', 'transaction', 'robotic', 'automation', 'younggyo', 'seo', 'pieter', 'abbeel', 'reinforcement', 'learning', 'actionfree', 'pretraining', 'video', 'gang', 'niu', 'editor', 'proceeding', '39th', 'international', 'conference', 'machine', 'learn', 'volume', 'proceeding', 'machine', 'learn', 'research', 'page', 'pmlr', 'alejandro', 'ajay', 'hafner', 'pieter', 'abbeel', 'video', 'prediction', 'model', 'reward', 'reinforcement', 'learning', 'stochastic', 'variational', 'video', 'prediction', 'international', 'conference', 'learn', 'representa', 'tion', 'manuel', 'watter', 'jost', 'springenberg', 'joschka', 'embed', 'control', 'locally', 'linear', 'latent', 'dynamic', 'model', 'control', 'raw', 'image', 'advance', 'neural', 'information', 'processing', 'system', 'maximilian', 'deep', 'variational', 'baye', 'filter', 'unsupervise', 'learning', 'state', 'space', 'model', 'raw', 'datum', 'international', 'conference', 'learn', 'representation', 'ian', 'learn', 'latent', 'dynamic', 'plan', 'pixel', 'international', 'conference', 'machine', 'learn', 'page', 'switch', 'linear', 'dynamic', 'variational', 'baye', 'filtering', 'editor', 'proceed', 'ing', '36th', 'international', 'conference', 'machine', 'learn', 'volume', 'proceeding', 'machine', 'learn', 'research', 'page', 'pmlr', 'dream', 'control', 'learn', 'behavior', 'latent', 'imagination', 'international', 'conference', 'learn', 'representa', 'tion', 'alexej', 'smagt', 'latent', 'matter', 'learn', 'deep', 'statespace', 'model', 'advance', 'neural', 'information', 'processing', 'system', 'welling', 'autoencode', 'variational', 'baye', '2nd', 'international', 'conference', 'learn', 'representation', 'iclr', 'banff', 'conference', 'track', 'proceeding', 'rezende', 'mohame', 'wierstra', 'stochastic', 'backpropagation', 'approximate', 'inference', 'deep', 'generative', 'model', 'tony', 'editor', 'proceeding', '31st', 'international', 'conference', 'machine', 'learn', 'volume', 'proceeding', 'machine', 'learn', 'research', 'page', 'bejing', 'jun', 'pmlr', 'saran', 'tunyasuvunakool', 'muldal', 'bohez', 'yuval', 'tassa', 'dmcontrol', 'software', 'task', 'continuous', 'control', 'software', 'impact', 'ramanan', 'rybkin', 'kosta', 'pieter', 'abbeel', 'hafner', 'deepak', 'pathak', 'plan', 'explore', 'selfsupervise', 'world', 'model', 'icml', 'faraz', 'stone', 'behavioral', 'cloning', 'observation', 'international', 'joint', 'conference', 'artificial', 'intelligence', 'page', 'faraz', 'stone', 'generative', 'adversarial', 'imitation', 'observa', 'tion', 'grimminger', 'martius', 'learn', 'agile', 'skill', 'adversarial', 'imitation', 'rough', 'partial', 'demonstration', '6th', 'annual', 'conference', 'robot', 'learn', 'deepak', 'pathak', 'shentu', 'evan', 'shelhamer', 'alexei', 'trevor', 'darrell', 'zeroshot', 'visual', 'imitation', 'iclr', 'nickla', 'temporal', 'difference', 'learn', 'model', 'predictive', 'control', 'gang', 'niu', 'editor', 'proceeding', '39th', 'international', 'conference', 'machine', 'learn', 'volume', 'proceeding', 'machine', 'learn', 'research', 'page', 'pmlr', 'ashvin', 'agrawal', 'phillip', 'isola', 'pieter', 'abbeel', 'combine', 'selfsupervise', 'learning', 'imitation', 'visionbase', 'rope', 'manipulation', 'ieee', 'international', 'conference', 'robotic', 'automation', 'icra', 'page', 'ieee', 'generative', 'adversarial', 'imitation', 'learn', 'guyon', 'garnett', 'editor', 'advance', 'neural', 'information', 'processing', 'system', 'volume', 'sahni', 'isbell', 'imitate', 'latent', 'policy', 'observation', 'editor', 'proceed', 'ing', '36th', 'international', 'conference', 'machine', 'learn', 'volume', 'proceeding', 'machine', 'learn', 'research', 'page', 'pmlr', 'oleh', 'rybkin', 'kosta', 'learn', 'video', 'combine', 'offline', 'observation', 'interaction', 'ramos', 'claire', 'editor', 'proceeding', 'conference', 'robot', 'learn', 'volume', 'proceeding', 'machine', 'learn', 'research', 'page', 'pmlr', 'pretraining', 'deep', 'bidirectional', 'transformer', 'language', 'understanding', 'christy', 'doran', 'solorio', 'editor', 'proceeding', 'conference', 'north', 'american', 'chapter', 'association', 'computational', 'linguistic', 'human', 'language', 'technology', 'naaclhlt', 'volume', 'long', 'short', 'paper', 'page', 'association', 'computational', 'linguistic', 'alec', 'radford', 'child', 'ilya', 'sutskever', 'language', 'model', 'unsupervise', 'learner', 'bommasani', 'draw', 'hudson', 'russ', 'bosselut', 'brunskill', 'shyamal', 'buch', 'card', 'castellon', 'jared', 'trevor', 'gale', 'tatsunori', 'kyle', 'keel', 'jure', 'isabelle', 'manning', 'suvir', 'hamed', 'papadimitriou', 'reich', 'hongyu', 'camilo', 'ruiz', 'sadigh', 'shiori', 'florian', 'rise', 'sing', 'jiaxuan', 'matei', 'opportunity', 'risk', 'foundation', 'model', 'kaime', 'xinlei', 'saine', 'piotr', 'dollár', 'mask', 'autoencoder', 'scalable', 'vision', 'learner', 'proceeding', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'page', 'chelsea', 'pieter', 'abbeel', 'modelagnostic', 'metalearning', 'fast', 'adap', 'tation', 'deep', 'network', 'teh', 'editor', 'proceeding', '34th', 'international', 'conference', 'machine', 'learn', 'volume', 'proceeding', 'machine', 'learn', 'research', 'page', 'pmlr', 'schmidhuber', 'recurrent', 'world', 'model', 'facilitate', 'policy', 'evolution', 'h', 'wallach', 'garnett', 'editor', 'advance', 'neural', 'information', 'processing', 'system', 'volume', 'learn', 'fly', 'deep', 'modelbase', 'reinforcement', 'learning', 'arxiv', 'preprint', 'mohammad', 'master', 'atari', 'discrete', 'world', 'model', 'international', 'conference', 'learn', 'representation', 'master', 'diverse', 'domain', 'world', 'model', 'łukasz', 'babaeizadeh', 'roy', 'michalewski', 'model', 'base', 'reinforcement', 'learning', 'atari', 'international', 'conference', 'learn', 'representation', 'julian', 'schrittwieser', 'ioannis', 'laurent', 'sifre', 'mon', 'schmitt', 'hassabis', 'thore', 'et', 'master', 'atari', 'go', 'chess', 'shogi', 'plan', 'learned', 'model', 'nature', 'gross', 'massa', 'trevor', 'killeen', 'zeme', 'antiga', 'desmaison', 'sasank', 'chilamkurthy', 'benoit', 'chintala', 'pytorch', 'imperative', 'style', 'high', 'performance', 'deep', 'learn', 'library', 'wallach', 'beygelzimer', 'e', 'fox', 'garnett', 'editor', 'advance', 'neural', 'information', 'processing', 'system', 'volume', 'junyoung', 'empirical', 'evaluation', 'gate', 'recurrent', 'neural', 'network', 'sequence', 'model', 'maximilian', 'seitzer', 'arash', 'tavakoli', 'dimitrije', 'antic', 'georg', 'martius', 'pitfall', 'heteroscedastic', 'uncertainty', 'estimation', 'probabilistic', 'neural', 'network', 'international', 'conference', 'learn', 'representation', 'djorkarné', 'fast', 'accurate', 'deep', 'network', 'learn', 'exponential', 'linear', 'unit', 'elu', 'aurick', 'pieter', 'abbeel', 'soft', 'actorcritic', 'policy', 'maximum', 'entropy', 'deep', 'reinforcement', 'learning', 'stochastic', 'actor', 'international', 'conference', 'machine', 'learn', 'page', 'pmlr', 'layer', 'normalization', 'cong', 'ball', 'parkerholder', 'osborne', 'teh', 'challenge', 'opportunity', 'offline', 'reinforcement', 'learning', 'visual', 'observation', 'transaction', 'machine', 'learn', 'research', 'schwarzer', 'pablo', 'deep', 'reinforcement', 'learning', 'edge', 'statistical', 'precipice', 'advance', 'neural', 'information', 'processing', 'system', 'computational', 'resource', 'gtx', '1080ti', 'graphic', 'card', 'aime', 'typically', 'require', 'hour', 'training', 'phase', 'hour', 'training', 'phase', 'mdp', 'lpomdp', 'setup', 'require', 'time', 'nearly', 'double', 'run', 'visual', 'setting', 'heavy', 'visual', 'backbone', 'render', 'conduct', 'experiment', 'share', 'local', 'cluster', 'use', 'rtx8000', 'gpu', 'new', 'gpu', 'slightly', 'improve', 'training', 'speed', 'much', 'main', 'computational', 'bottleneck', 'recurrent', 'structure', 'term', 'require', 'roughly', 'gpu', 'day', 'produce', 'benchmark', 'result', 'b', 'implementation', 'training', 'detail', 'implement', 'list', 'method', 'pytorch', 'world', 'model', 'use', 'rssm', 'offer', 'stateoftheart', 'performance', 'split', 'latent', 'state', 'combination', 'deterministic', 'stochastic', 'component', 'implemen', 'tation', 'largely', 'follow', 'dreamerv1', 'continuous', 'stochastic', 'deterministic', 'variable', 'new', 'version', 'offer', 'new', 'trick', 'improve', 'performance', 'initially', 'choose', 'use', 'sake', 'simplicity', 'use', 'slightly', 'large', 'state', 'space', 'experiment', 'deterministic', 'stochastic', 'dimension', 'find', 'generally', 'ease', 'policy', 'training', 'process', 'collect', 'dataset', 'visual', 'set', 'encoder', 'decoder', 'implement', 'cnn', 'decoder', 'output', 'gaussian', 'distribution', 'mean', 'output', 'fix', 'variance', 'lowdimensional', 'setting', 'encoder', 'implement', 'identity', 'function', 'decoder', 'gaussian', 'distribution', 'mean', 'variance', 'parameterise', 'mlp', 'deterministic', 'part', 'state', 'implement', 'gru', 'cell', 'default', 'hyperparameter', 'use', 'free', 'nat', 'scale', 'balance', 'trick', 'literature', 'relax', 'constraint', 'kl', 'term', 'decode', 'lowdimensional', 'signal', 'sometimes', 'observe', 'decoder', 'yield', 'degenerate', 'solution', 'find', 'use', 'βnll', 'remedy', 'problem', 'reweight', 'reconstruction', 'term', 'reweight', 'kl', 'term', 'accordingly', 'maintain', 'balance', 'far', 'mention', 'encoder', 'decoder', 'implement', 'mlp', 'hidden', 'layer', 'unit', 'layer', 'activation', 'function', 'component', 'train', 'optimiser', 'learning', 'rate', 'stochastic', 'policy', 'output', 'distribution', 'model', 'tanhgaussian', 'distribution', 'mean', 'variance', 'parameterise', 'neural', 'network', 'aime', 'consider', 'gradient', 'step', 'epoch', 'phase', 'model', 'train', 'epoch', 'phase', 'train', 'policy', 'epoch', 'final', 'model', 'policy', 'last', 'epoch', 'early', 'stopping', 'criterion', 'train', 'world', 'model', 'find', 'default', 'hyperparameter', 'stably', 'train', 'good', 'world', 'model', 'thus', 'adapt', 'implementation', 'exactly', 'network', 'structure', 'origin', 'repository', 'specifically', 'decoder', 'lowdimensional', 'observation', 'also', 'fix', 'variance', 'mlp', 'widen', 'neuron', 'hide', 'layer', 'equip', 'layer', 'normalisation', 'hyperparameter', 'learning', 'rate', 'decrease', 'use', 'free', 'nat', 'balancing', 'mitigate', 'collapse', 'unstable', 'problem', 'kl', 'term', 'lpomdp', 'set', 'also', 'set', 'scaling', 'parameter', 'relax', 'constraint', 'thing', 'need', 'mention', 'trick', 'kl', 'term', 'helpful', 'model', 'training', 'hurt', 'result', 'phase', 'phase', 'model', 'frozen', 'nomore', 'stability', 'issue', 'encounter', 'case', 'well', 'optimise', 'policy', 'true', 'elbo', 'strict', 'setup', 'phase', 'retrain', 'world', 'model', 'datum', 'collection', 'experiment', 'however', 'also', 'directly', 'use', 'world', 'model', 'train', 'agent', 'empirically', 'find', 'model', 'yield', 'similar', 'result', 'world', 'model', 'retrain', 'afterwards', 'reply', 'buffer', 'caveat', 'tempting', 'also', 'reuse', 'train', 'policy', 'initialisation', 'phase', 'find', 'actually', 'harmful', 'performance', 'conjecture', 'due', 'learnt', 'policy', 'stick', 'local', 'unable', 'escape', 'bco', 'baseline', 'idm', 'policy', 'build', 'use', 'network', 'architecture', 'world', 'model', 'make', 'fair', 'comparison', 'observation', 'first', 'process', 'encoder', 'network', 'stack', 'deal', 'temporal', 'information', 'mlp', 'use', 'decode', 'stack', 'representation', 'output', 'distribution', 'stack', 'consecutive', 'work', 'grid', 'search', 'width', 'depth', 'mlp', 'also', 'number', 'stack', 'frame', 'find', 'increase', 'performance', 'follow', 'original', 'paper', 'split', 'dataset', 'choose', 'finial', 'model', 'base', 'validation', 'loss', 'c', 'aime', 'idm', 'section', 'introduce', 'alternative', 'variant', 'aime', 'also', 'use', 'idm', 'recall', 'bayesian', 'derivation', 'factorise', 'posterior', 'prior', 'joint', 'distribution', 'state', 'action', 'share', 'policy', 'network', 'alternatively', 'refactorise', 'posterior', 'idm', 'ot', 'thing', 'need', 'notice', 'idm', 'familiar', 'form', 'latent', 'state', 'world', 'model', 'action', 'dependent', 'familiar', 'form', 'non', 'casual', 'world', 'model', 'highlight', 'noncasual', 'structure', 'result', 'model', 'use', 'phase', 'want', 'reuse', 'knowledge', 'learn', 'example', 'also', 'factorise', 'joint', 'posterior', 'ot', 'however', 'case', 'model', 'different', 'phase', 'section', 'stick', 'use', 'factorisation', 'new', 'idm', 'component', 'introduce', 'objective', 'phase', 'phase', 'need', 'modify', 'phase', 'action', 'available', 'dataset', 'idm', 'treat', 'decoder', 'train', 'maximise', 'likelihood', 'add', 'idm', 'τ', '−1', 'log', 'qϕ', 'ot1', 'objective', 'function', 'phase', 'action', 'available', 'idm', 'serve', 'posterior', 'guide', 'prior', 'policy', 'kl', 'divergence', '−dkl', 'ot1', 'idm', '−1', 'caveat', 'formulation', 'phase', 'idm', 'form', 'loop', 'graphical', 'model', 'order', 'stabilise', 'training', 'process', 'detach', 'gradient', 'idm', 'rest', 'network', 'dataset', 'detail', 'provide', 'extra', 'information', 'dataset', 'expert', 'return', 'normalise', 'show', 'table', 'table', 'table', 'average', 'expert', 'return', 'demonstration', 'dataset', 'walker', 'stand', 'walk', 'run', 'average', 'return', 'table', 'average', 'expert', 'return', 'demonstration', 'dataset', 'average', 'return', 'run', 'run', 'backwards', 'flip', 'backwards', 'max', 'table', 'result', 'vd4rl', 'main', 'dataset', 'embodiment', 'dataset', 'mark', 'left', 'demonstration', 'dataset', 'choose', 'expert', 'dataset', 'task', 'origin', 'environment', 'value', 'average', 'trajectory', 'report', 'accumulate', 'reward', 'divide', 'suggest', 'vd4rl', 'paper', 'bco', 'aime', 'walkermediumreplay', 'walkermix', 'cheetahmediumreplay', 'e', 'experiment', 'vd4rl', 'dataset', 'provide', 'additional', 'result', 'aime', 'vd4rl', 'dataset', 'showcase', 'aime', 'also', 'work', 'dataset', 'collect', 'nonmodelbased', 'method', 'vd4rl', 'provide', 'multiple', 'different', 'dataset', 'walker', 'embodiment', 'suite', 'original', 'design', 'offline', 'rl', 'visual', 'input', 'dataset', 'collect', 'run', 'modelfree', 'rl', 'method', 'keep', 'replay', 'buffer', 'rollout', 'policy', 'checkpoint', 'setting', 'require', 'bit', 'exploration', 'embodiment', 'dataset', 'understand', 'embodiment', 'choose', 'use', 'random', 'mediumreplay', 'dataset', 'embodiment', 'dataset', 'expert', 'dataset', 'use', 'demonstration', 'dataset', 'walker', 'embodiment', 'main', 'text', 'also', 'mix', 'embodiment', 'dataset', 'embodiment', 'form', 'mix', 'dataset', 'result', 'dataset', 'show', 'table', 'see', 'performance', 'bco', 'aime', 'generally', 'low', 'still', 'outperform', 'bco', 'prove', 'aime', 'also', 'handle', 'dataset', 'generate', 'modelfree', 'method', 'low', 'performance', 'due', 'constrained', 'setup', 'task', 'less', 'amount', 'embodiment', 'datum', 'less', 'diversity', 'cheetahmediumreplay', 'trajectory', 'dataset', 'provide', 'vd4rl', 'trajectory', 'much', 'less', 'trajectory', 'main', 'experiment', 'moreover', 'already', 'show', 'figure', 'figure', 'random', 'dataset', 'help', 'much', 'learn', 'model', 'intuitively', 'mediumreplay', 'dataset', 'well', 'still', 'contain', 'enough', 'information', 'solve', 'task', 'also', 'conduct', 'experiment', 'vd4rl', 'distract', 'dataset', 'test', 'performance', 'aime', 'distract', 'dataset', 'walker', 'embodiment', 'benchmark', 'provide', 'random', 'dataset', 'distraction', 'level', 'easy', 'medium', 'hard', 'also', 'merge', 'level', 'form', 'mix', 'dataset', 'moreover', 'also', 'merge', 'mix', 'dataset', 'mix', 'dataset', 'second', 'experiment', 'form', 'totalmix', 'dataset', 'treat', 'dataset', 'embodiment', 'dataset', 'expert', 'dataset', 'demonstration', 'dataset', 'benchmark', 'provide', 'medium', 'expert', 'dataset', 'distraction', 'level', 'easy', 'medium', 'hard', 'subsample', 'medium', 'dataset', 'get', 'trajectory', 'level', 'merge', 'mix', 'dataset', 'second', 'experiment', 'form', 'totalmix', 'dataset', 'algorithm', 'use', 'totalmix', 'dataset', 'embodiment', 'dataset', 'expert', 'dataset', 'demonstration', 'dataset', 'see', 'result', 'table', 'still', 'outperform', 'bco', 'baseline', 'aime', 'impact', 'significantly', 'distraction', 'behaviour', 'expect', 'world', 'model', 'train', 'reconstruction', 'loss', 'easy', 'handle', 'observation', 'distraction', 'potential', 'solution', 'problem', 'freeze', 'dynamic', 'part', 'world', 'model', 'allow', 'encoder', 'decoder', 'finetune', 'parameter', 'second', 'phase', 'leave', 'improvement', 'future', 'work', 'additional', 'plot', 'section', 'present', 'additional', 'plot', 'complement', 'main', 'text', 'provide', 'insight', 'table', 'result', 'vd4rl', 'distract', 'dataset', 'embodiment', 'dataset', 'mark', 'left', 'demonstration', 'dataset', 'choose', 'expert', 'dataset', 'task', 'origin', 'environment', 'value', 'average', 'trajectory', 'report', 'accumulate', 'reward', 'divide', 'suggest', 'vd4rl', 'paper', 'walkereasy', 'walkerhard', 'walkermix', 'aime', 'cheetahtotalmix', 'additional', 'figure', 'figure', 'also', 'provide', 'detailed', 'profile', 'plot', 'figure', 'figure', 'recommend', 'see', 'aime', 'normally', 'stable', 'wrt', 'performance', 'small', 'decay', 'region', 'clearly', 'show', 'task', 'walk', 'walk', 'run', 'run', 'walker', 'bco', 'mdp', 'trail', 'low', 'performance', 'variant', 'aime', 'maintain', 'decent', 'performance', 'figure', 'performance', 'distribution', 'method', 'walker', 'task', 'also', 'present', 'representative', 'training', 'curve', 'aime', 'phase', 'experiment', 'figure', 'first', 'figure', 'show', 'transfer', 'mix', 'dataset', 'run', 'task', 'setting', 'typical', 'success', 'case', 'aime', 'course', 'training', 'maximise', 'convergence', 'mse', 'generate', 'action', 'true', 'action', 'decrease', 'also', 'see', 'mdp', 'lpomdp', 'setting', 'converged', 'elbo', 'low', 'elbo', 'evaluate', 'true', 'action', 'sequence', 'indicate', 'still', 'space', 'improvement', 'however', 'visual', 'set', 'converged', 'exceed', 'true', 'action', 'attribute', 'overfitting', 'world', 'model', 'phase', 'last', 'figure', 'p', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'random', 'stand', 'random', 'walk', 'random', 'run', 'stand', 'walk', 'run', 'stand', 'stand', 'stand', 'walk', 'stand', 'run', 'walk', 'stand', 'walk', 'walk', 'walk', 'run', 'run', 'stand', 'run', 'walk', 'run', 'run', 'mix', 'stand', 'mix', 'walk', 'mix', 'run', 'relative', 'expert', 'performance', 'p', 'relative', 'expert', 'performance', 'p', 'relative', 'expert', 'performance', 'p', 'method', 'bco', 'visual', 'bco', 'lpomdp', 'aimevisual', 'aimelpomdp', 'aimemdp', 'figure', 'performance', 'distribution', 'method', 'task', 'show', 'transfer', 'random', 'dataset', 'task', 'visual', 'setting', 'consider', 'failure', 'case', 'stand', 'walk', 'task', 'none', 'metric', 'converge', 'run', 'task', 'observe', 'severe', 'overfitting', 'start', 'beginning', 'training', 'mse', 'keep', 'increase', 'conjecture', 'due', 'less', 'welltrained', 'world', 'model', 'p', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'l', 'r', 'random', 'run', 'random', 'runb', 'random', 'flip', 'random', 'flipb', 'run', 'runb', 'flip', 'run', 'run', 'run', 'runb', 'run', 'flip', 'run', 'runb', 'run', 'runb', 'visual', 'bco', 'lpomdp', 'aimevisual', 'aimelpomdp', 'aimemdp', 'flip', 'run', 'flip', 'runb', 'flip', 'flip', 'flip', 'run', 'flipb', 'flip', 'relative', 'expert', 'performance', 'p', 'relative', 'expert', 'performance', 'p', 'relative', 'expert', 'performance', 'p', 'relative', 'expert', 'performance', 'p', 'figure', 'sample', 'training', 'curve', 'phase', 'aime', 'first', 'showcase', 'typical', 'successful', 'training', 'curve', 'remain', 'demonstrate', 'failure', 'case', 'trueaction', 'refer', 'evaluate', 'trajectory', 'true', 'action', 'sequence', 'elbo', 'rec', 'term', 'kl', 'term', 'action', 'mse', 'aimemdp', 'mix', 'run', 'training', 'curve', 'aime', 'aime', 'trueaction', 'aime', 'trueaction', 'normalise', 'return', 'aime', 'elbo', 'rec', 'term', 'kl', 'term', 'action', 'mse', 'normalise', 'return', 'aimelpomdp', 'mix', 'run', 'training', 'curve', 'aime', 'trueaction', 'aime', 'trueaction', 'aime', 'aimevisual', 'mix', 'run', 'training', 'curve', 'kl', 'term', 'action', 'mse', 'normalise', 'return', 'rec', 'term', 'aime', 'trueaction', 'aime', 'trueaction', 'aime', 'trueaction', 'aime', 'aime', 'aimevisual', 'random', 'stand', 'training', 'curve', 'rec', 'term', 'kl', 'term', 'aime', 'trueaction', 'aime', 'trueaction', 'aime', 'normalise', 'return', 'aime', 'aime', 'aimevisual', 'random', 'walk', 'training', 'curve', 'rec', 'term', 'kl', 'term', 'aime', 'trueaction', 'aime', 'trueaction', 'action', 'mse', 'normalise', 'return', 'aime', 'aime', 'rec', 'term', 'kl', 'term', 'action', 'mse', 'aimevisual', 'random', 'run', 'training', 'curve', 'aime', 'trueaction', 'aime', 'aime', 'trueaction', 'normalise', 'return', 'aime', 'aime']"
"Google Tag Manager: Hidden Data Leaks and its Potential Violations under
  EU Data Protection Law","[{'href': 'http://arxiv.org/abs/2312.08806v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2312.08806v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-12-14 10:46:18,"3
2
0
2

c
e
D
3
1

]
h
p
-
t
n
a
u
q
[

1
v
0
1
1
8
0
.
2
1
3
2
:
v
i
X
r
a

Tailored and Externally Corrected Coupled Cluster with Quantum Inputs

Maximilian Scheurer,1,

∗ Gian-Luca R. Anselmetti,1,

† Oumarou

Oumarou,1 Christian Gogolin,1,

‡ and Nicholas C. Rubin2,

§

1Covestro Deutschland AG, 51373 Leverkusen, Germany
2Google Quantum AI, Venice, CA, United States
(Dated: December 14, 2023)

We propose to use wavefunction overlaps obtained from a quantum computer as inputs for the
classical split-amplitude techniques, tailored and externally corrected coupled cluster, to achieve
balanced treatment of static and dynamic correlation effects in molecular electronic structure simu-
lations. By combining insights from statistical properties of matchgate shadows, which are used to
measure quantum trial state overlaps, with classical correlation diagnostics, we are able to provide
quantum resource estimates well into the classically no longer exactly solvable regime. We find that
rather imperfect wavefunctions and remarkably low shot counts are sufficient to cure qualitative
failures of plain coupled cluster singles doubles and to obtain chemically precise dynamic correla-
tion energy corrections. We provide insights into which wavefunction preparation schemes have a
chance of yielding quantum advantage, and we test our proposed method using overlaps measured
on Google’s Sycamore device.

I.

INTRODUCTION

Recent work devising how to use a quantum computer to model electronic structure continues to suggest fermionic
simulation as a valuable and viable application of near-term and fault-tolerant quantum devices. Just as in the
classical modeling of electronic structure where various strategies are explored for treating different aspects of electron
correlation, quantum algorithms have largely followed a similar divide-and-conquer trajectory. While treatment of
strong correlation is cited as the most likely motivation for applying quantum computers to chemistry,1 an accurate
treatment of dynamic electronic correlation effects is an important aspect when considering total quantum resource
counts and the viability of applying a quantum computing protocol to solve electronic structure problems.

In this work, we further integrate classical electronic structure methodologies and quantum computation to lower
measurement requirements needed for dynamical correlation corrections. Our focus is on split-amplitude coupled
cluster (CC) methodologies that have been widely studied in the quantum chemistry community.2,3 Specifically,
we analyze the robustness of quantum inputs to these theories along with motivating wavefunction characteristics
that a quantum computer must satisfy to improve over classical approximate external amplitude inputs. While it
is generally possible to layer quantum state preparation with many dynamic correlation corrections, split-amplitude
methods provide the necessary framework in which we can analyze the sampling costs and robustness beyond common,
and usually loose, tomographic sampling bounds.

To date, there exist several approaches to include dynamic correlation effects in quantum simulations of chem-
istry, e.g., virtual quantum subspace expansion (VQSE),4 second-order perturbation theory using the variational
quantum eigensolver (VQE)1,5,6 together with quantum subspace expansion (QSE), named NEVPT2(VQE,QSE),7
non-orthogonal configuration interaction approaches,8 and NEVPT2 based on qubit reduced density matrices (RDMs),
named QRDM-NEVPT2.9 We note that a plethora of other methods for studies of chemical systems exists, e.g., based
on embedding techniques.10–17 The QRDM-NEVPT2 method, in addition to VQE state preparation and optimization,
requires quantum evaluation of the three-particle reduced density matrix (3RDM) and four-particle RDM-like terms,
exploiting a cumulant approximation. For quantum active space (AS) methods, it is already quite resource-intense
with respect to required number of measurement repetitions, so-called shots, to accurately determine the 2RDM for
energy evaluation. As a consequence, a multitude of approaches for efficient measurements of the 2RDM has evolved
so far, reducing the number of distinct measurement bases and variances significantly.18–25 Thus, the burden of even
more measurements required for higher-order reduced density matrices in, e.g., QRDM-NEVPT2 poses the question
whether one can construct a hybrid quantum/classical approach which does not rely on RDMs. Recent work leverag-
ing classical shadows26 combined with auxiliary-field Quantum Monte Carlo (AFQMC)27 suggests an efficient path
forward by shifting focus to wavefunction corrections in lieu of the RDMs.

∗ Corresponding Author: maximilian.scheurer@covestro.com
† Current Address: Quantum Lab, Boehringer Ingelheim, 55218 Ingelheim am Rhein, Germany
‡ christian.gogolin@covestro.com
§ Corresponding Author: nickrubin@google.com

 
 
 
 
 
 
2

FIG. 1: A visual representation of the quantum split-amplitude protocol analyzed in this work.

To this end, we propose to use quantum trial states as input for tailored coupled cluster (TCC) and externally
corrected coupled cluster (ec-CC) methods. On the quantum device level, this requires preparing a suitable state
and then measuring the overlaps of that state with (excited) Slater determinants, corresponding to computational
basis state overlaps. The steps required to obtain quantum inputs and run the subsequent classical CC calculation is
depicted in Figure 1, comparing the workflow with its purely classical counterpart. Only two building blocks differ
between the quantum and classical version. To extract computational basis overlaps we propose to leverage various
forms of classical shadows,26 a measurement technique allowing for efficient estimation of multiple expectation values,
which have recently been extended to use the matchgate group for efficient overlap estimation.23,25 These protocols
fulfill the requirement of providing overlap magnitudes and signs, which are needed for subsequent cluster analysis.
In contrast to classical TCC and ec-CC methodologies developed to date, quantum TCC and quantum ec-CC require
analysis of i) when improvements over classical approximate methods are possible and ii) sensitivity of these methods
to device and shot noise. We take steps towards addressing both questions in this work. We note that the proposed
methodologies are not limited to any particular quantum computing setting, since the CC methods are completely
agnostic of the origin of the cluster amplitudes. Hence, they are applicable to near-term and fault-tolerant setups
alike, provided a protocol for evaluating the overlaps exists. While the total number of computational basis state
overlaps scales exponentially in the number of qubits n, TCC with singles and doubles (TCCSD) and ec-CC only
require a polynomial number of overlaps as input for cluster analysis, i.e., less than n4 for TCCSD and less than n8
for ec-CC.

A substantial component of this work involves constructing a noise model for matchgates shadows and mapping a
model for measurement overheads given common electronic structure metrics that are cheaply available. We implement
the matchgate shadows described in Ref. 25 and numerically verify that the measurements of computational basis state
overlaps follow a Gaussian distribution and are independent and identically distributed. To determine a shot budget
for TCCSD using the Gaussian noise model of matchgate shadows, we fit the total shot requirements to a particular
D1 diagnostics.28,29 We analyze the
error to a power law distribution with constants determined by well-known
robustness ec-CC with experimental Clifford classical shadows to emphasize the regime of utility and demonstrate the
methods robustness to real experimental noise on using data taken from the recent QC-QMC experiment by Google
and collaborators.27

T1 or

We continue with a methodological account and an overview of split-amplitude methods, but expert readers can
directly skip to Section III, where we discuss the impact of possible quantum trial states and their quality require-
ments for split-amplitude quantum CC methods. Furthermore, we present numerical results of quantum TCCSD by
simulating of the N2 dissociation curve in a VQE-based NISQ setting, further highlighting state preparation robust-
ness of TCCSD. We then describe overlap measurement strategies in Section IV, which are the key ingredient for
providing quantum inputs. Based on numerical studies of the statistical properties of matchgate shadows, we develop
the noise model to mimic finite shot noise, and we employ this noise model to obtain quantum resource estimates for
beyond classically tractable molecular systems. For an N2 dissociation curve of 21 points within a double-zeta basis
set, we find that a total of 30 million shots will be enough for chemically precise results. Finally, in Section V, we

Classical Computer

HF Reference

Active Space Hamiltonian

Quantum Computer

Multiconfigurational Method

Quantum Trial Preparation

Molecular
Orbitals

Overlap Extraction

Overlap Measurements
(classical shadows)

Cluster Analysis

CC Calculation

study the performance of quantum split-amplitude CC energetics on H4 and diamond, using classical shadows data
from an experiment performed on Google’s Sycamore device, demonstrating that ec-CC can in principle compete with
QC-QMC.

3

II. BACKGROUND ON ELECTRONIC STRUCTURE METHODS

The field of quantum chemistry has seen remarkable progress over the past decades, with ab-initio coupled cluster
(CC) methods emerging as a reliable and systematically improvable framework for electronic structure simulations of
molecules.30–32 The most successful method of the CC family is probably coupled cluster with singles and doubles
(CCSD)33 in conjunction with a perturbative triples correction, CCSD(T),34 commonly referred to as the “gold
standard” for quantum chemistry.35,36 Therefore, CCSD and CCSD(T) are possibly the most used wavefunction
methods to investigate properties of small and medium-sized molecules, limited in applicability by the steep scaling.
Recent endeavours, however, have made it possible to push the boundaries with respect to system size even further.36
Due to favorable properties, e.g., size consistency in contrast to truncated configuration interaction (CI) ans¨atze,37
these single-reference CC (SRCC) methods usually perform well in describing molecular systems where dynamic
correlation effects are dominant.38 On the contrary, SRCC approaches can struggle in multi-reference (MR) scenarios,
such as describing the potential energy surface of bond breaking, and lead to catastrophic failures in several cases.2,39
The MR failures can in principle be remedied through an even more computationally demanding framework, that is,
multi-reference CC (MRCC).16,40 In case a system at hand is almost purely statically correlated, i.e., where the solution
to the electronic Schr¨odinger equation is well described by a couple of Slater determinants, accurate results can be
obtained through so-called multiconfigurational active space (AS) methods, such as complete active space configuration
interaction (CASCI).41–45 The active space consists of a subset of molecular orbitals (MOs) and electrons in which
the full configuration interaction (FCI) problem is then solved. This approach covers static correlation effects well,
but neglects major part of the dynamic correlation effects outside of the chosen active space. Hence, the division into
an active and external orbital space introduces approximations that, while qualitative phenomena might be described
correctly, can become unacceptable when chemical precision is required.4,46 With techniques such as selected CI
methods47–51 and density matrix renormalization group (DMRG),52 it becomes possible to simulate quite large active
spaces, or even aim toward FCI quality. If the active space size cannot be increased enough, the dynamic correlation
contributions can be approximately included through perturbation theory on the CAS method, yielding, e.g., the
well-known CASPT2 and NEVPT2 methods.53–57

Fortunately, the well-known framework of SRCC offers the possibility to capture static correlation properties from
an AS-type wavefunction through a so-called split-amplitude ansatz. The most prominent methods of this family
are tailored coupled cluster (TCC)2 and externally corrected coupled cluster (ec-CC),3,58–62 however, approaching
the encoding of static correlation effects from different directions. The high-level idea of both methods is to extract
information about the static correlation from the AS wavefunction and inject them through specific partitioning of
the cluster operator and the corresponding amplitudes in a SRCC wavefunction. Originally, these methods were
developed to remedy failures of SRCC approaches in the strongly correlated regime, as explained previously. TCC
and ec-CC are schematically illustrated in Figure 2, and more theoretical details are outlined in Appendix A. In the
TCC ansatz, the cluster operator is split into an active space part and an external part,

ˆT TCC = ˆT AS + ˆT ext.

(1)

The cluster amplitudes, accompanying the active space cluster operator, are obtained from the AS-type multicon-
figurational wavefunction through cluster analysis. Cluster analysis relies on the equivalence of the exponential CC
ansatz and the linear CI expansion using intermediate normalization, making it possible to recursively convert the
amplitudes from a CI-like wavefunction to their corresponding CC counterpart.2,63,64 For CC with singles and dou-
bles, this yields the so-called TCCSD approach, where the strategy is to extract T1 and T2 amplitudes from the
AS-type wavefunction. The active space T1 and T2 amplitudes are then frozen during the CC iterations on the
external amplitudes, assuming the active space amplitudes retain the MR information. The original work by Bartlett
and co-workers showed that, despite its simplicity, TCCSD yields dissociation energies and potential energy surfaces
which are in good agreement with higher-level MR methods.2 Note that the only inputs required for TCC are overlaps
of (excited) Slater determinants with the AS wavefunction, which can be formulated as the following projection,

cν =

Φν

⟨

|

ΨAS

.

⟩

(2)

In the equation above, cν is the CI coefficient vector of excitation level ν,
with respect to the Fermi vacuum/reference determinant

, and

Φν

is a ν-fold excited Slater determinant
|
is an AS-type wavefunction from which the

⟩

Φ0⟩
|

ΨAS
|

⟩

4

FIG. 2: Schematic illustration of TCC (left) and ec-CC (right). In TCC, a subset of the cluster amplitudes are

AS through cluster analysis. The external set of amplitudes is then
obtained from an active space wavefunction
⟩
solved in presence of frozen AS amplitudes, which encode the information on static correlation. The ec-CC ansatz
uses T3 and T4 amplitudes from an input wavefunction (which can stem either from an active space or from the full
space) and solves the full CCSDTQ singles and doubles equations in presence of the external T3 and T4 amplitudes.

Ψ
|

coefficients are to be extracted. For TCCSD, only the C1 (ν = 1) and C2 (ν = 2) coefficients need to be extracted,
i.e.,

ca
i =
cab
ij =

⟨

⟨

Φa
i |
Φab
ij |

ΨAS
⟩
ΨAS

⟩

,

,

(3)

(4)

ΨAS

|

⟩

Φ0⟩
|

, whereas a, b are so-called virtual orbital indices, i.e., unoccupied in

in addition to the overlap with the reference determinant, c0, if
is not intermediate-normalized. The indices
i, j refer to occupied orbitals in
.
Φ0⟩
|
Subsequently, the C amplitudes are recursively converted to T amplitudes, mapped from the active orbitals to the full
MO space, and kept fixed during solution of the CCSD projection equations. It is quite appealing that only minor
modifications to a standard CCSD code need to be made to support tailoring. Different types of input wavefunctions
have been successfully used for TCCSD, e.g., CASCI,2,65 DMRG for large active spaces,66 and pair coupled cluster
doubles (pCCD).67 A recent extension to excited state calculations has been presented by Bartlett and co-workers.68
There exists the tailored counterpart to CCSD(T), that is, TCCSD(T),69 which computes the perturbative triples
correction solely using the external contribution of the cluster amplitudes. Through combination with the LPNO
and DLPNO framework, TCC has been successfully employed to study the electronic structure of large molecular
complexes.70–72 Furthermore, the underlying numerical and theoretical aspects have been thoroughly analyzed from
a mathematical point of view.73,74 Even though the tailoring of T1 and T2 amplitudes captures the static correlation
effects to some extent, the final TCCSD wavefunction is still a SR wavefunction, which is known to fail in some
cases.39,75,76 To some level, these shortcomings can be circumvented by increasing the active space size and the choice
of orbitals.35,39

The second split-amplitude approach, ec-CC, addresses the inclusion of multi-reference phenomena in a SRCC
wavefunction from a different direction.3 Viewed as a variation of tailored coupled cluster but on the full space77,78 we
use the fact that the singles and doubles residual equations can only involve singles amplitudes through quadruples
amplitudes

Φab
ij |

⟨

ˆHN
(cid:20)

(cid:18)

1 + ˆT1 + ˆT2 +

1
2

Φa
i |
⟨

ˆHN
(cid:20)
1 + ˆT3 + ˆT1 ˆT2 +
ˆT 2

1
6

1
2

1 + ˆT1 + ˆT2 +

1 + ˆT3 + ˆT1 ˆT2 +
ˆT 2

(cid:18)
1 + ˆT4 + ˆT1 ˆT3 +
ˆT 3

1
2

ˆT 2
2 +

1
2

ˆT 2
1

ˆT2 +

1
6
1
24

ˆT 3
1

ˆT 4
1

Φ0⟩

(cid:19)(cid:21)c |

Φ0⟩

(cid:19)(cid:21)c |

= 0,

(5)

= 0,

(6)

which is true for any rank coupled cluster operator, above four, because the normal-ordered Hamiltonian ˆHN has
at most two-body interactions. If the triples and quadruples amplitudes in ˆT3 and ˆT4 are exactly determined with,
e.g., FCI, then the exact correlation energy can be recovered. This is to be expected since the exact amplitudes in
ˆT3 and ˆT4 depend on CI coefficients of rank 1, 2, 3, and 4. This can, however, provide an alternative route to better
than CCSD calculations if approximate triples and quadruples are obtained from an AS-type method. While there

ΨAS
|

⟩

ˆT AS

ˆT ext

Ψinput

|

⟩

ˆT3, ˆT4

ˆT1
ˆT2
ˆT3
ˆT4

ΨTCC
|

⟩

= exp

ˆT AS + ˆT ext

(cid:16)

Φ0⟩
|

(cid:17)

Ψec-CC
|

⟩

= exp

ˆT1 + ˆT2 + ˆT3 + ˆT4

(cid:16)

Φ0⟩
|

(cid:17)

5

are obvious instance where ec-CC provides no value (e.g., wavefunctions where cluster operators of rank 2 to 4 are
used and their active space versions – CCSDt, and CCSDtq), there are cases where improvements are observed.79
The key components of when an ec-CC treatement can provide improvement are described in Ref. 79 and will be
summarized in the context of quantum wavefunctions in Section III. The main idea is that if one uses frozen triples
and quadruples amplitudes obtained in some way and solves for the singles and doubles in their presence, one can
determine a corrected form of the quadruples CC involving MR character. In practice, a non-CC wavefunction theory
in an active space is used to determine the dominant triple and quadruple excitations, and the cluster operator takes
on the form

ˆT = ˆT1 + ˆT2 + ˆP3 ˆT3 + ˆP4 ˆT4,

(7)

where ˆP3,4 project out a subset of triples and quadruples excitation that are dictated from a correlated multi-reference
calculations such as DMRG, heat-bath CI,80 or adaptive CI.81 Alternatively, one can use an uncoverged FCIQMC
calculation to recover approximate triples and quadruples amplitudes to then solve for for the ˆT1 and ˆT2 parts.79
It was demonstrated that roughly converged FCIQMC calculations can result in quite accurate CCSDTQ energies.
The role of the FCIQMC calculation is to determine dominant triple and quadruple amplitudes. A caveat is that
the classical computational effort of ec-CC scales like N 8 (see Appendix A 4), which, contrary to TCCSD with a N 6
scaling, limits the applicability of ec-CC to systems of modest size. TCC and ec-CC require the same kind of inputs,
namely the overlaps of Slater determinants with the AS-type wavefunction which is then put into a cluster analysis
protocol. In the context of quantum computation, this has the appealing advantage that no higher-order RDMs are
required to enable a split-amplitude CC calculation based on a quantum trial state.

III.

IMPACT OF QUANTUM TRIAL STATES QUALITY

In this section we first investigate the stability of TCCSD against overlaps derived from imperfect wavefunctions,
such as those states prepared by a shallow VQE circuit. We find that even wavefunctions whose AS energy differs
significantly from CASCI do yield a TCCSD dynamic correlation energy correction that is in good agreement with both
TCCSD and NEVPT2 based on the exact CASCI wavefunction. What is more surprising, even a rather inaccurate
wavefunction as input to TCCSD turns out to be sufficient to cure the appearance of a qualitatively incorrect reaction
barrier in plain CCSD. We are further able to provide insights into which wavefunctions have a chance of leading to
an improved energy under ec-CC on the full orbital space.

A. Quantum TCCSD with Approximate VQE Wavefunctions

We model the dissociation of the N2 triple bond, a textbook example in which the dynamic and static correlation
regime need to be converged well for quantitatively reliable results.2 In the first TCCSD work,2 it has been shown that
TCCSD tailored by CASCI with 6 electrons in 6 orbitals, CAS(6,6), gives a qualitatively and quantitatively correct
dissociation curve, in contrast to plain CCSD. Our goal here is to assess whether TCCSD tailored by one of the
most prominent quantum methods for simulating electronic structure, VQE, behaves similarly. Since the underlying
VQE circuits which would be required to prepare the exact CASCI state are not affordable, we want to analyze
how inaccuracies in the wavefunction ansatz translate to TCCSD, or whether this even leads to a breakdown of the
beneficial properties of TCCSD after all. For this purpose, we set up a quantum-number-preserving (QNP)82 circuit
of 10 layers (50 parameters), which was optimized for each geometry along the dissociation curve. The reference
state was obtained with restricted HF/cc-pVDZ.83 For the “stress test” with respect to rather shallow VQE circuits,
we then ran TCCSD based on the overlaps obtained analytically from the final VQE state (through read-out of
the coefficients of the VQE state vector), referred to as VQE-TCCSD in the following. The dissociation curves for
CCSD, CASCI, NEVPT2, TCCSD, VQE, and VQE-TCCSD are shown in Figure 3 in the left panel. As previously
observed, the equilibrium region is well described by CCSD, but this method yields a qualitatively incorrect virtual
reaction barrier upon triple bond breaking, which is fully recovered by TCCSD.2 Plus, TCCSD provides an accurate
numerical value for the dissociation energy, whereas the CASCI curve results in a too small dissociation energy.
This shows how important the inclusion of dynamic correlation effect becomes for accurate simulations. Comparing
CASCI to TCCSD, the barrier is shifted from 286.8 milli-Hartree (mEh) by 45.4 mEh to 332.0 mEh, which is quite a
significant change. For comparison, we ran NEVPT2 on CASCI for this system, which yields almost exactly the same
dissociation curve as TCCSD. Now, due to the shallow VQE circuit used in our simulations, the predicted reaction
barrier is artificially too high and VQE-TCCSD cannot repair the incorrect energy contribution from the active space.
If the VQE circuit were expressive enough, one would obtain a dissociation curve identical to CASCI. In the upper

6

FIG. 3: Dissociation curve of N2 using classical and quantum methods (left panel), CASCI energy error of the
employed VQE ansatz (upper right panel), and external correlation energy Eext of TCCSD methods (lower right
panel). For the dissociation curve, energies are relative to the minimum energy the inter-nuclear distance R = 1.1 ˚A.
Note that the relative energies of TCCSD and NEVPT2 almost lie on top of each other.

right panel in Figure 3, the error of the VQE energy with respect to CASCI is shown. For bond distances R > 1.2 ˚A,
the energy error is larger than 10 mEh and steadily increases toward the dissociation limit. Around the equilibrium
bond distance, the system possesses only weak static correlation effects, such that the shallow VQE circuit is of course
much more accurate in that region. Looking at the VQE-TCCSD dissociation curve, no artificial reaction barrier
is present, i.e., despite the poor quality of the VQE ansatz, the quality of the underlying wavefunction seems good
enough to heal the physically wrong CCSD behavior. Interestingly, the VQE dissociation energy (345.3 mEh) is shifted
in VQE-TCCSD (392.6 mEh) by 47.3 mEh, which is almost identical to the energy shift from CASCI to TCCSD, i.e.,
without imperfections in the wavefunction. This parallel can be narrowed down to the external energy contribution
in TCCSD, Eext, depicted for TCCSD and VQE-TCCSD in the lower right panel in Figure 3. The contribution from
the external TCCSD part is almost identical, showing that the dynamic energy contribution in TCCSD is very robust
against a poor CI-like wavefunction produced from the shallow VQE circuit, and the error in energy shift from the
CI-like method to TCCSD is approximately one order of magnitude smaller than the plain VQE error. Note that
the quantum inputs for VQE-TCCSD amount to only measuring less than n4 overlap values, whereas a possible PT
approach would require higher-order RDMs.

B. Wavefunctions Suitable for Externally Corrected CC

In this section we discuss the characteristics of a quantum trial and the potential benefit over classically accessible
wavefunctions as input to ec-CC. Within the NISQ setting there is no shortage of methods for preparing approximate
ground states.5,6,82,84–95 If we consider fault-tolerance, an even wider set of methods is available.96–102

Here we emphasize recent work from Magoulas et al.79 which provides a framework for analyzing types of CI
expansions, i.e., the source of the external cluster amplitudes, that potentially yield an improved ec-CC energy.
That work servers as a blueprint for the type of wavefunction that a quantum computer would need to prepare to
potentially see an energy improvement through solving the ec-CC equations. At the core of their derivation is the
following theorem:

Theorem III.1. The solution to a truncated configuration interaction set of equations which includes full singles,
full doubles, and any set of higher excitations satisfies the coupled cluster singles and doubles equations.

600

500

CCSD
CASCI
NEVPT2

TCCSD
VQE
VQE-TCCSD

]
h
E
m

[

400

y
g
r
e
n
E

300

e
v
i
t
a
e
R

l

200

100

0

]
h
E
m

[

r
o
r
r
E

I

101

100

C
S
A
C

10 1

]
h
E
m

[

t
x
e
E

220

240

260

0.8

1.2

1.6

2.0

2.4

2.8

0.8

1.2

1.6

2.0

2.4

2.8

R [Å]

R [Å]

 
 
 
 
 
7

They prove this theorem algebraically and diagrammatically. We have reproduced the algebraic proof in Ap-
pendix A 3 for completeness. A key takeaway is that in order for the ec-CC equations to provide an improvement over
CI expansions one must only include the connected components – i.e., rank three and four cluster amplitudes with
non-zero CI-ampltiudes. Furthermore, to see improvement over CI expansions via ec-CC requires a CI expansion that
includes some but not all triple and quadruple excitations. This suggests that a quantum circuit exploring dominant
many-body excitations for a large system can be a useful input to ec-CC. Supporting this interpretation are the clas-
sical studies using FCIQMC as an external source and other methods that sample high-energy Slater determinants.77
While the connection to truncated CI should not be considered too strongly as an analogy for quantum circuits, it
does provide support for the use of particular quantum circuits that sample high-energy many-body excitations. This
new perspective serves as a different design principle when constructing quantum circuit ansatze with the potential
for beyond classical computation. The connection rules out quantum state ansatze where it is efficient to estimate
amplitudes up to additive error such as a circuit built from a fixed bond dimension MPS. No comparably generally
statements can be made about when quantum inputs can be useful for TCC or ec-CC in an active space.

IV. QUANTUM MEASUREMENT OF OVERLAPS

|

⟩

⟩

ΨT

ΨT

ΨT
|

ΨT
|

In the quantum CC methods proposed here, the input amplitudes are determined from quantum state overlaps
with the help of a quantum computer. When a Jordan-Wigner mapping of fermions to qubits is used, the Slater
determinant overlaps correspond to overlaps with computational basis states. As the non-relativistic second-quantized
molecular Hamiltonian can, without loss of generality, be chosen to be real when written in the computational basis,
the eigenstates are real, so that if a suitable state preparation method is used, all overlaps with computational basis
states should be real. However, since the signs of the overlaps enter the cluster analysis, sampling the quantum
trial state
on n qubits with ζ electrons in the computational basis is not sufficient. Various methods are
known that can be used to estimate overlaps including signs. A family of methods suitable for the task that has
received a lot of attention recently are classical shadows26 and extensions of this technique geared specifically towards
the fermionic setting.22,23,25 All these methods have in common that, given a state
, one draws unitaries U
from some ensemble of classically efficiently describable unitaries. A description of the drawn unitaries together
is recorded as a so-called classical
with the results of computational basis state measurements in the state U
shadow. From this classical shadow, one can, using purely classical computation, predict various properties of the
state
. Particularly relevant for our work is the protocol from Ref. 25 which is based on an ensemble of matchgate
⟩
circuits (Haar measure over general fermionic Gaussian unitaries), which allows to estimate all overlaps with Slater
(√n log(n)/ϵ2) quantum measurements or shots.
determinants up to additive error ϵ from shadows consisting of s
ζ/2)4/ϵ2)
The fully parallelizable classical computational effort per overlap scales as
ζ/2)3 scaling are possible, see Appendix D of Ref. 25). For this protocol, one needs to prepare
(improvements to a (n
ΨT
. If the state preparation method preserves
a superposition of a reference state (e.g., the true vacuum
⟩
|
the fermion number, this can be achieved by applying the circuit that prepares
from the Hartree-Fock state
(log(ζ)) by using
Φ0⟩
|
a single Hadamard gate and replacing the other Pauli X gates needed to prepare
by their controlled versions
(CNOT). Alternatively one can use the classical shadow protocol from Ref. 23, which randomizes only over number-
preserving (passive) Gaussian unitaries U and allows to compute all overlaps to error ϵ from shadows consisting of
2/3) shots (which is independent of n and ζ) or the Clifford shadow protocol from Ref. 27, which also
just s
has an n-independent sample complexity, however scaling with the logarithm of the number of overlaps. In the first
case, due to number preservation of the passive Gaussian unitaries, the superposition with the reference state must
be prepared on an enlarged set of up to 3n/2 qubits in the worst case of half-filling ζ = n/2. In the second case, the
classical processing of the shadow data is efficient for computational basis state overlaps required by our method (just
not for overlaps with general Slater determinants).27 In our numerical simulations, we focus on the matchgate shadow
protocol from Ref. 25, which has the worst scaling of the required number of shots among the three alternatives. This
means that the shot budgets reported here can asymptotically be thought of as upper bounds and probably be further
improved upon for finite n.

n. This state can be prepared in depth
⊗

to a state that is a superposition of

⟩
Φ0⟩
|

(√n log(n) (n

n) and
⊗

ζ/2)4) =

Φ0⟩
|

ΨT
|

(4ϵ−

(s (n

0
⟩
|

0
⟩
|

∈ O

∈ O

and

O

O

O

−

−

−

⟩

|

A. Statistical Properties of Matchgate Shadow Overlaps

We implemented the matchgate shadow protocol in order to study the statistical properties of finite shot overlap
measurements, summarized in detail in Appendix C 1. From our numerical simulations, we obtained the following
findings: 1.) The overlap estimates are approximately normal distributed, 2.)
the covariance matrix of overlap
measurements is diagonally dominant, and the covariances vanish asymptotically faster than the variances with

8

increasing s, and scatter plots (see Fig. C.1a in Appendix C 1) confirm that the overlap estimates are close to
independently distributed for large s, 3.) the spread of the variances decays faster than the mean variance, meaning
that for large s, all overlap estimates have approximately the same variance, and 4.) the numerically observed mean
variance ¯σ2 agrees well with the analytical performance guarantees from Ref. 25 (see Appendix C 1 for more details).
For the case of half-filling, ζ = n/2, we numerically found the simple relation

¯σ2 ⪅ √2n/s.

(8)

Ultimately, this allowed us to build a synthetic noise model, in which we can efficiently add Gaussian noise with
variance ¯σ2 to classically computed exact overlaps to “mimic” matchgate shadow overlap measurements without
having to classically simulate the entire shadow protocol. In the next section, we use the synthetic noise model to
estimate the number of quantum measurements s in order to reach chemical precision for sizeable systems, which
are intractable on current quantum devices. Given a finite shot shadow, one can estimate overlaps and the variance
of these estimates. This enabled us to build a classical post-processing scheme to screen out overlaps that were not
statistically significantly determined, improving the results of ec-CC in Section V.

B. Shot Noise Resilience and Quantum Resources for Tailored Coupled Cluster

(a)

(b)

(c)

FIG. 4: Fitted power law prefactors a for each molecule at fixed global exponents (a), Diagnostic values for each
molecule (b), scatter plot of the prefactor a vs. the diagnostic values including a linear fit (c).

17.5

15.0

12.5

a

10.0

7.5

5.0

2.5

0.0

p-B e n zy n e
2 (stretc h e d)
F 2 (stretc h e d)
Cl2 (stretc h e d)

N

F 2

2

N

H

Global Fit
Mean

2 O

M e-N C O
B e n ze n e
For m ald e h y d e

Cl2

Fura n

A c etald e h y d e

Molecule

1

1

0.125

0.100

0.075

0.050

l

e
u
a
V
c
i
t
s
o
n
g
a
D

i

0.025

0.000

p-B e n zy n e
2 (stretc h e d)
F 2 (stretc h e d)
Cl2 (stretc h e d)

N

F 2

2

N

H

2 O

M e-N C O
B e n ze n e
For m ald e h y d e

Cl2

Fura n

A c etald e h y d e

Molecule

 
R 2 = 0.96

R 2 = 0.75

20

15

10

a

5

0

0.000 0.025 0.050

0.05

0.10

1

1

9

The purpose of this section is to analyze the finite shot budget for matchgate shadows in order to obtain (noisy)
quantum TCCSD energies for molecular systems to a given precision. The observation that noisy overlaps extracted
from the matchgate shadow protocol are independent and identically distributed random variables with an underlying
normal distribution greatly facilitates the construction of an error model of the TCCSD energy, since we do not need
to record many finite shot shadows. Rather, one can take the exact overlaps from a classical CASCI calculation and
subsequently draw the noise of a given distribution with standard deviation or noise strength σ, and add it to the
exact overlaps. Subsequently, we compute the “noisy” TCCSD energy without having to simulate a single quantum
circuit. Ultimately, the goal is to find a heuristic model for the shot budgets, which will incorporate a) the dependence
of the error on the noise strength σ, which can be directly related to the shot budget via the variance bound published
by Wan et al.,25 and b) system/molecule-specific parameters (number of spin orbitals, active space size, etc.) making
it possible to estimate the quantum resources across a broad range of molecules of interest without having to perform
the actual sampling of the TCCSD error for that system. The details of our analysis and construction of the empirical
error model are explained in detail in Appendix C. The quantity we want to extrapolate using only pre-defined
system parameters and the noise strength is the absolute TCCSD energy error caused by noise,
. Due
to the relation with the noise strength, it will then be possible to substitute σ with the variance bound in eq (8),
, we can directly obtain a
which in turn contains the shot budget s. Thus, if we can convincingly model
, and the system-specific parameters, which we will outline in
shot budget given the desired accuracy in
the following. Most importantly, we tested the dependence of
(for a given system) on the noise strength
while keeping all other influential parameters (basis set, etc.) fixed. This analysis revealed a linear dependence of
∆Enoise
on σ, i.e., the TCCSD energy error is proportional to the underlying noise strength. The linear relationship
1), the
was observed consistently for different systems and active space sizes. Even at high noise strengths (σ = 10−
(cid:12)
TCCSD calculations converged, indicating that the procedure is robust even when tailored with almost random
(cid:12)
overlaps. With the linear dependence on σ at hand, we sought to incorporate molecule/system-specific parameters

∆Enoise

∆Enoise

∆Enoise

∆Enoise

TCCSD

TCCSD

TCCSD

TCCSD

TCCSD

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

precision in different correlation regimes, as indicated by the

FIG. 5: Extrapolation of the shot count s needed for determining the quantum TCCSD energy to milli-Hartree
T1 diagnostic. The data were generated for a system
with N = 600 orbitals and half-filled active spaces ζ = n/2. Shaded regions correspond to power laws with the

smallest and largest exponents (i.e., estimator

standard deviation, respectively).

±

into an extended extrapolation model for
. We composed a set of molecular systems, basis sets, and active
space sizes and sampled the TCCSD energy for these systems at a given noise strength, such that we could afterwards
find the system-dependent variables that explain trends in the error best. From analysis of the sampled data set, we
concluded that the total number of overlaps d that are put in to the TCCSD calculation, which directly depends on
n and ζ, i.e., the chosen active space size (see Appendix C 3), and the total number of spin orbitals of the system N
yield good results in a power law fit over the whole data set. The power law is given by

TCCSD

(cid:12)
(cid:12)

(cid:12)
(cid:12)

∆Enoise

∆Enoise

TCCSD

= a dβN γσ.

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(9)

1 0.05
1 0.015
1 < 0.015

108

106

s

104

102

101

102

n

10

The exponents of d and N in the power law seem to be largely independent of the chosen molecular system. The
0.054, shows that the error due to noisy amplitudes increases with the size of
exponent of d, given as β = 0.277
±
0.116, such that the absolute error
1.074
the active space, as expected. The exponent of N is approximately γ =
decreases when the total size of the MO space increases. This makes sense, because the active space contribution to
the total energy decreases when the relative size of the external space increases.

−

±

T1 and

The prefactor a encodes system-specific variables that were omitted by our choice of d and N as the most im-
portant general quantities. We noticed that the stronger the static correlation in the system was, the larger was
the corresponding prefactor a in a per-molecule fit with fixed exponents for β and γ. The per-molecule prefactors
are depicted in Figure 4. We found that the prefactor a across the molecule test set correlates with the well-known
D1 (see Fig. 4).28,29 These diagnostic values are typically used to quantify whether
CCSD diagnostic values,
a single-reference CCSD wavefunction is reliable, or whether one should opt for a MR treatment of the system. The
T1 to
T1 values correlate best with the molecule-specific prefactor a (Fig. 4), and we use a linear fit to convert from
a (fit parameters are shown in Appendix C 3).
The empirical error extrapolation model takes into account the following quantities; i) the noise strength σ, given
through the variance bound in eq (8), ii) the number of overlaps d, required for TCCSD, which depends on the size
of the chosen active space, iii) the total number of spin orbitals in the system N , and iv) the prefactor a of the power
law, derived from the
T1 diagnostic through a plain CCSD calculation. Of course, the empirical model is far from
general, however, it may give some guidance for the error level one can expect in a TCCSD calculation based on noisy
overlap measurements. Inserting the variance bound (eq (8)) into the power law, one can rearrange the equation for
the matchgate shadow shot budget at half-filling,

s ⪅

a2
∆Enoise

TCCSD

2 d2βN 2γ√2n.

(10)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

TCCSD

TCCSD

= 10−

∆Enoise
(cid:12)
(cid:12)
(cid:12)
(cid:12)

∆Enoise
with the other parameters obtained
The shot budget s can then be computed for a target accuracy
3 Eh as the required
from the fit and the molecule/setup-specific values. In the following, we set
“chemical precision”. Note that this shot budget is just assigned for the overlap measurements through matchgate
shadows and does not take into account the shot budget for, e.g., state preparation or optimization. Furthermore,
the Gaussian error model is herein applied to the exact overlaps from a CASCI trial wavefunction. For this reason,
the error model just covers errors in the overlap measurements but not the imperfections in the wavefunction we
have discussed in the previous section. Since the error model is independent of the underlying state, however, both
error contributions can be studied separately. We computed the values for s for a fictitious system with an MO
space of N = 600, for half-filling active spaces from n = 4 to n = 200 qubits with ζ = n/2 electrons. To cover
different correlation regimes, the shot budgets were obtained for three ranges of
0.015, and
0.05, as plotted in Figure 5. The shaded areas around the solid lines in the plot include the worst/best-case
T1 ≈
scenario, where the standard deviations of the exponents have been added/subtracted. The strongly correlated case,
0.05, corresponds to a system like N2 with a bond distance of 2.8 ˚A, i.e., an extreme case for MR character. The
T1 ≈
mixed/balanced case,
T1 is around
0.02), corresponds to a system like p-Benzyne, and the weakly correlated case to something like closed-shell organic
molecules. For the balanced case, the shot counts range from approximately 103 for 4 qubits to less than 107 for 200
qubits. The uncertainty of these numbers is given through the standard deviation of the exponent fit parameters, and
amounts to approximately one order of magnitude in each direction.

0.015, where CCSD is almost not reliable anymore (usually the threshold for

T1 < 0.015,

T1, i.e.,

T1 ≈

T1 ≈

(cid:12)
(cid:12)

C. Quantum Resource Estimates for Nitrogen Dissociation

Coming back to the test case in the previous section, we computed the total shot budgets to obtain the N2
dissociation curve with chemical precision in a noisy TCCSD setup. The shot budget per point on the dissociation
curve is given in Figure 6. While the number of overlaps and the number of spin orbitals is of course identical on
T1 increases and thus the shot budget is adjusted accordingly.
each point on the potential energy surface, the value of
Note that the shot budget grows quadratically in
T1, and the total shot budget for all 21 bond distances is dominated
by the strongly correlated regime for R > 1.7 ˚A, as expected. We note that the shot budget for obtaining the entire
dissociation curve in 0.1 ˚A increments is less than 3
107. We think it is remarkable that so few shots are sufficient to
obtain an energy estimator that includes dynamic correlation correction effects since, even when advanced methods
such as regularized compressed double factorization21 or fluid fermionic fragments103 are employed, measuring just
the bare active space VQE energy typically requires a comparable number of shots. Measurements of 2RDMs, let
alone sufficiently high quality higher-order RDMs, can be expected to require significantly more shots. Our estimate
does not include error mitigation overheads, but is a very feasible shot count on present-day quantum hardware, as is

×

11

FIG. 6: Estimated shot budget s for N2/cc-pVDZ/CAS(6,6) to achieve milli-Hartree precision in the TCCSD energy

T1, obtained from
as a function of the internuclear distance R along the dissociation curve. The value of
CCSD/cc-pVDZ, determines the increase in s, according to eq (10). The total shot budget amounts to
approximately 30 million shots. Raw data are shown in Table C.5.

testified by the fact that more shots were taken for individual echo-verified data points in Ref. 104. For a complete
comparison, a thorough investigation of the shot counts needed for PT-based methods for treating dynamic correlation
using higher-order RDMs would be desirable, but this is beyond the scope of this work. Additionally, it would be
interesting to numerically analyze quantum state preparation techniques other than VQE in the context of TCCSD
in future work.

D. Resilience to Device Noise

The combination of how overlaps are input into the split amplitude methods considered here with how they are
determined in the matchgate shadow protocol25 leads to a further noteworthy built-in error mitigation property of
the resulting method. To see this, we first need to recount how overlaps are measured from shadows. When recording
n, then one aims to prepare the state
0
the shadow one picks a reference state such as the true vacuum
⊗
|
)/√2 on the device and finally takes computational basis state measurements after random Gaussian
ρ
|
φ
rotations. From the shadow obtained in this way the sought-after overlap with a computational basis state
is then
|
⟩
computed as the expectation value of the non-Hermitian observables
ρ]. If this
φ
⟩⟨
|
state preparation is noisy so that instead of the state ρ =
p) ρ + p ρnoise
ρ
⟩ ⟨
for some error probability p and density matrix ρnoise, one has

= 2 Tr[
the device prepares the state ˜ρ = (1

, using that
φ
|

= (
|

0
|
−

ΨT
|

0
⟩
|

0
⟩

0
|

ΨT

ρ
|

⟩ ⟨

=

+

φ

⟨

⟩

⟩

⟩

⟩

|

|

2 Tr[

0
|

˜ρ] = (1
φ
|

p)

φ

ΨT

+ p

φ
⟨

ρnoise|
|

.

0
⟩

−
For several reasonable types of noise, including depolarizing noise, bit flip noise, and amplitude damping

0
⟩
will be either zero or very small for all states
from a subspace containing a reasonable number of particles
ζ. This means that overlaps such as those in eqs (3) and (4) can, because of the intermediate normalization of
ΨAS
be very well approximated by quotients of overlaps computed from the shadow of the noisy
|
state. For the overlap in eq (3), one has for example

ρnoise|
|

ΨT
|

Φ0 |

φ
⟩
|

φ
⟨

/
⟨

ΨT

⟩⟨

=

⟨

⟩

⟩

⟩

⟩

|

(11)

ca
i =

ΨAS

Φa
i |
⟨

⟩

Φa
i |
= ⟨
Φ0 |
⟨

ΨT
ΨT

⟩
⟩

≈

0
Tr[
|
0
Tr[
|

⟩⟨
⟩⟨

Φa
i |
Φ0|

˜ρ]
˜ρ]

,

(12)

p) in the enumerator and denominator cancel. Even estimation from a finite
because the common factors of 2/(1
ΨT
shot shadow should thus work well as long as (1
does not become too small (see Appendix D.6 of Ref. 27
|
for similar consideration). Contrary to this, without error mitigation techniques, expectation values such as that of,
e.g., the electronic structure Hamiltonian, are usually first order sensitive to the noise strength p.

φ
⟨

p)

−

−

⟩

A further major concern in several platforms are particle number dependent phases that can be caused, e.g., by
background magnetic fields. These are often particularly problematic for algorithms that prepare cat-like coherent
superpositions of states of markedly different particle number such as
. However, since we know that the input
⟩
overlaps are all real and we are only interested in getting the relative signs of the coefficients, which are quotients of
overlaps, correct and the computational basis state overlaps going into the enumerator all come from the same particle

ρ
|

106

s

105

104

0.04

0.03

1

0.02

0.01

0.8 1.2 1.6 2.0 2.4 2.8
R [Å]

12

number sub-space, a particle number dependent phase results in a global phase affecting all coefficients, which can
be easily corrected. One possible way of doing this is to rotate the coefficients in the complex plane such that the
largest coefficient or the principle component of all overlaps or is aligned with the real axis before either discarding the
imaginary part or taking the absolute value multiplied with the sign of the real part of each coefficient. This renders
our methods largely independent of uncontrolled particle number dependent phases and also implies some robustness
against general phase errors.

V. SPLIT-AMPLITUDE CC ON QUANTUM HARDWARE

In this section, we showcase how externally corrected CC performs on inputs obtained from actual quantum hard-
ware. For this purpose, we revisit the ground state energy of H4/STO-3G arranged in a square geometry with bond
distances of 1.23 ˚A, which was previously studied with QC-QMC in Ref. 27. Quantum overlaps were measured with
Clifford shadows on Google’s Sycamore superconducting quantum processor.105 In this hardware experiment, the
state preparation for H4/STO-3G on 8 qubits corresponds to preparing the exact FCI state. The overlaps, obtained
from a Clifford shadow protocol,22 were then used to drive a QMC calculation. Due to device and shot noise, the
measured overlaps of course do not exactly reproduce FCI overlaps, making it an interesting test case for studying
noise robustness of ec-CC. For details on how the experimental shadow data were processed, see Appendix D. The

FIG. 7: Post-processing protocol for quantum ec-CC. Overlaps measured in the classical (matchgate) shadow
protocol are first filtered based on variance, and set to zero if the overlap estimator has a too large variance. After
that, the cluster analysis is performed on the filtered overlaps, cluster amplitudes up to and including T4. Then,
purely disconnected T3 and T4 amplitudes are disconnected, yielding a so-called “Type-II” ec-CC calculation in the
end.79,80

quantum trial state prepared on the device (Q trial) first had to be converted to a wavefunction with real-valued
coefficients (Q trial real, see Appendix D) before use with ec-CC. The Q trial state was recorded four times with
different number of sampled Cliffords, NCliffords, in the original experiment, and we used the best two repetitions in
terms of root mean-square error of the reconstructed wavefunction with respect to FCI (the results are qualitatively
unchanged when all four runs are included, but the bands depicting uncertainty become unnecessarily wide). Note
that, for hardware reasons, the circuit for each group element was executed 1,000 times, yielding a so-called mulit-
shot/thrifty106,107 shadow. To complement the hardware data, we simulated a matchgate shadow (30 repetitions)
taken on the FCI wavefunction with both a single shot and 1,000 shots per group element. Furthermore, we devised a
classical post-processing protocol, illustrated in Figure 7, to ascertain certain properties of the wavefunction extracted
from the device. Therein, we filter overlaps based on their variance and set them to zero if a certain variance threshold
for the measurement is not fulfilled, i.e., the overlap was not determined reliably enough. In the given experiment,
we set overlaps to zero if the overlap value is larger than 2 σ. After that, we perform the usual cluster analysis which
then might contain purely disconnected T3 and T4 due to the variance-based thresholding, or due to the underlying
wavefunction. In the spirit of “Type-II” ec-CC input,79,80 we discard all purely disconnected T3 and T4 amplitudes
and subsequently perform the ec-CC calculation. The absolute energy error with respect to FCI as a function of the
total number of shots (i.e., number of group elements times number of circuit executions per group element) are shown

Classical Shadow

Filter overlaps
based on variance

Cluster Analysis

Discard purely
disconnected T3/T4

ec-CC Calculation

13

FIG. 8: Energy error of trial state (Q trial), Q trial converted to real wavefunction (Q trial real), ec-CC with
different shadow protocols, and QC-QMC with respect to FCI. Averages from two repetitions are shown, where the
shaded areas indicate the 95th percentile. Results based on experimental data from Ref. 27 are drawn a solid lines,
results from simulated matchgate shadows with only shot noise are drwan as dashed lines. The CCSD energy error
(7.05 mEh) and the limit for chemical precision (1 mEh) are shown for comparison. Without circuit noise, the Q
trial state would correspond to FCI. Raw data are shown in Tables D.1, D.2, and D.3.

in Figure 8, including the results for Q trial and QC-QMC from Ref. 27. For more than 106 shots, the experiment
is no more shot-noise-limited. In this limit, ec-CC and QC-QMC energy errors are less than 1 mEh, i.e., chemical
precision is reached, whereas the plain variational energy of the trial state and its purely real counterpart does not
105) the
reach the same level of accuracy. Our post-processing protocol ensures that for too few shots (up to about 2

×

FIG. 9: Number of sign errors (upper panel) and non-zero errors (lower panel) in the overlap measurements
depending on the number of Cliffords, NCliffords, in the H4/STO-3G experiment on 8 qubits, grouped by two runs of
the experiment. Non-zero errors are defined as overlap values that should be numerically zero (in the FCI vector),

but are larger than a given numerical threshold of 10−

6 in the shadow-based measurements.

results are never worse than plain CCSD. To understand this behavior, we analyzed the type of errors that can occur
in overlap measurements, namely sign errors and non-zero errors. The latter refer to an overlap value which should

100

10 1

]
h
E
[

10 2

r
o
r
r
E

y
g
r
e
n
E

10 3

10 4

Method
Q trial
Q trial real
ec-CC (multi Clifford)
ec-CC (multi Matchgate)
ec-CC (single Matchgate)
QC-QMC (multi Clifford)
Type
Experiment
Simulation

CCSD

chem. prec.

104

105

106

107

Total Number of Shots

 
 
8

6

4

2

s
r
o
r
r
E

i

n
g
S
#

0

s
r
o
r
r
E

o
r
e
Z
-
n
o
N
#

12
10
8
6
4
2
0

1 0

1 6

2 8

4 7

8 0

1 3 6

Experiment

1
2

1 1 0 0
6 5 2
3 8 7
2 2 9
NCliffords

1 8 5 6

3 1 2 9

5 2 7 6

1 5 0 0 0
8 8 9 6

 
 
 
 
14

be numerically zero (in this case, the corresponding value in the CI vector is zero), but is measured to be non-zero.
The sign and non-zero errors for the two experimental runs of the H4/STO-3G experiment are summarized in Figure
9. Sign errors completely vanish at NCliffords = 387, which perfectly coincides with the points on the energy error
curve where improvements over CCSD are observed. The non-zero errors do not decay as rapidly as the sign errors,
and some elements are still measured with a non-zero value for rather large number of sampled group elements. Thus,
sign errors seem to be most severe and affecting the quality of the input overlaps for ec-CC, but those errors quickly
disappear completely when the total number of shots is moderate, i.e., chemical precision is only reached for even
more shots.

Making the wavefunction real removes ambiguities because of the non-measurable global phase and is a necessity
because coupled cluster with a real molecular Hamiltonian requires real amplitude inputs. In addition, it seems to
improve the quality of the trial wavefunction energy. ec-CC on the experimental data does not seem to quite reach
the accuracy of QC-QMC, but gets close and drastically improves over the (real) Q trial energy by a factor of 5 and
25, respectively, as well as about a factor of 10 over the plain CCSD energy. It is reassuring that ec-CC is competitive
with QC-QMC in this setting since we are certain that, due to the wavefunction quality, ec-CC must improve over the
plain trial state energy. The comparison with the simulated matchgate shadow data shows that, with both shadow
protocols, chemical precision can be reached with a comparable number of group elements and shots. The 1,000
shots multi-shot variant only needs roughly 10 times more shots at 100 fewer distinct circuits, making it attractive
on hardware where changing the circuit incurs a run time overhead. We attribute the generally better performance
on simulated data to the absence of gate and detection noise.

FIG. 10: Error in total energy as a function of the lattice constant of a minimal cell diamond (DZVP-GTH basis
with 26 orbitals). The quantum trial state is prepared on an active space of 16 qubits using a perfect-pairing
wavefunction, as explained in detail in Ref. 27. Raw data are shown in Table D.4. The plot is split up in two panels
with different vertical axis limits to show the whole range of energy errors. The gray area in the lower panel
indicates the bounds for chemical precision of 1 kcal/mol. Data for Q trial, AFQMC, and QC-QMC are reproduced
from Ref. 27. The “/” notation in the plot legend indicates the input wavefunction for the respective method, i.e.,
‘Q trial‘ from the device or a classically simulated exact CAS(8,8). Note that for the lattice constant of 3.24 ˚A, the
results for (real) Q trial are not visible on the depicted energy scale. For high values of the lattice constant, only
TCCSD based on CAS(8,8) and NEVPT2 achieve chemical precision, however, all quantum split-amplitude methods
run on the hardware data significantly improve the energy of the prepared trial state.

As a second example run on actual hardware, we study the energy of a minimal diamond unit cell (two carbon
atoms) in a double-zeta basis (GTH-DZVP;108 26 orbitals, with GTH-PADE109 pseudopotential, only Γ point in
Brillouin zone sampling) as a function of the lattice constant.
In Ref. 27, the quantum trial corresponded to a
16-qubit active space perfect-pairing (PP) wavefunction, and the computational basis state overlaps were obtained

350

300

250

200

150

100

50
15

15

10

5

0

5

]
l
o
m

/
l
a
c
k
[

y
g
r
e
n
E

l

a
t
o
T

n

i

r
o
r
r
E

2.8

3.2

3.6
Lattice Constant [Å]

4.0

4.4

Q trial
Q trial real
ec-CC / Q trial
TCCSD / Q trial
QC-QMC / Q trial
CAS(8,8)
ec-CC / CAS
NEVPT2
TCCSD / CAS
CCSD(T)
AFQMC

 
 
 
 
15

using the Clifford shadow protocol, sampling 50,000 group elements for each lattice constant.
In addition to the
methods used in Ref. 27, we computed the single-point energy for each lattice constant using ec-CC and TCCSD on
the real-valued quantum trial state, CAS(8,8) (i.e., the exact solution to the given active space problem), ec-CC and
TCCSD on the exact CAS state, and NEVPT2 for comparison. The results are shown in Figure 10. In comparison
with the H4 hardware experiment, two factors limit the performance guarantees of ec-CC: 1) the fact that we are
dealing with an active space wavefunction, such that we do not have any convergence guarantees to the true FCI result
in the limit of exact external T3 and T4 amplitudes, and 2) the quantum trial PP state is a CC-like wavefunction,
which does not accurately treat higher-order excitations as would be beneficial for ec-CC. The results for quantum
ec-CC on the quantum trial state never reach chemical precision, and the error is between approximately 5 and 15
kcal/mol. This is comparable with the results from plain AFQMC. Even when the exact CAS(8,8) wavefunction is
used to construct the T3 and T4 amplitudes, the energy error only marginally improves over the quantum input one.
This strongly hints that the “truncation” of T3 and T4 stemming from an active space is of course preventing more
accurate ec-CC results. The performance of quantum TCCSD tailored with the quantum trial state is even worse,
since the energy error is larger than 15 kcal/mol for all values of the lattice constant. Still, for both split-amplitude
methods executed with actual quantum trial states, the energy error is vastly better than the variational energy of
the quantum trial state (for the value at 3.24 ˚A, it is literally off the charts). Interestingly, the energy error of a plain
CAS(8,8), due to neglect of dynamic correlation effects, is worse than that of the quantum split-amplitude methods.
The only methods in our setup that reach chemical precision for all values of the lattice constant are TCCSD tailored
with CAS(8,8) and NEVPT2. The energy error observed for those two methods is almost identical. TCCSD thus
provides vastly better results when tailored with the exact active space wavefunction than with the PP quantum
trial state. This is expected, since the CC-like PP wavefunction cannot yield a better result in this case than plain
CCSD on the full orbital space. Even though there are no strict theoretical requirements for input wavefunctions to
TCCSD, this is a case which is expected to fail based on the properties of the quantum trial. The fact that ec-CC
uses a post-processing protocol for the input amplitudes could explain why it performs better than TCCSD on actual
hardware data. From the perspective of classical electronic structure methods, the performance of TCCSD with CAS
is on par with NEVPT2, which is encouraging. We conclude that ec-CC of course was not expected to work well,
or even better than QC-QMC, in the active space and PP quantum input setting, which was corroborated by our
numerical results. Nonetheless, the split-amplitude methods provide a massive improvement in absolute energy error
even when seeded with noisy quantum input.

VI. CONCLUSIONS

In this work we proposed to use overlaps obtained from a quantum computer by means of classical shadows as inputs
to split-amplitude CC methods tailored coupled cluster (TCC) and externally corrected coupled cluster (ec-CC). The
resulting combinations of methods can be seen as a way of adding dynamic electron correlation corrections onto active
space trial states prepared on a quantum computer. These methods can further be viewed as a way of curing failures
of plain single-reference coupled cluster theory (such as the appearance of virtual reaction barriers) by taking into
account properties of a multi-reference wavefunction prepared on a quantum computer, while avoiding the dramatic
increase in classical computational complexity of classical multi-reference coupled cluster methods. We showed that
the combination of methods displays a range of desirable properties: 1) The dynamic correlation correction along
the N2 dissociation curve and for a stretched diamond cell is found to be comparable in quality to NEVPT2 and
remarkably robust against systematic imperfections in the prepared active space wavefunction, as may arise from too
shallow VQE circuits. 2) One can predict the number of repetitions (shots) required to obtain accurate results from
established correlation diagnostics that are classically efficiently obtainable from CCSD calculations. 3) Extrapolating
these resource estimates to the classically no longer exactly solvable regime, we found remarkably low shot counts,
which we attribute to the fact that measurement of expensive intermediates such as higher-order reduced density
matrices is avoided. 4) When tested with overlaps measured on real quantum hardware, our method provided results
with an accuracy comparable to QC-QMC for the ground state energy of H4 in a minimal basis. 5) The expensive
classical part of the computation can be performed with standard coupled cluster codes, opening the possibility for
further speedups with, e.g., DLPNO. 6) In particular ec-CC (and to a lesser degree TCC) seems to have some built-in
error mitigation abilities, producing energies that can be as good as CASCI or AFQMC, respectively, even from very
noisy trial state amplitudes. We analyzed the statistical properties of overlaps computed from matchgate shadows25
and numerically corroborated the validity of a Gaussian noise model that may be of general interest. Furthermore,
the quantum split-amplitude methods are fully agnostic of the measurement scheme. Hence, the quantum resource
estimates provided in our present work can most likely be improved upon using shadow protocols with lower sample
complexity. It would thus be interesting to see if similar noise models hold for other classical shadow protocols. In
particular, the particle-number-preserving shadow protocol from Ref. 23 promises to make the required number of

16

shots to obtain overlaps at a given precision independent of the number of qubits at the expense of an overhead in
circuit depth and number of qubits. It will be important to explore these trade-offs further. Another possible direction
is to combine the methods proposed here with shadow-based error mitigation methods.110–112 While the shot counts
we find for the quantum split-amplitude CC methods seem very low, even when comparing to typical shot counts
needed to just compute the energy of bare electronic structure Hamiltonians on quantum wavefunctions, a detailed
analysis of the shot counts needed to obtain similar quality energies via perturbative methods such as NEVPT2 from
higher-order RDMs measured either from shadows or directly remains outstanding. For ec-CC, we were able to give
some hints for what kind of wavefunctions could yield a quantum advantage and hope that this can inspire future
work on VQE ans¨atze and other state preparation schemes. Finally, it would be interesting to extend TCCSD with T3
amplitudes from the active space as suggested in the original TCC work,2 and to compute other molecular properties
with split-amplitude methods.

We acknowledge fruitful discussions with William J. Huggins, Eugene DePrince III, Fotios Gkritsis, Robert M. Par-

rish, and Pauline J. Ollitrault.

ACKNOWLEDGEMENTS

[1] S. McArdle, S. Endo, A. Aspuru-Guzik, S. C. Benjamin, and X. Yuan, Quantum computational chemistry, Reviews of

Modern Physics 92, 015003 (2020).

[2] T. Kinoshita, O. Hino, and R. J. Bartlett, Coupled-cluster method tailored by configuration interaction, The Journal of

chemical physics 123, 074106 (2005).

[3] J. Paldus, Externally and internally corrected coupled cluster approaches: an overview, Journal of Mathematical Chem-

istry 55, 477 (2017).

[4] T. Takeshita, N. C. Rubin, Z. Jiang, E. Lee, R. Babbush, and J. R. McClean, Increasing the representation accuracy of
quantum simulations of chemistry without extra quantum resources, Physical Review X 10, 10.1103/physrevx.10.011004
(2020).

[5] A. Peruzzo, J. McClean, P. Shadbolt, M.-H. Yung, X.-Q. Zhou, P. J. Love, A. Aspuru-Guzik, and J. L. O’Brien, A
variational eigenvalue solver on a photonic quantum processor, Nature Communications 5, 10.1038/ncomms5213 (2014).
[6] J. R. McClean, J. Romero, R. Babbush, and A. Aspuru-Guzik, The theory of variational hybrid quantum-classical

algorithms, New Journal of Physics 18, 023023 (2016).

[7] A. Tammaro, D. E. Galli, J. E. Rice, and M. Motta, N-electron valence perturbation theory with reference wave functions
from quantum computing: Application to the relative stability of hydroxide anion and hydroxyl radical, The Journal of
Physical Chemistry A 127, 817–827 (2023).

[8] U. Baek, D. Hait, J. Shee, O. Leimkuhler, W. J. Huggins, T. F. Stetina, M. Head-Gordon, and K. B. Whaley, Say no to

optimization: A nonorthogonal quantum eigensolver, PRX Quantum 4, 030307 (2023).

[9] M. Krompiec and D. M. Ramo, Strongly contracted n-electron valence state perturbation theory using reduced density

matrices from a quantum computer, arXiv preprint arXiv:2210.05702 (2022).

[10] Y. Kawashima, E. Lloyd, M. P. Coons, Y. Nam, S. Matsuura, A. J. Garza, S. Johri, L. Huntington, V. Senicourt,
A. O. Maksymov, et al., Optimizing electronic structure simulations on a trapped-ion quantum computer using problem
decomposition, Communications Physics 4, 245 (2021).

[11] M. Rossmannek, P. K. Barkoutsos, P. J. Ollitrault, and I. Tavernelli, Quantum hf/dft-embedding algorithms for
electronic structure calculations: Scaling up to complex molecular systems, The Journal of Chemical Physics 154,
doi.org/10.1063/5.0029536 (2021).

[12] W. Li, Z. Huang, C. Cao, Y. Huang, Z. Shuai, X. Sun, J. Sun, X. Yuan, and D. Lv, Toward practical quantum embedding

simulation of realistic chemical systems on near-term quantum computers, Chemical science 13, 8953 (2022).

[13] Y. Liu, O. R. Meitei, Z. E. Chin, A. Dutt, M. Tao, I. L. Chuang, and T. Van Voorhis, Bootstrap embedding on a quantum

computer, Journal of Chemical Theory and Computation 19, 2230–2247 (2023).

[14] N. He and F. A. Evangelista, A zeroth-order active-space frozen-orbital embedding scheme for multireference calculations,

The Journal of Chemical Physics 152, 10.1063/1.5142481 (2020).

[15] N. He, C. Li, and F. A. Evangelista, Second-order active-space embedding theory, Journal of Chemical Theory and

Computation 18, 1527 (2022).

[16] F. A. Evangelista, Perspective: Multireference coupled cluster theories of dynamical electron correlation, Journal of

Chemical Physics 149, 10.1063/1.5039496 (2018).

[17] R. Huang, C. Li, and F. A. Evangelista, Leveraging small-scale quantum computers with unitarily downfolded hamilto-

nians, PRX Quantum 4, 020313 (2023).

[18] W. J. Huggins, J. R. McClean, N. C. Rubin, Z. Jiang, N. Wiebe, K. B. Whaley, and R. Babbush, Efficient and noise resilient
measurements for quantum chemistry on near-term quantum computers, npj Quantum Information 7, 10.1038/s41534-
020-00341-7 (2021).

17

[19] J. Cohn, M. Motta, and R. M. Parrish, Quantum Filter Diagonalization with Compressed Double-Factorized Hamiltonians,

PRX Quantum 2, 040352 (2021).

[20] S. Choi, I. Loaiza, and A. F. Izmaylov, Fluid fermionic fragments for optimizing quantum measurements of electronic

Hamiltonians in the variational quantum eigensolver, Quantum 7, 889 (2023).

[21] O. Oumarou, M. Scheurer, R. M. Parrish, E. G. Hohenstein, and C. Gogolin, Accelerating quantum computations of

chemistry through regularized compressed double factorization, arXiv preprint arXiv:2212.07957 (2022).

[22] A. Zhao, N. C. Rubin, and A. Miyake, Fermionic Partial Tomography via Classical Shadows, Physical Review Letters

127, 110504 (2021), publisher: American Physical Society.

[23] G. H. Low, Classical shadows of fermions with particle number symmetry (2022), arXiv:2208.08964 [quant-ph].
[24] X. Bonet-Monroig, R. Babbush, and T. E. O’Brien, Nearly optimal measurement scheduling for partial tomography of

quantum states, Phys. Rev. X 10, 031064 (2020).

[25] K. Wan, W. J. Huggins, J. Lee, and R. Babbush, Matchgate shadows for fermionic quantum simulation, Communications

in Mathematical Physics 404, 629–700 (2023).

[26] H.-Y. Huang, R. Kueng, and J. Preskill, Predicting many properties of a quantum system from very few measurements,

Nature Physics 16, 1050 (2020).

[27] W. J. Huggins, B. A. O’Gorman, N. C. Rubin, D. R. Reichman, R. Babbush, and J. Lee, Unbiasing fermionic quantum
Monte Carlo with a quantum computer, Nature 603, 416 (2022), number: 7901 Publisher: Nature Publishing Group.
[28] T. J. Lee and P. R. Taylor, A diagnostic for determining the quality of single-reference electron correlation methods,

International Journal of Quantum Chemistry 36, 199 (1989).

[29] C. L. Janssen and I. M. Nielsen, New diagnostics for coupled-cluster and møller–plesset perturbation theory, Chemical

Physics Letters 290, 423 (1998).

[30] J. ˇC´ıˇzek, On the correlation problem in atomic and molecular systems. calculation of wavefunction components in ursell-

type expansion using quantum-field theoretical methods, The Journal of Chemical Physics 45, 4256 (1966).

[31] T. D. Crawford and H. F. Schaefer, An introduction to coupled cluster theory for computational chemists, Reviews in

Computational Chemistry 14, 33 (2006).

[32] I. Shavitt and R. J. Bartlett, Many-body methods in chemistry and physics: MBPT and coupled-cluster theory (Cambridge

University Press, 2009).

[33] G. D. Purvis III and R. J. Bartlett, A full coupled-cluster singles and doubles model: The inclusion of disconnected

triples, The Journal of Chemical Physics 76, 1910 (1982).

[34] K. Raghavachari, G. W. Trucks, J. A. Pople, and M. Head-Gordon, A fifth-order perturbation comparison of electron

correlation theories, Chemical Physics Letters 157, 479 (1989).

[35] R. J. Bartlett, How and why coupled-cluster theory became the pre-eminent method in an ab into quantum chemistry,

in Theory and Applications of Computational Chemistry (Elsevier, 2005) pp. 1191–1221.

[36] Y. Guo, C. Riplinger, U. Becker, D. G. Liakos, Y. Minenkov, L. Cavallo, and F. Neese, Communication: An improved
linear scaling perturbative triples correction for the domain based local pair-natural orbital based singles and doubles
coupled cluster method [DLPNO-CCSD(T)], The Journal of chemical physics 148, 10.1063/1.5011798 (2018).

[37] C. D. Sherrill and H. F. Schaefer III, The configuration interaction method: Advances in highly correlated approaches,

in Advances in Quantum Chemistry, Vol. 34 (Elsevier, 1999) pp. 143–269.

[38] D. G. Liakos, Y. Guo, and F. Neese, Comprehensive benchmark results for the domain based local pair natural orbital
coupled cluster method (dlpno-ccsd(t)) for closed- and open-shell systems, Journal of Physical Chemistry A 124, 90
(2020).

[39] M. M¨orchen, L. Freitag, and M. Reiher, Tailored coupled cluster theory in varying correlation regimes, The Journal of

Chemical Physics 153, 244113 (2020).

[40] N. Oliphant and L. Adamowicz, Multireference coupled cluster method for electronic structure of molecules, International

Reviews in Physical Chemistry 12, 339 (1993).

[41] P. J. Knowles and N. C. Handy, A new determinant-based full configuration interaction method, Chemical Physics Letters

111, 315 (1984).

[42] J. Olsen, B. O. Roos, P. Jo/rgensen, and H. J. A. Jensen, Determinant based configuration interaction algorithms for

complete and restricted configuration interaction spaces, The Journal of chemical physics 89, 2185 (1988).

[43] P. J. Knowles and N. C. Handy, A determinant based full configuration interaction program, Computer physics commu-

nications 54, 75 (1989).

[44] S. Zarrabian, C. Sarma, and J. Paldus, Vectorizable approach to molecular ci problems using determinantal basis, Chemical

physics letters 155, 183 (1989).

[45] G. L. Bendazzoli and S. Evangelisti, A vector and parallel full configuration interaction algorithm, The Journal of chemical

physics 98, 3141 (1993).

[46] C. J. Stein, V. von Burg, and M. Reiher, The delicate balance of static and dynamic electron correlation, Journal of

Chemical Theory and Computation 12, 3764–3773 (2016).

[47] R. J. Harrison, Approximating full configuration interaction with selected configuration interaction and perturbation

theory, The Journal of chemical physics 94, 5021 (1991).

[48] A. A. Holmes, N. M. Tubman, and C. Umrigar, Heat-bath configuration interaction: An efficient selected configuration
interaction algorithm inspired by heat-bath sampling, Journal of chemical theory and computation 12, 3674 (2016).
[49] S. Sharma, A. A. Holmes, G. Jeanmairet, A. Alavi, and C. J. Umrigar, Semistochastic heat-bath configuration interaction
method: Selected configuration interaction with semistochastic perturbation theory, Journal of chemical theory and
computation 13, 1595 (2017).

18

[50] J. B. Schriber and F. A. Evangelista, Communication: An adaptive configuration interaction approach for strongly

correlated electrons with tunable accuracy, The Journal of chemical physics 144, 10.1063/1.4948308 (2016).

[51] N. M. Tubman, C. D. Freeman, D. S. Levine, D. Hait, M. Head-Gordon, and K. B. Whaley, Modern approaches to exact
diagonalization and selected configuration interaction with the adaptive sampling CI method, Journal of chemical theory
and computation 16, 2139 (2020).

[52] H. Zhai, H. R. Larsson, S. Lee, Z.-H. Cui, T. Zhu, C. Sun, L. Peng, R. Peng, K. Liao, J. T¨olle, J. Yang, S. Li, and
G. K.-L. Chan, Block2: a comprehensive open source framework to develop and apply state-of-the-art dmrg algorithms
in electronic structure and beyond (2023), arXiv:2310.03920 [physics.chem-ph].

[53] C. Angeli, R. Cimiraglia, S. Evangelisti, T. Leininger, and J. P. Malrieu, Introduction of n-electron valence states for

multireference perturbation theory, The Journal of Chemical Physics 114, 10252 (2001).

[54] C. Angeli, R. Cimiraglia, and J. P. Malrieu, N-electron valence state perturbation theory: a fast implementation of the

strongly contracted variant, Chemical Physics Letters 350, 297 (2001).

[55] C. Angeli, R. Cimiraglia, and J. P. Malrieu, N-electron valence state perturbation theory: A spinless formulation and
an efficient implementation of the strongly contracted and of the partially contracted variants, The Journal of Chemical
Physics 117, 9138 (2002).

[56] P. Pulay, A perspective on the CASPT2 method, International Journal of Quantum Chemistry 111, 3273 (2011).
[57] S. Battaglia, I. F. Galv´a n, and R. Lindh, Multiconfigurational quantum chemistry: The CASPT2 method, in Theoretical

and Computational Photochemistry (Elsevier, 2023) pp. 135–162.

[58] J. Paldus, J. ˇC´ıˇzek, and M. Takahashi, Approximate account of the connected quadruply excited clusters in the coupled-

pair many-electron theory, Physical Review A 30, 2193 (1984).

[59] J. Paldus and J. Planelles, Valence bond corrected single reference coupled cluster approach:

I. general formalism,

Theoretica chimica acta 89, 13 (1994).

[60] J. Planelles, J. Paldus, and X. Li, Valence bond corrected single reference coupled cluster approach: II. application to

ppp model systems, Theoretica chimica acta 89, 33 (1994).

[61] J. Planelles, J. Paldus, and X. Li, Valence bond corrected single reference coupled cluster approach: III. simple model of

bond breaking or formation, Theoretica chimica acta 89, 59 (1994).

[62] X. Li and J. Paldus, Reduced multireference CCSD method: An effective approach to quasidegenerate states, The Journal

of chemical physics 107, 6257 (1997).

[63] H. J. Monkhorst, Calculation of properties with the coupled-cluster method, International Journal of Quantum Chemistry

12, 421 (1977).

[64] S. Lehtola, N. M. Tubman, K. B. Whaley, and M. Head-Gordon, Cluster decomposition of full configuration interaction
wave functions: A tool for chemical interpretation of systems with strong correlation, The Journal of chemical physics
147, 10.1063/1.4996044 (2017).

[65] O. Hino, T. Kinoshita, G. K. L. Chan, and R. J. Bartlett, Tailored coupled cluster singles and doubles method applied
to calculations on molecular structure and harmonic vibrational frequencies of ozone, Journal of Chemical Physics 124,
10.1063/1.2180775/186884 (2006).

[66] L. Veis, A. Antal´ık, J. Brabec, F. Neese, ¨Ors Legeza, and J. Pittner, Coupled cluster method with single and double
excitations tailored by matrix product state wave functions, Journal of Physical Chemistry Letters 7, 4072 (2016).
[67] A. Leszczyk, M. M´at´e, ¨Ors Legeza, and K. Boguslawski, Assessing the accuracy of tailored coupled cluster methods
corrected by electronic wave functions of polynomial cost, Journal of Chemical Theory and Computation 18, 96 (2022).
[68] M. Ravi, A. Perera, Y. C. Park, and R. J. Bartlett, Excited states with pair coupled cluster doubles tailored coupled

cluster theory, The Journal of Chemical Physics 159, 10.1063/5.0161368 (2023).

[69] D. I. Lyakh, V. F. Lotrich, and R. J. Bartlett, The ‘tailored’ CCSD(T) description of the automerization of cyclobutadiene,

Chemical Physics Letters 501, 166 (2011).

[70] A. Antal´ık, L. Veis, J. Brabec, O. Demel, ¨O. Legeza, and J. Pittner, Toward the efficient local tailored coupled cluster
approximation and the peculiar case of oxo-Mn (Salen), The Journal of Chemical Physics 151, 10.1063/1.5110477 (2019).
[71] A. Antal´ık, D. Nachtigallov´a, R. Lo, M. Matouˇsek, J. Lang, ¨Ors Legeza, J. Pittner, P. Hobza, and L. Veis, Ground state
of the fe(ii)-porphyrin model system corresponds to quintet: a dft and dmrg-based tailored cc study, Physical Chemistry
Chemical Physics 22, 17033 (2020).

[72] J. Lang, A. Antal´ık, L. Veis, J. Brandejs, J. Brabec, O. Legeza, and J. Pittner, Near-linear scaling in dmrg-based tailored
coupled clusters: an implementation of DLPNO-TCCSD and DLPNO-TCCSD(T), Journal of Chemical Theory and
Computation 16, 3028 (2020).

[73] F. M. Faulstich, A. Laestadius, ¨Ors Legeza, R. Schneider, and S. Kvaal, Analysis of the tailored coupled-cluster method

in quantum chemistry, SIAM Journal on Numerical Analysis 57, 2579 (2019).

[74] F. M. Faulstich, M. M´at´e, A. Laestadius, M. A. Csirik, L. Veis, A. Antalik, J. Brabec, R. Schneider, J. Pittner, S. Kvaal,
and ¨Ors Legeza, Numerical and theoretical aspects of the dmrg-tcc method exemplified by the nitrogen dimer, Journal
of Chemical Theory and Computation 15, 2206 (2019).

[75] A. Melnichuk and R. J. Bartlett, Relaxed active space: Fixing tailored-CC with high order coupled cluster. i, The Journal

of chemical physics 137, 10.1063/1.4767900 (2012).

[76] O. Demel, J. Brandejs, J. Lang, J. Brabec, L. Veis, O. Legeza, and J. Pittner, Hilbert space multireference coupled

clusters tailored by matrix product states, arXiv preprint arXiv:2304.01625 (2023).

[77] J. E. Deustua, I. Magoulas, J. Shen, and P. Piecuch, Communication: Approaching exact quantum chemistry by cluster
analysis of full configuration interaction quantum monte carlo wave functions, The Journal of Chemical Physics 149,

19

151101 (2018).

[78] J. E. Deustua, J. Shen, and P. Piecuch, Converging high-level coupled-cluster energetics by monte carlo sampling and

moment expansions, Phys. Rev. Lett. 119, 223003 (2017).

[79] I. Magoulas, K. Gururangan, P. Piecuch, J. E. Deustua, and J. Shen, Is externally corrected coupled cluster always better
than the underlying truncated configuration interaction?, Journal of Chemical Theory and Computation 17, 4006 (2021).
[80] S. Lee, H. Zhai, S. Sharma, C. J. Umrigar, and G. K.-L. Chan, Externally corrected ccsd with renormalized perturbative
triples (R-ecCCSD(T)) and the density matrix renormalization group and selected configuration interaction external
sources, Journal of Chemical Theory and Computation 17, 3414 (2021).

[81] G. J. Aroeira, M. M. Davis, J. M. Turney, and H. F. Schaefer III, Coupled cluster externally corrected by adaptive

configuration interaction, Journal of chemical theory and computation 17, 182 (2020).

[82] G.-L. R. Anselmetti, D. Wierichs, C. Gogolin, and R. M. Parrish, Local, expressive, quantum-number-preserving vqe

ans¨atze for fermionic systems, New Journal of Physics 23, 113010 (2021).

[83] T. H. Dunning, Gaussian basis sets for use in correlated molecular calculations. i. the atoms boron through neon and

hydrogen, J. Chem. Phys. 90, 1007 (1989).

[84] B. T. Gard, L. Zhu, G. S. Barron, N. J. Mayhall, S. E. Economou, and E. Barnes, Efficient symmetry-preserving state
preparation circuits for the variational quantum eigensolver algorithm, npj Quantum Information 6, 10.1038/s41534-019-
0240-1 (2020).

[85] H. R. Grimsley, S. E. Economou, E. Barnes, and N. J. Mayhall, An adaptive variational algorithm for exact molecular

simulations on a quantum computer, Nature Communications 10, 10.1038/s41467-019-10988-2 (2019).

[86] H. L. Tang, V. Shkolnikov, G. S. Barron, H. R. Grimsley, N. J. Mayhall, E. Barnes, and S. E. Economou, Qubit-adapt-
vqe: An adaptive algorithm for constructing hardware-efficient ans¨atze on a quantum processor, PRX Quantum 2, 020310
(2021).

[87] N. H. Stair and F. A. Evangelista, Simulating many-body systems with a projective quantum eigensolver, PRX Quantum

2, 030301 (2021).

[88] J. Lee, W. J. Huggins, M. Head-Gordon, and K. B. Whaley, Generalized unitary coupled cluster wave functions for

quantum computation, Journal of Chemical Theory and Computation 15, 311–324 (2018).

[89] B. O’Gorman, W. J. Huggins, E. G. Rieffel, and K. B. Whaley, Generalized swap networks for near-term quantum

computing, arXiv preprint arXiv:1905.05118 (2019).

[90] Y. Matsuzawa and Y. Kurashige, Jastrow-type decomposition in quantum chemistry for low-depth quantum circuits,

Journal of Chemical Theory and Computation 16, 944–952 (2020).

[91] M. Motta, C. Sun, A. T. K. Tan, M. J. O’Rourke, E. Ye, A. J. Minnich, F. G. S. L. Brand˜ao, and G. K.-L. Chan,
Determining eigenstates and thermal states on a quantum computer using quantum imaginary time evolution, Nature
Physics 16, 205–210 (2019).

[92] I. H. Kim and B. Swingle, Robust entanglement renormalization on a noisy quantum computer, arXiv preprint

arXiv:1711.07500 (2017).

[93] T. J. Sewell and S. P. Jordan, Preparing renormalization group fixed points on nisq hardware, arXiv preprint

arXiv:2109.09787 (2021).

[94] C. Pineda, T. Barthel, and J. Eisert, Unitary circuits for strongly correlated fermions, Phys. Rev. A 81, 050303 (2010).
[95] Q. Miao and T. Barthel, Quantum-classical eigensolver using multiscale entanglement renormalization, Physical Review

Research 5, 10.1103/physrevresearch.5.033141 (2023).

[96] L. Lin and Y. Tong, Near-optimal ground state preparation, Quantum 4, 372 (2020).
[97] D. Malz, G. Styliaris, Z.-Y. Wei, and J. I. Cirac, Preparation of matrix product states with log-depth quantum circuits,

arXiv preprint arXiv:2307.01696 (2023).

[98] Y. Ge, J. Tura, and J. I. Cirac, Faster ground state preparation and high-precision ground energy estimation with fewer

qubits, Journal of Mathematical Physics 60 (2019).

[99] S. Lu, M. C. Ba˜nuls, and J. I. Cirac, Algorithms for quantum simulation at finite energies, PRX Quantum 2, 020321

(2021).

[100] M.-Q. He, D.-B. Zhang, and Z. D. Wang, Quantum gaussian filter for exploring ground-state properties, Physical Review

A 106, 10.1103/physreva.106.032420 (2022).

[101] O. Kyriienko, Quantum inverse iteration algorithm for programmable quantum simulators, npj Quantum Information 6,

10.1038/s41534-019-0239-7 (2020).

[102] S. Fomichev, K. Hejazi, M. S. Zini, M. Kiser, J. F. Morales, P. A. M. Casares, A. Delgado, J. Huh, A.-C. Voigt, J. E.
Mueller, et al., Initial state preparation for quantum chemistry on quantum computers, arXiv preprint arXiv:2310.18410
(2023).

[103] S. Choi, I. Loaiza, and A. F. Izmaylov, Fluid fermionic fragments for optimizing quantum measurements of electronic

hamiltonians in the variational quantum eigensolver, Quantum 7, 889 (2023).

[104] T. E. O’Brien, G. Anselmetti, F. Gkritsis, V. E. Elfving, S. Polla, W. J. Huggins, O. Oumarou, K. Kechedzhi, D. Abanin,
R. Acharya, I. Aleiner, R. Allen, T. I. Andersen, K. Anderson, M. Ansmann, F. Arute, K. Arya, A. Asfaw, J. Atalaya, J. C.
Bardin, A. Bengtsson, G. Bortoli, A. Bourassa, J. Bovaird, L. Brill, M. Broughton, B. Buckley, D. A. Buell, T. Burger,
B. Burkett, N. Bushnell, J. Campero, Z. Chen, B. Chiaro, D. Chik, J. Cogan, R. Collins, P. Conner, W. Courtney, A. L.
Crook, B. Curtin, D. M. Debroy, S. Demura, I. Drozdov, A. Dunsworth, C. Erickson, L. Faoro, E. Farhi, R. Fatemi,
V. S. Ferreira, L. Flores Burgos, E. Forati, A. G. Fowler, B. Foxen, W. Giang, C. Gidney, D. Gilboa, M. Giustina,
R. Gosula, A. Grajales Dau, J. A. Gross, S. Habegger, M. C. Hamilton, M. Hansen, M. P. Harrigan, S. D. Harrington,
P. Heu, M. R. Hoffmann, S. Hong, T. Huang, A. Huff, L. B. Ioffe, S. V. Isakov, J. Iveland, E. Jeffrey, Z. Jiang, C. Jones,

20

P. Juhas, D. Kafri, T. Khattar, M. Khezri, M. Kieferov´a, S. Kim, P. V. Klimov, A. R. Klots, A. N. Korotkov, F. Kostritsa,
J. M. Kreikebaum, D. Landhuis, P. Laptev, K.-M. Lau, L. Laws, J. Lee, K. Lee, B. J. Lester, A. T. Lill, W. Liu, W. P.
Livingston, A. Locharla, F. D. Malone, S. Mandr`a, O. Martin, S. Martin, J. R. McClean, T. McCourt, M. McEwen,
X. Mi, A. Mieszala, K. C. Miao, M. Mohseni, S. Montazeri, A. Morvan, R. Movassagh, W. Mruczkiewicz, O. Naaman,
M. Neeley, C. Neill, A. Nersisyan, M. Newman, J. H. Ng, A. Nguyen, M. Nguyen, M. Y. Niu, S. Omonije, A. Opremcak,
A. Petukhov, R. Potter, L. P. Pryadko, C. Quintana, C. Rocque, P. Roushan, N. Saei, D. Sank, K. Sankaragomathi, K. J.
Satzinger, H. F. Schurkus, C. Schuster, M. J. Shearn, A. Shorter, N. Shutty, V. Shvarts, J. Skruzny, W. C. Smith, R. D.
Somma, G. Sterling, D. Strain, M. Szalay, D. Thor, A. Torres, G. Vidal, B. Villalonga, C. Vollgraff Heidweiller, T. White,
B. W. K. Woo, C. Xing, Z. J. Yao, P. Yeh, J. Yoo, G. Young, A. Zalcman, Y. Zhang, N. Zhu, N. Zobrist, D. Bacon,
S. Boixo, Y. Chen, J. Hilton, J. Kelly, E. Lucero, A. Megrant, H. Neven, V. Smelyanskiy, C. Gogolin, R. Babbush,
and N. C. Rubin, Purification-based quantum error mitigation of pair-correlated electron simulations, Nature Physics
10.1038/s41567-023-02240-y (2023).

[105] F. Arute, K. Arya, R. Babbush, D. Bacon, J. C. Bardin, R. Barends, R. Biswas, S. Boixo, F. G. Brandao, D. A. Buell,

et al., Quantum supremacy using a programmable superconducting processor, Nature 574, 505 (2019).

[106] J. Helsen and M. Walter, Thrifty shadow estimation:

re-using quantum circuits and bounding tails (2022),

arXiv:2212.06240 [quant-ph].

[107] Y. Zhou and Q. Liu, Performance analysis of multi-shot shadow estimation, Quantum 7, 1044 (2023).
[108] J. VandeVondele and J. Hutter, Gaussian basis sets for accurate calculations on molecular systems in gas and condensed

phases, The Journal of chemical physics 127, 10.1063/1.2770708 (2007).

[109] S. Goedecker, M. Teter, and J. Hutter, Separable dual-space gaussian pseudopotentials, Physical Review B 54, 1703

(1996).

[110] H. Jnane, J. Steinberg, Z. Cai, H. C. Nguyen, and B. Koczor, Quantum error mitigated classical shadows (2023),

arXiv:2305.04956 [quant-ph].

[111] H. H. S. Chan, R. Meister, M. L. Goh, and B. Koczor, Algorithmic shadow spectroscopy (2023), arXiv:2212.11036 [quant-

ph].

[112] R. Brieger, M. Heinrich, I. Roth, and M. Kliesch, Stability of classical shadows under gate-dependent noise (2023),

arXiv:2310.19947 [quant-ph].

[113] N. C. Rubin and A. E. DePrince, p†q: a tool for prototyping many-body methods for quantum chemistry, Molecular

Physics 119, 10.1080/00268976.2021.1954709 (2021).

[114] Q. Sun, X. Zhang, S. Banerjee, P. Bao, M. Barbry, N. S. Blunt, N. A. Bogdanov, G. H. Booth, J. Chen, Z.-H. Cui, J. J.
Eriksen, Y. Gao, S. Guo, J. Hermann, M. R. Hermes, K. Koh, P. Koval, S. Lehtola, Z. Li, J. Liu, N. Mardirossian, J. D.
McClain, M. Motta, B. Mussard, H. Q. Pham, A. Pulkin, W. Purwanto, P. J. Robinson, E. Ronca, E. R. Sayfutyarova,
M. Scheurer, H. F. Schurkus, J. E. T. Smith, C. Sun, S.-N. Sun, S. Upadhyay, L. K. Wagner, X. Wang, A. White, J. D.
Whitfield, M. J. Williamson, S. Wouters, J. Yang, J. M. Yu, T. Zhu, T. C. Berkelbach, S. Sharma, A. Y. Sokolov, and
G. K.-L. Chan, Recent developments in the PySCF program package, The Journal of Chemical Physics 153, 024109
(2020).

[115] J. Bradbury, R. Frostig, P. Hawkins, M. J. Johnson, C. Leary, D. Maclaurin, G. Necula, A. Paszke, J. VanderPlas,

S. Wanderman-Milne, and Q. Zhang, JAX: composable transformations of Python+NumPy programs (2018).

[116] N. C. Rubin, K. Gunst, A. White, L. Freitag, K. Throssell, G. K.-L. Chan, R. Babbush, and T. Shiozaki, The fermionic

quantum emulator, Quantum 5, 568 (2021).

[117] V. Bergholm, J. Izaac, M. Schuld, C. Gogolin, S. Ahmed, V. Ajith, M. S. Alam, G. Alonso-Linaje, B. AkashNarayanan,
A. Asadi, J. M. Arrazola, U. Azad, S. Banning, C. Blank, T. R. Bromley, B. A. Cordier, J. Ceroni, A. Delgado, O. Di Mat-
teo, A. Dusko, T. Garg, D. Guala, A. Hayes, R. Hill, A. Ijaz, T. Isacsson, D. Ittah, S. Jahangiri, P. Jain, E. Jiang,
A. Khandelwal, K. Kottmann, R. A. Lang, C. Lee, T. Loke, A. Lowe, K. McKiernan, J. J. Meyer, J. A. Monta˜nez-
Barrera, R. Moyard, Z. Niu, L. J. O’Riordan, S. Oud, A. Panigrahi, C.-Y. Park, D. Polatajko, N. Quesada, C. Roberts,
N. S´a, I. Schoch, B. Shi, S. Shu, S. Sim, A. Singh, I. Strandberg, J. Soni, A. Sz´ava, S. Thabet, R. A. Vargas-Hern´andez,
T. Vincent, N. Vitucci, M. Weber, D. Wierichs, R. Wiersema, M. Willmann, V. Wong, S. Zhang, and N. Killoran,
Pennylane: Automatic differentiation of hybrid quantum-classical computations (2018).

[118] C. R. Harris, K. J. Millman, S. J. van der Walt, R. Gommers, P. Virtanen, D. Cournapeau, E. Wieser, J. Taylor,
S. Berg, N. J. Smith, R. Kern, M. Picus, S. Hoyer, M. H. van Kerkwijk, M. Brett, A. Haldane, J. F. del R´ıo, M. Wiebe,
P. Peterson, P. G´erard-Marchant, K. Sheppard, T. Reddy, W. Weckesser, H. Abbasi, C. Gohlke, and T. E. Oliphant,
Array programming with numpy, Nature 585, 357 (2020).

[119] P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy, D. Cournapeau, E. Burovski, P. Peterson,
W. Weckesser, J. Bright, S. J. van der Walt, M. Brett, J. Wilson, K. J. Millman, N. Mayorov, A. R. J. Nelson, E. Jones,
R. Kern, E. Larson, C. J. Carey, ˙I. Polat, Y. Feng, E. W. Moore, J. VanderPlas, D. Laxalde, J. Perktold, R. Cimrman,
I. Henriksen, E. A. Quintero, C. R. Harris, A. M. Archibald, A. H. Ribeiro, F. Pedregosa, P. van Mulbregt, and SciPy 1.0
Contributors, SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python, Nature Methods 17, 261 (2020).

[120] T. pandas development team, pandas-dev/pandas: Pandas (2020).
[121] Wes McKinney, Data Structures for Statistical Computing in Python, in Proceedings of the 9th Python in Science Con-

ference, edited by St´efan van der Walt and Jarrod Millman (2010) pp. 56 – 61.

[122] J. D. Hunter, Matplotlib: A 2d graphics environment, Computing in Science & Engineering 9, 90 (2007).
[123] M. L. Waskom, seaborn: statistical data visualization, Journal of Open Source Software 6, 3021 (2021).
[124] A. Meurer, C. P. Smith, M. Paprocki, O. ˇCert´ık, S. B. Kirpichev, M. Rocklin, A. Kumar, S. Ivanov, J. K. Moore,
S. Singh, T. Rathnayake, S. Vig, B. E. Granger, R. P. Muller, F. Bonazzi, H. Gupta, S. Vats, F. Johansson, F. Pedregosa,

21

M. J. Curry, A. R. Terrel, v. Rouˇcka, A. Saboo, I. Fernando, S. Kulal, R. Cimrman, and A. Scopatz, Sympy: symbolic
computing in python, PeerJ Computer Science 3, e103 (2017).

[125] M. Wimmer, Efficient numerical computation of the pfaffian for dense and banded skew-symmetric matrices, ACM

Transactions on Mathematical Software 38, 10.1145/2331130.2331138 (2011).

[126] W. J. Hehre, R. F. Stewart, and J. A. Pople, Self-consistent molecular-orbital methods. i. use of gaussian expansions of

slater-type atomic orbitals, J. Chem. Phys. 51, 2657 (1969).

[127] W. J. Hehre, R. Ditchfield, R. F. Stewart, and J. A. Pople, Self-consistent molecular orbital methods. iv. use of gaussian

expansions of slater-type orbitals. extension to second-row molecules, J. Chem. Phys. 52, 2769 (1970).

[128] R. Ditchfield, W. J. Hehre, and J. A. Pople, Self-consistent molecular-orbital methods. ix. an extended gaussian-type

basis for molecular-orbital studies of organic molecules, J. Chem. Phys. 54, 724 (1971).

[129] M. M. Francl, W. J. Pietro, W. J. Hehre, J. S. Binkley, M. S. Gordon, D. J. DeFrees, and J. A. Pople, Self-consistent
molecular orbital methods. xxiii. a polarization-type basis set for second-row elements, J. Chem. Phys. 77, 3654 (1982).
[130] M. S. Gordon, J. S. Binkley, J. A. Pople, W. J. Pietro, and W. J. Hehre, Self-consistent molecular-orbital methods. 22.

small split-valence basis sets for second-row elements, J. Am. Chem. Soc. 104, 2797 (1982).

[131] W. J. Hehre, R. Ditchfield, and J. A. Pople, Self-consistent molecular orbital methods. xii. further extensions of gaussian-

type basis sets for use in molecular orbital studies of organic molecules, J. Chem. Phys. 56, 2257 (1972).

[132] R. A. Kendall, T. H. Dunning, and R. J. Harrison, Electron affinities of the first-row atoms revisited. systematic basis

sets and wave functions, J. Chem. Phys. 96, 6796 (1992).

[133] D. E. Woon and T. H. Dunning, Gaussian basis sets for use in correlated molecular calculations. iii. the atoms aluminum

through argon, J. Chem. Phys. 98, 1358 (1993).

[134] F. Malone, Data for Unbiasing fermionic quantum Monte Carlo with a quantum computer, 10.5281/zenodo.10141262

(2023).

Appendix A: Theoretical Background of Coupled Cluster Methods

The single reference coupled cluster (SRCC) wavefunction is constructed through an exponential ansatz acting on

22

the Hartree-Fock (or Fermi vacuum) reference determinant

ΨCC⟩
with the cluster operator ˆT . The cluster operator is formed by linear combination of individual operators

= e

|

,

,31,32

Φ0⟩
|
ˆT
Φ0⟩
|

ˆT =

ˆTν

(A1)

(A2)

ν
(cid:88)
with excitation level ν. Truncating this expression at a certain excitation level νmax yields the well-known hierarchy of
truncated CC methods: CC singles (CCS, νmax = 1), CC singles and doubles (CCSD, νmax = 2), CC singles, doubles,
and triples (CCSDT, νmax = 3), and so on. The excitation operators are generally defined as

ˆTν =

1
(ν!)2

abc...
(cid:88)
ijk...

tabc...
ijk... ˆa†aˆa†bˆa†c . . . ˆaiˆaj ˆak . . . ,

(A3)

with the Tν amplitudes tabc...
ijk... for a given excitation level ν and the fermionic creation and annihilation operators ˆa†p
and ˆap, respectively. The indices a, b, c, . . . denote virtual orbital indices, i, j, k, . . . refer to occupied orbitals in
,
Φ0⟩
|
and p, q, r, s, . . . refer to general spin orbitals. The T amplitudes are solved for by projecting excited determinant
manifolds

onto the similarity-transformed Hamiltonian ¯H

ˆT ˆHe ˆT ,

Φν

|

⟩

¯H
|
where rν is referred to as residual vector. The resulting non-linear amplitude equations can be solved iteratively. Note
that, due to the similarity transformation required for obtaining computationally tractable amplitude equations, the
from the left, one obtains the SRCC energy as
resulting Hamiltonian is no longer Hermitian. By projecting with

Φ0⟩

(A4)

≡ ⟨

Φν

rν

|

e−

≡
!= 0,

Φ0⟩
|

ECC =

¯H

⟨

Φ0|
=EHF +

Φ0⟩

|

i ta
f a

i +

ia
(cid:88)

i tb
ta
j⟨

ij

ab
⟩

||

+

1
4

1
2

ijab
(cid:88)

ijab
(cid:88)

tab
ij ⟨

ij

,
ab
⟩

||

(A5)

with the reference Hartree-Fock energy EHF, the Fock matrix elements f q
p , and the antisymmetrized two-electron
repulsion integrals in Physicists’ notation
. Note that only T1 and T2 amplitudes enter the SRCC energy
expression directly, independent of the truncation level, since the higher excitation cluster operators cannot produce
fully contracted terms with the Hamiltonian. The implicit energy contribution of higher-order T amplitudes originates
from the coupling of all amplitudes through the projection equations. For CCSD, the amplitude equations require
projections of the singly and doubly excited determinants, i.e.,

rs
⟩

pq

||

⟨

¯H
Φ0⟩
,
|
¯H
Φ0⟩
|
In the following sections, we use the normal-ordered Hamiltonian,

Φa
i |
⟨
Φab
ij |
⟨

0 =

0 =

.

to express the Baker-Campbell-Hausdorff (BCH) expansion of ¯H more conveniently as

ˆHN = ˆH

ˆH
Φ0|

,

Φ0⟩

|

− ⟨

¯H

→

( ˆHN ˆT )c,

(A6)

(A7)

(A8)

(A9)

where the (. . .)c denotes that only the connected contributions from the expansion survive.31 With the programmable
expressions for the projection equations at hand, which can for example be derived through code generation (see
Appendix B),113 the amplitudes are solved iteratively through standard numerical techniques.31

1. Tailored Coupled Cluster

23

The tailored coupled cluster (TCC) ansatz aims to encode static correlation effects from an active space (AS)

method in a SRCC wavefunction through a split-amplitude ansatz2

ˆT = ˆT ext + ˆT AS.

(A10)

The amplitudes in the active space cluster operator ˆT AS are extracted from an exact or approximate active space
wavefunction through the relationship of the linear configuration interaction (CI) ansatz and the exponential CC
ansatz

The CI excitation operators ˆCν are defined as the cluster operator in eq (A3), but with cabc...
ijk... as corresponding am-
plitudes. Conversion from CI to CC amplitudes is achieved by matching excitation levels and recursively determining
the amplitudes,63,64 here up to four-fold excitations, as

1 +

ˆCν = e

ˆT .

ν
(cid:88)

(A11)

ˆT1 = ˆC1
ˆT2 = ˆC2 −
ˆT3 = ˆC3 −
ˆT4 = ˆC4 −

1
2
1
2
1
2

ˆT 2
1

ˆT1 ˆT2 + ˆT2 ˆT1

(cid:16)

ˆT1 ˆT3 + ˆT3 ˆT1

(cid:17)

(cid:16)

(cid:17)

ˆT 3
1

1
3!
1
ˆT 2
2 −
2

−

−

1
4!

ˆT 4
1 .

Evaluating these terms as Wick contractions yields the following programmable expressions,64

i = ca
ta
i
tab
ij = cab
ij −
ijk = cabc
tabc
ijk −
+ tc
jtab
ik −
jtb
i tc
+ ta

i ta
j + tb
i tb
ta
j
i tac
jk + tb
i tbc
ta
ta
ktbc
ij + tb
j tc
i ta
k + tb

tabcd
ijkl = . . .

i tab
tc
j tbc
jtac
tb
jk + ta
jk −
ik −
ik
ktac
tc
ktab
ta
i tb
jtc
ij −
ij −
k
i tb
k + tc
j tb
i ta
tc
jta
i tc
tb

jta
k

k −

k −

(A12)

(A13)

(A14)

(A15)

(A16)

(A17)

(A18)

(A19)

The expressions contain single “non-redundant” outer products of T amplitudes, e.g., ta
jk, and the terms with
permuted indices ensure the correct anti-symmetry of the resulting amplitude, cancelling exactly the corresponding
prefactor from the Taylor expansion. If the coefficient of the reference determinant in the underlying CI expansion is
not equal to one, one has to renormalize the above conversion equations accordingly. As all CC methods, TCC is only
applicable if the coefficient of the reference determinant extracted from the active space method is non-zero. With a
set of CI amplitudes at hand, the corresponding spin-orbital T amplitudes can be built with the expressions above,
yielding an active space cluster operator ˆT AS. The orbital indices of the cluster amplitudes are fully contained in the
AS. Contrary to that, the external cluster amplitudes belonging to ˆT ext comprise
active space, i.e., ijk . . . abc . . .
an orbital space where at least one orbital index is not part of the active space, i.e., ijk . . . abc . . .
AS. Now, the
TCC energy functional is given by

i tbc

̸⊂

∈

Since the external and active space cluster operators commute by construction, one can obtain the active space energy
through the CC energy functional via

(cid:68)

(cid:16)

(cid:12)
(cid:12)
(cid:12)

c

(cid:17)

(cid:12)
(cid:12)
(cid:12)

(cid:69)

ETCC =

Φ0

ˆHN e

ˆT ext+ ˆT AS

Φ0

.

(A20)

ETCC =

Φ0

ˆHN e

ˆTAS

(cid:68)

(cid:12)
= EAS + Eext.
(cid:12)
(cid:12)

(cid:16)

Φ0

+

Φ0

ˆHN e

ˆText

(cid:69)

(cid:68)

(cid:16)

(cid:12)
(cid:12)
(cid:12)

Φ0

(cid:69)

c

(cid:17)

(cid:12)
(cid:12)
(cid:12)

c

(cid:17)

(cid:12)
(cid:12)
(cid:12)

(A21)

(A22)

The relationship holds due to the equivalence of the CI and CC expansions for exact wavefunctions, i.e., the T1 and
T2 amplitudes extracted from the active space wavefunction are exact and can be viewed as optimized in presence of

all higher-order T amplitudes through the active space method. For approximate active space methods, the mapping
is not exact, and the resulting energy computed through the CC energy functional is not necessarily equivalent to
the (variational) energy of the active space wavefunction.1 To retain the static correlation information in the TCC
wavefunction, the active space amplitudes are kept frozen during optimization of the external amplitudes. That is,
the following amplitude equations are to be solved in TCCSD, the most popular flavor of TCC:

24

ˆHN e( ˆT AS

1 + ˆT AS

2

)e( ˆT ext

1 + ˆT ext

2

)

(cid:16)

ˆHN e( ˆT AS

1 + ˆT AS

2

)e( ˆT ext

1 + ˆT ext

2

0 =

0 =

Φa
i
(cid:12)
(cid:68)
Φab
(cid:12)
ij
(cid:12)
(cid:68)

(cid:16)

(cid:12)
(cid:12)
(cid:12)

Φ0

,

i, a

AS

̸⊂

i, j, a, b

AS.

̸⊂

c
(cid:17)
)

(cid:12)
(cid:12)
(cid:12)
c

(cid:17)

(cid:12)
(cid:12)
(cid:12)

(cid:69)
Φ0

,

(cid:69)

(A23)

(A24)

Note that the “output” amplitudes are external, however, the active space amplitudes still appear in the algebraic
expressions of the projection equations. Thus, the frozen active space T amplitudes impact the TCC solution through
the active space energy, i.e., the energy evaluated directly from the frozen amplitudes, and additionally through
the contractions with the external amplitudes. Once the active space T amplitudes are known and mapped to the
corresponding orbitals in the full molecular orbital space, the standard SRCC framework is used to solve for the
external amplitudes, with the only constraint that a certain stride of the full space amplitudes be frozen. In practice,
this can be easily achieved by setting the stride of active space amplitudes in the CC residual vector to zero. As for
standard CCSD, a perturbative triples correction, i.e., CCSD(T) can be employed,69 which is only evaluated from the
external amplitudes for consistency.

2. Externally Corrected Coupled Cluster

Externally corrected CC (ec-CC)3 builds a similar split-amplitude ansatz as TCC, but aims to encode static corre-
lation into the SRCC wavefunction through higher-order cluster operators. Inspecting the un-truncated expressions
for the singles and doubles residual equations, it is clear that only ˆT3 and ˆT4 can contribute to achieve the correct
total excitation level, i.e.,

ˆHN ˆT3

Φa
i
(cid:68)

ra
i ←
(cid:12)
ˆHN ˆT3 + ˆT4 + ˆT1 ˆT3
(cid:12)
(cid:12)

(cid:16)

(cid:17)

c

c

Φ0

(cid:69)

Φ0

,

.

(A25)

(A26)

rab
ij ←

Φab
ij
(cid:68)

(cid:16)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:17)

(cid:69)

These expressions then, of course, correspond to the CCSDTQ residual equations for T1 and T2, however, higher-order
cluster operators cannot produce any further contributions to these terms. Hence, the traditional CCSD approach
corresponds to the approximate case where ˆT3 = 0 and ˆT4 = 0. This means that, adding the direct contributions of
T3 and T4 amplitudes (e.g., extracted from a high-quality correlated multi-reference wavefunction) to the T1 and T2
projection equations, one can in principle obtain an improved treatment of the overall electron correlation, including
non-dynamic correlation effects, compared to CCSD. The gist here is that convergence to full CI is guaranteed if
the input T3 and T4 amplitudes become exact. Thus, the ec-CC procedure optimizes the T1 and T2 amplitudes in
presence of (approximate) T3 and T4. The resulting ec-CC cluster operator is given by

where the T3 and T4 amplitudes are extracted from some input wavefunction. If the wavefunction only covers a
subset of the molecular orbitals, i.e., in case of an active space method, the operator is modified to project the sliced
T3 and T4 amplitudes onto the full orbital space, like in TCC, that is

ˆT = ˆT1 + ˆT2 + ˆT input

3

+ ˆT input
4

,

(A27)

ˆT = ˆT1 + ˆT2 + ˆP3 ˆT AS

3 + ˆP4 ˆT AS

4

,

(A28)

with the appropriate projection operators ˆP3 and ˆP4. For ec-CC, the same recursion relations to extract T amplitudes
from a CI-like wavefunction apply, see eqs (A12) through (A15). If an active space wavefunction is used as input, the
convergence guarantee toward FCI does not hold anymore, however, improvements can still be achieved by including
the dominant T3 and T4 amplitudes from the multi-reference treatment compared to completely neglecting the triples
and quadruples. The structure of the ec-CC ansatz directly implies that, depending on the quality of the underlying
input wavefunction, the ec-CC result might not always provide better results than the input wavefunction itself.79
We reproduce the corresponding proof in the following Section A 3.

1 The energies are equivalent though if singles and doubles are treated fully variationally in the approximate active space wavefunction.

3. Type-I ec-CC with Configuration Interaction

25

This section largely follows the arguments laid out in Ref. 79 with proofs abbreviated for conciseness. The ec-CC
singles and doubles equations with T3 and T4 generated from any coupled-cluster theory involving anything beyond
doubles would return an identical coupled-cluster energy. Naturally, one would get a different energy if T1 and T2
from the T3 and T4 source calculation are not treated fully. It turns out that truncated configuration interaction can
be shown to satisfy the ec-CC T1 and T2 equations.

To see this we will convert the set of singles and doubles truncated CI correlation energy equations into a form
equivalent to the coupled-cluster singles and doubles equations. Thus satisfying the truncated CI equations for singles
and doubles corresponds to solving the ec-CC equations singles and doubles equations. This implies that the energy
would be equivalent.

Theorem A.1. The solution to a truncated configuration interaction set of equations which includes full singles, full
doubles, and any set of higher excitations satisfies the coupled-cluster singles and doubles equations.

Proof. First, consider a truncated CI wavefunction expansion represented in intermediate normalization

=

Ψ
|

⟩

1 + ˆC1 + ˆC2 + ˆC B
(cid:16)

(cid:17)

Φ0⟩
|

(A29)

where ˆC1 is the full set of one-body excitations and their coefficients, ˆC2 is the full set of two-body excitations and
their variational coefficients, ˆC B is any higher excitations and their variational coefficients, and
is the reference
determinant. We note that the set ˆC B does not need to be complete. For example, only subsets of triples or quadruples
could be considered in ˆC B. The coupled equations for the CI correlation energy for singles and doubles are

Φ0⟩
|

Φa
i |
⟨
Φab
ij |
⟨

ˆHN

ˆHN

1 + ˆC1 + ˆC2 + ˆC B

(cid:16)

1 + ˆC1 + ˆC2 + ˆC B

(cid:16)
, and

Φ0⟩
|
Φ0⟩
|

= Ecorr ⟨
= Ecorr ⟨

(cid:17)

(cid:17)

,

ˆC1|
Φa
i |
ˆC2|
Φab
ij |

Φ0⟩
Φ0⟩

.

(A30)

(A31)

are the singly and doubly excited determinants, respec-

where Ecorr =
tively. Noting that the connected components of the wavefunction are given by

Φ0|
⟨

Φ0⟩
|

and

|

ˆHN

ˆC1 + ˆC2

Φab
ij ⟩
|

Φa
i ⟩

(cid:16)

(cid:17)

which is evaluated using the Mercator series and is a specific case of the more general cluster analysis equation
T = ln(1 + C) can be used to write the CI equations in exponential ansatz form

ˆT = ln(1 + ˆC1 + ˆC2 + ˆC B)

(A32)

Φa
e
i |
⟨
ˆT e−
Φab
e
ij |
⟨

ˆT e−

ˆT
ˆT ˆHN e

ˆT
ˆT ˆHN e

Φ0⟩
|
=
Φ0⟩
|

=

Φa
e
i |
⟨
Φab
e
ij |

ˆT

⟨

ˆT

ˆHN e

ˆT

(cid:16)
ˆT
ˆHN e

(cid:16)

(cid:17)

Φ0⟩
c |
Φ0⟩

(cid:17)
c |

= Ecorr⟨
= Ecorr⟨

ˆC1|
Φa
i |
ˆC2|
Φab
ij |

Φ0⟩
,
.
Φ0⟩

Now introducing projectors on to each relevant subspace of Hilbert space

(A33)

(A34)

P =

˜C †1 + ˜C2|
Φ0|
where Q is defined as the orthogonal compliment to P + P ˜C1, ˜C2
operators of ˆC without the variational coefficients. Inserting the resolution of identity we get

= ˜C1|

, P ˜C1, ˜C2

Φ0⟩⟨

Φ0⟩⟨

Φ0|

|

|

P + P ˜C1, ˜C2
˜C †2 P ˜CB = ˜C B

+ P ˜CB + Q = 1
˜C †B
Φ0⟩⟨
Φ0⟩⟨
+ P ˜CB and the tilde on the C indicates the excitation

(A36)

(A35)

Φ0|

Φ0|

Φa
e
i |
⟨
ˆT P

(cid:16)
HN eT

ˆT P ˜CB
(cid:0)

(cid:1)
ˆHN e

(cid:16)

Φa
e
i |
⟨
Φa
e
i |

⟨

ˆT

P + P ˜C1, ˜C2

+ P ˜CB + Q

ˆHN e

ˆT

Φ

⟩

c |
ˆT

c |

(cid:17)

+

Φa
i |
⟨
+
Φ0⟩
Φa
e
i |
⟨

(cid:17) (cid:16)
eT P ˜C1, ˜C2
ˆT Q

Φa
i |
⟨
ˆT P ˜C1, ˜C2

e

(cid:17)
ˆT

ˆHN e

(cid:16)
ˆHN e

ˆT

ˆHN e

ˆT

(cid:16)

(cid:16)

(cid:17)

(cid:17)

Φ0⟩
= Ecorr⟨
c |
+
Φ0⟩
c |
(cid:17)
Φ0⟩
c |
Φ0⟩
c |

= Ecorr⟨
= 0

ˆC1|
Φa
i |

ˆC1|
Φa
i |

Φ0⟩

Φ0⟩

(A37)

(A38)

(A39)

where the first term on the left-hand-side of Eq. (A38) cancels the right-hand-side and the last two terms on the left-
hand-side are zero because the cluster operator only excites from a given determinant. Following the same protocol
we obtain a similar expression for the doubles equation which is

26

Φab
ij |
⟨

e

ˆT P ˜C1, ˜C2

ˆT
ˆHN e

(cid:16)

(cid:17)

= 0.

Φ0⟩

(A40)

c |

Expanding the projector in Eq. (A39) and noting that the C1 operator only excites from a determinant we obtain the
singles coupled-cluster equation
= 0. Expanding the doubles equation in the projectors and the

ˆHN e ˆT

Φa
i |
⟨
exponential operator one obtains the doubles coupled-cluster equation

Φ0⟩

c |

(cid:17)

(cid:16)

ˆHN e ˆT

= 0.

Φ0⟩

■

c |

Φab
ij |

⟨

It should be re-emphasized that the full singles and doubles are required for this proof. If a subset of the singles are
used then the last term on the left-hand-side of Eq. (A39) cannot necessarily be concluded to be zero. The same can
be said for the analogous term in the doubles derivation. As is concluded in Ref. 79, the way to break the truncated
CI coupled-cluster energy symmetry is to modify the cluster equations to remove disconnected components of T3 and
T4.

(cid:16)

(cid:17)

4. Computational Scaling and Simplification of ec-CC

The ec-CC ansatz borrows only the T1 and T2 residual equations from CCSDTQ, i.e., the expensive T3 and T4
residual equations are not required. In addition, the CI expansion of the input wavefunction needs to be converted
to the corresponding T amplitudes, requiring outer products of T amplitudes that produce up to eight-index output
(N 8), but the prefactor is quite large in that case because all non-redundant anti-symmetric
tensors. This scales as
permutations need to be computed through transpositions of each unique outer product. However, the conversion
only occurs once per calculation and is thus not repeatedly evaluated. The most expensive contraction for ec-CC
occurs in the T2 residual equation as the product of T4 amplitudes and the electron-repulsion intergrals,

O

rab
ij ←

klcd
(cid:88)

tcdab
ijlk ⟨

lk

.
cd
⟩

||

(A41)

(N 8) contraction is executed only once and can
Since T4 is purely dictated by the input wavefunction method, this
be stored for the rest of the ec-CC computation. Another contribution to the T2 amplitude equation comes from
products of T1 and T3. To improve performance, some works on ec-CC report that this term can be pre-computed
using T1 from the input wavefunction, thereby neglecting an iterative update of the T1/T3 contribution to the
residual equations. This approximation seems to have only a minor influence on the quality of the result.3,81 Our
ec-CC implementation features “frozen” and iterative computation of the T1/T3 products for better debugging in the
context of quantum input.

O

Appendix B: Implementation and Computational Methodology

All classical electronic structure calculations (CASCI, CCSD, NEVPT2, etc.) were run using PySCF.114 Used
basis sets and other parameters are specified in the main text. Tailored and externally corrected coupled cluster
methods were implemented in a standalone Python library, using PySCF as input for reference states, e.g., molecular
integrals, and classical CASCI calculations. The cluster analysis working equations and CCSDTQ working equations
for ec-CC were generated using p†q.113 For improved performance, the tensor contractions are evaluated using JAX.115
Correctness of our cluster analysis code was verified using the ClusterDec library.64 For input from quantum hardware,
our code supports FQE wavefunctions as external source.116 The overlaps in case of PySCF’s CASCI or FQE input
are obtained by a simple look-up in the sparse state/CI vector, addressing determinants with the correct excitation
level and then converting them from true-vacuum sign convention to Fermi vacuum sign convention.64 VQE and
matchgate shadow simulations were performed using Covestro’s in-house quantum computing software stack based on
PennyLane.117 Data analysis was performed using NumPy,118 SciPy,119 Pandas,120,121 Matplotlib,122 and Seaborn.123

Appendix C: Split-Amplitude CC with Noisy Quantum Inputs

In this section we investigate how the shot noise due to finite sampling influences the errors of energies obtained
with the quantum TCCSD method. We do this in two steps: First, by means of explicit simulation of the matchgate

27

shadow protocol, we investigate how the errors of estimated overlaps depend on the number of shots and number
of orbitals. By doing this we numerically obtain concrete formulas characterizing the performance of the matchgate
shadow based overlap estimation method that complement the mathematically proven performance guarantees derived
in Ref. 25. In particular we find that the estimated overlaps are essentially normal distributed. In a second step we
use this knowledge to investigate the behavior of the TCCSD and ec-CC energy when Gaussian noise is added to
exact (obtained with CASCI) or approximate (obtained from a simulated VQE) overlaps.

We find that our conclusions are largely independent of the precise molecular system and state used in the compu-
tations. The data presented in the following was obtained using restricted Hartree Fock (RHF)/cc-pVDZ83 orbitals
of the N2 molecule at a bond distance of 1.09 ˚A. In addition to the chemically reasonable (6, 6) active space we have
performed simulations for other spin-zero active spaces characterized by n and ζ. For all simulations of matchgate
shadows the PennyLane library117 was used to prepare approximate CASCI ground states on 8 qubits by means
of the quantum number preserving fabrics82 with 22 layers (optimized without noise under L-BFGS-B with Π the
identity gate starting from initialization method B with a small amount of normal distributed noise added to the
initial parameters). Overlap computation was done following the protocol from Ref. 25, using Newton’s polynomial
interpolation for interpolating the Pfaffian polynomial, which was done with NumPy,118 Sympy,124 and Pfapack.125

(a)

(b)

4)!) = 70 computational
FIG. C.1: Panel (a) shows the covariance matrix of the overlaps between all d = 8!/(4!(8
basis states from the half-filling subspace of n = 8 qubits bootstrapped with k = 1000 sub-shadows with s = 2000
shots each drawn randomly from a shadow of 200 000 shots. Panel (b) shows on the diagonal for the 4 largest
overlaps a histogram of the distribution of the k values computed from each of the sub-shadows from which the
covariance matrix was computed. In the scatter plots in the off diagonal positions the blue dots are the overlaps
between pairs of basis states for each sub-shadow, the orange diamonds are the mean over the k sub-shadows, and
the green crosses are the analytically computed overlaps.

−

1. Statistical Properties of Overlaps Estimated from Finite Shot Matchgate Shadows

In this section we analyze the statistical properties of overlaps estimated from finite shot matchgate shadows. We
determine variances and covariances between the estimated overlaps via bootstrapping and analyze their distributions.
We first generate a shadow of 200, 000 shots (individually evaluated circuits measured following an i.i.d. Gaussian
unitary) and then randomly draw k sub-shadows, each of size s, estimate all overlaps for each sub-shadow and then
compute the covariance matrix of these estimates. For simplicity we omit the median of means estimation and work
with standard arithmetic means throughout. We find solid evidence that the overlaps with different computational
basis states are approximately uncorrelated and normal distributed (Figure C.1). The covariance matrix is diagonally
dominated with no visible structure at all in the off-diagonal entries, and the the scatter plots display no correlation.
As s and k grow, the bootstrapped variances increasingly concentrate around their mean and bootstrapped covariances

e
t
a
t
s

s
i
s
a
b

.
p
m
o
c

f
o

x
e
d
n

I

0
3
6
9
12
15
18
21
24
27
30
33
36
39
42
45
48
51
54
57
60
63
66
69

0 3 6 9

2
1

5
1

8
1

1
2

4
2

7
2

0
3

3
3

6
3

9
3

2
4

5
4

8
4

1
5

4
5

7
5

0
6

3
6

6
6

9
6

Index of comp. basis state

0.00200

0.00175

0.00150

0.00125

0.00100

0.00075

0.00050

0.00025

0.00000

 
 
 
 
0.2

0.1

0.0

1
0
1
0
0
1
0
1

1
0
0
1
1
0
0
1

0
1
1
0
0
1
1
0

0
0
0
0
1
1
1
1

0.2

0.1

0.0

0.1

0.2

0.1

0.0

0.1

1.1

1.0

0.9

0.8

Type

Shadow
Mean
Analytic

0.0

0.2

0.0

0.2

0.0

0.2

0.8

1.0

10100101

10011001

01100110

11110000

28

(a)

(b)

FIG. C.2: Panel (a) shows the mean of the estimated variances and the mean of the absolute values of the
covariances of all basis state overlaps as a function of the number k of shadows with each s = 2000 shots that were
used in the bootstrapping. Figure C.1a shows the estimated covariance matrix at k = 1000 where the variances are
well converged and covariances are about one order of magnitude smaller. Them decaying further with k, suggests
that the actual covariances are zero and the residual values are an artifact of the finite k used in their estimation.
Panel (b) shows the variances and the variance of their distribution (“variance of variances”) as a function of s and
the bound from Ref. 25.

decrease faster than the variances (Figure C.1a).

From eq (43) in Ref. 25 one obtains the bound σ2

4 b(n, ζ)/s, where the factor of 4 is due to the additional factor
of 2 added to step 4.1.ii of Algorithm 1 in the third arXiv version, which accounts for the fact that (in the notation
of Ref. 25)
/2 and b(ζ, n) is a bound on the variance of the left hand side. We instead find
⟩
numerically that the mean variance ¯σ2 (decaying as 1/s, as expected) is in nearly perfect agreement with the slightly
tighter bound

φ
|
⟨

)
|
|

ρ
⟨

0
|

(
|

≤

⟩⟨

=

φ

ψ

ρ

⟩

¯σ2 ⪅ √2 b(n, ζ)/s.

(C1)

Evaluating the bound b(n, ζ) in a numerically stable way becomes costly for large n and ζ. Fortunately we find that
in the half-filling case ζ = n/2 we have the simple boud

b(n, n/2) ⪅ √n,

(C2)

as can be seen from the power law fit in Figure C.3.

We have seen qualitatively identical statistical properties for other numbers of qubits and states. This motivates the
use of a Gaussian additive noise model when investigating the stability of TCCSD computations against imperfections
in the input overlaps in the next section.

2. TCCSD and ec-CC under Gaussian Noise

With the additive Gaussian noise model at hand, we next investigate how the energies of the hybrid TCCSD and
ec-CC method are influenced by the noise strength σ. To this end, classical CASCI calculations with increasing active
space sizes were run, the CI amplitudes were extracted and Gaussian noise (with standard deviation σ and mean
equal to zero) was added to the amplitude vectors. Subsequently, a TCCSD/ec-CC energy calculation was run for
1 and the used active
each realization of the additive noise. This procedure was conducted for σ = 10−
spaces are shown in Table C.1. For each σ and active space, the “noisy” TCCSD/ec-CC energy was sampled 100
times to obtain a well converged estimator for the energy error due to noise. The data were generated using the N2
molecule with a bond distance of 1.09˚A from restricted HF/cc-pVDZ83 reference orbitals, artificially constructing the
AS around the HOMO-LUMO gap. Note that this procedure would be computationally prohibitive if the overlaps

10, . . . , 10−

3

10−

4

10−

Mean variances
Mean absolute covariances
Fit with slope 0.0
Fit with slope -0.51

102

103

k

2

10−

3

10−

4

10−

5

10−

6

10−

7

10−

8

10−

Mean variances
Variances of variances
Fit with slope -1.0
Fit with slope -2.07
Wan bound √2 b(n = 8, ζ = 4)

102

103

s

29

FIG. C.3: Power law fit for b(n, n/2) (eq (C1)), i.e., half-filling, including √n as an upper bound for efficient
numerical evaluation.

TABLE C.1: Summary of active space sizes and required overlaps d used in Figure C.4.a)

CAS(ζ, n/2) d (TCCSD) d (ec-CC)

(2, 2)
(4, 4)
(4, 6)
(6, 6)
(4, 8)
(6, 8)
(8, 8)
(10, 10)
(12, 10)
(12, 12)
(10, 14)
(6, 16)
(8, 16)
(10, 16)
(12, 16)

4
27
93
118
199
316
361
876
805
1819
2836
2068
3193
4236
5071

4
36
225
381
784
2436
3355
21126
17255
98694
243376
97956
285255
555336
840796

a) Only active spaces highlighted in red were used in the case of ec-CC.

±

∆Enoise
∆Enoise
ec
−
= aσβσ yielded an exponent of βσ = 0.9998

were actually computed using a classical simulation of the matchgate shadow protocol. Depending on the active
space size and hybrid CC method, the required number of overlaps d to run the final energy calculation varies (see
Table C.1). The dependence of the absolute TCCSD and ec-CC energy errors,
, on σ
and d is shown in Figure C.4. A power law fit of the form
0.0016
(cid:12)
±
and βσ = 1.001
0.002 for TCCSD and ec-CC, respectively. Thus, the absolute energy error of both methods
(cid:12)
scales approximately linearly with the noise strength σ. Furthermore, no convergence issues of the classical CC
procedures were observed, even for large noise strengths. Consequently, TCCSD and ec-CC when run with noisy
input amplitudes, as is expected if they are obtained from actual quantum measurements, are very robust to the
strength of the underlying noise due to the linear dependency on σ. This is a rather beneficial behavior of the hybrid
methods, given that a large part of the amplitudes are usually rather small and might be even sign-flipped under
strong noise. The exponent βσ remains approximately one for other molecular systems as well (data not shown). Note
that, however, the prefactor a heavily depends on the system at hand and is irrelevant at this stage of the analysis.
Another interesting observation from Figure C.4 is that the absolute errors of both methods are comparable even
though ec-CC requires many more overlaps to be evaluated (see Table C.1). This behavior might be biased by the
choice of molecular test system, i.e., if the magnitude of the T3 and T4 amplitudes (extracted from CASCI in this

∆E
|

TCCSD

and

CC

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

|

101

b(n, n/2)
(0.956 ± 0.001) n0.4990 ± 0.0002

n

6 × 100

b

4 × 100

3 × 100

2 × 100

101

n

102

30

(a)

(b)

FIG. C.4: Absolute TCCSD energy error (a) and absolute ec-CC energy error (b) as a function of the noise strength
σ and the number of required overlaps d for each method. Note that the vertical axis intercept depends on the
molecular system.

case) is small, the contribution to the projection equations is only mildly influenced by noise. In the TCCSD case,
however, the lower-order frozen T1 and T2 amplitudes are larger in magnitude even for smaller systems, and these
amplitudes directly enter the TCCSD energy expression, contrary to ec-CC.

3. TCCSD Energy Error Extrapolation

With the variance bound for overlaps measured through matchgate shadows, it becomes possible to determine the
shot budget given an active space size to obtain the overlaps to a certain accuracy. As we observerd above, the TCCSD
energy error under noise depends linearly on the standard deviation of the underlying Gaussian distribution. This
dependence is, however, not sufficient to estimate the required variance for other molecular systems, since many prop-
erties of the system enter the TCCSD calculation and have an influence on the final TCCSD energy error. Another
problem is that some properties determining this error cannot be directly extracted just from the molecular Hamilto-
nian, i.e., without solving the underlying electronic structure problem, which becomes computationally prohibitive for
large active spaces, for example. We thus seek a simple extrapolation model for noisy TCCSD energies, taking as input
easy to obtain parameters of a molecular system. Even though we outlined some noise analysis on ec-CC in the section
above, we are going to focus exclusively on TCCSD in the following due to its favorable scaling and small number
of overlaps required. For the error extrapolation model, which will serve as an input for shot budget estimation, we
created a small data set containing 13 small molecules for which we first ran CASCI with a) different active space sizes
(see Table C.2) and b) different basis sets (STO-3G, 6-31G, 6-31G**, cc-pVDZ, aug-cc-pVDZ).83,126–133 From the
3, which were then
resulting CASCI states, we extracted the required overlaps and added Gaussian noise with σ = 10−
put into a TCCSD energy calculation. For each molecule/basis set/active space combination, the noise was sampled
30 times, such that an averaged
could be obtained for each combination. This amounts to approximately
20,000 single-point TCCSD calculations, therefore, we only ran the data collection with TCCSD on a small number
of molecules. The settings thus vary a) the required number of overlaps d (eq (C4)) and b) the number of total spin
orbitals N , which are easy to obtain for any molecule of interest. For completeness, the number of non-redundant
excitation amplitudes for a spin block σ
in nsp spatial orbitals and ζσ electrons with excitation level ν is
given by

∆Enoise

TCCSD

α, β

∈ {

(cid:12)
(cid:12)

(cid:12)
(cid:12)

}

d(nsp, ζσ, ν) =

1
(ν!)2

ν

−

1
(ζσ

i=0
(cid:89)

i)(nsp −

−

ζσ

−

i).

(C3)

For TCCSD, we need the overlap with
, all non-redundant single excitations, i.e., α and β single excitations, for
double excitations, we have αα, ββ, and αβ excitations, where the latter one corresponds to a single α excitation
coupled with a single β excitation. The total number of overlaps for TCCSD thus amounts to

Φ0⟩

|

1 + d(nsp, ζα, 1) + d(nsp, ζβ, 1) + d(nsp, ζα, 2) + d(nsp, ζβ, 2) + d(nsp, ζα, 1)d(nsp, ζβ, 1).

(C4)

d

≡

100

10 2

10 4

10 6

10 8

]
h
E
[

|
D
e
S
s
C
i
o
C
n
T
E

|

10 10

10 12

10 9

10 7

10 5

10 3

10 1

5000

4000

3000

d

2000

1000

 
100

10 2

10 4

10 6

10 8

]
h
E
[

|
C
C

e
s
i
o
c
n
e
E

|

10 10

10 12

80000

60000

d

40000

20000

10 9

10 7

10 5

10 3

10 1

 
TABLE C.2: Active spaces used in the test data set for TCCSD energy error extrapolation, including the resulting
number of required overlaps d as input for TCCSD.

nsp ζα ζβ

d

31

6
8

3 3
2 2
3 3
4 4
10 5 5
6 6

118
199
316
361
876
805
12 6 6 1819
14 5 5 2836
16 3 3 2068
4 4 3193
5 5 4236
6 6 5071
8 8 5793

∆Enoise

TCCSD

One “variable” contributing to

, which is highly system-specific, is the “amount” of static or dynamic
correlation in the system. For example, a weakly correlated molecule, where the dynamic correlation energy is
dominant, is only mildly affected by noisy input amplitudes for TCCSD, whereas the opposite might be the case for
strongly correlated systems. There is, however, no single quantity that could serve to model this properly. With our
choice of molecules, we try to cover several different correlation scenarios, e.g., diatomic molecules in equilibrium,
stretched diatomics, and some small organic molecules. All things considered, after several attempts to build a good
error model, we came up with the following power law,

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
In the randomized noise simulations above, we fixed the noise strength, yielding the unknown parameters on the
(cid:12)
right-hand side as

(cid:12)
(cid:12)

∆Enoise

TCCSD

= adβN γσ.

(C5)

(cid:12)
(cid:12)
We fitted the above power law to the recorded data over all molecules, basis sets, active space sizes, and noise
samples, yielding the exponent parameters shown in Table C.3 together with standard errors determined through
bootstrapping (50,000 bootstrap samples). The prefactor a carries the dependencies on omitted variables (e.g., the

(cid:12)
(cid:12)

∆Enoise
TCCSD
σ

= adβN γ.

(C6)

TABLE C.3: Parameters and errors obtained from power law fit over the entire TCCSD noise error data set.

Parameter Value Bootstrap Std. Error

β
γ

0.277
−1.074

0.054
0.116

correlation strength, etc.), thus, it is not advisable to fit this parameter globally, i.e., for all molecules at once. Through
running the power law fit on subsets of the sample (leave-one-out, etc.), we could confirm that the exponents seem to
be largely independent of the molecular system (data not shown), indicating that the fit parameters describe the trend
of the TCCSD error through noise quite well in the simple power law. In the subset power law fits, we found that the
prefactor varies largely depending on the molecular systems. For this reason, with the globally fitted exponents β and
γ at hand, we re-ran the fit for a for each molecule, keeping the exponents fixed at the fitted values from the entire
data set. This yielded a prefactor a for each molecule, shown in Table C.4 and plotted in Figure 4. The raw data for
∆Enoise
including the power law fits is plotted in Figure C.5. One can clearly see in this plot that the globally
fitted exponents represent the slope and trend of basis set dependence well, hinting that we can indeed use the error
(cid:12)
extrapolation model for active spaces and systems beyond the data set. As expected, the TCCSD error magnitude
(cid:12)
grows with the number of required overlaps, but decreases with the size of the total MO space (negative exponent).
The latter can be rationalized as follows: when keeping the active space size (and hence the number of overlaps d)
fixed while increasing the overall MO space, the contribution of the AS in relation to the external space decreases,
and the error made by noisy amplitude measurements becomes more and more negligible. The remaining hurdle is,

TCCSD

(cid:12)
(cid:12)

32

TABLE C.4: Prefactor a obtained in a per-molecule fit of the TCCSD noise error data with exponents fixed at
D1 values obtained from plain CCSD averaged over basis sets.
values from Table C.3, together with the

T1 and
Molecule

a

T1

N2 (stretched) 18.67
6.48
F2 (stretched)
5.65
p-Benzyne
Cl2 (stretched) 4.83
4.27
3.20
3.01
3.00
2.98
2.60
2.22
2.56
2.41

F2
N2
H2O
Me-NCO
Benzene
Formaldehyde
Acetaldehyde
Furan
Cl2

0.049
0.023
0.015
0.015
0.010
0.010
0.008
0.014
0.008
0.014
0.013
0.012
0.005

D1

0.107
0.089
0.061
0.081
0.028
0.024
0.017
0.053
0.027
0.045
0.048
0.046
0.018

T1 and

given a molecule not present in the data set, to select the prefactor a for that system. This needs to be done by
comparing the “correlation strength” and finding the best fit in our tabulated data. Since this is a bit cumbersome,
we sought for a more tangible metric that is easy to obtain and came up with the typical CCSD diagonstic values,
which are commonly used to assess whether the CCSD wavefunction provides a reliable, true SR result or whether
D2 diagnostics28,29 for each molecule and basis set. As can be
MR methods are needed. We computed the
seen in Figure 4, the trend of the molecule-specific prefactor a and their corresponding diagnostic values are in good
agreement with each other. Thus, for the determination of the prefactor of a molecule outside our data set, we suggest
T1 diagnostic value, because it has the strongest correlation with a, and to select the prefactor
to first compute the
T1 to a is given by
accordingly (see Table C.4). The linear model to convert
0.84.
× T1 −
Clearly, the stretched N2 molecule is kind of an outlier because the prefactor a and its diagnostic values are far off
the median/mean of the data set. This, however, shows that the scenario for N2 can serve as a “worst case” scenario,
which will be useful in the following to estimate upper bounds for shot budgets. In summary, our error extrapolation
protocol relies on the following steps:

375.9

(C7)

≈

a

1. Select a molecule and basis set (determining N )

2. Compute CCSD in that setting and obtain the

T1 diagnostic value

3. Select an active space size and compute the number of required overlaps for TCCSD d

4. Map the diagnostic value to a prefactor a using the conversion formula in eq (C7) (compare with Table C.4)

5. Insert all the quantities (d, N , a, and the exponents in Table C.3) into eq (C5)

6. Together with a noise strength σ, one can estimate the TCCSD energy error due to noise in that precise setting

We will use this procotol in the following to estimate shot budgets for quantum TCCSD.

4. Shot Budget Estimation

Combining eq (C1) with eq (C5) we can obtain a bound on the number of shots needed for guarantee that the shot
noise does not change the TCCSD energy by more than a given magnitude. Finally, one can estimate the shot budget
for the half-filling case as

s ⪅ a2
∆E
|

2 d2βN 2γ√2n
|

(C8)

for a given target TCCSD energy error
and the system-dependent variables, obtained through the protocol in the
previous section. Using the above equation, we estimated the shot budgets for the scenarios dictated by the molecule

∆E
|

|

33

as a function of d for different molecules and basis sets with

FIG. C.5: Absolute TCCSD energy error

∆Enoise

TCCSD

σ = 10−

3. The dashed lines employ a power law fit using the globally fitted exponents of d and N (Table C.3)

together with the molecule-specific prefactor a (Table C.4).

(cid:12)
(cid:12)

(cid:12)
(cid:12)

|

|

∆E

= 10−

3 Eh with an arbitrarily chosen MO space of N = 600 and half-
prefactors aiming for a target accuracy
filling active spaces from n = 4 to n = 200 qubits. Uncertainties in the fitted exponents were included by estimating a
lower bound (exponent minus bootstrap standard deviation) and an upper bound (exponent plus bootstrap standard
deviation) of the shot budget. The resulting shot budget estimates s are plotted in Figure C.6. Surprisingly, even in
the worst case scenario (strong correlation as in a stretched N2 molecule), our estimated upper bound for the shot
budget to obtain the (noisy) TCCSD energy to chemical precision barely exceeds 108 shots in a 200 qubit setting.
We want to stress again that the shots budgets do not include measurements for state preparation/optimization on
the quantum device, just the overlap measurements through matchgate shadows. If there were imperfections in the
trial state, i.e., the shot noise is not applied to the exact overlaps, the error of the quantum TCCSD with respect to
its (exact) classical counter part would be much larger than what our error model predicts. Nonetheless, the broad
window of different correlation scenarios covered in here should be helpful enough to get a decent understanding on
the order of magnitude of the required shot budget.

N2 (stretched)

F2 (stretched)

p-Benzyne

Cl2 (stretched)

F2

N2

H2O

Me-NCO

Benzene

Formaldehyde

Furan

Cl2

Acetaldehyde

102

103
d

102

103
d

102

103
d

10 3

10 4

|
D
e
S
s
C
i
o
C
n
T
E

|

10 5

10 6

10 3

10 4

|
D
e
S
s
C
i
o
C
n
T
E

|

10 5

10 6

10 3

10 4

|
D
e
S
s
C
i
o
C
n
T
E

|

10 5

10 6

10 3

10 4

|
D
e
S
s
C
i
o
C
n
T
E

|

10 5

Basis Set
STO-3G
6-31G
6-31G**
cc-pVDZ
aug-cc-pVDZ
Data
recorded
power law fit

10 6

102

103
d

34

FIG. C.6: Shot budget estimation for “scenarios” based on molecular systems (prefactor a), with globally fitted

exponents (
standard deviation of the exponents from global fit shown as gray shaded areas), target energy error
±
3 Eh, N = 600, ζ = n/2. Note that the molecules here are just labels for different prefactors a. This is
= 10−
∆E
|
done to cover different possible scenarios of the prefactor, i.e., figure out best/worst case scenarios for shot budgets
based on TCCSD energy error extrapolation.

|

TABLE C.5: Shot budgets s estimated using the error extrapolation model for the N2/cc-pVDZ dissociation curve
T1 diagnostic
needed for obtaining a TCCSD energy in a (6, 6) active space to chemical precision, together with the

extracted from CCSD.

R [˚A]

T1

0.8
0.9
1.0
1.1
1.2
1.3
1.4
1.5
1.6
1.7
1.8
1.9
2.0
2.1
2.2
2.3
2.4
2.5
2.6
2.7
2.8

0.004
0.006
0.008
0.010
0.012
0.015
0.018
0.020
0.023
0.025
0.028
0.030
0.032
0.035
0.038
0.040
0.042
0.044
0.045
0.046
0.046
(cid:80) s

s

5.2 × 103
1.9 × 104
5.0 × 104
1.0 × 105
1.8 × 105
2.8 × 105
4.1 × 105
5.6 × 105
7.3 × 105
9.0 × 105
1.1 × 106
1.3 × 106
1.6 × 106
1.8 × 106
2.2 × 106
2.5 × 106
2.8 × 106
3.0 × 106
3.1 × 106
3.2 × 106
3.3 × 106

2.9 × 107

108

106

s

104

102

101

n

102

a

N2 (stretched)
F2 (stretched)
p-Benzyne
Cl2 (stretched)
F2
N2
H2O
Me-NCO
Benzene
Formaldehyde
Furan
Cl2
Acetaldehyde

Appendix D: ec-CC on Hardware Data From Google’s Sycamore Quantum Processor

35

FIG. D.1: Root mean squared error (RMSE) of the absolute values of the wavefunction coefficients (CI vector)
extracted from the trial state for four different repetitions. The device noise in the first two repeats is far smaller
than in the last two repeats.

To investigate the performance of ec-CC on actual noisy data, we used the wavefunctions extracted from Clifford
shadows published in Ref. 27. The raw data can be obtained from Zenodo.134 The trial state wavefunctions (referred
to as “Q trial” in the original paper) were first “converted” to real-valued wavefunctions through rotation by the
phase of the largest absolute value wavefunction coefficient (i.e., making the wavefunction as “real” as possible), then
retaining only the real part of the wavefunction and renormalizing it. This state is referred to as “Q trial real”. Since
the quality of the trial wavefunctions extracted from the device in the first two repetitions is superior to the other
two runs (see Figure D.1), we only use the data from these runs.

TABLE D.1: H4/STO-3G energies from Q trial state converted to real-valued wavefunction. Absolute errors in mEh
with respect to FCI are shown in parentheses.

NCliffords Repeat 1

Repeat 2

−1.82121 (148.30) −1.80389 (165.63)
10
−1.85039 (119.13) −1.85554 (113.97)
16
−1.92465 (44.86) −1.88711 (82.40)
28
−1.94073 (28.78) −1.91560 (53.91)
47
−1.92072 (48.79) −1.89485 (74.66)
80
−1.94335 (26.16) −1.93524 (34.27)
136
−1.95366 (15.85) −1.95132 (18.19)
229
−1.95760 (11.91) −1.95954 (9.97)
387
652
−1.96250 (7.01) −1.96332 (6.20)
1100 −1.96616 (3.35) −1.96553 (3.98)
1856 −1.96634 (3.17) −1.96650 (3.02)
3129 −1.96549 (4.02) −1.96683 (2.69)
5276 −1.96604 (3.47) −1.96634 (3.18)
8896 −1.96540 (4.12) −1.96651 (3.00)
15000 −1.96562 (3.90) −1.96666 (2.85)

10 1

E
S
M
R
r
o
t
c
e
v

I

C

10 2

Experiment

1
2
3
4

101

102

103

104

NCliffords

 
 
TABLE D.2: H4/STO-3G ec-CC energies based on Q trial state converted to real-valued wavefunction. Absolute
errors in mEh with respect to FCI are shown in parentheses.

36

NCliffords Repeat 1

Repeat 2

−1.97656 (7.05) −1.97656 (7.05)
10
−1.97656 (7.05) −1.97656 (7.05)
16
−1.97637 (6.86) −1.97656 (7.05)
28
−1.97637 (6.86) −1.97656 (7.05)
47
−1.97656 (7.05) −1.97656 (7.05)
80
−1.97637 (6.86) −1.97656 (7.05)
136
−1.97637 (6.86) −1.96732 (2.19)
229
−1.96684 (2.67) −1.96846 (1.05)
387
652
−1.96779 (1.73) −1.96858 (0.93)
1100 −1.96928 (0.23) −1.96881 (0.70)
1856 −1.96973 (0.22) −1.96989 (0.38)
3129 −1.96929 (0.22) −1.97074 (1.23)
5276 −1.96961 (0.10) −1.97026 (0.75)
8896 −1.96893 (0.58) −1.97023 (0.72)
15000 −1.96891 (0.60) −1.97028 (0.76)

TABLE D.3: H4/STO-3G ec-CC energies based on the exact FCI state with overlaps measured through matchgate
shadows. The results are averaged over 30 samples of the matchgate shadow. Absolute errors in mEh with respect
to FCI are shown in parentheses.

Shots multi Matchgate single Matchgate

10000 −1.98029 (10.89) −1.96906 (3.32)
20000 −1.97662 (7.62) −1.96990 (2.33)
50000 −1.97160 (4.84) −1.96927 (1.35)
100000 −1.96922 (2.64) −1.96933 (0.88)
200000 −1.96965 (1.88) −1.96945 (0.55)
500000 −1.96937 (1.07) −1.96945 (0.39)
1000000 −1.96963 (0.75) −1.96949 (0.23)

TABLE D.4: Error in the total energy (in kcal/mol) of the diamond minimal unit cell in a double-zeta basis as a
function of the lattice constant R.

R [˚A] Q trial Q trial real ec-CC/Q trial TCCSD/Q trial QC-QMC CAS(8,8) ec-CC/CAS NEVPT2 TCCSD/CAS CCSD(T) AFQMC

2.88
3.24
3.60
3.96
4.32

266.58
1006.44
177.30
208.04
327.49

174.89
693.05
137.78
159.25
233.19

4.31
6.60
6.41
10.10
15.01

19.34
20.74
36.97
37.95
27.47

0.05
−0.85
1.17
3.46
4.44

51.15
51.96
52.45
52.84
53.14

3.17
4.11
5.49
7.70
11.66

0.68
0.71
0.67
0.54
0.66

1.11
1.04
0.72
0.17
−0.18

−0.35
−0.59
−1.10
−2.17
−4.40

2.76
3.15
4.99
8.47
16.54

","3 2 0 2 c e D 3 1 ] h p - t n a u q [ 1 v 0 1 1 8 0 . 2 1 3 2 : v i X r a Tailored and Externally Corrected Coupled Cluster with Quantum Inputs Maximilian Scheurer,1 , ∗ Gian-Luca R. Anselmetti,1 , † Oumarou Oumarou,1 Christian Gogolin,1 , ‡ and Nicholas C. Rubin2 , § 1Covestro Deutschland AG , 51373 Leverkusen , Germany 2Google Quantum AI , Venice , CA , United States ( Dated : December 14 , 2023 ) We propose to use wavefunction overlaps obtained from a quantum computer as inputs for the classical split-amplitude techniques , tailored and externally corrected coupled cluster , to achieve balanced treatment of static and dynamic correlation effects in molecular electronic structure simu- lations . By combining insights from statistical properties of matchgate shadows , which are used to measure quantum trial state overlaps , with classical correlation diagnostics , we are able to provide quantum resource estimates well into the classically no longer exactly solvable regime . We find that rather imperfect wavefunctions and remarkably low shot counts are sufficient to cure qualitative failures of plain coupled cluster singles doubles and to obtain chemically precise dynamic correla- tion energy corrections . We provide insights into which wavefunction preparation schemes have a chance of yielding quantum advantage , and we test our proposed method using overlaps measured on Google ’ s Sycamore device . I . INTRODUCTION Recent work devising how to use a quantum computer to model electronic structure continues to suggest fermionic simulation as a valuable and viable application of near-term and fault-tolerant quantum devices . Just as in the classical modeling of electronic structure where various strategies are explored for treating different aspects of electron correlation , quantum algorithms have largely followed a similar divide-and-conquer trajectory . While treatment of strong correlation is cited as the most likely motivation for applying quantum computers to chemistry,1 an accurate treatment of dynamic electronic correlation effects is an important aspect when considering total quantum resource counts and the viability of applying a quantum computing protocol to solve electronic structure problems . In this work , we further integrate classical electronic structure methodologies and quantum computation to lower measurement requirements needed for dynamical correlation corrections . Our focus is on split-amplitude coupled cluster ( CC ) methodologies that have been widely studied in the quantum chemistry community.2,3 Specifically , we analyze the robustness of quantum inputs to these theories along with motivating wavefunction characteristics that a quantum computer must satisfy to improve over classical approximate external amplitude inputs . While it is generally possible to layer quantum state preparation with many dynamic correlation corrections , split-amplitude methods provide the necessary framework in which we can analyze the sampling costs and robustness beyond common , and usually loose , tomographic sampling bounds . To date , there exist several approaches to include dynamic correlation effects in quantum simulations of chem- istry , e.g. , virtual quantum subspace expansion ( VQSE ) ,4 second-order perturbation theory using the variational quantum eigensolver ( VQE ) 1,5,6 together with quantum subspace expansion ( QSE ) , named NEVPT2 ( VQE , QSE ) ,7 non-orthogonal configuration interaction approaches,8 and NEVPT2 based on qubit reduced density matrices ( RDMs ) , named QRDM-NEVPT2.9 We note that a plethora of other methods for studies of chemical systems exists , e.g. , based on embedding techniques.10–17 The QRDM-NEVPT2 method , in addition to VQE state preparation and optimization , requires quantum evaluation of the three-particle reduced density matrix ( 3RDM ) and four-particle RDM-like terms , exploiting a cumulant approximation . For quantum active space ( AS ) methods , it is already quite resource-intense with respect to required number of measurement repetitions , so-called shots , to accurately determine the 2RDM for energy evaluation . As a consequence , a multitude of approaches for efficient measurements of the 2RDM has evolved so far , reducing the number of distinct measurement bases and variances significantly.18–25 Thus , the burden of even more measurements required for higher-order reduced density matrices in , e.g. , QRDM-NEVPT2 poses the question whether one can construct a hybrid quantum/classical approach which does not rely on RDMs . Recent work leverag- ing classical shadows26 combined with auxiliary-field Quantum Monte Carlo ( AFQMC ) 27 suggests an efficient path forward by shifting focus to wavefunction corrections in lieu of the RDMs . ∗ Corresponding Author : maximilian.scheurer @ covestro.com † Current Address : Quantum Lab , Boehringer Ingelheim , 55218 Ingelheim am Rhein , Germany ‡ christian.gogolin @ covestro.com § Corresponding Author : nickrubin @ google.com 2 FIG . 1 : A visual representation of the quantum split-amplitude protocol analyzed in this work . To this end , we propose to use quantum trial states as input for tailored coupled cluster ( TCC ) and externally corrected coupled cluster ( ec-CC ) methods . On the quantum device level , this requires preparing a suitable state and then measuring the overlaps of that state with ( excited ) Slater determinants , corresponding to computational basis state overlaps . The steps required to obtain quantum inputs and run the subsequent classical CC calculation is depicted in Figure 1 , comparing the workflow with its purely classical counterpart . Only two building blocks differ between the quantum and classical version . To extract computational basis overlaps we propose to leverage various forms of classical shadows,26 a measurement technique allowing for efficient estimation of multiple expectation values , which have recently been extended to use the matchgate group for efficient overlap estimation.23,25 These protocols fulfill the requirement of providing overlap magnitudes and signs , which are needed for subsequent cluster analysis . In contrast to classical TCC and ec-CC methodologies developed to date , quantum TCC and quantum ec-CC require analysis of i ) when improvements over classical approximate methods are possible and ii ) sensitivity of these methods to device and shot noise . We take steps towards addressing both questions in this work . We note that the proposed methodologies are not limited to any particular quantum computing setting , since the CC methods are completely agnostic of the origin of the cluster amplitudes . Hence , they are applicable to near-term and fault-tolerant setups alike , provided a protocol for evaluating the overlaps exists . While the total number of computational basis state overlaps scales exponentially in the number of qubits n , TCC with singles and doubles ( TCCSD ) and ec-CC only require a polynomial number of overlaps as input for cluster analysis , i.e. , less than n4 for TCCSD and less than n8 for ec-CC . A substantial component of this work involves constructing a noise model for matchgates shadows and mapping a model for measurement overheads given common electronic structure metrics that are cheaply available . We implement the matchgate shadows described in Ref . 25 and numerically verify that the measurements of computational basis state overlaps follow a Gaussian distribution and are independent and identically distributed . To determine a shot budget for TCCSD using the Gaussian noise model of matchgate shadows , we fit the total shot requirements to a particular D1 diagnostics.28,29 We analyze the error to a power law distribution with constants determined by well-known robustness ec-CC with experimental Clifford classical shadows to emphasize the regime of utility and demonstrate the methods robustness to real experimental noise on using data taken from the recent QC-QMC experiment by Google and collaborators.27 T1 or We continue with a methodological account and an overview of split-amplitude methods , but expert readers can directly skip to Section III , where we discuss the impact of possible quantum trial states and their quality require- ments for split-amplitude quantum CC methods . Furthermore , we present numerical results of quantum TCCSD by simulating of the N2 dissociation curve in a VQE-based NISQ setting , further highlighting state preparation robust- ness of TCCSD . We then describe overlap measurement strategies in Section IV , which are the key ingredient for providing quantum inputs . Based on numerical studies of the statistical properties of matchgate shadows , we develop the noise model to mimic finite shot noise , and we employ this noise model to obtain quantum resource estimates for beyond classically tractable molecular systems . For an N2 dissociation curve of 21 points within a double-zeta basis set , we find that a total of 30 million shots will be enough for chemically precise results . Finally , in Section V , we Classical Computer HF Reference Active Space Hamiltonian Quantum Computer Multiconfigurational Method Quantum Trial Preparation Molecular Orbitals Overlap Extraction Overlap Measurements ( classical shadows ) Cluster Analysis CC Calculation study the performance of quantum split-amplitude CC energetics on H4 and diamond , using classical shadows data from an experiment performed on Google ’ s Sycamore device , demonstrating that ec-CC can in principle compete with QC-QMC . 3 II . BACKGROUND ON ELECTRONIC STRUCTURE METHODS The field of quantum chemistry has seen remarkable progress over the past decades , with ab-initio coupled cluster ( CC ) methods emerging as a reliable and systematically improvable framework for electronic structure simulations of molecules.30–32 The most successful method of the CC family is probably coupled cluster with singles and doubles ( CCSD ) 33 in conjunction with a perturbative triples correction , CCSD ( T ) ,34 commonly referred to as the “ gold standard ” for quantum chemistry.35,36 Therefore , CCSD and CCSD ( T ) are possibly the most used wavefunction methods to investigate properties of small and medium-sized molecules , limited in applicability by the steep scaling . Recent endeavours , however , have made it possible to push the boundaries with respect to system size even further.36 Due to favorable properties , e.g. , size consistency in contrast to truncated configuration interaction ( CI ) ans¨atze,37 these single-reference CC ( SRCC ) methods usually perform well in describing molecular systems where dynamic correlation effects are dominant.38 On the contrary , SRCC approaches can struggle in multi-reference ( MR ) scenarios , such as describing the potential energy surface of bond breaking , and lead to catastrophic failures in several cases.2,39 The MR failures can in principle be remedied through an even more computationally demanding framework , that is , multi-reference CC ( MRCC ) .16,40 In case a system at hand is almost purely statically correlated , i.e. , where the solution to the electronic Schr¨odinger equation is well described by a couple of Slater determinants , accurate results can be obtained through so-called multiconfigurational active space ( AS ) methods , such as complete active space configuration interaction ( CASCI ) .41–45 The active space consists of a subset of molecular orbitals ( MOs ) and electrons in which the full configuration interaction ( FCI ) problem is then solved . This approach covers static correlation effects well , but neglects major part of the dynamic correlation effects outside of the chosen active space . Hence , the division into an active and external orbital space introduces approximations that , while qualitative phenomena might be described correctly , can become unacceptable when chemical precision is required.4,46 With techniques such as selected CI methods47–51 and density matrix renormalization group ( DMRG ) ,52 it becomes possible to simulate quite large active spaces , or even aim toward FCI quality . If the active space size can not be increased enough , the dynamic correlation contributions can be approximately included through perturbation theory on the CAS method , yielding , e.g. , the well-known CASPT2 and NEVPT2 methods.53–57 Fortunately , the well-known framework of SRCC offers the possibility to capture static correlation properties from an AS-type wavefunction through a so-called split-amplitude ansatz . The most prominent methods of this family are tailored coupled cluster ( TCC ) 2 and externally corrected coupled cluster ( ec-CC ) ,3,58–62 however , approaching the encoding of static correlation effects from different directions . The high-level idea of both methods is to extract information about the static correlation from the AS wavefunction and inject them through specific partitioning of the cluster operator and the corresponding amplitudes in a SRCC wavefunction . Originally , these methods were developed to remedy failures of SRCC approaches in the strongly correlated regime , as explained previously . TCC and ec-CC are schematically illustrated in Figure 2 , and more theoretical details are outlined in Appendix A . In the TCC ansatz , the cluster operator is split into an active space part and an external part , ˆT TCC = ˆT AS + ˆT ext . ( 1 ) The cluster amplitudes , accompanying the active space cluster operator , are obtained from the AS-type multicon- figurational wavefunction through cluster analysis . Cluster analysis relies on the equivalence of the exponential CC ansatz and the linear CI expansion using intermediate normalization , making it possible to recursively convert the amplitudes from a CI-like wavefunction to their corresponding CC counterpart.2,63,64 For CC with singles and dou- bles , this yields the so-called TCCSD approach , where the strategy is to extract T1 and T2 amplitudes from the AS-type wavefunction . The active space T1 and T2 amplitudes are then frozen during the CC iterations on the external amplitudes , assuming the active space amplitudes retain the MR information . The original work by Bartlett and co-workers showed that , despite its simplicity , TCCSD yields dissociation energies and potential energy surfaces which are in good agreement with higher-level MR methods.2 Note that the only inputs required for TCC are overlaps of ( excited ) Slater determinants with the AS wavefunction , which can be formulated as the following projection , cν = Φν ⟨ | ΨAS . ⟩ ( 2 ) In the equation above , cν is the CI coefficient vector of excitation level ν , with respect to the Fermi vacuum/reference determinant , and Φν is a ν-fold excited Slater determinant | is an AS-type wavefunction from which the ⟩ Φ0⟩ | ΨAS | ⟩ 4 FIG . 2 : Schematic illustration of TCC ( left ) and ec-CC ( right ) . In TCC , a subset of the cluster amplitudes are AS through cluster analysis . The external set of amplitudes is then obtained from an active space wavefunction ⟩ solved in presence of frozen AS amplitudes , which encode the information on static correlation . The ec-CC ansatz uses T3 and T4 amplitudes from an input wavefunction ( which can stem either from an active space or from the full space ) and solves the full CCSDTQ singles and doubles equations in presence of the external T3 and T4 amplitudes . Ψ | coefficients are to be extracted . For TCCSD , only the C1 ( ν = 1 ) and C2 ( ν = 2 ) coefficients need to be extracted , i.e. , ca i = cab ij = ⟨ ⟨ Φa i | Φab ij | ΨAS ⟩ ΨAS ⟩ , , ( 3 ) ( 4 ) ΨAS | ⟩ Φ0⟩ | , whereas a , b are so-called virtual orbital indices , i.e. , unoccupied in in addition to the overlap with the reference determinant , c0 , if is not intermediate-normalized . The indices i , j refer to occupied orbitals in . Φ0⟩ | Subsequently , the C amplitudes are recursively converted to T amplitudes , mapped from the active orbitals to the full MO space , and kept fixed during solution of the CCSD projection equations . It is quite appealing that only minor modifications to a standard CCSD code need to be made to support tailoring . Different types of input wavefunctions have been successfully used for TCCSD , e.g. , CASCI,2,65 DMRG for large active spaces,66 and pair coupled cluster doubles ( pCCD ) .67 A recent extension to excited state calculations has been presented by Bartlett and co-workers.68 There exists the tailored counterpart to CCSD ( T ) , that is , TCCSD ( T ) ,69 which computes the perturbative triples correction solely using the external contribution of the cluster amplitudes . Through combination with the LPNO and DLPNO framework , TCC has been successfully employed to study the electronic structure of large molecular complexes.70–72 Furthermore , the underlying numerical and theoretical aspects have been thoroughly analyzed from a mathematical point of view.73,74 Even though the tailoring of T1 and T2 amplitudes captures the static correlation effects to some extent , the final TCCSD wavefunction is still a SR wavefunction , which is known to fail in some cases.39,75,76 To some level , these shortcomings can be circumvented by increasing the active space size and the choice of orbitals.35,39 The second split-amplitude approach , ec-CC , addresses the inclusion of multi-reference phenomena in a SRCC wavefunction from a different direction.3 Viewed as a variation of tailored coupled cluster but on the full space77,78 we use the fact that the singles and doubles residual equations can only involve singles amplitudes through quadruples amplitudes Φab ij | ⟨ ˆHN ( cid:20 ) ( cid:18 ) 1 + ˆT1 + ˆT2 + 1 2 Φa i | ⟨ ˆHN ( cid:20 ) 1 + ˆT3 + ˆT1 ˆT2 + ˆT 2 1 6 1 2 1 + ˆT1 + ˆT2 + 1 + ˆT3 + ˆT1 ˆT2 + ˆT 2 ( cid:18 ) 1 + ˆT4 + ˆT1 ˆT3 + ˆT 3 1 2 ˆT 2 2 + 1 2 ˆT 2 1 ˆT2 + 1 6 1 24 ˆT 3 1 ˆT 4 1 Φ0⟩ ( cid:19 ) ( cid:21 ) c | Φ0⟩ ( cid:19 ) ( cid:21 ) c | = 0 , ( 5 ) = 0 , ( 6 ) which is true for any rank coupled cluster operator , above four , because the normal-ordered Hamiltonian ˆHN has at most two-body interactions . If the triples and quadruples amplitudes in ˆT3 and ˆT4 are exactly determined with , e.g. , FCI , then the exact correlation energy can be recovered . This is to be expected since the exact amplitudes in ˆT3 and ˆT4 depend on CI coefficients of rank 1 , 2 , 3 , and 4 . This can , however , provide an alternative route to better than CCSD calculations if approximate triples and quadruples are obtained from an AS-type method . While there ΨAS | ⟩ ˆT AS ˆT ext Ψinput | ⟩ ˆT3 , ˆT4 ˆT1 ˆT2 ˆT3 ˆT4 ΨTCC | ⟩ = exp ˆT AS + ˆT ext ( cid:16 ) Φ0⟩ | ( cid:17 ) Ψec-CC | ⟩ = exp ˆT1 + ˆT2 + ˆT3 + ˆT4 ( cid:16 ) Φ0⟩ | ( cid:17 ) 5 are obvious instance where ec-CC provides no value ( e.g. , wavefunctions where cluster operators of rank 2 to 4 are used and their active space versions – CCSDt , and CCSDtq ) , there are cases where improvements are observed.79 The key components of when an ec-CC treatement can provide improvement are described in Ref . 79 and will be summarized in the context of quantum wavefunctions in Section III . The main idea is that if one uses frozen triples and quadruples amplitudes obtained in some way and solves for the singles and doubles in their presence , one can determine a corrected form of the quadruples CC involving MR character . In practice , a non-CC wavefunction theory in an active space is used to determine the dominant triple and quadruple excitations , and the cluster operator takes on the form ˆT = ˆT1 + ˆT2 + ˆP3 ˆT3 + ˆP4 ˆT4 , ( 7 ) where ˆP3,4 project out a subset of triples and quadruples excitation that are dictated from a correlated multi-reference calculations such as DMRG , heat-bath CI,80 or adaptive CI.81 Alternatively , one can use an uncoverged FCIQMC calculation to recover approximate triples and quadruples amplitudes to then solve for for the ˆT1 and ˆT2 parts.79 It was demonstrated that roughly converged FCIQMC calculations can result in quite accurate CCSDTQ energies . The role of the FCIQMC calculation is to determine dominant triple and quadruple amplitudes . A caveat is that the classical computational effort of ec-CC scales like N 8 ( see Appendix A 4 ) , which , contrary to TCCSD with a N 6 scaling , limits the applicability of ec-CC to systems of modest size . TCC and ec-CC require the same kind of inputs , namely the overlaps of Slater determinants with the AS-type wavefunction which is then put into a cluster analysis protocol . In the context of quantum computation , this has the appealing advantage that no higher-order RDMs are required to enable a split-amplitude CC calculation based on a quantum trial state . III . IMPACT OF QUANTUM TRIAL STATES QUALITY In this section we first investigate the stability of TCCSD against overlaps derived from imperfect wavefunctions , such as those states prepared by a shallow VQE circuit . We find that even wavefunctions whose AS energy differs significantly from CASCI do yield a TCCSD dynamic correlation energy correction that is in good agreement with both TCCSD and NEVPT2 based on the exact CASCI wavefunction . What is more surprising , even a rather inaccurate wavefunction as input to TCCSD turns out to be sufficient to cure the appearance of a qualitatively incorrect reaction barrier in plain CCSD . We are further able to provide insights into which wavefunctions have a chance of leading to an improved energy under ec-CC on the full orbital space . A. Quantum TCCSD with Approximate VQE Wavefunctions We model the dissociation of the N2 triple bond , a textbook example in which the dynamic and static correlation regime need to be converged well for quantitatively reliable results.2 In the first TCCSD work,2 it has been shown that TCCSD tailored by CASCI with 6 electrons in 6 orbitals , CAS ( 6,6 ) , gives a qualitatively and quantitatively correct dissociation curve , in contrast to plain CCSD . Our goal here is to assess whether TCCSD tailored by one of the most prominent quantum methods for simulating electronic structure , VQE , behaves similarly . Since the underlying VQE circuits which would be required to prepare the exact CASCI state are not affordable , we want to analyze how inaccuracies in the wavefunction ansatz translate to TCCSD , or whether this even leads to a breakdown of the beneficial properties of TCCSD after all . For this purpose , we set up a quantum-number-preserving ( QNP ) 82 circuit of 10 layers ( 50 parameters ) , which was optimized for each geometry along the dissociation curve . The reference state was obtained with restricted HF/cc-pVDZ.83 For the “ stress test ” with respect to rather shallow VQE circuits , we then ran TCCSD based on the overlaps obtained analytically from the final VQE state ( through read-out of the coefficients of the VQE state vector ) , referred to as VQE-TCCSD in the following . The dissociation curves for CCSD , CASCI , NEVPT2 , TCCSD , VQE , and VQE-TCCSD are shown in Figure 3 in the left panel . As previously observed , the equilibrium region is well described by CCSD , but this method yields a qualitatively incorrect virtual reaction barrier upon triple bond breaking , which is fully recovered by TCCSD.2 Plus , TCCSD provides an accurate numerical value for the dissociation energy , whereas the CASCI curve results in a too small dissociation energy . This shows how important the inclusion of dynamic correlation effect becomes for accurate simulations . Comparing CASCI to TCCSD , the barrier is shifted from 286.8 milli-Hartree ( mEh ) by 45.4 mEh to 332.0 mEh , which is quite a significant change . For comparison , we ran NEVPT2 on CASCI for this system , which yields almost exactly the same dissociation curve as TCCSD . Now , due to the shallow VQE circuit used in our simulations , the predicted reaction barrier is artificially too high and VQE-TCCSD can not repair the incorrect energy contribution from the active space . If the VQE circuit were expressive enough , one would obtain a dissociation curve identical to CASCI . In the upper 6 FIG . 3 : Dissociation curve of N2 using classical and quantum methods ( left panel ) , CASCI energy error of the employed VQE ansatz ( upper right panel ) , and external correlation energy Eext of TCCSD methods ( lower right panel ) . For the dissociation curve , energies are relative to the minimum energy the inter-nuclear distance R = 1.1 ˚A . Note that the relative energies of TCCSD and NEVPT2 almost lie on top of each other . right panel in Figure 3 , the error of the VQE energy with respect to CASCI is shown . For bond distances R > 1.2 ˚A , the energy error is larger than 10 mEh and steadily increases toward the dissociation limit . Around the equilibrium bond distance , the system possesses only weak static correlation effects , such that the shallow VQE circuit is of course much more accurate in that region . Looking at the VQE-TCCSD dissociation curve , no artificial reaction barrier is present , i.e. , despite the poor quality of the VQE ansatz , the quality of the underlying wavefunction seems good enough to heal the physically wrong CCSD behavior . Interestingly , the VQE dissociation energy ( 345.3 mEh ) is shifted in VQE-TCCSD ( 392.6 mEh ) by 47.3 mEh , which is almost identical to the energy shift from CASCI to TCCSD , i.e. , without imperfections in the wavefunction . This parallel can be narrowed down to the external energy contribution in TCCSD , Eext , depicted for TCCSD and VQE-TCCSD in the lower right panel in Figure 3 . The contribution from the external TCCSD part is almost identical , showing that the dynamic energy contribution in TCCSD is very robust against a poor CI-like wavefunction produced from the shallow VQE circuit , and the error in energy shift from the CI-like method to TCCSD is approximately one order of magnitude smaller than the plain VQE error . Note that the quantum inputs for VQE-TCCSD amount to only measuring less than n4 overlap values , whereas a possible PT approach would require higher-order RDMs . B. Wavefunctions Suitable for Externally Corrected CC In this section we discuss the characteristics of a quantum trial and the potential benefit over classically accessible wavefunctions as input to ec-CC . Within the NISQ setting there is no shortage of methods for preparing approximate ground states.5,6,82,84–95 If we consider fault-tolerance , an even wider set of methods is available.96–102 Here we emphasize recent work from Magoulas et al.79 which provides a framework for analyzing types of CI expansions , i.e. , the source of the external cluster amplitudes , that potentially yield an improved ec-CC energy . That work servers as a blueprint for the type of wavefunction that a quantum computer would need to prepare to potentially see an energy improvement through solving the ec-CC equations . At the core of their derivation is the following theorem : Theorem III.1 . The solution to a truncated configuration interaction set of equations which includes full singles , full doubles , and any set of higher excitations satisfies the coupled cluster singles and doubles equations . 600 500 CCSD CASCI NEVPT2 TCCSD VQE VQE-TCCSD ] h E m [ 400 y g r e n E 300 e v i t a e R l 200 100 0 ] h E m [ r o r r E I 101 100 C S A C 10 1 ] h E m [ t x e E 220 240 260 0.8 1.2 1.6 2.0 2.4 2.8 0.8 1.2 1.6 2.0 2.4 2.8 R [ Å ] R [ Å ] 7 They prove this theorem algebraically and diagrammatically . We have reproduced the algebraic proof in Ap- pendix A 3 for completeness . A key takeaway is that in order for the ec-CC equations to provide an improvement over CI expansions one must only include the connected components – i.e. , rank three and four cluster amplitudes with non-zero CI-ampltiudes . Furthermore , to see improvement over CI expansions via ec-CC requires a CI expansion that includes some but not all triple and quadruple excitations . This suggests that a quantum circuit exploring dominant many-body excitations for a large system can be a useful input to ec-CC . Supporting this interpretation are the clas- sical studies using FCIQMC as an external source and other methods that sample high-energy Slater determinants.77 While the connection to truncated CI should not be considered too strongly as an analogy for quantum circuits , it does provide support for the use of particular quantum circuits that sample high-energy many-body excitations . This new perspective serves as a different design principle when constructing quantum circuit ansatze with the potential for beyond classical computation . The connection rules out quantum state ansatze where it is efficient to estimate amplitudes up to additive error such as a circuit built from a fixed bond dimension MPS . No comparably generally statements can be made about when quantum inputs can be useful for TCC or ec-CC in an active space . IV . QUANTUM MEASUREMENT OF OVERLAPS | ⟩ ⟩ ΨT ΨT ΨT | ΨT | In the quantum CC methods proposed here , the input amplitudes are determined from quantum state overlaps with the help of a quantum computer . When a Jordan-Wigner mapping of fermions to qubits is used , the Slater determinant overlaps correspond to overlaps with computational basis states . As the non-relativistic second-quantized molecular Hamiltonian can , without loss of generality , be chosen to be real when written in the computational basis , the eigenstates are real , so that if a suitable state preparation method is used , all overlaps with computational basis states should be real . However , since the signs of the overlaps enter the cluster analysis , sampling the quantum trial state on n qubits with ζ electrons in the computational basis is not sufficient . Various methods are known that can be used to estimate overlaps including signs . A family of methods suitable for the task that has received a lot of attention recently are classical shadows26 and extensions of this technique geared specifically towards the fermionic setting.22,23,25 All these methods have in common that , given a state , one draws unitaries U from some ensemble of classically efficiently describable unitaries . A description of the drawn unitaries together is recorded as a so-called classical with the results of computational basis state measurements in the state U shadow . From this classical shadow , one can , using purely classical computation , predict various properties of the state . Particularly relevant for our work is the protocol from Ref . 25 which is based on an ensemble of matchgate ⟩ circuits ( Haar measure over general fermionic Gaussian unitaries ) , which allows to estimate all overlaps with Slater ( √n log ( n ) /ϵ2 ) quantum measurements or shots . determinants up to additive error ϵ from shadows consisting of s ζ/2 ) 4/ϵ2 ) The fully parallelizable classical computational effort per overlap scales as ζ/2 ) 3 scaling are possible , see Appendix D of Ref . 25 ) . For this protocol , one needs to prepare ( improvements to a ( n ΨT . If the state preparation method preserves a superposition of a reference state ( e.g. , the true vacuum ⟩ | the fermion number , this can be achieved by applying the circuit that prepares from the Hartree-Fock state ( log ( ζ ) ) by using Φ0⟩ | a single Hadamard gate and replacing the other Pauli X gates needed to prepare by their controlled versions ( CNOT ) . Alternatively one can use the classical shadow protocol from Ref . 23 , which randomizes only over number- preserving ( passive ) Gaussian unitaries U and allows to compute all overlaps to error ϵ from shadows consisting of 2/3 ) shots ( which is independent of n and ζ ) or the Clifford shadow protocol from Ref . 27 , which also just s has an n-independent sample complexity , however scaling with the logarithm of the number of overlaps . In the first case , due to number preservation of the passive Gaussian unitaries , the superposition with the reference state must be prepared on an enlarged set of up to 3n/2 qubits in the worst case of half-filling ζ = n/2 . In the second case , the classical processing of the shadow data is efficient for computational basis state overlaps required by our method ( just not for overlaps with general Slater determinants ) .27 In our numerical simulations , we focus on the matchgate shadow protocol from Ref . 25 , which has the worst scaling of the required number of shots among the three alternatives . This means that the shot budgets reported here can asymptotically be thought of as upper bounds and probably be further improved upon for finite n. n. This state can be prepared in depth ⊗ to a state that is a superposition of ⟩ Φ0⟩ | ( √n log ( n ) ( n n ) and ⊗ ζ/2 ) 4 ) = Φ0⟩ | ΨT | ( 4ϵ− ( s ( n 0 ⟩ | 0 ⟩ | ∈ O ∈ O and O O O − − − ⟩ | A . Statistical Properties of Matchgate Shadow Overlaps We implemented the matchgate shadow protocol in order to study the statistical properties of finite shot overlap measurements , summarized in detail in Appendix C 1 . From our numerical simulations , we obtained the following findings : 1 . ) The overlap estimates are approximately normal distributed , 2 . ) the covariance matrix of overlap measurements is diagonally dominant , and the covariances vanish asymptotically faster than the variances with 8 increasing s , and scatter plots ( see Fig . C.1a in Appendix C 1 ) confirm that the overlap estimates are close to independently distributed for large s , 3 . ) the spread of the variances decays faster than the mean variance , meaning that for large s , all overlap estimates have approximately the same variance , and 4 . ) the numerically observed mean variance ¯σ2 agrees well with the analytical performance guarantees from Ref . 25 ( see Appendix C 1 for more details ) . For the case of half-filling , ζ = n/2 , we numerically found the simple relation ¯σ2 ⪅ √2n/s . ( 8 ) Ultimately , this allowed us to build a synthetic noise model , in which we can efficiently add Gaussian noise with variance ¯σ2 to classically computed exact overlaps to “ mimic ” matchgate shadow overlap measurements without having to classically simulate the entire shadow protocol . In the next section , we use the synthetic noise model to estimate the number of quantum measurements s in order to reach chemical precision for sizeable systems , which are intractable on current quantum devices . Given a finite shot shadow , one can estimate overlaps and the variance of these estimates . This enabled us to build a classical post-processing scheme to screen out overlaps that were not statistically significantly determined , improving the results of ec-CC in Section V. B . Shot Noise Resilience and Quantum Resources for Tailored Coupled Cluster ( a ) ( b ) ( c ) FIG . 4 : Fitted power law prefactors a for each molecule at fixed global exponents ( a ) , Diagnostic values for each molecule ( b ) , scatter plot of the prefactor a vs. the diagnostic values including a linear fit ( c ) . 17.5 15.0 12.5 a 10.0 7.5 5.0 2.5 0.0 p-B e n zy n e 2 ( stretc h e d ) F 2 ( stretc h e d ) Cl2 ( stretc h e d ) N F 2 2 N H Global Fit Mean 2 O M e-N C O B e n ze n e For m ald e h y d e Cl2 Fura n A c etald e h y d e Molecule 1 1 0.125 0.100 0.075 0.050 l e u a V c i t s o n g a D i 0.025 0.000 p-B e n zy n e 2 ( stretc h e d ) F 2 ( stretc h e d ) Cl2 ( stretc h e d ) N F 2 2 N H 2 O M e-N C O B e n ze n e For m ald e h y d e Cl2 Fura n A c etald e h y d e Molecule R 2 = 0.96 R 2 = 0.75 20 15 10 a 5 0 0.000 0.025 0.050 0.05 0.10 1 1 9 The purpose of this section is to analyze the finite shot budget for matchgate shadows in order to obtain ( noisy ) quantum TCCSD energies for molecular systems to a given precision . The observation that noisy overlaps extracted from the matchgate shadow protocol are independent and identically distributed random variables with an underlying normal distribution greatly facilitates the construction of an error model of the TCCSD energy , since we do not need to record many finite shot shadows . Rather , one can take the exact overlaps from a classical CASCI calculation and subsequently draw the noise of a given distribution with standard deviation or noise strength σ , and add it to the exact overlaps . Subsequently , we compute the “ noisy ” TCCSD energy without having to simulate a single quantum circuit . Ultimately , the goal is to find a heuristic model for the shot budgets , which will incorporate a ) the dependence of the error on the noise strength σ , which can be directly related to the shot budget via the variance bound published by Wan et al.,25 and b ) system/molecule-specific parameters ( number of spin orbitals , active space size , etc . ) making it possible to estimate the quantum resources across a broad range of molecules of interest without having to perform the actual sampling of the TCCSD error for that system . The details of our analysis and construction of the empirical error model are explained in detail in Appendix C. The quantity we want to extrapolate using only pre-defined system parameters and the noise strength is the absolute TCCSD energy error caused by noise , . Due to the relation with the noise strength , it will then be possible to substitute σ with the variance bound in eq ( 8 ) , , we can directly obtain a which in turn contains the shot budget s. Thus , if we can convincingly model , and the system-specific parameters , which we will outline in shot budget given the desired accuracy in the following . Most importantly , we tested the dependence of ( for a given system ) on the noise strength while keeping all other influential parameters ( basis set , etc . ) fixed . This analysis revealed a linear dependence of ∆Enoise on σ , i.e. , the TCCSD energy error is proportional to the underlying noise strength . The linear relationship 1 ) , the was observed consistently for different systems and active space sizes . Even at high noise strengths ( σ = 10− ( cid:12 ) TCCSD calculations converged , indicating that the procedure is robust even when tailored with almost random ( cid:12 ) overlaps . With the linear dependence on σ at hand , we sought to incorporate molecule/system-specific parameters ∆Enoise ∆Enoise ∆Enoise ∆Enoise TCCSD TCCSD TCCSD TCCSD TCCSD ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) precision in different correlation regimes , as indicated by the FIG . 5 : Extrapolation of the shot count s needed for determining the quantum TCCSD energy to milli-Hartree T1 diagnostic . The data were generated for a system with N = 600 orbitals and half-filled active spaces ζ = n/2 . Shaded regions correspond to power laws with the smallest and largest exponents ( i.e. , estimator standard deviation , respectively ) . ± into an extended extrapolation model for . We composed a set of molecular systems , basis sets , and active space sizes and sampled the TCCSD energy for these systems at a given noise strength , such that we could afterwards find the system-dependent variables that explain trends in the error best . From analysis of the sampled data set , we concluded that the total number of overlaps d that are put in to the TCCSD calculation , which directly depends on n and ζ , i.e. , the chosen active space size ( see Appendix C 3 ) , and the total number of spin orbitals of the system N yield good results in a power law fit over the whole data set . The power law is given by TCCSD ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ∆Enoise ∆Enoise TCCSD = a dβN γσ . ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( 9 ) 1 0.05 1 0.015 1 < 0.015 108 106 s 104 102 101 102 n 10 The exponents of d and N in the power law seem to be largely independent of the chosen molecular system . The 0.054 , shows that the error due to noisy amplitudes increases with the size of exponent of d , given as β = 0.277 ± 0.116 , such that the absolute error 1.074 the active space , as expected . The exponent of N is approximately γ = decreases when the total size of the MO space increases . This makes sense , because the active space contribution to the total energy decreases when the relative size of the external space increases . − ± T1 and The prefactor a encodes system-specific variables that were omitted by our choice of d and N as the most im- portant general quantities . We noticed that the stronger the static correlation in the system was , the larger was the corresponding prefactor a in a per-molecule fit with fixed exponents for β and γ . The per-molecule prefactors are depicted in Figure 4 . We found that the prefactor a across the molecule test set correlates with the well-known D1 ( see Fig . 4 ) .28,29 These diagnostic values are typically used to quantify whether CCSD diagnostic values , a single-reference CCSD wavefunction is reliable , or whether one should opt for a MR treatment of the system . The T1 to T1 values correlate best with the molecule-specific prefactor a ( Fig . 4 ) , and we use a linear fit to convert from a ( fit parameters are shown in Appendix C 3 ) . The empirical error extrapolation model takes into account the following quantities ; i ) the noise strength σ , given through the variance bound in eq ( 8 ) , ii ) the number of overlaps d , required for TCCSD , which depends on the size of the chosen active space , iii ) the total number of spin orbitals in the system N , and iv ) the prefactor a of the power law , derived from the T1 diagnostic through a plain CCSD calculation . Of course , the empirical model is far from general , however , it may give some guidance for the error level one can expect in a TCCSD calculation based on noisy overlap measurements . Inserting the variance bound ( eq ( 8 ) ) into the power law , one can rearrange the equation for the matchgate shadow shot budget at half-filling , s ⪅ a2 ∆Enoise TCCSD 2 d2βN 2γ√2n . ( 10 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) TCCSD TCCSD = 10− ∆Enoise ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ∆Enoise with the other parameters obtained The shot budget s can then be computed for a target accuracy 3 Eh as the required from the fit and the molecule/setup-specific values . In the following , we set “ chemical precision ” . Note that this shot budget is just assigned for the overlap measurements through matchgate shadows and does not take into account the shot budget for , e.g. , state preparation or optimization . Furthermore , the Gaussian error model is herein applied to the exact overlaps from a CASCI trial wavefunction . For this reason , the error model just covers errors in the overlap measurements but not the imperfections in the wavefunction we have discussed in the previous section . Since the error model is independent of the underlying state , however , both error contributions can be studied separately . We computed the values for s for a fictitious system with an MO space of N = 600 , for half-filling active spaces from n = 4 to n = 200 qubits with ζ = n/2 electrons . To cover different correlation regimes , the shot budgets were obtained for three ranges of 0.015 , and 0.05 , as plotted in Figure 5 . The shaded areas around the solid lines in the plot include the worst/best-case T1 ≈ scenario , where the standard deviations of the exponents have been added/subtracted . The strongly correlated case , 0.05 , corresponds to a system like N2 with a bond distance of 2.8 ˚A , i.e. , an extreme case for MR character . The T1 ≈ mixed/balanced case , T1 is around 0.02 ) , corresponds to a system like p-Benzyne , and the weakly correlated case to something like closed-shell organic molecules . For the balanced case , the shot counts range from approximately 103 for 4 qubits to less than 107 for 200 qubits . The uncertainty of these numbers is given through the standard deviation of the exponent fit parameters , and amounts to approximately one order of magnitude in each direction . 0.015 , where CCSD is almost not reliable anymore ( usually the threshold for T1 < 0.015 , T1 , i.e. , T1 ≈ T1 ≈ ( cid:12 ) ( cid:12 ) C. Quantum Resource Estimates for Nitrogen Dissociation Coming back to the test case in the previous section , we computed the total shot budgets to obtain the N2 dissociation curve with chemical precision in a noisy TCCSD setup . The shot budget per point on the dissociation curve is given in Figure 6 . While the number of overlaps and the number of spin orbitals is of course identical on T1 increases and thus the shot budget is adjusted accordingly . each point on the potential energy surface , the value of Note that the shot budget grows quadratically in T1 , and the total shot budget for all 21 bond distances is dominated by the strongly correlated regime for R > 1.7 ˚A , as expected . We note that the shot budget for obtaining the entire dissociation curve in 0.1 ˚A increments is less than 3 107 . We think it is remarkable that so few shots are sufficient to obtain an energy estimator that includes dynamic correlation correction effects since , even when advanced methods such as regularized compressed double factorization21 or fluid fermionic fragments103 are employed , measuring just the bare active space VQE energy typically requires a comparable number of shots . Measurements of 2RDMs , let alone sufficiently high quality higher-order RDMs , can be expected to require significantly more shots . Our estimate does not include error mitigation overheads , but is a very feasible shot count on present-day quantum hardware , as is × 11 FIG . 6 : Estimated shot budget s for N2/cc-pVDZ/CAS ( 6,6 ) to achieve milli-Hartree precision in the TCCSD energy T1 , obtained from as a function of the internuclear distance R along the dissociation curve . The value of CCSD/cc-pVDZ , determines the increase in s , according to eq ( 10 ) . The total shot budget amounts to approximately 30 million shots . Raw data are shown in Table C.5 . testified by the fact that more shots were taken for individual echo-verified data points in Ref . 104 . For a complete comparison , a thorough investigation of the shot counts needed for PT-based methods for treating dynamic correlation using higher-order RDMs would be desirable , but this is beyond the scope of this work . Additionally , it would be interesting to numerically analyze quantum state preparation techniques other than VQE in the context of TCCSD in future work . D. Resilience to Device Noise The combination of how overlaps are input into the split amplitude methods considered here with how they are determined in the matchgate shadow protocol25 leads to a further noteworthy built-in error mitigation property of the resulting method . To see this , we first need to recount how overlaps are measured from shadows . When recording n , then one aims to prepare the state 0 the shadow one picks a reference state such as the true vacuum ⊗ | ) /√2 on the device and finally takes computational basis state measurements after random Gaussian ρ | φ rotations . From the shadow obtained in this way the sought-after overlap with a computational basis state is then | ⟩ computed as the expectation value of the non-Hermitian observables ρ ] . If this φ ⟩⟨ | state preparation is noisy so that instead of the state ρ = p ) ρ + p ρnoise ρ ⟩ ⟨ for some error probability p and density matrix ρnoise , one has = 2 Tr [ the device prepares the state ˜ρ = ( 1 , using that φ | = ( | 0 | − ΨT | 0 ⟩ | 0 ⟩ 0 | ΨT ρ | ⟩ ⟨ = + φ ⟨ ⟩ ⟩ ⟩ ⟩ | | 2 Tr [ 0 | ˜ρ ] = ( 1 φ | p ) φ ΨT + p φ ⟨ ρnoise| | . 0 ⟩ − For several reasonable types of noise , including depolarizing noise , bit flip noise , and amplitude damping 0 ⟩ will be either zero or very small for all states from a subspace containing a reasonable number of particles ζ . This means that overlaps such as those in eqs ( 3 ) and ( 4 ) can , because of the intermediate normalization of ΨAS be very well approximated by quotients of overlaps computed from the shadow of the noisy | state . For the overlap in eq ( 3 ) , one has for example ρnoise| | ΨT | Φ0 | φ ⟩ | φ ⟨ / ⟨ ΨT ⟩⟨ = ⟨ ⟩ ⟩ ⟩ ⟩ | ( 11 ) ca i = ΨAS Φa i | ⟨ ⟩ Φa i | = ⟨ Φ0 | ⟨ ΨT ΨT ⟩ ⟩ ≈ 0 Tr [ | 0 Tr [ | ⟩⟨ ⟩⟨ Φa i | Φ0| ˜ρ ] ˜ρ ] , ( 12 ) p ) in the enumerator and denominator cancel . Even estimation from a finite because the common factors of 2/ ( 1 ΨT shot shadow should thus work well as long as ( 1 does not become too small ( see Appendix D.6 of Ref . 27 | for similar consideration ) . Contrary to this , without error mitigation techniques , expectation values such as that of , e.g. , the electronic structure Hamiltonian , are usually first order sensitive to the noise strength p. φ ⟨ p ) − − ⟩ A further major concern in several platforms are particle number dependent phases that can be caused , e.g. , by background magnetic fields . These are often particularly problematic for algorithms that prepare cat-like coherent superpositions of states of markedly different particle number such as . However , since we know that the input ⟩ overlaps are all real and we are only interested in getting the relative signs of the coefficients , which are quotients of overlaps , correct and the computational basis state overlaps going into the enumerator all come from the same particle ρ | 106 s 105 104 0.04 0.03 1 0.02 0.01 0.8 1.2 1.6 2.0 2.4 2.8 R [ Å ] 12 number sub-space , a particle number dependent phase results in a global phase affecting all coefficients , which can be easily corrected . One possible way of doing this is to rotate the coefficients in the complex plane such that the largest coefficient or the principle component of all overlaps or is aligned with the real axis before either discarding the imaginary part or taking the absolute value multiplied with the sign of the real part of each coefficient . This renders our methods largely independent of uncontrolled particle number dependent phases and also implies some robustness against general phase errors . V. SPLIT-AMPLITUDE CC ON QUANTUM HARDWARE In this section , we showcase how externally corrected CC performs on inputs obtained from actual quantum hard- ware . For this purpose , we revisit the ground state energy of H4/STO-3G arranged in a square geometry with bond distances of 1.23 ˚A , which was previously studied with QC-QMC in Ref . 27 . Quantum overlaps were measured with Clifford shadows on Google ’ s Sycamore superconducting quantum processor.105 In this hardware experiment , the state preparation for H4/STO-3G on 8 qubits corresponds to preparing the exact FCI state . The overlaps , obtained from a Clifford shadow protocol,22 were then used to drive a QMC calculation . Due to device and shot noise , the measured overlaps of course do not exactly reproduce FCI overlaps , making it an interesting test case for studying noise robustness of ec-CC . For details on how the experimental shadow data were processed , see Appendix D. The FIG . 7 : Post-processing protocol for quantum ec-CC . Overlaps measured in the classical ( matchgate ) shadow protocol are first filtered based on variance , and set to zero if the overlap estimator has a too large variance . After that , the cluster analysis is performed on the filtered overlaps , cluster amplitudes up to and including T4 . Then , purely disconnected T3 and T4 amplitudes are disconnected , yielding a so-called “ Type-II ” ec-CC calculation in the end.79,80 quantum trial state prepared on the device ( Q trial ) first had to be converted to a wavefunction with real-valued coefficients ( Q trial real , see Appendix D ) before use with ec-CC . The Q trial state was recorded four times with different number of sampled Cliffords , NCliffords , in the original experiment , and we used the best two repetitions in terms of root mean-square error of the reconstructed wavefunction with respect to FCI ( the results are qualitatively unchanged when all four runs are included , but the bands depicting uncertainty become unnecessarily wide ) . Note that , for hardware reasons , the circuit for each group element was executed 1,000 times , yielding a so-called mulit- shot/thrifty106,107 shadow . To complement the hardware data , we simulated a matchgate shadow ( 30 repetitions ) taken on the FCI wavefunction with both a single shot and 1,000 shots per group element . Furthermore , we devised a classical post-processing protocol , illustrated in Figure 7 , to ascertain certain properties of the wavefunction extracted from the device . Therein , we filter overlaps based on their variance and set them to zero if a certain variance threshold for the measurement is not fulfilled , i.e. , the overlap was not determined reliably enough . In the given experiment , we set overlaps to zero if the overlap value is larger than 2 σ . After that , we perform the usual cluster analysis which then might contain purely disconnected T3 and T4 due to the variance-based thresholding , or due to the underlying wavefunction . In the spirit of “ Type-II ” ec-CC input,79,80 we discard all purely disconnected T3 and T4 amplitudes and subsequently perform the ec-CC calculation . The absolute energy error with respect to FCI as a function of the total number of shots ( i.e. , number of group elements times number of circuit executions per group element ) are shown Classical Shadow Filter overlaps based on variance Cluster Analysis Discard purely disconnected T3/T4 ec-CC Calculation 13 FIG . 8 : Energy error of trial state ( Q trial ) , Q trial converted to real wavefunction ( Q trial real ) , ec-CC with different shadow protocols , and QC-QMC with respect to FCI . Averages from two repetitions are shown , where the shaded areas indicate the 95th percentile . Results based on experimental data from Ref . 27 are drawn a solid lines , results from simulated matchgate shadows with only shot noise are drwan as dashed lines . The CCSD energy error ( 7.05 mEh ) and the limit for chemical precision ( 1 mEh ) are shown for comparison . Without circuit noise , the Q trial state would correspond to FCI . Raw data are shown in Tables D.1 , D.2 , and D.3 . in Figure 8 , including the results for Q trial and QC-QMC from Ref . 27 . For more than 106 shots , the experiment is no more shot-noise-limited . In this limit , ec-CC and QC-QMC energy errors are less than 1 mEh , i.e. , chemical precision is reached , whereas the plain variational energy of the trial state and its purely real counterpart does not 105 ) the reach the same level of accuracy . Our post-processing protocol ensures that for too few shots ( up to about 2 × FIG . 9 : Number of sign errors ( upper panel ) and non-zero errors ( lower panel ) in the overlap measurements depending on the number of Cliffords , NCliffords , in the H4/STO-3G experiment on 8 qubits , grouped by two runs of the experiment . Non-zero errors are defined as overlap values that should be numerically zero ( in the FCI vector ) , but are larger than a given numerical threshold of 10− 6 in the shadow-based measurements . results are never worse than plain CCSD . To understand this behavior , we analyzed the type of errors that can occur in overlap measurements , namely sign errors and non-zero errors . The latter refer to an overlap value which should 100 10 1 ] h E [ 10 2 r o r r E y g r e n E 10 3 10 4 Method Q trial Q trial real ec-CC ( multi Clifford ) ec-CC ( multi Matchgate ) ec-CC ( single Matchgate ) QC-QMC ( multi Clifford ) Type Experiment Simulation CCSD chem . prec . 104 105 106 107 Total Number of Shots 8 6 4 2 s r o r r E i n g S # 0 s r o r r E o r e Z - n o N # 12 10 8 6 4 2 0 1 0 1 6 2 8 4 7 8 0 1 3 6 Experiment 1 2 1 1 0 0 6 5 2 3 8 7 2 2 9 NCliffords 1 8 5 6 3 1 2 9 5 2 7 6 1 5 0 0 0 8 8 9 6 14 be numerically zero ( in this case , the corresponding value in the CI vector is zero ) , but is measured to be non-zero . The sign and non-zero errors for the two experimental runs of the H4/STO-3G experiment are summarized in Figure 9 . Sign errors completely vanish at NCliffords = 387 , which perfectly coincides with the points on the energy error curve where improvements over CCSD are observed . The non-zero errors do not decay as rapidly as the sign errors , and some elements are still measured with a non-zero value for rather large number of sampled group elements . Thus , sign errors seem to be most severe and affecting the quality of the input overlaps for ec-CC , but those errors quickly disappear completely when the total number of shots is moderate , i.e. , chemical precision is only reached for even more shots . Making the wavefunction real removes ambiguities because of the non-measurable global phase and is a necessity because coupled cluster with a real molecular Hamiltonian requires real amplitude inputs . In addition , it seems to improve the quality of the trial wavefunction energy . ec-CC on the experimental data does not seem to quite reach the accuracy of QC-QMC , but gets close and drastically improves over the ( real ) Q trial energy by a factor of 5 and 25 , respectively , as well as about a factor of 10 over the plain CCSD energy . It is reassuring that ec-CC is competitive with QC-QMC in this setting since we are certain that , due to the wavefunction quality , ec-CC must improve over the plain trial state energy . The comparison with the simulated matchgate shadow data shows that , with both shadow protocols , chemical precision can be reached with a comparable number of group elements and shots . The 1,000 shots multi-shot variant only needs roughly 10 times more shots at 100 fewer distinct circuits , making it attractive on hardware where changing the circuit incurs a run time overhead . We attribute the generally better performance on simulated data to the absence of gate and detection noise . FIG . 10 : Error in total energy as a function of the lattice constant of a minimal cell diamond ( DZVP-GTH basis with 26 orbitals ) . The quantum trial state is prepared on an active space of 16 qubits using a perfect-pairing wavefunction , as explained in detail in Ref . 27 . Raw data are shown in Table D.4 . The plot is split up in two panels with different vertical axis limits to show the whole range of energy errors . The gray area in the lower panel indicates the bounds for chemical precision of 1 kcal/mol . Data for Q trial , AFQMC , and QC-QMC are reproduced from Ref . 27 . The “ / ” notation in the plot legend indicates the input wavefunction for the respective method , i.e. , ‘ Q trial ‘ from the device or a classically simulated exact CAS ( 8,8 ) . Note that for the lattice constant of 3.24 ˚A , the results for ( real ) Q trial are not visible on the depicted energy scale . For high values of the lattice constant , only TCCSD based on CAS ( 8,8 ) and NEVPT2 achieve chemical precision , however , all quantum split-amplitude methods run on the hardware data significantly improve the energy of the prepared trial state . As a second example run on actual hardware , we study the energy of a minimal diamond unit cell ( two carbon atoms ) in a double-zeta basis ( GTH-DZVP ; 108 26 orbitals , with GTH-PADE109 pseudopotential , only Γ point in Brillouin zone sampling ) as a function of the lattice constant . In Ref . 27 , the quantum trial corresponded to a 16-qubit active space perfect-pairing ( PP ) wavefunction , and the computational basis state overlaps were obtained 350 300 250 200 150 100 50 15 15 10 5 0 5 ] l o m / l a c k [ y g r e n E l a t o T n i r o r r E 2.8 3.2 3.6 Lattice Constant [ Å ] 4.0 4.4 Q trial Q trial real ec-CC / Q trial TCCSD / Q trial QC-QMC / Q trial CAS ( 8,8 ) ec-CC / CAS NEVPT2 TCCSD / CAS CCSD ( T ) AFQMC 15 using the Clifford shadow protocol , sampling 50,000 group elements for each lattice constant . In addition to the methods used in Ref . 27 , we computed the single-point energy for each lattice constant using ec-CC and TCCSD on the real-valued quantum trial state , CAS ( 8,8 ) ( i.e. , the exact solution to the given active space problem ) , ec-CC and TCCSD on the exact CAS state , and NEVPT2 for comparison . The results are shown in Figure 10 . In comparison with the H4 hardware experiment , two factors limit the performance guarantees of ec-CC : 1 ) the fact that we are dealing with an active space wavefunction , such that we do not have any convergence guarantees to the true FCI result in the limit of exact external T3 and T4 amplitudes , and 2 ) the quantum trial PP state is a CC-like wavefunction , which does not accurately treat higher-order excitations as would be beneficial for ec-CC . The results for quantum ec-CC on the quantum trial state never reach chemical precision , and the error is between approximately 5 and 15 kcal/mol . This is comparable with the results from plain AFQMC . Even when the exact CAS ( 8,8 ) wavefunction is used to construct the T3 and T4 amplitudes , the energy error only marginally improves over the quantum input one . This strongly hints that the “ truncation ” of T3 and T4 stemming from an active space is of course preventing more accurate ec-CC results . The performance of quantum TCCSD tailored with the quantum trial state is even worse , since the energy error is larger than 15 kcal/mol for all values of the lattice constant . Still , for both split-amplitude methods executed with actual quantum trial states , the energy error is vastly better than the variational energy of the quantum trial state ( for the value at 3.24 ˚A , it is literally off the charts ) . Interestingly , the energy error of a plain CAS ( 8,8 ) , due to neglect of dynamic correlation effects , is worse than that of the quantum split-amplitude methods . The only methods in our setup that reach chemical precision for all values of the lattice constant are TCCSD tailored with CAS ( 8,8 ) and NEVPT2 . The energy error observed for those two methods is almost identical . TCCSD thus provides vastly better results when tailored with the exact active space wavefunction than with the PP quantum trial state . This is expected , since the CC-like PP wavefunction can not yield a better result in this case than plain CCSD on the full orbital space . Even though there are no strict theoretical requirements for input wavefunctions to TCCSD , this is a case which is expected to fail based on the properties of the quantum trial . The fact that ec-CC uses a post-processing protocol for the input amplitudes could explain why it performs better than TCCSD on actual hardware data . From the perspective of classical electronic structure methods , the performance of TCCSD with CAS is on par with NEVPT2 , which is encouraging . We conclude that ec-CC of course was not expected to work well , or even better than QC-QMC , in the active space and PP quantum input setting , which was corroborated by our numerical results . Nonetheless , the split-amplitude methods provide a massive improvement in absolute energy error even when seeded with noisy quantum input . VI . CONCLUSIONS In this work we proposed to use overlaps obtained from a quantum computer by means of classical shadows as inputs to split-amplitude CC methods tailored coupled cluster ( TCC ) and externally corrected coupled cluster ( ec-CC ) . The resulting combinations of methods can be seen as a way of adding dynamic electron correlation corrections onto active space trial states prepared on a quantum computer . These methods can further be viewed as a way of curing failures of plain single-reference coupled cluster theory ( such as the appearance of virtual reaction barriers ) by taking into account properties of a multi-reference wavefunction prepared on a quantum computer , while avoiding the dramatic increase in classical computational complexity of classical multi-reference coupled cluster methods . We showed that the combination of methods displays a range of desirable properties : 1 ) The dynamic correlation correction along the N2 dissociation curve and for a stretched diamond cell is found to be comparable in quality to NEVPT2 and remarkably robust against systematic imperfections in the prepared active space wavefunction , as may arise from too shallow VQE circuits . 2 ) One can predict the number of repetitions ( shots ) required to obtain accurate results from established correlation diagnostics that are classically efficiently obtainable from CCSD calculations . 3 ) Extrapolating these resource estimates to the classically no longer exactly solvable regime , we found remarkably low shot counts , which we attribute to the fact that measurement of expensive intermediates such as higher-order reduced density matrices is avoided . 4 ) When tested with overlaps measured on real quantum hardware , our method provided results with an accuracy comparable to QC-QMC for the ground state energy of H4 in a minimal basis . 5 ) The expensive classical part of the computation can be performed with standard coupled cluster codes , opening the possibility for further speedups with , e.g. , DLPNO . 6 ) In particular ec-CC ( and to a lesser degree TCC ) seems to have some built-in error mitigation abilities , producing energies that can be as good as CASCI or AFQMC , respectively , even from very noisy trial state amplitudes . We analyzed the statistical properties of overlaps computed from matchgate shadows25 and numerically corroborated the validity of a Gaussian noise model that may be of general interest . Furthermore , the quantum split-amplitude methods are fully agnostic of the measurement scheme . Hence , the quantum resource estimates provided in our present work can most likely be improved upon using shadow protocols with lower sample complexity . It would thus be interesting to see if similar noise models hold for other classical shadow protocols . In particular , the particle-number-preserving shadow protocol from Ref . 23 promises to make the required number of 16 shots to obtain overlaps at a given precision independent of the number of qubits at the expense of an overhead in circuit depth and number of qubits . It will be important to explore these trade-offs further . Another possible direction is to combine the methods proposed here with shadow-based error mitigation methods.110–112 While the shot counts we find for the quantum split-amplitude CC methods seem very low , even when comparing to typical shot counts needed to just compute the energy of bare electronic structure Hamiltonians on quantum wavefunctions , a detailed analysis of the shot counts needed to obtain similar quality energies via perturbative methods such as NEVPT2 from higher-order RDMs measured either from shadows or directly remains outstanding . For ec-CC , we were able to give some hints for what kind of wavefunctions could yield a quantum advantage and hope that this can inspire future work on VQE ans¨atze and other state preparation schemes . Finally , it would be interesting to extend TCCSD with T3 amplitudes from the active space as suggested in the original TCC work,2 and to compute other molecular properties with split-amplitude methods . We acknowledge fruitful discussions with William J. Huggins , Eugene DePrince III , Fotios Gkritsis , Robert M. Par- rish , and Pauline J. Ollitrault . ACKNOWLEDGEMENTS [ 1 ] S. McArdle , S. Endo , A. Aspuru-Guzik , S. C. Benjamin , and X. Yuan , Quantum computational chemistry , Reviews of Modern Physics 92 , 015003 ( 2020 ) . [ 2 ] T. Kinoshita , O. Hino , and R. J. Bartlett , Coupled-cluster method tailored by configuration interaction , The Journal of chemical physics 123 , 074106 ( 2005 ) . [ 3 ] J. Paldus , Externally and internally corrected coupled cluster approaches : an overview , Journal of Mathematical Chem- istry 55 , 477 ( 2017 ) . [ 4 ] T. Takeshita , N. C. Rubin , Z. Jiang , E. Lee , R. Babbush , and J. R. McClean , Increasing the representation accuracy of quantum simulations of chemistry without extra quantum resources , Physical Review X 10 , 10.1103/physrevx.10.011004 ( 2020 ) . [ 5 ] A. Peruzzo , J. McClean , P. Shadbolt , M.-H. Yung , X.-Q . Zhou , P. J . Love , A. Aspuru-Guzik , and J. L. O ’ Brien , A variational eigenvalue solver on a photonic quantum processor , Nature Communications 5 , 10.1038/ncomms5213 ( 2014 ) . [ 6 ] J. R. McClean , J. Romero , R. Babbush , and A. Aspuru-Guzik , The theory of variational hybrid quantum-classical algorithms , New Journal of Physics 18 , 023023 ( 2016 ) . [ 7 ] A. Tammaro , D. E. Galli , J. E. Rice , and M. Motta , N-electron valence perturbation theory with reference wave functions from quantum computing : Application to the relative stability of hydroxide anion and hydroxyl radical , The Journal of Physical Chemistry A 127 , 817–827 ( 2023 ) . [ 8 ] U. Baek , D. Hait , J. Shee , O. Leimkuhler , W. J. Huggins , T. F. Stetina , M. Head-Gordon , and K. B. Whaley , Say no to optimization : A nonorthogonal quantum eigensolver , PRX Quantum 4 , 030307 ( 2023 ) . [ 9 ] M. Krompiec and D. M. Ramo , Strongly contracted n-electron valence state perturbation theory using reduced density matrices from a quantum computer , arXiv preprint arXiv:2210.05702 ( 2022 ) . [ 10 ] Y. Kawashima , E. Lloyd , M. P. Coons , Y. Nam , S. Matsuura , A. J. Garza , S. Johri , L. Huntington , V. Senicourt , A. O. Maksymov , et al. , Optimizing electronic structure simulations on a trapped-ion quantum computer using problem decomposition , Communications Physics 4 , 245 ( 2021 ) . [ 11 ] M. Rossmannek , P. K. Barkoutsos , P. J. Ollitrault , and I. Tavernelli , Quantum hf/dft-embedding algorithms for electronic structure calculations : Scaling up to complex molecular systems , The Journal of Chemical Physics 154 , doi.org/10.1063/5.0029536 ( 2021 ) . [ 12 ] W. Li , Z. Huang , C. Cao , Y. Huang , Z. Shuai , X . Sun , J . Sun , X. Yuan , and D. Lv , Toward practical quantum embedding simulation of realistic chemical systems on near-term quantum computers , Chemical science 13 , 8953 ( 2022 ) . [ 13 ] Y. Liu , O. R. Meitei , Z. E. Chin , A. Dutt , M. Tao , I. L. Chuang , and T. Van Voorhis , Bootstrap embedding on a quantum computer , Journal of Chemical Theory and Computation 19 , 2230–2247 ( 2023 ) . [ 14 ] N. He and F. A. Evangelista , A zeroth-order active-space frozen-orbital embedding scheme for multireference calculations , The Journal of Chemical Physics 152 , 10.1063/1.5142481 ( 2020 ) . [ 15 ] N. He , C. Li , and F. A. Evangelista , Second-order active-space embedding theory , Journal of Chemical Theory and Computation 18 , 1527 ( 2022 ) . [ 16 ] F. A. Evangelista , Perspective : Multireference coupled cluster theories of dynamical electron correlation , Journal of Chemical Physics 149 , 10.1063/1.5039496 ( 2018 ) . [ 17 ] R. Huang , C. Li , and F. A. Evangelista , Leveraging small-scale quantum computers with unitarily downfolded hamilto- nians , PRX Quantum 4 , 020313 ( 2023 ) . [ 18 ] W. J. Huggins , J. R. McClean , N. C. Rubin , Z. Jiang , N. Wiebe , K. B. Whaley , and R. Babbush , Efficient and noise resilient measurements for quantum chemistry on near-term quantum computers , npj Quantum Information 7 , 10.1038/s41534- 020-00341-7 ( 2021 ) . 17 [ 19 ] J. Cohn , M. Motta , and R. M. Parrish , Quantum Filter Diagonalization with Compressed Double-Factorized Hamiltonians , PRX Quantum 2 , 040352 ( 2021 ) . [ 20 ] S. Choi , I. Loaiza , and A. F. Izmaylov , Fluid fermionic fragments for optimizing quantum measurements of electronic Hamiltonians in the variational quantum eigensolver , Quantum 7 , 889 ( 2023 ) . [ 21 ] O. Oumarou , M. Scheurer , R. M. Parrish , E. G. Hohenstein , and C. Gogolin , Accelerating quantum computations of chemistry through regularized compressed double factorization , arXiv preprint arXiv:2212.07957 ( 2022 ) . [ 22 ] A. Zhao , N. C. Rubin , and A. Miyake , Fermionic Partial Tomography via Classical Shadows , Physical Review Letters 127 , 110504 ( 2021 ) , publisher : American Physical Society . [ 23 ] G. H. Low , Classical shadows of fermions with particle number symmetry ( 2022 ) , arXiv:2208.08964 [ quant-ph ] . [ 24 ] X. Bonet-Monroig , R. Babbush , and T. E. O ’ Brien , Nearly optimal measurement scheduling for partial tomography of quantum states , Phys . Rev . X 10 , 031064 ( 2020 ) . [ 25 ] K. Wan , W. J. Huggins , J. Lee , and R. Babbush , Matchgate shadows for fermionic quantum simulation , Communications in Mathematical Physics 404 , 629–700 ( 2023 ) . [ 26 ] H.-Y . Huang , R. Kueng , and J. Preskill , Predicting many properties of a quantum system from very few measurements , Nature Physics 16 , 1050 ( 2020 ) . [ 27 ] W. J. Huggins , B . A. O ’ Gorman , N. C. Rubin , D. R. Reichman , R. Babbush , and J. Lee , Unbiasing fermionic quantum Monte Carlo with a quantum computer , Nature 603 , 416 ( 2022 ) , number : 7901 Publisher : Nature Publishing Group . [ 28 ] T. J. Lee and P. R. Taylor , A diagnostic for determining the quality of single-reference electron correlation methods , International Journal of Quantum Chemistry 36 , 199 ( 1989 ) . [ 29 ] C. L. Janssen and I. M. Nielsen , New diagnostics for coupled-cluster and møller–plesset perturbation theory , Chemical Physics Letters 290 , 423 ( 1998 ) . [ 30 ] J . ˇC´ıˇzek , On the correlation problem in atomic and molecular systems . calculation of wavefunction components in ursell- type expansion using quantum-field theoretical methods , The Journal of Chemical Physics 45 , 4256 ( 1966 ) . [ 31 ] T. D. Crawford and H. F. Schaefer , An introduction to coupled cluster theory for computational chemists , Reviews in Computational Chemistry 14 , 33 ( 2006 ) . [ 32 ] I. Shavitt and R. J. Bartlett , Many-body methods in chemistry and physics : MBPT and coupled-cluster theory ( Cambridge University Press , 2009 ) . [ 33 ] G. D. Purvis III and R. J. Bartlett , A full coupled-cluster singles and doubles model : The inclusion of disconnected triples , The Journal of Chemical Physics 76 , 1910 ( 1982 ) . [ 34 ] K. Raghavachari , G. W. Trucks , J . A. Pople , and M. Head-Gordon , A fifth-order perturbation comparison of electron correlation theories , Chemical Physics Letters 157 , 479 ( 1989 ) . [ 35 ] R. J. Bartlett , How and why coupled-cluster theory became the pre-eminent method in an ab into quantum chemistry , in Theory and Applications of Computational Chemistry ( Elsevier , 2005 ) pp . 1191–1221 . [ 36 ] Y. Guo , C. Riplinger , U. Becker , D. G. Liakos , Y. Minenkov , L. Cavallo , and F. Neese , Communication : An improved linear scaling perturbative triples correction for the domain based local pair-natural orbital based singles and doubles coupled cluster method [ DLPNO-CCSD ( T ) ] , The Journal of chemical physics 148 , 10.1063/1.5011798 ( 2018 ) . [ 37 ] C. D. Sherrill and H. F. Schaefer III , The configuration interaction method : Advances in highly correlated approaches , in Advances in Quantum Chemistry , Vol . 34 ( Elsevier , 1999 ) pp . 143–269 . [ 38 ] D. G. Liakos , Y. Guo , and F. Neese , Comprehensive benchmark results for the domain based local pair natural orbital coupled cluster method ( dlpno-ccsd ( t ) ) for closed- and open-shell systems , Journal of Physical Chemistry A 124 , 90 ( 2020 ) . [ 39 ] M. M¨orchen , L. Freitag , and M. Reiher , Tailored coupled cluster theory in varying correlation regimes , The Journal of Chemical Physics 153 , 244113 ( 2020 ) . [ 40 ] N. Oliphant and L. Adamowicz , Multireference coupled cluster method for electronic structure of molecules , International Reviews in Physical Chemistry 12 , 339 ( 1993 ) . [ 41 ] P. J. Knowles and N. C. Handy , A new determinant-based full configuration interaction method , Chemical Physics Letters 111 , 315 ( 1984 ) . [ 42 ] J. Olsen , B. O. Roos , P. Jo/rgensen , and H. J . A. Jensen , Determinant based configuration interaction algorithms for complete and restricted configuration interaction spaces , The Journal of chemical physics 89 , 2185 ( 1988 ) . [ 43 ] P. J. Knowles and N. C. Handy , A determinant based full configuration interaction program , Computer physics commu- nications 54 , 75 ( 1989 ) . [ 44 ] S. Zarrabian , C. Sarma , and J. Paldus , Vectorizable approach to molecular ci problems using determinantal basis , Chemical physics letters 155 , 183 ( 1989 ) . [ 45 ] G. L. Bendazzoli and S. Evangelisti , A vector and parallel full configuration interaction algorithm , The Journal of chemical physics 98 , 3141 ( 1993 ) . [ 46 ] C. J. Stein , V. von Burg , and M. Reiher , The delicate balance of static and dynamic electron correlation , Journal of Chemical Theory and Computation 12 , 3764–3773 ( 2016 ) . [ 47 ] R. J. Harrison , Approximating full configuration interaction with selected configuration interaction and perturbation theory , The Journal of chemical physics 94 , 5021 ( 1991 ) . [ 48 ] A . A. Holmes , N. M. Tubman , and C. Umrigar , Heat-bath configuration interaction : An efficient selected configuration interaction algorithm inspired by heat-bath sampling , Journal of chemical theory and computation 12 , 3674 ( 2016 ) . [ 49 ] S. Sharma , A . A. Holmes , G. Jeanmairet , A. Alavi , and C. J. Umrigar , Semistochastic heat-bath configuration interaction method : Selected configuration interaction with semistochastic perturbation theory , Journal of chemical theory and computation 13 , 1595 ( 2017 ) . 18 [ 50 ] J . B. Schriber and F. A. Evangelista , Communication : An adaptive configuration interaction approach for strongly correlated electrons with tunable accuracy , The Journal of chemical physics 144 , 10.1063/1.4948308 ( 2016 ) . [ 51 ] N. M. Tubman , C. D. Freeman , D. S. Levine , D. Hait , M. Head-Gordon , and K. B. Whaley , Modern approaches to exact diagonalization and selected configuration interaction with the adaptive sampling CI method , Journal of chemical theory and computation 16 , 2139 ( 2020 ) . [ 52 ] H. Zhai , H. R. Larsson , S. Lee , Z.-H. Cui , T. Zhu , C. Sun , L. Peng , R. Peng , K. Liao , J. T¨olle , J. Yang , S. Li , and G. K.-L. Chan , Block2 : a comprehensive open source framework to develop and apply state-of-the-art dmrg algorithms in electronic structure and beyond ( 2023 ) , arXiv:2310.03920 [ physics.chem-ph ] . [ 53 ] C. Angeli , R. Cimiraglia , S. Evangelisti , T. Leininger , and J. P. Malrieu , Introduction of n-electron valence states for multireference perturbation theory , The Journal of Chemical Physics 114 , 10252 ( 2001 ) . [ 54 ] C. Angeli , R. Cimiraglia , and J. P. Malrieu , N-electron valence state perturbation theory : a fast implementation of the strongly contracted variant , Chemical Physics Letters 350 , 297 ( 2001 ) . [ 55 ] C. Angeli , R. Cimiraglia , and J. P. Malrieu , N-electron valence state perturbation theory : A spinless formulation and an efficient implementation of the strongly contracted and of the partially contracted variants , The Journal of Chemical Physics 117 , 9138 ( 2002 ) . [ 56 ] P. Pulay , A perspective on the CASPT2 method , International Journal of Quantum Chemistry 111 , 3273 ( 2011 ) . [ 57 ] S. Battaglia , I. F. Galv´a n , and R. Lindh , Multiconfigurational quantum chemistry : The CASPT2 method , in Theoretical and Computational Photochemistry ( Elsevier , 2023 ) pp . 135–162 . [ 58 ] J. Paldus , J . ˇC´ıˇzek , and M. Takahashi , Approximate account of the connected quadruply excited clusters in the coupled- pair many-electron theory , Physical Review A 30 , 2193 ( 1984 ) . [ 59 ] J. Paldus and J. Planelles , Valence bond corrected single reference coupled cluster approach : I. general formalism , Theoretica chimica acta 89 , 13 ( 1994 ) . [ 60 ] J. Planelles , J. Paldus , and X. Li , Valence bond corrected single reference coupled cluster approach : II . application to ppp model systems , Theoretica chimica acta 89 , 33 ( 1994 ) . [ 61 ] J. Planelles , J. Paldus , and X. Li , Valence bond corrected single reference coupled cluster approach : III . simple model of bond breaking or formation , Theoretica chimica acta 89 , 59 ( 1994 ) . [ 62 ] X. Li and J. Paldus , Reduced multireference CCSD method : An effective approach to quasidegenerate states , The Journal of chemical physics 107 , 6257 ( 1997 ) . [ 63 ] H. J. Monkhorst , Calculation of properties with the coupled-cluster method , International Journal of Quantum Chemistry 12 , 421 ( 1977 ) . [ 64 ] S. Lehtola , N. M. Tubman , K. B. Whaley , and M. Head-Gordon , Cluster decomposition of full configuration interaction wave functions : A tool for chemical interpretation of systems with strong correlation , The Journal of chemical physics 147 , 10.1063/1.4996044 ( 2017 ) . [ 65 ] O. Hino , T. Kinoshita , G. K. L. Chan , and R. J. Bartlett , Tailored coupled cluster singles and doubles method applied to calculations on molecular structure and harmonic vibrational frequencies of ozone , Journal of Chemical Physics 124 , 10.1063/1.2180775/186884 ( 2006 ) . [ 66 ] L. Veis , A. Antal´ık , J. Brabec , F. Neese , ¨Ors Legeza , and J. Pittner , Coupled cluster method with single and double excitations tailored by matrix product state wave functions , Journal of Physical Chemistry Letters 7 , 4072 ( 2016 ) . [ 67 ] A. Leszczyk , M. M´at´e , ¨Ors Legeza , and K. Boguslawski , Assessing the accuracy of tailored coupled cluster methods corrected by electronic wave functions of polynomial cost , Journal of Chemical Theory and Computation 18 , 96 ( 2022 ) . [ 68 ] M. Ravi , A. Perera , Y. C. Park , and R. J. Bartlett , Excited states with pair coupled cluster doubles tailored coupled cluster theory , The Journal of Chemical Physics 159 , 10.1063/5.0161368 ( 2023 ) . [ 69 ] D. I. Lyakh , V. F. Lotrich , and R. J. Bartlett , The ‘ tailored ’ CCSD ( T ) description of the automerization of cyclobutadiene , Chemical Physics Letters 501 , 166 ( 2011 ) . [ 70 ] A. Antal´ık , L. Veis , J. Brabec , O. Demel , ¨O . Legeza , and J. Pittner , Toward the efficient local tailored coupled cluster approximation and the peculiar case of oxo-Mn ( Salen ) , The Journal of Chemical Physics 151 , 10.1063/1.5110477 ( 2019 ) . [ 71 ] A. Antal´ık , D. Nachtigallov´a , R. Lo , M. Matouˇsek , J. Lang , ¨Ors Legeza , J. Pittner , P. Hobza , and L. Veis , Ground state of the fe ( ii ) -porphyrin model system corresponds to quintet : a dft and dmrg-based tailored cc study , Physical Chemistry Chemical Physics 22 , 17033 ( 2020 ) . [ 72 ] J. Lang , A. Antal´ık , L. Veis , J. Brandejs , J. Brabec , O. Legeza , and J. Pittner , Near-linear scaling in dmrg-based tailored coupled clusters : an implementation of DLPNO-TCCSD and DLPNO-TCCSD ( T ) , Journal of Chemical Theory and Computation 16 , 3028 ( 2020 ) . [ 73 ] F. M. Faulstich , A. Laestadius , ¨Ors Legeza , R. Schneider , and S. Kvaal , Analysis of the tailored coupled-cluster method in quantum chemistry , SIAM Journal on Numerical Analysis 57 , 2579 ( 2019 ) . [ 74 ] F. M. Faulstich , M. M´at´e , A. Laestadius , M. A. Csirik , L. Veis , A. Antalik , J. Brabec , R. Schneider , J. Pittner , S. Kvaal , and ¨Ors Legeza , Numerical and theoretical aspects of the dmrg-tcc method exemplified by the nitrogen dimer , Journal of Chemical Theory and Computation 15 , 2206 ( 2019 ) . [ 75 ] A. Melnichuk and R. J. Bartlett , Relaxed active space : Fixing tailored-CC with high order coupled cluster . i , The Journal of chemical physics 137 , 10.1063/1.4767900 ( 2012 ) . [ 76 ] O. Demel , J. Brandejs , J. Lang , J. Brabec , L. Veis , O. Legeza , and J. Pittner , Hilbert space multireference coupled clusters tailored by matrix product states , arXiv preprint arXiv:2304.01625 ( 2023 ) . [ 77 ] J. E. Deustua , I. Magoulas , J. Shen , and P. Piecuch , Communication : Approaching exact quantum chemistry by cluster analysis of full configuration interaction quantum monte carlo wave functions , The Journal of Chemical Physics 149 , 19 151101 ( 2018 ) . [ 78 ] J. E. Deustua , J. Shen , and P. Piecuch , Converging high-level coupled-cluster energetics by monte carlo sampling and moment expansions , Phys . Rev . Lett . 119 , 223003 ( 2017 ) . [ 79 ] I. Magoulas , K. Gururangan , P. Piecuch , J. E. Deustua , and J. Shen , Is externally corrected coupled cluster always better than the underlying truncated configuration interaction ? , Journal of Chemical Theory and Computation 17 , 4006 ( 2021 ) . [ 80 ] S. Lee , H. Zhai , S. Sharma , C. J. Umrigar , and G. K.-L. Chan , Externally corrected ccsd with renormalized perturbative triples ( R-ecCCSD ( T ) ) and the density matrix renormalization group and selected configuration interaction external sources , Journal of Chemical Theory and Computation 17 , 3414 ( 2021 ) . [ 81 ] G. J. Aroeira , M. M. Davis , J. M. Turney , and H. F. Schaefer III , Coupled cluster externally corrected by adaptive configuration interaction , Journal of chemical theory and computation 17 , 182 ( 2020 ) . [ 82 ] G.-L. R. Anselmetti , D. Wierichs , C. Gogolin , and R. M. Parrish , Local , expressive , quantum-number-preserving vqe ans¨atze for fermionic systems , New Journal of Physics 23 , 113010 ( 2021 ) . [ 83 ] T. H. Dunning , Gaussian basis sets for use in correlated molecular calculations . i. the atoms boron through neon and hydrogen , J. Chem . Phys . 90 , 1007 ( 1989 ) . [ 84 ] B. T. Gard , L. Zhu , G. S. Barron , N. J. Mayhall , S. E. Economou , and E. Barnes , Efficient symmetry-preserving state preparation circuits for the variational quantum eigensolver algorithm , npj Quantum Information 6 , 10.1038/s41534-019- 0240-1 ( 2020 ) . [ 85 ] H. R. Grimsley , S. E. Economou , E. Barnes , and N. J. Mayhall , An adaptive variational algorithm for exact molecular simulations on a quantum computer , Nature Communications 10 , 10.1038/s41467-019-10988-2 ( 2019 ) . [ 86 ] H. L. Tang , V. Shkolnikov , G. S. Barron , H. R. Grimsley , N. J. Mayhall , E. Barnes , and S. E. Economou , Qubit-adapt- vqe : An adaptive algorithm for constructing hardware-efficient ans¨atze on a quantum processor , PRX Quantum 2 , 020310 ( 2021 ) . [ 87 ] N. H. Stair and F. A. Evangelista , Simulating many-body systems with a projective quantum eigensolver , PRX Quantum 2 , 030301 ( 2021 ) . [ 88 ] J. Lee , W. J. Huggins , M. Head-Gordon , and K. B. Whaley , Generalized unitary coupled cluster wave functions for quantum computation , Journal of Chemical Theory and Computation 15 , 311–324 ( 2018 ) . [ 89 ] B. O ’ Gorman , W. J. Huggins , E. G. Rieffel , and K. B. Whaley , Generalized swap networks for near-term quantum computing , arXiv preprint arXiv:1905.05118 ( 2019 ) . [ 90 ] Y. Matsuzawa and Y. Kurashige , Jastrow-type decomposition in quantum chemistry for low-depth quantum circuits , Journal of Chemical Theory and Computation 16 , 944–952 ( 2020 ) . [ 91 ] M. Motta , C. Sun , A. T. K. Tan , M. J. O ’ Rourke , E. Ye , A. J. Minnich , F. G. S. L. Brand˜ao , and G. K.-L. Chan , Determining eigenstates and thermal states on a quantum computer using quantum imaginary time evolution , Nature Physics 16 , 205–210 ( 2019 ) . [ 92 ] I. H. Kim and B. Swingle , Robust entanglement renormalization on a noisy quantum computer , arXiv preprint arXiv:1711.07500 ( 2017 ) . [ 93 ] T. J. Sewell and S. P. Jordan , Preparing renormalization group fixed points on nisq hardware , arXiv preprint arXiv:2109.09787 ( 2021 ) . [ 94 ] C. Pineda , T. Barthel , and J. Eisert , Unitary circuits for strongly correlated fermions , Phys . Rev . A 81 , 050303 ( 2010 ) . [ 95 ] Q. Miao and T. Barthel , Quantum-classical eigensolver using multiscale entanglement renormalization , Physical Review Research 5 , 10.1103/physrevresearch.5.033141 ( 2023 ) . [ 96 ] L. Lin and Y. Tong , Near-optimal ground state preparation , Quantum 4 , 372 ( 2020 ) . [ 97 ] D. Malz , G. Styliaris , Z.-Y . Wei , and J. I. Cirac , Preparation of matrix product states with log-depth quantum circuits , arXiv preprint arXiv:2307.01696 ( 2023 ) . [ 98 ] Y. Ge , J. Tura , and J. I. Cirac , Faster ground state preparation and high-precision ground energy estimation with fewer qubits , Journal of Mathematical Physics 60 ( 2019 ) . [ 99 ] S. Lu , M. C. Ba˜nuls , and J. I. Cirac , Algorithms for quantum simulation at finite energies , PRX Quantum 2 , 020321 ( 2021 ) . [ 100 ] M.-Q . He , D.-B . Zhang , and Z. D. Wang , Quantum gaussian filter for exploring ground-state properties , Physical Review A 106 , 10.1103/physreva.106.032420 ( 2022 ) . [ 101 ] O. Kyriienko , Quantum inverse iteration algorithm for programmable quantum simulators , npj Quantum Information 6 , 10.1038/s41534-019-0239-7 ( 2020 ) . [ 102 ] S. Fomichev , K. Hejazi , M. S. Zini , M. Kiser , J. F. Morales , P. A. M. Casares , A. Delgado , J. Huh , A.-C. Voigt , J. E. Mueller , et al. , Initial state preparation for quantum chemistry on quantum computers , arXiv preprint arXiv:2310.18410 ( 2023 ) . [ 103 ] S. Choi , I. Loaiza , and A. F. Izmaylov , Fluid fermionic fragments for optimizing quantum measurements of electronic hamiltonians in the variational quantum eigensolver , Quantum 7 , 889 ( 2023 ) . [ 104 ] T. E. O ’ Brien , G. Anselmetti , F. Gkritsis , V. E. Elfving , S. Polla , W. J. Huggins , O. Oumarou , K. Kechedzhi , D. Abanin , R. Acharya , I. Aleiner , R. Allen , T. I. Andersen , K. Anderson , M. Ansmann , F. Arute , K. Arya , A. Asfaw , J. Atalaya , J. C. Bardin , A. Bengtsson , G. Bortoli , A. Bourassa , J. Bovaird , L. Brill , M. Broughton , B. Buckley , D. A. Buell , T. Burger , B. Burkett , N. Bushnell , J. Campero , Z. Chen , B. Chiaro , D. Chik , J. Cogan , R. Collins , P. Conner , W. Courtney , A. L. Crook , B. Curtin , D. M. Debroy , S. Demura , I. Drozdov , A. Dunsworth , C. Erickson , L. Faoro , E. Farhi , R. Fatemi , V. S. Ferreira , L. Flores Burgos , E. Forati , A. G. Fowler , B. Foxen , W. Giang , C. Gidney , D. Gilboa , M. Giustina , R. Gosula , A. Grajales Dau , J . A . Gross , S. Habegger , M. C. Hamilton , M. Hansen , M. P. Harrigan , S. D. Harrington , P. Heu , M. R. Hoffmann , S. Hong , T. Huang , A. Huff , L. B. Ioffe , S. V. Isakov , J. Iveland , E. Jeffrey , Z. Jiang , C. Jones , 20 P. Juhas , D. Kafri , T. Khattar , M. Khezri , M. Kieferov´a , S. Kim , P. V. Klimov , A. R. Klots , A. N. Korotkov , F. Kostritsa , J. M. Kreikebaum , D. Landhuis , P. Laptev , K.-M. Lau , L. Laws , J. Lee , K. Lee , B. J. Lester , A. T. Lill , W. Liu , W. P. Livingston , A. Locharla , F. D. Malone , S. Mandr ` a , O. Martin , S. Martin , J. R. McClean , T. McCourt , M. McEwen , X. Mi , A. Mieszala , K. C. Miao , M. Mohseni , S. Montazeri , A. Morvan , R. Movassagh , W. Mruczkiewicz , O. Naaman , M. Neeley , C. Neill , A. Nersisyan , M. Newman , J. H. Ng , A. Nguyen , M. Nguyen , M. Y. Niu , S. Omonije , A. Opremcak , A. Petukhov , R. Potter , L. P. Pryadko , C. Quintana , C. Rocque , P. Roushan , N. Saei , D. Sank , K. Sankaragomathi , K. J. Satzinger , H. F. Schurkus , C. Schuster , M. J. Shearn , A . Shorter , N. Shutty , V. Shvarts , J. Skruzny , W. C. Smith , R. D. Somma , G. Sterling , D. Strain , M. Szalay , D. Thor , A. Torres , G. Vidal , B. Villalonga , C. Vollgraff Heidweiller , T. White , B. W. K. Woo , C. Xing , Z. J. Yao , P. Yeh , J. Yoo , G. Young , A. Zalcman , Y. Zhang , N. Zhu , N. Zobrist , D. Bacon , S. Boixo , Y. Chen , J. Hilton , J. Kelly , E. Lucero , A. Megrant , H. Neven , V. Smelyanskiy , C. Gogolin , R. Babbush , and N. C. Rubin , Purification-based quantum error mitigation of pair-correlated electron simulations , Nature Physics 10.1038/s41567-023-02240-y ( 2023 ) . [ 105 ] F. Arute , K. Arya , R. Babbush , D. Bacon , J. C. Bardin , R. Barends , R. Biswas , S. Boixo , F. G. Brandao , D. A. Buell , et al. , Quantum supremacy using a programmable superconducting processor , Nature 574 , 505 ( 2019 ) . [ 106 ] J. Helsen and M. Walter , Thrifty shadow estimation : re-using quantum circuits and bounding tails ( 2022 ) , arXiv:2212.06240 [ quant-ph ] . [ 107 ] Y. Zhou and Q. Liu , Performance analysis of multi-shot shadow estimation , Quantum 7 , 1044 ( 2023 ) . [ 108 ] J. VandeVondele and J. Hutter , Gaussian basis sets for accurate calculations on molecular systems in gas and condensed phases , The Journal of chemical physics 127 , 10.1063/1.2770708 ( 2007 ) . [ 109 ] S. Goedecker , M. Teter , and J. Hutter , Separable dual-space gaussian pseudopotentials , Physical Review B 54 , 1703 ( 1996 ) . [ 110 ] H. Jnane , J. Steinberg , Z. Cai , H. C. Nguyen , and B. Koczor , Quantum error mitigated classical shadows ( 2023 ) , arXiv:2305.04956 [ quant-ph ] . [ 111 ] H. H. S. Chan , R. Meister , M. L. Goh , and B. Koczor , Algorithmic shadow spectroscopy ( 2023 ) , arXiv:2212.11036 [ quant- ph ] . [ 112 ] R. Brieger , M. Heinrich , I. Roth , and M. Kliesch , Stability of classical shadows under gate-dependent noise ( 2023 ) , arXiv:2310.19947 [ quant-ph ] . [ 113 ] N. C. Rubin and A. E. DePrince , p†q : a tool for prototyping many-body methods for quantum chemistry , Molecular Physics 119 , 10.1080/00268976.2021.1954709 ( 2021 ) . [ 114 ] Q . Sun , X. Zhang , S. Banerjee , P. Bao , M. Barbry , N. S. Blunt , N. A. Bogdanov , G. H. Booth , J. Chen , Z.-H. Cui , J. J. Eriksen , Y. Gao , S. Guo , J. Hermann , M. R. Hermes , K. Koh , P. Koval , S. Lehtola , Z. Li , J. Liu , N. Mardirossian , J. D. McClain , M. Motta , B. Mussard , H. Q. Pham , A. Pulkin , W. Purwanto , P. J. Robinson , E. Ronca , E. R. Sayfutyarova , M. Scheurer , H. F. Schurkus , J. E. T. Smith , C. Sun , S.-N. Sun , S. Upadhyay , L. K. Wagner , X. Wang , A . White , J. D. Whitfield , M. J. Williamson , S. Wouters , J. Yang , J. M. Yu , T. Zhu , T. C. Berkelbach , S. Sharma , A. Y. Sokolov , and G. K.-L. Chan , Recent developments in the PySCF program package , The Journal of Chemical Physics 153 , 024109 ( 2020 ) . [ 115 ] J. Bradbury , R. Frostig , P. Hawkins , M. J. Johnson , C. Leary , D. Maclaurin , G. Necula , A. Paszke , J. VanderPlas , S. Wanderman-Milne , and Q. Zhang , JAX : composable transformations of Python+NumPy programs ( 2018 ) . [ 116 ] N. C. Rubin , K. Gunst , A . White , L. Freitag , K. Throssell , G. K.-L. Chan , R. Babbush , and T. Shiozaki , The fermionic quantum emulator , Quantum 5 , 568 ( 2021 ) . [ 117 ] V. Bergholm , J. Izaac , M. Schuld , C. Gogolin , S. Ahmed , V. Ajith , M. S. Alam , G. Alonso-Linaje , B. AkashNarayanan , A. Asadi , J. M. Arrazola , U. Azad , S. Banning , C. Blank , T. R. Bromley , B . A. Cordier , J. Ceroni , A. Delgado , O . Di Mat- teo , A. Dusko , T. Garg , D. Guala , A. Hayes , R. Hill , A. Ijaz , T. Isacsson , D. Ittah , S. Jahangiri , P. Jain , E. Jiang , A. Khandelwal , K. Kottmann , R. A. Lang , C. Lee , T. Loke , A. Lowe , K. McKiernan , J. J. Meyer , J . A. Monta˜nez- Barrera , R. Moyard , Z. Niu , L. J. O ’ Riordan , S. Oud , A. Panigrahi , C.-Y . Park , D. Polatajko , N. Quesada , C. Roberts , N. S´a , I. Schoch , B. Shi , S. Shu , S. Sim , A. Singh , I. Strandberg , J. Soni , A. Sz´ava , S. Thabet , R. A. Vargas-Hern´andez , T. Vincent , N. Vitucci , M. Weber , D. Wierichs , R. Wiersema , M. Willmann , V. Wong , S. Zhang , and N. Killoran , Pennylane : Automatic differentiation of hybrid quantum-classical computations ( 2018 ) . [ 118 ] C. R. Harris , K. J. Millman , S. J. van der Walt , R. Gommers , P. Virtanen , D. Cournapeau , E. Wieser , J. Taylor , S. Berg , N. J. Smith , R. Kern , M. Picus , S. Hoyer , M. H. van Kerkwijk , M. Brett , A. Haldane , J. F. del R´ıo , M. Wiebe , P. Peterson , P. G´erard-Marchant , K. Sheppard , T. Reddy , W. Weckesser , H. Abbasi , C. Gohlke , and T. E. Oliphant , Array programming with numpy , Nature 585 , 357 ( 2020 ) . [ 119 ] P. Virtanen , R. Gommers , T. E. Oliphant , M. Haberland , T. Reddy , D. Cournapeau , E. Burovski , P. Peterson , W. Weckesser , J . Bright , S. J. van der Walt , M. Brett , J. Wilson , K. J. Millman , N. Mayorov , A. R. J. Nelson , E. Jones , R. Kern , E. Larson , C. J. Carey , ˙I . Polat , Y. Feng , E. W. Moore , J. VanderPlas , D. Laxalde , J. Perktold , R. Cimrman , I. Henriksen , E. A. Quintero , C. R. Harris , A. M. Archibald , A. H. Ribeiro , F. Pedregosa , P. van Mulbregt , and SciPy 1.0 Contributors , SciPy 1.0 : Fundamental Algorithms for Scientific Computing in Python , Nature Methods 17 , 261 ( 2020 ) . [ 120 ] T. pandas development team , pandas-dev/pandas : Pandas ( 2020 ) . [ 121 ] Wes McKinney , Data Structures for Statistical Computing in Python , in Proceedings of the 9th Python in Science Con- ference , edited by St´efan van der Walt and Jarrod Millman ( 2010 ) pp . 56 – 61 . [ 122 ] J. D. Hunter , Matplotlib : A 2d graphics environment , Computing in Science & Engineering 9 , 90 ( 2007 ) . [ 123 ] M. L. Waskom , seaborn : statistical data visualization , Journal of Open Source Software 6 , 3021 ( 2021 ) . [ 124 ] A. Meurer , C. P. Smith , M. Paprocki , O . ˇCert´ık , S. B. Kirpichev , M. Rocklin , A. Kumar , S. Ivanov , J. K. Moore , S. Singh , T. Rathnayake , S. Vig , B. E. Granger , R. P. Muller , F. Bonazzi , H. Gupta , S. Vats , F. Johansson , F. Pedregosa , 21 M. J. Curry , A. R. Terrel , v. Rouˇcka , A. Saboo , I. Fernando , S. Kulal , R. Cimrman , and A. Scopatz , Sympy : symbolic computing in python , PeerJ Computer Science 3 , e103 ( 2017 ) . [ 125 ] M. Wimmer , Efficient numerical computation of the pfaffian for dense and banded skew-symmetric matrices , ACM Transactions on Mathematical Software 38 , 10.1145/2331130.2331138 ( 2011 ) . [ 126 ] W. J. Hehre , R. F. Stewart , and J . A. Pople , Self-consistent molecular-orbital methods . i. use of gaussian expansions of slater-type atomic orbitals , J. Chem . Phys . 51 , 2657 ( 1969 ) . [ 127 ] W. J. Hehre , R. Ditchfield , R. F. Stewart , and J . A. Pople , Self-consistent molecular orbital methods . iv . use of gaussian expansions of slater-type orbitals . extension to second-row molecules , J. Chem . Phys . 52 , 2769 ( 1970 ) . [ 128 ] R. Ditchfield , W. J. Hehre , and J . A. Pople , Self-consistent molecular-orbital methods . ix . an extended gaussian-type basis for molecular-orbital studies of organic molecules , J. Chem . Phys . 54 , 724 ( 1971 ) . [ 129 ] M. M. Francl , W. J. Pietro , W. J. Hehre , J. S. Binkley , M. S. Gordon , D. J. DeFrees , and J . A. Pople , Self-consistent molecular orbital methods . xxiii . a polarization-type basis set for second-row elements , J. Chem . Phys . 77 , 3654 ( 1982 ) . [ 130 ] M. S. Gordon , J. S. Binkley , J . A. Pople , W. J. Pietro , and W. J. Hehre , Self-consistent molecular-orbital methods . 22. small split-valence basis sets for second-row elements , J . Am . Chem . Soc . 104 , 2797 ( 1982 ) . [ 131 ] W. J. Hehre , R. Ditchfield , and J . A. Pople , Self-consistent molecular orbital methods . xii . further extensions of gaussian- type basis sets for use in molecular orbital studies of organic molecules , J. Chem . Phys . 56 , 2257 ( 1972 ) . [ 132 ] R. A. Kendall , T. H. Dunning , and R. J. Harrison , Electron affinities of the first-row atoms revisited . systematic basis sets and wave functions , J. Chem . Phys . 96 , 6796 ( 1992 ) . [ 133 ] D. E. Woon and T. H. Dunning , Gaussian basis sets for use in correlated molecular calculations . iii . the atoms aluminum through argon , J. Chem . Phys . 98 , 1358 ( 1993 ) . [ 134 ] F. Malone , Data for Unbiasing fermionic quantum Monte Carlo with a quantum computer , 10.5281/zenodo.10141262 ( 2023 ) . Appendix A : Theoretical Background of Coupled Cluster Methods The single reference coupled cluster ( SRCC ) wavefunction is constructed through an exponential ansatz acting on 22 the Hartree-Fock ( or Fermi vacuum ) reference determinant ΨCC⟩ with the cluster operator ˆT . The cluster operator is formed by linear combination of individual operators = e | , ,31,32 Φ0⟩ | ˆT Φ0⟩ | ˆT = ˆTν ( A1 ) ( A2 ) ν ( cid:88 ) with excitation level ν. Truncating this expression at a certain excitation level νmax yields the well-known hierarchy of truncated CC methods : CC singles ( CCS , νmax = 1 ) , CC singles and doubles ( CCSD , νmax = 2 ) , CC singles , doubles , and triples ( CCSDT , νmax = 3 ) , and so on . The excitation operators are generally defined as ˆTν = 1 ( ν ! ) 2 abc ... ( cid:88 ) ijk ... tabc ... ijk ... ˆa†aˆa†bˆa†c . . . ˆaiˆaj ˆak . . . , ( A3 ) with the Tν amplitudes tabc ... ijk ... for a given excitation level ν and the fermionic creation and annihilation operators ˆa†p and ˆap , respectively . The indices a , b , c , . . . denote virtual orbital indices , i , j , k , . . . refer to occupied orbitals in , Φ0⟩ | and p , q , r , s , . . . refer to general spin orbitals . The T amplitudes are solved for by projecting excited determinant manifolds onto the similarity-transformed Hamiltonian ¯H ˆT ˆHe ˆT , Φν | ⟩ ¯H | where rν is referred to as residual vector . The resulting non-linear amplitude equations can be solved iteratively . Note that , due to the similarity transformation required for obtaining computationally tractable amplitude equations , the from the left , one obtains the SRCC energy as resulting Hamiltonian is no longer Hermitian . By projecting with Φ0⟩ ( A4 ) ≡ ⟨ Φν rν | e− ≡ ! = 0 , Φ0⟩ | ECC = ¯H ⟨ Φ0| =EHF + Φ0⟩ | i ta f a i + ia ( cid:88 ) i tb ta j⟨ ij ab ⟩ || + 1 4 1 2 ijab ( cid:88 ) ijab ( cid:88 ) tab ij ⟨ ij , ab ⟩ || ( A5 ) with the reference Hartree-Fock energy EHF , the Fock matrix elements f q p , and the antisymmetrized two-electron repulsion integrals in Physicists ’ notation . Note that only T1 and T2 amplitudes enter the SRCC energy expression directly , independent of the truncation level , since the higher excitation cluster operators can not produce fully contracted terms with the Hamiltonian . The implicit energy contribution of higher-order T amplitudes originates from the coupling of all amplitudes through the projection equations . For CCSD , the amplitude equations require projections of the singly and doubly excited determinants , i.e. , rs ⟩ pq || ⟨ ¯H Φ0⟩ , | ¯H Φ0⟩ | In the following sections , we use the normal-ordered Hamiltonian , Φa i | ⟨ Φab ij | ⟨ 0 = 0 = . to express the Baker-Campbell-Hausdorff ( BCH ) expansion of ¯H more conveniently as ˆHN = ˆH ˆH Φ0| , Φ0⟩ | − ⟨ ¯H → ( ˆHN ˆT ) c , ( A6 ) ( A7 ) ( A8 ) ( A9 ) where the ( . . . ) c denotes that only the connected contributions from the expansion survive.31 With the programmable expressions for the projection equations at hand , which can for example be derived through code generation ( see Appendix B ) ,113 the amplitudes are solved iteratively through standard numerical techniques.31 1 . Tailored Coupled Cluster 23 The tailored coupled cluster ( TCC ) ansatz aims to encode static correlation effects from an active space ( AS ) method in a SRCC wavefunction through a split-amplitude ansatz2 ˆT = ˆT ext + ˆT AS . ( A10 ) The amplitudes in the active space cluster operator ˆT AS are extracted from an exact or approximate active space wavefunction through the relationship of the linear configuration interaction ( CI ) ansatz and the exponential CC ansatz The CI excitation operators ˆCν are defined as the cluster operator in eq ( A3 ) , but with cabc ... ijk ... as corresponding am- plitudes . Conversion from CI to CC amplitudes is achieved by matching excitation levels and recursively determining the amplitudes,63,64 here up to four-fold excitations , as 1 + ˆCν = e ˆT . ν ( cid:88 ) ( A11 ) ˆT1 = ˆC1 ˆT2 = ˆC2 − ˆT3 = ˆC3 − ˆT4 = ˆC4 − 1 2 1 2 1 2 ˆT 2 1 ˆT1 ˆT2 + ˆT2 ˆT1 ( cid:16 ) ˆT1 ˆT3 + ˆT3 ˆT1 ( cid:17 ) ( cid:16 ) ( cid:17 ) ˆT 3 1 1 3 ! 1 ˆT 2 2 − 2 − − 1 4 ! ˆT 4 1 . Evaluating these terms as Wick contractions yields the following programmable expressions,64 i = ca ta i tab ij = cab ij − ijk = cabc tabc ijk − + tc jtab ik − jtb i tc + ta i ta j + tb i tb ta j i tac jk + tb i tbc ta ta ktbc ij + tb j tc i ta k + tb tabcd ijkl = . . . i tab tc j tbc jtac tb jk + ta jk − ik − ik ktac tc ktab ta i tb jtc ij − ij − k i tb k + tc j tb i ta tc jta i tc tb jta k k − k − ( A12 ) ( A13 ) ( A14 ) ( A15 ) ( A16 ) ( A17 ) ( A18 ) ( A19 ) The expressions contain single “ non-redundant ” outer products of T amplitudes , e.g. , ta jk , and the terms with permuted indices ensure the correct anti-symmetry of the resulting amplitude , cancelling exactly the corresponding prefactor from the Taylor expansion . If the coefficient of the reference determinant in the underlying CI expansion is not equal to one , one has to renormalize the above conversion equations accordingly . As all CC methods , TCC is only applicable if the coefficient of the reference determinant extracted from the active space method is non-zero . With a set of CI amplitudes at hand , the corresponding spin-orbital T amplitudes can be built with the expressions above , yielding an active space cluster operator ˆT AS . The orbital indices of the cluster amplitudes are fully contained in the AS . Contrary to that , the external cluster amplitudes belonging to ˆT ext comprise active space , i.e. , ijk . . . abc . . . an orbital space where at least one orbital index is not part of the active space , i.e. , ijk . . . abc . . . AS . Now , the TCC energy functional is given by i tbc ̸⊂ ∈ Since the external and active space cluster operators commute by construction , one can obtain the active space energy through the CC energy functional via ( cid:68 ) ( cid:16 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) c ( cid:17 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:69 ) ETCC = Φ0 ˆHN e ˆT ext+ ˆT AS Φ0 . ( A20 ) ETCC = Φ0 ˆHN e ˆTAS ( cid:68 ) ( cid:12 ) = EAS + Eext . ( cid:12 ) ( cid:12 ) ( cid:16 ) Φ0 + Φ0 ˆHN e ˆText ( cid:69 ) ( cid:68 ) ( cid:16 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) Φ0 ( cid:69 ) c ( cid:17 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) c ( cid:17 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( A21 ) ( A22 ) The relationship holds due to the equivalence of the CI and CC expansions for exact wavefunctions , i.e. , the T1 and T2 amplitudes extracted from the active space wavefunction are exact and can be viewed as optimized in presence of all higher-order T amplitudes through the active space method . For approximate active space methods , the mapping is not exact , and the resulting energy computed through the CC energy functional is not necessarily equivalent to the ( variational ) energy of the active space wavefunction.1 To retain the static correlation information in the TCC wavefunction , the active space amplitudes are kept frozen during optimization of the external amplitudes . That is , the following amplitude equations are to be solved in TCCSD , the most popular flavor of TCC : 24 ˆHN e ( ˆT AS 1 + ˆT AS 2 ) e ( ˆT ext 1 + ˆT ext 2 ) ( cid:16 ) ˆHN e ( ˆT AS 1 + ˆT AS 2 ) e ( ˆT ext 1 + ˆT ext 2 0 = 0 = Φa i ( cid:12 ) ( cid:68 ) Φab ( cid:12 ) ij ( cid:12 ) ( cid:68 ) ( cid:16 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) Φ0 , i , a AS ̸⊂ i , j , a , b AS . ̸⊂ c ( cid:17 ) ) ( cid:12 ) ( cid:12 ) ( cid:12 ) c ( cid:17 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:69 ) Φ0 , ( cid:69 ) ( A23 ) ( A24 ) Note that the “ output ” amplitudes are external , however , the active space amplitudes still appear in the algebraic expressions of the projection equations . Thus , the frozen active space T amplitudes impact the TCC solution through the active space energy , i.e. , the energy evaluated directly from the frozen amplitudes , and additionally through the contractions with the external amplitudes . Once the active space T amplitudes are known and mapped to the corresponding orbitals in the full molecular orbital space , the standard SRCC framework is used to solve for the external amplitudes , with the only constraint that a certain stride of the full space amplitudes be frozen . In practice , this can be easily achieved by setting the stride of active space amplitudes in the CC residual vector to zero . As for standard CCSD , a perturbative triples correction , i.e. , CCSD ( T ) can be employed,69 which is only evaluated from the external amplitudes for consistency . 2 . Externally Corrected Coupled Cluster Externally corrected CC ( ec-CC ) 3 builds a similar split-amplitude ansatz as TCC , but aims to encode static corre- lation into the SRCC wavefunction through higher-order cluster operators . Inspecting the un-truncated expressions for the singles and doubles residual equations , it is clear that only ˆT3 and ˆT4 can contribute to achieve the correct total excitation level , i.e. , ˆHN ˆT3 Φa i ( cid:68 ) ra i ← ( cid:12 ) ˆHN ˆT3 + ˆT4 + ˆT1 ˆT3 ( cid:12 ) ( cid:12 ) ( cid:16 ) ( cid:17 ) c c Φ0 ( cid:69 ) Φ0 , . ( A25 ) ( A26 ) rab ij ← Φab ij ( cid:68 ) ( cid:16 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:17 ) ( cid:69 ) These expressions then , of course , correspond to the CCSDTQ residual equations for T1 and T2 , however , higher-order cluster operators can not produce any further contributions to these terms . Hence , the traditional CCSD approach corresponds to the approximate case where ˆT3 = 0 and ˆT4 = 0 . This means that , adding the direct contributions of T3 and T4 amplitudes ( e.g. , extracted from a high-quality correlated multi-reference wavefunction ) to the T1 and T2 projection equations , one can in principle obtain an improved treatment of the overall electron correlation , including non-dynamic correlation effects , compared to CCSD . The gist here is that convergence to full CI is guaranteed if the input T3 and T4 amplitudes become exact . Thus , the ec-CC procedure optimizes the T1 and T2 amplitudes in presence of ( approximate ) T3 and T4 . The resulting ec-CC cluster operator is given by where the T3 and T4 amplitudes are extracted from some input wavefunction . If the wavefunction only covers a subset of the molecular orbitals , i.e. , in case of an active space method , the operator is modified to project the sliced T3 and T4 amplitudes onto the full orbital space , like in TCC , that is ˆT = ˆT1 + ˆT2 + ˆT input 3 + ˆT input 4 , ( A27 ) ˆT = ˆT1 + ˆT2 + ˆP3 ˆT AS 3 + ˆP4 ˆT AS 4 , ( A28 ) with the appropriate projection operators ˆP3 and ˆP4 . For ec-CC , the same recursion relations to extract T amplitudes from a CI-like wavefunction apply , see eqs ( A12 ) through ( A15 ) . If an active space wavefunction is used as input , the convergence guarantee toward FCI does not hold anymore , however , improvements can still be achieved by including the dominant T3 and T4 amplitudes from the multi-reference treatment compared to completely neglecting the triples and quadruples . The structure of the ec-CC ansatz directly implies that , depending on the quality of the underlying input wavefunction , the ec-CC result might not always provide better results than the input wavefunction itself.79 We reproduce the corresponding proof in the following Section A 3 . 1 The energies are equivalent though if singles and doubles are treated fully variationally in the approximate active space wavefunction . 3 . Type-I ec-CC with Configuration Interaction 25 This section largely follows the arguments laid out in Ref . 79 with proofs abbreviated for conciseness . The ec-CC singles and doubles equations with T3 and T4 generated from any coupled-cluster theory involving anything beyond doubles would return an identical coupled-cluster energy . Naturally , one would get a different energy if T1 and T2 from the T3 and T4 source calculation are not treated fully . It turns out that truncated configuration interaction can be shown to satisfy the ec-CC T1 and T2 equations . To see this we will convert the set of singles and doubles truncated CI correlation energy equations into a form equivalent to the coupled-cluster singles and doubles equations . Thus satisfying the truncated CI equations for singles and doubles corresponds to solving the ec-CC equations singles and doubles equations . This implies that the energy would be equivalent . Theorem A.1 . The solution to a truncated configuration interaction set of equations which includes full singles , full doubles , and any set of higher excitations satisfies the coupled-cluster singles and doubles equations . Proof . First , consider a truncated CI wavefunction expansion represented in intermediate normalization = Ψ | ⟩ 1 + ˆC1 + ˆC2 + ˆC B ( cid:16 ) ( cid:17 ) Φ0⟩ | ( A29 ) where ˆC1 is the full set of one-body excitations and their coefficients , ˆC2 is the full set of two-body excitations and their variational coefficients , ˆC B is any higher excitations and their variational coefficients , and is the reference determinant . We note that the set ˆC B does not need to be complete . For example , only subsets of triples or quadruples could be considered in ˆC B . The coupled equations for the CI correlation energy for singles and doubles are Φ0⟩ | Φa i | ⟨ Φab ij | ⟨ ˆHN ˆHN 1 + ˆC1 + ˆC2 + ˆC B ( cid:16 ) 1 + ˆC1 + ˆC2 + ˆC B ( cid:16 ) , and Φ0⟩ | Φ0⟩ | = Ecorr ⟨ = Ecorr ⟨ ( cid:17 ) ( cid:17 ) , ˆC1| Φa i | ˆC2| Φab ij | Φ0⟩ Φ0⟩ . ( A30 ) ( A31 ) are the singly and doubly excited determinants , respec- where Ecorr = tively . Noting that the connected components of the wavefunction are given by Φ0| ⟨ Φ0⟩ | and | ˆHN ˆC1 + ˆC2 Φab ij ⟩ | Φa i ⟩ ( cid:16 ) ( cid:17 ) which is evaluated using the Mercator series and is a specific case of the more general cluster analysis equation T = ln ( 1 + C ) can be used to write the CI equations in exponential ansatz form ˆT = ln ( 1 + ˆC1 + ˆC2 + ˆC B ) ( A32 ) Φa e i | ⟨ ˆT e− Φab e ij | ⟨ ˆT e− ˆT ˆT ˆHN e ˆT ˆT ˆHN e Φ0⟩ | = Φ0⟩ | = Φa e i | ⟨ Φab e ij | ˆT ⟨ ˆT ˆHN e ˆT ( cid:16 ) ˆT ˆHN e ( cid:16 ) ( cid:17 ) Φ0⟩ c | Φ0⟩ ( cid:17 ) c | = Ecorr⟨ = Ecorr⟨ ˆC1| Φa i | ˆC2| Φab ij | Φ0⟩ , . Φ0⟩ Now introducing projectors on to each relevant subspace of Hilbert space ( A33 ) ( A34 ) P = ˜C †1 + ˜C2| Φ0| where Q is defined as the orthogonal compliment to P + P ˜C1 , ˜C2 operators of ˆC without the variational coefficients . Inserting the resolution of identity we get = ˜C1| , P ˜C1 , ˜C2 Φ0⟩⟨ Φ0⟩⟨ Φ0| | | P + P ˜C1 , ˜C2 ˜C †2 P ˜CB = ˜C B + P ˜CB + Q = 1 ˜C †B Φ0⟩⟨ Φ0⟩⟨ + P ˜CB and the tilde on the C indicates the excitation ( A36 ) ( A35 ) Φ0| Φ0| Φa e i | ⟨ ˆT P ( cid:16 ) HN eT ˆT P ˜CB ( cid:0 ) ( cid:1 ) ˆHN e ( cid:16 ) Φa e i | ⟨ Φa e i | ⟨ ˆT P + P ˜C1 , ˜C2 + P ˜CB + Q ˆHN e ˆT Φ ⟩ c | ˆT c | ( cid:17 ) + Φa i | ⟨ + Φ0⟩ Φa e i | ⟨ ( cid:17 ) ( cid:16 ) eT P ˜C1 , ˜C2 ˆT Q Φa i | ⟨ ˆT P ˜C1 , ˜C2 e ( cid:17 ) ˆT ˆHN e ( cid:16 ) ˆHN e ˆT ˆHN e ˆT ( cid:16 ) ( cid:16 ) ( cid:17 ) ( cid:17 ) Φ0⟩ = Ecorr⟨ c | + Φ0⟩ c | ( cid:17 ) Φ0⟩ c | Φ0⟩ c | = Ecorr⟨ = 0 ˆC1| Φa i | ˆC1| Φa i | Φ0⟩ Φ0⟩ ( A37 ) ( A38 ) ( A39 ) where the first term on the left-hand-side of Eq . ( A38 ) cancels the right-hand-side and the last two terms on the left- hand-side are zero because the cluster operator only excites from a given determinant . Following the same protocol we obtain a similar expression for the doubles equation which is 26 Φab ij | ⟨ e ˆT P ˜C1 , ˜C2 ˆT ˆHN e ( cid:16 ) ( cid:17 ) = 0 . Φ0⟩ ( A40 ) c | Expanding the projector in Eq . ( A39 ) and noting that the C1 operator only excites from a determinant we obtain the singles coupled-cluster equation = 0 . Expanding the doubles equation in the projectors and the ˆHN e ˆT Φa i | ⟨ exponential operator one obtains the doubles coupled-cluster equation Φ0⟩ c | ( cid:17 ) ( cid:16 ) ˆHN e ˆT = 0 . Φ0⟩ ■ c | Φab ij | ⟨ It should be re-emphasized that the full singles and doubles are required for this proof . If a subset of the singles are used then the last term on the left-hand-side of Eq . ( A39 ) can not necessarily be concluded to be zero . The same can be said for the analogous term in the doubles derivation . As is concluded in Ref . 79 , the way to break the truncated CI coupled-cluster energy symmetry is to modify the cluster equations to remove disconnected components of T3 and T4 . ( cid:16 ) ( cid:17 ) 4 . Computational Scaling and Simplification of ec-CC The ec-CC ansatz borrows only the T1 and T2 residual equations from CCSDTQ , i.e. , the expensive T3 and T4 residual equations are not required . In addition , the CI expansion of the input wavefunction needs to be converted to the corresponding T amplitudes , requiring outer products of T amplitudes that produce up to eight-index output ( N 8 ) , but the prefactor is quite large in that case because all non-redundant anti-symmetric tensors . This scales as permutations need to be computed through transpositions of each unique outer product . However , the conversion only occurs once per calculation and is thus not repeatedly evaluated . The most expensive contraction for ec-CC occurs in the T2 residual equation as the product of T4 amplitudes and the electron-repulsion intergrals , O rab ij ← klcd ( cid:88 ) tcdab ijlk ⟨ lk . cd ⟩ || ( A41 ) ( N 8 ) contraction is executed only once and can Since T4 is purely dictated by the input wavefunction method , this be stored for the rest of the ec-CC computation . Another contribution to the T2 amplitude equation comes from products of T1 and T3 . To improve performance , some works on ec-CC report that this term can be pre-computed using T1 from the input wavefunction , thereby neglecting an iterative update of the T1/T3 contribution to the residual equations . This approximation seems to have only a minor influence on the quality of the result.3,81 Our ec-CC implementation features “ frozen ” and iterative computation of the T1/T3 products for better debugging in the context of quantum input . O Appendix B : Implementation and Computational Methodology All classical electronic structure calculations ( CASCI , CCSD , NEVPT2 , etc . ) were run using PySCF.114 Used basis sets and other parameters are specified in the main text . Tailored and externally corrected coupled cluster methods were implemented in a standalone Python library , using PySCF as input for reference states , e.g. , molecular integrals , and classical CASCI calculations . The cluster analysis working equations and CCSDTQ working equations for ec-CC were generated using p†q.113 For improved performance , the tensor contractions are evaluated using JAX.115 Correctness of our cluster analysis code was verified using the ClusterDec library.64 For input from quantum hardware , our code supports FQE wavefunctions as external source.116 The overlaps in case of PySCF ’ s CASCI or FQE input are obtained by a simple look-up in the sparse state/CI vector , addressing determinants with the correct excitation level and then converting them from true-vacuum sign convention to Fermi vacuum sign convention.64 VQE and matchgate shadow simulations were performed using Covestro ’ s in-house quantum computing software stack based on PennyLane.117 Data analysis was performed using NumPy,118 SciPy,119 Pandas,120,121 Matplotlib,122 and Seaborn.123 Appendix C : Split-Amplitude CC with Noisy Quantum Inputs In this section we investigate how the shot noise due to finite sampling influences the errors of energies obtained with the quantum TCCSD method . We do this in two steps : First , by means of explicit simulation of the matchgate 27 shadow protocol , we investigate how the errors of estimated overlaps depend on the number of shots and number of orbitals . By doing this we numerically obtain concrete formulas characterizing the performance of the matchgate shadow based overlap estimation method that complement the mathematically proven performance guarantees derived in Ref . 25 . In particular we find that the estimated overlaps are essentially normal distributed . In a second step we use this knowledge to investigate the behavior of the TCCSD and ec-CC energy when Gaussian noise is added to exact ( obtained with CASCI ) or approximate ( obtained from a simulated VQE ) overlaps . We find that our conclusions are largely independent of the precise molecular system and state used in the compu- tations . The data presented in the following was obtained using restricted Hartree Fock ( RHF ) /cc-pVDZ83 orbitals of the N2 molecule at a bond distance of 1.09 ˚A . In addition to the chemically reasonable ( 6 , 6 ) active space we have performed simulations for other spin-zero active spaces characterized by n and ζ . For all simulations of matchgate shadows the PennyLane library117 was used to prepare approximate CASCI ground states on 8 qubits by means of the quantum number preserving fabrics82 with 22 layers ( optimized without noise under L-BFGS-B with Π the identity gate starting from initialization method B with a small amount of normal distributed noise added to the initial parameters ) . Overlap computation was done following the protocol from Ref . 25 , using Newton ’ s polynomial interpolation for interpolating the Pfaffian polynomial , which was done with NumPy,118 Sympy,124 and Pfapack.125 ( a ) ( b ) 4 ) ! ) = 70 computational FIG . C.1 : Panel ( a ) shows the covariance matrix of the overlaps between all d = 8 ! / ( 4 ! ( 8 basis states from the half-filling subspace of n = 8 qubits bootstrapped with k = 1000 sub-shadows with s = 2000 shots each drawn randomly from a shadow of 200 000 shots . Panel ( b ) shows on the diagonal for the 4 largest overlaps a histogram of the distribution of the k values computed from each of the sub-shadows from which the covariance matrix was computed . In the scatter plots in the off diagonal positions the blue dots are the overlaps between pairs of basis states for each sub-shadow , the orange diamonds are the mean over the k sub-shadows , and the green crosses are the analytically computed overlaps . − 1 . Statistical Properties of Overlaps Estimated from Finite Shot Matchgate Shadows In this section we analyze the statistical properties of overlaps estimated from finite shot matchgate shadows . We determine variances and covariances between the estimated overlaps via bootstrapping and analyze their distributions . We first generate a shadow of 200 , 000 shots ( individually evaluated circuits measured following an i.i.d . Gaussian unitary ) and then randomly draw k sub-shadows , each of size s , estimate all overlaps for each sub-shadow and then compute the covariance matrix of these estimates . For simplicity we omit the median of means estimation and work with standard arithmetic means throughout . We find solid evidence that the overlaps with different computational basis states are approximately uncorrelated and normal distributed ( Figure C.1 ) . The covariance matrix is diagonally dominated with no visible structure at all in the off-diagonal entries , and the the scatter plots display no correlation . As s and k grow , the bootstrapped variances increasingly concentrate around their mean and bootstrapped covariances e t a t s s i s a b . p m o c f o x e d n I 0 3 6 9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60 63 66 69 0 3 6 9 2 1 5 1 8 1 1 2 4 2 7 2 0 3 3 3 6 3 9 3 2 4 5 4 8 4 1 5 4 5 7 5 0 6 3 6 6 6 9 6 Index of comp . basis state 0.00200 0.00175 0.00150 0.00125 0.00100 0.00075 0.00050 0.00025 0.00000 0.2 0.1 0.0 1 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 1 1 1 0.2 0.1 0.0 0.1 0.2 0.1 0.0 0.1 1.1 1.0 0.9 0.8 Type Shadow Mean Analytic 0.0 0.2 0.0 0.2 0.0 0.2 0.8 1.0 10100101 10011001 01100110 11110000 28 ( a ) ( b ) FIG . C.2 : Panel ( a ) shows the mean of the estimated variances and the mean of the absolute values of the covariances of all basis state overlaps as a function of the number k of shadows with each s = 2000 shots that were used in the bootstrapping . Figure C.1a shows the estimated covariance matrix at k = 1000 where the variances are well converged and covariances are about one order of magnitude smaller . Them decaying further with k , suggests that the actual covariances are zero and the residual values are an artifact of the finite k used in their estimation . Panel ( b ) shows the variances and the variance of their distribution ( “ variance of variances ” ) as a function of s and the bound from Ref . 25. decrease faster than the variances ( Figure C.1a ) . From eq ( 43 ) in Ref . 25 one obtains the bound σ2 4 b ( n , ζ ) /s , where the factor of 4 is due to the additional factor of 2 added to step 4.1.ii of Algorithm 1 in the third arXiv version , which accounts for the fact that ( in the notation of Ref . 25 ) /2 and b ( ζ , n ) is a bound on the variance of the left hand side . We instead find ⟩ numerically that the mean variance ¯σ2 ( decaying as 1/s , as expected ) is in nearly perfect agreement with the slightly tighter bound φ | ⟨ ) | | ρ ⟨ 0 | ( | ≤ ⟩⟨ = φ ψ ρ ⟩ ¯σ2 ⪅ √2 b ( n , ζ ) /s . ( C1 ) Evaluating the bound b ( n , ζ ) in a numerically stable way becomes costly for large n and ζ. Fortunately we find that in the half-filling case ζ = n/2 we have the simple boud b ( n , n/2 ) ⪅ √n , ( C2 ) as can be seen from the power law fit in Figure C.3 . We have seen qualitatively identical statistical properties for other numbers of qubits and states . This motivates the use of a Gaussian additive noise model when investigating the stability of TCCSD computations against imperfections in the input overlaps in the next section . 2 . TCCSD and ec-CC under Gaussian Noise With the additive Gaussian noise model at hand , we next investigate how the energies of the hybrid TCCSD and ec-CC method are influenced by the noise strength σ . To this end , classical CASCI calculations with increasing active space sizes were run , the CI amplitudes were extracted and Gaussian noise ( with standard deviation σ and mean equal to zero ) was added to the amplitude vectors . Subsequently , a TCCSD/ec-CC energy calculation was run for 1 and the used active each realization of the additive noise . This procedure was conducted for σ = 10− spaces are shown in Table C.1 . For each σ and active space , the “ noisy ” TCCSD/ec-CC energy was sampled 100 times to obtain a well converged estimator for the energy error due to noise . The data were generated using the N2 molecule with a bond distance of 1.09˚A from restricted HF/cc-pVDZ83 reference orbitals , artificially constructing the AS around the HOMO-LUMO gap . Note that this procedure would be computationally prohibitive if the overlaps 10 , . . . , 10− 3 10− 4 10− Mean variances Mean absolute covariances Fit with slope 0.0 Fit with slope -0.51 102 103 k 2 10− 3 10− 4 10− 5 10− 6 10− 7 10− 8 10− Mean variances Variances of variances Fit with slope -1.0 Fit with slope -2.07 Wan bound √2 b ( n = 8 , ζ = 4 ) 102 103 s 29 FIG . C.3 : Power law fit for b ( n , n/2 ) ( eq ( C1 ) ) , i.e. , half-filling , including √n as an upper bound for efficient numerical evaluation . TABLE C.1 : Summary of active space sizes and required overlaps d used in Figure C.4.a ) CAS ( ζ , n/2 ) d ( TCCSD ) d ( ec-CC ) ( 2 , 2 ) ( 4 , 4 ) ( 4 , 6 ) ( 6 , 6 ) ( 4 , 8 ) ( 6 , 8 ) ( 8 , 8 ) ( 10 , 10 ) ( 12 , 10 ) ( 12 , 12 ) ( 10 , 14 ) ( 6 , 16 ) ( 8 , 16 ) ( 10 , 16 ) ( 12 , 16 ) 4 27 93 118 199 316 361 876 805 1819 2836 2068 3193 4236 5071 4 36 225 381 784 2436 3355 21126 17255 98694 243376 97956 285255 555336 840796 a ) Only active spaces highlighted in red were used in the case of ec-CC . ± ∆Enoise ∆Enoise ec − = aσβσ yielded an exponent of βσ = 0.9998 were actually computed using a classical simulation of the matchgate shadow protocol . Depending on the active space size and hybrid CC method , the required number of overlaps d to run the final energy calculation varies ( see Table C.1 ) . The dependence of the absolute TCCSD and ec-CC energy errors , , on σ and d is shown in Figure C.4 . A power law fit of the form 0.0016 ( cid:12 ) ± and βσ = 1.001 0.002 for TCCSD and ec-CC , respectively . Thus , the absolute energy error of both methods ( cid:12 ) scales approximately linearly with the noise strength σ . Furthermore , no convergence issues of the classical CC procedures were observed , even for large noise strengths . Consequently , TCCSD and ec-CC when run with noisy input amplitudes , as is expected if they are obtained from actual quantum measurements , are very robust to the strength of the underlying noise due to the linear dependency on σ . This is a rather beneficial behavior of the hybrid methods , given that a large part of the amplitudes are usually rather small and might be even sign-flipped under strong noise . The exponent βσ remains approximately one for other molecular systems as well ( data not shown ) . Note that , however , the prefactor a heavily depends on the system at hand and is irrelevant at this stage of the analysis . Another interesting observation from Figure C.4 is that the absolute errors of both methods are comparable even though ec-CC requires many more overlaps to be evaluated ( see Table C.1 ) . This behavior might be biased by the choice of molecular test system , i.e. , if the magnitude of the T3 and T4 amplitudes ( extracted from CASCI in this ∆E | TCCSD and CC ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) | 101 b ( n , n/2 ) ( 0.956 ± 0.001 ) n0.4990 ± 0.0002 n 6 × 100 b 4 × 100 3 × 100 2 × 100 101 n 102 30 ( a ) ( b ) FIG . C.4 : Absolute TCCSD energy error ( a ) and absolute ec-CC energy error ( b ) as a function of the noise strength σ and the number of required overlaps d for each method . Note that the vertical axis intercept depends on the molecular system . case ) is small , the contribution to the projection equations is only mildly influenced by noise . In the TCCSD case , however , the lower-order frozen T1 and T2 amplitudes are larger in magnitude even for smaller systems , and these amplitudes directly enter the TCCSD energy expression , contrary to ec-CC . 3 . TCCSD Energy Error Extrapolation With the variance bound for overlaps measured through matchgate shadows , it becomes possible to determine the shot budget given an active space size to obtain the overlaps to a certain accuracy . As we observerd above , the TCCSD energy error under noise depends linearly on the standard deviation of the underlying Gaussian distribution . This dependence is , however , not sufficient to estimate the required variance for other molecular systems , since many prop- erties of the system enter the TCCSD calculation and have an influence on the final TCCSD energy error . Another problem is that some properties determining this error can not be directly extracted just from the molecular Hamilto- nian , i.e. , without solving the underlying electronic structure problem , which becomes computationally prohibitive for large active spaces , for example . We thus seek a simple extrapolation model for noisy TCCSD energies , taking as input easy to obtain parameters of a molecular system . Even though we outlined some noise analysis on ec-CC in the section above , we are going to focus exclusively on TCCSD in the following due to its favorable scaling and small number of overlaps required . For the error extrapolation model , which will serve as an input for shot budget estimation , we created a small data set containing 13 small molecules for which we first ran CASCI with a ) different active space sizes ( see Table C.2 ) and b ) different basis sets ( STO-3G , 6-31G , 6-31G * * , cc-pVDZ , aug-cc-pVDZ ) .83,126–133 From the 3 , which were then resulting CASCI states , we extracted the required overlaps and added Gaussian noise with σ = 10− put into a TCCSD energy calculation . For each molecule/basis set/active space combination , the noise was sampled 30 times , such that an averaged could be obtained for each combination . This amounts to approximately 20,000 single-point TCCSD calculations , therefore , we only ran the data collection with TCCSD on a small number of molecules . The settings thus vary a ) the required number of overlaps d ( eq ( C4 ) ) and b ) the number of total spin orbitals N , which are easy to obtain for any molecule of interest . For completeness , the number of non-redundant excitation amplitudes for a spin block σ in nsp spatial orbitals and ζσ electrons with excitation level ν is given by ∆Enoise TCCSD α , β ∈ { ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) } d ( nsp , ζσ , ν ) = 1 ( ν ! ) 2 ν − 1 ( ζσ i=0 ( cid:89 ) i ) ( nsp − − ζσ − i ) . ( C3 ) For TCCSD , we need the overlap with , all non-redundant single excitations , i.e. , α and β single excitations , for double excitations , we have αα , ββ , and αβ excitations , where the latter one corresponds to a single α excitation coupled with a single β excitation . The total number of overlaps for TCCSD thus amounts to Φ0⟩ | 1 + d ( nsp , ζα , 1 ) + d ( nsp , ζβ , 1 ) + d ( nsp , ζα , 2 ) + d ( nsp , ζβ , 2 ) + d ( nsp , ζα , 1 ) d ( nsp , ζβ , 1 ) . ( C4 ) d ≡ 100 10 2 10 4 10 6 10 8 ] h E [ | D e S s C i o C n T E | 10 10 10 12 10 9 10 7 10 5 10 3 10 1 5000 4000 3000 d 2000 1000 100 10 2 10 4 10 6 10 8 ] h E [ | C C e s i o c n e E | 10 10 10 12 80000 60000 d 40000 20000 10 9 10 7 10 5 10 3 10 1 TABLE C.2 : Active spaces used in the test data set for TCCSD energy error extrapolation , including the resulting number of required overlaps d as input for TCCSD . nsp ζα ζβ d 31 6 8 3 3 2 2 3 3 4 4 10 5 5 6 6 118 199 316 361 876 805 12 6 6 1819 14 5 5 2836 16 3 3 2068 4 4 3193 5 5 4236 6 6 5071 8 8 5793 ∆Enoise TCCSD One “ variable ” contributing to , which is highly system-specific , is the “ amount ” of static or dynamic correlation in the system . For example , a weakly correlated molecule , where the dynamic correlation energy is dominant , is only mildly affected by noisy input amplitudes for TCCSD , whereas the opposite might be the case for strongly correlated systems . There is , however , no single quantity that could serve to model this properly . With our choice of molecules , we try to cover several different correlation scenarios , e.g. , diatomic molecules in equilibrium , stretched diatomics , and some small organic molecules . All things considered , after several attempts to build a good error model , we came up with the following power law , ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) In the randomized noise simulations above , we fixed the noise strength , yielding the unknown parameters on the ( cid:12 ) right-hand side as ( cid:12 ) ( cid:12 ) ∆Enoise TCCSD = adβN γσ . ( C5 ) ( cid:12 ) ( cid:12 ) We fitted the above power law to the recorded data over all molecules , basis sets , active space sizes , and noise samples , yielding the exponent parameters shown in Table C.3 together with standard errors determined through bootstrapping ( 50,000 bootstrap samples ) . The prefactor a carries the dependencies on omitted variables ( e.g. , the ( cid:12 ) ( cid:12 ) ∆Enoise TCCSD σ = adβN γ . ( C6 ) TABLE C.3 : Parameters and errors obtained from power law fit over the entire TCCSD noise error data set . Parameter Value Bootstrap Std . Error β γ 0.277 −1.074 0.054 0.116 correlation strength , etc . ) , thus , it is not advisable to fit this parameter globally , i.e. , for all molecules at once . Through running the power law fit on subsets of the sample ( leave-one-out , etc . ) , we could confirm that the exponents seem to be largely independent of the molecular system ( data not shown ) , indicating that the fit parameters describe the trend of the TCCSD error through noise quite well in the simple power law . In the subset power law fits , we found that the prefactor varies largely depending on the molecular systems . For this reason , with the globally fitted exponents β and γ at hand , we re-ran the fit for a for each molecule , keeping the exponents fixed at the fitted values from the entire data set . This yielded a prefactor a for each molecule , shown in Table C.4 and plotted in Figure 4 . The raw data for ∆Enoise including the power law fits is plotted in Figure C.5 . One can clearly see in this plot that the globally fitted exponents represent the slope and trend of basis set dependence well , hinting that we can indeed use the error ( cid:12 ) extrapolation model for active spaces and systems beyond the data set . As expected , the TCCSD error magnitude ( cid:12 ) grows with the number of required overlaps , but decreases with the size of the total MO space ( negative exponent ) . The latter can be rationalized as follows : when keeping the active space size ( and hence the number of overlaps d ) fixed while increasing the overall MO space , the contribution of the AS in relation to the external space decreases , and the error made by noisy amplitude measurements becomes more and more negligible . The remaining hurdle is , TCCSD ( cid:12 ) ( cid:12 ) 32 TABLE C.4 : Prefactor a obtained in a per-molecule fit of the TCCSD noise error data with exponents fixed at D1 values obtained from plain CCSD averaged over basis sets . values from Table C.3 , together with the T1 and Molecule a T1 N2 ( stretched ) 18.67 6.48 F2 ( stretched ) 5.65 p-Benzyne Cl2 ( stretched ) 4.83 4.27 3.20 3.01 3.00 2.98 2.60 2.22 2.56 2.41 F2 N2 H2O Me-NCO Benzene Formaldehyde Acetaldehyde Furan Cl2 0.049 0.023 0.015 0.015 0.010 0.010 0.008 0.014 0.008 0.014 0.013 0.012 0.005 D1 0.107 0.089 0.061 0.081 0.028 0.024 0.017 0.053 0.027 0.045 0.048 0.046 0.018 T1 and given a molecule not present in the data set , to select the prefactor a for that system . This needs to be done by comparing the “ correlation strength ” and finding the best fit in our tabulated data . Since this is a bit cumbersome , we sought for a more tangible metric that is easy to obtain and came up with the typical CCSD diagonstic values , which are commonly used to assess whether the CCSD wavefunction provides a reliable , true SR result or whether D2 diagnostics28,29 for each molecule and basis set . As can be MR methods are needed . We computed the seen in Figure 4 , the trend of the molecule-specific prefactor a and their corresponding diagnostic values are in good agreement with each other . Thus , for the determination of the prefactor of a molecule outside our data set , we suggest T1 diagnostic value , because it has the strongest correlation with a , and to select the prefactor to first compute the T1 to a is given by accordingly ( see Table C.4 ) . The linear model to convert 0.84 . × T1 − Clearly , the stretched N2 molecule is kind of an outlier because the prefactor a and its diagnostic values are far off the median/mean of the data set . This , however , shows that the scenario for N2 can serve as a “ worst case ” scenario , which will be useful in the following to estimate upper bounds for shot budgets . In summary , our error extrapolation protocol relies on the following steps : 375.9 ( C7 ) ≈ a 1 . Select a molecule and basis set ( determining N ) 2 . Compute CCSD in that setting and obtain the T1 diagnostic value 3 . Select an active space size and compute the number of required overlaps for TCCSD d 4 . Map the diagnostic value to a prefactor a using the conversion formula in eq ( C7 ) ( compare with Table C.4 ) 5 . Insert all the quantities ( d , N , a , and the exponents in Table C.3 ) into eq ( C5 ) 6 . Together with a noise strength σ , one can estimate the TCCSD energy error due to noise in that precise setting We will use this procotol in the following to estimate shot budgets for quantum TCCSD . 4 . Shot Budget Estimation Combining eq ( C1 ) with eq ( C5 ) we can obtain a bound on the number of shots needed for guarantee that the shot noise does not change the TCCSD energy by more than a given magnitude . Finally , one can estimate the shot budget for the half-filling case as s ⪅ a2 ∆E | 2 d2βN 2γ√2n | ( C8 ) for a given target TCCSD energy error and the system-dependent variables , obtained through the protocol in the previous section . Using the above equation , we estimated the shot budgets for the scenarios dictated by the molecule ∆E | | 33 as a function of d for different molecules and basis sets with FIG . C.5 : Absolute TCCSD energy error ∆Enoise TCCSD σ = 10− 3 . The dashed lines employ a power law fit using the globally fitted exponents of d and N ( Table C.3 ) together with the molecule-specific prefactor a ( Table C.4 ) . ( cid:12 ) ( cid:12 ) ( cid:12 ) ( cid:12 ) | | ∆E = 10− 3 Eh with an arbitrarily chosen MO space of N = 600 and half- prefactors aiming for a target accuracy filling active spaces from n = 4 to n = 200 qubits . Uncertainties in the fitted exponents were included by estimating a lower bound ( exponent minus bootstrap standard deviation ) and an upper bound ( exponent plus bootstrap standard deviation ) of the shot budget . The resulting shot budget estimates s are plotted in Figure C.6 . Surprisingly , even in the worst case scenario ( strong correlation as in a stretched N2 molecule ) , our estimated upper bound for the shot budget to obtain the ( noisy ) TCCSD energy to chemical precision barely exceeds 108 shots in a 200 qubit setting . We want to stress again that the shots budgets do not include measurements for state preparation/optimization on the quantum device , just the overlap measurements through matchgate shadows . If there were imperfections in the trial state , i.e. , the shot noise is not applied to the exact overlaps , the error of the quantum TCCSD with respect to its ( exact ) classical counter part would be much larger than what our error model predicts . Nonetheless , the broad window of different correlation scenarios covered in here should be helpful enough to get a decent understanding on the order of magnitude of the required shot budget . N2 ( stretched ) F2 ( stretched ) p-Benzyne Cl2 ( stretched ) F2 N2 H2O Me-NCO Benzene Formaldehyde Furan Cl2 Acetaldehyde 102 103 d 102 103 d 102 103 d 10 3 10 4 | D e S s C i o C n T E | 10 5 10 6 10 3 10 4 | D e S s C i o C n T E | 10 5 10 6 10 3 10 4 | D e S s C i o C n T E | 10 5 10 6 10 3 10 4 | D e S s C i o C n T E | 10 5 Basis Set STO-3G 6-31G 6-31G * * cc-pVDZ aug-cc-pVDZ Data recorded power law fit 10 6 102 103 d 34 FIG . C.6 : Shot budget estimation for “ scenarios ” based on molecular systems ( prefactor a ) , with globally fitted exponents ( standard deviation of the exponents from global fit shown as gray shaded areas ) , target energy error ± 3 Eh , N = 600 , ζ = n/2 . Note that the molecules here are just labels for different prefactors a . This is = 10− ∆E | done to cover different possible scenarios of the prefactor , i.e. , figure out best/worst case scenarios for shot budgets based on TCCSD energy error extrapolation . | TABLE C.5 : Shot budgets s estimated using the error extrapolation model for the N2/cc-pVDZ dissociation curve T1 diagnostic needed for obtaining a TCCSD energy in a ( 6 , 6 ) active space to chemical precision , together with the extracted from CCSD . R [ ˚A ] T1 0.8 0.9 1.0 1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.0 2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 0.004 0.006 0.008 0.010 0.012 0.015 0.018 0.020 0.023 0.025 0.028 0.030 0.032 0.035 0.038 0.040 0.042 0.044 0.045 0.046 0.046 ( cid:80 ) s s 5.2 × 103 1.9 × 104 5.0 × 104 1.0 × 105 1.8 × 105 2.8 × 105 4.1 × 105 5.6 × 105 7.3 × 105 9.0 × 105 1.1 × 106 1.3 × 106 1.6 × 106 1.8 × 106 2.2 × 106 2.5 × 106 2.8 × 106 3.0 × 106 3.1 × 106 3.2 × 106 3.3 × 106 2.9 × 107 108 106 s 104 102 101 n 102 a N2 ( stretched ) F2 ( stretched ) p-Benzyne Cl2 ( stretched ) F2 N2 H2O Me-NCO Benzene Formaldehyde Furan Cl2 Acetaldehyde Appendix D : ec-CC on Hardware Data From Google ’ s Sycamore Quantum Processor 35 FIG . D.1 : Root mean squared error ( RMSE ) of the absolute values of the wavefunction coefficients ( CI vector ) extracted from the trial state for four different repetitions . The device noise in the first two repeats is far smaller than in the last two repeats . To investigate the performance of ec-CC on actual noisy data , we used the wavefunctions extracted from Clifford shadows published in Ref . 27 . The raw data can be obtained from Zenodo.134 The trial state wavefunctions ( referred to as “ Q trial ” in the original paper ) were first “ converted ” to real-valued wavefunctions through rotation by the phase of the largest absolute value wavefunction coefficient ( i.e. , making the wavefunction as “ real ” as possible ) , then retaining only the real part of the wavefunction and renormalizing it . This state is referred to as “ Q trial real ” . Since the quality of the trial wavefunctions extracted from the device in the first two repetitions is superior to the other two runs ( see Figure D.1 ) , we only use the data from these runs . TABLE D.1 : H4/STO-3G energies from Q trial state converted to real-valued wavefunction . Absolute errors in mEh with respect to FCI are shown in parentheses . NCliffords Repeat 1 Repeat 2 −1.82121 ( 148.30 ) −1.80389 ( 165.63 ) 10 −1.85039 ( 119.13 ) −1.85554 ( 113.97 ) 16 −1.92465 ( 44.86 ) −1.88711 ( 82.40 ) 28 −1.94073 ( 28.78 ) −1.91560 ( 53.91 ) 47 −1.92072 ( 48.79 ) −1.89485 ( 74.66 ) 80 −1.94335 ( 26.16 ) −1.93524 ( 34.27 ) 136 −1.95366 ( 15.85 ) −1.95132 ( 18.19 ) 229 −1.95760 ( 11.91 ) −1.95954 ( 9.97 ) 387 652 −1.96250 ( 7.01 ) −1.96332 ( 6.20 ) 1100 −1.96616 ( 3.35 ) −1.96553 ( 3.98 ) 1856 −1.96634 ( 3.17 ) −1.96650 ( 3.02 ) 3129 −1.96549 ( 4.02 ) −1.96683 ( 2.69 ) 5276 −1.96604 ( 3.47 ) −1.96634 ( 3.18 ) 8896 −1.96540 ( 4.12 ) −1.96651 ( 3.00 ) 15000 −1.96562 ( 3.90 ) −1.96666 ( 2.85 ) 10 1 E S M R r o t c e v I C 10 2 Experiment 1 2 3 4 101 102 103 104 NCliffords TABLE D.2 : H4/STO-3G ec-CC energies based on Q trial state converted to real-valued wavefunction . Absolute errors in mEh with respect to FCI are shown in parentheses . 36 NCliffords Repeat 1 Repeat 2 −1.97656 ( 7.05 ) −1.97656 ( 7.05 ) 10 −1.97656 ( 7.05 ) −1.97656 ( 7.05 ) 16 −1.97637 ( 6.86 ) −1.97656 ( 7.05 ) 28 −1.97637 ( 6.86 ) −1.97656 ( 7.05 ) 47 −1.97656 ( 7.05 ) −1.97656 ( 7.05 ) 80 −1.97637 ( 6.86 ) −1.97656 ( 7.05 ) 136 −1.97637 ( 6.86 ) −1.96732 ( 2.19 ) 229 −1.96684 ( 2.67 ) −1.96846 ( 1.05 ) 387 652 −1.96779 ( 1.73 ) −1.96858 ( 0.93 ) 1100 −1.96928 ( 0.23 ) −1.96881 ( 0.70 ) 1856 −1.96973 ( 0.22 ) −1.96989 ( 0.38 ) 3129 −1.96929 ( 0.22 ) −1.97074 ( 1.23 ) 5276 −1.96961 ( 0.10 ) −1.97026 ( 0.75 ) 8896 −1.96893 ( 0.58 ) −1.97023 ( 0.72 ) 15000 −1.96891 ( 0.60 ) −1.97028 ( 0.76 ) TABLE D.3 : H4/STO-3G ec-CC energies based on the exact FCI state with overlaps measured through matchgate shadows . The results are averaged over 30 samples of the matchgate shadow . Absolute errors in mEh with respect to FCI are shown in parentheses . Shots multi Matchgate single Matchgate 10000 −1.98029 ( 10.89 ) −1.96906 ( 3.32 ) 20000 −1.97662 ( 7.62 ) −1.96990 ( 2.33 ) 50000 −1.97160 ( 4.84 ) −1.96927 ( 1.35 ) 100000 −1.96922 ( 2.64 ) −1.96933 ( 0.88 ) 200000 −1.96965 ( 1.88 ) −1.96945 ( 0.55 ) 500000 −1.96937 ( 1.07 ) −1.96945 ( 0.39 ) 1000000 −1.96963 ( 0.75 ) −1.96949 ( 0.23 ) TABLE D.4 : Error in the total energy ( in kcal/mol ) of the diamond minimal unit cell in a double-zeta basis as a function of the lattice constant R. R [ ˚A ] Q trial Q trial real ec-CC/Q trial TCCSD/Q trial QC-QMC CAS ( 8,8 ) ec-CC/CAS NEVPT2 TCCSD/CAS CCSD ( T ) AFQMC 2.88 3.24 3.60 3.96 4.32 266.58 1006.44 177.30 208.04 327.49 174.89 693.05 137.78 159.25 233.19 4.31 6.60 6.41 10.10 15.01 19.34 20.74 36.97 37.95 27.47 0.05 −0.85 1.17 3.46 4.44 51.15 51.96 52.45 52.84 53.14 3.17 4.11 5.49 7.70 11.66 0.68 0.71 0.67 0.54 0.66 1.11 1.04 0.72 0.17 −0.18 −0.35 −0.59 −1.10 −2.17 −4.40 2.76 3.15 4.99 8.47 16.54","['c', 'e', 'h', 'p', 'q', 'v', 'r', 'tailored', 'externally', 'correct', 'couple', 'cluster', 'scheurer1', '∗', 'r', 'anselmetti1', 'gogolin1', '‡', 'quantum', 'date', 'propose', 'use', 'wavefunction', 'overlap', 'obtain', 'quantum', 'computer', 'input', 'classical', 'splitamplitude', 'technique', 'tailor', 'externally', 'correct', 'couple', 'cluster', 'achieve', 'balanced', 'treatment', 'static', 'dynamic', 'correlation', 'effect', 'molecular', 'electronic', 'structure', 'simu', 'lation', 'combine', 'insight', 'statistical', 'property', 'matchgate', 'shadow', 'use', 'measure', 'quantum', 'trial', 'state', 'overlap', 'classical', 'correlation', 'diagnostic', 'able', 'provide', 'quantum', 'resource', 'estimate', 'well', 'classically', 'long', 'exactly', 'solvable', 'regime', 'find', 'rather', 'imperfect', 'wavefunction', 'remarkably', 'low', 'shot', 'count', 'sufficient', 'cure', 'qualitative', 'failure', 'plain', 'couple', 'cluster', 'single', 'double', 'obtain', 'chemically', 'precise', 'dynamic', 'energy', 'correction', 'provide', 'insight', 'wavefunction', 'preparation', 'scheme', 'chance', 'yield', 'quantum', 'advantage', 'test', 'propose', 'method', 'use', 'overlap', 'measure', 'sycamore', 'device', 'introduction', 'recent', 'work', 'devise', 'use', 'quantum', 'computer', 'model', 'electronic', 'structure', 'continue', 'suggest', 'fermionic', 'simulation', 'valuable', 'viable', 'application', 'nearterm', 'faulttolerant', 'quantum', 'device', 'classical', 'modeling', 'electronic', 'structure', 'various', 'strategy', 'explore', 'treat', 'different', 'aspect', 'electron', 'correlation', 'quantum', 'algorithm', 'largely', 'follow', 'similar', 'divideandconquer', 'trajectory', 'treatment', 'strong', 'correlation', 'cite', 'likely', 'motivation', 'apply', 'quantum', 'computer', 'chemistry1', 'accurate', 'treatment', 'dynamic', 'electronic', 'correlation', 'effect', 'important', 'aspect', 'consider', 'total', 'quantum', 'resource', 'count', 'viability', 'apply', 'quantum', 'compute', 'protocol', 'solve', 'electronic', 'structure', 'problem', 'work', 'far', 'integrate', 'classical', 'electronic', 'structure', 'methodology', 'quantum', 'computation', 'low', 'measurement', 'requirement', 'need', 'dynamical', 'correlation', 'correction', 'focus', 'splitamplitude', 'coupled', 'cluster', 'methodology', 'widely', 'study', 'quantum', 'chemistry', 'community23', 'specifically', 'analyze', 'robustness', 'quantum', 'input', 'theory', 'motivate', 'wavefunction', 'characteristic', 'quantum', 'computer', 'satisfy', 'improve', 'classical', 'approximate', 'external', 'amplitude', 'input', 'generally', 'possible', 'layer', 'quantum', 'state', 'preparation', 'many', 'dynamic', 'correlation', 'correction', 'splitamplitude', 'method', 'provide', 'necessary', 'framework', 'analyze', 'sampling', 'cost', 'robustness', 'common', 'usually', 'loose', 'tomographic', 'sampling', 'bound', 'date', 'exist', 'several', 'approach', 'include', 'dynamic', 'correlation', 'effect', 'quantum', 'simulation', 'chem', 'istry', 'eg', 'virtual', 'quantum', 'subspace', 'expansion', 'secondorder', 'perturbation', 'theory', 'use', 'variational', 'quantum', 'together', 'subspace', 'expansion', 'name', 'nonorthogonal', 'configuration', 'interaction', 'approaches8', 'nevpt2', 'base', 'qubit', 'reduce', 'density', 'matrix', 'name', 'qrdmnevpt29', 'note', 'plethora', 'method', 'study', 'chemical', 'system', 'exist', 'eg', 'base', 'embed', 'techniques10–17', 'qrdmnevpt2', 'method', 'addition', 'state', 'preparation', 'optimization', 'require', 'quantum', 'evaluation', 'threeparticle', 'reduce', 'density', 'matrix', '3rdm', 'fourparticle', 'rdmlike', 'term', 'exploit', 'cumulant', 'approximation', 'quantum', 'active', 'space', 'method', 'already', 'quite', 'resourceintense', 'respect', 'require', 'number', 'measurement', 'repetition', 'socalle', 'shot', 'accurately', 'determine', '2rdm', 'energy', 'evaluation', 'consequence', 'multitude', 'approach', 'efficient', 'measurement', '2rdm', 'evolve', 'far', 'reduce', 'number', 'distinct', 'measurement', 'basis', 'variance', 'thus', 'burden', 'even', 'measurement', 'require', 'higherorder', 'reduce', 'density', 'matrix', 'eg', 'qrdmnevpt2', 'pose', 'question', 'construct', 'hybrid', 'quantumclassical', 'approach', 'rely', 'rdms', 'recent', 'work', 'leverag', 'ing', 'classical', 'shadows26', 'combine', 'auxiliaryfield', 'quantum', 'suggest', 'efficient', 'path', 'forward', 'shift', 'focus', 'wavefunction', 'correction', 'lieu', 'rdms', '∗', 'correspond', 'author', 'maximilianscheurer', 'current', 'address', 'lab', 'corresponding', 'author', 'fig', 'visual', 'representation', 'quantum', 'splitamplitude', 'protocol', 'analyze', 'work', 'end', 'propose', 'use', 'quantum', 'trial', 'state', 'input', 'tailor', 'couple', 'cluster', 'tcc', 'externally', 'correct', 'couple', 'cluster', 'method', 'quantum', 'device', 'level', 'require', 'prepare', 'suitable', 'state', 'measure', 'overlap', 'state', 'excited', 'slater', 'determinant', 'correspond', 'computational', 'basis', 'state', 'overlap', 'step', 'require', 'obtain', 'quantum', 'input', 'run', 'subsequent', 'classical', 'cc', 'calculation', 'depict', 'figure', 'compare', 'workflow', 'purely', 'classical', 'counterpart', 'building', 'block', 'differ', 'quantum', 'classical', 'version', 'extract', 'computational', 'basis', 'overlap', 'propose', 'leverage', 'various', 'form', 'classical', 'shadows26', 'measurement', 'technique', 'allow', 'efficient', 'estimation', 'multiple', 'expectation', 'value', 'recently', 'extend', 'use', 'matchgate', 'group', 'efficient', 'overlap', 'protocol', 'fulfill', 'requirement', 'provide', 'overlap', 'magnitude', 'sign', 'need', 'subsequent', 'cluster', 'analysis', 'contrast', 'classical', 'tcc', 'methodology', 'develop', 'date', 'quantum', 'tcc', 'require', 'analysis', 'improvement', 'classical', 'approximate', 'method', 'possible', 'sensitivity', 'method', 'device', 'shot', 'noise', 'take', 'step', 'address', 'question', 'work', 'note', 'propose', 'methodology', 'limit', 'particular', 'quantum', 'computing', 'setting', 'cc', 'method', 'completely', 'agnostic', 'origin', 'cluster', 'amplitude', 'hence', 'applicable', 'nearterm', 'faulttolerant', 'setup', 'alike', 'provide', 'protocol', 'evaluate', 'overlap', 'exist', 'total', 'number', 'computational', 'basis', 'state', 'overlap', 'scale', 'exponentially', 'number', 'qubit', 'tcc', 'single', 'double', 'tccsd', 'require', 'polynomial', 'number', 'overlap', 'input', 'cluster', 'analysis', 'ie', 'less', 'tccsd', 'less', 'substantial', 'component', 'work', 'involve', 'construct', 'noise', 'model', 'matchgate', 'shadow', 'mapping', 'model', 'measurement', 'overhead', 'give', 'common', 'electronic', 'structure', 'metric', 'cheaply', 'available', 'implement', 'matchgate', 'shadow', 'describe', 'numerically', 'verify', 'measurement', 'computational', 'basis', 'state', 'overlap', 'follow', 'gaussian', 'distribution', 'independent', 'identically', 'distribute', 'determine', 'shot', 'budget', 'tccsd', 'use', 'gaussian', 'noise', 'model', 'matchgate', 'shadow', 'fit', 'total', 'shot', 'requirement', 'particular', 'd1', 'diagnostics2829', 'analyze', 'error', 'power', 'law', 'distribution', 'constant', 'determine', 'wellknown', 'robustness', 'eccc', 'experimental', 'classical', 'shadow', 'emphasize', 'regime', 'utility', 'demonstrate', 'method', 'robustness', 'real', 'experimental', 'noise', 'use', 'datum', 'take', 'recent', 'qcqmc', 'experiment', 'collaborators27', 'continue', 'methodological', 'account', 'overview', 'splitamplitude', 'method', 'expert', 'reader', 'directly', 'skip', 'section', 'discuss', 'impact', 'possible', 'quantum', 'trial', 'state', 'quality', 'require', 'ment', 'splitamplitude', 'quantum', 'cc', 'method', 'furthermore', 'present', 'numerical', 'result', 'quantum', 'tccsd', 'simulate', 'dissociation', 'curve', 'vqebased', 'nisq', 'set', 'far', 'highlight', 'state', 'preparation', 'robust', 'ness', 'describe', 'overlap', 'measurement', 'strategy', 'section', 'key', 'ingredient', 'provide', 'quantum', 'input', 'base', 'numerical', 'study', 'statistical', 'property', 'matchgate', 'shadow', 'develop', 'noise', 'model', 'mimic', 'noise', 'employ', 'noise', 'model', 'obtain', 'quantum', 'resource', 'estimate', 'classically', 'tractable', 'molecular', 'system', 'n2', 'dissociation', 'curve', 'point', 'doublezeta', 'basis', 'set', 'find', 'total', 'shot', 'enough', 'chemically', 'precise', 'result', 'finally', 'section', 'classical', 'computer', 'hf', 'reference', 'active', 'space', 'hamiltonian', 'quantum', 'computer', 'multiconfigurational', 'method', 'quantum', 'trial', 'preparation', 'molecular', 'orbital', 'overlap', 'extraction', 'overlap', 'measurement', 'classical', 'shadow', 'cluster', 'analysis', 'calculation', 'study', 'performance', 'quantum', 'splitamplitude', 'cc', 'energetic', 'diamond', 'use', 'classical', 'shadow', 'datum', 'experiment', 'perform', 'sycamore', 'device', 'demonstrating', 'principle', 'compete', 'ii', 'background', 'electronic', 'structure', 'method', 'field', 'quantum', 'chemistry', 'see', 'remarkable', 'progress', 'past', 'decade', 'abinitio', 'couple', 'cluster', 'method', 'emerge', 'reliable', 'systematically', 'improvable', 'framework', 'electronic', 'structure', 'simulation', 'molecules30–32', 'successful', 'method', 'family', 'probably', 'couple', 'cluster', 'single', 'double', 'conjunction', 'perturbative', 'triple', 'correction', 'commonly', 'refer', 'gold', 'standard', 'quantum', 'therefore', 'possibly', 'use', 'wavefunction', 'method', 'investigate', 'property', 'small', 'mediumsized', 'molecule', 'limit', 'applicability', 'steep', 'scaling', 'recent', 'endeavour', 'however', 'make', 'possible', 'push', 'boundary', 'respect', 'system', 'size', 'even', 'further36', 'favorable', 'property', 'size', 'consistency', 'contrast', 'truncated', 'configuration', 'interaction', 'ans¨atze37', 'singlereference', 'srcc', 'method', 'usually', 'perform', 'well', 'describe', 'molecular', 'system', 'dynamic', 'correlation', 'effect', 'dominant38', 'contrary', 'srcc', 'approach', 'struggle', 'multireference', 'scenario', 'describe', 'potential', 'energy', 'surface', 'bond', 'break', 'lead', 'catastrophic', 'failure', 'several', 'failure', 'principle', 'remedie', 'even', 'computationally', 'demanding', 'framework', 'multireference', 'mrcc', 'case', 'system', 'hand', 'almost', 'purely', 'statically', 'correlate', 'solution', 'electronic', 'schr¨oding', 'equation', 'well', 'describe', 'couple', 'slater', 'determinant', 'accurate', 'result', 'obtain', 'socalled', 'multiconfigurational', 'active', 'space', 'method', 'complete', 'active', 'space', 'configuration', 'interaction', '41–45', 'active', 'space', 'consist', 'subset', 'molecular', 'orbital', 'electron', 'full', 'configuration', 'interaction', 'fci', 'problem', 'solve', 'approach', 'cover', 'static', 'correlation', 'effect', 'well', 'neglect', 'major', 'part', 'dynamic', 'correlation', 'effect', 'choose', 'active', 'space', 'hence', 'division', 'active', 'external', 'orbital', 'space', 'introduce', 'approximation', 'qualitative', 'phenomenon', 'describe', 'correctly', 'become', 'unacceptable', 'chemical', 'precision', 'technique', 'select', 'methods47–51', 'density', 'matrix', 'renormalization', 'group', 'dmrg', 'become', 'possible', 'simulate', 'quite', 'large', 'active', 'space', 'even', 'aim', 'fci', 'quality', 'active', 'space', 'size', 'increase', 'enough', 'dynamic', 'correlation', 'contribution', 'approximately', 'include', 'perturbation', 'theory', 'method', 'yield', 'eg', 'wellknown', 'caspt2', 'nevpt2', 'fortunately', 'wellknown', 'framework', 'srcc', 'offer', 'possibility', 'capture', 'static', 'correlation', 'property', 'astype', 'wavefunction', 'socalled', 'splitamplitude', 'ansatz', 'prominent', 'method', 'family', 'tailor', 'couple', 'cluster', 'tcc', 'externally', 'correct', 'couple', 'cluster', 'however', 'approach', 'encoding', 'static', 'correlation', 'effect', 'different', 'direction', 'highlevel', 'idea', 'method', 'extract', 'information', 'static', 'correlation', 'wavefunction', 'inject', 'specific', 'partitioning', 'cluster', 'operator', 'correspond', 'amplitude', 'srcc', 'wavefunction', 'originally', 'method', 'develop', 'remedy', 'failure', 'srcc', 'approach', 'strongly', 'correlate', 'regime', 'explain', 'previously', 'tcc', 'schematically', 'illustrate', 'figure', 'theoretical', 'detail', 'outline', 'tcc', 'ansatz', 'cluster', 'operator', 'split', 'active', 'space', 'part', 'external', 'part', 'tcc', 'ˆt', 'ext', 'cluster', 'amplitude', 'accompany', 'active', 'space', 'cluster', 'operator', 'obtain', 'figurational', 'wavefunction', 'cluster', 'analysis', 'cluster', 'analysis', 'rely', 'equivalence', 'exponential', 'linear', 'ci', 'expansion', 'use', 'intermediate', 'normalization', 'make', 'possible', 'recursively', 'convert', 'amplitude', 'cilike', 'wavefunction', 'corresponding', 'single', 'dou', 'ble', 'yield', 'socalled', 'tccsd', 'approach', 'strategy', 'extract', 't1', 'amplitude', 'astype', 'wavefunction', 'active', 'space', 't1', 'amplitude', 'freeze', 'cc', 'iteration', 'external', 'amplitude', 'assume', 'active', 'space', 'amplitude', 'retain', 'information', 'original', 'work', 'coworker', 'show', 'simplicity', 'tccsd', 'yield', 'dissociation', 'energy', 'potential', 'energy', 'surface', 'good', 'agreement', 'higherlevel', 'note', 'input', 'require', 'tcc', 'overlap', 'excited', 'slater', 'determinant', 'wavefunction', 'formulate', 'follow', 'projection', 'cν', 'equation', 'coefficient', 'vector', 'excitation', 'level', 'ν', 'respect', 'fermi', 'vacuumreference', 'determinant', 'νfold', 'excited', 'slater', 'determinant', 'astype', 'wavefunction', 'fig', 'schematic', 'illustration', 'tcc', 'leave', 'right', 'tcc', 'subset', 'cluster', 'amplitude', 'cluster', 'analysis', 'external', 'set', 'amplitude', 'obtain', 'active', 'space', 'wavefunction', 'solve', 'presence', 'frozen', 'amplitude', 'encode', 'information', 'static', 'correlation', 'use', 'amplitude', 'input', 'wavefunction', 'stem', 'active', 'space', 'full', 'space', 'solve', 'full', 'ccsdtq', 'single', 'double', 'equation', 'presence', 'external', 'amplitude', 'coefficient', 'extract', 'tccsd', 'c1', 'ν', 'ν', 'coefficient', 'need', 'extract', 'cab', 'b', 'socalle', 'virtual', 'orbital', 'index', 'unoccupied', 'addition', 'overlap', 'reference', 'determinant', 'intermediatenormalize', 'index', 'j', 'refer', 'occupy', 'orbital', 'subsequently', 'c', 'amplitude', 'recursively', 'convert', 'amplitude', 'map', 'active', 'orbital', 'full', 'mo', 'space', 'keep', 'fix', 'solution', 'projection', 'equation', 'quite', 'appealing', 'minor', 'modification', 'standard', 'code', 'need', 'make', 'support', 'tailor', 'different', 'type', 'input', 'wavefunction', 'successfully', 'use', 'dmrg', 'large', 'active', 'spaces66', 'pair', 'couple', 'cluster', 'double', 'pccd', 'recent', 'extension', 'excited', 'state', 'calculation', 'present', 'exist', 'tailor', 'counterpart', 'compute', 'perturbative', 'triple', 'correction', 'solely', 'use', 'external', 'contribution', 'cluster', 'amplitude', 'combination', 'lpno', 'dlpno', 'framework', 'tcc', 'successfully', 'employ', 'study', 'electronic', 'structure', 'large', 'molecular', 'complexes70–72', 'furthermore', 'underlie', 'numerical', 'theoretical', 'aspect', 'thoroughly', 'analyze', 'mathematical', 'point', 'view7374', 'even', 'tailoring', 't1', 'amplitude', 'capture', 'static', 'correlation', 'effect', 'extent', 'final', 'tccsd', 'wavefunction', 'still', 'wavefunction', 'know', 'fail', 'level', 'shortcoming', 'circumvent', 'increase', 'active', 'space', 'size', 'choice', 'second', 'splitamplitude', 'approach', 'address', 'inclusion', 'multireference', 'phenomenon', 'srcc', 'wavefunction', 'different', 'direction3', 'view', 'variation', 'tailor', 'coupled', 'cluster', 'full', 'space7778', 'use', 'fact', 'single', 'double', 'residual', 'equation', 'involve', 'single', 'amplitude', 'quadruple', 'amplitude', 'ij', '⟨', 'ˆhn', 'cid20', 'ˆt1', 'ˆt2', 'φa', 'cid20', 'ˆt3', 'ˆt1', 'ˆt2', 'ˆt1', 'ˆt2', 'ˆt3', 'ˆt1', 'ˆt2', 'cid18', 'ˆt4', 'ˆt1', 'ˆt3', 'ˆt', 'ˆt2', 'ˆt', 'φ0⟩', 'cid19', 'c', 'cid19', 'c', 'true', 'rank', 'couple', 'cluster', 'operator', 'normalordered', 'hamiltonian', 'twobody', 'interaction', 'triple', 'quadruple', 'amplitude', 'ˆt3', 'ˆt4', 'exactly', 'determined', 'fci', 'exact', 'correlation', 'energy', 'recover', 'expect', 'exact', 'amplitude', 'ˆt3', 'ˆt4', 'depend', 'coefficient', 'rank', 'however', 'provide', 'alternative', 'route', 'well', 'ccsd', 'calculation', 'approximate', 'triple', 'quadruple', 'obtain', 'astype', 'method', 'ψas', 'ext', 'ψinput', 'ˆt3', 'ˆt4', 'ˆt1', 'ˆt2', 'ˆt3', 'ˆt4', 'ψtcc', 'exp', 'ˆt', 'ˆt', 'exp', 'ˆt2', 'ˆt3', 'ˆt4', 'cid17', 'obvious', 'instance', 'provide', 'value', 'eg', 'wavefunction', 'cluster', 'operator', 'rank', 'use', 'active', 'space', 'version', 'case', 'improvement', 'observed79', 'key', 'component', 'treatement', 'provide', 'improvement', 'describe', 'summarize', 'context', 'quantum', 'wavefunction', 'section', 'main', 'idea', 'use', 'frozen', 'triple', 'quadruple', 'amplitude', 'obtain', 'way', 'solve', 'single', 'double', 'presence', 'determine', 'correct', 'form', 'quadruple', 'involve', 'character', 'practice', 'noncc', 'wavefunction', 'theory', 'active', 'space', 'use', 'determine', 'dominant', 'triple', 'quadruple', 'excitation', 'cluster', 'operator', 'take', 'form', 'ˆt', 'ˆt1', 'ˆt2', 'ˆp3', 'ˆt3', 'ˆp4', 'ˆt4', 'project', 'subset', 'triple', 'quadruple', 'excitation', 'dictate', 'correlate', 'multireference', 'calculation', 'dmrg', 'heatbath', 'adaptive', 'alternatively', 'use', 'uncoverged', 'fciqmc', 'calculation', 'recover', 'approximate', 'triple', 'quadruple', 'amplitude', 'solve', 'ˆt1', 'parts79', 'demonstrate', 'roughly', 'converge', 'fciqmc', 'calculation', 'result', 'quite', 'accurate', 'ccsdtq', 'energie', 'role', 'fciqmc', 'calculation', 'determine', 'dominant', 'triple', 'quadruple', 'amplitude', 'caveat', 'classical', 'computational', 'effort', 'scale', 'see', 'contrary', 'tccsd', 'n', 'scale', 'limit', 'applicability', 'system', 'modest', 'size', 'tcc', 'require', 'kind', 'input', 'namely', 'overlap', 'slater', 'determinant', 'astype', 'wavefunction', 'put', 'cluster', 'analysis', 'protocol', 'context', 'quantum', 'computation', 'appealing', 'advantage', 'higherorder', 'rdms', 'require', 'enable', 'splitamplitude', 'cc', 'calculation', 'base', 'quantum', 'trial', 'state', 'impact', 'quantum', 'trial', 'state', 'quality', 'section', 'first', 'investigate', 'stability', 'tccsd', 'overlap', 'derive', 'imperfect', 'wavefunction', 'state', 'prepare', 'shallow', 'vqe', 'circuit', 'find', 'even', 'wavefunction', 'energy', 'differ', 'significantly', 'casci', 'yield', 'tccsd', 'dynamic', 'correlation', 'energy', 'correction', 'good', 'agreement', 'tccsd', 'nevpt2', 'base', 'exact', 'wavefunction', 'surprising', 'even', 'rather', 'inaccurate', 'wavefunction', 'input', 'turn', 'sufficient', 'cure', 'appearance', 'qualitatively', 'incorrect', 'reaction', 'barrier', 'plain', 'ccsd', 'far', 'able', 'provide', 'insight', 'wavefunction', 'chance', 'lead', 'improved', 'energy', 'full', 'orbital', 'space', 'quantum', 'tccsd', 'approximate', 'vqe', 'wavefunction', 'model', 'dissociation', 'n2', 'triple', 'bond', 'textbook', 'example', 'dynamic', 'static', 'correlation', 'regime', 'need', 'converge', 'well', 'quantitatively', 'reliable', 'results2', 'first', 'tccsd', 'work2', 'show', 'tccsd', 'tailor', 'electron', 'orbital', 'give', 'qualitatively', 'quantitatively', 'correct', 'dissociation', 'curve', 'contrast', 'plain', 'ccsd', 'goal', 'assess', 'tailor', 'prominent', 'quantum', 'method', 'simulate', 'electronic', 'structure', 'behave', 'similarly', 'underlie', 'vqe', 'circuit', 'require', 'prepare', 'exact', 'casci', 'state', 'affordable', 'want', 'analyze', 'inaccuracy', 'wavefunction', 'ansatz', 'translate', 'tccsd', 'even', 'lead', 'breakdown', 'beneficial', 'property', 'tccsd', 'purpose', 'set', 'quantumnumberpreserve', 'circuit', 'layer', 'parameter', 'optimize', 'geometry', 'dissociation', 'curve', 'reference', 'state', 'obtain', 'restricted', 'hfccpvdz83', 'stress', 'test', 'respect', 'rather', 'shallow', 'vqe', 'circuit', 'run', 'base', 'overlap', 'obtain', 'analytically', 'final', 'vqe', 'state', 'readout', 'coefficient', 'state', 'vector', 'refer', 'vqetccsd', 'follow', 'dissociation', 'curve', 'vqetccsd', 'show', 'figure', 'left', 'panel', 'previously', 'observe', 'equilibrium', 'region', 'well', 'describe', 'method', 'yield', 'qualitatively', 'incorrect', 'virtual', 'reaction', 'barrier', 'triple', 'bond', 'breaking', 'fully', 'recover', 'tccsd2', 'provide', 'accurate', 'numerical', 'value', 'dissociation', 'energy', 'curve', 'result', 'small', 'dissociation', 'energy', 'show', 'important', 'inclusion', 'dynamic', 'correlation', 'effect', 'become', 'accurate', 'simulation', 'compare', 'casci', 'tccsd', 'barrier', 'shift', 'millihartree', 'meh', 'meh', 'meh', 'significant', 'change', 'comparison', 'run', 'nevpt2', 'casci', 'system', 'yield', 'almost', 'exactly', 'dissociation', 'curve', 'tccsd', 'shallow', 'circuit', 'use', 'simulation', 'predict', 'reaction', 'barrier', 'artificially', 'high', 'vqetccsd', 'repair', 'incorrect', 'energy', 'contribution', 'active', 'space', 'circuit', 'expressive', 'enough', 'obtain', 'dissociation', 'curve', 'identical', 'upper', 'fig', 'dissociation', 'curve', 'n2', 'use', 'classical', 'quantum', 'method', 'leave', 'panel', 'energy', 'error', 'employ', 'ansatz', 'upper', 'right', 'panel', 'external', 'correlation', 'energy', 'eext', 'tccsd', 'method', 'low', 'right', 'panel', 'dissociation', 'curve', 'energy', 'relative', 'minimum', 'energy', 'internuclear', 'distance', 'r', '˚a', 'note', 'relative', 'energy', 'tccsd', 'nevpt2', 'almost', 'lie', 'top', 'right', 'panel', 'figure', 'error', 'energy', 'respect', 'show', 'bond', 'distance', 'r', '˚a', 'energy', 'error', 'large', 'meh', 'steadily', 'increase', 'dissociation', 'limit', 'equilibrium', 'bond', 'distance', 'system', 'possess', 'weak', 'static', 'correlation', 'effect', 'shallow', 'circuit', 'course', 'much', 'accurate', 'region', 'look', 'vqetccsd', 'dissociation', 'curve', 'artificial', 'reaction', 'barrier', 'present', 'ie', 'poor', 'quality', 'quality', 'underlying', 'wavefunction', 'seem', 'good', 'enough', 'heal', 'physically', 'wrong', 'behavior', 'interestingly', 'energy', 'meh', 'shift', 'vqetccsd', 'meh', 'meh', 'almost', 'identical', 'energy', 'shift', 'casci', 'imperfection', 'wavefunction', 'parallel', 'narrow', 'external', 'energy', 'contribution', 'eext', 'depict', 'tccsd', 'vqetccsd', 'low', 'right', 'panel', 'figure', 'contribution', 'external', 'tccsd', 'part', 'almost', 'identical', 'show', 'dynamic', 'energy', 'contribution', 'robust', 'poor', 'cilike', 'wavefunction', 'produce', 'shallow', 'circuit', 'error', 'energy', 'shift', 'cilike', 'method', 'tccsd', 'approximately', 'order', 'magnitude', 'small', 'plain', 'vqe', 'error', 'note', 'quantum', 'input', 'vqetccsd', 'amount', 'measure', 'less', 'overlap', 'value', 'possible', 'pt', 'approach', 'require', 'higherorder', 'b', 'wavefunction', 'suitable', 'externally', 'correct', 'section', 'discuss', 'characteristic', 'quantum', 'trial', 'potential', 'benefit', 'classically', 'accessible', 'wavefunction', 'input', 'nisq', 'set', 'shortage', 'method', 'prepare', 'approximate', 'ground', 'consider', 'faulttolerance', 'even', 'wide', 'set', 'method', 'emphasize', 'recent', 'work', 'magoula', 'provide', 'framework', 'analyze', 'type', 'expansion', 'source', 'external', 'cluster', 'amplitude', 'potentially', 'yield', 'improved', 'energy', 'work', 'server', 'blueprint', 'type', 'wavefunction', 'quantum', 'computer', 'need', 'prepare', 'potentially', 'see', 'energy', 'improvement', 'solve', 'equation', 'core', 'derivation', 'follow', 'theorem', 'theorem', 'solution', 'truncated', 'configuration', 'interaction', 'set', 'equation', 'include', 'full', 'single', 'full', 'double', 'set', 'high', 'excitation', 'satisfy', 'coupled', 'cluster', 'single', 'double', 'equation', 'h', 'e', 'e', 'n', 'e', 'e', 'r', 'l', 'h', 'e', 'r', 'r', 'r', 'e', 'c', 'c', 'h', 'e', 'e', 'r', 'r', 'å', 'prove', 'theorem', 'algebraically', 'diagrammatically', 'reproduce', 'algebraic', 'proof', 'completeness', 'key', 'takeaway', 'order', 'equation', 'provide', 'improvement', 'expansion', 'include', 'connect', 'component', 'rank', 'cluster', 'amplitude', 'nonzero', 'ciampltiude', 'furthermore', 'see', 'improvement', 'expansion', 'require', 'ci', 'expansion', 'include', 'triple', 'quadruple', 'excitation', 'suggest', 'quantum', 'circuit', 'explore', 'dominant', 'manybody', 'excitation', 'large', 'system', 'useful', 'input', 'support', 'interpretation', 'clas', 'sical', 'study', 'use', 'fciqmc', 'external', 'source', 'method', 'sample', 'highenergy', 'connection', 'truncate', 'ci', 'consider', 'strongly', 'analogy', 'quantum', 'circuit', 'provide', 'support', 'use', 'particular', 'quantum', 'circuit', 'sample', 'highenergy', 'excitation', 'new', 'perspective', 'serve', 'different', 'design', 'principle', 'construct', 'quantum', 'circuit', 'ansatze', 'potential', 'classical', 'computation', 'connection', 'rule', 'state', 'ansatze', 'efficient', 'estimate', 'amplitude', 'additive', 'error', 'circuit', 'build', 'fix', 'bond', 'dimension', 'mp', 'comparably', 'generally', 'statement', 'make', 'quantum', 'input', 'useful', 'tcc', 'active', 'space', 'quantum', 'measurement', 'overlap', 'quantum', 'method', 'propose', 'input', 'amplitude', 'determine', 'quantum', 'state', 'overlap', 'help', 'quantum', 'computer', 'jordanwigner', 'mapping', 'fermion', 'qubit', 'use', 'slater', 'determinant', 'overlap', 'correspond', 'overlap', 'computational', 'basis', 'state', 'nonrelativistic', 'secondquantize', 'molecular', 'hamiltonian', 'loss', 'generality', 'choose', 'real', 'write', 'computational', 'basis', 'eigenstate', 'real', 'suitable', 'state', 'preparation', 'method', 'use', 'overlap', 'computational', 'basis', 'state', 'real', 'however', 'sign', 'overlap', 'enter', 'cluster', 'analysis', 'sample', 'quantum', 'trial', 'state', 'n', 'qubit', 'ζ', 'electron', 'computational', 'basis', 'sufficient', 'various', 'method', 'know', 'use', 'estimate', 'overlap', 'include', 'sign', 'family', 'method', 'suitable', 'task', 'receive', 'lot', 'attention', 'recently', 'classical', 'shadows26', 'extension', 'technique', 'gear', 'specifically', 'fermionic', 'method', 'common', 'give', 'state', 'one', 'draw', 'unitarie', 'u', 'ensemble', 'classically', 'efficiently', 'describable', 'unitarie', 'description', 'draw', 'unitarie', 'together', 'record', 'socalled', 'classical', 'result', 'computational', 'basis', 'state', 'measurement', 'state', 'shadow', 'classical', 'shadow', 'use', 'purely', 'classical', 'computation', 'predict', 'various', 'property', 'state', 'particularly', 'relevant', 'work', 'protocol', 'base', 'ensemble', 'matchgate', 'circuit', 'haar', 'measure', 'general', 'fermionic', 'gaussian', 'unitarie', 'allow', 'estimate', 'overlap', 'slater', '√n', 'log', 'quantum', 'measurement', 'shot', 'determinant', 'additive', 'error', 'ϵ', 'shadow', 'consist', 'fully', 'parallelizable', 'classical', 'computational', 'effort', 'overlap', 'scale', 'ζ2', 'scaling', 'possible', 'see', 'protocol', 'need', 'prepare', 'improvement', 'n', 'state', 'preparation', 'method', 'preserve', 'superposition', 'reference', 'state', 'true', 'vacuum', 'fermion', 'number', 'achieve', 'apply', 'circuit', 'prepare', 'hartreefock', 'state', 'log', 'ζ', 'use', 'single', 'hadamard', 'gate', 'replace', 'pauli', 'gate', 'need', 'prepare', 'control', 'version', 'cnot', 'alternatively', 'use', 'classical', 'shadow', 'protocol', 'randomize', 'number', 'preserve', 'passive', 'gaussian', 'unitarie', 'allow', 'compute', 'overlap', 'error', 'ϵ', 'shadow', 'consist', 'shot', 'independent', 'n', 'shadow', 'protocol', 'also', 'nindependent', 'sample', 'complexity', 'however', 'scale', 'logarithm', 'number', 'overlap', 'first', 'case', 'number', 'preservation', 'passive', 'gaussian', 'unitarie', 'superposition', 'reference', 'state', 'prepare', 'enlarged', 'set', 'qubit', 'bad', 'case', 'halffille', 'ζ', 'second', 'case', 'classical', 'processing', 'shadow', 'datum', 'efficient', 'computational', 'basis', 'state', 'overlap', 'require', 'method', 'overlap', 'general', 'slater', 'determinant', 'numerical', 'simulation', 'focus', 'matchgate', 'shadow', 'protocol', 'bad', 'scaling', 'require', 'number', 'shot', 'alternative', 'mean', 'shot', 'budget', 'report', 'asymptotically', 'think', 'upper', 'bound', 'probably', 'far', 'improve', 'state', 'prepare', 'depth', '⊗', 'state', 'superposition', '√n', 'log', 'n', 'n', '⊗', 'statistical', 'property', 'matchgate', 'shadow', 'overlap', 'implement', 'matchgate', 'shadow', 'protocol', 'order', 'study', 'statistical', 'property', 'overlap', 'measurement', 'summarize', 'detail', 'numerical', 'simulation', 'obtain', 'follow', 'finding', 'overlap', 'estimate', 'approximately', 'normal', 'distribute', 'covariance', 'matrix', 'overlap', 'measurement', 'diagonally', 'dominant', 'covariance', 'vanish', 'asymptotically', 'fast', 'variance', 'increase', 'scatter', 'plot', 'see', 'fig', 'c', 'confirm', 'overlap', 'estimate', 'close', 'independently', 'distribute', 'large', 'spread', 'variance', 'decay', 'fast', 'mean', 'variance', 'mean', 'large', 'overlap', 'estimate', 'approximately', 'variance', 'numerically', 'observe', 'mean', 'variance', 'agree', 'well', 'analytical', 'performance', 'guarantee', 'see', 'c', 'detail', 'case', 'halffille', 'ζ', 'numerically', 'find', 'simple', 'relation', '¯σ2', '√2ns', 'ultimately', 'allow', 'build', 'synthetic', 'noise', 'model', 'efficiently', 'add', 'gaussian', 'noise', 'variance', 'classically', 'compute', 'exact', 'overlap', 'mimic', 'matchgate', 'shadow', 'overlap', 'measurement', 'classically', 'simulate', 'entire', 'shadow', 'protocol', 'next', 'section', 'use', 'synthetic', 'noise', 'model', 'estimate', 'number', 'quantum', 'measurement', 'order', 'reach', 'chemical', 'precision', 'sizeable', 'system', 'intractable', 'current', 'quantum', 'device', 'give', 'finite', 'shadow', 'estimate', 'overlap', 'variance', 'estimate', 'enable', 'build', 'classical', 'postprocessing', 'scheme', 'screen', 'overlap', 'statistically', 'significantly', 'determine', 'improve', 'result', 'section', 'b', 'shot', 'noise', 'resilience', 'quantum', 'resource', 'tailor', 'couple', 'cluster', 'b', 'c', 'fig', 'fit', 'power', 'law', 'prefactor', 'molecule', 'fix', 'global', 'exponent', 'diagnostic', 'value', 'molecule', 'scatter', 'plot', 'prefactor', 'diagnostic', 'value', 'include', 'linear', 'fit', 'c', 'e', 'n', 'e', 'h', 'e', 'h', 'e', 'cl2', 'h', 'e', 'n', 'h', 'global', 'fit', 'c', 'n', 'c', 'etald', 'molecule', 'u', 'v', 'c', 'e', 'n', 'e', 'h', 'e', 'h', 'e', 'cl2', 'h', 'e', 'h', 'c', 'n', 'c', 'etald', 'molecule', 'r', 'r', 'purpose', 'section', 'analyze', 'budget', 'matchgate', 'shadow', 'order', 'obtain', 'noisy', 'quantum', 'tccsd', 'energy', 'molecular', 'system', 'give', 'precision', 'observation', 'noisy', 'overlap', 'extract', 'matchgate', 'shadow', 'protocol', 'independent', 'identically', 'distribute', 'random', 'variable', 'underlie', 'normal', 'distribution', 'greatly', 'facilitate', 'construction', 'error', 'model', 'tccsd', 'energy', 'need', 'record', 'many', 'finite', 'shot', 'shadow', 'rather', 'take', 'exact', 'overlap', 'classical', 'casci', 'calculation', 'subsequently', 'draw', 'noise', 'give', 'distribution', 'standard', 'deviation', 'noise', 'strength', 'add', 'exact', 'overlap', 'subsequently', 'compute', 'noisy', 'tccsd', 'energy', 'simulate', 'single', 'quantum', 'circuit', 'ultimately', 'goal', 'find', 'heuristic', 'model', 'shot', 'budget', 'incorporate', 'dependence', 'error', 'noise', 'strength', 'directly', 'relate', 'shot', 'budget', 'variance', 'bind', 'publish', 'b', 'systemmoleculespecific', 'parameter', 'number', 'spin', 'orbital', 'active', 'space', 'size', 'make', 'possible', 'estimate', 'quantum', 'resource', 'broad', 'range', 'molecule', 'interest', 'perform', 'actual', 'sampling', 'tccsd', 'error', 'system', 'detail', 'analysis', 'construction', 'empirical', 'error', 'model', 'explain', 'detail', 'c', 'quantity', 'want', 'extrapolate', 'use', 'predefine', 'system', 'parameter', 'noise', 'strength', 'absolute', 'tccsd', 'energy', 'error', 'cause', 'noise', 'relation', 'noise', 'strength', 'possible', 'substitute', 'σ', 'variance', 'bind', 'directly', 'obtain', 'turn', 'contain', 'shot', 'budget', 'thus', 'convincingly', 'model', 'systemspecific', 'parameter', 'outline', 'shot', 'budget', 'give', 'desire', 'accuracy', 'follow', 'importantly', 'test', 'dependence', 'give', 'system', 'noise', 'strength', 'keep', 'influential', 'parameter', 'basis', 'set', 'fix', 'analysis', 'reveal', 'linear', 'dependence', '∆enoise', 'σ', 'tccsd', 'energy', 'error', 'proportional', 'underlying', 'noise', 'strength', 'relationship', 'observe', 'consistently', 'different', 'system', 'active', 'space', 'size', 'even', 'high', 'noise', 'strength', 'tccsd', 'calculation', 'converge', 'indicate', 'procedure', 'robust', 'even', 'tailor', 'almost', 'random', 'overlap', 'linear', 'dependence', 'σ', 'hand', 'seek', 'incorporate', 'moleculesystemspecific', 'parameter', '∆enoise', '∆enoise', '∆enoise', '∆enoise', 'tccsd', 'precision', 'different', 'correlation', 'regime', 'indicate', 'fig', 'extrapolation', 'shot', 'count', 'need', 'determine', 'quantum', 'energy', 'millihartree', 't1', 'diagnostic', 'datum', 'generate', 'system', 'n', 'orbital', 'halffille', 'active', 'space', 'shaded', 'region', 'correspond', 'power', 'law', 'small', 'large', 'exponent', 'estimator', 'standard', 'deviation', 'respectively', 'extended', 'extrapolation', 'model', 'compose', 'set', 'molecular', 'system', 'basis', 'set', 'active', 'space', 'size', 'sample', 'tccsd', 'energy', 'system', 'give', 'noise', 'strength', 'afterwards', 'find', 'systemdependent', 'variable', 'explain', 'trend', 'error', 'good', 'analysis', 'sampled', 'datum', 'set', 'conclude', 'total', 'number', 'overlap', 'put', 'tccsd', 'calculation', 'directly', 'depend', 'n', 'choose', 'active', 'space', 'size', 'see', 'c', 'total', 'number', 'spin', 'orbital', 'system', 'yield', 'good', 'result', 'power', 'law', 'fit', 'whole', 'datum', 'set', 'power', 'law', 'give', '∆enoise', '∆enoise', 'tccsd', 'dβn', 'exponent', 'n', 'power', 'law', 'seem', 'largely', 'independent', 'choose', 'molecular', 'system', 'show', 'error', 'noisy', 'amplitude', 'increase', 'size', 'exponent', 'give', 'absolute', 'error', 'active', 'space', 'expect', 'exponent', 'n', 'approximately', 'decrease', 'total', 'size', 'space', 'increase', 'make', 'sense', 'active', 'space', 'contribution', 'total', 'energy', 'decrease', 'relative', 'size', 'external', 'space', 'increase', 'prefactor', 'systemspecific', 'variable', 'omit', 'choice', 'n', 'portant', 'general', 'quantity', 'notice', 'strong', 'static', 'correlation', 'system', 'large', 'correspond', 'prefactor', 'permolecule', 'fit', 'fix', 'exponent', 'permolecule', 'prefactor', 'depict', 'figure', 'find', 'prefactor', 'molecule', 'test', 'set', 'correlate', 'wellknown', 'd1', 'see', 'fig', 'diagnostic', 'value', 'typically', 'use', 'quantify', 'diagnostic', 'value', 'singlereference', 'ccsd', 'wavefunction', 'reliable', 'opt', 'treatment', 'system', 't1', 't1', 'value', 'correlate', 'good', 'moleculespecific', 'prefactor', 'fig', 'use', 'linear', 'fit', 'convert', 'fit', 'parameter', 'show', 'c', 'empirical', 'error', 'extrapolation', 'model', 'take', 'account', 'follow', 'quantity', 'noise', 'strength', 'give', 'variance', 'bind', 'number', 'overlap', 'require', 'tccsd', 'depend', 'size', 'choose', 'active', 'space', 'total', 'number', 'spin', 'orbital', 'system', 'prefactor', 'power', 'law', 'derive', 't1', 'diagnostic', 'plain', 'ccsd', 'calculation', 'course', 'empirical', 'model', 'far', 'general', 'however', 'give', 'guidance', 'error', 'level', 'expect', 'tccsd', 'calculation', 'base', 'noisy', 'overlap', 'measurement', 'insert', 'variance', 'bind', 'power', 'law', 'rearrange', 'equation', 'matchgate', 'shadow', 'shoot', 'budget', 'halffille', '⪅', '∆enoise', 'tccsd', 'd2βn', '∆enoise', '∆enoise', 'parameter', 'obtain', 'shot', 'budget', 'compute', 'target', 'accuracy', 'require', 'fit', 'moleculesetupspecific', 'value', 'following', 'set', 'chemical', 'precision', 'note', 'shot', 'budget', 'assign', 'overlap', 'measurement', 'matchgate', 'shadow', 'take', 'account', 'shot', 'budget', 'state', 'preparation', 'optimization', 'furthermore', 'gaussian', 'error', 'model', 'herein', 'apply', 'exact', 'overlap', 'trial', 'wavefunction', 'reason', 'error', 'model', 'cover', 'error', 'overlap', 'measurement', 'imperfection', 'wavefunction', 'discuss', 'previous', 'section', 'error', 'model', 'independent', 'underlying', 'state', 'however', 'error', 'contribution', 'study', 'separately', 'compute', 'value', 'fictitious', 'system', 'mo', 'space', 'n', 'halffille', 'active', 'space', 'n', 'n', 'qubit', 'ζ', 'n2', 'electron', 'cover', 'different', 'correlation', 'regime', 'shot', 'budget', 'obtain', 'range', 'plot', 'figure', 'shaded', 'area', 'solid', 'line', 'plot', 'include', 'scenario', 'standard', 'deviation', 'exponent', 'addedsubtracte', 'strongly', 'correlate', 'case', 'correspond', 'system', 'n2', 'bond', 'distance', '˚a', 'extreme', 'case', 'character', 't1', 'mixedbalanced', 'case', 't1', 'around', 'correspond', 'system', 'pbenzyne', 'weakly', 'correlate', 'case', 'closedshell', 'organic', 'molecule', 'balanced', 'case', 'shot', 'count', 'range', 'approximately', 'qubit', 'less', 'qubit', 'uncertainty', 'number', 'give', 'standard', 'deviation', 'exponent', 'fit', 'parameter', 'amount', 'approximately', 'order', 'magnitude', 'direction', 'ccsd', 'almost', 'reliable', 'anymore', 'usually', 'threshold', 't1', 't1', 'c', 'quantum', 'resource', 'estimate', 'nitrogen', 'dissociation', 'come', 'back', 'test', 'case', 'previous', 'section', 'compute', 'total', 'shot', 'budget', 'obtain', 'n2', 'dissociation', 'curve', 'chemical', 'precision', 'noisy', 'tccsd', 'setup', 'shot', 'budget', 'point', 'dissociation', 'curve', 'give', 'figure', 'number', 'overlap', 'number', 'spin', 'orbital', 'course', 'identical', 't1', 'increase', 'thus', 'shot', 'budget', 'adjust', 'accordingly', 'point', 'potential', 'energy', 'surface', 'value', 'note', 'shot', 'budget', 'grow', 'quadratically', 't1', 'total', 'shot', 'budget', 'bond', 'distance', 'dominate', 'strongly', 'correlate', 'regime', 'r', '˚a', 'expect', 'note', 'shot', 'budget', 'obtain', 'entire', 'dissociation', 'curve', '˚a', 'increment', 'less', 'think', 'remarkable', 'shot', 'sufficient', 'obtain', 'energy', 'estimator', 'include', 'dynamic', 'correlation', 'correction', 'effect', 'even', 'advanced', 'method', 'regularize', 'compress', 'double', 'factorization21', 'fluid', 'fermionic', 'fragments103', 'employ', 'measure', 'bare', 'active', 'space', 'energy', 'typically', 'require', 'comparable', 'number', 'shot', 'measurement', 'let', 'alone', 'sufficiently', 'high', 'quality', 'higherorder', 'rdm', 'expect', 'require', 'significantly', 'shot', 'estimate', 'include', 'error', 'mitigation', 'overhead', 'feasible', 'shot', 'count', 'hardware', 'fig', 'estimate', 'shot', 'budget', 'achieve', 'millihartree', 'precision', 'tccsd', 'energy', 'obtain', 'function', 'internuclear', 'distance', 'r', 'dissociation', 'curve', 'value', 'ccsdccpvdz', 'determine', 'increase', 'accord', 'total', 'shot', 'budget', 'amount', 'approximately', 'shot', 'raw', 'datum', 'show', 'table', 'testify', 'fact', 'shot', 'take', 'individual', 'echoverifie', 'data', 'point', 'complete', 'comparison', 'thorough', 'investigation', 'shot', 'count', 'need', 'ptbase', 'method', 'treat', 'dynamic', 'correlation', 'use', 'higherorder', 'rdm', 'desirable', 'scope', 'work', 'additionally', 'interesting', 'numerically', 'analyze', 'quantum', 'state', 'preparation', 'technique', 'context', 'tccsd', 'future', 'work', 'resilience', 'device', 'noise', 'combination', 'overlap', 'input', 'split', 'amplitude', 'method', 'consider', 'determined', 'matchgate', 'shadow', 'protocol25', 'lead', 'far', 'noteworthy', 'builtin', 'error', 'mitigation', 'property', 'result', 'method', 'see', 'first', 'need', 'recount', 'overlap', 'measure', 'shadow', 'record', 'aim', 'prepare', 'state', 'shadow', 'one', 'pick', 'reference', 'state', 'true', 'vacuum', '⊗', 'device', 'finally', 'take', 'computational', 'basis', 'state', 'measurement', 'random', 'gaussian', 'ρ', 'φ', 'rotation', 'shadow', 'obtain', 'way', 'soughtafter', 'overlap', 'computational', 'basis', 'state', 'compute', 'expectation', 'value', 'nonhermitian', 'observable', 'ρ', 'φ', '⟩⟨', 'state', 'preparation', 'noisy', 'instead', 'state', 'ρ', 'p', 'ρ', 'p', 'ρnoise', 'ρ', '⟩', '⟨', 'error', 'probability', 'p', 'density', 'matrix', 'ρnoise', 'one', 'tr', 'device', 'prepare', 'state', 'use', 'φ', 'φ', '⟨', 'tr', 'p', 'p', 'φ', '⟨', 'ρnoise', 'several', 'reasonable', 'type', 'noise', 'include', 'depolarize', 'noise', 'bit', 'flip', 'noise', 'amplitude', 'damp', '⟩', 'small', 'state', 'subspace', 'contain', 'reasonable', 'number', 'particle', 'mean', 'overlap', 'eq', 'intermediate', 'normalization', 'well', 'approximate', 'quotient', 'overlap', 'compute', 'shadow', 'noisy', 'state', 'overlap', 'one', 'example', 'ρnoise', 'φ', 'φ', '⟨', '⟨', 'ψt', '⟩⟨', 'ψas', '⟨', '⟩', '⟨', '⟨', 'tr', 'tr', '⟩⟨', '⟩⟨', 'p', 'enumerator', 'denominator', 'cancel', 'even', 'estimation', 'finite', 'common', 'factor', 'ψt', 'shot', 'shadow', 'thus', 'work', 'well', 'long', 'become', 'small', 'see', 'similar', 'consideration', 'contrary', 'error', 'mitigation', 'technique', 'expectation', 'value', 'eg', 'electronic', 'structure', 'hamiltonian', 'usually', 'first', 'order', 'sensitive', 'noise', 'strength', 'φ', '⟨', 'major', 'concern', 'several', 'platform', 'particle', 'number', 'dependent', 'phase', 'cause', 'eg', 'background', 'magnetic', 'field', 'often', 'particularly', 'problematic', 'algorithm', 'prepare', 'catlike', 'coherent', 'superposition', 'state', 'markedly', 'different', 'particle', 'number', 'however', 'know', 'input', 'overlap', 'real', 'interested', 'get', 'relative', 'sign', 'coefficient', 'quotient', 'overlap', 'correct', 'computational', 'basis', 'state', 'overlap', 'go', 'enumerator', 'come', 'particle', 'r', 'number', 'subspace', 'particle', 'number', 'dependent', 'phase', 'result', 'global', 'phase', 'affect', 'coefficient', 'easily', 'correct', 'possible', 'way', 'rotate', 'coefficient', 'complex', 'plane', 'large', 'coefficient', 'principle', 'component', 'overlap', 'align', 'real', 'axis', 'discard', 'imaginary', 'part', 'take', 'absolute', 'value', 'multiply', 'sign', 'real', 'part', 'coefficient', 'render', 'method', 'largely', 'independent', 'uncontrolled', 'particle', 'number', 'dependent', 'phase', 'also', 'imply', 'robustness', 'general', 'phase', 'error', 'splitamplitude', 'cc', 'quantum', 'hardware', 'section', 'showcase', 'externally', 'correct', 'perform', 'input', 'obtain', 'actual', 'quantum', 'hard', 'ware', 'purpose', 'revisit', 'ground', 'state', 'energy', 'h4sto3', 'arrange', 'square', 'geometry', 'bond', 'distance', '˚a', 'previously', 'study', 'qcqmc', 'quantum', 'overlap', 'measure', 'clifford', 'shadow', 'sycamore', 'superconducte', 'quantum', 'hardware', 'experiment', 'state', 'preparation', 'h4sto3', 'g', 'qubit', 'correspond', 'prepare', 'exact', 'fci', 'state', 'overlap', 'obtain', 'shadow', 'protocol22', 'use', 'drive', 'qmc', 'calculation', 'device', 'shot', 'noise', 'measure', 'overlap', 'course', 'exactly', 'reproduce', 'fci', 'overlap', 'make', 'interesting', 'test', 'case', 'study', 'noise', 'robustness', 'eccc', 'detail', 'experimental', 'shadow', 'datum', 'process', 'see', 'fig', 'postprocessing', 'protocol', 'overlap', 'measure', 'classical', 'matchgate', 'shadow', 'protocol', 'first', 'filter', 'base', 'variance', 'set', 'overlap', 'estimator', 'large', 'variance', 'cluster', 'analysis', 'perform', 'filter', 'cluster', 'amplitude', 'include', 'purely', 'disconnect', 'amplitude', 'disconnect', 'yield', 'socalled', 'typeii', 'calculation', 'end7980', 'quantum', 'trial', 'state', 'prepare', 'device', 'q', 'trial', 'first', 'convert', 'wavefunction', 'realvalue', 'coefficient', 'q', 'trial', 'real', 'see', 'use', 'trial', 'state', 'record', 'time', 'different', 'number', 'sample', 'clifford', 'nclifford', 'original', 'experiment', 'use', 'good', 'repetition', 'term', 'root', 'meansquare', 'error', 'reconstructed', 'wavefunction', 'respect', 'fci', 'result', 'qualitatively', 'unchanged', 'run', 'include', 'band', 'depict', 'uncertainty', 'become', 'unnecessarily', 'wide', 'note', 'hardware', 'reason', 'circuit', 'group', 'element', 'execute', 'time', 'yield', 'socalled', 'mulit', 'shadow', 'complement', 'hardware', 'datum', 'simulate', 'matchgate', 'shadow', 'repetition', 'take', 'fci', 'wavefunction', 'single', 'shot', 'shot', 'group', 'element', 'furthermore', 'devise', 'classical', 'postprocessing', 'protocol', 'illustrate', 'figure', 'ascertain', 'certain', 'property', 'wavefunction', 'extract', 'device', 'therein', 'filter', 'overlap', 'base', 'variance', 'set', 'certain', 'variance', 'threshold', 'measurement', 'fulfil', 'overlap', 'determine', 'reliably', 'enough', 'give', 'experiment', 'set', 'overlap', 'overlap', 'value', 'large', 'σ', 'perform', 'usual', 'cluster', 'analysis', 'contain', 'purely', 'disconnect', 'variancebase', 'thresholding', 'underlying', 'wavefunction', 'spirit', 'typeii', 'discard', 'purely', 'disconnect', 'amplitude', 'subsequently', 'perform', 'calculation', 'absolute', 'energy', 'error', 'respect', 'fci', 'function', 'total', 'number', 'shot', 'number', 'group', 'element', 'time', 'number', 'circuit', 'execution', 'group', 'element', 'show', 'classical', 'shadow', 'filter', 'overlap', 'base', 'variance', 'cluster', 'analysis', 'discard', 'purely', 'disconnect', 'calculation', 'fig', 'energy', 'error', 'trial', 'state', 'q', 'trial', 'q', 'trial', 'convert', 'real', 'wavefunction', 'q', 'trial', 'real', 'eccc', 'different', 'shadow', 'protocol', 'qcqmc', 'respect', 'fci', 'average', 'repetition', 'show', 'shaded', 'area', 'indicate', '95th', 'percentile', 'result', 'base', 'experimental', 'datum', 'draw', 'solid', 'line', 'result', 'simulated', 'matchgate', 'shadow', 'shot', 'noise', 'dash', 'line', 'energy', 'error', 'meh', 'limit', 'chemical', 'precision', 'meh', 'show', 'comparison', 'circuit', 'noise', 'q', 'trial', 'state', 'correspond', 'fci', 'raw', 'datum', 'show', 'table', 'd1', 'figure', 'include', 'result', 'q', 'trial', 'qcqmc', 'shot', 'experiment', 'shotnoiselimited', 'limit', 'energy', 'error', 'less', 'meh', 'chemical', 'precision', 'reach', 'plain', 'variational', 'energy', 'trial', 'state', 'purely', 'real', 'counterpart', 'reach', 'level', 'accuracy', 'postprocesse', 'protocol', 'ensure', 'shot', '×', 'fig', 'number', 'sign', 'error', 'upper', 'panel', 'nonzero', 'error', 'low', 'panel', 'overlap', 'measurement', 'depend', 'number', 'clifford', 'nclifford', 'h4sto3', 'g', 'experiment', 'qubit', 'group', 'run', 'experiment', 'nonzero', 'error', 'define', 'overlap', 'value', 'numerically', 'fci', 'vector', 'large', 'give', 'numerical', 'threshold', 'shadowbase', 'measurement', 'result', 'never', 'bad', 'plain', 'ccsd', 'understand', 'behavior', 'analyze', 'type', 'error', 'occur', 'overlap', 'measurement', 'namely', 'sign', 'error', 'nonzero', 'error', 'latter', 'refer', 'overlap', 'value', 'h', 'e', 'r', 'r', 'r', 'e', 'method', 'q', 'trial', 'q', 'trial', 'real', 'eccc', 'single', 'matchgate', 'type', 'experiment', 'simulation', 'total', 'number', 'shot', 'r', 'r', 'r', 'e', 'n', 'r', 'r', 'r', 'e', 'r', 'e', 'z', 'n', 'experiment', 'nclifford', 'numerically', 'case', 'correspond', 'value', 'vector', 'measure', 'nonzero', 'sign', 'nonzero', 'error', 'experimental', 'run', 'h4sto3', 'g', 'experiment', 'summarize', 'figure', 'sign', 'error', 'completely', 'vanish', 'nclifford', 'perfectly', 'coincide', 'point', 'energy', 'error', 'curve', 'improvement', 'observe', 'nonzero', 'error', 'decay', 'rapidly', 'sign', 'error', 'element', 'still', 'measure', 'nonzero', 'value', 'rather', 'large', 'number', 'sample', 'group', 'element', 'thus', 'sign', 'error', 'seem', 'severe', 'affect', 'quality', 'input', 'overlap', 'error', 'quickly', 'disappear', 'completely', 'total', 'number', 'shot', 'moderate', 'chemical', 'precision', 'reach', 'even', 'shot', 'make', 'wavefunction', 'real', 'remove', 'ambiguity', 'nonmeasurable', 'global', 'phase', 'necessity', 'couple', 'cluster', 'real', 'molecular', 'hamiltonian', 'require', 'real', 'amplitude', 'input', 'addition', 'seem', 'improve', 'quality', 'trial', 'wavefunction', 'energy', 'experimental', 'datum', 'seem', 'quite', 'reach', 'accuracy', 'qcqmc', 'get', 'close', 'drastically', 'improve', 'real', 'q', 'trial', 'energy', 'factor', 'respectively', 'well', 'factor', 'plain', 'energy', 'reassure', 'competitive', 'qcqmc', 'setting', 'certain', 'wavefunction', 'quality', 'improve', 'plain', 'trial', 'state', 'energy', 'comparison', 'simulated', 'shadow', 'datum', 'show', 'shadow', 'protocol', 'chemical', 'precision', 'reach', 'comparable', 'number', 'group', 'element', 'shot', 'shot', 'multishot', 'variant', 'need', 'roughly', 'time', 'shot', 'distinct', 'circuit', 'make', 'attractive', 'hardware', 'change', 'circuit', 'incur', 'run', 'time', 'overhead', 'attribute', 'generally', 'well', 'performance', 'simulate', 'datum', 'absence', 'gate', 'detection', 'noise', 'fig', 'error', 'total', 'energy', 'function', 'lattice', 'constant', 'minimal', 'cell', 'diamond', 'dzvpgth', 'basis', 'orbital', 'trial', 'state', 'prepare', 'active', 'space', 'qubit', 'use', 'perfectpairing', 'wavefunction', 'explain', 'detail', 'raw', 'datum', 'show', 'table', 'plot', 'split', 'panel', 'different', 'vertical', 'axis', 'limit', 'show', 'whole', 'range', 'energy', 'error', 'gray', 'area', 'low', 'panel', 'indicate', 'bound', 'chemical', 'precision', 'kcalmol', 'datum', 'q', 'trial', 'reproduce', 'notation', 'plot', 'legend', 'indicate', 'input', 'wavefunction', 'respective', 'method', 'q', 'trial', 'device', 'classically', 'simulate', 'exact', 'note', 'lattice', 'constant', '˚a', 'result', 'real', 'q', 'trial', 'visible', 'depict', 'energy', 'scale', 'high', 'value', 'lattice', 'constant', 'tccsd', 'base', 'nevpt2', 'achieve', 'chemical', 'precision', 'however', 'quantum', 'splitamplitude', 'method', 'run', 'hardware', 'datum', 'significantly', 'improve', 'energy', 'prepared', 'trial', 'state', 'second', 'example', 'run', 'actual', 'hardware', 'study', 'energy', 'minimal', 'diamond', 'unit', 'cell', 'carbon', 'atom', 'doublezeta', 'basis', 'gthdzvp', 'orbital', 'pseudopotential', 'point', 'sample', 'function', 'lattice', 'constant', 'quantum', 'trial', 'correspond', 'active', 'space', 'perfectpaire', 'pp', 'wavefunction', 'computational', 'basis', 'state', 'overlap', 'obtain', 'l', 'l', 'c', 'k', 'l', 'r', 'r', 'r', 'e', 'lattice', 'constant', 'q', 'trial', 'q', 'trial', 'real', 'eccc', 'q', 'trial', 'tccsd', 'trial', 'qcqmc', 'trial', 'cas', 'use', 'shadow', 'protocol', 'sample', 'group', 'element', 'lattice', 'constant', 'addition', 'method', 'use', 'compute', 'singlepoint', 'energy', 'lattice', 'constant', 'use', 'eccc', 'tccsd', 'realvalue', 'quantum', 'trial', 'state', 'exact', 'solution', 'give', 'active', 'space', 'problem', 'tccsd', 'exact', 'cas', 'state', 'comparison', 'result', 'show', 'figure', 'comparison', 'hardware', 'experiment', 'factor', 'limit', 'performance', 'guarantee', 'fact', 'deal', 'active', 'space', 'wavefunction', 'convergence', 'guarantee', 'true', 'fci', 'result', 'limit', 'exact', 'external', 'amplitude', 'quantum', 'trial', 'state', 'cclike', 'wavefunction', 'accurately', 'treat', 'higherorder', 'excitation', 'beneficial', 'result', 'quantum', 'eccc', 'quantum', 'trial', 'state', 'never', 'reach', 'chemical', 'precision', 'error', 'approximately', 'kcalmol', 'comparable', 'result', 'plain', 'even', 'exact', 'cas', 'wavefunction', 'use', 'construct', 'amplitude', 'energy', 'error', 'marginally', 'improve', 'quantum', 'input', 'strongly', 'hint', 'truncation', 'stem', 'active', 'space', 'course', 'prevent', 'accurate', 'result', 'performance', 'tailor', 'quantum', 'trial', 'state', 'even', 'bad', 'energy', 'error', 'large', 'kcalmol', 'value', 'lattice', 'constant', 'still', 'splitamplitude', 'method', 'execute', 'actual', 'quantum', 'trial', 'state', 'energy', 'error', 'vastly', 'well', 'variational', 'energy', 'quantum', 'trial', 'state', 'value', '˚a', 'literally', 'chart', 'interestingly', 'energy', 'error', 'plain', 'cas', 'neglect', 'dynamic', 'correlation', 'effect', 'bad', 'quantum', 'splitamplitude', 'method', 'method', 'setup', 'reach', 'chemical', 'precision', 'value', 'lattice', 'constant', 'tailor', 'nevpt2', 'energy', 'error', 'observe', 'method', 'almost', 'identical', 'tccsd', 'thus', 'provide', 'vastly', 'well', 'result', 'tailor', 'exact', 'active', 'space', 'wavefunction', 'pp', 'quantum', 'trial', 'state', 'expect', 'cclike', 'pp', 'wavefunction', 'yield', 'well', 'result', 'case', 'plain', 'ccsd', 'full', 'orbital', 'space', 'even', 'strict', 'theoretical', 'requirement', 'input', 'wavefunction', 'tccsd', 'case', 'expect', 'fail', 'base', 'property', 'quantum', 'trial', 'fact', 'use', 'postprocessing', 'protocol', 'input', 'amplitude', 'explain', 'perform', 'well', 'tccsd', 'actual', 'hardware', 'datum', 'perspective', 'classical', 'electronic', 'structure', 'method', 'performance', 'tccsd', 'par', 'nevpt2', 'encourage', 'conclude', 'course', 'expect', 'work', 'well', 'even', 'well', 'qcqmc', 'active', 'space', 'pp', 'quantum', 'input', 'set', 'corroborate', 'numerical', 'result', 'nonetheless', 'splitamplitude', 'method', 'provide', 'massive', 'improvement', 'absolute', 'energy', 'error', 'even', 'seed', 'noisy', 'input', 'conclusion', 'work', 'propose', 'use', 'overlap', 'obtain', 'quantum', 'computer', 'mean', 'classical', 'shadow', 'input', 'splitamplitude', 'cc', 'method', 'tailor', 'couple', 'cluster', 'tcc', 'externally', 'correct', 'couple', 'cluster', 'result', 'combination', 'method', 'see', 'way', 'add', 'dynamic', 'electron', 'correlation', 'correction', 'active', 'space', 'trial', 'state', 'prepare', 'quantum', 'computer', 'method', 'far', 'view', 'way', 'cure', 'failure', 'plain', 'singlereference', 'couple', 'cluster', 'theory', 'appearance', 'virtual', 'reaction', 'barrier', 'take', 'account', 'property', 'multireference', 'wavefunction', 'prepare', 'quantum', 'computer', 'avoid', 'dramatic', 'increase', 'classical', 'computational', 'complexity', 'classical', 'multireference', 'couple', 'cluster', 'method', 'show', 'combination', 'method', 'display', 'range', 'desirable', 'property', 'dynamic', 'correlation', 'correction', 'dissociation', 'curve', 'stretch', 'diamond', 'cell', 'find', 'comparable', 'quality', 'nevpt2', 'remarkably', 'robust', 'systematic', 'imperfection', 'prepared', 'active', 'space', 'wavefunction', 'arise', 'shallow', 'vqe', 'circuit', 'predict', 'number', 'repetition', 'shot', 'require', 'obtain', 'accurate', 'result', 'establish', 'correlation', 'diagnostic', 'classically', 'efficiently', 'obtainable', 'calculation', 'extrapolate', 'resource', 'estimate', 'classically', 'long', 'exactly', 'solvable', 'regime', 'find', 'remarkably', 'low', 'shot', 'count', 'attribute', 'fact', 'measurement', 'expensive', 'intermediate', 'higherorder', 'reduce', 'density', 'matrix', 'avoid', 'test', 'overlap', 'measure', 'real', 'quantum', 'hardware', 'method', 'provide', 'result', 'accuracy', 'comparable', 'qcqmc', 'ground', 'state', 'energy', 'minimal', 'basis', 'expensive', 'classical', 'part', 'computation', 'perform', 'standard', 'couple', 'cluster', 'code', 'open', 'possibility', 'speedup', 'particular', 'eccc', 'less', 'degree', 'tcc', 'seem', 'builtin', 'error', 'mitigation', 'ability', 'produce', 'energy', 'good', 'respectively', 'even', 'noisy', 'trial', 'state', 'amplitude', 'analyze', 'statistical', 'property', 'overlap', 'compute', 'matchgate', 'shadows25', 'numerically', 'corroborate', 'validity', 'gaussian', 'noise', 'model', 'general', 'interest', 'furthermore', 'quantum', 'splitamplitude', 'method', 'fully', 'agnostic', 'measurement', 'scheme', 'hence', 'quantum', 'resource', 'estimate', 'provide', 'present', 'work', 'likely', 'improve', 'use', 'shadow', 'protocol', 'low', 'sample', 'complexity', 'thus', 'interesting', 'see', 'similar', 'noise', 'model', 'hold', 'classical', 'shadow', 'protocol', 'particular', 'particlenumberpreserve', 'shadow', 'protocol', 'promise', 'make', 'require', 'number', 'shot', 'obtain', 'overlap', 'give', 'precision', 'independent', 'number', 'qubit', 'expense', 'overhead', 'circuit', 'depth', 'number', 'qubit', 'important', 'explore', 'tradeoff', 'possible', 'direction', 'combine', 'method', 'propose', 'shadowbased', 'error', 'mitigation', 'methods110–112', 'shot', 'count', 'find', 'quantum', 'splitamplitude', 'cc', 'method', 'seem', 'low', 'even', 'compare', 'typical', 'shot', 'count', 'need', 'compute', 'energy', 'bare', 'electronic', 'structure', 'hamiltonian', 'quantum', 'wavefunction', 'detailed', 'analysis', 'shot', 'count', 'need', 'obtain', 'similar', 'quality', 'energy', 'perturbative', 'method', 'nevpt2', 'higherorder', 'measure', 'shadow', 'directly', 'remain', 'outstanding', 'able', 'give', 'hint', 'kind', 'wavefunction', 'yield', 'quantum', 'advantage', 'hope', 'inspire', 'future', 'work', 'state', 'preparation', 'scheme', 'finally', 'interesting', 'extend', 'tccsd', 't3', 'amplitude', 'active', 'space', 'suggest', 'original', 'tcc', 'work2', 'compute', 'molecular', 'property', 'splitamplitude', 'method', 'acknowledge', 'fruitful', 'discussion', 'huggin', 'eugene', 'fotio', 'gkritsis', 'pauline', 'ollitrault', 'acknowledgement', 'mcardle', 'aspuruguzik', 'c', 'computational', 'chemistry', 'review', 'modern', 'physics', 'hino', 'method', 'tailor', 'configuration', 'interaction', 'journal', 'chemical', 'j', 'paldus', 'externally', 'internally', 'correct', 'couple', 'cluster', 'approach', 'overview', 'journal', 'mathematical', 'chem', 'istry', 'r', 'babbush', 'j', 'r', 'mcclean', 'increase', 'representation', 'accuracy', 'quantum', 'simulation', 'chemistry', 'extra', 'quantum', 'resource', 'peruzzo', 'mcclean', 'p', 'shadbolt', 'love', 'aspuruguzik', 'variational', 'eigenvalue', 'solver', 'photonic', 'quantum', 'processor', 'nature', 'communication', 'j', 'r', 'mcclean', 'r', 'babbush', 'aspuruguzik', 'theory', 'variational', 'hybrid', 'quantumclassical', 'algorithm', 'new', 'journal', 'tammaro', 'e', 'galli', 'rice', 'motta', 'valence', 'perturbation', 'theory', 'reference', 'wave', 'function', 'computing', 'application', 'relative', 'stability', 'hydroxide', 'anion', 'journal', 'physical', 'chemistry', 'baek', 'hait', 'shee', 'leimkuhler', 'w', 'huggin', 'say', 'optimization', 'nonorthogonal', 'quantum', 'eigensolver', 'quantum', 'strongly', 'contract', 'nelectron', 'valence', 'state', 'perturbation', 'theory', 'use', 'reduce', 'density', 'matrix', 'quantum', 'computer', 'arxiv', 'preprint', 'coon', 'matsuura', 'garza', 'senicourt', 'maksymov', 'et', 'optimize', 'electronic', 'structure', 'simulation', 'trappedion', 'quantum', 'computer', 'use', 'problem', 'decomposition', 'communication', 'rossmannek', 'barkoutsos', 'p', 'ollitrault', 'quantum', 'hfdftembedde', 'algorithm', 'electronic', 'structure', 'calculation', 'scale', 'complex', 'molecular', 'system', 'journal', 'chemical', 'doiorg10106350029536', 'sun', 'sun', 'practical', 'quantum', 'embed', 'simulation', 'realistic', 'chemical', 'system', 'nearterm', 'quantum', 'computer', 'chemical', 'r', 'meitei', 'chin', 'dutt', 'l', 'bootstrap', 'embed', 'quantum', 'computer', 'journal', 'chemical', 'theory', 'computation', 'evangelista', 'zerothorder', 'activespace', 'frozenorbital', 'embed', 'scheme', 'multireference', 'calculation', 'journal', 'chemical', 'n', 'evangelista', 'secondorder', 'activespace', 'embed', 'theory', 'journal', 'chemical', 'theory', 'computation', 'evangelista', 'perspective', 'multireference', 'couple', 'cluster', 'theory', 'dynamical', 'electron', 'correlation', 'journal', 'chemical', 'r', 'evangelista', 'leverage', 'smallscale', 'quantum', 'computer', 'unitarily', 'downfolde', 'nian', 'quantum', 'huggin', 'j', 'r', 'mcclean', 'whaley', 'r', 'babbush', 'efficient', 'noise', 'resilient', 'measurement', 'quantum', 'chemistry', 'nearterm', 'quantum', 'computer', 'information', 'motta', 'parrish', 'quantum', 'filter', 'diagonalization', 'compress', 'doublefactorized', 'hamiltonian', 'prx', 'quantum', 'choi', 'loaiza', 'izmaylov', 'fluid', 'fermionic', 'fragment', 'optimize', 'quantum', 'measurement', 'electronic', 'hamiltonian', 'variational', 'quantum', 'eigensolver', 'quantum', 'scheurer', 'r', 'c', 'gogolin', 'accelerate', 'quantum', 'computation', 'chemistry', 'regularize', 'compress', 'double', 'factorization', 'arxiv', 'preprint', 'miyake', 'fermionic', 'partial', 'tomography', 'classical', 'shadow', 'physical', 'review', 'letter', 'publisher', 'american', 'society', 'g', 'low', 'classical', 'shadow', 'fermion', 'particle', 'number', 'symmetry', 'arxiv220808964', 'quantph', 'bonetmonroig', 'r', 'babbush', 'brien', 'nearly', 'optimal', 'measurement', 'scheduling', 'partial', 'tomography', 'phy', 'rev', 'huggin', 'r', 'babbush', 'matchgate', 'shadow', 'fermionic', 'quantum', 'simulation', 'communication', 'mathematical', 'physics', 'hy', 'kueng', 'preskill', 'predict', 'many', 'property', 'quantum', 'system', 'measurement', 'nature', 'physics', 'w', 'huggin', 'b', 'gorman', 'r', 'reichman', 'r', 'babbush', 'unbiase', 'fermionic', 'quantum', 'quantum', 'computer', 'nature', 'number', 'publisher', 'nature', 'publish', 'group', 'r', 'taylor', 'diagnostic', 'determine', 'quality', 'singlereference', 'electron', 'correlation', 'method', 'international', 'journal', 'chemistry', 'new', 'diagnostic', 'coupledcluster', 'møller', 'plesset', 'perturbation', 'theory', 'chemical', 'physics', 'letter', 'correlation', 'problem', 'atomic', 'molecular', 'system', 'calculation', 'wavefunction', 'component', 'ursell', 'type', 'expansion', 'use', 'quantumfield', 'theoretical', 'method', 'journal', 'chemical', 'crawford', 'introduction', 'coupled', 'cluster', 'theory', 'computational', 'chemist', 'review', 'computational', 'chemistry', 'shavitt', 'method', 'chemistry', 'coupledcluster', 'theory', 'press', 'g', 'bartlett', 'full', 'coupledcluster', 'single', 'double', 'model', 'inclusion', 'disconnected', 'triple', 'journal', 'chemical', 'truck', 'j', 'pople', 'fifthorder', 'perturbation', 'comparison', 'electron', 'correlation', 'theory', 'chemical', 'physics', 'letter', 'r', 'bartlett', 'coupledcluster', 'theory', 'become', 'preeminent', 'method', 'ab', 'chemistry', 'theory', 'application', 'computational', 'chemistry', 'elsevi', 'pp', 'c', 'riplinger', 'g', 'minenkov', 'l', 'cavallo', 'neese', 'communication', 'improved', 'linear', 'scale', 'perturbative', 'triple', 'correction', 'domain', 'base', 'local', 'pairnatural', 'orbital', 'base', 'single', 'double', 'couple', 'cluster', 'method', 'journal', 'chemical', 'physics', 'c', 'sherrill', 'configuration', 'interaction', 'method', 'advance', 'highly', 'correlate', 'approach', 'advance', 'chemistry', 'vol', 'elsevi', 'pp', 'g', 'neese', 'comprehensive', 'benchmark', 'result', 'domain', 'base', 'local', 'pair', 'natural', 'orbital', 'couple', 'cluster', 'method', 'closed', 'openshell', 'system', 'journal', 'physical', 'chemistry', 'm¨orchen', 'l', 'freitag', 'tailor', 'couple', 'cluster', 'theory', 'vary', 'correlation', 'regime', 'journal', 'chemical', 'oliphant', 'adamowicz', 'multireference', 'couple', 'cluster', 'method', 'electronic', 'structure', 'molecule', 'international', 'review', 'physical', 'chemistry', 'p', 'j', 'knowle', 'n', 'c', 'handy', 'new', 'determinantbase', 'full', 'configuration', 'interaction', 'method', 'chemical', 'physics', 'letter', 'roo', 'j', 'jensen', 'determinant', 'base', 'configuration', 'interaction', 'algorithm', 'complete', 'restrict', 'configuration', 'interaction', 'space', 'journal', 'chemical', 'p', 'j', 'knowle', 'n', 'c', 'handy', 'determinant', 'base', 'full', 'configuration', 'interaction', 'program', 'computer', 'commu', 'nication', 'paldus', 'vectorizable', 'approach', 'molecular', 'ci', 'problem', 'use', 'determinantal', 'basis', 'chemical', 'physics', 'letter', 'l', 'bendazzoli', 'evangelisti', 'vector', 'parallel', 'full', 'configuration', 'interaction', 'journal', 'chemical', 'c', 'burg', 'delicate', 'balance', 'static', 'dynamic', 'electron', 'correlation', 'journal', 'chemical', 'theory', 'computation', 'r', 'harrison', 'approximate', 'full', 'configuration', 'interaction', 'select', 'configuration', 'interaction', 'perturbation', 'theory', 'journal', 'chemical', 'holme', 'umrigar', 'heatbath', 'configuration', 'interaction', 'efficient', 'select', 'configuration', 'interaction', 'inspire', 'heatbath', 'sample', 'journal', 'chemical', 'theory', 'computation', 'sharma', 'holmes', 'alavi', 'umrigar', 'semistochastic', 'heatbath', 'configuration', 'interaction', 'method', 'select', 'configuration', 'interaction', 'semistochastic', 'perturbation', 'theory', 'journal', 'chemical', 'theory', 'computation', 'schriber', 'evangelista', 'communication', 'adaptive', 'configuration', 'interaction', 'approach', 'strongly', 'correlate', 'electron', 'tunable', 'accuracy', 'journal', 'chemical', 'c', 'freeman', 'levine', 'modern', 'approach', 'exact', 'diagonalization', 'select', 'configuration', 'interaction', 'adaptive', 'sample', 'method', 'journal', 'chemical', 'theory', 'computation', 'h', 'r', 'larsson', 'r', 'block2', 'comprehensive', 'open', 'source', 'framework', 'develop', 'apply', 'stateoftheart', 'dmrg', 'algorithm', 'electronic', 'structure', 'arxiv231003920', 'physicschemph', 'c', 'angeli', 'r', 'cimiraglia', 'evangelisti', 'leininger', 'p', 'malrieu', 'introduction', 'valence', 'state', 'multireference', 'perturbation', 'theory', 'journal', 'chemical', 'c', 'angeli', 'r', 'cimiraglia', 'malrieu', 'valence', 'state', 'perturbation', 'theory', 'fast', 'implementation', 'strongly', 'contract', 'variant', 'chemical', 'physics', 'letter', 'c', 'angeli', 'r', 'cimiraglia', 'malrieu', 'valence', 'state', 'perturbation', 'theory', 'spinless', 'formulation', 'efficient', 'implementation', 'strongly', 'contract', 'partially', 'contract', 'variant', 'journal', 'chemical', 'p', 'pulay', 'perspective', 'caspt2', 'method', 'international', 'journal', 'f', 'r', 'lindh', 'multiconfigurational', 'quantum', 'chemistry', 'caspt2', 'method', 'theoretical', 'computational', 'photochemistry', 'elsevi', 'pp', 'paldus', 'ˇc´ıˇzek', 'approximate', 'account', 'connected', 'quadruply', 'excited', 'cluster', 'coupled', 'pair', 'manyelectron', 'theory', 'review', 'j', 'paldus', 'j', 'planelle', 'valence', 'bond', 'correct', 'single', 'reference', 'couple', 'cluster', 'approach', 'general', 'formalism', 'planelle', 'paldus', 'valence', 'bond', 'correct', 'single', 'reference', 'couple', 'cluster', 'approach', 'application', 'ppp', 'model', 'planelle', 'paldus', 'valence', 'bond', 'correct', 'single', 'reference', 'couple', 'cluster', 'approach', 'simple', 'model', 'bond', 'breaking', 'formation', 'paldus', 'reduce', 'multireference', 'method', 'effective', 'approach', 'quasidegenerate', 'state', 'journal', 'chemical', 'h', 'j', 'monkhorst', 'calculation', 'property', 'coupledcluster', 'international', 'journal', 'chemistry', 'cluster', 'decomposition', 'full', 'configuration', 'interaction', 'wave', 'function', 'tool', 'chemical', 'interpretation', 'system', 'strong', 'correlation', 'journal', 'chemical', 'hino', 'tailor', 'couple', 'cluster', 'single', 'double', 'method', 'apply', 'calculation', 'molecular', 'structure', 'harmonic', 'vibrational', 'frequency', 'ozone', 'journal', 'chemical', 'l', 'veis', 'antal´ık', 'neese', 'legeza', 'pittner', 'couple', 'cluster', 'method', 'single', 'double', 'excitation', 'tailor', 'matrix', 'product', 'state', 'wave', 'function', 'journal', 'physical', 'chemistry', 'letter', 'legeza', 'assess', 'accuracy', 'tailor', 'couple', 'cluster', 'method', 'correct', 'electronic', 'wave', 'function', 'polynomial', 'cost', 'journal', 'chemical', 'theory', 'computation', 'ravi', 'perera', 'park', 'bartlett', 'excite', 'state', 'pair', 'couple', 'cluster', 'double', 'tailor', 'couple', 'cluster', 'theory', 'journal', 'chemical', 'lyakh', 'lotrich', 'r', 'bartlett', 'tailor', 'description', 'automerization', 'cyclobutadiene', 'chemical', 'physics', 'letter', 'antal´ık', 'demel', 'legeza', 'j', 'pittner', 'efficient', 'local', 'tailor', 'couple', 'cluster', 'approximation', 'peculiar', 'case', 'oxomn', 'journal', 'chemical', 'antal´ık', 'nachtigallov´a', 'legeza', 'j', 'pittner', 'p', 'l', 'veis', 'ground', 'state', 'model', 'system', 'correspond', 'quintet', 'dft', 'dmrgbase', 'tailor', 'study', 'physical', 'chemistry', 'chemical', 'antal´ık', 'l', 'veis', 'legeza', 'pittner', 'nearlinear', 'scale', 'dmrgbase', 'tailor', 'couple', 'cluster', 'implementation', 'dlpnotccsd', 'journal', 'chemical', 'theory', 'computation', 'faulstich', 'laestadius', 'legeza', 'r', 'schneider', 'kvaal', 'analysis', 'tailor', 'coupledcluster', 'method', 'numerical', 'analysis', 'csirik', 'l', 'veis', 'antalik', 'r', 'schneider', 'j', 'pittner', 'kvaal', '¨or', 'legeza', 'numerical', 'theoretical', 'aspect', 'dmrgtcc', 'method', 'exemplify', 'dimer', 'journal', 'chemical', 'theory', 'computation', 'melnichuk', 'r', 'bartlett', 'relax', 'active', 'space', 'fix', 'tailoredcc', 'high', 'order', 'couple', 'cluster', 'journal', 'chemical', 'physics', 'demel', 'pittner', 'space', 'multireference', 'couple', 'cluster', 'tailor', 'matrix', 'product', 'state', 'arxiv', 'preprint', 'arxiv230401625', 'magoula', 'p', 'piecuch', 'communication', 'approach', 'exact', 'quantum', 'chemistry', 'cluster', 'analysis', 'full', 'configuration', 'interaction', 'wave', 'function', 'journal', 'chemical', 'physics', 'p', 'piecuch', 'converge', 'highlevel', 'coupledcluster', 'energetic', 'sampling', 'moment', 'expansion', 'phy', 'rev', 'magoula', 'piecuch', 'externally', 'correct', 'couple', 'cluster', 'always', 'well', 'underlie', 'truncate', 'configuration', 'interaction', 'journal', 'chemical', 'theory', 'computation', 'c', 'externally', 'correct', 'ccsd', 'renormalized', 'perturbative', 'triple', 'recccsd', 'density', 'matrix', 'renormalization', 'group', 'select', 'configuration', 'interaction', 'external', 'source', 'journal', 'chemical', 'theory', 'computation', 'turney', 'couple', 'cluster', 'externally', 'correct', 'adaptive', 'configuration', 'interaction', 'journal', 'chemical', 'theory', 'computation', 'gl', 'r', 'c', 'parrish', 'local', 'expressive', 'quantumnumberpreserve', 'fermionic', 'system', 'new', 'journal', 'physics', 'h', 'dun', 'gaussian', 'basis', 'set', 'use', 'correlate', 'molecular', 'calculation', 'atom', 'boron', 'neon', 'hydrogen', 'chem', 'phy', 'gard', 'l', 'e', 'economou', 'barne', 'efficient', 'symmetrypreserve', 'state', 'preparation', 'circuit', 'variational', 'information', 'h', 'r', 'grimsley', 'e', 'e', 'barne', 'mayhall', 'adaptive', 'variational', 'exact', 'molecular', 'simulation', 'quantum', 'computer', 'nature', 'communication', 'h', 'r', 'grimsley', 'mayhall', 'e', 'barne', 'e', 'adaptive', 'construct', 'hardwareefficient', 'quantum', 'processor', 'quantum', 'stair', 'evangelista', 'simulate', 'manybody', 'system', 'projective', 'quantum', 'eigensolver', 'quantum', 'huggin', 'generalize', 'unitary', 'couple', 'cluster', 'wave', 'function', 'quantum', 'computation', 'journal', 'chemical', 'theory', 'computation', 'gorman', 'w', 'huggin', 'e', 'rieffel', 'generalize', 'swap', 'network', 'nearterm', 'quantum', 'compute', 'arxiv', 'preprint', 'jastrowtype', 'decomposition', 'quantum', 'chemistry', 'lowdepth', 'quantum', 'circuit', 'journal', 'chemical', 'theory', 'computation', 'sun', 'rourke', 'e', 'ye', 'determine', 'eigenstate', 'thermal', 'state', 'quantum', 'computer', 'use', 'quantum', 'imaginary', 'time', 'evolution', 'nature', 'physics', 'h', 'swingle', 'robust', 'entanglement', 'renormalization', 'noisy', 'quantum', 'computer', 'arxiv', 'preprint', 'j', 'sewell', 'prepare', 'renormalization', 'group', 'fix', 'point', 'hardware', 'arxiv', 'preprint', 'unitary', 'circuit', 'strongly', 'correlate', 'fermion', 'phy', 'rev', 'quantumclassical', 'eigensolver', 'use', 'entanglement', 'renormalization', 'physical', 'review', 'research', 'l', 'nearoptimal', 'ground', 'state', 'preparation', 'quantum', 'malz', 'zy', 'cirac', 'preparation', 'matrix', 'product', 'state', 'logdepth', 'quantum', 'circuit', 'arxiv', 'preprint', 'arxiv230701696', 'tura', 'cirac', 'fast', 'ground', 'state', 'preparation', 'highprecision', 'ground', 'energy', 'estimation', 'qubit', 'journal', 'mathematical', 'c', 'ba˜nul', 'cirac', 'algorithm', 'quantum', 'simulation', 'energy', 'quantum', 'db', 'gaussian', 'filter', 'explore', 'property', 'review', '101103physreva106032420', 'kyriienko', 'inverse', 'iteration', 'programmable', 'quantum', 'simulator', 'information', 'morale', 'p', 'casare', 'delgado', 'j', 'initial', 'state', 'preparation', 'quantum', 'chemistry', 'quantum', 'computer', 'arxiv', 'preprint', 'loaiza', 'izmaylov', 'fluid', 'fermionic', 'fragment', 'optimize', 'quantum', 'measurement', 'electronic', 'hamiltonian', 'variational', 'quantum', 'eigensolver', 'quantum', 'gkritsis', 'e', 'elfve', 'polla', 'huggin', 'abanin', 'r', 'acharya', 'aleiner', 'r', 'andersen', 'asfaw', 'c', 'bengtsson', 'bourassa', 'buell', 'burger', 'campero', 'chiaro', 'chik', 'j', 'r', 'collin', 'p', 'l', 'crook', 'debroy', 'demura', 'drozdov', 'dunsworth', 'farhi', 'r', 'fatemi', 'gilboa', 'r', 'gosula', 'grajale', 'j', 'gross', 'habegger', 'r', 'hoffmann', 'ioffe', 'isakov', 'p', 'khattar', 'r', 'klot', 'n', 'korotkov', 'landhuis', 'laptev', 'km', 'l', 'law', 'lester', 'lill', 'locharla', 'malone', 'mcclean', 'mccourt', 'mieszala', 'morvan', 'r', 'mruczkiewicz', 'neeley', 'h', 'nguyen', 'omonije', 'opremcak', 'petukhov', 'r', 'potter', 'l', 'p', 'c', 'p', 'roushan', 'saei', 'sink', 'shearn', 'short', 'shvart', 'r', 'somma', 'sterle', 'strain', 'szalay', 'thor', 'torre', 'vidal', 'b', 'villalonga', 'c', 'young', 'zalcman', 'zobrist', 'bacon', 'boixo', 'lucero', 'megrant', 'h', 'neven', 'smelyanskiy', 'c', 'r', 'babbush', 'n', 'purificationbase', 'quantum', 'error', 'mitigation', 'paircorrelate', 'electron', 'simulation', 'nature', 'physics', 'r', 'babbush', 'bacon', 'j', 'c', 'r', 'barend', 'r', 'biswas', 'boixo', 'buell', 'et', 'supremacy', 'use', 'programmable', 'superconducte', 'processor', 'nature', 'thrifty', 'shadow', 'estimation', 'reuse', 'quantum', 'circuit', 'bound', 'tail', 'quantph', 'performance', 'analysis', 'multishot', 'shadow', 'estimation', 'quantum', 'hutter', 'gaussian', 'basis', 'set', 'accurate', 'calculation', 'molecular', 'system', 'gas', 'condense', 'phase', 'journal', 'chemical', 'goedecker', 'tet', 'j', 'hutter', 'separable', 'pseudopotential', 'jnane', 'h', 'c', 'nguyen', 'error', 'mitigate', 'classical', 'shadow', 'quantph', 'h', 'r', 'meister', 'algorithmic', 'shadow', 'spectroscopy', 'arxiv221211036', 'quant', 'ph', 'r', 'brieger', 'heinrich', 'roth', 'stability', 'classical', 'shadow', 'gatedependent', 'noise', 'quantph', 'c', 'rubin', 'e', 'deprince', 'tool', 'prototype', 'manybody', 'method', 'chemistry', 'molecular', 'physics', 'q', 'sun', 'banerjee', 'p', 'blunt', 'n', 'bogdanov', 'koval', 'mussard', 'pulkin', 'robinson', 'ronca', 'e', 'r', 'scheurer', 'sun', 'white', 'wouter', 'c', 'sharma', 'sokolov', 'recent', 'development', 'pyscf', 'program', 'package', 'journal', 'chemical', 'bradbury', 'r', 'frostig', 'maclaurin', 'necula', 'paszke', 'wandermanmilne', 'jax', 'composable', 'transformation', 'pythonnumpy', 'program', 'white', 'l', 'freitag', 'r', 'babbush', 'shiozaki', 'fermionic', 'quantum', 'emulator', 'quantum', 'bergholm', 'ahme', 'akashnarayanan', 'asadi', 'ban', 'c', 'r', 'bromley', 'b', 'cordi', 'delgado', 'dusko', 'garg', 'guala', 'hill', 'isacsson', 'e', 'khandelwal', 'r', 'lang', 'loke', 'lowe', 'monta˜nez', 'barrera', 'r', 'moyard', 'z', 'niu', 'oud', 'panigrahi', 'park', 'polatajko', 'shu', 'sim', 'sz´ava', 'thabet', 'r', 'r', 'wiersema', 'pennylane', 'automatic', 'differentiation', 'hybrid', 'quantumclassical', 'computation', 'c', 'millman', 'r', 'gommer', 'virtanen', 'cournapeau', 'kern', 'picu', 'hoyer', 'haldane', 'wiebe', 'p', 'g´erardmarchant', 'sheppard', 'gohlke', 'e', 'oliphant', 'array', 'programming', 'numpy', 'nature', 'virtanen', 'r', 'gommer', 'oliphant', 'reddy', 'cournapeau', 'bright', 'millman', 'r', 'j', 'kern', 'c', 'carey', '˙i', 'polat', 'laxalde', 'r', 'cimrman', 'henriksen', 'e', 'quintero', 'c', 'r', 'h', 'ribeiro', 'p', 'mulbregt', 'scipy', 'contributor', 'scipy', 'fundamental', 'algorithm', 'scientific', 'computing', 'python', 'nature', 'method', 'panda', 'development', 'team', 'pandasdevpanda', 'panda', 'wes', 'datum', 'structure', 'statistical', 'computing', 'proceeding', '9th', 'python', 'science', 'con', 'ference', 'edit', 'pp', 'hunter', 'graphic', 'environment', 'compute', 'science', 'engineering', 'seaborn', 'statistical', 'data', 'visualization', 'journal', 'open', 'source', 'software', 'meurer', 'ˇcert´ık', 'rathnayake', 'granger', 'r', 'p', 'muller', 'gupta', 'vat', 'curry', 'r', 'terrel', 'rouˇcka', 'saboo', 'fernando', 'r', 'cimrman', 'scopatz', 'sympy', 'symbolic', 'computing', 'peerj', 'computer', 'science', 'wimmer', 'efficient', 'numerical', 'computation', 'pfaffian', 'dense', 'band', 'skewsymmetric', 'matrix', 'acm', 'transaction', 'mathematical', 'software', 'w', 'r', 'stewart', 'pople', 'selfconsistent', 'molecularorbital', 'method', 'use', 'gaussian', 'expansion', 'slatertype', 'atomic', 'orbital', 'chem', 'phy', 'r', 'ditchfield', 'r', 'f', 'stewart', 'pople', 'selfconsistent', 'molecular', 'orbital', 'method', 'use', 'gaussian', 'expansion', 'slatertype', 'orbital', 'extension', 'secondrow', 'molecule', 'chem', 'phy', 'r', 'ditchfield', 'w', 'pople', 'selfconsistent', 'molecularorbital', 'method', 'extended', 'gaussiantype', 'basis', 'molecularorbital', 'study', 'organic', 'molecule', 'chem', 'phy', 'francl', 'w', 'binkley', 'j', 'defree', 'j', 'pople', 'selfconsistent', 'molecular', 'orbital', 'method', 'polarizationtype', 'basis', 'set', 'secondrow', 'element', 'chem', 'phy', 'binkley', 'j', 'pople', 'w', 'selfconsistent', 'molecularorbital', 'method', 'small', 'splitvalence', 'basis', 'set', 'secondrow', 'element', 'chem', 'soc', 'r', 'ditchfield', 'pople', 'selfconsistent', 'molecular', 'orbital', 'method', 'xii', 'extension', 'gaussian', 'type', 'basis', 'set', 'use', 'molecular', 'orbital', 'study', 'organic', 'molecule', 'chem', 'phy', 'r', 'kendall', 'h', 'dun', 'harrison', 'electron', 'affinity', 'firstrow', 'atom', 'revisit', 'systematic', 'basis', 'set', 'wave', 'function', 'chem', 'phy', 'e', 'h', 'dun', 'gaussian', 'basis', 'set', 'use', 'correlate', 'molecular', 'calculation', 'atom', 'aluminum', 'chem', 'phy', 'malone', 'datum', 'unbiase', 'fermionic', 'quantum', 'quantum', 'computer', 'appendix', 'theoretical', 'background', 'couple', 'cluster', 'method', 'single', 'reference', 'couple', 'cluster', 'srcc', 'wavefunction', 'construct', 'exponential', 'ansatz', 'act', 'hartreefock', 'fermi', 'vacuum', 'reference', 'determinant', 'ψcc⟩', 'cluster', 'operator', 'cluster', 'operator', 'form', 'linear', 'combination', 'individual', 'operator', 'e', 'ˆt', 'ˆt', 'ˆtν', 'excitation', 'level', 'ν', 'truncate', 'expression', 'certain', 'excitation', 'level', 'νmax', 'yield', 'wellknown', 'hierarchy', 'truncated', 'method', 'single', 'νmax', 'single', 'double', 'νmax', 'single', 'double', 'triple', 'νmax', 'excitation', 'operator', 'generally', 'define', 'ˆtν', 'ijk', 'amplitude', 'give', 'excitation', 'level', 'ν', 'fermionic', 'creation', 'annihilation', 'operator', 'ˆa†p', 'ˆap', 'respectively', 'index', 'b', 'c', 'denote', 'virtual', 'orbital', 'index', 'j', 'k', 'refer', 'occupy', 'orbital', 'p', 'q', 'r', 'refer', 'general', 'spin', 'orbital', 'amplitude', 'solve', 'project', 'excited', 'determinant', 'manifold', 'similaritytransformed', 'hamiltonian', '¯h', '¯h', 'refer', 'residual', 'vector', 'result', 'nonlinear', 'amplitude', 'equation', 'solve', 'iteratively', 'note', 'similarity', 'transformation', 'require', 'obtain', 'computationally', 'tractable', 'amplitude', 'equation', 'left', 'obtain', 'srcc', 'energy', 'result', 'hamiltonian', 'long', 'hermitian', 'project', '≡', '⟨', 'e−', '≡', 'ecc', '¯h', '⟨', 'φ0', 'ehf', 'tb', 'ijab', 'ijab', 'tab', 'reference', 'hartreefock', 'energy', 'ehf', 'fock', 'matrix', 'element', 'p', 'antisymmetrize', 'twoelectron', 'repulsion', 'integral', 'physicist', 'notation', 'note', 't1', 'amplitude', 'enter', 'srcc', 'energy', 'expression', 'directly', 'independent', 'truncation', 'level', 'high', 'excitation', 'cluster', 'operator', 'produce', 'fully', 'contract', 'term', 'hamiltonian', 'implicit', 'energy', 'contribution', 'higherorder', 'amplitude', 'originate', 'coupling', 'amplitude', 'projection', 'equation', 'amplitude', 'equation', 'require', 'projection', 'singly', 'doubly', 'excited', 'determinant', 'rs', 'pq', '⟨', '¯h', '¯h', 'follow', 'section', 'use', 'normalordered', 'hamiltonian', '⟨', 'express', 'bakercampbellhausdorff', 'bch', 'expansion', '¯h', 'conveniently', '⟨', '¯h', 'c', 'a6', 'a9', 'c', 'denote', 'connect', 'contribution', 'expansion', 'survive31', 'programmable', 'expression', 'projection', 'equation', 'hand', 'example', 'derive', 'code', 'generation', 'see', 'amplitude', 'solve', 'iteratively', 'standard', 'tailor', 'couple', 'cluster', 'tailor', 'couple', 'cluster', 'tcc', 'aim', 'encode', 'static', 'correlation', 'effect', 'active', 'space', 'method', 'srcc', 'wavefunction', 'splitamplitude', 'ansatz2', 'ˆt', 'ˆt', 'a10', 'amplitude', 'active', 'space', 'cluster', 'operator', 'ˆt', 'extract', 'exact', 'approximate', 'active', 'space', 'wavefunction', 'relationship', 'configuration', 'interaction', 'ansatz', 'exponential', 'excitation', 'operator', 'ˆcν', 'define', 'cluster', 'operator', 'corresponding', 'plitude', 'conversion', 'amplitude', 'achieve', 'match', 'excitation', 'level', 'recursively', 'determine', 'amplitudes6364', 'fourfold', 'excitation', 'ˆcν', 'e', 'a11', 'ˆt1', 'ˆt2', 'ˆc2', 'ˆt3', 'ˆt4', 'ˆc4', 'ˆt', 'ˆt1', 'ˆt2', 'ˆt2', 'ˆt1', 'ˆt3', 'ˆt3', 'ˆt1', 'ˆt', 'evaluate', 'term', 'wick', 'contraction', 'yield', 'follow', 'programmable', 'expressions64', 'tab', 'cab', 'tb', 'tabcd', 'ijkl', 'tab', 'ik', 'ik', 'ktac', 'ktab', 'tc', 'tc', 'a12', 'a13', 'a14', 'a15', 'a16', 'a18', 'expression', 'contain', 'single', 'nonredundant', 'outer', 'product', 'amplitude', 'term', 'permuted', 'index', 'ensure', 'correct', 'antisymmetry', 'result', 'amplitude', 'cancel', 'exactly', 'correspond', 'prefactor', 'taylor', 'expansion', 'coefficient', 'reference', 'determinant', 'underlie', 'ci', 'expansion', 'equal', 'one', 'renormalize', 'conversion', 'equation', 'accordingly', 'method', 'tcc', 'applicable', 'coefficient', 'reference', 'determinant', 'extract', 'active', 'space', 'method', 'nonzero', 'set', 'ci', 'amplitude', 'hand', 'correspond', 'spinorbital', 'amplitude', 'build', 'expression', 'yield', 'active', 'space', 'cluster', 'operator', 'ˆt', 'orbital', 'index', 'cluster', 'amplitude', 'fully', 'contain', 'contrary', 'external', 'cluster', 'amplitude', 'belong', 'comprise', 'active', 'space', 'orbital', 'space', 'least', 'orbital', 'index', 'part', 'active', 'space', 'tcc', 'energy', 'functional', 'give', 'external', 'active', 'space', 'cluster', 'operator', 'commute', 'construction', 'obtain', 'active', 'space', 'energy', 'cc', 'energy', 'functional', 'c', 'etcc', 'e', 'ˆt', 'φ0', 'a20', 'etcc', 'e', 'ˆta', 'eext', 'e', 'ˆtext', 'cid68', 'cid69', 'c', 'c', 'a21', 'a22', 'relationship', 'hold', 'equivalence', 'cc', 'expansion', 'exact', 'wavefunction', 'amplitude', 'extract', 'active', 'space', 'wavefunction', 'exact', 'view', 'optimize', 'presence', 'higherorder', 'amplitude', 'active', 'space', 'method', 'approximate', 'active', 'space', 'method', 'mapping', 'exact', 'result', 'energy', 'compute', 'cc', 'energy', 'functional', 'necessarily', 'equivalent', 'variational', 'energy', 'active', 'space', 'wavefunction1', 'retain', 'static', 'correlation', 'information', 'tcc', 'wavefunction', 'active', 'space', 'amplitude', 'keep', 'freeze', 'optimization', 'external', 'amplitude', 'follow', 'amplitude', 'equation', 'solve', 'tccsd', 'popular', 'flavor', 'tcc', 'ˆhn', 'e', 'ˆt', 'ˆt', 'e', 'ˆt', 'ˆt', 'ext', 'e', 'ˆt', 'ˆt', 'e', 'ˆt', 'ˆt', 'ext', 'cid68', 'cid12', 'cid68', '̸⊂', 'j', 'b', 'c', 'cid69', 'a23', 'a24', 'note', 'output', 'amplitude', 'external', 'however', 'active', 'space', 'amplitude', 'still', 'appear', 'algebraic', 'expression', 'projection', 'equation', 'thus', 'frozen', 'active', 'space', 'amplitude', 'impact', 'tcc', 'solution', 'active', 'space', 'energy', 'energy', 'evaluate', 'directly', 'frozen', 'amplitude', 'additionally', 'contraction', 'external', 'amplitude', 'active', 'space', 'amplitude', 'know', 'map', 'correspond', 'orbital', 'full', 'molecular', 'orbital', 'space', 'standard', 'srcc', 'framework', 'use', 'solve', 'external', 'amplitude', 'constraint', 'certain', 'stride', 'full', 'space', 'amplitude', 'freeze', 'practice', 'easily', 'achieve', 'set', 'stride', 'active', 'space', 'amplitude', 'cc', 'residual', 'vector', 'standard', 'perturbative', 'triple', 'correction', 'employed69', 'evaluate', 'external', 'amplitude', 'consistency', 'externally', 'correct', 'couple', 'cluster', 'externally', 'correct', 'build', 'similar', 'splitamplitude', 'ansatz', 'tcc', 'aim', 'encode', 'static', 'corre', 'lation', 'srcc', 'wavefunction', 'higherorder', 'cluster', 'operator', 'inspect', 'untruncated', 'expression', 'single', 'double', 'residual', 'equation', 'clear', 'ˆt3', 'ˆt4', 'contribute', 'achieve', 'correct', 'total', 'excitation', 'level', 'ˆt3', 'ˆt3', 'ˆt4', 'ˆt1', 'ˆt3', 'c', 'a26', 'rab', 'cid68', 'expression', 'course', 'correspond', 'ccsdtq', 'residual', 'equation', 't1', 'however', 'higherorder', 'cluster', 'operator', 'produce', 'contribution', 'term', 'hence', 'traditional', 'ccsd', 'approach', 'correspond', 'approximate', 'case', 'ˆt3', 'ˆt4', 'mean', 'add', 'direct', 'contribution', 'amplitude', 'eg', 'extract', 'highquality', 'correlate', 'multireference', 'wavefunction', 'projection', 'equation', 'principle', 'obtain', 'improved', 'treatment', 'overall', 'electron', 'correlation', 'include', 'nondynamic', 'correlation', 'effect', 'compare', 'gist', 'convergence', 'full', 'ci', 'guarantee', 'input', 'amplitude', 'become', 'exact', 'thus', 'procedure', 'optimize', 't1', 'amplitude', 'presence', 'approximate', 'result', 'cluster', 'operator', 'give', 'amplitude', 'extract', 'input', 'wavefunction', 'wavefunction', 'cover', 'subset', 'molecular', 'orbital', 'case', 'active', 'space', 'method', 'operator', 'modify', 'project', 'slice', 'amplitude', 'full', 'orbital', 'space', 'tcc', 'ˆt', 'ˆt1', 'ˆt2', 'ˆt', 'input', 'ˆt', 'input', 'a27', 'ˆt', 'ˆt1', 'ˆt2', 'ˆp3', 'ˆt', 'ˆp4', 'ˆt', 'a28', 'appropriate', 'projection', 'operator', 'ˆp3', 'ˆp4', 'recursion', 'relation', 'extract', 'amplitude', 'cilike', 'wavefunction', 'see', 'eq', 'a12', 'a15', 'active', 'space', 'wavefunction', 'use', 'input', 'convergence', 'guarantee', 'fci', 'hold', 'anymore', 'however', 'improvement', 'still', 'achieve', 'include', 'dominant', 'amplitude', 'multireference', 'treatment', 'compare', 'completely', 'neglect', 'triple', 'quadruple', 'structure', 'directly', 'imply', 'depend', 'quality', 'underlie', 'input', 'wavefunction', 'result', 'always', 'provide', 'well', 'result', 'input', 'wavefunction', 'reproduce', 'corresponding', 'proof', 'follow', 'section', 'energy', 'equivalent', 'though', 'single', 'double', 'treat', 'fully', 'variationally', 'approximate', 'active', 'space', 'wavefunction', 'configuration', 'interaction', 'section', 'largely', 'follow', 'argument', 'lay', 'proof', 'abbreviate', 'conciseness', 'single', 'double', 'equation', 'generate', 'coupledcluster', 'theory', 'involve', 'double', 'return', 'identical', 'coupledcluster', 'energy', 'naturally', 'get', 'different', 'energy', 't1', 'source', 'calculation', 'treat', 'fully', 'turn', 'truncate', 'configuration', 'interaction', 'show', 'satisfy', 'equation', 'see', 'convert', 'set', 'single', 'double', 'truncate', 'ci', 'correlation', 'energy', 'equation', 'form', 'equivalent', 'coupledcluster', 'single', 'double', 'equation', 'thus', 'satisfy', 'truncated', 'ci', 'equation', 'single', 'double', 'correspond', 'solve', 'eccc', 'equation', 'single', 'double', 'equation', 'imply', 'energy', 'equivalent', 'theorem', 'solution', 'truncated', 'configuration', 'interaction', 'set', 'equation', 'include', 'full', 'single', 'full', 'double', 'set', 'high', 'excitation', 'satisfy', 'coupledcluster', 'single', 'double', 'equation', 'proof', 'first', 'consider', 'truncated', 'ci', 'wavefunction', 'expansion', 'represent', 'intermediate', 'normalization', 'ˆc1', 'ˆc2', 'ˆc1', 'full', 'set', 'onebody', 'excitation', 'coefficient', 'ˆc2', 'full', 'set', 'twobody', 'excitation', 'variational', 'coefficient', 'high', 'excitation', 'variational', 'coefficient', 'reference', 'determinant', 'note', 'need', 'complete', 'example', 'subset', 'triple', 'quadruple', 'consider', 'couple', 'equation', 'correlation', 'energy', 'single', 'double', '⟨', 'ˆc2', 'ˆc1', 'ˆc2', 'ˆc1', 'ˆc2', 'a30', 'a31', 'singly', 'doubly', 'excited', 'determinant', 'respec', 'ecorr', 'tively', 'note', 'connect', 'component', 'wavefunction', 'give', 'φ0', '⟨', 'ˆc1', 'ˆc2', 'evaluate', 'use', 'mercator', 'series', 'specific', 'case', 'general', 'cluster', 'analysis', 'equation', 'ln', 'c', 'use', 'write', 'ci', 'equation', 'exponential', 'ansatz', 'form', 'ln', 'ˆc1', 'ˆc2', 'a32', 'e', 'ˆt', 'e−', 'e', 'ˆt', 'c', 'c', 'ˆc1', 'ˆc2', 'introduce', 'projector', 'relevant', 'subspace', 'space', 'a33', 'a34', 'p', '†1', 'q', 'define', 'orthogonal', 'compliment', 'p', 'operator', 'variational', 'coefficient', 'insert', 'resolution', 'identity', 'get', 'p', 'p', 'p', '†2', 'p', 'b', 'p', 'q', '†b', 'φ0⟩⟨', 'p', 'tilde', 'c', 'indicate', 'excitation', 'a36', 'φa', 'e', 'ˆt', 'p', 'et', 'ˆt', 'p', 'cid0', 'e', 'e', 'ˆt', 'p', 'p', 'p', 'c', 'e', 'et', 'p', 'ˆt', 'q', 'ˆt', 'p', 'e', 'c', 'ˆc1', 'ˆc1', 'a37', 'a38', 'a39', 'first', 'term', 'lefthandside', 'eq', 'a38', 'cancel', 'righthandside', 'last', 'term', 'left', 'handside', 'cluster', 'operator', 'excite', 'give', 'determinant', 'follow', 'protocol', 'obtain', 'similar', 'expression', 'double', 'equation', 'φab', 'ij', 'e', 'a40', 'c', 'expand', 'projector', 'a39', 'note', 'c1', 'operator', 'excite', 'determinant', 'obtain', 'single', 'coupledcluster', 'equation', 'expand', 'double', 'equation', 'projector', 'exponential', 'operator', 'obtain', 'double', 'coupledcluster', 'equation', 'c', 'reemphasize', 'full', 'single', 'double', 'require', 'proof', 'subset', 'single', 'use', 'last', 'term', 'lefthandside', 'eq', 'a39', 'necessarily', 'conclude', 'say', 'analogous', 'term', 'double', 'derivation', 'conclude', 'way', 'break', 'truncated', 'symmetry', 'modify', 'cluster', 'equation', 'remove', 'disconnected', 'component', 'cid17', 'computational', 'scaling', 'simplification', 'borrow', 't1', 't2', 'residual', 'equation', 'ccsdtq', 'expensive', 'residual', 'equation', 'require', 'addition', 'expansion', 'input', 'wavefunction', 'need', 'convert', 'correspond', 'amplitude', 'require', 'outer', 'product', 'amplitude', 'produce', 'eightindex', 'output', 'prefactor', 'quite', 'large', 'case', 'nonredundant', 'antisymmetric', 'tensor', 'scale', 'permutation', 'need', 'compute', 'transposition', 'unique', 'outer', 'product', 'however', 'conversion', 'occur', 'calculation', 'thus', 'repeatedly', 'evaluate', 'expensive', 'contraction', 'occur', 't2', 'residual', 'equation', 'product', 'amplitude', 'electronrepulsion', 'intergral', 'rab', 'ijlk', '⟨', 'a41', 'contraction', 'execute', 'purely', 'dictate', 'input', 'wavefunction', 'method', 'store', 'rest', 'computation', 'contribution', 'amplitude', 'equation', 'come', 'product', 't1', 'improve', 'performance', 'work', 'report', 'term', 'precompute', 'use', 't1', 'input', 'wavefunction', 'thereby', 'neglect', 'iterative', 'update', 't1t3', 'contribution', 'residual', 'equation', 'approximation', 'seem', 'minor', 'influence', 'quality', 'eccc', 'implementation', 'feature', 'frozen', 'iterative', 'computation', 'product', 'well', 'debugging', 'context', 'quantum', 'input', 'b', 'implementation', 'computational', 'methodology', 'classical', 'electronic', 'structure', 'calculation', 'run', 'use', 'use', 'basis', 'set', 'parameter', 'specify', 'main', 'text', 'tailor', 'externally', 'correct', 'couple', 'cluster', 'method', 'implement', 'standalone', 'python', 'library', 'use', 'pyscf', 'input', 'reference', 'state', 'molecular', 'integral', 'classical', 'casci', 'calculation', 'cluster', 'analysis', 'work', 'equation', 'ccsdtq', 'work', 'equation', 'generate', 'use', 'p†q113', 'improved', 'performance', 'tensor', 'contraction', 'evaluate', 'use', 'correctness', 'cluster', 'analysis', 'code', 'verify', 'use', 'library64', 'input', 'quantum', 'hardware', 'code', 'support', 'fqe', 'wavefunction', 'external', 'source116', 'overlap', 'case', 'fqe', 'input', 'obtain', 'simple', 'lookup', 'sparse', 'stateci', 'vector', 'address', 'determinant', 'correct', 'excitation', 'level', 'convert', 'fermi', 'matchgate', 'shadow', 'simulation', 'perform', 'use', 'inhouse', 'quantum', 'computing', 'software', 'stack', 'base', 'datum', 'analysis', 'perform', 'use', 'pandas120121', 'matplotlib122', 'c', 'splitamplitude', 'cc', 'noisy', 'quantum', 'input', 'section', 'investigate', 'shot', 'noise', 'finite', 'sampling', 'influence', 'error', 'energy', 'obtain', 'quantum', 'step', 'first', 'mean', 'explicit', 'simulation', 'matchgate', 'shadow', 'protocol', 'investigate', 'error', 'estimate', 'overlap', 'depend', 'number', 'shot', 'number', 'orbital', 'numerically', 'obtain', 'concrete', 'formula', 'characterize', 'performance', 'matchgate', 'shadow', 'base', 'overlap', 'estimation', 'method', 'complement', 'mathematically', 'prove', 'performance', 'guarantee', 'derive', 'particular', 'find', 'estimate', 'overlap', 'essentially', 'normal', 'distribute', 'second', 'step', 'use', 'knowledge', 'investigate', 'behavior', 'tccsd', 'energy', 'noise', 'add', 'exact', 'obtain', 'approximate', 'obtain', 'simulated', 'vqe', 'overlap', 'find', 'conclusion', 'largely', 'independent', 'precise', 'molecular', 'system', 'state', 'use', 'compu', 'tation', 'datum', 'present', 'following', 'obtain', 'use', 'restricted', 'hartree', 'fock', 'orbital', 'n2', 'molecule', 'bond', 'distance', '˚a', 'addition', 'chemically', 'reasonable', 'active', 'space', 'perform', 'simulation', 'spinzero', 'active', 'space', 'characterize', 'n', 'ζ', 'simulation', 'matchgate', 'shadow', 'pennylane', 'library117', 'use', 'prepare', 'approximate', 'ground', 'state', 'qubit', 'mean', 'quantum', 'number', 'preserve', 'fabrics82', 'layer', 'optimize', 'noise', 'lbfgsb', 'identity', 'gate', 'start', 'initialization', 'small', 'amount', 'normal', 'distribute', 'noise', 'add', 'initial', 'parameter', 'overlap', 'computation', 'follow', 'protocol', 'use', 'polynomial', 'interpolation', 'interpolate', 'pfaffian', 'polynomial', 'sympy124', 'b', 'computational', 'fig', 'c1', 'panel', 'show', 'covariance', 'matrix', 'overlap', 'basis', 'state', 'halffilling', 'subspace', 'n', 'qubit', 'bootstrappe', 'subshadow', 'shot', 'draw', 'randomly', 'shadow', 'shot', 'panel', 'show', 'diagonal', 'large', 'overlap', 'histogram', 'distribution', 'value', 'compute', 'subshadow', 'covariance', 'matrix', 'compute', 'scatter', 'plot', 'diagonal', 'position', 'blue', 'dot', 'overlap', 'pair', 'basis', 'state', 'subshadow', 'orange', 'diamond', 'mean', 'k', 'subshadow', 'green', 'crosse', 'analytically', 'compute', 'statistical', 'property', 'overlap', 'estimate', 'shoot', 'matchgate', 'shadow', 'section', 'analyze', 'statistical', 'property', 'overlap', 'estimate', 'shoot', 'matchgate', 'shadow', 'determine', 'variance', 'covariance', 'estimate', 'overlap', 'bootstrappe', 'analyze', 'distribution', 'first', 'generate', 'shadow', 'shot', 'individually', 'evaluate', 'circuit', 'measure', 'follow', 'iid', 'gaussian', 'unitary', 'randomly', 'draw', 'k', 'subshadow', 'size', 'estimate', 'overlap', 'subshadow', 'compute', 'covariance', 'matrix', 'estimate', 'simplicity', 'omit', 'median', 'mean', 'estimation', 'work', 'standard', 'arithmetic', 'mean', 'find', 'solid', 'evidence', 'overlap', 'different', 'computational', 'basis', 'state', 'approximately', 'uncorrelated', 'normal', 'distribute', 'figure', 'c1', 'covariance', 'matrix', 'diagonally', 'dominate', 'visible', 'structure', 'offdiagonal', 'entry', 'scatter', 'plot', 'display', 'correlation', 'grow', 'bootstrapped', 'variance', 'increasingly', 'concentrate', 'mean', 'covariance', 'b', 'p', 'c', 'e', 'index', 'comp', 'basis', 'state', 'type', 'shadow', 'mean', 'analytic', 'b', 'fig', 'panel', 'show', 'mean', 'estimate', 'variance', 'mean', 'absolute', 'value', 'covariance', 'basis', 'state', 'overlap', 'function', 'number', 'shadow', 'shot', 'use', 'bootstrappe', 'figure', 'show', 'estimate', 'covariance', 'matrix', 'variance', 'well', 'converge', 'covariance', 'order', 'magnitude', 'small', 'decay', 'far', 'k', 'suggest', 'actual', 'covariance', 'residual', 'value', 'artifact', 'use', 'estimation', 'panel', 'show', 'variance', 'variance', 'distribution', 'variance', 'variance', 'function', 'bind', 'decrease', 'fast', 'variance', 'figure', 'obtain', 'bind', 'n', 'ζ', 'factor', 'due', 'additional', 'factor', 'add', 'step', '41ii', 'third', 'arxiv', 'version', 'account', 'fact', 'notation', 'b', 'ζ', 'bind', 'variance', 'left', 'hand', 'side', 'instead', 'find', 'numerically', 'mean', 'variance', 'decaying', '1', 'expect', 'nearly', 'perfect', 'agreement', 'slightly', 'tight', 'bind', 'φ', '⟨', '⟨', '≤', '⟩⟨', 'ρ', 'n', 'ζ', 'c1', 'evaluate', 'bind', 'n', 'ζ', 'numerically', 'stable', 'way', 'become', 'costly', 'large', 'n', 'ζ', 'fortunately', 'find', 'halffilling', 'case', 'ζ', 'n2', 'simple', 'boud', 'n2', '⪅', 'see', 'power', 'law', 'fit', 'figure', 'c3', 'see', 'qualitatively', 'identical', 'statistical', 'property', 'number', 'qubit', 'state', 'motivate', 'use', 'gaussian', 'additive', 'noise', 'model', 'investigate', 'stability', 'tccsd', 'computation', 'imperfection', 'input', 'overlap', 'next', 'section', 'tccsd', 'noise', 'additive', 'noise', 'model', 'hand', 'next', 'investigate', 'energy', 'hybrid', 'tccsd', 'method', 'influence', 'noise', 'strength', 'end', 'classical', 'casci', 'calculation', 'increase', 'active', 'space', 'size', 'run', 'amplitude', 'extract', 'gaussian', 'noise', 'standard', 'deviation', 'mean', 'equal', 'add', 'amplitude', 'vector', 'subsequently', 'tccsdeccc', 'energy', 'calculation', 'run', 'use', 'active', 'realization', 'additive', 'noise', 'procedure', 'conduct', 'space', 'show', 'table', 'c1', 'σ', 'active', 'space', 'noisy', 'energy', 'sample', 'time', 'obtain', 'well', 'converge', 'estimator', 'energy', 'error', 'noise', 'datum', 'generate', 'use', 'n2', 'molecule', 'bond', 'distance', '109˚a', 'restricted', 'reference', 'orbital', 'artificially', 'construct', 'homolumo', 'gap', 'note', 'procedure', 'computationally', 'prohibitive', 'overlaps', 'mean', 'variance', 'mean', 'absolute', 'covariance', 'fit', 'slope', 'fit', 'slope', 'k', 'mean', 'variance', 'variance', 'variance', 'fit', 'slope', 'fit', 'slope', 'wan', 'bind', 'n', 'ζ', 'fig', 'power', 'law', 'fit', 'b', 'n', 'c1', 'halffilling', 'include', '√n', 'upper', 'bind', 'efficient', 'numerical', 'evaluation', 'table', 'c1', 'summary', 'active', 'space', 'size', 'require', 'overlap', 'use', 'figure', 'tccsd', 'eccc', 'active', 'space', 'highlight', 'red', 'use', 'case', '∆enoise', '∆enoise', 'aσβσ', 'yield', 'exponent', 'actually', 'compute', 'use', 'classical', 'simulation', 'matchgate', 'shadow', 'protocol', 'depend', 'active', 'space', 'size', 'hybrid', 'method', 'require', 'number', 'overlap', 'run', 'final', 'energy', 'calculation', 'vary', 'see', 'table', 'c1', 'dependence', 'absolute', 'tccsd', 'energy', 'error', 'σ', 'show', 'figure', 'c4', 'power', 'law', 'fit', 'form', 'tccsd', 'respectively', 'thus', 'absolute', 'energy', 'error', 'method', 'scale', 'approximately', 'linearly', 'noise', 'strength', 'furthermore', 'convergence', 'issue', 'classical', 'procedure', 'observe', 'even', 'large', 'noise', 'strength', 'consequently', 'run', 'noisy', 'input', 'amplitude', 'expect', 'obtain', 'actual', 'quantum', 'measurement', 'robust', 'strength', 'underlying', 'noise', 'linear', 'dependency', 'σ', 'rather', 'beneficial', 'behavior', 'hybrid', 'method', 'give', 'large', 'part', 'amplitude', 'usually', 'rather', 'small', 'even', 'signflippe', 'strong', 'noise', 'exponent', 'remain', 'approximately', 'molecular', 'system', 'well', 'datum', 'show', 'note', 'however', 'prefactor', 'heavily', 'depend', 'system', 'hand', 'irrelevant', 'stage', 'analysis', 'interesting', 'observation', 'figure', 'c4', 'absolute', 'error', 'method', 'comparable', 'even', 'require', 'many', 'overlap', 'evaluate', 'see', 'table', 'c1', 'behavior', 'bias', 'choice', 'molecular', 'test', 'system', 'ie', 'magnitude', 'amplitude', 'extract', 'n', 'n2', '×', 'b', 'fig', 'c4', 'absolute', 'tccsd', 'energy', 'error', 'absolute', 'energy', 'error', 'b', 'function', 'noise', 'strength', 'number', 'require', 'overlap', 'method', 'note', 'vertical', 'axis', 'intercept', 'depend', 'molecular', 'system', 'case', 'small', 'contribution', 'projection', 'equation', 'mildly', 'influence', 'noise', 'tccsd', 'case', 'however', 'lowerorder', 'frozen', 't1', 'amplitude', 'large', 'magnitude', 'even', 'small', 'system', 'amplitude', 'directly', 'enter', 'tccsd', 'energy', 'expression', 'contrary', 'tccsd', 'energy', 'error', 'extrapolation', 'variance', 'bind', 'overlap', 'measure', 'matchgate', 'shadow', 'become', 'possible', 'determine', 'shot', 'budget', 'give', 'active', 'space', 'size', 'obtain', 'overlap', 'certain', 'accuracy', 'observerd', 'tccsd', 'energy', 'error', 'noise', 'depend', 'linearly', 'standard', 'deviation', 'underlie', 'gaussian', 'distribution', 'dependence', 'however', 'sufficient', 'estimate', 'required', 'variance', 'molecular', 'system', 'many', 'prop', 'ertie', 'system', 'enter', 'tccsd', 'calculation', 'influence', 'final', 'tccsd', 'energy', 'error', 'problem', 'property', 'determine', 'error', 'directly', 'extract', 'molecular', 'solve', 'underlie', 'electronic', 'structure', 'problem', 'become', 'computationally', 'prohibitive', 'large', 'active', 'space', 'example', 'thus', 'seek', 'simple', 'extrapolation', 'model', 'noisy', 'energy', 'take', 'input', 'easy', 'obtain', 'parameter', 'molecular', 'system', 'even', 'outline', 'noise', 'analysis', 'section', 'go', 'focus', 'exclusively', 'tccsd', 'following', 'favorable', 'scaling', 'small', 'number', 'overlap', 'require', 'error', 'extrapolation', 'model', 'serve', 'input', 'budget', 'estimation', 'create', 'small', 'datum', 'set', 'contain', 'small', 'molecule', 'first', 'run', 'different', 'active', 'space', 'size', 'see', 'table', 'different', 'basis', 'set', 'sto3', 'g', 'g', 'ccpvdz', 'augccpvdz', '83126–133', 'result', 'state', 'extract', 'require', 'overlap', 'add', 'gaussian', 'noise', 'put', 'tccsd', 'energy', 'calculation', 'moleculebasis', 'setactive', 'space', 'combination', 'noise', 'sample', 'time', 'average', 'obtain', 'combination', 'amount', 'approximately', 'singlepoint', 'tccsd', 'calculation', 'therefore', 'run', 'datum', 'collection', 'tccsd', 'small', 'number', 'molecule', 'setting', 'thus', 'vary', 'require', 'number', 'overlap', 'c4', 'b', 'number', 'total', 'spin', 'orbital', 'n', 'easy', 'obtain', 'molecule', 'interest', 'completeness', 'number', 'nonredundant', 'excitation', 'amplitude', 'spin', 'block', 'nsp', 'spatial', 'orbital', 'electron', 'excitation', 'level', 'give', '∆enoise', 'tccsd', 'nsp', 'ν', 'cid89', 'nsp', 'c3', 'tccsd', 'need', 'overlap', 'nonredundant', 'single', 'excitation', 'single', 'excitation', 'double', 'excitation', 'αα', 'αβ', 'excitation', 'latter', 'correspond', 'single', 'excitation', 'couple', 'single', 'β', 'excitation', 'total', 'number', 'overlap', 'tccsd', 'thus', 'amount', 'nsp', 'ζα', 'nsp', 'nsp', 'ζα', 'nsp', 'nsp', 'ζα', 'nsp', 'c4', '≡', 'h', 'e', 'e', 'c', 'c', 'e', 'h', 'e', 'c', 'table', 'active', 'space', 'use', 'test', 'datum', 'set', 'tccsd', 'energy', 'error', 'extrapolation', 'include', 'result', 'number', 'require', 'overlap', 'input', '∆enoise', 'tccsd', 'variable', 'contribute', 'highly', 'systemspecific', 'amount', 'static', 'dynamic', 'correlation', 'system', 'example', 'weakly', 'correlate', 'molecule', 'dynamic', 'correlation', 'energy', 'dominant', 'mildly', 'affect', 'noisy', 'input', 'amplitude', 'tccsd', 'opposite', 'case', 'strongly', 'correlate', 'system', 'however', 'single', 'quantity', 'serve', 'model', 'properly', 'choice', 'molecule', 'try', 'cover', 'several', 'different', 'correlation', 'scenario', 'diatomic', 'molecule', 'equilibrium', 'stretch', 'diatomic', 'small', 'organic', 'molecule', 'thing', 'consider', 'several', 'attempt', 'build', 'good', 'error', 'model', 'come', 'follow', 'power', 'law', 'randomize', 'noise', 'simulation', 'fix', 'noise', 'strength', 'yield', 'unknown', 'parameter', 'righthand', 'side', '∆enoise', 'tccsd', 'adβn', 'fit', 'power', 'law', 'recorded', 'datum', 'molecule', 'basis', 'set', 'active', 'space', 'size', 'noise', 'sample', 'yield', 'exponent', 'parameter', 'show', 'table', 'c3', 'together', 'standard', 'error', 'determine', 'bootstrappe', 'bootstrap', 'sample', 'prefactor', 'carry', 'dependency', 'omit', 'variable', '∆enoise', 'adβn', 'c6', 'table', 'c3', 'parameter', 'error', 'obtain', 'power', 'law', 'fit', 'entire', 'tccsd', 'noise', 'error', 'datum', 'set', 'parameter', 'value', 'bootstrap', 'std', 'error', 'correlation', 'strength', 'thus', 'advisable', 'fit', 'parameter', 'globally', 'ie', 'molecule', 'run', 'power', 'law', 'fit', 'subset', 'sample', 'leaveoneout', 'confirm', 'exponent', 'seem', 'largely', 'independent', 'molecular', 'system', 'datum', 'show', 'indicate', 'fit', 'parameter', 'describe', 'trend', 'tccsd', 'error', 'noise', 'quite', 'well', 'simple', 'power', 'law', 'subset', 'power', 'law', 'fit', 'find', 'prefactor', 'vary', 'largely', 'depend', 'molecular', 'system', 'reason', 'globally', 'fit', 'exponent', 'hand', 'rerun', 'fit', 'molecule', 'keep', 'exponent', 'fix', 'fit', 'value', 'entire', 'datum', 'set', 'yield', 'prefactor', 'molecule', 'show', 'table', 'c4', 'plot', 'figure', 'raw', 'datum', '∆enoise', 'include', 'power', 'law', 'fit', 'plot', 'figure', 'clearly', 'see', 'plot', 'globally', 'fit', 'exponent', 'represent', 'slope', 'trend', 'basis', 'set', 'dependence', 'well', 'hint', 'indeed', 'use', 'error', 'cid12', 'extrapolation', 'model', 'active', 'space', 'system', 'datum', 'set', 'expect', 'error', 'magnitude', 'grow', 'number', 'require', 'overlap', 'decrease', 'size', 'total', 'mo', 'space', 'negative', 'exponent', 'latter', 'rationalize', 'follow', 'keep', 'active', 'space', 'size', 'hence', 'number', 'overlap', 'fix', 'increase', 'overall', 'space', 'contribution', 'relation', 'external', 'space', 'decrease', 'error', 'make', 'noisy', 'amplitude', 'measurement', 'become', 'negligible', 'remain', 'hurdle', 'table', 'c4', 'prefactor', 'obtain', 'permolecule', 'fit', 'noise', 'error', 'datum', 'exponent', 'fix', 'd1', 'value', 'obtain', 'plain', 'average', 'basis', 'set', 'value', 'table', 'c3', 'together', 't1', 'molecule', 't1', 'n2', 'stretch', 'stretch', 'pbenzyne', 'cl2', 'stretch', 'd1', 'give', 'molecule', 'present', 'datum', 'set', 'select', 'prefactor', 'system', 'need', 'compare', 'correlation', 'strength', 'find', 'good', 'fit', 'tabulate', 'datum', 'bit', 'cumbersome', 'seek', 'tangible', 'metric', 'easy', 'obtain', 'come', 'typical', 'diagonstic', 'value', 'commonly', 'use', 'assess', 'ccsd', 'wavefunction', 'provide', 'reliable', 'true', 'result', 'molecule', 'basis', 'set', 'method', 'need', 'compute', 'see', 'figure', 'trend', 'moleculespecific', 'prefactor', 'corresponding', 'diagnostic', 'value', 'good', 'agreement', 'thus', 'determination', 'prefactor', 'molecule', 'datum', 'set', 'suggest', 't1', 'diagnostic', 'value', 'strong', 'correlation', 'select', 'prefactor', 'first', 'compute', 't1', 'give', 'accordingly', 'see', 'table', 'c4', 'linear', 'model', 'convert', 't1', 'clearly', 'stretch', 'n2', 'molecule', 'kind', 'outlier', 'prefactor', 'diagnostic', 'value', 'far', 'medianmean', 'datum', 'set', 'however', 'show', 'scenario', 'n2', 'serve', 'bad', 'case', 'scenario', 'useful', 'following', 'estimate', 'upper', 'bound', 'shot', 'budget', 'summary', 'error', 'extrapolation', 'protocol', 'rely', 'follow', 'step', 'select', 'molecule', 'basis', 'set', 'determine', 'n', 'compute', 'ccsd', 'setting', 'obtain', 't1', 'diagnostic', 'value', 'select', 'active', 'space', 'size', 'compute', 'number', 'require', 'overlap', 'map', 'diagnostic', 'value', 'prefactor', 'use', 'conversion', 'formula', 'compare', 'table', 'c4', 'insert', 'quantity', 'n', 'exponent', 'table', 'c3', 'together', 'noise', 'strength', 'one', 'estimate', 'tccsd', 'energy', 'error', 'noise', 'precise', 'setting', 'use', 'procotol', 'following', 'estimate', 'shoot', 'budget', 'shot', 'budget', 'estimation', 'combine', 'c1', 'obtain', 'bind', 'number', 'shot', 'need', 'guarantee', 'shot', 'noise', 'change', 'tccsd', 'energy', 'give', 'magnitude', 'finally', 'estimate', 'shot', 'budget', 'halffilling', 'case', 'd2βn', '2γ√2n', 'give', 'target', 'tccsd', 'energy', 'error', 'systemdependent', 'variable', 'obtain', 'protocol', 'previous', 'section', 'use', 'equation', 'estimate', 'shot', 'budget', 'scenario', 'dictate', 'molecule', 'function', 'different', 'molecule', 'basis', 'set', 'fig', 'absolute', 'tccsd', 'energy', 'error', '∆enoise', 'dash', 'line', 'employ', 'power', 'law', 'fit', 'use', 'globally', 'fit', 'exponent', 'table', 'c3', 'together', 'moleculespecific', 'prefactor', 'table', 'c4', 'arbitrarily', 'choose', 'mo', 'space', 'n', 'half', 'prefactor', 'aim', 'target', 'accuracy', 'fill', 'active', 'space', 'n', 'n', 'qubit', 'uncertainty', 'fit', 'exponent', 'include', 'estimate', 'lower', 'bind', 'standard', 'deviation', 'upper', 'bind', 'exponent', 'bootstrap', 'standard', 'deviation', 'budget', 'result', 'shot', 'budget', 'estimate', 'plot', 'figure', 'surprisingly', 'even', 'bad', 'case', 'scenario', 'strong', 'correlation', 'stretch', 'n2', 'molecule', 'estimate', 'upper', 'bind', 'shot', 'budget', 'obtain', 'noisy', 'tccsd', 'energy', 'chemical', 'precision', 'barely', 'exceed', 'shot', 'qubit', 'set', 'want', 'stress', 'shot', 'budget', 'include', 'measurement', 'state', 'preparationoptimization', 'quantum', 'device', 'overlap', 'measurement', 'matchgate', 'shadow', 'imperfection', 'trial', 'state', 'shot', 'noise', 'apply', 'exact', 'overlap', 'error', 'quantum', 'tccsd', 'respect', 'exact', 'classical', 'counter', 'part', 'much', 'large', 'error', 'model', 'predict', 'nonetheless', 'broad', 'window', 'different', 'correlation', 'scenario', 'cover', 'helpful', 'enough', 'get', 'decent', 'understanding', 'order', 'magnitude', 'require', 'budget', 'stretch', 'stretch', 'pbenzyne', 'cl2', 'stretch', 'e', 'c', 'c', 'e', 'e', 'c', 'c', 'e', 'e', 'c', 'c', 'e', 'e', 'c', 'c', 'e', 'basis', 'set', 'sto3', 'g', 'ccpvdz', 'augccpvdz', 'datum', 'record', 'power', 'law', 'fit', 'fig', 'shoot', 'budget', 'estimation', 'scenario', 'base', 'molecular', 'system', 'prefactor', 'globally', 'fit', 'exponent', 'standard', 'deviation', 'exponent', 'global', 'fit', 'show', 'gray', 'shaded', 'area', 'target', 'energy', 'error', 'n', 'ζ', 'n2', 'note', 'molecule', 'label', 'different', 'prefactor', 'cover', 'different', 'possible', 'scenario', 'prefactor', 'figure', 'bestworst', 'case', 'scenario', 'shot', 'budget', 'base', 'tccsd', 'energy', 'error', 'extrapolation', 'table', 'shoot', 'budget', 'estimate', 'use', 'error', 'extrapolation', 'model', 'dissociation', 'curve', 'diagnostic', 'need', 'obtain', 'tccsd', 'energy', 'active', 'space', 'chemical', 'precision', 'together', 'extract', 'r', '˚a', '×', '×', '×', '×', 'n2', 'stretch', 'stretch', 'pbenzyne', 'cl2', 'stretch', 'eccc', 'hardware', 'datum', 'sycamore', 'quantum', 'processor', 'fig', 'd1', 'root', 'mean', 'square', 'error', 'rmse', 'absolute', 'value', 'wavefunction', 'coefficient', 'vector', 'extract', 'trial', 'state', 'different', 'repetition', 'device', 'noise', 'first', 'repeat', 'far', 'small', 'last', 'repeat', 'investigate', 'performance', 'actual', 'noisy', 'datum', 'use', 'wavefunction', 'extract', 'shadow', 'publish', 'raw', 'data', 'obtain', 'trial', 'state', 'wavefunction', 'refer', 'q', 'trial', 'original', 'paper', 'first', 'convert', 'realvalue', 'wavefunction', 'rotation', 'phase', 'large', 'absolute', 'value', 'wavefunction', 'coefficient', 'make', 'wavefunction', 'real', 'possible', 'retain', 'real', 'part', 'wavefunction', 'renormalize', 'state', 'refer', 'q', 'trial', 'real', 'quality', 'trial', 'wavefunction', 'extract', 'device', 'first', 'repetition', 'superior', 'run', 'see', 'figure', 'd1', 'use', 'datum', 'run', 'table', 'd1', 'h4sto3', 'g', 'energy', 'q', 'trial', 'state', 'convert', 'realvalue', 'wavefunction', 'absolute', 'error', 'meh', 'respect', 'fci', 'show', 'parenthesis', 'nclifford', 'repeat', 'repeat', '−192465', '−188711', '−191560', '−192072', '−189485', '−195366', '−196553', '−196650', '−196683', '−196634', 'e', 'r', 'r', 'c', 'e', 'c', 'experiment', 'nclifford', 'table', 'h4sto3', 'energy', 'base', 'q', 'trial', 'state', 'convert', 'realvalue', 'wavefunction', 'absolute', 'error', 'meh', 'respect', 'fci', 'show', 'parenthesis', 'nclifford', 'repeat', 'repeat', '−197656', '−197656', '−197656', '−197656', '−197637', '−197656', '−197637', '−197656', '−197656', '−197656', '−197637', '−197656', '−197637', '−196846', '−196881', '−197026', '−196893', '−197028', 'table', 'h4sto3', 'energy', 'base', 'exact', 'fci', 'state', 'overlap', 'measure', 'matchgate', 'shadow', 'result', 'average', 'sample', 'matchgate', 'shadow', 'absolute', 'error', 'meh', 'respect', 'fci', 'show', 'parenthesis', 'shot', 'single', 'matchgate', '−196990', '−197160', '−196965', '−196945', 'table', 'error', 'total', 'energy', 'diamond', 'minimal', 'unit', 'cell', 'doublezeta', 'basis', 'function', 'lattice', 'constant', 'r', 'r', '˚a', 'q', 'trial', 'q', 'trial', 'real', 'ecccq', 'trial', 'qcqmc', '−085', '−018']"
Tailored and Externally Corrected Coupled Cluster with Quantum Inputs,"[{'href': 'http://arxiv.org/abs/2312.08110v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2312.08110v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-12-13 12:57:39,"3
2
0
2

c
e
D
2
1

]

R
C
.
s
c
[

1
v
3
8
7
7
0
.
2
1
3
2
:
v
i
X
r
a

BarraCUDA:
Bringing Electromagnetic Side Channel Into Play to Steal the Weights of Neural
Networks from NVIDIA GPUs

P´eter Horv´ath∗, Łukasz Chmielewski†, Leo Weissbart∗, Lejla Batina∗, Yuval Yarom‡
∗Radboud University
†Masaryk University
‡Ruhr University Bochum

Abstract—Over the last decade, applications of neural networks
have spread to cover all aspects of life. A large number of
companies base their businesses on building products that use
neural networks for tasks such as face recognition, machine
translation, and autonomous cars. They are being used in
safety and security-critical applications like high definition
maps and medical wristbands, or in globally used products
like Google Translate and ChatGPT. Much of the intellectual
property underpinning these products is encoded in the exact
configuration of the neural networks. Consequently, protecting
these is of utmost priority to businesses. At the same time,
many of these products need to operate under a strong threat
model, in which the adversary has unfettered physical control
of the product.

Past work has demonstrated that with physical access,
attackers can reverse engineer neural networks that run on
scalar microcontrollers, like ARM Cortex M3. However, for
performance reasons, neural networks are often implemented
on highly-parallel general purpose graphics processing units
(GPGPUs), and so far, attacks on these have only recovered
course-grained information on the structure of the neural
network, but failed to retrieve the detailed weights and biases.
In this work, we present BarraCUDA, a novel attack
on GPGPUs that can completely extract the parameters of
neural networks. BarraCUDA uses correlation electromagnetic
analysis to recover the weights and biases in the convolutional
layers of neural networks. We use BarraCUDA to attack the
popular NVIDIA Jetson Nano device, demonstrating successful
reverse engineering of neural networks in a highly parallel and
noisy environment.

1. Introduction

The field of machine learning has seen an explosive in-
crease in interest and use over the last decade. In particular,
deep learning has proven to be a versatile technique that
provides state-of-the-art performance for many real-world
application. The use of deep learning proved useful for a
broad range of domains including playing chess [50], object
detection [35], image classification [17, 23, 29, 34, 51],
audio processing [43], forecasting [31, 45, 47, 48] and

natural language processing [40]. Thus, applications of deep
learning are changing many areas of our lives and have
become indispensable to our everyday life.

Deep learning typically utilizes artificial neural net-
works, consisting of multiple layers of (simulated) neu-
rons. In a nutshell, a neuron takes a number of inputs
and computes a non-linear function of the weighted sum
of the inputs. A common example of such a function is
a rectified linear unit (ReLU), which basically returns its
input if it is positive and zero otherwise. When designing
a deep learning solution for a problem, the designer first
chooses the network architecture, which specifies the layers
of neurons, including their sizes and types, as well as how
the neurons are connected, i.e. which neurons outputs are
connected to which inputs. The designer then trains the
network, selecting the weights used for each weighted sum
as well as bias values that are added to the sums before the
computation of the non-linear function.

Training a network for any non-trivial example is a
resource intensive process. There is a need to curate a
specialized dataset of correctly labeled samples that can be
used for the training, and the training process often requires
days and even weeks of computation on specialized high-
performance hardware, such as large quantities of graphical
processing units (GPUs). Moreover, the design of the right
network architecture for a given purpose requires special-
ized expertise. Consequently, the design and parameters of
trained models are in many cases considered as trade secrets,
which vendors try to protect against undesired disclosure.

Side-channel attacks, which exploit information leakage
via unintended effects of performing computation, are a
major threat
to the confidentiality of deep learning de-
signs. Such attacks against neural network implementa-
tions on CPUs have been demonstrated using both power
analysis [13] and microarchitectural attacks [54], among
others. However, to achieve a better performance neural
networks are often implemented on GPUs. So far, attacks on
such implementations only recover the network architecture,
but not the parameters [16, 37]. Moreover, these attacks
only target open-source neural networks, implemented using
PyTorch [41] and TensorFlow [12], while we target the
commonly used NVIDIA closed-source TensorRT frame-

 
 
 
 
 
 
work [10].

Therefore, this work focuses on the following research

questions:
Are implementations of neural networks on GPU vulnerable
to parameter extraction using side-channel analysis?

Our Contribution

In this work we answer the question in the affirmative.
We analyze NVIDIA’s closed-source neural network frame-
work TensorRT [10] executing on an industrial-strength
Jetson Nano device [9]. While TensorRT is a closed-source
framework, the produced CUDA binaries can be disassem-
bled.

We demonstrate a side-channel attack that monitors the
electromagnetic (EM) emanations emitted from the device.
The attack allows full extraction of the parameters of the
neural network running on the device, overcoming the
measurement noise and the uncertainty inherent in closed
platforms.

The attack uses correlation electromagnetic analysis
(CEMA) to recover the weights and biases of neural net-
works. For the attack, we collect and process 15 million
traces over a period of 10 days. We then show how to
analyze the traces to recover weights and biases used in
the target network.

The results of attack demonstrate that GPU implementa-
tions of deep learning are not protected against side-channel
attacks, even when the source code is not available.
Disclosure. We notified NVIDIA of the found vulnera-
bilities on September 22nd, 2023. We shortly received a
response on 24/09/2023 that they are looking into our find-
ings and as a result of mutual agreement the findings would
be not released until December 13rd, 2023. On November
22nd, 2023 NVIDIA notified us that they reviewed our
disclosure and classified the vulnerabilities as a low severity
issue while also recommending the users to follow guide-
lines to prevent physical access to secure systems to avoid
information leakage.
Organization.
The rest of this paper is organized as
follows: After providing the necessary background on side-
channel attacks and GPU architecture (Section 2), we de-
scribe our weight extraction attack. in Section 3. Finally,
Section 4 covers the limitations, possible extensions, coun-
termeasures, and related work.

2. Background

Here we introduce the concepts of side channels and
related techniques that were used for the attacks and provide
background on NVIDIA’S CUDA programming model and
GPU architecture.

2.1. Side-Channel Analysis

28]. Leakage can occur through various channels, includ-
ing power consumption, electromagnetic, timing, optical or
sound, and various types of secret information can leak.
In academic settings, side-channel attacks were first
in-
troduced in the 90’s targeting constrained cryptographic
devices [27, 28] and pose ever since a constant threat to
the security of various embedded systems. In this work, we
exploit the EM side channel.

2.1.1. Electromagnetic emanation. The electromagnetic
(EM) emanations from a computing device correlate with
the code and the data that the device processes. This cor-
relation has been used to break cryptographic implementa-
tions [30, 44], reverse engineer neural networks [13, 16] and
eavesdrop on display units [20, 24, 36].

In Simple EM Analysis (SEMA), the attacker samples
the emitted signal during the execution of the target pro-
gram, creating a trace of measurements. The attacker then
analyzes the trace to identify components that correspond
to the secret information.

In Correlation EM Analysis (CEMA), the attacker builds
a model of the leakage based on the data the program
processes. The attacker then executes the program multi-
ple times with different inputs, and looks for correlation
between the predicted leakage based on the model and the
observed leakage at some points of interest (POIs) in the
collected traces. Two common models are the Hamming
weight (HW) model, which predicts that the leakage is linear
with the number of set bits in the data (i.e. its Hamming
weight), and the Hamming distance (HD) model, which
predicts that the leakage is linear with the number of bits
that need to be changed between consecutive data values.

2.1.2. Leakage evaluation. Multiple methods have been
proposed to evaluate the leakage of embedded devices, such
as intermediate correlation, Test Vector Leakage Assessment
(TVLA) [49] and χ2-test [39]. In this paper, we use inter-
mediate correlation and TVLA to place our EM probe at a
location that leaks the most information and detect where
each intermediate value leaks in the collected measurements
in the parameter extraction attack presented in Section 3.

2.2. CUDA programming model

To leverage the parallelism offered by GPUs, NVIDIA
exposes the CUDA programming model [5] to developers.
In this model, multiple abstraction levels exist and each
level has different implications with respect to the GPU
hardware. The lowest level of abstraction is the thread,
which executes a CUDA function defined by the developer.
The number of threads executing the CUDA function in
parallel is specified at the time of invoking the function.1
Subsequently, multiple threads can be grouped together into
a single block of threads. Threads in a block have a
per block on-chip shared memory region where they can

Side-Channel Analysis (SCA) exploits the physical leak-
ages of electronic devices to extract secret information [27,

1. Functions in CUDA are also called kernels. We use the term function

to avoid confusion with kernels in CNNs.

the same shared memory on the chip. More importantly for
side-channel attacks, each PU also has a dedicated register
file. Since the details of assigning individual warps to PUs
are not publicly disclosed information, multiple register files
could mean that a CPA/CEMA attack is significantly hin-
dered. If a particular warp, one that calculates our targeted
intermediate variable, is assigned to different PUs in sub-
sequent executions, then our targeted intermediate variable
is saved into multiple, different register files which poten-
tially results in different power/EM signatures. Therefore,
mounting side-channel attacks that rely on the HD leakage
model might become difficult on the GPU, but we present a
successful attack using the HW as well as the HD leakage
model.

3. Weight and bias extraction attack

In this section, we detail our attack which recovers the
weights and biases of a CNN with 2 convolutional layers,
each containing one kernel. First, we describe the threat
model and explore the NN implementations from NVIDIA
on the assembly level. Second, we describe our experiment
setup and the process of establishing points of interest
(PoI) where the implementations leak information. Lastly,
we apply CEMA on intermediate values in the convolution
operation to extract the weights and bias of each layer.
To the best of our knowledge, this is the first time that
the weights and biases of NNs are extracted from imple-
mentations running on an NVIDIA GPU. In addition, the
experiments are carried out using half-precision calculations
in the convolutional layers.

Figure 1: CUDA programming interface and GPU hardware
implementation.

Figure 2: GPU Streaming Multiprocessor architecture.

exchange data with other threads in the block. Blocks of
threads form a grid of thread blocks. Each block in a grid
executes independently from the other blocks, but all blocks
in the grid share the same off-chip global memory region.

2.3. GPU Streaming Multiprocessor

3.1. Threat model

When a CUDA function is invoked, the parallel threads
execute on the Streaming Multiprocessor (SM) of the GPU.
A GPU can consist of one or more SMs to further improve
parallelism. Our target, the Jetson Nano, features a Tegra X1
System-On-Chip that consists of one SM of the Maxwell
architecture [11] and CUDA Compute Capability 5.3 [1]
from NVIDIA. As illustrated in Figure 1, when blocks of
threads are scheduled onto a particular SM, the threads
in the blocks are divided into groups of 32 threads, also
called warps. Warp is the lowest level of execution unit
and is of great concern for SCA. Every warp is assigned
to a particular Processing Unit (PU) where every PU has
dedicated resources to schedule and execute warps in the
SM. Figure 2 shows the building blocks of the Maxwell
SM and the PUs in the SM.2 The warp scheduler in a PU is
responsible for scheduling and issuing instructions for warps
that are ready. Every PU has a set of 32 CUDA cores for
arithmetic instructions as well as load/store units (LD/ST)
and special function units (SPU) for memory operations and
transcendental functions, respectively. In addition, a pair of
PUs share a texture/L1 cache but all PUs have access to

2. Graphics related components, such as the PolyMorph engine, are

omitted in our figure as these are not relevant for our target application.

In this scenario, we consider an adversary who has
access to the target device, can observe random inputs fed to
the device, and knows the architecture of the NN that runs
on the device. In addition, we also assume that the adversary
can collect electromagnetic side-channel measurements. We
assume that the architecture of the target NN is already
extracted as the architecture of a NN needs to be known
for the NN parameters to be extracted using CEMA.

3.2. Exploring TensorRT implementations

The approach of NVIDIA’s TensorRT framework is “one
size fits many”, that is, one implementation can be used for
layers with different kernel sizes, input sizes, batch sizes
etc. TensorRT provides information [8] about the optimized
model and this information includes the names of the CUDA
function implementations that are used for the model as well
as a hexadecimal undocumented value called Tacticvalue.3
Using this information, it is possible to extract the assembly
device code that is executed by each thread on the GPU. One

3. While there is no documentation about Tacticvalue, it might impact
the implementation’s execution since it might be used in predicated in-
structions.

CUDA programming level

GPU hardware level

Grid of thread blocks

Warp 1

Streaming Multiprocessor

PU 1

PU 2

PU 3

PU 4

Warp 2

Warp n

Maxwell Streaming Multiprocessor

Instruction cache

PU

Instruction buffer

Warp scheduler

Dispatch units

Register file

Cores

LD/ST SPU

PU 1

PU 2

Texture / L1 cache

PU 3

PU 4

Texture / L1 cache

Shared memory

can use cuobjdump [4] from the CUDA toolkit to extract
all the GPU assembly code that can be found in the different
CUDA shared library files (CuBLAS, CuDNN, TensorRT).
Eventually, we found the CUDA function corresponding
to the implementation of a convolutional layer with ReLU
activation in the libnvinfer.so file by the name that can be
retrieved using the TensorRT API.

In our parameter extraction attack, we reverse engineer
the weights of a NN with two convolutional layers each with
a kernel containing 5 weights. In the shared library files, 4
implementations can be found for a convolutional layer with
half-precision calculations and ReLU activation, named:

maxwell f p16x2 hcudnn f p16x2 128x k relu t nn v1,

where

k ∈ {32, 64, 128},

t ∈ {small, medium, large, interior}.

Based on repeated testing, the small, medium and interior
implementations can all be an implementation that the Ten-
sorRT API chooses for each convolutional layer in our 2-
layer model configuration. This is possible if the timing
differences are small in the implementations. Thus, it could
be that the same implementation is used for both layers or
a combination of two.

Furthermore, based on testing and using the information
provided by the API [8], these are also the implementations
that are chosen by the API for the large-scale neural net-
works such as MobileNet [25].

The names of implementations also include f p16x2
which refers to the half2 [6] data type in CUDA. When half2
is used, a register is packed with 2 half-precision floating
point values and the GPU can execute a floating point
instruction on each half in parallel, doubling the throughput
of the GPU, as opposed to using single-precision floating
point values. This also means additional noise for SCA in
addition to the parallel threads executing in the GPU.

3.3. Convolutional layer structure

Although there are 4 possible implementations for a
convolutional layer with ReLU activation, these implemen-
tations are very similar in their structure and they consist of
the following blocks:
1. block of initialization instructions,
2. block of convolution operations, and
3. block of bias addition and ReLU calculation.

1. Init block. The first main block consists of instructions
to set up the CUDA function. In this block, 64 accumulator
registers are initialized which are later used to calculate the
sum of multiplications in the convolution operation.

2. Convolutional block. The second block is where the
convolution operations are carried out. This block consists
of vectorized load and HFMA2 instructions. In addition, it
contains predicated load instructions from global memory.
Since registers are packed with two 16-bit floating point

Figure 3: Location of the Langer EM probe. The probe tip
is located between two capacitors.

values, it is also crucial to know exactly how the input
data is loaded into the registers. If this information is
available, it sheds light on how the convolution operation
is carried out in the implementations. According to the
API, the input is reformatted so that it is laid out in “Two
wide channel vectorized row major FP16 format”. This
means that each register holding inputs is loaded with two
half-precision floating point inputs from two different input
channels. Therefore, this also suggests that each register
holds weights from different channels in a kernel. In the
case of our one dimensional convolution, we set the number
of input channels to 1, as it is common for one-dimensional
convolutional use cases. In other cases, such as RGB image
inputs, the number of input channels would be 3 so each
register would hold input values from two different input
channels. With multiple input channels processed in parallel,
our CEMA attack would then not require more time to
get all the weights because the channels in the kernels are
independent from each other. Additionally, the code in the
second block indicates that each accumulator register is used
in 8 HFMA2 instruction in this block, unless a predicated
jump instruction is executed at the end of the code block
which jumps back to the start of this block. This suggests
that the execution of the jump instruction likely depends on
the kernel size in the layer.

3. ReLU block. The third block, repeated four times,
first calculates the sum of the lower and higher half of each
register. This suggests that the channel combinations of the
convolutional operation, after the sum of multiplications, are
executed in these blocks. Then, half2 floating point additions
and HSET instructions are executed in the block suggesting
the calculation of the bias addition and the ReLU output.

Overall, the four implementations are very similar. For
our particular two-layer model configuration, more than 50%
of the times the chosen implementation by the API is the
relu small implementation for both layers, so we choose
to carry out the parameter extraction attack with this imple-
mentation. However, we also analyzed the relu medium
and relu interior implementations in our leakage detection
process in Section 3.6.

Figure 4: Raw trace of the whole operation on the GPU. The
2 layers are clearly separated in the traces. Additionally, the
CUDA device-to-host memory copy is also clearly visisble
in the end of the trace.

Figure 5: Result of TVLA for the multiplication with the
first weight in the kernel in convolutional block. The top
figure depicts an elastically aligned trace while the bottom
figure shows the corresponding absolute t-test statistics at
each time sample. There are multiple leaking spots with
|t| > 4.5 but the overall leakage is not high.

Figure 6: Result of fixed vs random bias TVLA. The top
figure depicts an example trace while the bottom figure
shows the corresponding absolute t-test statistics at each
time sample. There is clear leakage scattered across multiple
clock cycles with |t| >> 4.5.

3.4. Experiment setup

In our setup, the Jetson Nano’s GPU cores operate at
the highest possible clock frequency at 921 MHz. In order
to collect electromagnetic traces, we use the Lecroy 8404M-
MS oscilloscope at a sampling rate of 10GS/s with the

Figure 7: Segmented raw trace of first
layer. The first
highlighted block contains the initialization instructions. The
second highlighted block is where the convolution operation
is carried out. The third highlighted block corresponds to the
bias addition and ReLU activation calculation.

leak information about

Langer MFA-R 0.275 near-field probe [7]. Each trace con-
tains measurements of the electromagnetic emanations of the
GPU when the target neural network executes inference on
random inputs. By scanning the Tegra SoC and the nearby
capacitors with the EM probe, we found multiple interesting
locations that
the parameters of
neural network. Eventually, we observed the best signal
between two capacitors, as shown in Figure 3. In terms of
leakage magnitude using TVLA, locations above the chip
and between the capacitors are very similar. However, the
emitted signal between the capacitors provides less noisier
traces which makes trace acquisition and alignment easier.
To trigger the oscilloscope to collect measurements when
the inference of the NN starts, we use the rising edge of
inference signal as trigger.

3.5. Trace preprocessing

Figure 4 shows an example trace of the inference oper-
ation of a CNN with two layers. The two layers are clearly
separated and display similar patterns. However, the first
layer takes considerably more time to execute. Since the
input sizes of the layers are 500 and 496, respectively, this
difference alone might not explain the observed difference
in execution times. However, the GPU has various caches
which might explain this behaviour. More importantly, we
observed that different patterns can repeat in the second
layer from trace to trace. Whereas the patterns are very
similar in the first layer for all collected traces, the same
does not hold for the second layer. For the second layer,
only about 40% of the collected traces display completely
similar patterns. We tested this behaviour with the other
implementations as well and this issue only comes up when
the same implementation is used for each layer. For exam-
ple, the combination of the relu small and relu interior
implementations for the first and second layers, respectively,
result in uniform patterns for both layers. In contrast, if
the relu small implementation is used for both layers,
then it results in non-uniform patterns for the second layer.
We also tested this behaviour with networks with more
than two convolutional layers, and as soon as the same
implementation is used in two different layers the non-
uniform behaviour is encountered. Regardless, as mentioned
in Section 3.2, we carry out the parameter extraction with
the relu small as the used implementation for each layers.

Since accurate alignment with static alignment [38] 4 is not
possible using all of the traces for the second layer, 60%
of the collected traces are not used in the CEMA attack for
the second layer.

In addition, despite collecting measurements with mini-
mum misalignment, the traces are hard to fully synchronize
as they contain lot of jitter. To combat this problem, we
use elastic alignment [52] in the leakage detection process.
Elastic alignment allows us to align the traces at every time
point, however, it is also a technique that requires tuning
the correct parameters and it is computationally expensive
to do so. Therefore, it is used only to align traces to detect
leaking points but the CEMA attack is carried out on the
raw traces which are aligned using static alignment.

3.6. Leakage detection

Detecting where intermediate values might leak is a
necessary step before applying CEMA. In order to do so,
we apply random vs fixed TVLA [21] and intermediate
correlation to detect PoIs in both layers. We also used
leakage detection process to decide the best location for
the probe in our setup. Furthermore, we performed the
leakage detection on the relu small, relu medium and
relu interior implementations and the analysis presented
in this section applies to all three.

The TensorRT framework supports refitting networks on-
the-fly with different weights but a new CUDA context [2]
has to be created every time the network is refitted with new
weights as per the documentation. Normally, an application
is not required to create a new CUDA context for every
inference operation, but it is required for TVLA as we refit
the weights or the bias for every inference operation.

To the detect PoIs, we applied TVLA 5 times, which
is equal to the kernel size, each time with one weight in
the convolutional kernel being fixed vs random and the
rest of the weights 0. The corresponding first input, with
which the weight is multiplied, is fixed and non-zero while
the rest of the inputs are set to 0. This setup allows us
to detect
leakages corresponding to the partial sums in
the convolutional operation. In this case, the unexploitable
false positives can be loading of the weights. The presented
approach is more desired, i.e. leads to less false positives,
then applying TVLA with random vs fixed inputs as the
same input is loaded at different times, potentially leading
to more false positives.

In addition, to detect leakage corresponding to the bias,
we apply fixed vs. random bias TVLA. Similarly to the ran-
dom vs. fixed weight TVLA, the false positives in this test
can be the loading of the bias. To help filtering these false
positives, we also apply correlation to intermediate values.
However, we also observed several ghost peaks [14, 15]
with the correlation method which cannot be exploited in
the CEMA attack.

4. Static align employs a standard pattern-based approach: we select a
part of a trace as a reference, and compute correlation for each offset
within a chosen range for each of the traces. We then shift each trace by
the respective offset that maximizes the correlation.

Figure 5 shows the results of TVLA for the first weight
in the kernel in the first layer with 45k traces. We repeat
this process for the rest of the weights and the results clearly
show that leakages of the convolution operation are in the
second highlighted part of Figure 7. Figure 6 shows the
results of TVLA for the bias of the kernel in the first layer
with 37k traces. There is a much clearer leakage present for
the bias than for the weights in the convolution operation.
After establishing the PoIs with the help of elastic
alignment, we use static alignment on the raw traces at these
points as static alignment produced higher individual TVLA
peaks as well as correlation for the attack.

After the TVLA and correlations tests, it is possible
to segment the raw traces according the instruction blocks
mentioned in Section 3.2. Figure 7 shows a raw trace where
the first highlighted section corresponds to the initialization
block. The second highlighted block corresponds to the
sum of multiplications in the convolution operation. The
third highlighted segment corresponds to the calculation of
the bias addition and ReLU output, repeated 4 times for
different sets of registers. Note, that these instruction blocks
are also separated by synchronization instructions which are
also visible in the trace as the amplitude of the EM signal
drops close to 0 between the blocks. The same segmentation
applies for the second layer.

3.7. Weight and bias extraction

If an adversary is able to recover a neural network’s
architecture as well as the parameters of a network, then the
adversary completely recovered the model. In this attack,
we show how to extract the weights and the biases of a
CNN with 2 layers using CEMA. Observe that this attack
is general and can be extended to arbitrary number of
convolutional layers with arbitrary dimensions: since the
implementations in Section 3.2 are parallelized on a kernel
and channel level, CEMA also can be parallelized to recover
all
the weights in a layer if an adversary has multiple
machines available.

The input and batch size of our CNN are set to 500 and
1, respectively, while the weights and biases are initialized
randomly. With an input size of 500 and stride of 1, the
number of convolutions executed by a layer is input size−
kernel size + 1. Consequently, the first and second layers
execute 496 and 492 convolutions, respectively. This means
there are lots of convolutional intermediates to target in each
layer to recover the weights and bias of a kernel. However,
our attack only requires knowing just a fraction of the inputs,
and the size of this fraction is equivalent to the kernel size.
Therefore, we only use the first 5 inputs to each layer to
recover the weights and biases in the layers.5

The layers in our example consist of one kernel each
containing 5 unknown weights and 1 unknown bias. The
convolutional layers are followed by ReLU activation. Alto-
gether, 12 unknowns have to be recovered from both layers.

5. However, in order to calculate the first 5 inputs to the second layer,

the first 9 inputs to the first layer has to be known.

(a) Key rank vs number of traces of the first weight
in the first layer with value of -1.22.

(b) Correlation vs number of traces of the first weight
in the first layer with value of -1.22.

(c) Key rank vs number of traces of the fifth weight
in the first layer with value of 0.3564.

(d) Correlation vs number of traces of the fifth weight
in the first layer with value of 0.3564.

Figure 8: Key ranks and correlations of the first and fifth weights in the first layer.

(a) Key rank vs number of traces of the second weight
in the second layer with value of -0.5137.

(b) Correlation vs number of traces of the second
weight in the second layer with value of -0.5137.

(c) Key rank vs number of traces of the third weight
in the second layer with value of -0.6406.

(d) Correlation vs number of traces of the third weight
in the second layer with value of -0.6406.

Figure 9: Key rank and correlation for the third and fourth weights in the kernel in the second layer.

30000

20000

10000

k
n
a
r

y
e
k

0

0

1

2
number of traces

3

4

5

1e6

 
Formally, each layer computes

ReLU (W ∗ M + b) = ReLU (

5
(cid:88)

wi · mi + b),

i=1

for a piece of input where W and M are vectors containing
the kernel weights and layer inputs, respectively, and b is the
bias that is added after the sum of multiplications. In this
case, there are multiple intermediate values that depend on
the secret weights. First, every weight wi is multiplied by
an input mi so the results of the individual multiplications
can be targeted. Second, the results of multiplications are
summed. Afterward, the bias b is added to the accumulated
results. Lastly, the ReLU activation is applied after the bias
addition. All of these intermediate values depend on the
unknown weights or the unknown bias. In the attack, we
have to recover of the parameters of the layers sequentially,
i.e. we have to recover the weights and bias in the first layer
to be able to attack the second layer.

3.7.1. Weight extraction. In this experiment, we target the
intermediate results of the convolution between the weights
and the inputs, as we could observe results with this leakage.
We present results with two different leakage models as us-
ing the HW leakage model on the partial sum intermediates
and the HD between two subsequent intermediate allows us
to extract the weights.

Following Batina et al. [13], we restrict the search space
of the weights to the interval [−5, 5]. With 16-bit floats, there
are 35 330 possible candidates in this range. We use the HW
leakage model on our chosen intermediate value, the partial
sums, to map hypothetical EM consumption values to real
measurements T and calculate the Pearson’s correlation per
sample point between them:

ρ(HW (

i
(cid:88)

j=1

wj · mj), T )

i = 1..5.

We calculate the correlation with each weight candidate,
selecting the candidate that shows the highest correlation.

Figure 8 shows the key rankings and correlations of the
correct weight value vs the number of traces in the first
layer for the first and fifth weights, respectively. As shown
in Figure 8a, at around the 3,2 million mark, the candidate
that ranks first is −1.212 for the first weight, so it is already
a value that is close to the correct candidate. At this mark,
the correct candidate ranks 106th. Overall, the key rank
decreases quickly but in order to get the first rank for the
correct candidate, more than 5 million traces are required.
This might suggest that the exponent of the intermediate
values leak mostly but not the mantissa, and it requires
significantly more traces to get the correct candidate. We
leave analyzing this phenomenon for future work.

Figure 8b shows the correlation of the correct weight
candidate and the incorrect weight candidates vs the number
of traces for the first weight. As expected, it shows a similar
trend to the key rank figure, as the correlation of the correct
candidate gets close to the top at the 3 million traces mark.

However, the correlation of the correct weight candidate
only reaches the maximum after 5 million traces with respect
to the incorrect candidates. Figure 8c shows the ranking of
the correct weight value vs the number of traces in the first
layer for the fifth weight. Similarly to the first weight, the
key rank drops quickly, but it takes a lot more traces to for
the key rank to converge zero. Similarly, Figure 8d shows the
correlation of the weight candidates vs the number of traces
for the fifth weight in the first layer. The correct weight
candidates already approaches key rank 0 at 8 million mark
while needing more traces to fully converge. Every weight in
the kernel leaks similarly and targeting the Hamming weight
of partial sums can recover the correct weight candidate for
all the weight in the kernel. After recovering the weights
and bias of the kernel in the first layer, we can calculate
the inputs to the second layer to recover the weights and
the bias of the kernel in second kernel. Figure 9 shows the
key ranking and correlations of the correct weight value vs
the number of traces in the second layer for the second and
third weights, respectively. Similarly to the weights in the
first layer, the key ranks for both weights drop quickly, but
reaching a key rank of 0 requires 800 000 and 1.2 million
traces for the second and third weights, respectively.

3.7.2. Bias extraction. There are two operations in the
layer that are dependent on the bias value. The first op-
eration is the calculation of the sum of convolution and
the bias W ∗ M + b. The second one is the ReLU out-
put, ReLU (W ∗ M + b). We observed leakage with the
Hamming weight of the sum of convolution and the bias, as
well as with the output of the ReLU activation. Formally,
HW (W ∗ M + b) and HW (ReLU (W ∗ M + b)) both
show correlation with the EM measurements. Therefore, we
calculate the Pearson correlation for every bias candidate
with these leakage models to the real measurements.

Figure 10 shows the key ranking and correlation of
the CEMA attack on the bias in the first layer with the
ReLU (W ∗ M + b) intermediates. The key rank drops
rapidly, but
the convergence to key rank 0 takes more
than 10 million traces. Similarly, Figure 10 shows the key
rankings and correlation of the CEMA attack on the bias in
the second layer with the W ∗ M + b intermediate. The key
rank also drops quickly for the bias in the second layer, but
the convergence to key rank 0 takes more than 10 million
traces. In general, the biases seem to require more traces to
converge to key rank 0 than the weights.

4. Discussion

4.1. Limitations

4.1.1. Parameter extraction. In this work, we demon-
strated the parameter extraction of a NN with two convolu-
tional layers. However, there are multiple aspects that could
impact the CEMA attack:
Kernel size. The kernel size does not impact the CEMA
attack in terms of number of traces needed, but it would

(a) Key rank vs number of traces of the bias in the
first layer with the ReLU intermediate.

(b) Correlation vs number of traces of the bias in the
first layer with the ReLU intermediate.

Figure 10: Key ranks and correlations of the bias with value of 0.856 in the first layer with ReLU intermediate.

(a) Key rank vs number of traces of the bias in the
second layer with the W ∗ M + b intermediate.

(b) Correlation vs number of traces of the bias in the
second layer with the W ∗ M + b intermediate.

Figure 11: Key ranks and correlations of the bias with value of 0.345 in the second layer with W ∗ M + b intermediate.

take more time to recover all the weights, as our attack
targets the partial sums in the convolution where we
recover the weights one-by-one. In other words, the time it
takes to recover all the weights in a kernel scales linearly
with the kernel size.

Batch size. In our experiments, the batch size is set to 1.
However, a larger batch size might not impact the CEMA
attack because the same operations could be carried out
in parallel with different inputs. This means that two or
more intermediate values are calculated at the same time
that depend on the same weight or bias. Therefore, the
CEMA attack would be applied using the combination of
multiple intermediate values.

Concurrent applications. The GPU is able to handle and
schedule concurrently CUDA functions from multiple ap-
plications. This could likely introduce noise in the attacks.
However, this highly depends on the required resources
for each CUDA function. If a CUDA function takes up
most of the GPU resources (e.g. shared memory, registers,
etc.), then a different CUDA function will only be sched-
uled after all the thread blocks in the previous CUDA
function finished execution [3].

4.2. Single-precision implementations

The implementations for a convolutional

layer with
ReLU activation and single-precision calculations are very
similar to half-precision implementations analyzed in this
work. In fact,
the single-precision implementations are
named the following:

maxwell scudnn 128x k relu t nn v1

where

k ∈ {32, 64, 128},

t ∈ {small, medium, large, interior}.

More importantly, the structures of these implementa-
tions are also identical to their half-precision counterparts
with the exception of using single-precision instructions
instead of half-precision instructions. Consequently, our
CEMA attack is also applicable for single-precision im-
plementation. However, targeting 32-bit floats significantly
increases the search space even if it is limited to the [−5, 5]
interval.

4.3. Mitigation

Traditional ways to contain electromagnetic emanation,
such as proper shielding or introducing noise to decrease
the Signal-to-Noise ratio, could alleviate the problem [38].
Specifically against parameter extraction, one of the possible
countermeasures, which is also mentioned in the CSI-NN
paper [13], is shuffling [53] the order of multiplications in
the layers, which can make it significantly harder for an
adversary to recover the weights. Additionally, masking [18,
42], also mentioned in the CSI-NN paper, would provide
a way to break the relationship between the side-channel
measurements and the processed data. However, this comes
at the price of execution speed, which might not be desired
in real-time systems.

4.4. Comparison with related work

To the best of our knowledge, no previous work has been
able to extract the parameters of neural networks on GPU
using physical side-channel.

NWA.1215.18.014, which is (partly) financed by the Nether-
lands Organisation for Scientific Research (NWO). More-
over, Łukasz Chmielewski was partially supported by Ai-
SecTools (VJ02010010) project.

Author

Platform

Side channel

References

BarraCUDA (this work)
Batina, et al. (2019) [13]
Dubet, et al. (2020) [19]
Yoshida, et al. (2020) [57]
Regazzoni, et al. (2020) [46]
Yli-M¨ayry, et al. (2021) [55]
Li, et al. (2022) [33]
Joud, et al. (2022) [26]
Gongye et al. (2023) [22]

GPU
microcontroller
FPGA
FPGA
FPGA
FPGA
FPGA
microcontroller
FPGA

EM
EM
Power
Power
EM
EM
Power
EM
EM

TABLE 1: Comparison with related work.

Previous works have demonstrated parameter extraction
on microcontrollers and FPGAs using power or EM side
channel as shown in Table 1, but not on GPUs. In addition,
these attacks were performed on neural networks with binary
parameters [19, 46, 56], 8-bit parameters [13, 22, 32, 57] or
32-bit parameters [13, 26]. In our work, we demonstrate pa-
rameter extraction on 16-bit parameters with discussion on
extending it to 32-bit parameters. Additionally, the approach
presented in this work is scalable because it does not rely
on chosen inputs as in [22]. Chosen inputs are not scalable
to large neural networks as crafting chosen inputs becomes
harder the deeper the target NN is.

5. Conclusions

In this work, we analyze the NVIDIA Jetson Nano GPU,
a commonly chosen platform for real-world neural network
implementations, for resilience against side-channel attacks
that aim to extract the weights of the target NN. First, we
establish where the GPU leaks information about the param-
eters of the target DNN. Subsequently, we demonstrate the
extraction of weights and biases of a CNN consisting of two
convolutional layers using CEMA. Overall, the neural net-
work implementations of NVIDIA’s TensorRT framework
are vulnerable to parameter extraction using electromagnetic
side-channel attack despite the networks running in a highly
parallel and noisy environment. It remains an open problem
to protect
their implementations in security or privacy-
sensitive applications.

Acknowledgments

This work was supported by an ARC Discovery Early
Career Researcher Award DE200101577; an ARC Dis-
covery Project number DP210102670; and the Deutsche
Forschungsgemeinschaft (DFG, German Research Founda-
tion) under Germany’s Excellence Strategy - EXC 2092
CASA - 390781972. Additionally,
this work received
funding in the framework of
the NWA Cybersecurity
Call with project name PROACT with project number

[1]

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

compute

context,”

capabilities,”

https://docs.nvidia.

programming model,”

https://docs.nvidia.com/cuda/cuda-

https://docs.nvidia.com/cuda/cuda-
accessed:

“Cuda
com/cuda/cuda-c-programming-guide/index.html#
compute-capabilities, accessed: 2022-09-30.
“Cuda
c-programming-guide/index.html#context,
2022-09-30.
https://developer.download.nvidia.com/CUDA/
training/StreamsAndConcurrencyWebinar.pdf,
accessed: 2022-11-30.
“cuobjdump,”
binary-utilities/#usage, accessed: 2022-09-30.
“Cuda
com/cuda/cuda-c-programming-guide/index.html#
programming-model, accessed: 2022-09-30.
“Cuda half2 data type,” https://docs.nvidia.com/cuda/
cuda-math-api/struct
accessed: 2022-09-30.
https://www.langer-emv.de/en/product/mfa-active-
1mhz-up-to-6-ghz/32/mfa-r-0-2-75-near-field-micro-
probe-1-mhz-up-to-1-ghz/854, accessed: 2022-01-25.
“Tensorrt model inspection,” https://docs.nvidia.com/
deeplearning/tensorrt/archives/tensorrt-821/api/c api/
classnvinfer1 1 1 i engine inspector.html, accessed:
2022-09-30.
“Nvidia jetson nano,” https://developer.nvidia.com/
embedded/jetson-nano-developer-kit, accessed: 2022-
09-30.

https://docs.nvidia.

half2.html#struct

half2,

[10] “Nvidia

tensorrt,”

https://developer.nvidia.com/

[11] “Tegra

tensorrt, accessed: 2022-09-30.
system-on-chip,”

http://international.
download.nvidia.com/pdf/tegra/Tegra-X1-whitepaper-
v1.0.pdf, accessed: 2022-09-30.

x1

[12] M. Abadi, A. Agarwal, P. Barham, E. Brevdo,
Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean,
M. Devin, S. Ghemawat, I. Goodfellow, A. Harp,
G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser,
M. Kudlur, J. Levenberg, D. Man´e, R. Monga,
S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens,
B. Steiner,
I. Sutskever, K. Talwar, P. Tucker,
V. Vanhoucke, V. Vasudevan, F. Vi´egas, O. Vinyals,
P. Warden, M. Wattenberg, M. Wicke, Y. Yu,
and X. Zheng, “TensorFlow: Large-scale machine
learning on heterogeneous systems,” 2015, software
available from tensorflow.org.
[Online]. Available:
https://www.tensorflow.org/

[13] L. Batina, S. Bhasin, D. Jap, and S. Picek, “CSI–
NN: Reverse engineering of neural network architec-
tures through electromagnetic side channel,” in 28th
USENIX Security Symposium USENIX Security 19),
2019, pp. 515–532.

[14] E. Brier, C. Clavier, and F. Olivier, “Correlation power
analysis with a leakage model,” in International work-
shop on cryptographic hardware and embedded sys-
tems. Springer, 2004, pp. 16–29.

[15] C. Canovas and J. Cl´edi`ere, “What do s-boxes say in
differential side channel attacks?” Cryptology ePrint
Archive, 2005.

[16] Ł. Chmielewski and L. Weissbart, “On reverse en-
gineering neural network implementation on GPU,”
in International Conference on Applied Cryptography
and Network Security. Springer, 2021, pp. 96–113.

[17] F. Chollet, “Xception: Deep learning with depthwise
separable convolutions,” in Proceedings of the IEEE
conference on computer vision and pattern recognition,
2017, pp. 1251–1258.

[18] J.-S. Coron and L. Goubin, “On boolean and arithmetic
masking against differential power analysis,” in Cryp-
tographic Hardware and Embedded Systems—CHES
2000: Second International Workshop Worcester, MA,
USA, August 17–18, 2000 Proceedings 2.
Springer,
2000, pp. 231–237.

[19] A. Dubey, R. Cammarota, and A. Aysu, “Maskednet:
The first hardware inference engine aiming power side-
channel protection,” in IEEE International Symposium
on Hardware Oriented Security and Trust, 2020, pp.
197–208.

[20] F. Elibol, U. Sarac, and I. Erer, “Realistic eavesdrop-
ping attacks on computer displays with low-cost and
mobile receiver system,” in 2012 Proceedings of the
20th European Signal Processing Conference (EU-
SIPCO).

IEEE, 2012, pp. 1767–1771.
[21] B. J. Gilbert Goodwill, J. Jaffe, P. Rohatgi et al., “A
testing methodology for side-channel resistance vali-
dation,” in NIST non-invasive attack testing workshop,
vol. 7, 2011, pp. 115–136.

[22] C. Gongye, Y. Luo, X. Xu, and Y. Fei, “Side-channel-
assisted reverse-engineering of encrypted dnn hard-
ware accelerator ip and attack surface exploration,” in
IEEE Symposium on Security and Privacy, 2024.
[23] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual
learning for image recognition,” in Proceedings of
the IEEE conference on computer vision and pattern
recognition, 2016, pp. 770–778.

[24] Z. Hongxin, H. Yuewang, W. Jianxin, L. Yinghua,
and Z. Jinling, “Recognition of electro-magnetic leak-
age information from computer radiation with SVM,”
Computers & Security, vol. 28, no. 1-2, pp. 72–76,
2009.

[25] A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko,
W. Wang, T. Weyand, M. Andreetto, and H. Adam,
“Mobilenets: Efficient convolutional neural networks
for mobile vision applications,” arXiv preprint
arXiv:1704.04861, 2017.

[26] R. Joud, P.-A. Mo¨ellic, S. Ponti´e, and J.-B. Rigaud,
introduction to side-channel extraction
“A practical
of deep neural network parameters,” in International
Conference on Smart Card Research and Advanced
Applications. Springer, 2022, pp. 45–65.

[27] P. Kocher, J. Jaffe, and B. Jun, “Differential power
analysis,” in Annual international cryptology confer-
ence. Springer, 1999, pp. 388–397.

[28] P. C. Kocher, “Timing attacks on implementations of
Diffie-Hellman, RSA, DSS, and other systems,” in An-
nual International Cryptology Conference. Springer,
1996, pp. 104–113.

[29] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Im-
agenet classification with deep convolutional neural
networks,” Advances in neural information processing
systems, vol. 25, pp. 1097–1105, 2012.

[30] M. G. Kuhn and R. J. Anderson, “Soft tempest: Hid-
den data transmission using electromagnetic emana-
tions,” in International Workshop on Information Hid-
ing. Springer, 1998, pp. 124–142.

[31] N. Laptev, J. Yosinski, L. E. Li, and S. Smyl, “Time-
series extreme event forecasting with neural networks
at uber,” in International conference on machine learn-
ing, vol. 34.

sn, 2017, pp. 1–5.
[32] G. Li, M. Tiwari, and M. Orshansky, “Power-
based attacks on spatial DNN accelerators,” ACM
J. Emerg. Technol. Comput. Syst., vol. 18, no. 3,
pp. 58:1–58:18, 2022.
[Online]. Available: https:
//doi.org/10.1145/3491219

[33] ——, “Power-based attacks on spatial dnn acceler-
ators,” ACM Journal on Emerging Technologies in
Computing Systems, vol. 18, no. 3, pp. 1–18, 2022.

[34] M. Lin, Q. Chen, and S. Yan, “Network in network,”

arXiv preprint arXiv:1312.4400, 2013.

[35] L. Liu, W. Ouyang, X. Wang, P. Fieguth, J. Chen,
X. Liu, and M. Pietik¨ainen, “Deep learning for generic
object detection: A survey,” International journal of
computer vision, vol. 128, no. 2, pp. 261–318, 2020.
[36] Z. Liu, N. Samwel, L. Weissbart, Z. Zhao, D. Lauret,
L. Batina, and M. Larson, “Screen gleaning: A screen
reading tempest attack on mobile devices exploit-
ing an electromagnetic side channel,” arXiv preprint
arXiv:2011.09877, 2020.

[37] H. T. Maia, C. Xiao, D. Li, E. Grinspun, and C. Zheng,
“Can one hear
the shape of a neural network?:
Snooping the GPU via magnetic side channel,” in 31st
USENIX Security Symposium, USENIX Security 2022,
Boston, MA, USA, August 10-12, 2022, K. R. B. Butler
and K. Thomas, Eds. USENIX Association, 2022, pp.
4383–4400. [Online]. Available: https://www.usenix.
org/conference/usenixsecurity22/presentation/maia
[38] S. Mangard, E. Oswald, and T. Popp, Power analysis
attacks: Revealing the secrets of smart cards. Springer
Science & Business Media, 2008, vol. 31.

[39] A. Moradi, B. Richter, T. Schneider, and F.-X. Stan-
daert, “Leakage detection with the x2-test,” IACR
Transactions on Cryptographic Hardware and Embed-
ded Systems, pp. 209–237, 2018.

[40] D. W. Otter, J. R. Medina, and J. K. Kalita, “A survey
of the usages of deep learning for natural language
processing,” IEEE transactions on neural networks and
learning systems, vol. 32, no. 2, pp. 604–624, 2020.

[41] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury,

Cryptographers’ Track at the RSA Conference 2011,
San Francisco, CA, USA, February 14-18, 2011. Pro-
ceedings. Springer, 2011, pp. 104–119.

[53] N. Veyrat-Charvillon, M. Medwed, S. Kerckhof, and
F.-X. Standaert, “Shuffling against side-channel at-
tacks: A comprehensive study with cautionary note,” in
Advances in Cryptology–ASIACRYPT 2012: 18th Inter-
national Conference on the Theory and Application of
Cryptology and Information Security, Beijing, China,
December 2-6, 2012. Proceedings 18. Springer, 2012,
pp. 740–757.

[54] M. Yan, C. W. Fletcher, and J. Torrellas, “Cache telepa-
thy: Leveraging shared resource attacks to learn DNN
architectures,” in USENIX Security, 2020, pp. 2003–
2020.

of

Jap,

binarized

“Extraction

[55] V. Yli-M¨ayry, A.

Ito, N. Homma, S. Bhasin,
and D.
neural
network architecture and secret parameters using
information,” in IEEE International
side-channel
Symposium on Circuits
ISCAS
2021, Daegu, South Korea, May 22-28, 2021.
IEEE,
[Online]. Available:
1–5.
https://doi.org/10.1109/ISCAS51556.2021.9401626
[56] V. Yli-M¨ayry, A. Ito, N. Homma, S. Bhasin, and
D. Jap, “Extraction of binarized neural network archi-
tecture and secret parameters using side-channel infor-
mation,” in IEEE International Symposium on Circuits
and Systems (ISCAS), 2021, pp. 1–5.

Systems,

2021,

and

pp.

[57] K. Yoshida, T. Kubota, S. Okura, M. Shiozaki, and
T. Fujino, “Model reverse-engineering attack using
correlation power analysis against systolic array based
neural network accelerator,” in IEEE International
Symposium on Circuits and Systems (ISCAS), 2020,
pp. 1–5.

G. Chanan, T. Killeen, Z. Lin, N. Gimelshein,
L. Antiga, A. Desmaison, A. Kopf, E. Yang,
Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy,
B. Steiner, L. Fang,
J. Bai, and S. Chintala,
“Pytorch: An imperative style, high-performance deep
learning library,” in Advances in Neural Information
Processing Systems 32. Curran Associates,
Inc.,
2019, pp. 8024–8035.
[Online]. Available: http:
//papers.neurips.cc/paper/9015-pytorch-an-imperative-
style-high-performance-deep-learning-library.pdf
[42] E. Prouff and M. Rivain, “Masking against side-
channel attacks: A formal security proof,” in Advances
in Cryptology–EUROCRYPT 2013: 32nd Annual Inter-
national Conference on the Theory and Applications of
Cryptographic Techniques, Athens, Greece, May 26-30,
2013. Proceedings 32. Springer, 2013, pp. 142–159.
[43] H. Purwins, B. Li, T. Virtanen, J. Schl¨uter, S.-Y. Chang,
and T. Sainath, “Deep learning for audio signal pro-
cessing,” IEEE Journal of Selected Topics in Signal
Processing, vol. 13, no. 2, pp. 206–219, 2019.
[44] J.-J. Quisquater and D. Samyde, “ElectroMagnetic
Analysis (EMA): Measures and Counter-Measures for
Smard Cards,” in Smart Card Programming and Se-
curity (E-smart 2001), ser. Lecture Notes in Computer
Science, I. Attali and T. P. Jensen, Eds., vol. 2140.
Springer-Verlag, 2001, pp. 200–210.

[45] S. S. Rangapuram, M. W. Seeger,

J. Gasthaus,
L. Stella, Y. Wang, and T. Januschowski, “Deep state
space models for time series forecasting,” Advances in
neural information processing systems, vol. 31, 2018.
[46] F. Regazzoni, S. Bhasin, A. A. Pour, I. Alshaer, F. Ay-
din, A. Aysu, V. Beroulle, G. Di Natale, P. Franzon,
D. Hely et al., “Machine learning and hardware se-
curity: Challenges and opportunities,” in International
Conference on Computer-Aided Design, 2020, pp. 1–6.
[47] A. Sagheer and M. Kotb, “Time series forecasting of
petroleum production using deep lstm recurrent net-
works,” Neurocomputing, vol. 323, pp. 203–213, 2019.
and
T. Januschowski, “Deepar: Probabilistic forecasting
with autoregressive recurrent networks,” International
Journal of Forecasting, vol. 36, no. 3, pp. 1181–1191,
2020.

J. Gasthaus,

Salinas, V.

Flunkert,

[48] D.

[49] T. Schneider and A. Moradi, “Leakage assessment
methodology,” in International Workshop on Crypto-
graphic Hardware and Embedded Systems. Springer,
2015, pp. 495–513.

[50] D. Silver, T. Hubert, J. Schrittwieser, I. Antonoglou,
M. Lai, A. Guez, M. Lanctot, L. Sifre, D. Kumaran,
T. Graepel et al., “Mastering chess and shogi by self-
play with a general reinforcement learning algorithm,”
arXiv preprint arXiv:1712.01815, 2017.

[51] K. Simonyan and A. Zisserman, “Very deep convo-
lutional networks for large-scale image recognition,”
arXiv preprint arXiv:1409.1556, 2014.

[52] J. G. van Woudenberg, M. F. Witteman, and B. Bakker,
“Improving differential power analysis by elastic align-
ment,” in Topics in Cryptology–CT-RSA 2011: The

","3 2 0 2 c e D 2 1 ] R C . s c [ 1 v 3 8 7 7 0 . 2 1 3 2 : v i X r a BarraCUDA : Bringing Electromagnetic Side Channel Into Play to Steal the Weights of Neural Networks from NVIDIA GPUs P´eter Horv´ath∗ , Łukasz Chmielewski† , Leo Weissbart∗ , Lejla Batina∗ , Yuval Yarom‡ ∗Radboud University †Masaryk University ‡Ruhr University Bochum Abstract—Over the last decade , applications of neural networks have spread to cover all aspects of life . A large number of companies base their businesses on building products that use neural networks for tasks such as face recognition , machine translation , and autonomous cars . They are being used in safety and security-critical applications like high definition maps and medical wristbands , or in globally used products like Google Translate and ChatGPT . Much of the intellectual property underpinning these products is encoded in the exact configuration of the neural networks . Consequently , protecting these is of utmost priority to businesses . At the same time , many of these products need to operate under a strong threat model , in which the adversary has unfettered physical control of the product . Past work has demonstrated that with physical access , attackers can reverse engineer neural networks that run on scalar microcontrollers , like ARM Cortex M3 . However , for performance reasons , neural networks are often implemented on highly-parallel general purpose graphics processing units ( GPGPUs ) , and so far , attacks on these have only recovered course-grained information on the structure of the neural network , but failed to retrieve the detailed weights and biases . In this work , we present BarraCUDA , a novel attack on GPGPUs that can completely extract the parameters of neural networks . BarraCUDA uses correlation electromagnetic analysis to recover the weights and biases in the convolutional layers of neural networks . We use BarraCUDA to attack the popular NVIDIA Jetson Nano device , demonstrating successful reverse engineering of neural networks in a highly parallel and noisy environment . 1 . Introduction The field of machine learning has seen an explosive in- crease in interest and use over the last decade . In particular , deep learning has proven to be a versatile technique that provides state-of-the-art performance for many real-world application . The use of deep learning proved useful for a broad range of domains including playing chess [ 50 ] , object detection [ 35 ] , image classification [ 17 , 23 , 29 , 34 , 51 ] , audio processing [ 43 ] , forecasting [ 31 , 45 , 47 , 48 ] and natural language processing [ 40 ] . Thus , applications of deep learning are changing many areas of our lives and have become indispensable to our everyday life . Deep learning typically utilizes artificial neural net- works , consisting of multiple layers of ( simulated ) neu- rons . In a nutshell , a neuron takes a number of inputs and computes a non-linear function of the weighted sum of the inputs . A common example of such a function is a rectified linear unit ( ReLU ) , which basically returns its input if it is positive and zero otherwise . When designing a deep learning solution for a problem , the designer first chooses the network architecture , which specifies the layers of neurons , including their sizes and types , as well as how the neurons are connected , i.e . which neurons outputs are connected to which inputs . The designer then trains the network , selecting the weights used for each weighted sum as well as bias values that are added to the sums before the computation of the non-linear function . Training a network for any non-trivial example is a resource intensive process . There is a need to curate a specialized dataset of correctly labeled samples that can be used for the training , and the training process often requires days and even weeks of computation on specialized high- performance hardware , such as large quantities of graphical processing units ( GPUs ) . Moreover , the design of the right network architecture for a given purpose requires special- ized expertise . Consequently , the design and parameters of trained models are in many cases considered as trade secrets , which vendors try to protect against undesired disclosure . Side-channel attacks , which exploit information leakage via unintended effects of performing computation , are a major threat to the confidentiality of deep learning de- signs . Such attacks against neural network implementa- tions on CPUs have been demonstrated using both power analysis [ 13 ] and microarchitectural attacks [ 54 ] , among others . However , to achieve a better performance neural networks are often implemented on GPUs . So far , attacks on such implementations only recover the network architecture , but not the parameters [ 16 , 37 ] . Moreover , these attacks only target open-source neural networks , implemented using PyTorch [ 41 ] and TensorFlow [ 12 ] , while we target the commonly used NVIDIA closed-source TensorRT frame- work [ 10 ] . Therefore , this work focuses on the following research questions : Are implementations of neural networks on GPU vulnerable to parameter extraction using side-channel analysis ? Our Contribution In this work we answer the question in the affirmative . We analyze NVIDIA ’ s closed-source neural network frame- work TensorRT [ 10 ] executing on an industrial-strength Jetson Nano device [ 9 ] . While TensorRT is a closed-source framework , the produced CUDA binaries can be disassem- bled . We demonstrate a side-channel attack that monitors the electromagnetic ( EM ) emanations emitted from the device . The attack allows full extraction of the parameters of the neural network running on the device , overcoming the measurement noise and the uncertainty inherent in closed platforms . The attack uses correlation electromagnetic analysis ( CEMA ) to recover the weights and biases of neural net- works . For the attack , we collect and process 15 million traces over a period of 10 days . We then show how to analyze the traces to recover weights and biases used in the target network . The results of attack demonstrate that GPU implementa- tions of deep learning are not protected against side-channel attacks , even when the source code is not available . Disclosure . We notified NVIDIA of the found vulnera- bilities on September 22nd , 2023 . We shortly received a response on 24/09/2023 that they are looking into our find- ings and as a result of mutual agreement the findings would be not released until December 13rd , 2023 . On November 22nd , 2023 NVIDIA notified us that they reviewed our disclosure and classified the vulnerabilities as a low severity issue while also recommending the users to follow guide- lines to prevent physical access to secure systems to avoid information leakage . Organization . The rest of this paper is organized as follows : After providing the necessary background on side- channel attacks and GPU architecture ( Section 2 ) , we de- scribe our weight extraction attack . in Section 3 . Finally , Section 4 covers the limitations , possible extensions , coun- termeasures , and related work . 2 . Background Here we introduce the concepts of side channels and related techniques that were used for the attacks and provide background on NVIDIA ’ S CUDA programming model and GPU architecture . 2.1 . Side-Channel Analysis 28 ] . Leakage can occur through various channels , includ- ing power consumption , electromagnetic , timing , optical or sound , and various types of secret information can leak . In academic settings , side-channel attacks were first in- troduced in the 90 ’ s targeting constrained cryptographic devices [ 27 , 28 ] and pose ever since a constant threat to the security of various embedded systems . In this work , we exploit the EM side channel . 2.1.1 . Electromagnetic emanation . The electromagnetic ( EM ) emanations from a computing device correlate with the code and the data that the device processes . This cor- relation has been used to break cryptographic implementa- tions [ 30 , 44 ] , reverse engineer neural networks [ 13 , 16 ] and eavesdrop on display units [ 20 , 24 , 36 ] . In Simple EM Analysis ( SEMA ) , the attacker samples the emitted signal during the execution of the target pro- gram , creating a trace of measurements . The attacker then analyzes the trace to identify components that correspond to the secret information . In Correlation EM Analysis ( CEMA ) , the attacker builds a model of the leakage based on the data the program processes . The attacker then executes the program multi- ple times with different inputs , and looks for correlation between the predicted leakage based on the model and the observed leakage at some points of interest ( POIs ) in the collected traces . Two common models are the Hamming weight ( HW ) model , which predicts that the leakage is linear with the number of set bits in the data ( i.e . its Hamming weight ) , and the Hamming distance ( HD ) model , which predicts that the leakage is linear with the number of bits that need to be changed between consecutive data values . 2.1.2 . Leakage evaluation . Multiple methods have been proposed to evaluate the leakage of embedded devices , such as intermediate correlation , Test Vector Leakage Assessment ( TVLA ) [ 49 ] and χ2-test [ 39 ] . In this paper , we use inter- mediate correlation and TVLA to place our EM probe at a location that leaks the most information and detect where each intermediate value leaks in the collected measurements in the parameter extraction attack presented in Section 3 . 2.2 . CUDA programming model To leverage the parallelism offered by GPUs , NVIDIA exposes the CUDA programming model [ 5 ] to developers . In this model , multiple abstraction levels exist and each level has different implications with respect to the GPU hardware . The lowest level of abstraction is the thread , which executes a CUDA function defined by the developer . The number of threads executing the CUDA function in parallel is specified at the time of invoking the function.1 Subsequently , multiple threads can be grouped together into a single block of threads . Threads in a block have a per block on-chip shared memory region where they can Side-Channel Analysis ( SCA ) exploits the physical leak- ages of electronic devices to extract secret information [ 27 , 1 . Functions in CUDA are also called kernels . We use the term function to avoid confusion with kernels in CNNs . the same shared memory on the chip . More importantly for side-channel attacks , each PU also has a dedicated register file . Since the details of assigning individual warps to PUs are not publicly disclosed information , multiple register files could mean that a CPA/CEMA attack is significantly hin- dered . If a particular warp , one that calculates our targeted intermediate variable , is assigned to different PUs in sub- sequent executions , then our targeted intermediate variable is saved into multiple , different register files which poten- tially results in different power/EM signatures . Therefore , mounting side-channel attacks that rely on the HD leakage model might become difficult on the GPU , but we present a successful attack using the HW as well as the HD leakage model . 3 . Weight and bias extraction attack In this section , we detail our attack which recovers the weights and biases of a CNN with 2 convolutional layers , each containing one kernel . First , we describe the threat model and explore the NN implementations from NVIDIA on the assembly level . Second , we describe our experiment setup and the process of establishing points of interest ( PoI ) where the implementations leak information . Lastly , we apply CEMA on intermediate values in the convolution operation to extract the weights and bias of each layer . To the best of our knowledge , this is the first time that the weights and biases of NNs are extracted from imple- mentations running on an NVIDIA GPU . In addition , the experiments are carried out using half-precision calculations in the convolutional layers . Figure 1 : CUDA programming interface and GPU hardware implementation . Figure 2 : GPU Streaming Multiprocessor architecture . exchange data with other threads in the block . Blocks of threads form a grid of thread blocks . Each block in a grid executes independently from the other blocks , but all blocks in the grid share the same off-chip global memory region . 2.3 . GPU Streaming Multiprocessor 3.1 . Threat model When a CUDA function is invoked , the parallel threads execute on the Streaming Multiprocessor ( SM ) of the GPU . A GPU can consist of one or more SMs to further improve parallelism . Our target , the Jetson Nano , features a Tegra X1 System-On-Chip that consists of one SM of the Maxwell architecture [ 11 ] and CUDA Compute Capability 5.3 [ 1 ] from NVIDIA . As illustrated in Figure 1 , when blocks of threads are scheduled onto a particular SM , the threads in the blocks are divided into groups of 32 threads , also called warps . Warp is the lowest level of execution unit and is of great concern for SCA . Every warp is assigned to a particular Processing Unit ( PU ) where every PU has dedicated resources to schedule and execute warps in the SM . Figure 2 shows the building blocks of the Maxwell SM and the PUs in the SM.2 The warp scheduler in a PU is responsible for scheduling and issuing instructions for warps that are ready . Every PU has a set of 32 CUDA cores for arithmetic instructions as well as load/store units ( LD/ST ) and special function units ( SPU ) for memory operations and transcendental functions , respectively . In addition , a pair of PUs share a texture/L1 cache but all PUs have access to 2 . Graphics related components , such as the PolyMorph engine , are omitted in our figure as these are not relevant for our target application . In this scenario , we consider an adversary who has access to the target device , can observe random inputs fed to the device , and knows the architecture of the NN that runs on the device . In addition , we also assume that the adversary can collect electromagnetic side-channel measurements . We assume that the architecture of the target NN is already extracted as the architecture of a NN needs to be known for the NN parameters to be extracted using CEMA . 3.2 . Exploring TensorRT implementations The approach of NVIDIA ’ s TensorRT framework is “ one size fits many ” , that is , one implementation can be used for layers with different kernel sizes , input sizes , batch sizes etc . TensorRT provides information [ 8 ] about the optimized model and this information includes the names of the CUDA function implementations that are used for the model as well as a hexadecimal undocumented value called Tacticvalue.3 Using this information , it is possible to extract the assembly device code that is executed by each thread on the GPU . One 3 . While there is no documentation about Tacticvalue , it might impact the implementation ’ s execution since it might be used in predicated in- structions . CUDA programming level GPU hardware level Grid of thread blocks Warp 1 Streaming Multiprocessor PU 1 PU 2 PU 3 PU 4 Warp 2 Warp n Maxwell Streaming Multiprocessor Instruction cache PU Instruction buffer Warp scheduler Dispatch units Register file Cores LD/ST SPU PU 1 PU 2 Texture / L1 cache PU 3 PU 4 Texture / L1 cache Shared memory can use cuobjdump [ 4 ] from the CUDA toolkit to extract all the GPU assembly code that can be found in the different CUDA shared library files ( CuBLAS , CuDNN , TensorRT ) . Eventually , we found the CUDA function corresponding to the implementation of a convolutional layer with ReLU activation in the libnvinfer.so file by the name that can be retrieved using the TensorRT API . In our parameter extraction attack , we reverse engineer the weights of a NN with two convolutional layers each with a kernel containing 5 weights . In the shared library files , 4 implementations can be found for a convolutional layer with half-precision calculations and ReLU activation , named : maxwell f p16x2 hcudnn f p16x2 128x k relu t nn v1 , where k ∈ { 32 , 64 , 128 } , t ∈ { small , medium , large , interior } . Based on repeated testing , the small , medium and interior implementations can all be an implementation that the Ten- sorRT API chooses for each convolutional layer in our 2- layer model configuration . This is possible if the timing differences are small in the implementations . Thus , it could be that the same implementation is used for both layers or a combination of two . Furthermore , based on testing and using the information provided by the API [ 8 ] , these are also the implementations that are chosen by the API for the large-scale neural net- works such as MobileNet [ 25 ] . The names of implementations also include f p16x2 which refers to the half2 [ 6 ] data type in CUDA . When half2 is used , a register is packed with 2 half-precision floating point values and the GPU can execute a floating point instruction on each half in parallel , doubling the throughput of the GPU , as opposed to using single-precision floating point values . This also means additional noise for SCA in addition to the parallel threads executing in the GPU . 3.3 . Convolutional layer structure Although there are 4 possible implementations for a convolutional layer with ReLU activation , these implemen- tations are very similar in their structure and they consist of the following blocks : 1. block of initialization instructions , 2. block of convolution operations , and 3. block of bias addition and ReLU calculation . 1 . Init block . The first main block consists of instructions to set up the CUDA function . In this block , 64 accumulator registers are initialized which are later used to calculate the sum of multiplications in the convolution operation . 2 . Convolutional block . The second block is where the convolution operations are carried out . This block consists of vectorized load and HFMA2 instructions . In addition , it contains predicated load instructions from global memory . Since registers are packed with two 16-bit floating point Figure 3 : Location of the Langer EM probe . The probe tip is located between two capacitors . values , it is also crucial to know exactly how the input data is loaded into the registers . If this information is available , it sheds light on how the convolution operation is carried out in the implementations . According to the API , the input is reformatted so that it is laid out in “ Two wide channel vectorized row major FP16 format ” . This means that each register holding inputs is loaded with two half-precision floating point inputs from two different input channels . Therefore , this also suggests that each register holds weights from different channels in a kernel . In the case of our one dimensional convolution , we set the number of input channels to 1 , as it is common for one-dimensional convolutional use cases . In other cases , such as RGB image inputs , the number of input channels would be 3 so each register would hold input values from two different input channels . With multiple input channels processed in parallel , our CEMA attack would then not require more time to get all the weights because the channels in the kernels are independent from each other . Additionally , the code in the second block indicates that each accumulator register is used in 8 HFMA2 instruction in this block , unless a predicated jump instruction is executed at the end of the code block which jumps back to the start of this block . This suggests that the execution of the jump instruction likely depends on the kernel size in the layer . 3 . ReLU block . The third block , repeated four times , first calculates the sum of the lower and higher half of each register . This suggests that the channel combinations of the convolutional operation , after the sum of multiplications , are executed in these blocks . Then , half2 floating point additions and HSET instructions are executed in the block suggesting the calculation of the bias addition and the ReLU output . Overall , the four implementations are very similar . For our particular two-layer model configuration , more than 50 % of the times the chosen implementation by the API is the relu small implementation for both layers , so we choose to carry out the parameter extraction attack with this imple- mentation . However , we also analyzed the relu medium and relu interior implementations in our leakage detection process in Section 3.6 . Figure 4 : Raw trace of the whole operation on the GPU . The 2 layers are clearly separated in the traces . Additionally , the CUDA device-to-host memory copy is also clearly visisble in the end of the trace . Figure 5 : Result of TVLA for the multiplication with the first weight in the kernel in convolutional block . The top figure depicts an elastically aligned trace while the bottom figure shows the corresponding absolute t-test statistics at each time sample . There are multiple leaking spots with |t| > 4.5 but the overall leakage is not high . Figure 6 : Result of fixed vs random bias TVLA . The top figure depicts an example trace while the bottom figure shows the corresponding absolute t-test statistics at each time sample . There is clear leakage scattered across multiple clock cycles with |t| > > 4.5 . 3.4 . Experiment setup In our setup , the Jetson Nano ’ s GPU cores operate at the highest possible clock frequency at 921 MHz . In order to collect electromagnetic traces , we use the Lecroy 8404M- MS oscilloscope at a sampling rate of 10GS/s with the Figure 7 : Segmented raw trace of first layer . The first highlighted block contains the initialization instructions . The second highlighted block is where the convolution operation is carried out . The third highlighted block corresponds to the bias addition and ReLU activation calculation . leak information about Langer MFA-R 0.275 near-field probe [ 7 ] . Each trace con- tains measurements of the electromagnetic emanations of the GPU when the target neural network executes inference on random inputs . By scanning the Tegra SoC and the nearby capacitors with the EM probe , we found multiple interesting locations that the parameters of neural network . Eventually , we observed the best signal between two capacitors , as shown in Figure 3 . In terms of leakage magnitude using TVLA , locations above the chip and between the capacitors are very similar . However , the emitted signal between the capacitors provides less noisier traces which makes trace acquisition and alignment easier . To trigger the oscilloscope to collect measurements when the inference of the NN starts , we use the rising edge of inference signal as trigger . 3.5 . Trace preprocessing Figure 4 shows an example trace of the inference oper- ation of a CNN with two layers . The two layers are clearly separated and display similar patterns . However , the first layer takes considerably more time to execute . Since the input sizes of the layers are 500 and 496 , respectively , this difference alone might not explain the observed difference in execution times . However , the GPU has various caches which might explain this behaviour . More importantly , we observed that different patterns can repeat in the second layer from trace to trace . Whereas the patterns are very similar in the first layer for all collected traces , the same does not hold for the second layer . For the second layer , only about 40 % of the collected traces display completely similar patterns . We tested this behaviour with the other implementations as well and this issue only comes up when the same implementation is used for each layer . For exam- ple , the combination of the relu small and relu interior implementations for the first and second layers , respectively , result in uniform patterns for both layers . In contrast , if the relu small implementation is used for both layers , then it results in non-uniform patterns for the second layer . We also tested this behaviour with networks with more than two convolutional layers , and as soon as the same implementation is used in two different layers the non- uniform behaviour is encountered . Regardless , as mentioned in Section 3.2 , we carry out the parameter extraction with the relu small as the used implementation for each layers . Since accurate alignment with static alignment [ 38 ] 4 is not possible using all of the traces for the second layer , 60 % of the collected traces are not used in the CEMA attack for the second layer . In addition , despite collecting measurements with mini- mum misalignment , the traces are hard to fully synchronize as they contain lot of jitter . To combat this problem , we use elastic alignment [ 52 ] in the leakage detection process . Elastic alignment allows us to align the traces at every time point , however , it is also a technique that requires tuning the correct parameters and it is computationally expensive to do so . Therefore , it is used only to align traces to detect leaking points but the CEMA attack is carried out on the raw traces which are aligned using static alignment . 3.6 . Leakage detection Detecting where intermediate values might leak is a necessary step before applying CEMA . In order to do so , we apply random vs fixed TVLA [ 21 ] and intermediate correlation to detect PoIs in both layers . We also used leakage detection process to decide the best location for the probe in our setup . Furthermore , we performed the leakage detection on the relu small , relu medium and relu interior implementations and the analysis presented in this section applies to all three . The TensorRT framework supports refitting networks on- the-fly with different weights but a new CUDA context [ 2 ] has to be created every time the network is refitted with new weights as per the documentation . Normally , an application is not required to create a new CUDA context for every inference operation , but it is required for TVLA as we refit the weights or the bias for every inference operation . To the detect PoIs , we applied TVLA 5 times , which is equal to the kernel size , each time with one weight in the convolutional kernel being fixed vs random and the rest of the weights 0 . The corresponding first input , with which the weight is multiplied , is fixed and non-zero while the rest of the inputs are set to 0 . This setup allows us to detect leakages corresponding to the partial sums in the convolutional operation . In this case , the unexploitable false positives can be loading of the weights . The presented approach is more desired , i.e . leads to less false positives , then applying TVLA with random vs fixed inputs as the same input is loaded at different times , potentially leading to more false positives . In addition , to detect leakage corresponding to the bias , we apply fixed vs. random bias TVLA . Similarly to the ran- dom vs. fixed weight TVLA , the false positives in this test can be the loading of the bias . To help filtering these false positives , we also apply correlation to intermediate values . However , we also observed several ghost peaks [ 14 , 15 ] with the correlation method which can not be exploited in the CEMA attack . 4 . Static align employs a standard pattern-based approach : we select a part of a trace as a reference , and compute correlation for each offset within a chosen range for each of the traces . We then shift each trace by the respective offset that maximizes the correlation . Figure 5 shows the results of TVLA for the first weight in the kernel in the first layer with 45k traces . We repeat this process for the rest of the weights and the results clearly show that leakages of the convolution operation are in the second highlighted part of Figure 7 . Figure 6 shows the results of TVLA for the bias of the kernel in the first layer with 37k traces . There is a much clearer leakage present for the bias than for the weights in the convolution operation . After establishing the PoIs with the help of elastic alignment , we use static alignment on the raw traces at these points as static alignment produced higher individual TVLA peaks as well as correlation for the attack . After the TVLA and correlations tests , it is possible to segment the raw traces according the instruction blocks mentioned in Section 3.2 . Figure 7 shows a raw trace where the first highlighted section corresponds to the initialization block . The second highlighted block corresponds to the sum of multiplications in the convolution operation . The third highlighted segment corresponds to the calculation of the bias addition and ReLU output , repeated 4 times for different sets of registers . Note , that these instruction blocks are also separated by synchronization instructions which are also visible in the trace as the amplitude of the EM signal drops close to 0 between the blocks . The same segmentation applies for the second layer . 3.7 . Weight and bias extraction If an adversary is able to recover a neural network ’ s architecture as well as the parameters of a network , then the adversary completely recovered the model . In this attack , we show how to extract the weights and the biases of a CNN with 2 layers using CEMA . Observe that this attack is general and can be extended to arbitrary number of convolutional layers with arbitrary dimensions : since the implementations in Section 3.2 are parallelized on a kernel and channel level , CEMA also can be parallelized to recover all the weights in a layer if an adversary has multiple machines available . The input and batch size of our CNN are set to 500 and 1 , respectively , while the weights and biases are initialized randomly . With an input size of 500 and stride of 1 , the number of convolutions executed by a layer is input size− kernel size + 1 . Consequently , the first and second layers execute 496 and 492 convolutions , respectively . This means there are lots of convolutional intermediates to target in each layer to recover the weights and bias of a kernel . However , our attack only requires knowing just a fraction of the inputs , and the size of this fraction is equivalent to the kernel size . Therefore , we only use the first 5 inputs to each layer to recover the weights and biases in the layers.5 The layers in our example consist of one kernel each containing 5 unknown weights and 1 unknown bias . The convolutional layers are followed by ReLU activation . Alto- gether , 12 unknowns have to be recovered from both layers . 5 . However , in order to calculate the first 5 inputs to the second layer , the first 9 inputs to the first layer has to be known . ( a ) Key rank vs number of traces of the first weight in the first layer with value of -1.22 . ( b ) Correlation vs number of traces of the first weight in the first layer with value of -1.22 . ( c ) Key rank vs number of traces of the fifth weight in the first layer with value of 0.3564 . ( d ) Correlation vs number of traces of the fifth weight in the first layer with value of 0.3564 . Figure 8 : Key ranks and correlations of the first and fifth weights in the first layer . ( a ) Key rank vs number of traces of the second weight in the second layer with value of -0.5137 . ( b ) Correlation vs number of traces of the second weight in the second layer with value of -0.5137 . ( c ) Key rank vs number of traces of the third weight in the second layer with value of -0.6406 . ( d ) Correlation vs number of traces of the third weight in the second layer with value of -0.6406 . Figure 9 : Key rank and correlation for the third and fourth weights in the kernel in the second layer . 30000 20000 10000 k n a r y e k 0 0 1 2 number of traces 3 4 5 1e6 Formally , each layer computes ReLU ( W ∗ M + b ) = ReLU ( 5 ( cid:88 ) wi · mi + b ) , i=1 for a piece of input where W and M are vectors containing the kernel weights and layer inputs , respectively , and b is the bias that is added after the sum of multiplications . In this case , there are multiple intermediate values that depend on the secret weights . First , every weight wi is multiplied by an input mi so the results of the individual multiplications can be targeted . Second , the results of multiplications are summed . Afterward , the bias b is added to the accumulated results . Lastly , the ReLU activation is applied after the bias addition . All of these intermediate values depend on the unknown weights or the unknown bias . In the attack , we have to recover of the parameters of the layers sequentially , i.e . we have to recover the weights and bias in the first layer to be able to attack the second layer . 3.7.1 . Weight extraction . In this experiment , we target the intermediate results of the convolution between the weights and the inputs , as we could observe results with this leakage . We present results with two different leakage models as us- ing the HW leakage model on the partial sum intermediates and the HD between two subsequent intermediate allows us to extract the weights . Following Batina et al . [ 13 ] , we restrict the search space of the weights to the interval [ −5 , 5 ] . With 16-bit floats , there are 35 330 possible candidates in this range . We use the HW leakage model on our chosen intermediate value , the partial sums , to map hypothetical EM consumption values to real measurements T and calculate the Pearson ’ s correlation per sample point between them : ρ ( HW ( i ( cid:88 ) j=1 wj · mj ) , T ) i = 1 .. 5 . We calculate the correlation with each weight candidate , selecting the candidate that shows the highest correlation . Figure 8 shows the key rankings and correlations of the correct weight value vs the number of traces in the first layer for the first and fifth weights , respectively . As shown in Figure 8a , at around the 3,2 million mark , the candidate that ranks first is −1.212 for the first weight , so it is already a value that is close to the correct candidate . At this mark , the correct candidate ranks 106th . Overall , the key rank decreases quickly but in order to get the first rank for the correct candidate , more than 5 million traces are required . This might suggest that the exponent of the intermediate values leak mostly but not the mantissa , and it requires significantly more traces to get the correct candidate . We leave analyzing this phenomenon for future work . Figure 8b shows the correlation of the correct weight candidate and the incorrect weight candidates vs the number of traces for the first weight . As expected , it shows a similar trend to the key rank figure , as the correlation of the correct candidate gets close to the top at the 3 million traces mark . However , the correlation of the correct weight candidate only reaches the maximum after 5 million traces with respect to the incorrect candidates . Figure 8c shows the ranking of the correct weight value vs the number of traces in the first layer for the fifth weight . Similarly to the first weight , the key rank drops quickly , but it takes a lot more traces to for the key rank to converge zero . Similarly , Figure 8d shows the correlation of the weight candidates vs the number of traces for the fifth weight in the first layer . The correct weight candidates already approaches key rank 0 at 8 million mark while needing more traces to fully converge . Every weight in the kernel leaks similarly and targeting the Hamming weight of partial sums can recover the correct weight candidate for all the weight in the kernel . After recovering the weights and bias of the kernel in the first layer , we can calculate the inputs to the second layer to recover the weights and the bias of the kernel in second kernel . Figure 9 shows the key ranking and correlations of the correct weight value vs the number of traces in the second layer for the second and third weights , respectively . Similarly to the weights in the first layer , the key ranks for both weights drop quickly , but reaching a key rank of 0 requires 800 000 and 1.2 million traces for the second and third weights , respectively . 3.7.2 . Bias extraction . There are two operations in the layer that are dependent on the bias value . The first op- eration is the calculation of the sum of convolution and the bias W ∗ M + b . The second one is the ReLU out- put , ReLU ( W ∗ M + b ) . We observed leakage with the Hamming weight of the sum of convolution and the bias , as well as with the output of the ReLU activation . Formally , HW ( W ∗ M + b ) and HW ( ReLU ( W ∗ M + b ) ) both show correlation with the EM measurements . Therefore , we calculate the Pearson correlation for every bias candidate with these leakage models to the real measurements . Figure 10 shows the key ranking and correlation of the CEMA attack on the bias in the first layer with the ReLU ( W ∗ M + b ) intermediates . The key rank drops rapidly , but the convergence to key rank 0 takes more than 10 million traces . Similarly , Figure 10 shows the key rankings and correlation of the CEMA attack on the bias in the second layer with the W ∗ M + b intermediate . The key rank also drops quickly for the bias in the second layer , but the convergence to key rank 0 takes more than 10 million traces . In general , the biases seem to require more traces to converge to key rank 0 than the weights . 4 . Discussion 4.1 . Limitations 4.1.1 . Parameter extraction . In this work , we demon- strated the parameter extraction of a NN with two convolu- tional layers . However , there are multiple aspects that could impact the CEMA attack : Kernel size . The kernel size does not impact the CEMA attack in terms of number of traces needed , but it would ( a ) Key rank vs number of traces of the bias in the first layer with the ReLU intermediate . ( b ) Correlation vs number of traces of the bias in the first layer with the ReLU intermediate . Figure 10 : Key ranks and correlations of the bias with value of 0.856 in the first layer with ReLU intermediate . ( a ) Key rank vs number of traces of the bias in the second layer with the W ∗ M + b intermediate . ( b ) Correlation vs number of traces of the bias in the second layer with the W ∗ M + b intermediate . Figure 11 : Key ranks and correlations of the bias with value of 0.345 in the second layer with W ∗ M + b intermediate . take more time to recover all the weights , as our attack targets the partial sums in the convolution where we recover the weights one-by-one . In other words , the time it takes to recover all the weights in a kernel scales linearly with the kernel size . Batch size . In our experiments , the batch size is set to 1 . However , a larger batch size might not impact the CEMA attack because the same operations could be carried out in parallel with different inputs . This means that two or more intermediate values are calculated at the same time that depend on the same weight or bias . Therefore , the CEMA attack would be applied using the combination of multiple intermediate values . Concurrent applications . The GPU is able to handle and schedule concurrently CUDA functions from multiple ap- plications . This could likely introduce noise in the attacks . However , this highly depends on the required resources for each CUDA function . If a CUDA function takes up most of the GPU resources ( e.g . shared memory , registers , etc . ) , then a different CUDA function will only be sched- uled after all the thread blocks in the previous CUDA function finished execution [ 3 ] . 4.2 . Single-precision implementations The implementations for a convolutional layer with ReLU activation and single-precision calculations are very similar to half-precision implementations analyzed in this work . In fact , the single-precision implementations are named the following : maxwell scudnn 128x k relu t nn v1 where k ∈ { 32 , 64 , 128 } , t ∈ { small , medium , large , interior } . More importantly , the structures of these implementa- tions are also identical to their half-precision counterparts with the exception of using single-precision instructions instead of half-precision instructions . Consequently , our CEMA attack is also applicable for single-precision im- plementation . However , targeting 32-bit floats significantly increases the search space even if it is limited to the [ −5 , 5 ] interval . 4.3 . Mitigation Traditional ways to contain electromagnetic emanation , such as proper shielding or introducing noise to decrease the Signal-to-Noise ratio , could alleviate the problem [ 38 ] . Specifically against parameter extraction , one of the possible countermeasures , which is also mentioned in the CSI-NN paper [ 13 ] , is shuffling [ 53 ] the order of multiplications in the layers , which can make it significantly harder for an adversary to recover the weights . Additionally , masking [ 18 , 42 ] , also mentioned in the CSI-NN paper , would provide a way to break the relationship between the side-channel measurements and the processed data . However , this comes at the price of execution speed , which might not be desired in real-time systems . 4.4 . Comparison with related work To the best of our knowledge , no previous work has been able to extract the parameters of neural networks on GPU using physical side-channel . NWA.1215.18.014 , which is ( partly ) financed by the Nether- lands Organisation for Scientific Research ( NWO ) . More- over , Łukasz Chmielewski was partially supported by Ai- SecTools ( VJ02010010 ) project . Author Platform Side channel References BarraCUDA ( this work ) Batina , et al . ( 2019 ) [ 13 ] Dubet , et al . ( 2020 ) [ 19 ] Yoshida , et al . ( 2020 ) [ 57 ] Regazzoni , et al . ( 2020 ) [ 46 ] Yli-M¨ayry , et al . ( 2021 ) [ 55 ] Li , et al . ( 2022 ) [ 33 ] Joud , et al . ( 2022 ) [ 26 ] Gongye et al . ( 2023 ) [ 22 ] GPU microcontroller FPGA FPGA FPGA FPGA FPGA microcontroller FPGA EM EM Power Power EM EM Power EM EM TABLE 1 : Comparison with related work . Previous works have demonstrated parameter extraction on microcontrollers and FPGAs using power or EM side channel as shown in Table 1 , but not on GPUs . In addition , these attacks were performed on neural networks with binary parameters [ 19 , 46 , 56 ] , 8-bit parameters [ 13 , 22 , 32 , 57 ] or 32-bit parameters [ 13 , 26 ] . In our work , we demonstrate pa- rameter extraction on 16-bit parameters with discussion on extending it to 32-bit parameters . Additionally , the approach presented in this work is scalable because it does not rely on chosen inputs as in [ 22 ] . Chosen inputs are not scalable to large neural networks as crafting chosen inputs becomes harder the deeper the target NN is . 5 . Conclusions In this work , we analyze the NVIDIA Jetson Nano GPU , a commonly chosen platform for real-world neural network implementations , for resilience against side-channel attacks that aim to extract the weights of the target NN . First , we establish where the GPU leaks information about the param- eters of the target DNN . Subsequently , we demonstrate the extraction of weights and biases of a CNN consisting of two convolutional layers using CEMA . Overall , the neural net- work implementations of NVIDIA ’ s TensorRT framework are vulnerable to parameter extraction using electromagnetic side-channel attack despite the networks running in a highly parallel and noisy environment . It remains an open problem to protect their implementations in security or privacy- sensitive applications . Acknowledgments This work was supported by an ARC Discovery Early Career Researcher Award DE200101577 ; an ARC Dis- covery Project number DP210102670 ; and the Deutsche Forschungsgemeinschaft ( DFG , German Research Founda- tion ) under Germany ’ s Excellence Strategy - EXC 2092 CASA - 390781972 . Additionally , this work received funding in the framework of the NWA Cybersecurity Call with project name PROACT with project number [ 1 ] [ 2 ] [ 3 ] [ 4 ] [ 5 ] [ 6 ] [ 7 ] [ 8 ] [ 9 ] compute context , ” capabilities , ” https : //docs.nvidia . programming model , ” https : //docs.nvidia.com/cuda/cuda- https : //docs.nvidia.com/cuda/cuda- accessed : “ Cuda # compute-capabilities , accessed : 2022-09-30 . “ Cuda c-programming-guide/index.html # context , 2022-09-30. https : , accessed : 2022-11-30 . “ cuobjdump , ” binary-utilities/ # usage , accessed : 2022-09-30 . “ Cuda # programming-model , accessed : 2022-09-30 . “ Cuda half2 data type , ” https : //docs.nvidia.com/cuda/ cuda-math-api/struct accessed : 2022-09-30. https : probe-1-mhz-up-to-1-ghz/854 , accessed : 2022-01-25 . “ Tensorrt model inspection , ” https : //docs.nvidia.com/ api/ classnvinfer1 1 1 i engine inspector.html , accessed : 2022-09-30 . “ Nvidia jetson nano , ” https : //developer.nvidia.com/ embedded/jetson-nano-developer-kit , accessed : 2022- 09-30. https : //docs.nvidia . half2.html # struct half2 , [ 10 ] “ Nvidia tensorrt , ” https : //developer.nvidia.com/ [ 11 ] “ Tegra tensorrt , accessed : 2022-09-30. system-on-chip , ” http : //international . v1.0.pdf , accessed : 2022-09-30. x1 [ 12 ] M. Abadi , A. Agarwal , P. Barham , E. Brevdo , Z. Chen , C. Citro , G. S. Corrado , A. Davis , J . Dean , M. Devin , S. Ghemawat , I. Goodfellow , A. Harp , G. Irving , M. Isard , Y. Jia , R. Jozefowicz , L. Kaiser , M. Kudlur , J. Levenberg , D. Man´e , R. Monga , S. Moore , D. Murray , C. Olah , M. Schuster , J. Shlens , B. Steiner , I. Sutskever , K. Talwar , P. Tucker , V. Vanhoucke , V. Vasudevan , F. Vi´egas , O. Vinyals , P. Warden , M. Wattenberg , M. Wicke , Y. Yu , and X. Zheng , “ TensorFlow : Large-scale machine learning on heterogeneous systems , ” 2015 , software available from tensorflow.org . [ Online ] . Available : https : //www.tensorflow.org/ [ 13 ] L. Batina , S. Bhasin , D. Jap , and S. Picek , “ CSI– NN : Reverse engineering of neural network architec- tures through electromagnetic side channel , ” in 28th USENIX Security Symposium USENIX Security 19 ) , 2019 , pp . 515–532 . [ 14 ] E. Brier , C. Clavier , and F. Olivier , “ Correlation power analysis with a leakage model , ” in International work- shop on cryptographic hardware and embedded sys- tems . Springer , 2004 , pp . 16–29 . [ 15 ] C. Canovas and J. Cl´edi ` ere , “ What do s-boxes say in differential side channel attacks ? ” Cryptology ePrint Archive , 2005 . [ 16 ] Ł. Chmielewski and L. Weissbart , “ On reverse en- gineering neural network implementation on GPU , ” in International Conference on Applied Cryptography and Network Security . Springer , 2021 , pp . 96–113 . [ 17 ] F. Chollet , “ Xception : Deep learning with depthwise separable convolutions , ” in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017 , pp . 1251–1258 . [ 18 ] J.-S. Coron and L. Goubin , “ On boolean and arithmetic masking against differential power analysis , ” in Cryp- tographic Hardware and Embedded Systems—CHES 2000 : Second International Workshop Worcester , MA , USA , August 17–18 , 2000 Proceedings 2 . Springer , 2000 , pp . 231–237 . [ 19 ] A. Dubey , R. Cammarota , and A. Aysu , “ Maskednet : The first hardware inference engine aiming power side- channel protection , ” in IEEE International Symposium on Hardware Oriented Security and Trust , 2020 , pp . 197–208 . [ 20 ] F. Elibol , U. Sarac , and I. Erer , “ Realistic eavesdrop- ping attacks on computer displays with low-cost and mobile receiver system , ” in 2012 Proceedings of the 20th European Signal Processing Conference ( EU- SIPCO ) . IEEE , 2012 , pp . 1767–1771 . [ 21 ] B. J. Gilbert Goodwill , J. Jaffe , P. Rohatgi et al. , “ A testing methodology for side-channel resistance vali- dation , ” in NIST non-invasive attack testing workshop , vol . 7 , 2011 , pp . 115–136 . [ 22 ] C. Gongye , Y. Luo , X. Xu , and Y. Fei , “ Side-channel- assisted reverse-engineering of encrypted dnn hard- ware accelerator ip and attack surface exploration , ” in IEEE Symposium on Security and Privacy , 2024 . [ 23 ] K. He , X. Zhang , S. Ren , and J . Sun , “ Deep residual learning for image recognition , ” in Proceedings of the IEEE conference on computer vision and pattern recognition , 2016 , pp . 770–778 . [ 24 ] Z. Hongxin , H. Yuewang , W. Jianxin , L. Yinghua , and Z. Jinling , “ Recognition of electro-magnetic leak- age information from computer radiation with SVM , ” Computers & Security , vol . 28 , no . 1-2 , pp . 72–76 , 2009 . [ 25 ] A. G. Howard , M. Zhu , B. Chen , D. Kalenichenko , W. Wang , T. Weyand , M. Andreetto , and H. Adam , “ Mobilenets : Efficient convolutional neural networks for mobile vision applications , ” arXiv preprint arXiv:1704.04861 , 2017 . [ 26 ] R. Joud , P.-A . Mo¨ellic , S. Ponti´e , and J.-B . Rigaud , introduction to side-channel extraction “ A practical of deep neural network parameters , ” in International Conference on Smart Card Research and Advanced Applications . Springer , 2022 , pp . 45–65 . [ 27 ] P. Kocher , J. Jaffe , and B. Jun , “ Differential power analysis , ” in Annual international cryptology confer- ence . Springer , 1999 , pp . 388–397 . [ 28 ] P. C. Kocher , “ Timing attacks on implementations of Diffie-Hellman , RSA , DSS , and other systems , ” in An- nual International Cryptology Conference . Springer , 1996 , pp . 104–113 . [ 29 ] A. Krizhevsky , I. Sutskever , and G. E. Hinton , “ Im- agenet classification with deep convolutional neural networks , ” Advances in neural information processing systems , vol . 25 , pp . 1097–1105 , 2012 . [ 30 ] M. G. Kuhn and R. J. Anderson , “ Soft tempest : Hid- den data transmission using electromagnetic emana- tions , ” in International Workshop on Information Hid- ing . Springer , 1998 , pp . 124–142 . [ 31 ] N. Laptev , J. Yosinski , L. E. Li , and S. Smyl , “ Time- series extreme event forecasting with neural networks at uber , ” in International conference on machine learn- ing , vol . 34. sn , 2017 , pp . 1–5 . [ 32 ] G. Li , M. Tiwari , and M. Orshansky , “ Power- based attacks on spatial DNN accelerators , ” ACM J. Emerg . Technol . Comput . Syst. , vol . 18 , no . 3 , pp . 58:1–58:18 , 2022 . [ Online ] . Available : https : //doi.org/10.1145/3491219 [ 33 ] —— , “ Power-based attacks on spatial dnn acceler- ators , ” ACM Journal on Emerging Technologies in Computing Systems , vol . 18 , no . 3 , pp . 1–18 , 2022 . [ 34 ] M. Lin , Q. Chen , and S. Yan , “ Network in network , ” arXiv preprint arXiv:1312.4400 , 2013 . [ 35 ] L. Liu , W. Ouyang , X. Wang , P. Fieguth , J. Chen , X. Liu , and M. Pietik¨ainen , “ Deep learning for generic object detection : A survey , ” International journal of computer vision , vol . 128 , no . 2 , pp . 261–318 , 2020 . [ 36 ] Z. Liu , N. Samwel , L. Weissbart , Z. Zhao , D. Lauret , L. Batina , and M. Larson , “ Screen gleaning : A screen reading tempest attack on mobile devices exploit- ing an electromagnetic side channel , ” arXiv preprint arXiv:2011.09877 , 2020 . [ 37 ] H. T. Maia , C. Xiao , D. Li , E. Grinspun , and C. Zheng , “ Can one hear the shape of a neural network ? : Snooping the GPU via magnetic side channel , ” in 31st USENIX Security Symposium , USENIX Security 2022 , Boston , MA , USA , August 10-12 , 2022 , K. R. B. Butler and K. Thomas , Eds . USENIX Association , 2022 , pp . 4383–4400 . [ Online ] . Available : https : //www.usenix . [ 38 ] S. Mangard , E. Oswald , and T. Popp , Power analysis attacks : Revealing the secrets of smart cards . Springer Science & Business Media , 2008 , vol . 31 . [ 39 ] A. Moradi , B. Richter , T. Schneider , and F.-X . Stan- daert , “ Leakage detection with the x2-test , ” IACR Transactions on Cryptographic Hardware and Embed- ded Systems , pp . 209–237 , 2018 . [ 40 ] D. W. Otter , J. R. Medina , and J. K. Kalita , “ A survey of the usages of deep learning for natural language processing , ” IEEE transactions on neural networks and learning systems , vol . 32 , no . 2 , pp . 604–624 , 2020 . [ 41 ] A. Paszke , S. Gross , F. Massa , A. Lerer , J. Bradbury , Cryptographers ’ Track at the RSA Conference 2011 , San Francisco , CA , USA , February 14-18 , 2011 . Pro- ceedings . Springer , 2011 , pp . 104–119 . [ 53 ] N. Veyrat-Charvillon , M. Medwed , S. Kerckhof , and F.-X . Standaert , “ Shuffling against side-channel at- tacks : A comprehensive study with cautionary note , ” in Advances in Cryptology–ASIACRYPT 2012 : 18th Inter- national Conference on the Theory and Application of Cryptology and Information Security , Beijing , China , December 2-6 , 2012 . Proceedings 18 . Springer , 2012 , pp . 740–757 . [ 54 ] M. Yan , C. W. Fletcher , and J. Torrellas , “ Cache telepa- thy : Leveraging shared resource attacks to learn DNN architectures , ” in USENIX Security , 2020 , pp . 2003– 2020. of Jap , binarized “ Extraction [ 55 ] V. Yli-M¨ayry , A. Ito , N. Homma , S. Bhasin , and D. neural network architecture and secret parameters using information , ” in IEEE International side-channel Symposium on Circuits ISCAS 2021 , Daegu , South Korea , May 22-28 , 2021 . IEEE , [ Online ] . Available : 1–5 . https : [ 56 ] V. Yli-M¨ayry , A. Ito , N. Homma , S. Bhasin , and D. Jap , “ Extraction of binarized neural network archi- tecture and secret parameters using side-channel infor- mation , ” in IEEE International Symposium on Circuits and Systems ( ISCAS ) , 2021 , pp . 1–5 . Systems , 2021 , and pp . [ 57 ] K. Yoshida , T. Kubota , S. Okura , M. Shiozaki , and T. Fujino , “ Model reverse-engineering attack using correlation power analysis against systolic array based neural network accelerator , ” in IEEE International Symposium on Circuits and Systems ( ISCAS ) , 2020 , pp . 1–5 . G. Chanan , T. Killeen , Z. Lin , N. Gimelshein , L. Antiga , A. Desmaison , A. Kopf , E. Yang , Z. DeVito , M. Raison , A. Tejani , S. Chilamkurthy , B. Steiner , L. Fang , J. Bai , and S. Chintala , “ Pytorch : An imperative style , high-performance deep learning library , ” in Advances in Neural Information Processing Systems 32 . Curran Associates , Inc. , 2019 , pp . 8024–8035 . [ Online ] . Available : http : [ 42 ] E. Prouff and M. Rivain , “ Masking against side- channel attacks : A formal security proof , ” in Advances in Cryptology–EUROCRYPT 2013 : 32nd Annual Inter- national Conference on the Theory and Applications of Cryptographic Techniques , Athens , Greece , May 26-30 , 2013 . Proceedings 32 . Springer , 2013 , pp . 142–159 . [ 43 ] H. Purwins , B. Li , T. Virtanen , J. Schl¨uter , S.-Y . Chang , and T. Sainath , “ Deep learning for audio signal pro- cessing , ” IEEE Journal of Selected Topics in Signal Processing , vol . 13 , no . 2 , pp . 206–219 , 2019 . [ 44 ] J.-J . Quisquater and D. Samyde , “ ElectroMagnetic Analysis ( EMA ) : Measures and Counter-Measures for Smard Cards , ” in Smart Card Programming and Se- curity ( E-smart 2001 ) , ser . Lecture Notes in Computer Science , I. Attali and T. P. Jensen , Eds. , vol . 2140 . Springer-Verlag , 2001 , pp . 200–210 . [ 45 ] S. S. Rangapuram , M. W. Seeger , J. Gasthaus , L. Stella , Y. Wang , and T. Januschowski , “ Deep state space models for time series forecasting , ” Advances in neural information processing systems , vol . 31 , 2018 . [ 46 ] F. Regazzoni , S. Bhasin , A . A. Pour , I. Alshaer , F. Ay- din , A. Aysu , V. Beroulle , G. Di Natale , P. Franzon , D. Hely et al. , “ Machine learning and hardware se- curity : Challenges and opportunities , ” in International Conference on Computer-Aided Design , 2020 , pp . 1–6 . [ 47 ] A. Sagheer and M. Kotb , “ Time series forecasting of petroleum production using deep lstm recurrent net- works , ” Neurocomputing , vol . 323 , pp . 203–213 , 2019. and T. Januschowski , “ Deepar : Probabilistic forecasting with autoregressive recurrent networks , ” International Journal of Forecasting , vol . 36 , no . 3 , pp . 1181–1191 , 2020 . J. Gasthaus , Salinas , V. Flunkert , [ 48 ] D. [ 49 ] T. Schneider and A. Moradi , “ Leakage assessment methodology , ” in International Workshop on Crypto- graphic Hardware and Embedded Systems . Springer , 2015 , pp . 495–513 . [ 50 ] D. Silver , T. Hubert , J. Schrittwieser , I. Antonoglou , M. Lai , A. Guez , M. Lanctot , L. Sifre , D. Kumaran , T. Graepel et al. , “ Mastering chess and shogi by self- play with a general reinforcement learning algorithm , ” arXiv preprint arXiv:1712.01815 , 2017 . [ 51 ] K. Simonyan and A. Zisserman , “ Very deep convo- lutional networks for large-scale image recognition , ” arXiv preprint arXiv:1409.1556 , 2014 . [ 52 ] J. G. van Woudenberg , M. F. Witteman , and B. Bakker , “ Improving differential power analysis by elastic align- ment , ” in Topics in Cryptology–CT-RSA 2011 : The","['c', 'e', 'r', 'c', 'c', 'v', 'r', 'barracuda', 'bring', 'electromagnetic', 'side', 'channel', 'play', 'steal', 'weight', 'neural', 'network', 'łukasz', 'lejla', 'yuval', 'bochum', 'abstract', 'last', 'decade', 'application', 'neural', 'network', 'spread', 'cover', 'aspect', 'life', 'large', 'number', 'company', 'base', 'business', 'build', 'product', 'use', 'neural', 'network', 'task', 'face', 'recognition', 'machine', 'translation', 'autonomous', 'car', 'use', 'safety', 'securitycritical', 'application', 'high', 'definition', 'map', 'medical', 'wristband', 'globally', 'use', 'product', 'translate', 'chatgpt', 'much', 'intellectual', 'property', 'underpin', 'product', 'encode', 'exact', 'configuration', 'neural', 'network', 'consequently', 'protect', 'utmost', 'priority', 'business', 'time', 'many', 'product', 'need', 'operate', 'strong', 'threat', 'model', 'adversary', 'unfettere', 'physical', 'control', 'product', 'past', 'work', 'demonstrate', 'physical', 'access', 'attacker', 'reverse', 'engineer', 'neural', 'network', 'run', 'scalar', 'microcontroller', 'arm', 'however', 'performance', 'reason', 'neural', 'network', 'often', 'implement', 'highlyparallel', 'general', 'purpose', 'graphic', 'processing', 'unit', 'gpgpu', 'far', 'attack', 'recover', 'coursegraine', 'information', 'structure', 'neural', 'network', 'fail', 'retrieve', 'detailed', 'weight', 'bias', 'work', 'present', 'barracuda', 'novel', 'attack', 'gpgpu', 'completely', 'extract', 'parameter', 'neural', 'network', 'barracuda', 'use', 'correlation', 'electromagnetic', 'analysis', 'recover', 'weight', 'bias', 'convolutional', 'layer', 'neural', 'network', 'use', 'barracuda', 'attack', 'popular', 'device', 'demonstrate', 'successful', 'reverse', 'engineering', 'neural', 'network', 'highly', 'parallel', 'noisy', 'environment', 'introduction', 'field', 'machine', 'learning', 'see', 'explosive', 'crease', 'interest', 'use', 'last', 'decade', 'particular', 'deep', 'learning', 'prove', 'versatile', 'technique', 'provide', 'stateoftheart', 'performance', 'many', 'realworld', 'application', 'use', 'deep', 'learning', 'prove', 'useful', 'broad', 'range', 'domain', 'include', 'play', 'chess', 'object', 'detection', 'image', 'classification', 'audio', 'processing', 'forecasting', 'natural', 'language', 'processing', 'thus', 'application', 'deep', 'learning', 'change', 'many', 'area', 'life', 'become', 'indispensable', 'everyday', 'life', 'deep', 'learning', 'typically', 'utilize', 'artificial', 'neural', 'net', 'work', 'consist', 'multiple', 'layer', 'simulate', 'neu', 'ron', 'nutshell', 'neuron', 'take', 'number', 'input', 'compute', 'nonlinear', 'function', 'weighted', 'sum', 'input', 'common', 'example', 'function', 'rectify', 'linear', 'unit', 'relu', 'basically', 'return', 'input', 'positive', 'otherwise', 'design', 'deep', 'learning', 'solution', 'problem', 'designer', 'first', 'choose', 'network', 'architecture', 'specify', 'layer', 'neuron', 'include', 'size', 'type', 'well', 'neuron', 'connect', 'neuron', 'output', 'connect', 'input', 'designer', 'train', 'network', 'select', 'weight', 'use', 'weight', 'sum', 'well', 'bias', 'value', 'add', 'sum', 'computation', 'nonlinear', 'function', 'train', 'network', 'nontrivial', 'example', 'resource', 'intensive', 'process', 'need', 'curate', 'specialized', 'dataset', 'correctly', 'label', 'sample', 'use', 'training', 'training', 'process', 'often', 'require', 'day', 'even', 'week', 'computation', 'specialized', 'high', 'performance', 'hardware', 'large', 'quantity', 'graphical', 'processing', 'unit', 'gpu', 'moreover', 'design', 'right', 'network', 'architecture', 'give', 'purpose', 'require', 'special', 'ized', 'expertise', 'consequently', 'design', 'parameter', 'train', 'model', 'many', 'case', 'consider', 'trade', 'secret', 'vendor', 'try', 'protect', 'undesired', 'disclosure', 'sidechannel', 'attack', 'exploit', 'information', 'leakage', 'unintended', 'effect', 'perform', 'computation', 'major', 'threat', 'confidentiality', 'deep', 'learn', 'sign', 'attack', 'neural', 'network', 'implementa', 'tion', 'cpu', 'demonstrate', 'use', 'power', 'analysis', 'microarchitectural', 'attack', 'however', 'achieve', 'well', 'performance', 'neural', 'network', 'often', 'implement', 'gpu', 'far', 'attack', 'implementation', 'recover', 'network', 'architecture', 'parameter', 'moreover', 'attack', 'target', 'opensource', 'neural', 'network', 'implement', 'use', 'pytorch', 'tensorflow', 'target', 'commonly', 'use', 'closedsource', 'tensorrt', 'frame', 'work', 'therefore', 'work', 'focus', 'follow', 'research', 'question', 'implementation', 'neural', 'network', 'vulnerable', 'parameter', 'extraction', 'use', 'sidechannel', 'analysis', 'contribution', 'work', 'answer', 'question', 'affirmative', 'analyze', 'closedsource', 'neural', 'network', 'frame', 'work', 'tensorrt', 'execute', 'industrialstrength', 'jetson', 'device', 'tensorrt', 'closedsource', 'framework', 'produce', 'cuda', 'binary', 'disassem', 'bleed', 'demonstrate', 'sidechannel', 'attack', 'monitor', 'electromagnetic', 'emanation', 'emit', 'device', 'attack', 'allow', 'full', 'extraction', 'parameter', 'neural', 'network', 'run', 'device', 'overcome', 'measurement', 'noise', 'uncertainty', 'inherent', 'closed', 'platform', 'attack', 'use', 'correlation', 'electromagnetic', 'analysis', 'cema', 'recover', 'weight', 'bias', 'neural', 'net', 'work', 'attack', 'collect', 'process', 'trace', 'period', 'day', 'show', 'analyze', 'trace', 'recover', 'weight', 'bias', 'use', 'target', 'network', 'result', 'attack', 'demonstrate', 'implementa', 'tion', 'deep', 'learning', 'protect', 'sidechannel', 'attack', 'even', 'source', 'code', 'available', 'disclosure', 'notify', 'find', 'vulnera', 'bilitie', '22nd', 'shortly', 'receive', 'response', 'look', 'find', 'ing', 'result', 'mutual', 'agreement', 'finding', 'release', '22nd', 'notify', 'review', 'disclosure', 'classify', 'vulnerability', 'low', 'severity', 'issue', 'also', 'recommend', 'user', 'follow', 'guide', 'line', 'prevent', 'physical', 'access', 'secure', 'system', 'avoid', 'information', 'leakage', 'organization', 'rest', 'paper', 'organize', 'follow', 'provide', 'necessary', 'background', 'side', 'channel', 'attack', 'architecture', 'section', 'scribe', 'weight', 'extraction', 'attack', 'section', 'finally', 'section', 'cover', 'limitation', 'possible', 'extension', 'coun', 'termeasure', 'related', 'work', 'background', 'introduce', 'concept', 'side', 'channel', 'relate', 'technique', 'use', 'attack', 'provide', 'background', 'cuda', 'programming', 'model', 'architecture', 'analysis', 'leakage', 'occur', 'various', 'channel', 'includ', 'ing', 'power', 'consumption', 'electromagnetic', 'time', 'optical', 'sound', 'various', 'type', 'secret', 'information', 'leak', 'academic', 'setting', 'sidechannel', 'attack', 'first', 'troduced', 'target', 'constrain', 'cryptographic', 'device', 'pose', 'ever', 'constant', 'threat', 'security', 'various', 'embed', 'system', 'work', 'exploit', 'side', 'channel', 'electromagnetic', 'emanation', 'electromagnetic', 'emanation', 'compute', 'device', 'correlate', 'code', 'datum', 'device', 'process', 'cor', 'relation', 'use', 'break', 'cryptographic', 'implementa', 'tion', 'reverse', 'engineer', 'neural', 'network', 'eavesdrop', 'display', 'unit', 'simple', 'analysis', 'sema', 'attacker', 'sample', 'emit', 'signal', 'execution', 'target', 'gram', 'create', 'trace', 'measurement', 'attacker', 'analyze', 'trace', 'identify', 'component', 'correspond', 'secret', 'information', 'correlation', 'analysis', 'cema', 'attacker', 'build', 'model', 'leakage', 'base', 'datum', 'program', 'process', 'attacker', 'execute', 'program', 'multi', 'time', 'different', 'input', 'look', 'correlation', 'predict', 'leakage', 'base', 'model', 'observed', 'leakage', 'point', 'interest', 'pois', 'collect', 'trace', 'common', 'model', 'hamming', 'weight', 'model', 'predict', 'leakage', 'linear', 'number', 'set', 'bit', 'datum', 'hamming', 'weight', 'hamming', 'distance', 'hd', 'model', 'predict', 'leakage', 'linear', 'number', 'bit', 'need', 'change', 'consecutive', 'data', 'value', 'leakage', 'evaluation', 'multiple', 'method', 'propose', 'evaluate', 'leakage', 'embed', 'device', 'intermediate', 'correlation', 'test', 'vector', 'leakage', 'assessment', 'tvla', 'χ2test', 'paper', 'use', 'inter', 'mediate', 'correlation', 'tvla', 'place', 'probe', 'location', 'leak', 'information', 'detect', 'intermediate', 'value', 'leak', 'collect', 'measurement', 'parameter', 'extraction', 'attack', 'present', 'section', 'cuda', 'programming', 'model', 'leverage', 'parallelism', 'offer', 'gpu', 'expose', 'cuda', 'programming', 'model', 'developer', 'model', 'multiple', 'abstraction', 'level', 'exist', 'level', 'different', 'implication', 'respect', 'hardware', 'low', 'level', 'abstraction', 'thread', 'execute', 'cuda', 'function', 'define', 'developer', 'number', 'thread', 'execute', 'cuda', 'function', 'parallel', 'specify', 'time', 'invoke', 'function1', 'subsequently', 'multiple', 'thread', 'group', 'together', 'single', 'block', 'thread', 'thread', 'block', 'block', 'onchip', 'share', 'memory', 'region', 'sidechannel', 'analysis', 'exploit', 'physical', 'leak', 'age', 'electronic', 'device', 'extract', 'secret', 'information', 'function', 'cuda', 'also', 'call', 'kernel', 'use', 'term', 'function', 'avoid', 'confusion', 'kernel', 'cnn', 'share', 'memory', 'chip', 'importantly', 'sidechannel', 'attack', 'also', 'dedicated', 'register', 'file', 'detail', 'assign', 'individual', 'warps', 'publicly', 'disclose', 'information', 'multiple', 'register', 'file', 'mean', 'cpacema', 'attack', 'significantly', 'dere', 'particular', 'warp', 'one', 'calculate', 'target', 'intermediate', 'variable', 'assign', 'different', 'sub', 'sequent', 'execution', 'target', 'intermediate', 'variable', 'save', 'multiple', 'different', 'register', 'file', 'poten', 'tially', 'result', 'different', 'powerem', 'signature', 'therefore', 'mount', 'sidechannel', 'attack', 'rely', 'leakage', 'model', 'become', 'difficult', 'present', 'successful', 'attack', 'use', 'hw', 'well', 'hd', 'leakage', 'model', 'weight', 'bias', 'extraction', 'attack', 'section', 'detail', 'attack', 'recover', 'weight', 'bias', 'cnn', 'convolutional', 'layer', 'contain', 'kernel', 'first', 'describe', 'threat', 'model', 'explore', 'nn', 'implementation', 'assembly', 'level', 'second', 'describe', 'experiment', 'setup', 'process', 'establish', 'point', 'interest', 'poi', 'implementation', 'leak', 'information', 'lastly', 'apply', 'cema', 'intermediate', 'value', 'convolution', 'operation', 'extract', 'weight', 'bias', 'layer', 'good', 'knowledge', 'first', 'time', 'weight', 'bias', 'nn', 'extract', 'imple', 'mentation', 'run', 'addition', 'experiment', 'carry', 'use', 'halfprecision', 'calculation', 'convolutional', 'layer', 'figure', 'cuda', 'programming', 'interface', 'hardware', 'implementation', 'figure', 'stream', 'multiprocessor', 'architecture', 'exchange', 'datum', 'thread', 'block', 'block', 'thread', 'form', 'grid', 'thread', 'block', 'block', 'grid', 'execute', 'independently', 'block', 'block', 'grid', 'share', 'offchip', 'global', 'memory', 'region', 'stream', 'multiprocessor', 'threat', 'model', 'cuda', 'function', 'invoke', 'parallel', 'thread', 'execute', 'stream', 'multiprocessor', 'gpu', 'consist', 'sm', 'far', 'improve', 'parallelism', 'target', 'feature', 'tegra', 'systemonchip', 'consist', 'sm', 'maxwell', 'architecture', 'cuda', 'compute', 'capability', 'illustrate', 'figure', 'block', 'thread', 'schedule', 'particular', 'thread', 'block', 'divide', 'group', 'thread', 'also', 'call', 'warp', 'warp', 'low', 'level', 'execution', 'unit', 'great', 'concern', 'warp', 'assign', 'particular', 'processing', 'unit', 'dedicate', 'resource', 'schedule', 'execute', 'warps', 'sm', 'figure', 'show', 'building', 'block', 'maxwell', 'sm2', 'warp', 'scheduler', 'responsible', 'scheduling', 'issue', 'instruction', 'warp', 'ready', 'set', 'cuda', 'core', 'arithmetic', 'instruction', 'well', 'loadstore', 'unit', 'ldst', 'special', 'function', 'unit', 'spu', 'memory', 'operation', 'transcendental', 'function', 'respectively', 'addition', 'pair', 'share', 'texturel1', 'cache', 'access', 'graphic', 'relate', 'component', 'polymorph', 'engine', 'omit', 'figure', 'relevant', 'target', 'application', 'scenario', 'consider', 'adversary', 'access', 'target', 'device', 'observe', 'random', 'input', 'feed', 'device', 'know', 'architecture', 'nn', 'run', 'device', 'addition', 'also', 'assume', 'adversary', 'collect', 'electromagnetic', 'sidechannel', 'measurement', 'assume', 'architecture', 'target', 'already', 'extract', 'architecture', 'nn', 'need', 'know', 'nn', 'parameter', 'extract', 'use', 'cema', 'explore', 'tensorrt', 'implementation', 'approach', 'tensorrt', 'framework', 'size', 'fit', 'many', 'implementation', 'use', 'layer', 'different', 'kernel', 'size', 'input', 'size', 'batch', 'size', 'tensorrt', 'provide', 'information', 'optimize', 'model', 'information', 'include', 'name', 'cuda', 'function', 'implementation', 'use', 'model', 'well', 'hexadecimal', 'undocumented', 'value', 'call', 'tacticvalue3', 'use', 'information', 'possible', 'extract', 'assembly', 'device', 'code', 'execute', 'thread', 'documentation', 'impact', 'implementation', 'execution', 'use', 'predicate', 'struction', 'cuda', 'programming', 'level', 'gpu', 'hardware', 'level', 'grid', 'thread', 'block', 'warp', 'stream', 'multiprocessor', 'pu', 'pu', 'pu', 'warp', 'warp', 'maxwell', 'stream', 'multiprocessor', 'instruction', 'cache', 'instruction', 'warp', 'scheduler', 'dispatch', 'unit', 'register', 'file', 'core', 'ldst', 'spu', 'pu', 'texture', 'cache', 'pu', 'texture', 'cache', 'share', 'memory', 'use', 'cuobjdump', 'cuda', 'toolkit', 'extract', 'code', 'find', 'different', 'cuda', 'share', 'library', 'file', 'cubla', 'cudnn', 'tensorrt', 'eventually', 'find', 'cuda', 'function', 'correspond', 'implementation', 'convolutional', 'layer', 'relu', 'activation', 'libnvinferso', 'file', 'name', 'retrieve', 'use', 'tensorrt', 'api', 'parameter', 'extraction', 'attack', 'reverse', 'engineer', 'weight', 'nn', 'convolutional', 'layer', 'kernel', 'contain', 'weight', 'share', 'library', 'file', 'implementation', 'find', 'convolutional', 'layer', 'halfprecision', 'calculation', 'relu', 'activation', 'name', 'p16x2', 'p16x2', 'small', 'medium', 'large', 'interior', 'base', 'repeat', 'testing', 'small', 'medium', 'interior', 'implementation', 'implementation', 'sorrt', 'api', 'choose', 'convolutional', 'layer', 'layer', 'model', 'configuration', 'possible', 'timing', 'difference', 'small', 'implementation', 'thus', 'implementation', 'use', 'layer', 'combination', 'furthermore', 'base', 'testing', 'use', 'information', 'provide', 'api', 'also', 'implementation', 'choose', 'api', 'largescale', 'neural', 'net', 'work', 'mobilenet', 'name', 'implementation', 'also', 'include', 'p16x2', 'refer', 'half2', 'datum', 'type', 'cuda', 'half2', 'use', 'register', 'pack', 'halfprecision', 'float', 'point', 'value', 'gpu', 'execute', 'float', 'point', 'instruction', 'half', 'parallel', 'double', 'throughput', 'oppose', 'use', 'singleprecision', 'float', 'point', 'value', 'also', 'mean', 'additional', 'noise', 'addition', 'parallel', 'thread', 'execute', 'convolutional', 'layer', 'structure', 'possible', 'implementation', 'convolutional', 'layer', 'relu', 'activation', 'impleman', 'tation', 'similar', 'structure', 'consist', 'follow', 'block', 'block', 'initialization', 'instruction', 'block', 'convolution', 'operation', 'block', 'bias', 'addition', 'relu', 'calculation', 'init', 'block', 'first', 'main', 'block', 'consist', 'instruction', 'set', 'cuda', 'function', 'block', 'accumulator', 'register', 'initialize', 'later', 'use', 'calculate', 'sum', 'multiplication', 'convolution', 'operation', 'convolutional', 'block', 'second', 'block', 'convolution', 'operation', 'carry', 'block', 'consist', 'vectorized', 'load', 'hfma2', 'instruction', 'addition', 'contain', 'predicate', 'load', 'instruction', 'global', 'memory', 'register', 'pack', '16bit', 'float', 'point', 'figure', 'location', 'langer', 'probe', 'probe', 'tip', 'locate', 'capacitor', 'value', 'also', 'crucial', 'know', 'exactly', 'input', 'data', 'load', 'register', 'information', 'available', 'shed', 'light', 'convolution', 'operation', 'carry', 'implementation', 'accord', 'api', 'input', 'reformatte', 'lay', 'wide', 'channel', 'vectorize', 'row', 'major', 'format', 'mean', 'register', 'hold', 'input', 'load', 'halfprecision', 'float', 'point', 'input', 'different', 'input', 'channel', 'therefore', 'also', 'suggest', 'register', 'hold', 'weight', 'different', 'channel', 'kernel', 'case', 'dimensional', 'convolution', 'set', 'number', 'input', 'channel', 'common', 'onedimensional', 'convolutional', 'use', 'case', 'case', 'image', 'input', 'number', 'input', 'channel', 'register', 'hold', 'input', 'value', 'different', 'input', 'channel', 'multiple', 'input', 'channel', 'process', 'parallel', 'cema', 'attack', 'require', 'time', 'get', 'weight', 'channel', 'kernel', 'independent', 'additionally', 'code', 'second', 'block', 'indicate', 'accumulator', 'register', 'use', 'hfma2', 'instruction', 'block', 'predicate', 'jump', 'instruction', 'execute', 'end', 'code', 'block', 'jump', 'back', 'start', 'block', 'suggest', 'execution', 'jump', 'instruction', 'likely', 'depend', 'kernel', 'size', 'layer', 'relu', 'block', 'third', 'block', 'repeat', 'time', 'first', 'calculate', 'sum', 'low', 'high', 'half', 'register', 'suggest', 'channel', 'combination', 'convolutional', 'operation', 'sum', 'multiplication', 'execute', 'block', 'half2', 'float', 'point', 'addition', 'hset', 'instruction', 'execute', 'block', 'suggest', 'calculation', 'bias', 'addition', 'relu', 'output', 'overall', 'implementation', 'similar', 'particular', 'twolayer', 'model', 'configuration', 'time', 'choose', 'implementation', 'api', 'relu', 'small', 'implementation', 'layer', 'choose', 'carry', 'parameter', 'extraction', 'attack', 'imple', 'mentation', 'however', 'also', 'analyze', 'relu', 'medium', 'relu', 'interior', 'implementation', 'leakage', 'detection', 'process', 'section', 'figure', 'raw', 'trace', 'whole', 'operation', 'layer', 'clearly', 'separate', 'trace', 'additionally', 'cuda', 'devicetohost', 'memory', 'copy', 'also', 'clearly', 'visisble', 'end', 'trace', 'figure', 'result', 'tvla', 'multiplication', 'first', 'weight', 'kernel', 'convolutional', 'block', 'top', 'figure', 'depict', 'elastically', 'align', 'trace', 'bottom', 'figure', 'show', 'correspond', 'absolute', 'tt', 'statistic', 'time', 'sample', 'multiple', 'leak', 'spot', 'overall', 'leakage', 'high', 'figure', 'result', 'fix', 'random', 'bias', 'tvla', 'top', 'figure', 'depict', 'example', 'trace', 'bottom', 'figure', 'show', 'correspond', 'absolute', 'tt', 'statistic', 'time', 'sample', 'clear', 'leakage', 'scatter', 'multiple', 'clock', 'cycle', 'experiment', 'setup', 'setup', 'core', 'operate', 'high', 'possible', 'clock', 'frequency', 'mhz', 'order', 'collect', 'electromagnetic', 'trace', 'use', 'lecroy', 'sample', 'rate', '10gss', 'figure', 'segment', 'raw', 'trace', 'first', 'layer', 'first', 'highlighted', 'block', 'contain', 'initialization', 'instruction', 'second', 'highlighted', 'block', 'convolution', 'operation', 'carry', 'third', 'highlight', 'block', 'correspond', 'bias', 'addition', 'relu', 'activation', 'calculation', 'leak', 'information', 'langer', 'nearfield', 'probe', 'trace', 'tain', 'measurement', 'electromagnetic', 'emanation', 'gpu', 'target', 'neural', 'network', 'execute', 'inference', 'random', 'input', 'scan', 'tegra', 'soc', 'nearby', 'capacitor', 'probe', 'find', 'multiple', 'interesting', 'location', 'parameter', 'neural', 'network', 'eventually', 'observe', 'good', 'signal', 'capacitor', 'show', 'figure', 'term', 'leakage', 'magnitude', 'use', 'tvla', 'location', 'chip', 'capacitor', 'similar', 'however', 'emit', 'signal', 'capacitor', 'provide', 'less', 'noisy', 'trace', 'make', 'trace', 'acquisition', 'alignment', 'easy', 'trigger', 'oscilloscope', 'collect', 'measurement', 'inference', 'nn', 'start', 'use', 'rise', 'edge', 'inference', 'signal', 'trigger', 'trace', 'preprocessing', 'figure', 'show', 'example', 'trace', 'inference', 'oper', 'ation', 'cnn', 'layer', 'layer', 'clearly', 'separate', 'display', 'similar', 'pattern', 'however', 'first', 'layer', 'take', 'considerably', 'time', 'execute', 'input', 'size', 'layer', 'respectively', 'difference', 'alone', 'explain', 'observed', 'difference', 'execution', 'time', 'however', 'various', 'cache', 'explain', 'behaviour', 'importantly', 'observe', 'different', 'pattern', 'repeat', 'second', 'layer', 'trace', 'trace', 'pattern', 'similar', 'first', 'layer', 'collect', 'trace', 'hold', 'second', 'layer', 'second', 'layer', 'collect', 'trace', 'display', 'completely', 'similar', 'pattern', 'test', 'behaviour', 'implementation', 'well', 'issue', 'come', 'implementation', 'use', 'layer', 'exam', 'combination', 'relu', 'small', 'relu', 'interior', 'implementation', 'first', 'second', 'layer', 'respectively', 'result', 'uniform', 'pattern', 'layer', 'contrast', 'relu', 'small', 'implementation', 'use', 'layer', 'result', 'nonuniform', 'pattern', 'second', 'layer', 'also', 'test', 'behaviour', 'network', 'convolutional', 'layer', 'soon', 'implementation', 'use', 'different', 'layer', 'uniform', 'behaviour', 'encounter', 'regardless', 'mention', 'section', 'carry', 'parameter', 'extraction', 'relu', 'small', 'use', 'implementation', 'layer', 'accurate', 'alignment', 'static', 'alignment', 'possible', 'use', 'trace', 'second', 'layer', 'collect', 'trace', 'use', 'cema', 'attack', 'second', 'layer', 'addition', 'collect', 'measurement', 'mini', 'mum', 'trace', 'hard', 'fully', 'synchronize', 'contain', 'lot', 'jitter', 'combat', 'problem', 'use', 'elastic', 'alignment', 'leakage', 'detection', 'process', 'elastic', 'alignment', 'allow', 'align', 'trace', 'time', 'point', 'however', 'also', 'technique', 'require', 'tune', 'correct', 'parameter', 'computationally', 'expensive', 'therefore', 'use', 'align', 'trace', 'detect', 'leak', 'point', 'cema', 'attack', 'carry', 'raw', 'trace', 'align', 'use', 'static', 'alignment', 'leakage', 'detection', 'detect', 'intermediate', 'value', 'leak', 'necessary', 'step', 'apply', 'cema', 'order', 'apply', 'random', 'fix', 'tvla', 'intermediate', 'correlation', 'detect', 'pois', 'layer', 'also', 'use', 'leakage', 'detection', 'process', 'decide', 'good', 'location', 'probe', 'setup', 'furthermore', 'perform', 'leakage', 'detection', 'relu', 'small', 'relu', 'medium', 'relu', 'interior', 'implementation', 'analysis', 'present', 'section', 'apply', 'tensorrt', 'framework', 'support', 'refit', 'network', 'thefly', 'different', 'weight', 'new', 'cuda', 'context', 'create', 'time', 'network', 'refit', 'new', 'weight', 'documentation', 'normally', 'application', 'require', 'create', 'new', 'cuda', 'context', 'inference', 'operation', 'require', 'tvla', 'refit', 'weight', 'bias', 'inference', 'operation', 'detect', 'pois', 'apply', 'tvla', 'time', 'equal', 'kernel', 'size', 'time', 'weight', 'convolutional', 'kernel', 'fix', 'random', 'rest', 'weight', 'corresponding', 'first', 'input', 'weight', 'multiply', 'fix', 'nonzero', 'rest', 'input', 'set', 'setup', 'allow', 'detect', 'leakage', 'correspond', 'partial', 'sum', 'convolutional', 'operation', 'case', 'unexploitable', 'false', 'positive', 'load', 'weight', 'present', 'approach', 'desire', 'lead', 'less', 'false', 'positive', 'apply', 'tvla', 'random', 'fix', 'input', 'input', 'load', 'different', 'time', 'potentially', 'lead', 'false', 'positive', 'addition', 'detect', 'leakage', 'correspond', 'bias', 'apply', 'fix', 'random', 'bias', 'tvla', 'similarly', 'ran', 'dom', 'fix', 'weight', 'tvla', 'false', 'positive', 'test', 'loading', 'bias', 'help', 'filter', 'false', 'positive', 'also', 'apply', 'correlation', 'intermediate', 'value', 'however', 'also', 'observe', 'several', 'ghost', 'peak', 'correlation', 'method', 'exploit', 'cema', 'attack', 'static', 'align', 'employ', 'standard', 'patternbase', 'approach', 'select', 'part', 'trace', 'reference', 'compute', 'correlation', 'offset', 'choose', 'range', 'trace', 'shift', 'trace', 'respective', 'offset', 'maximize', 'correlation', 'figure', 'show', 'result', 'tvla', 'first', 'weight', 'kernel', 'first', 'layer', '45k', 'trace', 'repeat', 'process', 'rest', 'weight', 'result', 'clearly', 'show', 'leakage', 'convolution', 'operation', 'second', 'highlight', 'part', 'figure', 'figure', 'show', 'result', 'tvla', 'bias', 'kernel', 'first', 'layer', '37k', 'trace', 'much', 'clear', 'leakage', 'present', 'bias', 'weight', 'convolution', 'operation', 'establish', 'pois', 'help', 'elastic', 'alignment', 'use', 'static', 'alignment', 'raw', 'trace', 'point', 'static', 'alignment', 'produce', 'high', 'individual', 'tvla', 'peak', 'well', 'correlation', 'attack', 'tvla', 'correlation', 'test', 'possible', 'segment', 'raw', 'trace', 'accord', 'instruction', 'block', 'mention', 'section', 'figure', 'show', 'raw', 'trace', 'first', 'highlighted', 'section', 'correspond', 'initialization', 'block', 'second', 'highlight', 'block', 'correspond', 'sum', 'multiplication', 'convolution', 'operation', 'third', 'highlight', 'segment', 'correspond', 'calculation', 'bias', 'addition', 'relu', 'output', 'repeat', 'time', 'different', 'set', 'register', 'note', 'instruction', 'block', 'also', 'separate', 'synchronization', 'instruction', 'also', 'visible', 'trace', 'amplitude', 'signal', 'drop', 'close', 'block', 'segmentation', 'apply', 'second', 'layer', 'weight', 'bias', 'extraction', 'adversary', 'able', 'recover', 'neural', 'network', 'architecture', 'well', 'parameter', 'network', 'adversary', 'completely', 'recover', 'model', 'attack', 'show', 'extract', 'weight', 'bias', 'cnn', 'layer', 'use', 'cema', 'observe', 'attack', 'general', 'extend', 'arbitrary', 'number', 'convolutional', 'layer', 'arbitrary', 'dimension', 'implementation', 'section', 'parallelize', 'kernel', 'channel', 'level', 'cema', 'also', 'parallelize', 'recover', 'weight', 'layer', 'adversary', 'multiple', 'machine', 'available', 'input', 'batch', 'size', 'cnn', 'set', 'respectively', 'weight', 'bias', 'initialize', 'randomly', 'input', 'size', 'stride', 'number', 'convolution', 'execute', 'layer', 'input', 'consequently', 'first', 'second', 'layer', 'execute', 'convolution', 'respectively', 'mean', 'lot', 'convolutional', 'intermediate', 'target', 'layer', 'recover', 'weight', 'bias', 'kernel', 'however', 'attack', 'require', 'know', 'fraction', 'input', 'size', 'fraction', 'equivalent', 'kernel', 'size', 'therefore', 'use', 'first', 'input', 'layer', 'recover', 'weight', 'bias', 'layers5', 'layer', 'example', 'consist', 'kernel', 'contain', 'unknown', 'weight', 'unknown', 'bias', 'convolutional', 'layer', 'follow', 'relu', 'activation', 'gether', 'unknown', 'recover', 'layer', 'however', 'order', 'calculate', 'first', 'input', 'second', 'layer', 'first', 'input', 'first', 'layer', 'know', 'key', 'rank', 'number', 'trace', 'first', 'weight', 'first', 'layer', 'value', 'b', 'correlation', 'number', 'trace', 'first', 'weight', 'first', 'layer', 'value', 'c', 'key', 'rank', 'number', 'trace', 'fifth', 'weight', 'first', 'layer', 'value', 'correlation', 'number', 'trace', 'fifth', 'weight', 'first', 'layer', 'value', 'figure', 'key', 'rank', 'correlation', 'first', 'fifth', 'weight', 'first', 'layer', 'key', 'rank', 'number', 'trace', 'second', 'weight', 'second', 'layer', 'value', 'b', 'correlation', 'number', 'trace', 'second', 'weight', 'second', 'layer', 'value', 'c', 'key', 'rank', 'number', 'trace', 'third', 'weight', 'second', 'layer', 'value', 'correlation', 'number', 'trace', 'third', 'weight', 'second', 'layer', 'value', 'figure', 'key', 'rank', 'correlation', 'third', 'fourth', 'weight', 'kernel', 'second', 'layer', 'r', 'number', 'trace', 'formally', 'layer', 'compute', 'relu', 'relu', 'piece', 'input', 'vector', 'contain', 'kernel', 'weight', 'layer', 'input', 'respectively', 'bias', 'add', 'sum', 'multiplication', 'case', 'multiple', 'intermediate', 'value', 'depend', 'secret', 'weight', 'first', 'weight', 'multiply', 'input', 'mi', 'result', 'individual', 'multiplication', 'target', 'second', 'result', 'multiplication', 'sum', 'afterward', 'bias', 'add', 'accumulate', 'result', 'lastly', 'relu', 'activation', 'apply', 'bias', 'addition', 'intermediate', 'value', 'depend', 'unknown', 'weight', 'unknown', 'bias', 'attack', 'recover', 'parameter', 'layer', 'sequentially', 'recover', 'weight', 'bias', 'first', 'layer', 'able', 'attack', 'second', 'layer', 'weight', 'extraction', 'experiment', 'target', 'intermediate', 'result', 'convolution', 'weight', 'input', 'observe', 'result', 'leakage', 'present', 'result', 'different', 'leakage', 'model', 'e', 'leakage', 'model', 'partial', 'sum', 'intermediate', 'hd', 'subsequent', 'intermediate', 'allow', 'extract', 'weight', 'follow', 'restrict', 'search', 'space', 'weight', 'interval', '−5', '16bit', 'float', 'possible', 'candidate', 'range', 'use', 'leakage', 'model', 'choose', 'intermediate', 'value', 'partial', 'sum', 'map', 'hypothetical', 'consumption', 'value', 'real', 'measurement', 'calculate', 'pearson', 'correlation', 'sample', 'point', 'ρ', 'wj', 'calculate', 'correlation', 'weight', 'candidate', 'select', 'candidate', 'show', 'high', 'correlation', 'figure', 'show', 'key', 'ranking', 'correlation', 'correct', 'weight', 'value', 'number', 'trace', 'first', 'layer', 'first', 'fifth', 'weight', 'respectively', 'show', 'figure', 'mark', 'candidate', 'rank', 'first', 'first', 'weight', 'already', 'value', 'close', 'correct', 'candidate', 'mark', 'correct', 'candidate', 'rank', '106th', 'overall', 'key', 'rank', 'decrease', 'quickly', 'order', 'get', 'first', 'rank', 'correct', 'candidate', 'trace', 'require', 'suggest', 'exponent', 'intermediate', 'value', 'leak', 'mostly', 'mantissa', 'require', 'significantly', 'trace', 'get', 'correct', 'candidate', 'leave', 'analyze', 'phenomenon', 'future', 'work', 'figure', 'show', 'correlation', 'correct', 'weight', 'candidate', 'incorrect', 'weight', 'candidate', 'number', 'trace', 'first', 'weight', 'expect', 'show', 'similar', 'trend', 'key', 'rank', 'figure', 'correlation', 'correct', 'candidate', 'get', 'close', 'top', 'trace', 'mark', 'however', 'correlation', 'correct', 'weight', 'candidate', 'reach', 'maximum', 'trace', 'respect', 'incorrect', 'candidate', 'figure', 'show', 'ranking', 'correct', 'weight', 'value', 'number', 'trace', 'first', 'layer', 'fifth', 'weight', 'similarly', 'first', 'weight', 'key', 'rank', 'drop', 'quickly', 'take', 'lot', 'trace', 'key', 'rank', 'converge', 'similarly', 'figure', 'show', 'correlation', 'weight', 'candidate', 'number', 'trace', 'fifth', 'weight', 'first', 'layer', 'correct', 'weight', 'candidate', 'already', 'approach', 'key', 'rank', 'mark', 'need', 'trace', 'fully', 'converge', 'weight', 'kernel', 'leak', 'similarly', 'target', 'hamming', 'weight', 'partial', 'sum', 'recover', 'correct', 'weight', 'candidate', 'weight', 'kernel', 'recover', 'weight', 'bias', 'kernel', 'first', 'layer', 'calculate', 'input', 'second', 'layer', 'recover', 'weight', 'bias', 'kernel', 'second', 'kernel', 'figure', 'show', 'key', 'ranking', 'correlation', 'correct', 'weight', 'value', 'number', 'trace', 'second', 'layer', 'second', 'third', 'weight', 'respectively', 'similarly', 'weight', 'first', 'layer', 'key', 'rank', 'weight', 'drop', 'quickly', 'reach', 'key', 'rank', 'require', 'trace', 'second', 'third', 'weight', 'respectively', 'bias', 'extraction', 'operation', 'layer', 'dependent', 'bias', 'value', 'first', 'op', 'eration', 'calculation', 'sum', 'convolution', 'bias', 'w', 'b', 'second', 'one', 'relu', 'put', 'relu', 'b', 'observe', 'leakage', 'hamming', 'weight', 'sum', 'convolution', 'bias', 'well', 'output', 'relu', 'activation', 'formally', 'w', '∗', 'b', 'relu', 'b', 'show', 'correlation', 'measurement', 'therefore', 'calculate', 'pearson', 'correlation', 'bias', 'candidate', 'leakage', 'model', 'real', 'measurement', 'figure', 'show', 'key', 'ranking', 'correlation', 'cema', 'attack', 'bias', 'first', 'layer', 'relu', 'b', 'intermediate', 'key', 'rank', 'drop', 'rapidly', 'convergence', 'key', 'rank', 'take', 'trace', 'similarly', 'figure', 'show', 'key', 'ranking', 'correlation', 'cema', 'attack', 'bias', 'second', 'layer', 'w', 'intermediate', 'key', 'rank', 'also', 'drop', 'quickly', 'bias', 'second', 'layer', 'convergence', 'key', 'rank', 'take', 'trace', 'general', 'bias', 'seem', 'require', 'trace', 'converge', 'key', 'rank', 'weight', 'discussion', 'limitation', 'parameter', 'extraction', 'work', 'demon', 'strate', 'parameter', 'extraction', 'nn', 'tional', 'layer', 'however', 'multiple', 'aspect', 'impact', 'attack', 'size', 'kernel', 'size', 'impact', 'cema', 'attack', 'term', 'number', 'trace', 'need', 'key', 'rank', 'number', 'trace', 'bias', 'first', 'layer', 'relu', 'intermediate', 'b', 'correlation', 'number', 'trace', 'bias', 'first', 'layer', 'relu', 'intermediate', 'figure', 'key', 'rank', 'correlation', 'bias', 'value', 'first', 'layer', 'relu', 'intermediate', 'key', 'rank', 'number', 'trace', 'bias', 'second', 'layer', 'w', 'intermediate', 'b', 'correlation', 'number', 'trace', 'bias', 'second', 'layer', 'w', 'intermediate', 'figure', 'key', 'rank', 'correlation', 'bias', 'value', 'second', 'layer', 'intermediate', 'take', 'time', 'recover', 'weight', 'attack', 'target', 'partial', 'sum', 'convolution', 'recover', 'weight', 'onebyone', 'word', 'time', 'take', 'recover', 'weight', 'kernel', 'scale', 'linearly', 'kernel', 'size', 'batch', 'size', 'experiment', 'batch', 'size', 'set', 'however', 'large', 'batch', 'size', 'impact', 'cema', 'attack', 'operation', 'carry', 'parallel', 'different', 'input', 'mean', 'intermediate', 'value', 'calculate', 'time', 'depend', 'weight', 'bias', 'therefore', 'cema', 'attack', 'apply', 'use', 'combination', 'multiple', 'intermediate', 'value', 'concurrent', 'application', 'able', 'handle', 'schedule', 'concurrently', 'cuda', 'function', 'multiple', 'plication', 'likely', 'introduce', 'noise', 'attack', 'however', 'highly', 'depend', 'require', 'resource', 'cuda', 'function', 'cuda', 'function', 'take', 'resource', 'share', 'memory', 'register', 'different', 'cuda', 'function', 'sche', 'uled', 'thread', 'block', 'previous', 'cuda', 'function', 'finish', 'execution', 'singleprecision', 'implementation', 'implementation', 'convolutional', 'layer', 'relu', 'activation', 'singleprecision', 'calculation', 'similar', 'halfprecision', 'implementation', 'analyze', 'work', 'fact', 'singleprecision', 'implementation', 'name', 'follow', 'maxwell', 'scudnn', 'small', 'medium', 'large', 'interior', 'importantly', 'structure', 'implementa', 'tion', 'also', 'identical', 'halfprecision', 'counterpart', 'exception', 'use', 'singleprecision', 'instruction', 'instead', 'halfprecision', 'instruction', 'consequently', 'cema', 'attack', 'also', 'applicable', 'singleprecision', 'plementation', 'however', 'target', '32bit', 'float', 'significantly', 'increase', 'search', 'space', 'even', 'limited', '−5', 'interval', 'mitigation', 'traditional', 'way', 'contain', 'electromagnetic', 'emanation', 'proper', 'shielding', 'introduce', 'noise', 'decrease', 'signaltonoise', 'ratio', 'alleviate', 'problem', 'specifically', 'parameter', 'extraction', 'possible', 'countermeasure', 'also', 'mention', 'csinn', 'paper', 'shuffle', 'order', 'multiplication', 'layer', 'make', 'significantly', 'hard', 'adversary', 'recover', 'weight', 'additionally', 'mask', 'also', 'mention', 'csinn', 'paper', 'provide', 'way', 'break', 'relationship', 'sidechannel', 'measurement', 'process', 'datum', 'however', 'come', 'price', 'execution', 'speed', 'desire', 'realtime', 'system', 'comparison', 'related', 'work', 'good', 'knowledge', 'previous', 'work', 'able', 'extract', 'parameter', 'neural', 'network', 'use', 'physical', 'sidechannel', 'partly', 'finance', 'nether', 'land', 'organisation', 'scientific', 'research', 'nwo', 'łukasz', 'partially', 'support', 'sectools', 'project', 'author', 'platform', 'side', 'channel', 'reference', 'barracuda', 'work', 'yoshida', 'regazzoni', 'gongye', 'microcontroller', 'fpga', 'fpga', 'fpga', 'fpga', 'fpga', 'microcontroller', 'fpga', 'power', 'power', 'power', 'table', 'comparison', 'related', 'work', 'previous', 'work', 'demonstrate', 'parameter', 'extraction', 'microcontroller', 'fpgas', 'use', 'power', 'side', 'channel', 'show', 'table', 'gpu', 'addition', 'attack', 'perform', 'neural', 'network', 'binary', 'parameter', '8bit', 'parameter', '32bit', 'parameter', 'work', 'demonstrate', 'rameter', 'extraction', '16bit', 'parameter', 'discussion', 'extend', '32bit', 'parameter', 'additionally', 'approach', 'present', 'work', 'scalable', 'rely', 'choose', 'input', 'choose', 'input', 'scalable', 'large', 'neural', 'network', 'craft', 'choose', 'input', 'become', 'hard', 'deep', 'target', 'conclusion', 'work', 'analyze', 'commonly', 'choose', 'platform', 'neural', 'implementation', 'resilience', 'sidechannel', 'attack', 'aim', 'extract', 'weight', 'target', 'first', 'establish', 'leak', 'information', 'param', 'eter', 'target', 'subsequently', 'demonstrate', 'extraction', 'weight', 'bias', 'cnn', 'consist', 'convolutional', 'layer', 'use', 'cema', 'overall', 'neural', 'net', 'work', 'implementation', 'tensorrt', 'framework', 'vulnerable', 'parameter', 'extraction', 'use', 'electromagnetic', 'sidechannel', 'attack', 'network', 'run', 'highly', 'parallel', 'noisy', 'environment', 'remain', 'open', 'problem', 'protect', 'implementation', 'security', 'privacy', 'sensitive', 'application', 'acknowledgment', 'work', 'support', 'arc', 'early', 'career', 'researcher', 'award', 'arc', 'covery', 'project', 'number', 'deutsche', 'forschungsgemeinschaft', 'dfg', 'german', 'research', 'founda', 'tion', 'excellence', 'strategy', 'additionally', 'work', 'receive', 'funding', 'framework', 'cybersecurity', 'call', 'project', 'name', 'proact', 'project', 'number', 'compute', 'context', 'capability', 'https', 'docsnvidia', 'programming', 'model', 'access', 'cuda', 'computecapabilitie', 'access', 'cuda', 'context', 'https', 'access', 'cuobjdump', 'binaryutilitie', 'usage', 'access', 'cuda', 'programmingmodel', 'access', 'cuda', 'type', 'https', 'docsnvidiacomcuda', 'cudamathapistruct', 'access', 'https', 'access', 'tensorrt', 'model', 'inspection', 'https', 'api', 'classnvinfer1', 'engine', 'inspectorhtml', 'access', 'embeddedjetsonnanodeveloperkit', 'access', 'https', 'docsnvidia', 'struct', 'half2', 'tensorrt', 'https', 'developernvidiacom', 'tegra', 'tensorrt', 'access', 'systemonchip', 'http', 'access', 'agarwal', 'brevdo', 'ghemawat', 'goodfellow', 'harp', 'jozefowicz', 'man´e', 'r', 'moore', 'shlen', 'sutskever', 'tucker', 'vanhoucke', 'vinyal', 'tensorflow', 'largescale', 'machine', 'learn', 'heterogeneous', 'system', 'software', 'available', 'tensorfloworg', 'online', 'available', 'https', 'wwwtensorfloworg', 'bhasin', 'reverse', 'engineering', 'neural', 'network', 'architec', 'ture', 'electromagnetic', 'side', 'channel', '28th', 'usenix', 'security', 'symposium', 'usenix', 'security', 'pp', 'e', 'bri', 'c', 'clavier', 'f', 'olivi', 'correlation', 'power', 'analysis', 'leakage', 'model', 'international', 'work', 'shop', 'cryptographic', 'hardware', 'embed', 'sys', 'tem', 'springer', 'pp', 'c', 'canovas', 'sboxe', 'say', 'differential', 'side', 'channel', 'attack', 'cryptology', 'eprint', 'archive', 'ł', 'chmielewski', 'l', 'weissbart', 'reverse', 'gineere', 'neural', 'network', 'implementation', 'international', 'conference', 'apply', 'cryptography', 'network', 'security', 'springer', 'pp', 'xception', 'deep', 'learning', 'depthwise', 'separable', 'convolution', 'proceeding', 'ieee', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', 'l', 'goubin', 'boolean', 'arithmetic', 'masking', 'differential', 'power', 'analysis', 'cryp', 'tographic', 'hardware', 'embed', 'system', 'che', 'second', 'international', 'workshop', 'proceeding', 'springer', 'pp', 'dubey', 'r', 'cammarota', 'aysu', 'maskednet', 'first', 'hardware', 'inference', 'engine', 'aim', 'power', 'side', 'channel', 'protection', 'ieee', 'international', 'symposium', 'hardware', 'orient', 'security', 'trust', 'pp', 'elibol', 'sarac', 'erer', 'realistic', 'eavesdrop', 'ping', 'attack', 'computer', 'display', 'lowcost', 'mobile', 'receiver', 'system', 'proceeding', '20th', 'european', 'signal', 'processing', 'conference', 'ieee', 'pp', 'testing', 'methodology', 'resistance', 'vali', 'dation', 'nist', 'noninvasive', 'attack', 'testing', 'workshop', 'vol', 'pp', 'gongye', 'assist', 'reverseengineere', 'encrypted', 'hard', 'accelerator', 'ip', 'attack', 'surface', 'exploration', 'ieee', 'symposium', 'security', 'privacy', 'k', 'ren', 'sun', 'deep', 'residual', 'learning', 'image', 'recognition', 'proceeding', 'ieee', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', 'z', 'hongxin', 'h', 'yinghua', 'jinle', 'recognition', 'electromagnetic', 'leak', 'age', 'information', 'computer', 'radiation', 'computer', 'security', 'vol', 'pp', 'g', 'andreetto', 'h', 'mobilenet', 'efficient', 'convolutional', 'neural', 'network', 'mobile', 'vision', 'application', 'arxiv', 'preprint', 'r', 'mo¨ellic', 'ponti´e', 'introduction', 'sidechannel', 'extraction', 'practical', 'deep', 'neural', 'network', 'parameter', 'international', 'conference', 'smart', 'card', 'research', 'advanced', 'application', 'springer', 'pp', 'jun', 'differential', 'power', 'analysis', 'annual', 'international', 'cryptology', 'confer', 'ence', 'springer', 'pp', 'p', 'c', 'kocher', 'time', 'attack', 'implementation', 'diffiehellman', 'rsa', 'dss', 'system', 'nual', 'international', 'cryptology', 'conference', 'pp', 'krizhevsky', 'sutskever', 'agenet', 'classification', 'deep', 'convolutional', 'neural', 'network', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'soft', 'tempest', 'hide', 'den', 'data', 'transmission', 'use', 'electromagnetic', 'tion', 'international', 'workshop', 'information', 'hide', 'springer', 'pp', 'laptev', 'j', 'smyl', 'time', 'series', 'extreme', 'event', 'forecast', 'neural', 'network', 'uber', 'international', 'conference', 'machine', 'learn', 'vol', 'sn', 'pp', 'orshansky', 'power', 'base', 'attack', 'spatial', 'dnn', 'accelerator', 'acm', 'technol', 'comput', 'syst', 'vol', 'pp', 'online', 'available', 'https', 'powerbase', 'attack', 'spatial', 'acceler', 'ator', 'journal', 'emerge', 'technology', 'computing', 'system', 'vol', 'pp', '1–18', 'network', 'network', 'arxiv', 'preprint', 'arxiv13124400', 'pietik¨ainen', 'deep', 'learning', 'generic', 'object', 'detection', 'survey', 'international', 'journal', 'computer', 'vision', 'vol', 'pp', 'samwel', 'weissbart', 'larson', 'screen', 'gleaning', 'screen', 'read', 'tempest', 'attack', 'mobile', 'device', 'exploit', 'electromagnetic', 'side', 'channel', 'arxiv', 'preprint', 'h', 'grinspun', 'hear', 'shape', 'neural', 'network', 'snoop', 'magnetic', 'side', 'channel', '31st', 'usenix', 'security', 'symposium', 'usenix', 'security', 'r', 'b', 'butler', 'ed', 'pp', '4383–4400', 'online', 'available', 'https', 'wwwusenix', 'mangard', 'e', 'power', 'analysis', 'attack', 'reveal', 'secret', 'smart', 'card', 'science', 'business', 'medium', 'vol', 'moradi', 'schneider', 'leakage', 'detection', 'x2t', 'iacr', 'transaction', 'cryptographic', 'hardware', 'embed', 'de', 'system', 'pp', 'w', 'otter', 'survey', 'usage', 'deep', 'learning', 'natural', 'language', 'processing', 'ieee', 'transaction', 'neural', 'network', 'learn', 'system', 'vol', 'pp', 'paszke', 'gross', 'massa', 'lerer', 'bradbury', 'cryptographer', 'track', 'rsa', 'conference', 'pro', 'ceeding', 'springer', 'pp', 'n', 'veyratcharvillon', 'medwe', 'kerckhof', 'standaert', 'shuffle', 'sidechannel', 'tack', 'comprehensive', 'study', 'cautionary', 'note', 'advance', 'cryptology', '18th', 'inter', 'national', 'conference', 'theory', 'application', 'cryptology', 'information', 'security', 'proceeding', 'springer', 'pp', '740–757', 'cache', 'telepa', 'leverage', 'share', 'resource', 'attack', 'learn', 'architecture', 'usenix', 'security', 'pp', 'binarize', 'extraction', 'ito', 'bhasin', 'neural', 'network', 'architecture', 'secret', 'parameter', 'use', 'information', 'symposium', 'circuit', 'daegu', 'ieee', 'online', 'available', 'https', 'ito', 'bhasin', 'jap', 'extraction', 'binarize', 'neural', 'network', 'tecture', 'secret', 'parameter', 'use', 'sidechannel', 'mation', 'ieee', 'international', 'symposium', 'circuit', 'system', 'pp', 'system', 'pp', 'okura', 'fujino', 'model', 'reverseengineere', 'attack', 'use', 'correlation', 'power', 'analysis', 'systolic', 'array', 'base', 'neural', 'network', 'accelerator', 'ieee', 'international', 'symposium', 'circuit', 'system', 'pp', 'killeen', 'antiga', 'desmaison', 'kopf', 'tejani', 'chilamkurthy', 'bai', 'chintala', 'pytorch', 'imperative', 'style', 'highperformance', 'deep', 'learn', 'library', 'advance', 'neural', 'information', 'processing', 'system', 'pp', 'online', 'available', 'http', 'e', 'prouff', 'rivain', 'mask', 'side', 'channel', 'attack', 'formal', 'security', 'proof', 'advance', 'cryptology', 'eurocrypt', '32nd', 'annual', 'inter', 'national', 'conference', 'theory', 'application', 'cryptographic', 'technique', 'greece', 'proceeding', 'springer', 'pp', 'h', 'purwin', 'virtanen', 'j', 'sy', 'sainath', 'deep', 'learning', 'audio', 'signal', 'pro', 'cesse', 'ieee', 'journal', 'select', 'topic', 'signal', 'processing', 'vol', 'pp', 'jj', 'quisquater', 'samyde', 'electromagnetic', 'analysis', 'measure', 'countermeasure', 'smard', 'card', 'smart', 'card', 'programming', 'se', 'curity', 'esmart', 'ser', 'lecture', 'note', 'computer', 'attali', 'ed', 'vol', 'pp', 'stella', 'deep', 'state', 'space', 'model', 'time', 'series', 'forecasting', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'bhasin', 'pour', 'ay', 'din', 'aysu', 'natale', 'p', 'franzon', 'hely', 'machine', 'learning', 'hardware', 'se', 'curity', 'challenge', 'opportunity', 'international', 'conference', 'computeraide', 'design', 'pp', 'sagheer', 'time', 'series', 'forecasting', 'petroleum', 'production', 'use', 'deep', 'lstm', 'recurrent', 'net', 'work', 'neurocompute', 'vol', 'pp', 'deepar', 'probabilistic', 'forecasting', 'autoregressive', 'recurrent', 'network', 'international', 'journal', 'forecasting', 'vol', 'pp', 'salina', 'flunkert', 'schneider', 'moradi', 'leakage', 'assessment', 'methodology', 'international', 'workshop', 'crypto', 'graphic', 'hardware', 'embed', 'system', 'springer', 'pp', 'silver', 'guez', 'lanctot', 'l', 'sifre', 'graepel', 'master', 'chess', 'shogi', 'self', 'play', 'general', 'reinforcement', 'learning', 'arxiv', 'preprint', 'arxiv171201815', 'zisserman', 'deep', 'lutional', 'network', 'largescale', 'image', 'recognition', 'arxiv', 'preprint', 'j', 'witteman', 'bakker', 'improve', 'differential', 'power', 'analysis', 'elastic', 'align', 'ment', 'topic', 'cryptology', 'ctrsa']"
"BarraCUDA: Bringing Electromagnetic Side Channel Into Play to Steal the
  Weights of Neural Networks from NVIDIA GPUs","[{'href': 'http://arxiv.org/abs/2312.07783v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2312.07783v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-12-12 22:57:06,"A Reliable Representation with Bidirectional Transition Model for Visual
Reinforcement Learning Generalization

Xiaobo Hu1, Youfang Lin1, Yue Liu1, Jinwen Wang1, Shuo Wang1, Hehe Fan2 and Kai Lv1,
1Beijing Jiaotong University 2Zhejiang University
xiaobohu@bjtu.edu.cn,
yflin@bjtu.edu.cn,liuyue@bjtu.edu.cn,jwwang@bjtu.edu.cn,shuo.wang@bjtu.edu.cn,hehefan@zju.edu.cn, lvkai@bjtu.edu.cn

3
2
0
2
c
e
D
4

]

V
C
.
s
c
[

1
v
5
1
9
1
0
.
2
1
3
2
:
v
i
X
r
a

Abstract

Visual reinforcement learning has proven effective in solving
control tasks with high-dimensional observations. However,
extracting reliable and generalizable representations from
vision-based observations remains a central challenge. In-
spired by the human thought process, when the representation
extracted from the observation can predict the future and trace
history, the representation is reliable and accurate in com-
prehending the environment. Based on this concept, we in-
troduce a Bidirectional Transition (BiT) model, which lever-
ages the ability to bidirectionally predict environmental tran-
sitions both forward and backward to extract reliable repre-
sentations. Our model demonstrates competitive generaliza-
tion performance and sample efficiency on two settings of the
DeepMind Control suite. Additionally, we utilize robotic ma-
nipulation and CARLA simulators to demonstrate the wide
applicability of our method.

Introduction
Visual Reinforcement Learning (Visual RL) is an active re-
search field and focuses on learning optimal control policies
from high-dimensional image inputs. Visual RL has shown
remarkable success in various applications, including video
games (Mnih et al. 2013), robotic manipulation (Levine et al.
2016), and autonomous navigation (Hu et al. 2023). How-
ever, generalizing the learned policies to novel environments
with visual changes remains a significant challenge (Cobbe
et al. 2019; Zhang et al. 2018).

Recent studies have achieved significant progress in
the generalization task by utilizing self-supervised meth-
ods (Grill et al. 2020; Laskin, Srinivas, and Abbeel 2020).
These methods design specific auxiliary tasks to imbue the
representation with certain properties (Hansen and Wang
2021), resulting in effective generalization. Similarly, we fo-
cus on designing auxiliary tasks to extract representations
for the generalization of visual reinforcement learning.

The auxiliary task in our method is to predict bidirectional
environment transitions, aiding the agent in extracting more
reliable representations. The intuition behind our method
is that representations with strong environmental transition
properties can better comprehend the context information
and provide more reliable support for decision-making. In
Figure 1, we draw parallels to the human thought process.
When humans encounter a perplexing decision-making sit-
uation and struggle to accurately assess their current state,

Figure 1: The basic idea of our method. When humans
encounter a perplexing situation, they usually conduct both
backward and forward environmental transition analysis. A
successful analysis indicates trustworthy comprehension of
the current environment, while a failed analysis suggests un-
reliable environmental understanding.

they often ask themselves two crucial questions: “Where did
I come from?” and “Where am I going?”. If they can suc-
cessfully trace back history and predict the future based on
the current situation, they will have a reliable comprehen-
sion of their current state, facilitating dependable decisions.
Conversely, if they cannot backtrack and deduce, it means a
lack of proper comprehension of the situation, and making
decisions based on this incorrect comprehension would also
be unreliable.

Inspired by the above human thought, we propose a
Bidirectional Transition (BiT) model to extract reliable rep-
resentations from image observations for policy learning.
Specifically, we first design a feature extractor to generate
representations of visual observations. Then, we propose a
bidirectional transition learner that considers both forward
and backward transition predictions. To avoid trivial solu-
tions, our approach includes an action prediction module
within the bidirectional transition learner. Learning repre-
sentation with BiT is independent of vision-based reinforce-
ment learning methods and can be utilized with any policy
learner. In this paper, we implement the standard Soft Actor-
Critic (SAC) (Haarnoja et al. 2018) as the policy learner.

We employ two distinct configurations of the DeepMind
Control suite (DMControl) (Tassa et al. 2018; Hansen and
Wang 2021) to validate the generalization ability and sample

""Where did I come from?"" 
""Where am I going?""

Backward

Forward

−1



+1

−1



+1

Reliable

Time



Backward

Forward

Unreliable

−1



+1

 
 
 
 
 
 
efficiency of BiT. Additionally, we implement the robotic
manipulation simulator (Jangir et al. 2022) and driving sim-
ulator CARLA (Dosovitskiy et al. 2017) to illustrate the
wide applicability of our method. Extensive experiments
exhibit that BiT has superior generalization performance
and sample efficiency compared to previous state-of-the-art
methods. In summary, our contributions are threefold:

• We introduce the concept of utilizing predictions of back-
ward and forward transitions in visual RL for observation
comprehension, aligning with human intuition.

• We propose a Bidirectional Transition (BiT) model that
can assist the agent in obtaining stable and reliable rep-
resentations from the image observations.

• Extensive experimental results show that our method
achieves superior results with previous state-of-the-art
methods in generalization and sample efficiency.

Related Work
Data Augmentation in Visual RL
Data Augmentation has been demonstrated to significantly
improve the generalization of visual RL. Randomized con-
volution (Lee et al. 2020) is a simple technique to improve
the generalization ability of agents introducing a randomized
neural network to perturb input observations. RAD (Laskin
et al. 2020) compares different data augmentation meth-
ods and evidences their benefits in visual RL. DrQ (Yarats,
Kostrikov, and Fergus 2020) aggregates multiple image aug-
mentations, averaging the value functions and their targets.
UCB-DrAC (Raileanu et al. 2021) combines the previous
method with UCB (Auer 2002) and introduces three ap-
proaches for automatically finding an effective augmenta-
tion. SECANT (Fan et al. 2021) mentions the weak and
strong augmentations and shows their different effects on
the generalization task. CNSN (Li et al. 2023) proposes a
normalization technique without relying on prior knowledge
of the shift characteristics. CLOP (Bertoin and Rachelson
2022) introduces a novel regularization approach involving
channel-consistent local permutations to the feature maps.
Data augmentation has demonstrated significant efficacy in
enhancing generalization by leveraging prior knowledge as
an inductive bias for the agent (Ma et al. 2022).

Representation learning in Visual RL
Numerous approaches have been dedicated to learning im-
proved representations that can bridge the generalization gap
in visual RL. For example, DBC (Zhang et al. 2020) intro-
duces a bisimulation metric (Ferns, Panangaden, and Pre-
cup 2011) to learn robust representations. CURL (Laskin,
Srinivas, and Abbeel 2020) implements contrastive learning
(Chen et al. 2020) and data augmentations to learn repre-
sentation more efficiently. SVEA (Hansen, Su, and Wang
2021) identifies two problems rooted in high-variance Q-
targets and proposes a technique for stabilizing this vari-
ance under data augmentations. PAD (Hansen et al. 2021)
proposes a method that utilizes a self-supervision task to
allow the policy to continue training after deployment in
a novel environment without relying on any rewards. SPD

(Kim, Ha, and Kim 2022) designs a self-predictive dynam-
ics model as an auxiliary task to extract task-relevant fea-
tures efficiently. However, SPD exclusively focuses on for-
ward transition prediction, leading to the potential acquisi-
tion of unreliable state representations. We not only account
for predicting the forward transition but also consider the
backward transition. Our method can more effectively learn
the environmental contextual information to obtain a reliable
representation of observation.

Transition Models in RL

Previous RL methods achieve superior sample efficiency by
learning a transition model of the environment and plan-
ning their policy based on the model (Sutton and Barto
2018). These algorithms benefit from the trained forward
(Finn and Levine 2017) or backward transition model (Wang
et al. 2021) and also have better generalization. For example,
MOPO (Yu et al. 2020) proposes a modified method apply-
ing the existing transition models with rewards artificially
penalized by the uncertainty of the transitions. BMIL (Park
and Wong 2022) introduces a generative backward dynamics
model and generates short imagined trajectories from states
in the demonstrations. Inspired by these transition model
learning methods, we propose the bidirectional transition
model learning method in high-dimensional vision-based re-
inforcement learning tasks.

Preliminaries

Visual Reinforcement Learning

We formulate the interaction between the agent and envi-
ronment as a Partially Observable Markov Decision Process
(POMDP) (Kaelbling, Littman, and Cassandra 1998) M =
⟨S, O, A, P, r, γ⟩, where S is the state space, O is the high-
dimensional observation space (Mnih et al. 2013), A is the
action space, P(st+1|st, at) is the state transition function,
r : S×A (cid:55)→ R is the scalar reward function, and γ ∈ [0, 1) is
the discount factor. RL aims to train an agent policy πθ (·|s)
parameterized by θ and maximize the expected cumula-
(cid:105)
tive return J(θ) = Eat∼πθ(·|st),st∼P
,
where T is the horizon of the POMDP. In the visual gener-
alization setting, we expect the learned policy πθ to be well
generalized to novel environments with the same structure
as the original POMDP but with different observation space
˜O constructed from the same state space S.

t=0 γtr (st, at)

(cid:104)(cid:80)T

Environment Transition Model

The basic transition models in RL learn the environment
transition, and others also learn the reward function simulta-
neously. Categorized by the transfer direction, it can be di-
vided into the forward transition model pυ (st+1, rt|st, at)
and the backward transition model pν (st, rt|st+1, at) pa-
rameterized by υ and ν, respectively. The forward model
pυ represents the probability of the next state and corre-
sponding reward given the current state and action. Con-
versely, the backward model pν generates the probability
for the current state and reward by taking the next state

Figure 2: Overview of our model. We implement a feature extractor with a parallel architecture to generate distinct encoded
representations. For the bidirectional transition learner, there are three modules, i.e., the forward transition module Fυ, the
backward transition module Bν, and the action prediction module hψ. Our objective is to utilize the loss functions of the
bidirectional transition prediction to learn the encoder fφ for generating reliable representations.

and action as input. The reward function r (st, at) only de-
pends on the current state st and action at. So the for-
ward transition can be decomposed as pυ(st, rt|st+1, at) =
p(st+1|st, at)p(rt|st, at) and backward transition as well
(Lyu, Li, and Lu 2022). The maximizing of the log-
likelihood functions are as follows:

υ = E(st,at,rt,st+1)∼Denv [− log pυ(st+1, rt|st, at)],
Lf wd
(1)

ν = E(st,at,rt,st+1)∼Denv [− log pν(st, rt|st+1, at)],
Lbwd

(2)

where Denv is the sample dataset of the agent policy.

Method
We present a Bidirectional Transition (BiT) Model, depicted
in Figure 2 and described in Algorithm 1. Our approach en-
sures that the representation reliably comprehends the cur-
rent visual observation by leveraging predictions from a
bidirectional transition learner. Notably, our method pro-
vides an auxiliary representation learning task, effectively
assisting shared encoders’ updates to offer dependable rep-
resentations for reinforcement learning. BiT is a generic
model adaptable to various vision-based RL algorithms.

Overview
Our model aims to deliver a reliable and generalizable rep-
resentation from the input observation for the policy learner.
Figure 2 illustrates that BiT comprises a feature extractor
and a bidirectional transition learner. During training, we
introduce data augmentation to perturb image observations.
Subsequently, we leverage the feature extractor with a par-
allel architecture (Grill et al. 2020) to generate distinct en-
coded representations. The bidirectional transition learner
mainly consists of three parts: the forward transition mod-
ule Fυ, the backward transition module Bν, and an action
prediction module hψ. For the policy learner, we implement
the standard Soft Actor-Critic (SAC) (Haarnoja et al. 2018)
algorithm, sharing the encoder fφ and utilizing the unaug-
mented observations ot to learn the control policy. BiT and

Algorithm 1: Training Bidirectional Transition (BiT) Model

for update = 1, 2, ..., ω do

Sample batch of transitions (ot, at, rt, ot+1) ∼ B
Obtain features ˜zt, ˜zt+1 by fφ
Minimize LRL

1: θ, φ: initialize feature extractor parameters
2: ψ, υ, ν: initialize transition learner parameters
3: ω: RL updates per iteration
4: ϵ: momentum coefficient
5: for every iteration do
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18: Minimize LBiT
19:
20: end for

end for
Sample batch of observations ot, ot+1 ∼ B
Augment observations o′
t = Aug(ot)
Obtain online feature z′
t by fφ, gφ, qφ
Obtain target feature zt, zt+1 by fθ, gθ
Action prediction ˆa = hψ(z′
Forward transition prediction ˆzt+1 = Fυ(z′
Backward transition prediction ˆzt = Bν(ˆa, zt+1)

Update θ ← (1 − ϵ)θ + ϵφ

t, zt+1)

t, ˆa)

the policy learner are alternating training, as shown in Al-
gorithm 1. During testing, we only utilize the encoder fφ to
generate the representation ˜zt from the visual observation
ot and implement the policy learner to control the agent.

Feature Extractor
Given the input observation o ∈ RC×H×W, we employ the
feature extractor to acquire an encoded representation ˜z. Our
feature extractor comprises both an online branch and a tar-
get branch. The online branch encompasses three compo-
nents, i.e., a shared encoder fφ, a projection gφ, and a pre-
diction head qφ. Meanwhile, the target branch includes an
encoder fθ and a projection gθ, sharing the same structure
with the corresponding ones of the online branch.

Specifically, we sample the image observations ot and
ot+1 from the buffer B for every training step. We uti-

’
Augment


EMA


EMA



’

ℎ




Forward

+1




Feature Extractor


+1
Bidirectional Transition Learner



Backward

+1



：

action

ℒ

：





fwd
ℒ

+1

：

+1

bwd
ℒ

：stop-gradient





Loss Function

t = qφ(gφ(fφ(o′

lize data augmentation to perturb ot and produce an aug-
mented observation o′
t. Subsequently, we derive the corre-
sponding representation z′
t))) through en-
coding, projection, and prediction. Identically, we obtain the
corresponding representations zt and zt+1 using the target
branch: zt = gθ(fθ(ot)) and zt+1 = gθ(fθ(ot+1)). Dur-
ing training, the encoder fφ, projection gφ, and prediction
qφ are trained simultaneously by the bidirectional transition
learner’s total objective function LBiT. fφ is also optimized
by the policy learner’s objective function LRL. For θ, we
perform a stop-gradient operation to prevent parameters up-
date through gradient backpropagation. Specifically, we de-
fine the parameters θ as an Exponential Moving Average
(EMA) of φ, following the rule:

θn+1 ← (1 − ϵ)θn + ϵφn,
where ϵ ∈ (0, 1] is a momentum coefficient, and n is the iter-
ation step of the training process. This architecture enhances
expressiveness in the acquired representation, aligning with
prior studies (Chen et al. 2020; Grill et al. 2020).

(3)

Bidirectional Transition Learner
To obtain a reliable state representation of the current obser-
vation, we believe that the representation should be able to
forward predict future developments and backward trace his-
tories. We propose a bidirectional transition learner, where
representations generated by the feature extractor are uti-
lized to predict the environment’s forward and backward
transitions. This learner consists of three modules: a forward
transition module Fυ, a backward transition module Bν, and
an action prediction module hψ.

Specifically, we first establish an action prediction mod-
ule hψ to derive a pseudo action ˆa based on the input
state representations. The pseudo action is obtained as ˆa =
hψ(z′, zt+1), and the corresponding optimization objective
function is as follows:
Laction
ψ

= Eτ ∼Denv [∥ˆa − a∥2
2],

(4)

where Denv is the trajectory dataset of the agent, τ repre-
sents a transition (ot, at, rt, ot+1) sampled from Denv, and
∥·∥2
2 is the mean squared error. The action prediction module
assists the forward and backward transitions without falling
into the trivial solution and enhances the task-related infor-
mation of the representations.

After predicting the pseudo action ˆa, we feed it into the
forward and backward transition modules. Considering the
influence of sparse rewards on the representation learning
process, our transition model exclusively focuses on pre-
dicting state representation transitions without considering
reward function. Specifically, the forward transition mod-
ule Fυ utilizes the augmented representation z′ and the
pseudo action ˆa as inputs, outputting the predicted transi-
tion state representation ˆzt+1 at the next time. The process
is ˆzt+1 = Fυ(z′
t, ˆa), and the corresponding objective func-
tion is defined as follows:

υ = Eτ ∼Denv [∥ ˆzt+1 − zt+1∥2
Lfwd
2].
Conversely, the backward transition module Bν utilizes the
state representation zt+1 at the next step and pseudo action ˆa

(5)

to output the current state representation prediction ˆzt. The
process is expressed as ˆzt = Bν(ˆa, zt+1), and the objective
function is defined as follows:

(6)

ν = Eτ ∼Denv [∥ ˆzt − zt∥2
Lbwd
2].
Note that we do not predict environment transition in
the pixel space but in the compressed state representation
space. This approach enables the representation to circum-
vent the uncertainty of predicting pixels and prevents inter-
ference from task-independent areas within the pixel space.
We jointly optimize the bidirectional transition learner and
the above feature extractor with the total objective function
LBiT as follows:

LBiT = Lfwd

ν + Laction

υ + Lbwd
After optimizing the total objective function LBiT, the ex-
tracted representation will more precisely reflect the state
information of the agent, providing more reliable support for
correct decision-making.

(7)

ψ

.

Policy Learner
BiT is independent of the policy learner as an encoding rep-
resentation module and applies to any visual RL algorithm.
This paper implements a standard off-policy RL method
Soft Actor-Critic (SAC) (Haarnoja et al. 2018) as the policy
learner. Specifically, the unaugmented raw image observa-
tion ot is fed into the encoder fφ to output the representa-
tion ˜zt. Then, the policy learner utilizes ˜zt to train the policy.
As shown in Algorithm 1, the optimization of representation
learning LBiT is performed alternately with the optimiza-
tion of reinforcement learning LRL with ω steps. The two
optimization objectives jointly update the parameters of the
shared encoder fφ. We present a more detailed architecture
of SAC in the supplementary material.

Experiments
We validate the effectiveness of BiT with other state-of-the-
art methods on a wide spectrum of visual generalization
tasks. We mainly choose two configurations of the Deep-
Mind Control suite (DMControl) (Tassa et al. 2018; Hansen
and Wang 2021) to compare the generalization performance
and sample efficiency. We also perform ablation and aug-
mentation methods analysis to study BiT. Moreover, we im-
plement the robotic manipulation simulator (Jangir et al.
2022) and driving simulator CARLA (Dosovitskiy et al.
2017). More experiments details and results on CARLA are
in the supplementary material.

DMControl Environment
DMControl is a vision-based simulator offering a collection
of continuous control tasks. The generalization problem in
DMControl introduces visually distracting environments un-
related to reward signals for motor control tasks. To evaluate
the effectiveness of our method, we conduct experiments uti-
lizing two distinct settings to assess generalization capacity
and sample efficiency.

Generalization Setup. The training environment is with-
out background distractions, and the test environment has

Setting

Video Easy

Video Hard

Task
Walker Stand
Cartpole Swingup
Ball in cup Catch
Finger Spin
Reacher Easy
Walker Stand
Cartpole Swingup
Ball in cup Catch
Finger Spin
Reacher Easy

CURL
852±75
404±67
316±119
502±19
724±49
45±5
114±15
115±33
27±21
86±11

PAD
935±20
521±76
436±55
691±80
692±14
278±72
123±24
66±61
56±18
118±35

SODA
955±13
758±62
875±56
695±97
567±64
771±83
429±64
327±100
302±41
233±57

SVEA
961±8
782±27
871±106
808±33
294±43
834±76
393±45
403±174
335±58
236±56

TLDA
973±6
671±57
855±56
756±87
976±1
769±59
223±62
457±16
224±56
160±67

BiT
966±3
779±34
899±23
835±25
978±4
829±24
526±40
570±71
400±13
590±43

Table 1: Generalization Performance. We report the average episode return and corresponding variances over three different
seeds. These methods are trained on a distractor-free background and tested on different video distractor backgrounds. Our
algorithm attains state-of-the-art performance in most tasks while also delivering competitive results in others.

Figure 3: Examples of Generalization Setup. We uti-
lize three different background types, i.e., Distractor-free for
training, “Video Easy” and “Video Hard”. The data augmen-
tation in this environment is “random overlay”. There are
examples of the “Walker Stand” task.

Figure 4: Examples of Sample Efficiency Setup. We
choose two color configurations, namely “Gray” and
“Color”, for two video backgrounds: “Simple Distractor”
and “Natural Video”. There are examples of the “Cheetah
Run” task.

two video background interference settings of the DMCon-
trol Generalization Benchmark (DMControl-GB) (Hansen
and Wang 2021). The degree of video impact in the test
environment can be divided into “Video Easy” and “Video
Hard”. We verify the generalization of our method on five
tasks. We mainly consider the random overlay to augment
the image observation, which is also applied in the prior
methods. Samples from different environments are shown in
Figure 3. The comparison methods are as follows: (1) CURL
(Laskin, Srinivas, and Abbeel 2020) implements contrastive
learning and data augmentations; (2) PAD (Hansen et al.
2021) implies an auxiliary task for continuing training in a
novel environment; (3) SODA (Hansen and Wang 2021) uti-
lizes the BYOL-like (Grill et al. 2020) architecture to learn
the latent representation consistency; (4) SVEA (Hansen,
Su, and Wang 2021) proposes a technique for stabilizing
high-variance Q-targets. (5) TLDA (Yuan et al. 2022) re-
duces the interference of augmentation to the image. We run
3 random seeds and report the mean and standard deviation
of the episode return in Table 1.

Sample Efficiency Setup. We train our method us-
ing four interference settings and five tasks, following the
approach outlined in (Zhang et al. 2020), to assess the
anti-interference capability and sample efficiency during
training. Specifically, we employ two distinct video back-

grounds: “Simple Distractor” and “Natural Video”, along
with two color settings: “Gray” and “Color”. Examples from
different settings are shown in Figure 4. The testing and
training environment background settings are the same for
the sample efficiency assessment. Furthermore, we conduct
a generalization evaluation in this setup. We train methods
in the simple distractor background and compare their per-
formance in the novel natural video background.

For a fair comparison of the method’s inherent general-
ization ability rather than the impact of the data augmenta-
tion technique, we implement the same data augmentation
method as SPD. We apply weak and strong augmentation
methods to the image observations, respectively. In this sec-
tion, we compare our approach with CURL, SODA, PAD,
and other new methods as follows: SAC (Haarnoja et al.
2018) is a standard off-policy RL algorithm. DrQ (Yarats,
Kostrikov, and Fergus 2020) incorporates multiple image
transformations. SPD (Kim, Ha, and Kim 2022) employs a
self-predictive forward dynamics approach to efficiently ex-
tract task-relevant features. The comparative results are car-
ried out utilizing 3 random seeds and reported in Table 2.

Generalization Performance. The results in distraction-
free background training and evaluation with video distrac-
tors in five DMControl-GB tasks are presented in Table 1.

Simple

Video

Simple

Video

(a) Gray

(b) Color

Training

Random Overlay

Video Easy

Video Hard

Simple

Video

Simple

Video

(a) Gray

(b) Color

Training

Random Overlay

Video Easy

Video Hard

Gray

Task

SAC

PAD

CURL

SODA

230±20
399±25
92±6
107±1
37±5

335±1
656±47
74±28
409±45
917±12

304±24
735±33
86±44
286±50
869±12

301±33
689±27
125±87
287±160
862±2

DrQ
(a) Sample Efficiency (training and testing on Simple Distractor)
272±31
Cheetah Run
665±27
Finger Spin
92±32
Hopper Hop
230±47
Reacher Easy
Walker Walk
494±105
(b) Sample Efficiency (training and testing on Natural Video)
Cheetah Run
Finger Spin
Hopper Hop
Reacher Easy
Walker Walk
(c) Generalization (training on Simple Distractor but testing on Natural Video)
Cheetah Run
Finger Spin
Hopper Hop
Reacher Easy
Walker Walk

118±38
227±147
10±5
414±107
812±52

64±20
205±145
0±0
90±15
104±43

171±114
3±2
1±1
104±21
73±8

298±19
690±28
113±68
274±158
835±1

229±18
653±39
59±32
160±28
754±25

190±31
647±44
43±24
287±47
408±35

219±25
661±27
81±30
158±20
271±82

74±31
59±40
0±0
80±5
404±47

136±22
289±12
33±7
100±2
33±2

51±18
125±27
15±5
109±4
58±17

SPD

334±3
984±1
153±6
646±107
895±7

330±26
983±1
164±14
574±62
896±18

329±6
893±30
135±6
432±119
855±16

Color

BiT

SPD

BiT

349±26
983±1
234±20
953±36
917±59

411±13
712±2
41±15
633±73
947±5

331±36
974±19
197±18
844±19
927±4

317±25
981±4
181±74
590±170
927±18

81±47
171±25
18±15
190±152
571±163

174±39
113±75
22±2
170±43
634±34

333±42
977±11
138±7
778±101
928±24

387±200
728±180
70±37
605±237
654±173

306±32
983±2
138±1
860±31
876±31

Table 2: Sample Efficiency and Generalization Performance. We report the average episode return and corresponding vari-
ances for over three seeds. We train methods on “Simple Distractor” and “Natural Video”. We evaluate methods on the same
background for sample efficiency experiments and also assess methods training on Simple Distractor on novel Natural Video
for generalization experiments. Our method achieves state-of-the-art results on most tasks, particularly in the more challenging
setting, “Color Natural Video”.

Our method excels in most tasks, achieving optimal values
in 7 out of 10 tasks and suboptimal values in the remaining
3 tasks. In contrast, alternative algorithms, such as SODA,
SVEA, or TLDA, only exhibit superior performance in a
few specific tasks, lacking the capability to achieve opti-
mal results across the majority of tasks. The representations
learned by our method enable a correct and reliable compre-
hension of environmental observations and effectively gen-
eralize to novel environments. As evidenced in Table 2 (c),
even when trained in the presence of noisy backgrounds,
BiT retains the capacity to acquire a dependable comprehen-
sion of the environment, showcasing robust generalization
skills. Our model consistently outperforms state-of-the-art
algorithms across all tasks that were trained on the simple
distractor background and then generalized to the natural
video background. In contrast, other algorithms frequently
struggle to learn reliable representations and effective poli-
cies when confronted with interfering backgrounds.

Sample efficiency Performance. As presented in Table
1 (a) and (b), the training and test environments are iden-
tical, and we compare the training sample efficiency. Our
method surpasses other baselines on 7 out of 10 tasks in
the context of the “Simple Distractor” background. Further-
more, BiT outperforms other baselines on 8 out of 10 tasks
when considering the “Natural Video” background. Notably,
BiT attains state-of-the-art performance on the particularly
challenging task: “Color” and “Natural Video” background
distraction. Specifically analyzing SPD, its generalization
ability significantly diminishes when changing the training

environment from gray to color. This disparity can be at-
tributed to the fact that SPD employs forward transition
for representation learning, thereby hindered by the uncer-
tainties inherent to unidirectional transfer predictions. Con-
sequently, SPD fails to furnish stable representations con-
ducive to policy learning. In contrast, our bidirectional tran-
sition learner simultaneously encompasses both forward and
backward transition modules as auxiliary tasks. This bidirec-
tional approach substantially mitigates the instability of rep-
resentation learning and provides a dependable state repre-
sentation, thus enhancing the efficacy of agent policy learn-
ing. As a result, our model demonstrates superior sample ef-
ficiency and enhanced generalization capability. In the sup-
plementary material, we further compare the learning curve
with the SPD algorithm to analyze the sample efficiency.

Ablation Study. We conduct ablation experiments on
the DMControl-GB task to verify the roles of each objec-
tive function in our bidirectional transition learner, as shown
in Figure 5 (a). We chose the “Cartpole Swingup” task un-
der the “Video Easy” background. “BiT w/o fwd” indicates
the absence of a forward transition module, while “BiT w/o
bwd” signifies the omission of a backward transition mod-
ule. “BiT w/o action” implies the exclusion of an action pre-
diction module, and “BiT only action” suggests the presence
of only the action prediction module within the bidirectional
transition learner. The term “Baseline” refers to a degraded
version of our model, lacking the proposed objective func-
tion but including data augmentation.

Figure 5 shows that BiT yields the best generalization ef-

Method

Reach

Peg in box

Environment
test 1
test 2
test 3
test 4
test 5
Avg
test 1
test 2
test 3
test 4
test 5
Avg

SAC
-29±16
-26±21
-41±15
-23±23
-39±11
-32±17
-55±8
-62±11
-53±6
-61±11
-66±21
-59±11

SODA
-28±28
-31±18
-35±15
-37±22
-55±14
-37±19
-16±76
-10±68
-1±91
-27±81
-87±50
-28±73

SVEA
-39±25
-7±36
-16±36
-5±32
-49±23
-23±30
-40±47
18±67
16±33
48±60
-51±42
-2±50

BiT
-9±18
-3±21
-28±30
-27±34
-25±23
-18±25
-16±57
27±43
55±52
72±48
1±59
28±52

Table 3: Performance on the robotic environments. We
report the average return and variance for each task and their
mean. Our algorithm excels in most tasks, demonstrating the
wide applicability of our model.

fectively acquires a stable and generalizable representation
through data augmentation. Moreover, BiT has a larger per-
formance gain utilizing the “random overlay”. It is because
the “random overlay” produces texture increases that better
match the video background than the color distractions in-
duced by a “random convolution”.

Visualization of Attention Map. We choose two tasks
in the generalization setting: “Walker Stand” and “Cartpole
Swingup”, to show the attention maps of BiT on differ-
ent backgrounds, i.e., “distracting-free”, “Video Easy” and
“Video Hard”. The results in Figure 6 show that BiT can
clearly perceive the task-related regions in the image obser-
vation, regardless of the presence or absence of background
interference. In this way, BiT provides a reliable and correct
representation of the image observation for the agent to learn
a generalizable policy.

Robotic Manipulation Environment
To demonstrate the wide applicability of our method, we im-
plement two tasks from the vision-based robotic manipula-
tion simulator (Jangir et al. 2022). We train agents on the de-
fault background and validate them on five testing environ-
ments. The test environments are similar to the training ones
but with different colors and textures for the background.
The evaluated algorithms include SAC, SODA, and SVEA,
with the corresponding results presented in Table 3. Exper-
imental results demonstrate that BiT can well generalize in
robotic training domain novel environments.

Conclusion
In this paper, we introduce a Bidirectional Transition
(BiT) Model to aid agents in extracting reliable and well-
generalized representations from visual observations. The
BiT method utilizes the bidirectional transition prediction
objectives to ensure the agent accurately comprehends vi-
sual observations. Our method demonstrates competitive
generalization and sample efficiency on various benchmark
tasks, including the DeepMind Control suite, robotic manip-
ulation simulators, and driving simulator CARLA.

Figure 5: Left: Ablation Study. In Figure (a), we analyze
the effectiveness of each constraint objective. Right: Dif-
ferent Augmentation Methods. In Figure (b), we assess the
impact of data augmentation.

Figure 6: Attention Maps of BiT. We show the attention
maps of BiT on the different backgrounds of tasks “Walker
walk” and “Cartpole Swingup”.

fect and sample efficiency. We found that adding forward
or backward transition prediction separately on action pre-
diction also improves performance, but the enhancement is
insignificant. That is because of the unidirectional transition
prediction’s inherent instability, and the agent might lead to
a biased comprehension of the observation. In contrast, bidi-
rectional prediction helps the agent with a more stable state
representation and mitigates the uncertainty of observational
comprehension by concurrently predicting both forward and
backward transition. This principle aligns with the prior
works (Lai et al. 2020; Lyu, Li, and Lu 2022). Moreover,
omitting the action prediction module cause the learned rep-
resentation to lack task-related information and easily fall
into a trivial solution. Overall, the result demonstrates that
each module in BiT plays a significant and effective role.

Study of Different Augmentation Methods. We analyze
the effects of different data augmentations for the model,
i.e., “random overlay,” “random convolution,” and “without
augmentation”. We conduct a comparison with the base SAC
algorithm. The task setting is the same as the ablation study
section, and the results are depicted in Figure 5 (b).

The results demonstrate that our model achieves substan-
tial improvements over the SAC, both with and without data
augmentation. With data augmentation, the SAC algorithm
struggles to acquire a stable representation due to the in-
creased diversity in the samples. Consequently, its ability
to improve generalization is limited, and in some cases, it
even results in performance degradation. In contrast, BiT ef-

(a) Ablation Study

(b) Different Augmentation Methods

Walker
Stand

Cartpole
Swingup

Training

Video Easy

Video Hard

References
Auer, P. 2002. Using confidence bounds for exploitation-
exploration trade-offs. Journal of Machine Learning Re-
search, 3(Nov): 397–422.
Bertoin, D.; and Rachelson, E. 2022. Local Feature Swap-
ping for Generalization in Reinforcement Learning. In The
Tenth International Conference on Learning Representa-
tions, ICLR 2022, Virtual Event, April 25-29, 2022. Open-
Review.net.
Chen, T.; Kornblith, S.; Norouzi, M.; and Hinton, G. 2020.
A simple framework for contrastive learning of visual repre-
sentations. In International conference on machine learning,
1597–1607. PMLR.
Cobbe, K.; Klimov, O.; Hesse, C.; Kim, T.; and Schulman, J.
2019. Quantifying generalization in reinforcement learning.
In International Conference on Machine Learning, 1282–
1289. PMLR.
Dosovitskiy, A.; Ros, G.; Codevilla, F.; Lopez, A.; and
Koltun, V. 2017. CARLA: An open urban driving simula-
tor. In Conference on robot learning, 1–16. PMLR.
Fan, L.; Wang, G.; Huang, D.-A.; Yu, Z.; Fei-Fei, L.; Zhu,
Y.; and Anandkumar, A. 2021.
SECANT: Self-Expert
Cloning for Zero-Shot Generalization of Visual Policies. In
Meila, M.; and Zhang, T., eds., Proceedings of the 38th In-
ternational Conference on Machine Learning, volume 139
of Proceedings of Machine Learning Research, 3088–3099.
PMLR.
Ferns, N.; Panangaden, P.; and Precup, D. 2011. Bisim-
ulation metrics for continuous Markov decision processes.
SIAM Journal on Computing, 40(6): 1662–1714.
Finn, C.; and Levine, S. 2017. Deep visual foresight for
In 2017 IEEE International Con-
planning robot motion.
ference on Robotics and Automation (ICRA), 2786–2793.
IEEE.
Grill, J.-B.; Strub, F.; Altch´e, F.; Tallec, C.; Richemond,
P.; Buchatskaya, E.; Doersch, C.; Avila Pires, B.; Guo, Z.;
Gheshlaghi Azar, M.; et al. 2020. Bootstrap your own latent-
a new approach to self-supervised learning. Advances in
neural information processing systems, 33: 21271–21284.
Haarnoja, T.; Zhou, A.; Abbeel, P.; and Levine, S. 2018.
Soft actor-critic: Off-policy maximum entropy deep rein-
forcement learning with a stochastic actor. In International
conference on machine learning, 1861–1870. PMLR.
Hansen, N.; Jangir, R.; Sun, Y.; Aleny`a, G.; Abbeel, P.;
Efros, A. A.; Pinto, L.; and Wang, X. 2021. Self-Supervised
Policy Adaptation during Deployment. In 9th International
Conference on Learning Representations, ICLR 2021, Vir-
tual Event, Austria, May 3-7, 2021. OpenReview.net.
Hansen, N.; Su, H.; and Wang, X. 2021. Stabilizing deep
q-learning with convnets and vision transformers under data
augmentation. Advances in neural information processing
systems, 34: 3680–3693.
Hansen, N.; and Wang, X. 2021. Generalization in rein-
In 2021
forcement learning by soft data augmentation.
IEEE International Conference on Robotics and Automation
(ICRA), 13611–13617. IEEE.

Hu, X.; Lin, Y.; Wang, S.; Wu, Z.; and Lv, K. 2023. Agent-
Centric Relation Graph for Object Visual Navigation. IEEE
Transactions on Circuits and Systems for Video Technology,
1–1.
Jangir, R.; Hansen, N.; Ghosal, S.; Jain, M.; and Wang, X.
2022. Look closer: Bridging egocentric and third-person
IEEE
views with transformers for robotic manipulation.
Robotics and Automation Letters, 7(2): 3046–3053.
Kaelbling, L. P.; Littman, M. L.; and Cassandra, A. R. 1998.
Planning and acting in partially observable stochastic do-
mains. Artificial intelligence, 101(1-2): 99–134.
Kim, K.; Ha, J.; and Kim, Y. 2022. Self-Predictive Dy-
namics for Generalization of Vision-based Reinforcement
Learning. In IJCAI International Joint Conference on Ar-
tificial Intelligence, 3150–3156. International Joint Confer-
ences on Artificial Intelligence.
Lai, H.; Shen, J.; Zhang, W.; and Yu, Y. 2020. Bidirectional
model-based policy optimization. In International Confer-
ence on Machine Learning, 5618–5627. PMLR.
Laskin, M.; Lee, K.; Stooke, A.; Pinto, L.; Abbeel, P.; and
Srinivas, A. 2020. Reinforcement learning with augmented
data. Advances in neural information processing systems,
33: 19884–19895.
Curl:
Laskin, M.; Srinivas, A.; and Abbeel, P. 2020.
Contrastive unsupervised representations for reinforcement
learning. In International Conference on Machine Learning,
5639–5650. PMLR.
Lee, K.; Lee, K.; Shin, J.; and Lee, H. 2020. Network Ran-
domization: A Simple Technique for Generalization in Deep
In 8th International Conference
Reinforcement Learning.
on Learning Representations, ICLR 2020, Addis Ababa,
Ethiopia, April 26-30, 2020. OpenReview.net.
Levine, S.; Finn, C.; Darrell, T.; and Abbeel, P. 2016. End-
to-end training of deep visuomotor policies. The Journal of
Machine Learning Research, 17(1): 1334–1373.
Li, L.; Lyu, J.; Ma, G.; Wang, Z.; Yang, Z.; Li, X.; and Li,
Z. 2023. Normalization Enhances Generalization in Visual
Reinforcement Learning. arXiv preprint arXiv:2306.00656.
Lyu, J.; Li, X.; and Lu, Z. 2022. Double Check Your State
Before Trusting It: Confidence-Aware Bidirectional Offline
Model-Based Imagination. Advances in Neural Information
Processing Systems, 35: 38218–38231.
Ma, G.; Wang, Z.; Yuan, Z.; Wang, X.; Yuan, B.; and
Tao, D. 2022. A comprehensive survey of data augmen-
arXiv preprint
tation in visual reinforcement learning.
arXiv:2210.04561.
Mnih, V.; Kavukcuoglu, K.; Silver, D.; Graves, A.;
Antonoglou, I.; Wierstra, D.; and Riedmiller, M. 2013. Play-
ing atari with deep reinforcement learning. arXiv preprint
arXiv:1312.5602.
Park, J. Y.; and Wong, L. 2022. Robust Imitation of a Few
Demonstrations with a Backwards Model.
In Koyejo, S.;
Mohamed, S.; Agarwal, A.; Belgrave, D.; Cho, K.; and Oh,
A., eds., Advances in Neural Information Processing Sys-
tems, volume 35, 19759–19772. Curran Associates, Inc.

Raileanu, R.; Goldstein, M.; Yarats, D.; Kostrikov, I.; and
Fergus, R. 2021. Automatic data augmentation for general-
ization in reinforcement learning. Advances in Neural Infor-
mation Processing Systems, 34: 5402–5415.
Sutton, R. S.; and Barto, A. G. 2018. Reinforcement learn-
ing: An introduction. MIT press.
Tassa, Y.; Doron, Y.; Muldal, A.; Erez, T.; Li, Y.; Casas, D.
d. L.; Budden, D.; Abdolmaleki, A.; Merel, J.; Lefrancq,
A.; et al. 2018. Deepmind control suite. arXiv preprint
arXiv:1801.00690.
Wang, J.; Li, W.; Jiang, H.; Zhu, G.; Li, S.; and Zhang, C.
2021. Offline reinforcement learning with reverse model-
based imagination. Advances in Neural Information Pro-
cessing Systems, 34: 29420–29432.
Yarats, D.; Kostrikov, I.; and Fergus, R. 2020. Image aug-
mentation is all you need: Regularizing deep reinforcement
learning from pixels. In International conference on learn-
ing representations.
Yu, T.; Thomas, G.; Yu, L.; Ermon, S.; Zou, J. Y.; Levine,
S.; Finn, C.; and Ma, T. 2020. Mopo: Model-based offline
policy optimization. Advances in Neural Information Pro-
cessing Systems, 33: 14129–14142.
Yuan, Z.; Ma, G.; Mu, Y.; Xia, B.; Yuan, B.; Wang, X.; Luo,
P.; and Xu, H. 2022. Don’t Touch What Matters: Task-
Aware Lipschitz Data Augmentation for Visual Reinforce-
In Raedt, L. D., ed., Proceedings of the
ment Learning.
Thirty-First International Joint Conference on Artificial In-
telligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022,
3702–3708. ijcai.org.
Zhang, A.; McAllister, R.; Calandra, R.; Gal, Y.; and
Levine, S. 2020. Learning invariant representations for re-
inforcement learning without reconstruction. arXiv preprint
arXiv:2006.10742.
Zhang, C.; Vinyals, O.; Munos, R.; and Bengio, S. 2018. A
study on overfitting in deep reinforcement learning. arXiv
preprint arXiv:1804.06893.

","A Reliable Representation with Bidirectional Transition Model for Visual Reinforcement Learning Generalization Xiaobo Hu1 , Youfang Lin1 , Yue Liu1 , Jinwen Wang1 , Shuo Wang1 , Hehe Fan2 and Kai Lv1 , 1Beijing Jiaotong University 2Zhejiang University xiaobohu @ bjtu.edu.cn , yflin @ bjtu.edu.cn , liuyue @ bjtu.edu.cn , jwwang @ bjtu.edu.cn , shuo.wang @ bjtu.edu.cn , hehefan @ zju.edu.cn , lvkai @ bjtu.edu.cn 3 2 0 2 c e D 4 ] V C . s c [ 1 v 5 1 9 1 0 . 2 1 3 2 : v i X r a Abstract Visual reinforcement learning has proven effective in solving control tasks with high-dimensional observations . However , extracting reliable and generalizable representations from vision-based observations remains a central challenge . In- spired by the human thought process , when the representation extracted from the observation can predict the future and trace history , the representation is reliable and accurate in com- prehending the environment . Based on this concept , we in- troduce a Bidirectional Transition ( BiT ) model , which lever- ages the ability to bidirectionally predict environmental tran- sitions both forward and backward to extract reliable repre- sentations . Our model demonstrates competitive generaliza- tion performance and sample efficiency on two settings of the DeepMind Control suite . Additionally , we utilize robotic ma- nipulation and CARLA simulators to demonstrate the wide applicability of our method . Introduction Visual Reinforcement Learning ( Visual RL ) is an active re- search field and focuses on learning optimal control policies from high-dimensional image inputs . Visual RL has shown remarkable success in various applications , including video games ( Mnih et al . 2013 ) , robotic manipulation ( Levine et al . 2016 ) , and autonomous navigation ( Hu et al . 2023 ) . How- ever , generalizing the learned policies to novel environments with visual changes remains a significant challenge ( Cobbe et al . 2019 ; Zhang et al . 2018 ) . Recent studies have achieved significant progress in the generalization task by utilizing self-supervised meth- ods ( Grill et al . 2020 ; Laskin , Srinivas , and Abbeel 2020 ) . These methods design specific auxiliary tasks to imbue the representation with certain properties ( Hansen and Wang 2021 ) , resulting in effective generalization . Similarly , we fo- cus on designing auxiliary tasks to extract representations for the generalization of visual reinforcement learning . The auxiliary task in our method is to predict bidirectional environment transitions , aiding the agent in extracting more reliable representations . The intuition behind our method is that representations with strong environmental transition properties can better comprehend the context information and provide more reliable support for decision-making . In Figure 1 , we draw parallels to the human thought process . When humans encounter a perplexing decision-making sit- uation and struggle to accurately assess their current state , Figure 1 : The basic idea of our method . When humans encounter a perplexing situation , they usually conduct both backward and forward environmental transition analysis . A successful analysis indicates trustworthy comprehension of the current environment , while a failed analysis suggests un- reliable environmental understanding . they often ask themselves two crucial questions : “ Where did I come from ? ” and “ Where am I going ? ” . If they can suc- cessfully trace back history and predict the future based on the current situation , they will have a reliable comprehen- sion of their current state , facilitating dependable decisions . Conversely , if they can not backtrack and deduce , it means a lack of proper comprehension of the situation , and making decisions based on this incorrect comprehension would also be unreliable . Inspired by the above human thought , we propose a Bidirectional Transition ( BiT ) model to extract reliable rep- resentations from image observations for policy learning . Specifically , we first design a feature extractor to generate representations of visual observations . Then , we propose a bidirectional transition learner that considers both forward and backward transition predictions . To avoid trivial solu- tions , our approach includes an action prediction module within the bidirectional transition learner . Learning repre- sentation with BiT is independent of vision-based reinforce- ment learning methods and can be utilized with any policy learner . In this paper , we implement the standard Soft Actor- Critic ( SAC ) ( Haarnoja et al . 2018 ) as the policy learner . We employ two distinct configurations of the DeepMind Control suite ( DMControl ) ( Tassa et al . 2018 ; Hansen and Wang 2021 ) to validate the generalization ability and sample `` Where did I come from ? '' `` Where am I going ? '' Backward Forward −1 +1 −1 +1 Reliable Time Backward Forward Unreliable −1 +1 efficiency of BiT . Additionally , we implement the robotic manipulation simulator ( Jangir et al . 2022 ) and driving sim- ulator CARLA ( Dosovitskiy et al . 2017 ) to illustrate the wide applicability of our method . Extensive experiments exhibit that BiT has superior generalization performance and sample efficiency compared to previous state-of-the-art methods . In summary , our contributions are threefold : • We introduce the concept of utilizing predictions of back- ward and forward transitions in visual RL for observation comprehension , aligning with human intuition . • We propose a Bidirectional Transition ( BiT ) model that can assist the agent in obtaining stable and reliable rep- resentations from the image observations . • Extensive experimental results show that our method achieves superior results with previous state-of-the-art methods in generalization and sample efficiency . Related Work Data Augmentation in Visual RL Data Augmentation has been demonstrated to significantly improve the generalization of visual RL . Randomized con- volution ( Lee et al . 2020 ) is a simple technique to improve the generalization ability of agents introducing a randomized neural network to perturb input observations . RAD ( Laskin et al . 2020 ) compares different data augmentation meth- ods and evidences their benefits in visual RL . DrQ ( Yarats , Kostrikov , and Fergus 2020 ) aggregates multiple image aug- mentations , averaging the value functions and their targets . UCB-DrAC ( Raileanu et al . 2021 ) combines the previous method with UCB ( Auer 2002 ) and introduces three ap- proaches for automatically finding an effective augmenta- tion . SECANT ( Fan et al . 2021 ) mentions the weak and strong augmentations and shows their different effects on the generalization task . CNSN ( Li et al . 2023 ) proposes a normalization technique without relying on prior knowledge of the shift characteristics . CLOP ( Bertoin and Rachelson 2022 ) introduces a novel regularization approach involving channel-consistent local permutations to the feature maps . Data augmentation has demonstrated significant efficacy in enhancing generalization by leveraging prior knowledge as an inductive bias for the agent ( Ma et al . 2022 ) . Representation learning in Visual RL Numerous approaches have been dedicated to learning im- proved representations that can bridge the generalization gap in visual RL . For example , DBC ( Zhang et al . 2020 ) intro- duces a bisimulation metric ( Ferns , Panangaden , and Pre- cup 2011 ) to learn robust representations . CURL ( Laskin , Srinivas , and Abbeel 2020 ) implements contrastive learning ( Chen et al . 2020 ) and data augmentations to learn repre- sentation more efficiently . SVEA ( Hansen , Su , and Wang 2021 ) identifies two problems rooted in high-variance Q- targets and proposes a technique for stabilizing this vari- ance under data augmentations . PAD ( Hansen et al . 2021 ) proposes a method that utilizes a self-supervision task to allow the policy to continue training after deployment in a novel environment without relying on any rewards . SPD ( Kim , Ha , and Kim 2022 ) designs a self-predictive dynam- ics model as an auxiliary task to extract task-relevant fea- tures efficiently . However , SPD exclusively focuses on for- ward transition prediction , leading to the potential acquisi- tion of unreliable state representations . We not only account for predicting the forward transition but also consider the backward transition . Our method can more effectively learn the environmental contextual information to obtain a reliable representation of observation . Transition Models in RL Previous RL methods achieve superior sample efficiency by learning a transition model of the environment and plan- ning their policy based on the model ( Sutton and Barto 2018 ) . These algorithms benefit from the trained forward ( Finn and Levine 2017 ) or backward transition model ( Wang et al . 2021 ) and also have better generalization . For example , MOPO ( Yu et al . 2020 ) proposes a modified method apply- ing the existing transition models with rewards artificially penalized by the uncertainty of the transitions . BMIL ( Park and Wong 2022 ) introduces a generative backward dynamics model and generates short imagined trajectories from states in the demonstrations . Inspired by these transition model learning methods , we propose the bidirectional transition model learning method in high-dimensional vision-based re- inforcement learning tasks . Preliminaries Visual Reinforcement Learning We formulate the interaction between the agent and envi- ronment as a Partially Observable Markov Decision Process ( POMDP ) ( Kaelbling , Littman , and Cassandra 1998 ) M = ⟨S , O , A , P , r , γ⟩ , where S is the state space , O is the high- dimensional observation space ( Mnih et al . 2013 ) , A is the action space , P ( st+1|st , at ) is the state transition function , r : S×A ( cid:55 ) → R is the scalar reward function , and γ ∈ [ 0 , 1 ) is the discount factor . RL aims to train an agent policy πθ ( ·|s ) parameterized by θ and maximize the expected cumula- ( cid:105 ) tive return J ( θ ) = Eat∼πθ ( ·|st ) , st∼P , where T is the horizon of the POMDP . In the visual gener- alization setting , we expect the learned policy πθ to be well generalized to novel environments with the same structure as the original POMDP but with different observation space ˜O constructed from the same state space S. t=0 γtr ( st , at ) ( cid:104 ) ( cid:80 ) T Environment Transition Model The basic transition models in RL learn the environment transition , and others also learn the reward function simulta- neously . Categorized by the transfer direction , it can be di- vided into the forward transition model pυ ( st+1 , rt|st , at ) and the backward transition model pν ( st , rt|st+1 , at ) pa- rameterized by υ and ν , respectively . The forward model pυ represents the probability of the next state and corre- sponding reward given the current state and action . Con- versely , the backward model pν generates the probability for the current state and reward by taking the next state Figure 2 : Overview of our model . We implement a feature extractor with a parallel architecture to generate distinct encoded representations . For the bidirectional transition learner , there are three modules , i.e. , the forward transition module Fυ , the backward transition module Bν , and the action prediction module hψ . Our objective is to utilize the loss functions of the bidirectional transition prediction to learn the encoder fφ for generating reliable representations . and action as input . The reward function r ( st , at ) only de- pends on the current state st and action at . So the for- ward transition can be decomposed as pυ ( st , rt|st+1 , at ) = p ( st+1|st , at ) p ( rt|st , at ) and backward transition as well ( Lyu , Li , and Lu 2022 ) . The maximizing of the log- likelihood functions are as follows : υ = E ( st , at , rt , st+1 ) ∼Denv [ − log pυ ( st+1 , rt|st , at ) ] , Lf wd ( 1 ) ν = E ( st , at , rt , st+1 ) ∼Denv [ − log pν ( st , rt|st+1 , at ) ] , Lbwd ( 2 ) where Denv is the sample dataset of the agent policy . Method We present a Bidirectional Transition ( BiT ) Model , depicted in Figure 2 and described in Algorithm 1 . Our approach en- sures that the representation reliably comprehends the cur- rent visual observation by leveraging predictions from a bidirectional transition learner . Notably , our method pro- vides an auxiliary representation learning task , effectively assisting shared encoders ’ updates to offer dependable rep- resentations for reinforcement learning . BiT is a generic model adaptable to various vision-based RL algorithms . Overview Our model aims to deliver a reliable and generalizable rep- resentation from the input observation for the policy learner . Figure 2 illustrates that BiT comprises a feature extractor and a bidirectional transition learner . During training , we introduce data augmentation to perturb image observations . Subsequently , we leverage the feature extractor with a par- allel architecture ( Grill et al . 2020 ) to generate distinct en- coded representations . The bidirectional transition learner mainly consists of three parts : the forward transition mod- ule Fυ , the backward transition module Bν , and an action prediction module hψ . For the policy learner , we implement the standard Soft Actor-Critic ( SAC ) ( Haarnoja et al . 2018 ) algorithm , sharing the encoder fφ and utilizing the unaug- mented observations ot to learn the control policy . BiT and Algorithm 1 : Training Bidirectional Transition ( BiT ) Model for update = 1 , 2 , ... , ω do Sample batch of transitions ( ot , at , rt , ot+1 ) ∼ B Obtain features ˜zt , ˜zt+1 by fφ Minimize LRL 1 : θ , φ : initialize feature extractor parameters 2 : ψ , υ , ν : initialize transition learner parameters 3 : ω : RL updates per iteration 4 : ϵ : momentum coefficient 5 : for every iteration do 6 : 7 : 8 : 9 : 10 : 11 : 12 : 13 : 14 : 15 : 16 : 17 : 18 : Minimize LBiT 19 : 20 : end for end for Sample batch of observations ot , ot+1 ∼ B Augment observations o′ t = Aug ( ot ) Obtain online feature z′ t by fφ , gφ , qφ Obtain target feature zt , zt+1 by fθ , gθ Action prediction ˆa = hψ ( z′ Forward transition prediction ˆzt+1 = Fυ ( z′ Backward transition prediction ˆzt = Bν ( ˆa , zt+1 ) Update θ ← ( 1 − ϵ ) θ + ϵφ t , zt+1 ) t , ˆa ) the policy learner are alternating training , as shown in Al- gorithm 1 . During testing , we only utilize the encoder fφ to generate the representation ˜zt from the visual observation ot and implement the policy learner to control the agent . Feature Extractor Given the input observation o ∈ RC×H×W , we employ the feature extractor to acquire an encoded representation ˜z . Our feature extractor comprises both an online branch and a tar- get branch . The online branch encompasses three compo- nents , i.e. , a shared encoder fφ , a projection gφ , and a pre- diction head qφ . Meanwhile , the target branch includes an encoder fθ and a projection gθ , sharing the same structure with the corresponding ones of the online branch . Specifically , we sample the image observations ot and ot+1 from the buffer B for every training step . We uti- ’ Augment EMA EMA ’ ℎ Forward +1 Feature Extractor +1 Bidirectional Transition Learner Backward +1 ： action ℒ ： fwd ℒ +1 ： +1 bwd ℒ ：stop-gradient Loss Function t = qφ ( gφ ( fφ ( o′ lize data augmentation to perturb ot and produce an aug- mented observation o′ t. Subsequently , we derive the corre- sponding representation z′ t ) ) ) through en- coding , projection , and prediction . Identically , we obtain the corresponding representations zt and zt+1 using the target branch : zt = gθ ( fθ ( ot ) ) and zt+1 = gθ ( fθ ( ot+1 ) ) . Dur- ing training , the encoder fφ , projection gφ , and prediction qφ are trained simultaneously by the bidirectional transition learner ’ s total objective function LBiT . fφ is also optimized by the policy learner ’ s objective function LRL . For θ , we perform a stop-gradient operation to prevent parameters up- date through gradient backpropagation . Specifically , we de- fine the parameters θ as an Exponential Moving Average ( EMA ) of φ , following the rule : θn+1 ← ( 1 − ϵ ) θn + ϵφn , where ϵ ∈ ( 0 , 1 ] is a momentum coefficient , and n is the iter- ation step of the training process . This architecture enhances expressiveness in the acquired representation , aligning with prior studies ( Chen et al . 2020 ; Grill et al . 2020 ) . ( 3 ) Bidirectional Transition Learner To obtain a reliable state representation of the current obser- vation , we believe that the representation should be able to forward predict future developments and backward trace his- tories . We propose a bidirectional transition learner , where representations generated by the feature extractor are uti- lized to predict the environment ’ s forward and backward transitions . This learner consists of three modules : a forward transition module Fυ , a backward transition module Bν , and an action prediction module hψ . Specifically , we first establish an action prediction mod- ule hψ to derive a pseudo action ˆa based on the input state representations . The pseudo action is obtained as ˆa = hψ ( z′ , zt+1 ) , and the corresponding optimization objective function is as follows : Laction ψ = Eτ ∼Denv [ ∥ˆa − a∥2 2 ] , ( 4 ) where Denv is the trajectory dataset of the agent , τ repre- sents a transition ( ot , at , rt , ot+1 ) sampled from Denv , and ∥·∥2 2 is the mean squared error . The action prediction module assists the forward and backward transitions without falling into the trivial solution and enhances the task-related infor- mation of the representations . After predicting the pseudo action ˆa , we feed it into the forward and backward transition modules . Considering the influence of sparse rewards on the representation learning process , our transition model exclusively focuses on pre- dicting state representation transitions without considering reward function . Specifically , the forward transition mod- ule Fυ utilizes the augmented representation z′ and the pseudo action ˆa as inputs , outputting the predicted transi- tion state representation ˆzt+1 at the next time . The process is ˆzt+1 = Fυ ( z′ t , ˆa ) , and the corresponding objective func- tion is defined as follows : υ = Eτ ∼Denv [ ∥ ˆzt+1 − zt+1∥2 Lfwd 2 ] . Conversely , the backward transition module Bν utilizes the state representation zt+1 at the next step and pseudo action ˆa ( 5 ) to output the current state representation prediction ˆzt . The process is expressed as ˆzt = Bν ( ˆa , zt+1 ) , and the objective function is defined as follows : ( 6 ) ν = Eτ ∼Denv [ ∥ ˆzt − zt∥2 Lbwd 2 ] . Note that we do not predict environment transition in the pixel space but in the compressed state representation space . This approach enables the representation to circum- vent the uncertainty of predicting pixels and prevents inter- ference from task-independent areas within the pixel space . We jointly optimize the bidirectional transition learner and the above feature extractor with the total objective function LBiT as follows : LBiT = Lfwd ν + Laction υ + Lbwd After optimizing the total objective function LBiT , the ex- tracted representation will more precisely reflect the state information of the agent , providing more reliable support for correct decision-making . ( 7 ) ψ . Policy Learner BiT is independent of the policy learner as an encoding rep- resentation module and applies to any visual RL algorithm . This paper implements a standard off-policy RL method Soft Actor-Critic ( SAC ) ( Haarnoja et al . 2018 ) as the policy learner . Specifically , the unaugmented raw image observa- tion ot is fed into the encoder fφ to output the representa- tion ˜zt . Then , the policy learner utilizes ˜zt to train the policy . As shown in Algorithm 1 , the optimization of representation learning LBiT is performed alternately with the optimiza- tion of reinforcement learning LRL with ω steps . The two optimization objectives jointly update the parameters of the shared encoder fφ . We present a more detailed architecture of SAC in the supplementary material . Experiments We validate the effectiveness of BiT with other state-of-the- art methods on a wide spectrum of visual generalization tasks . We mainly choose two configurations of the Deep- Mind Control suite ( DMControl ) ( Tassa et al . 2018 ; Hansen and Wang 2021 ) to compare the generalization performance and sample efficiency . We also perform ablation and aug- mentation methods analysis to study BiT . Moreover , we im- plement the robotic manipulation simulator ( Jangir et al . 2022 ) and driving simulator CARLA ( Dosovitskiy et al . 2017 ) . More experiments details and results on CARLA are in the supplementary material . DMControl Environment DMControl is a vision-based simulator offering a collection of continuous control tasks . The generalization problem in DMControl introduces visually distracting environments un- related to reward signals for motor control tasks . To evaluate the effectiveness of our method , we conduct experiments uti- lizing two distinct settings to assess generalization capacity and sample efficiency . Generalization Setup . The training environment is with- out background distractions , and the test environment has Setting Video Easy Video Hard Task Walker Stand Cartpole Swingup Ball in cup Catch Finger Spin Reacher Easy Walker Stand Cartpole Swingup Ball in cup Catch Finger Spin Reacher Easy CURL 852±75 404±67 316±119 502±19 724±49 45±5 114±15 115±33 27±21 86±11 PAD 935±20 521±76 436±55 691±80 692±14 278±72 123±24 66±61 56±18 118±35 SODA 955±13 758±62 875±56 695±97 567±64 771±83 429±64 327±100 302±41 233±57 SVEA 961±8 782±27 871±106 808±33 294±43 834±76 393±45 403±174 335±58 236±56 TLDA 973±6 671±57 855±56 756±87 976±1 769±59 223±62 457±16 224±56 160±67 BiT 966±3 779±34 899±23 835±25 978±4 829±24 526±40 570±71 400±13 590±43 Table 1 : Generalization Performance . We report the average episode return and corresponding variances over three different seeds . These methods are trained on a distractor-free background and tested on different video distractor backgrounds . Our algorithm attains state-of-the-art performance in most tasks while also delivering competitive results in others . Figure 3 : Examples of Generalization Setup . We uti- lize three different background types , i.e. , Distractor-free for training , “ Video Easy ” and “ Video Hard ” . The data augmen- tation in this environment is “ random overlay ” . There are examples of the “ Walker Stand ” task . Figure 4 : Examples of Sample Efficiency Setup . We choose two color configurations , namely “ Gray ” and “ Color ” , for two video backgrounds : “ Simple Distractor ” and “ Natural Video ” . There are examples of the “ Cheetah Run ” task . two video background interference settings of the DMCon- trol Generalization Benchmark ( DMControl-GB ) ( Hansen and Wang 2021 ) . The degree of video impact in the test environment can be divided into “ Video Easy ” and “ Video Hard ” . We verify the generalization of our method on five tasks . We mainly consider the random overlay to augment the image observation , which is also applied in the prior methods . Samples from different environments are shown in Figure 3 . The comparison methods are as follows : ( 1 ) CURL ( Laskin , Srinivas , and Abbeel 2020 ) implements contrastive learning and data augmentations ; ( 2 ) PAD ( Hansen et al . 2021 ) implies an auxiliary task for continuing training in a novel environment ; ( 3 ) SODA ( Hansen and Wang 2021 ) uti- lizes the BYOL-like ( Grill et al . 2020 ) architecture to learn the latent representation consistency ; ( 4 ) SVEA ( Hansen , Su , and Wang 2021 ) proposes a technique for stabilizing high-variance Q-targets . ( 5 ) TLDA ( Yuan et al . 2022 ) re- duces the interference of augmentation to the image . We run 3 random seeds and report the mean and standard deviation of the episode return in Table 1 . Sample Efficiency Setup . We train our method us- ing four interference settings and five tasks , following the approach outlined in ( Zhang et al . 2020 ) , to assess the anti-interference capability and sample efficiency during training . Specifically , we employ two distinct video back- grounds : “ Simple Distractor ” and “ Natural Video ” , along with two color settings : “ Gray ” and “ Color ” . Examples from different settings are shown in Figure 4 . The testing and training environment background settings are the same for the sample efficiency assessment . Furthermore , we conduct a generalization evaluation in this setup . We train methods in the simple distractor background and compare their per- formance in the novel natural video background . For a fair comparison of the method ’ s inherent general- ization ability rather than the impact of the data augmenta- tion technique , we implement the same data augmentation method as SPD . We apply weak and strong augmentation methods to the image observations , respectively . In this sec- tion , we compare our approach with CURL , SODA , PAD , and other new methods as follows : SAC ( Haarnoja et al . 2018 ) is a standard off-policy RL algorithm . DrQ ( Yarats , Kostrikov , and Fergus 2020 ) incorporates multiple image transformations . SPD ( Kim , Ha , and Kim 2022 ) employs a self-predictive forward dynamics approach to efficiently ex- tract task-relevant features . The comparative results are car- ried out utilizing 3 random seeds and reported in Table 2 . Generalization Performance . The results in distraction- free background training and evaluation with video distrac- tors in five DMControl-GB tasks are presented in Table 1 . Simple Video Simple Video ( a ) Gray ( b ) Color Training Random Overlay Video Easy Video Hard Simple Video Simple Video ( a ) Gray ( b ) Color Training Random Overlay Video Easy Video Hard Gray Task SAC PAD CURL SODA 230±20 399±25 92±6 107±1 37±5 335±1 656±47 74±28 409±45 917±12 304±24 735±33 86±44 286±50 869±12 301±33 689±27 125±87 287±160 862±2 DrQ ( a ) Sample Efficiency ( training and testing on Simple Distractor ) 272±31 Cheetah Run 665±27 Finger Spin 92±32 Hopper Hop 230±47 Reacher Easy Walker Walk 494±105 ( b ) Sample Efficiency ( training and testing on Natural Video ) Cheetah Run Finger Spin Hopper Hop Reacher Easy Walker Walk ( c ) Generalization ( training on Simple Distractor but testing on Natural Video ) Cheetah Run Finger Spin Hopper Hop Reacher Easy Walker Walk 118±38 227±147 10±5 414±107 812±52 64±20 205±145 0±0 90±15 104±43 171±114 3±2 1±1 104±21 73±8 298±19 690±28 113±68 274±158 835±1 229±18 653±39 59±32 160±28 754±25 190±31 647±44 43±24 287±47 408±35 219±25 661±27 81±30 158±20 271±82 74±31 59±40 0±0 80±5 404±47 136±22 289±12 33±7 100±2 33±2 51±18 125±27 15±5 109±4 58±17 SPD 334±3 984±1 153±6 646±107 895±7 330±26 983±1 164±14 574±62 896±18 329±6 893±30 135±6 432±119 855±16 Color BiT SPD BiT 349±26 983±1 234±20 953±36 917±59 411±13 712±2 41±15 633±73 947±5 331±36 974±19 197±18 844±19 927±4 317±25 981±4 181±74 590±170 927±18 81±47 171±25 18±15 190±152 571±163 174±39 113±75 22±2 170±43 634±34 333±42 977±11 138±7 778±101 928±24 387±200 728±180 70±37 605±237 654±173 306±32 983±2 138±1 860±31 876±31 Table 2 : Sample Efficiency and Generalization Performance . We report the average episode return and corresponding vari- ances for over three seeds . We train methods on “ Simple Distractor ” and “ Natural Video ” . We evaluate methods on the same background for sample efficiency experiments and also assess methods training on Simple Distractor on novel Natural Video for generalization experiments . Our method achieves state-of-the-art results on most tasks , particularly in the more challenging setting , “ Color Natural Video ” . Our method excels in most tasks , achieving optimal values in 7 out of 10 tasks and suboptimal values in the remaining 3 tasks . In contrast , alternative algorithms , such as SODA , SVEA , or TLDA , only exhibit superior performance in a few specific tasks , lacking the capability to achieve opti- mal results across the majority of tasks . The representations learned by our method enable a correct and reliable compre- hension of environmental observations and effectively gen- eralize to novel environments . As evidenced in Table 2 ( c ) , even when trained in the presence of noisy backgrounds , BiT retains the capacity to acquire a dependable comprehen- sion of the environment , showcasing robust generalization skills . Our model consistently outperforms state-of-the-art algorithms across all tasks that were trained on the simple distractor background and then generalized to the natural video background . In contrast , other algorithms frequently struggle to learn reliable representations and effective poli- cies when confronted with interfering backgrounds . Sample efficiency Performance . As presented in Table 1 ( a ) and ( b ) , the training and test environments are iden- tical , and we compare the training sample efficiency . Our method surpasses other baselines on 7 out of 10 tasks in the context of the “ Simple Distractor ” background . Further- more , BiT outperforms other baselines on 8 out of 10 tasks when considering the “ Natural Video ” background . Notably , BiT attains state-of-the-art performance on the particularly challenging task : “ Color ” and “ Natural Video ” background distraction . Specifically analyzing SPD , its generalization ability significantly diminishes when changing the training environment from gray to color . This disparity can be at- tributed to the fact that SPD employs forward transition for representation learning , thereby hindered by the uncer- tainties inherent to unidirectional transfer predictions . Con- sequently , SPD fails to furnish stable representations con- ducive to policy learning . In contrast , our bidirectional tran- sition learner simultaneously encompasses both forward and backward transition modules as auxiliary tasks . This bidirec- tional approach substantially mitigates the instability of rep- resentation learning and provides a dependable state repre- sentation , thus enhancing the efficacy of agent policy learn- ing . As a result , our model demonstrates superior sample ef- ficiency and enhanced generalization capability . In the sup- plementary material , we further compare the learning curve with the SPD algorithm to analyze the sample efficiency . Ablation Study . We conduct ablation experiments on the DMControl-GB task to verify the roles of each objec- tive function in our bidirectional transition learner , as shown in Figure 5 ( a ) . We chose the “ Cartpole Swingup ” task un- der the “ Video Easy ” background . “ BiT w/o fwd ” indicates the absence of a forward transition module , while “ BiT w/o bwd ” signifies the omission of a backward transition mod- ule . “ BiT w/o action ” implies the exclusion of an action pre- diction module , and “ BiT only action ” suggests the presence of only the action prediction module within the bidirectional transition learner . The term “ Baseline ” refers to a degraded version of our model , lacking the proposed objective func- tion but including data augmentation . Figure 5 shows that BiT yields the best generalization ef- Method Reach Peg in box Environment test 1 test 2 test 3 test 4 test 5 Avg test 1 test 2 test 3 test 4 test 5 Avg SAC -29±16 -26±21 -41±15 -23±23 -39±11 -32±17 -55±8 -62±11 -53±6 -61±11 -66±21 -59±11 SODA -28±28 -31±18 -35±15 -37±22 -55±14 -37±19 -16±76 -10±68 -1±91 -27±81 -87±50 -28±73 SVEA -39±25 -7±36 -16±36 -5±32 -49±23 -23±30 -40±47 18±67 16±33 48±60 -51±42 -2±50 BiT -9±18 -3±21 -28±30 -27±34 -25±23 -18±25 -16±57 27±43 55±52 72±48 1±59 28±52 Table 3 : Performance on the robotic environments . We report the average return and variance for each task and their mean . Our algorithm excels in most tasks , demonstrating the wide applicability of our model . fectively acquires a stable and generalizable representation through data augmentation . Moreover , BiT has a larger per- formance gain utilizing the “ random overlay ” . It is because the “ random overlay ” produces texture increases that better match the video background than the color distractions in- duced by a “ random convolution ” . Visualization of Attention Map . We choose two tasks in the generalization setting : “ Walker Stand ” and “ Cartpole Swingup ” , to show the attention maps of BiT on differ- ent backgrounds , i.e. , “ distracting-free ” , “ Video Easy ” and “ Video Hard ” . The results in Figure 6 show that BiT can clearly perceive the task-related regions in the image obser- vation , regardless of the presence or absence of background interference . In this way , BiT provides a reliable and correct representation of the image observation for the agent to learn a generalizable policy . Robotic Manipulation Environment To demonstrate the wide applicability of our method , we im- plement two tasks from the vision-based robotic manipula- tion simulator ( Jangir et al . 2022 ) . We train agents on the de- fault background and validate them on five testing environ- ments . The test environments are similar to the training ones but with different colors and textures for the background . The evaluated algorithms include SAC , SODA , and SVEA , with the corresponding results presented in Table 3 . Exper- imental results demonstrate that BiT can well generalize in robotic training domain novel environments . Conclusion In this paper , we introduce a Bidirectional Transition ( BiT ) Model to aid agents in extracting reliable and well- generalized representations from visual observations . The BiT method utilizes the bidirectional transition prediction objectives to ensure the agent accurately comprehends vi- sual observations . Our method demonstrates competitive generalization and sample efficiency on various benchmark tasks , including the DeepMind Control suite , robotic manip- ulation simulators , and driving simulator CARLA . Figure 5 : Left : Ablation Study . In Figure ( a ) , we analyze the effectiveness of each constraint objective . Right : Dif- ferent Augmentation Methods . In Figure ( b ) , we assess the impact of data augmentation . Figure 6 : Attention Maps of BiT . We show the attention maps of BiT on the different backgrounds of tasks “ Walker walk ” and “ Cartpole Swingup ” . fect and sample efficiency . We found that adding forward or backward transition prediction separately on action pre- diction also improves performance , but the enhancement is insignificant . That is because of the unidirectional transition prediction ’ s inherent instability , and the agent might lead to a biased comprehension of the observation . In contrast , bidi- rectional prediction helps the agent with a more stable state representation and mitigates the uncertainty of observational comprehension by concurrently predicting both forward and backward transition . This principle aligns with the prior works ( Lai et al . 2020 ; Lyu , Li , and Lu 2022 ) . Moreover , omitting the action prediction module cause the learned rep- resentation to lack task-related information and easily fall into a trivial solution . Overall , the result demonstrates that each module in BiT plays a significant and effective role . Study of Different Augmentation Methods . We analyze the effects of different data augmentations for the model , i.e. , “ random overlay , ” “ random convolution , ” and “ without augmentation ” . We conduct a comparison with the base SAC algorithm . The task setting is the same as the ablation study section , and the results are depicted in Figure 5 ( b ) . The results demonstrate that our model achieves substan- tial improvements over the SAC , both with and without data augmentation . With data augmentation , the SAC algorithm struggles to acquire a stable representation due to the in- creased diversity in the samples . Consequently , its ability to improve generalization is limited , and in some cases , it even results in performance degradation . In contrast , BiT ef- ( a ) Ablation Study ( b ) Different Augmentation Methods Walker Stand Cartpole Swingup Training Video Easy Video Hard References Auer , P. 2002 . Using confidence bounds for exploitation- exploration trade-offs . Journal of Machine Learning Re- search , 3 ( Nov ) : 397–422 . Bertoin , D. ; and Rachelson , E. 2022 . Local Feature Swap- ping for Generalization in Reinforcement Learning . In The Tenth International Conference on Learning Representa- tions , ICLR 2022 , Virtual Event , April 25-29 , 2022 . Open- Review.net . Chen , T. ; Kornblith , S. ; Norouzi , M. ; and Hinton , G. 2020 . A simple framework for contrastive learning of visual repre- sentations . In International conference on machine learning , 1597–1607 . PMLR . Cobbe , K. ; Klimov , O. ; Hesse , C. ; Kim , T. ; and Schulman , J . 2019 . Quantifying generalization in reinforcement learning . In International Conference on Machine Learning , 1282– 1289 . PMLR . Dosovitskiy , A. ; Ros , G. ; Codevilla , F. ; Lopez , A. ; and Koltun , V. 2017 . CARLA : An open urban driving simula- tor . In Conference on robot learning , 1–16 . PMLR . Fan , L. ; Wang , G. ; Huang , D.-A . ; Yu , Z. ; Fei-Fei , L. ; Zhu , Y. ; and Anandkumar , A . 2021 . SECANT : Self-Expert Cloning for Zero-Shot Generalization of Visual Policies . In Meila , M. ; and Zhang , T. , eds. , Proceedings of the 38th In- ternational Conference on Machine Learning , volume 139 of Proceedings of Machine Learning Research , 3088–3099 . PMLR . Ferns , N. ; Panangaden , P. ; and Precup , D. 2011 . Bisim- ulation metrics for continuous Markov decision processes . SIAM Journal on Computing , 40 ( 6 ) : 1662–1714 . Finn , C. ; and Levine , S. 2017 . Deep visual foresight for In 2017 IEEE International Con- planning robot motion . ference on Robotics and Automation ( ICRA ) , 2786–2793 . IEEE . Grill , J.-B . ; Strub , F. ; Altch´e , F. ; Tallec , C. ; Richemond , P. ; Buchatskaya , E. ; Doersch , C. ; Avila Pires , B. ; Guo , Z. ; Gheshlaghi Azar , M. ; et al . 2020 . Bootstrap your own latent- a new approach to self-supervised learning . Advances in neural information processing systems , 33 : 21271–21284 . Haarnoja , T. ; Zhou , A. ; Abbeel , P. ; and Levine , S. 2018 . Soft actor-critic : Off-policy maximum entropy deep rein- forcement learning with a stochastic actor . In International conference on machine learning , 1861–1870 . PMLR . Hansen , N. ; Jangir , R. ; Sun , Y. ; Aleny ` a , G. ; Abbeel , P. ; Efros , A . A. ; Pinto , L. ; and Wang , X . 2021 . Self-Supervised Policy Adaptation during Deployment . In 9th International Conference on Learning Representations , ICLR 2021 , Vir- tual Event , Austria , May 3-7 , 2021 . OpenReview.net . Hansen , N. ; Su , H. ; and Wang , X . 2021 . Stabilizing deep q-learning with convnets and vision transformers under data augmentation . Advances in neural information processing systems , 34 : 3680–3693 . Hansen , N. ; and Wang , X . 2021 . Generalization in rein- In 2021 forcement learning by soft data augmentation . IEEE International Conference on Robotics and Automation ( ICRA ) , 13611–13617 . IEEE . Hu , X. ; Lin , Y. ; Wang , S. ; Wu , Z. ; and Lv , K. 2023 . Agent- Centric Relation Graph for Object Visual Navigation . IEEE Transactions on Circuits and Systems for Video Technology , 1–1 . Jangir , R. ; Hansen , N. ; Ghosal , S. ; Jain , M. ; and Wang , X . 2022 . Look closer : Bridging egocentric and third-person IEEE views with transformers for robotic manipulation . Robotics and Automation Letters , 7 ( 2 ) : 3046–3053 . Kaelbling , L. P. ; Littman , M. L. ; and Cassandra , A. R. 1998 . Planning and acting in partially observable stochastic do- mains . Artificial intelligence , 101 ( 1-2 ) : 99–134 . Kim , K. ; Ha , J. ; and Kim , Y . 2022 . Self-Predictive Dy- namics for Generalization of Vision-based Reinforcement Learning . In IJCAI International Joint Conference on Ar- tificial Intelligence , 3150–3156 . International Joint Confer- ences on Artificial Intelligence . Lai , H. ; Shen , J. ; Zhang , W. ; and Yu , Y . 2020 . Bidirectional model-based policy optimization . In International Confer- ence on Machine Learning , 5618–5627 . PMLR . Laskin , M. ; Lee , K. ; Stooke , A. ; Pinto , L. ; Abbeel , P. ; and Srinivas , A . 2020 . Reinforcement learning with augmented data . Advances in neural information processing systems , 33 : 19884–19895 . Curl : Laskin , M. ; Srinivas , A. ; and Abbeel , P. 2020 . Contrastive unsupervised representations for reinforcement learning . In International Conference on Machine Learning , 5639–5650 . PMLR . Lee , K. ; Lee , K. ; Shin , J. ; and Lee , H. 2020 . Network Ran- domization : A Simple Technique for Generalization in Deep In 8th International Conference Reinforcement Learning . on Learning Representations , ICLR 2020 , Addis Ababa , Ethiopia , April 26-30 , 2020 . OpenReview.net . Levine , S. ; Finn , C. ; Darrell , T. ; and Abbeel , P. 2016 . End- to-end training of deep visuomotor policies . The Journal of Machine Learning Research , 17 ( 1 ) : 1334–1373 . Li , L. ; Lyu , J. ; Ma , G. ; Wang , Z. ; Yang , Z. ; Li , X. ; and Li , Z . 2023 . Normalization Enhances Generalization in Visual Reinforcement Learning . arXiv preprint arXiv:2306.00656 . Lyu , J. ; Li , X. ; and Lu , Z . 2022 . Double Check Your State Before Trusting It : Confidence-Aware Bidirectional Offline Model-Based Imagination . Advances in Neural Information Processing Systems , 35 : 38218–38231 . Ma , G. ; Wang , Z. ; Yuan , Z. ; Wang , X. ; Yuan , B. ; and Tao , D. 2022 . A comprehensive survey of data augmen- arXiv preprint tation in visual reinforcement learning . arXiv:2210.04561 . Mnih , V. ; Kavukcuoglu , K. ; Silver , D. ; Graves , A. ; Antonoglou , I. ; Wierstra , D. ; and Riedmiller , M. 2013 . Play- ing atari with deep reinforcement learning . arXiv preprint arXiv:1312.5602 . Park , J. Y. ; and Wong , L. 2022 . Robust Imitation of a Few Demonstrations with a Backwards Model . In Koyejo , S. ; Mohamed , S. ; Agarwal , A. ; Belgrave , D. ; Cho , K. ; and Oh , A. , eds. , Advances in Neural Information Processing Sys- tems , volume 35 , 19759–19772 . Curran Associates , Inc. Raileanu , R. ; Goldstein , M. ; Yarats , D. ; Kostrikov , I. ; and Fergus , R. 2021 . Automatic data augmentation for general- ization in reinforcement learning . Advances in Neural Infor- mation Processing Systems , 34 : 5402–5415 . Sutton , R. S. ; and Barto , A. G. 2018 . Reinforcement learn- ing : An introduction . MIT press . Tassa , Y. ; Doron , Y. ; Muldal , A. ; Erez , T. ; Li , Y. ; Casas , D. d. L. ; Budden , D. ; Abdolmaleki , A. ; Merel , J. ; Lefrancq , A. ; et al . 2018 . Deepmind control suite . arXiv preprint arXiv:1801.00690 . Wang , J. ; Li , W. ; Jiang , H. ; Zhu , G. ; Li , S. ; and Zhang , C. 2021 . Offline reinforcement learning with reverse model- based imagination . Advances in Neural Information Pro- cessing Systems , 34 : 29420–29432 . Yarats , D. ; Kostrikov , I. ; and Fergus , R. 2020 . Image aug- mentation is all you need : Regularizing deep reinforcement learning from pixels . In International conference on learn- ing representations . Yu , T. ; Thomas , G. ; Yu , L. ; Ermon , S. ; Zou , J. Y. ; Levine , S. ; Finn , C. ; and Ma , T. 2020 . Mopo : Model-based offline policy optimization . Advances in Neural Information Pro- cessing Systems , 33 : 14129–14142 . Yuan , Z. ; Ma , G. ; Mu , Y. ; Xia , B. ; Yuan , B. ; Wang , X. ; Luo , P. ; and Xu , H. 2022 . Don ’ t Touch What Matters : Task- Aware Lipschitz Data Augmentation for Visual Reinforce- In Raedt , L. D. , ed. , Proceedings of the ment Learning . Thirty-First International Joint Conference on Artificial In- telligence , IJCAI 2022 , Vienna , Austria , 23-29 July 2022 , 3702–3708 . ijcai.org . Zhang , A. ; McAllister , R. ; Calandra , R. ; Gal , Y. ; and Levine , S. 2020 . Learning invariant representations for re- inforcement learning without reconstruction . arXiv preprint arXiv:2006.10742 . Zhang , C. ; Vinyals , O. ; Munos , R. ; and Bengio , S. 2018 . A study on overfitting in deep reinforcement learning . arXiv preprint arXiv:1804.06893 .","['reliable', 'representation', 'bidirectional', 'transition', 'model', 'visual', 'reinforcement', 'learning', 'generalization', '1beije', 'jiaotong', 'university', 'bjtueducn', 'liuyue', 'hehefan', 'bjtueducn', 'c', 'e', 'c', 'c', 'r', 'abstract', 'visual', 'reinforcement', 'learning', 'prove', 'effective', 'solve', 'control', 'task', 'highdimensional', 'observation', 'however', 'extract', 'reliable', 'generalizable', 'representation', 'visionbase', 'observation', 'remain', 'central', 'challenge', 'spired', 'human', 'thought', 'process', 'representation', 'extract', 'observation', 'predict', 'future', 'trace', 'history', 'representation', 'reliable', 'accurate', 'com', 'prehend', 'environment', 'base', 'concept', 'troduce', 'bidirectional', 'transition', 'bit', 'model', 'lever', 'age', 'ability', 'bidirectionally', 'predict', 'environmental', 'tran', 'sition', 'forward', 'backward', 'extract', 'reliable', 'repre', 'sentation', 'model', 'demonstrate', 'competitive', 'generaliza', 'tion', 'performance', 'sample', 'efficiency', 'setting', 'deepmind', 'control', 'suite', 'additionally', 'utilize', 'robotic', 'nipulation', 'carla', 'simulator', 'demonstrate', 'wide', 'applicability', 'method', 'introduction', 'visual', 'reinforcement', 'learning', 'visual', 'rl', 'active', 'search', 'field', 'focus', 'learn', 'optimal', 'control', 'policy', 'highdimensional', 'image', 'input', 'visual', 'rl', 'show', 'remarkable', 'success', 'various', 'application', 'include', 'video', 'game', 'robotic', 'manipulation', 'levine', 'autonomous', 'navigation', 'ever', 'generalize', 'learn', 'policy', 'novel', 'environment', 'visual', 'change', 'remain', 'significant', 'challenge', 'cobbe', 'recent', 'study', 'achieve', 'significant', 'progress', 'generalization', 'task', 'utilize', 'selfsupervise', 'meth', 'od', 'grill', 'laskin', 'srinivas', 'abbeel', 'method', 'design', 'specific', 'auxiliary', 'task', 'imbue', 'representation', 'certain', 'property', 'result', 'effective', 'generalization', 'similarly', 'fo', 'cus', 'design', 'auxiliary', 'task', 'extract', 'representation', 'generalization', 'visual', 'reinforcement', 'learn', 'auxiliary', 'task', 'method', 'predict', 'bidirectional', 'environment', 'transition', 'aid', 'agent', 'extract', 'reliable', 'representation', 'intuition', 'method', 'representation', 'strong', 'environmental', 'transition', 'property', 'well', 'comprehend', 'context', 'information', 'provide', 'reliable', 'support', 'decisionmake', 'figure', 'draw', 'parallel', 'human', 'thought', 'process', 'human', 'encounter', 'perplexing', 'decisionmake', 'sit', 'uation', 'struggle', 'accurately', 'assess', 'current', 'state', 'figure', 'basic', 'idea', 'method', 'human', 'encounter', 'perplexing', 'situation', 'usually', 'conduct', 'backward', 'forward', 'environmental', 'transition', 'analysis', 'successful', 'analysis', 'indicate', 'trustworthy', 'comprehension', 'current', 'environment', 'fail', 'analysis', 'suggest', 'reliable', 'environmental', 'understanding', 'often', 'ask', 'crucial', 'question', 'come', 'go', 'suc', 'cessfully', 'trace', 'history', 'predict', 'future', 'base', 'current', 'situation', 'reliable', 'comprehen', 'sion', 'current', 'state', 'facilitate', 'dependable', 'decision', 'conversely', 'backtrack', 'deduce', 'mean', 'lack', 'proper', 'comprehension', 'situation', 'make', 'decision', 'base', 'incorrect', 'comprehension', 'also', 'unreliable', 'inspire', 'human', 'thought', 'propose', 'bidirectional', 'transition', 'bit', 'model', 'extract', 'reliable', 'rep', 'resentation', 'image', 'observation', 'policy', 'learning', 'specifically', 'first', 'design', 'feature', 'extractor', 'generate', 'representation', 'visual', 'observation', 'propose', 'bidirectional', 'transition', 'learner', 'consider', 'forward', 'backward', 'transition', 'prediction', 'avoid', 'trivial', 'tion', 'approach', 'include', 'action', 'prediction', 'module', 'bidirectional', 'transition', 'learner', 'learn', 'repre', 'sentation', 'bit', 'independent', 'visionbase', 'reinforce', 'ment', 'learning', 'method', 'utilize', 'policy', 'learner', 'paper', 'implement', 'standard', 'soft', 'actor', 'critic', 'sac', 'policy', 'learner', 'employ', 'distinct', 'configuration', 'deepmind', 'control', 'suite', 'dmcontrol', 'tassa', 'validate', 'generalization', 'ability', 'sample', 'come', 'go', 'backward', 'forward', '−1', '−1', 'reliable', 'time', 'backward', 'forward', 'unreliable', '−1', 'efficiency', 'bit', 'additionally', 'implement', 'robotic', 'manipulation', 'simulator', 'jangir', 'drive', 'sim', 'ulator', 'illustrate', 'wide', 'applicability', 'method', 'extensive', 'experiment', 'exhibit', 'bit', 'superior', 'generalization', 'performance', 'sample', 'efficiency', 'compare', 'previous', 'stateoftheart', 'method', 'summary', 'contribution', 'threefold', '•', 'introduce', 'concept', 'utilize', 'prediction', 'back', 'ward', 'forward', 'transition', 'visual', 'rl', 'observation', 'comprehension', 'align', 'human', 'intuition', '•', 'propose', 'bidirectional', 'transition', 'bit', 'model', 'assist', 'agent', 'obtain', 'stable', 'reliable', 'rep', 'resentation', 'image', 'observation', 'extensive', 'experimental', 'result', 'show', 'method', 'achieve', 'superior', 'result', 'previous', 'stateoftheart', 'method', 'generalization', 'sample', 'efficiency', 'relate', 'work', 'datum', 'augmentation', 'visual', 'rl', 'datum', 'augmentation', 'demonstrate', 'significantly', 'improve', 'generalization', 'visual', 'rl', 'randomize', 'volution', 'simple', 'technique', 'improve', 'generalization', 'ability', 'agent', 'introduce', 'randomize', 'neural', 'network', 'perturb', 'input', 'observation', 'compare', 'different', 'datum', 'augmentation', 'meth', 'od', 'evidence', 'benefit', 'visual', 'rl', 'drq', 'yarat', 'kostrikov', 'fergus', 'aggregate', 'multiple', 'image', 'average', 'value', 'function', 'target', 'ucbdrac', 'raileanu', 'combine', 'previous', 'method', 'ucb', 'auer', 'introduce', 'proache', 'automatically', 'find', 'effective', 'augmenta', 'tion', 'secant', 'fan', 'mention', 'weak', 'strong', 'augmentation', 'show', 'different', 'effect', 'generalization', 'task', 'cnsn', 'propose', 'normalization', 'technique', 'rely', 'prior', 'knowledge', 'shift', 'characteristic', 'clop', 'bertoin', 'rachelson', 'introduce', 'novel', 'regularization', 'approach', 'involve', 'channelconsistent', 'local', 'permutation', 'feature', 'map', 'datum', 'augmentation', 'demonstrate', 'significant', 'efficacy', 'enhance', 'generalization', 'leverage', 'prior', 'knowledge', 'inductive', 'bias', 'agent', 'representation', 'learning', 'visual', 'rl', 'numerous', 'approach', 'dedicate', 'learn', 'prove', 'representation', 'bridge', 'generalization', 'gap', 'visual', 'rl', 'example', 'duce', 'bisimulation', 'metric', 'fern', 'cup', 'learn', 'robust', 'representation', 'laskin', 'srinivas', 'abbeel', 'implement', 'contrastive', 'learning', 'datum', 'augmentation', 'learn', 'repre', 'sentation', 'efficiently', 'svea', 'identify', 'problem', 'root', 'highvariance', 'q', 'target', 'propose', 'technique', 'stabilize', 'vari', 'ance', 'datum', 'augmentation', 'hansen', 'propose', 'method', 'utilize', 'selfsupervision', 'task', 'allow', 'policy', 'continue', 'training', 'deployment', 'novel', 'environment', 'rely', 'reward', 'spd', 'design', 'selfpredictive', 'dynam', 'ic', 'model', 'auxiliary', 'task', 'extract', 'taskrelevant', 'fea', 'ture', 'efficiently', 'however', 'spd', 'exclusively', 'focus', 'ward', 'transition', 'prediction', 'lead', 'potential', 'acquisi', 'tion', 'unreliable', 'state', 'representation', 'account', 'predict', 'forward', 'transition', 'also', 'consider', 'backward', 'transition', 'method', 'effectively', 'learn', 'environmental', 'contextual', 'information', 'obtain', 'reliable', 'representation', 'observation', 'transition', 'model', 'rl', 'previous', 'method', 'achieve', 'superior', 'sample', 'efficiency', 'learn', 'transition', 'model', 'environment', 'plan', 'ne', 'policy', 'base', 'model', 'sutton', 'algorithm', 'benefit', 'train', 'forward', 'backward', 'transition', 'model', 'also', 'well', 'generalization', 'example', 'propose', 'modify', 'method', 'apply', 'exist', 'transition', 'model', 'reward', 'artificially', 'penalize', 'uncertainty', 'transition', 'park', 'introduce', 'generative', 'backward', 'dynamic', 'model', 'generate', 'short', 'imagine', 'trajectory', 'state', 'demonstration', 'inspire', 'transition', 'model', 'learning', 'method', 'propose', 'bidirectional', 'transition', 'model', 'learn', 'method', 'highdimensional', 'visionbase', 'inforcement', 'learn', 'task', 'preliminary', 'visual', 'reinforcement', 'learning', 'formulate', 'interaction', 'agent', 'envi', 'ronment', 'partially', 'observable', 'markov', 'decision', 'process', 'pomdp', 'kaelble', 'littman', 'cassandra', 'p', 'r', 'state', 'space', 'high', 'dimensional', 'observation', 'space', 'action', 'space', 'p', 'st1st', 'state', 'transition', 'function', 'r', 's×a', 'cid55', 'r', 'scalar', 'reward', 'function', 'discount', 'factor', 'rl', 'aim', 'train', 'agent', 'policy', 'πθ', 'parameterize', 'maximize', 'expect', 'cumula', 'tive', 'return', 'j', 'θ', 'st∼p', 'horizon', 'pomdp', 'visual', 'gener', 'alization', 'set', 'expect', 'learn', 'policy', 'πθ', 'well', 'generalized', 'novel', 'environment', 'structure', 'original', 'pomdp', 'different', 'observation', 'space', 'construct', 'state', 'space', 'γtr', 'cid104', 'environment', 'transition', 'model', 'basic', 'transition', 'model', 'learn', 'environment', 'transition', 'also', 'learn', 'reward', 'function', 'simulta', 'neously', 'categorize', 'transfer', 'direction', 'di', 'vide', 'forward', 'transition', 'model', 'st1', 'rtst', 'backward', 'transition', 'model', 'rtst1', 'rameterize', 'respectively', 'forward', 'model', 'represent', 'probability', 'next', 'state', 'sponde', 'reward', 'give', 'current', 'state', 'action', 'versely', 'backward', 'model', 'generate', 'probability', 'current', 'state', 'reward', 'take', 'next', 'state', 'figure', 'overview', 'model', 'implement', 'feature', 'extractor', 'parallel', 'architecture', 'generate', 'distinct', 'encode', 'representation', 'bidirectional', 'transition', 'learner', 'module', 'forward', 'transition', 'module', 'backward', 'transition', 'module', 'action', 'prediction', 'module', 'objective', 'utilize', 'loss', 'function', 'bidirectional', 'transition', 'prediction', 'learn', 'encoder', 'fφ', 'generate', 'reliable', 'representation', 'action', 'input', 'reward', 'function', 'r', 'pend', 'current', 'state', 'action', 'ward', 'transition', 'decompose', 'rtst1', 'p', 'st1st', 'p', 'rtst', 'backward', 'transition', 'well', 'maximizing', 'log', 'likelihood', 'function', 'follow', 'e', 'st1', '∼denv', 'log', 'st1', 'rtst', 'e', 'st1', '∼denv', 'log', 'rtst1', 'lbwd', 'denv', 'sample', 'dataset', 'agent', 'policy', 'method', 'present', 'bidirectional', 'transition', 'bit', 'model', 'depict', 'figure', 'describe', 'approach', 'sure', 'representation', 'reliably', 'comprehend', 'cur', 'rent', 'visual', 'observation', 'leverage', 'prediction', 'bidirectional', 'transition', 'learner', 'notably', 'method', 'vide', 'auxiliary', 'representation', 'learn', 'task', 'effectively', 'assist', 'share', 'encoder', 'update', 'offer', 'dependable', 'resentation', 'reinforcement', 'learning', 'bit', 'generic', 'model', 'adaptable', 'various', 'visionbase', 'rl', 'algorithm', 'overview', 'model', 'aim', 'deliver', 'reliable', 'generalizable', 'rep', 'resentation', 'input', 'observation', 'policy', 'learner', 'figure', 'illustrate', 'bit', 'comprise', 'feature', 'extractor', 'bidirectional', 'transition', 'learner', 'training', 'introduce', 'datum', 'augmentation', 'perturb', 'image', 'observation', 'subsequently', 'leverage', 'feature', 'extractor', 'par', 'allel', 'architecture', 'grill', 'generate', 'distinct', 'code', 'representation', 'bidirectional', 'transition', 'learner', 'mainly', 'consist', 'part', 'forward', 'transition', 'mod', 'ule', 'backward', 'transition', 'module', 'action', 'prediction', 'module', 'policy', 'learner', 'implement', 'standard', 'soft', 'actorcritic', 'sac', 'share', 'encoder', 'fφ', 'utilize', 'mente', 'observation', 'learn', 'control', 'policy', 'bit', 'training', 'bidirectional', 'transition', 'bit', 'model', 'update', 'ω', 'sample', 'batch', 'transition', 'ot1', 'b', 'obtain', 'feature', '˜zt1', 'minimize', 'θ', 'φ', 'initialize', 'feature', 'extractor', 'parameter', 'initialize', 'transition', 'learner', 'parameter', 'ω', 'rl', 'update', 'iteration', 'ϵ', 'momentum', 'coefficient', 'iteration', 'minimize', 'lbit', 'end', 'end', 'sample', 'batch', 'observation', 'ot1', 'b', 'augment', 'observation', 'obtain', 'online', 'feature', 'obtain', 'target', 'feature', 'zt1', 'fθ', 'action', 'prediction', 'forward', 'transition', 'prediction', 'ˆzt1', 'backward', 'transition', 'prediction', 'zt1', 'update', 'ϵ', 'θ', 'zt1', 'policy', 'learner', 'alternate', 'training', 'show', 'testing', 'utilize', 'encoder', 'fφ', 'generate', 'representation', 'visual', 'observation', 'implement', 'policy', 'learner', 'control', 'agent', 'feature', 'extractor', 'give', 'input', 'observation', 'employ', 'feature', 'extractor', 'acquire', 'encoded', 'representation', 'feature', 'extractor', 'comprise', 'online', 'branch', 'tar', 'get', 'branch', 'online', 'branch', 'encompass', 'compo', 'nent', 'share', 'encoder', 'projection', 'pre', 'diction', 'head', 'meanwhile', 'target', 'branch', 'include', 'encoder', 'fθ', 'projection', 'share', 'structure', 'corresponding', 'one', 'online', 'branch', 'specifically', 'sample', 'image', 'observation', 'ot', 'ot1', 'training', 'step', 'augment', 'forward', 'feature', 'extractor', 'bidirectional', 'transition', 'learner', 'action', 'ℒ', 'fwd', 'ℒ', 'bwd', 'ℒ', 'stopgradient', 'loss', 'function', 'lize', 'datum', 'augmentation', 'perturb', 'produce', 'mente', 'observation', 'subsequently', 'derive', 'sponding', 'representation', 'code', 'projection', 'prediction', 'identically', 'obtain', 'correspond', 'representation', 'zt1', 'use', 'target', 'branch', 'fθ', 'zt1', 'fθ', 'ot1', 'dur', 'ing', 'train', 'encoder', 'projection', 'prediction', 'train', 'simultaneously', 'bidirectional', 'transition', 'learner', 'total', 'objective', 'function', 'lbit', 'also', 'optimize', 'policy', 'learner', 'objective', 'function', 'lrl', 'perform', 'stopgradient', 'operation', 'prevent', 'parameter', 'date', 'gradient', 'backpropagation', 'specifically', 'fine', 'parameter', 'θ', 'exponential', 'move', 'average', 'φ', 'follow', 'rule', 'θn1', 'ϵφn', 'momentum', 'coefficient', 'n', 'iter', 'ation', 'step', 'training', 'process', 'architecture', 'enhance', 'expressiveness', 'acquire', 'representation', 'align', 'prior', 'study', 'grill', 'bidirectional', 'transition', 'learner', 'obtain', 'reliable', 'state', 'representation', 'current', 'obser', 'vation', 'believe', 'representation', 'able', 'forward', 'predict', 'future', 'development', 'backward', 'trace', 'tory', 'propose', 'bidirectional', 'transition', 'learner', 'representation', 'generate', 'feature', 'extractor', 'lize', 'predict', 'environment', 'forward', 'backward', 'transition', 'learner', 'consist', 'module', 'forward', 'transition', 'module', 'backward', 'transition', 'module', 'action', 'prediction', 'module', 'specifically', 'first', 'establish', 'action', 'prediction', 'mod', 'ule', 'derive', 'pseudo', 'action', 'base', 'input', 'state', 'representation', 'pseudo', 'action', 'obtain', 'zt1', 'correspond', 'optimization', 'objective', 'function', 'follow', 'laction', '∥ˆa', 'a∥2', 'denv', 'trajectory', 'dataset', 'agent', 'τ', 'repre', 'sent', 'transition', 'ot1', 'sample', 'denv', '∥·∥2', 'mean', 'square', 'error', 'action', 'prediction', 'module', 'assist', 'forward', 'backward', 'transition', 'fall', 'trivial', 'solution', 'enhance', 'taskrelate', 'mation', 'representation', 'predict', 'pseudo', 'action', 'feed', 'forward', 'backward', 'transition', 'module', 'consider', 'influence', 'sparse', 'reward', 'representation', 'learning', 'process', 'transition', 'model', 'exclusively', 'focus', 'pre', 'dicte', 'state', 'representation', 'transition', 'consider', 'reward', 'function', 'specifically', 'forward', 'transition', 'mod', 'ule', 'utilize', 'augment', 'representation', 'pseudo', 'action', 'ˆa', 'input', 'output', 'predict', 'transi', 'tion', 'state', 'representation', 'ˆzt1', 'next', 'time', 'process', 'ˆzt1', 'ˆa', 'corresponding', 'objective', 'func', 'tion', 'define', 'follow', 'eτ', '∼denv', 'ˆzt1', 'conversely', 'backward', 'transition', 'module', 'utilize', 'state', 'representation', 'zt1', 'next', 'step', 'pseudo', 'action', 'output', 'current', 'state', 'representation', 'prediction', 'ˆzt', 'process', 'express', 'zt1', 'objective', 'function', 'define', 'follow', '∼denv', 'lbwd', 'note', 'predict', 'environment', 'transition', 'pixel', 'space', 'compressed', 'state', 'representation', 'space', 'approach', 'enable', 'representation', 'vent', 'uncertainty', 'predict', 'pixel', 'prevent', 'int', 'ference', 'taskindependent', 'area', 'space', 'jointly', 'optimize', 'bidirectional', 'transition', 'learner', 'feature', 'extractor', 'total', 'objective', 'function', 'lbit', 'follow', 'lbit', 'laction', 'lbwd', 'optimize', 'total', 'objective', 'function', 'lbit', 'ex', 'tracte', 'representation', 'precisely', 'reflect', 'state', 'information', 'agent', 'provide', 'reliable', 'support', 'correct', 'decisionmake', 'ψ', 'policy', 'learner', 'bit', 'independent', 'policy', 'learner', 'encoding', 'rep', 'module', 'apply', 'visual', 'rl', 'paper', 'implement', 'standard', 'offpolicy', 'rl', 'method', 'soft', 'actorcritic', 'sac', 'policy', 'learner', 'specifically', 'unaugmented', 'raw', 'image', 'observa', 'tion', 'feed', 'encoder', 'fφ', 'output', 'representa', 'tion', 'policy', 'learner', 'utilize', 'train', 'policy', 'show', 'optimization', 'representation', 'learning', 'lbit', 'perform', 'alternately', 'tion', 'reinforcement', 'learn', 'step', 'optimization', 'objective', 'jointly', 'update', 'parameter', 'share', 'encoder', 'present', 'detailed', 'architecture', 'sac', 'supplementary', 'material', 'experiment', 'validate', 'effectiveness', 'bit', 'stateofthe', 'art', 'method', 'wide', 'spectrum', 'visual', 'generalization', 'task', 'mainly', 'choose', 'configuration', 'deep', 'mind', 'control', 'dmcontrol', 'tassa', 'compare', 'generalization', 'performance', 'sample', 'efficiency', 'also', 'perform', 'ablation', 'mentation', 'method', 'analysis', 'study', 'bit', 'moreover', 'plement', 'robotic', 'manipulation', 'simulator', 'jangir', 'drive', 'simulator', 'experiment', 'detail', 'result', 'supplementary', 'material', 'environment', 'visionbased', 'simulator', 'offer', 'collection', 'continuous', 'control', 'task', 'generalization', 'problem', 'dmcontrol', 'introduce', 'visually', 'distract', 'environment', 'relate', 'reward', 'signal', 'motor', 'control', 'task', 'evaluate', 'effectiveness', 'method', 'conduct', 'experiment', 'lize', 'distinct', 'setting', 'assess', 'generalization', 'capacity', 'sample', 'efficiency', 'generalization', 'setup', 'training', 'environment', 'background', 'distraction', 'test', 'environment', 'set', 'video', 'easy', 'video', 'hard', 'task', 'walker', 'stand', 'catch', 'finger', 'spin', 'reacher', 'easy', 'walker', 'stand', 'catch', 'finger', 'spin', 'reacher', 'easy', '45±5', '114±15', 'pad', '436±55', 'soda', '695±97', '567±64', '302±41', 'svea', '808±33', '393±45', 'bit', 'table', 'generalization', 'performance', 'report', 'average', 'episode', 'return', 'correspond', 'variance', 'different', 'seed', 'method', 'train', 'distractorfree', 'background', 'test', 'different', 'video', 'distractor', 'background', 'stateoftheart', 'performance', 'task', 'also', 'deliver', 'competitive', 'result', 'figure', 'example', 'generalization', 'setup', 'uti', 'lize', 'different', 'background', 'type', 'distractorfree', 'training', 'video', 'easy', 'video', 'hard', 'datum', 'augman', 'tation', 'environment', 'random', 'overlay', 'example', 'walker', 'stand', 'task', 'figure', 'example', 'sample', 'efficiency', 'setup', 'choose', 'color', 'configuration', 'namely', 'gray', 'color', 'video', 'background', 'simple', 'distractor', 'natural', 'video', 'example', 'run', 'task', 'video', 'background', 'interference', 'setting', 'dmcon', 'trol', 'generalization', 'benchmark', 'dmcontrolgb', 'degree', 'video', 'impact', 'test', 'environment', 'divide', 'video', 'easy', 'video', 'hard', 'verify', 'generalization', 'method', 'task', 'mainly', 'consider', 'random', 'overlay', 'augment', 'image', 'observation', 'also', 'apply', 'prior', 'method', 'sample', 'different', 'environment', 'show', 'figure', 'comparison', 'method', 'follow', 'laskin', 'srinivas', 'abbeel', 'implement', 'contrastive', 'learning', 'datum', 'augmentation', 'pad', 'hansen', 'imply', 'auxiliary', 'task', 'continue', 'training', 'novel', 'environment', 'soda', 'lize', 'byollike', 'grill', 'architecture', 'learn', 'latent', 'representation', 'consistency', 'svea', 'propose', 'technique', 'stabilize', 'highvariance', 'qtarget', 'tlda', 'duce', 'interference', 'augmentation', 'image', 'run', 'random', 'seed', 'report', 'mean', 'standard', 'deviation', 'episode', 'return', 'table', 'sample', 'efficiency', 'setup', 'train', 'method', 'interference', 'setting', 'task', 'follow', 'approach', 'outline', 'assess', 'antiinterference', 'capability', 'sample', 'efficiency', 'training', 'specifically', 'employ', 'distinct', 'video', 'back', 'ground', 'simple', 'distractor', 'natural', 'video', 'color', 'setting', 'gray', 'color', 'example', 'different', 'setting', 'show', 'figure', 'testing', 'training', 'environment', 'background', 'setting', 'sample', 'efficiency', 'assessment', 'furthermore', 'conduct', 'generalization', 'evaluation', 'setup', 'train', 'method', 'simple', 'distractor', 'background', 'compare', 'formance', 'novel', 'natural', 'video', 'background', 'fair', 'comparison', 'method', 'inherent', 'general', 'ization', 'ability', 'rather', 'impact', 'data', 'augmenta', 'tion', 'technique', 'implement', 'data', 'augmentation', 'method', 'spd', 'apply', 'weak', 'strong', 'augmentation', 'method', 'image', 'observation', 'respectively', 'tion', 'compare', 'approach', 'curl', 'soda', 'pad', 'new', 'method', 'follow', 'sac', 'standard', 'offpolicy', 'drq', 'yarat', 'kostrikov', 'fergus', 'incorporate', 'multiple', 'image', 'transformation', 'spd', 'employ', 'selfpredictive', 'forward', 'dynamic', 'approach', 'efficiently', 'ex', 'tract', 'taskrelevant', 'feature', 'comparative', 'result', 'car', 'rie', 'utilize', 'random', 'seed', 'report', 'table', 'generalization', 'performance', 'result', 'distraction', 'free', 'background', 'training', 'evaluation', 'video', 'distrac', 'tor', 'dmcontrolgb', 'task', 'present', 'table', 'simple', 'video', 'simple', 'video', 'gray', 'b', 'color', 'training', 'random', 'overlay', 'video', 'easy', 'video', 'hard', 'simple', 'video', 'simple', 'video', 'gray', 'b', 'color', 'training', 'random', 'overlay', 'video', 'easy', 'video', 'hard', 'gray', 'soda', '37±5', '689±27', 'drq', 'sample', 'efficiency', 'training', 'testing', 'simple', 'distractor', 'run', '665±27', 'finger', 'spin', 'hopper', 'reacher', 'easy', 'walker', 'walk', 'b', 'sample', 'efficiency', 'training', 'testing', 'natural', 'video', 'run', 'finger', 'spin', 'hopper', 'reacher', 'easy', 'walker', 'walk', 'c', 'generalization', 'training', 'simple', 'distractor', 'test', 'natural', 'video', 'run', 'finger', 'spin', 'hopper', 'reacher', 'easy', 'walker', 'walk', '10±5', '90±15', '73±8', '274±158', '653±39', '160±28', '408±35', '15±5', 'spd', '646±107', '330±26', '983±1', 'color', 'bit', 'spd', 'bit', '349±26', '953±36', '917±59', '41±15', '633±73', '981±4', '81±47', '18±15', '928±24', '728±180', '70±37', '605±237', '860±31', 'table', 'sample', 'efficiency', 'generalization', 'performance', 'report', 'average', 'episode', 'return', 'correspond', 'ance', 'seed', 'train', 'method', 'simple', 'distractor', 'natural', 'video', 'evaluate', 'method', 'background', 'sample', 'efficiency', 'experiment', 'also', 'assess', 'method', 'train', 'simple', 'distractor', 'novel', 'natural', 'video', 'generalization', 'experiment', 'method', 'achieve', 'stateoftheart', 'result', 'task', 'particularly', 'challenging', 'set', 'color', 'natural', 'video', 'method', 'excel', 'task', 'achieve', 'optimal', 'value', 'task', 'suboptimal', 'value', 'remain', 'task', 'contrast', 'alternative', 'algorithm', 'soda', 'svea', 'tlda', 'exhibit', 'superior', 'performance', 'specific', 'task', 'lack', 'capability', 'achieve', 'mal', 'result', 'majority', 'task', 'representation', 'learn', 'method', 'enable', 'correct', 'reliable', 'compre', 'hension', 'environmental', 'observation', 'effectively', 'eralize', 'novel', 'environment', 'evidence', 'table', 'c', 'even', 'train', 'presence', 'noisy', 'background', 'bit', 'retain', 'capacity', 'acquire', 'dependable', 'comprehen', 'sion', 'environment', 'showcase', 'robust', 'generalization', 'skill', 'model', 'consistently', 'outperform', 'stateoftheart', 'algorithm', 'task', 'train', 'simple', 'distractor', 'background', 'generalize', 'natural', 'video', 'background', 'contrast', 'algorithm', 'frequently', 'struggle', 'learn', 'reliable', 'representation', 'effective', 'poli', 'cie', 'confront', 'interfere', 'background', 'sample', 'efficiency', 'performance', 'present', 'table', 'b', 'training', 'test', 'environment', 'iden', 'tical', 'compare', 'training', 'sample', 'efficiency', 'method', 'surpass', 'baseline', 'task', 'context', 'simple', 'distractor', 'background', 'far', 'bit', 'outperform', 'baseline', 'task', 'consider', 'natural', 'video', 'background', 'notably', 'bit', 'attain', 'stateoftheart', 'performance', 'particularly', 'challenging', 'task', 'color', 'natural', 'video', 'background', 'distraction', 'specifically', 'analyze', 'spd', 'generalization', 'ability', 'significantly', 'diminish', 'change', 'training', 'environment', 'gray', 'color', 'disparity', 'tributed', 'fact', 'spd', 'employ', 'forward', 'transition', 'representation', 'learning', 'thereby', 'hinder', 'uncer', 'taintie', 'inherent', 'unidirectional', 'transfer', 'prediction', 'sequently', 'spd', 'fail', 'furnish', 'stable', 'representation', 'ducive', 'policy', 'learning', 'contrast', 'bidirectional', 'tran', 'sition', 'learner', 'simultaneously', 'encompass', 'forward', 'backward', 'transition', 'module', 'auxiliary', 'task', 'tional', 'approach', 'substantially', 'mitigate', 'instability', 'learning', 'provide', 'dependable', 'state', 'repre', 'sentation', 'thus', 'enhance', 'efficacy', 'agent', 'policy', 'learn', 'result', 'model', 'demonstrate', 'superior', 'sample', 'ficiency', 'enhance', 'generalization', 'capability', 'sup', 'plementary', 'material', 'far', 'compare', 'learn', 'curve', 'spd', 'analyze', 'sample', 'efficiency', 'ablation', 'study', 'conduct', 'ablation', 'experiment', 'dmcontrolgb', 'task', 'verify', 'role', 'objec', 'tive', 'function', 'bidirectional', 'transition', 'learner', 'show', 'figure', 'choose', 'cartpole', 'video', 'easy', 'background', 'bit', 'fwd', 'indicate', 'absence', 'forward', 'transition', 'module', 'bit', 'signify', 'omission', 'backward', 'transition', 'mod', 'ule', 'bit', 'action', 'imply', 'exclusion', 'action', 'pre', 'diction', 'module', 'bit', 'action', 'suggest', 'presence', 'action', 'prediction', 'module', 'bidirectional', 'transition', 'learner', 'term', 'baseline', 'refer', 'degraded', 'version', 'model', 'lack', 'propose', 'objective', 'func', 'tion', 'include', 'data', 'augmentation', 'figure', 'show', 'bit', 'yield', 'good', 'generalization', 'ef', 'method', 'reach', 'test', 'test', 'test', 'test', 'test', 'avg', 'test', 'test', 'test', 'test', 'test', 'sac', '41±15', '23±23', '55±8', '61±11', '66±21', '59±11', 'soda', 'svea', '39±25', '16±36', 'bit', '28±52', 'table', 'performance', 'robotic', 'environment', 'report', 'average', 'return', 'variance', 'task', 'mean', 'excel', 'task', 'demonstrate', 'wide', 'applicability', 'model', 'fectively', 'acquire', 'stable', 'generalizable', 'representation', 'datum', 'augmentation', 'moreover', 'bit', 'large', 'formance', 'gain', 'utilize', 'random', 'overlay', 'random', 'overlay', 'produce', 'texture', 'increase', 'well', 'match', 'video', 'background', 'color', 'distraction', 'duce', 'random', 'convolution', 'visualization', 'attention', 'map', 'choose', 'task', 'generalization', 'set', 'walker', 'stand', 'cartpole', 'show', 'attention', 'map', 'bit', 'differ', 'ent', 'background', 'distractingfree', 'video', 'easy', 'video', 'hard', 'result', 'figure', 'show', 'bit', 'clearly', 'perceive', 'taskrelate', 'region', 'image', 'obser', 'vation', 'regardless', 'presence', 'absence', 'background', 'interference', 'way', 'bit', 'provide', 'reliable', 'correct', 'representation', 'image', 'observation', 'agent', 'learn', 'generalizable', 'policy', 'robotic', 'manipulation', 'environment', 'demonstrate', 'wide', 'applicability', 'method', 'plement', 'task', 'visionbase', 'robotic', 'manipula', 'tion', 'simulator', 'jangir', 'train', 'agent', 'fault', 'background', 'validate', 'testing', 'environ', 'ment', 'test', 'environment', 'similar', 'training', 'one', 'different', 'color', 'texture', 'background', 'evaluate', 'algorithm', 'include', 'sac', 'soda', 'svea', 'correspond', 'result', 'present', 'table', 'exper', 'imental', 'result', 'demonstrate', 'bit', 'well', 'generalize', 'robotic', 'training', 'domain', 'novel', 'environment', 'conclusion', 'paper', 'introduce', 'bidirectional', 'transition', 'bit', 'model', 'aid', 'agent', 'extract', 'reliable', 'well', 'generalized', 'representation', 'visual', 'observation', 'bit', 'method', 'utilize', 'bidirectional', 'transition', 'prediction', 'objective', 'ensure', 'agent', 'accurately', 'comprehend', 'vi', 'sual', 'observation', 'method', 'demonstrate', 'competitive', 'generalization', 'sample', 'efficiency', 'various', 'benchmark', 'task', 'include', 'deepmind', 'control', 'suite', 'robotic', 'manip', 'ulation', 'simulator', 'drive', 'simulator', 'figure', 'leave', 'ablation', 'study', 'figure', 'analyze', 'effectiveness', 'constraint', 'objective', 'right', 'dif', 'ferent', 'augmentation', 'method', 'figure', 'assess', 'impact', 'datum', 'augmentation', 'figure', 'attention', 'map', 'bit', 'show', 'attention', 'map', 'bit', 'different', 'background', 'task', 'walker', 'walk', 'cartpole', 'fect', 'sample', 'efficiency', 'find', 'add', 'forward', 'backward', 'transition', 'prediction', 'separately', 'action', 'pre', 'diction', 'also', 'improve', 'performance', 'enhancement', 'insignificant', 'unidirectional', 'transition', 'prediction', 'inherent', 'instability', 'agent', 'lead', 'biased', 'comprehension', 'observation', 'contrast', 'rectional', 'prediction', 'help', 'agent', 'stable', 'state', 'representation', 'mitigate', 'uncertainty', 'observational', 'comprehension', 'concurrently', 'predict', 'forward', 'backward', 'transition', 'principle', 'align', 'prior', 'work', 'moreover', 'omit', 'action', 'prediction', 'module', 'cause', 'learn', 'resentation', 'lack', 'taskrelate', 'information', 'easily', 'fall', 'trivial', 'solution', 'overall', 'result', 'demonstrate', 'module', 'bit', 'play', 'significant', 'effective', 'role', 'study', 'different', 'augmentation', 'method', 'analyze', 'effect', 'different', 'datum', 'augmentation', 'model', 'random', 'overlay', 'random', 'convolution', 'augmentation', 'conduct', 'comparison', 'base', 'sac', 'task', 'setting', 'ablation', 'study', 'section', 'result', 'depict', 'figure', 'b', 'result', 'demonstrate', 'model', 'achieve', 'substan', 'tial', 'improvement', 'sac', 'datum', 'augmentation', 'datum', 'augmentation', 'sac', 'struggle', 'acquire', 'stable', 'representation', 'creased', 'diversity', 'sample', 'consequently', 'ability', 'improve', 'generalization', 'limit', 'case', 'even', 'result', 'performance', 'degradation', 'contrast', 'bit', 'ablation', 'study', 'different', 'augmentation', 'method', 'walker', 'stand', 'cartpole', 'train', 'video', 'easy', 'video', 'hard', 'reference', 'auer', 'p', 'use', 'confidence', 'bound', 'exploitation', 'exploration', 'tradeoff', 'journal', 'machine', 'learning', 'search', 'bertoin', 'local', 'feature', 'swap', 'ping', 'generalization', 'reinforcement', 'learning', 'tenth', 'international', 'conference', 'learn', 'representa', 'tion', 'iclr', 'virtual', 'event', 'open', 'simple', 'framework', 'contrastive', 'learning', 'visual', 'repre', 'sentation', 'international', 'conference', 'machine', 'learn', 'pmlr', 'hesse', 'schulman', 'quantify', 'generalization', 'reinforcement', 'learning', 'international', 'conference', 'machine', 'learn', 'pmlr', 'dosovitskiy', 'ros', 'codevilla', 'lopez', 'koltun', 'open', 'urban', 'drive', 'simula', 'tor', 'conference', 'robot', 'learn', 'pmlr', 'fan', 'l', 'secant', 'selfexpert', 'cloning', 'zeroshot', 'generalization', 'visual', 'policy', 'ed', 'proceeding', '38th', 'ternational', 'conference', 'machine', 'learn', 'volume', 'proceeding', 'machine', 'learn', 'research', 'pmlr', 'fern', 'p', 'precup', 'bisim', 'ulation', 'metric', 'continuous', 'markov', 'decision', 'process', 'compute', 'c', 'deep', 'visual', 'foresight', 'ieee', 'planning', 'robot', 'motion', 'ference', 'robotic', 'automation', 'icra', 'ieee', 'grill', 'tallec', 'c', 'richemond', 'p', 'buchatskaya', 'e', 'doersch', 'c', 'pire', 'bootstrap', 'latent', 'new', 'approach', 'selfsupervise', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'haarnoja', 'zhou', 'abbeel', 'p', 'soft', 'actorcritic', 'offpolicy', 'maximum', 'entropy', 'deep', 'rein', 'forcement', 'learning', 'stochastic', 'actor', 'international', 'conference', 'machine', 'learn', 'pmlr', 'hansen', 'n', 'jangir', 'r', 'sun', 'aleny', 'g', 'abbeel', 'efro', 'pinto', 'l', 'selfsupervise', 'policy', 'adaptation', 'deployment', '9th', 'international', 'conference', 'learn', 'representation', 'iclr', 'vir', 'tual', 'event', 'openreviewnet', 'hansen', 'n', 'h', 'stabilize', 'deep', 'qlearning', 'convnet', 'vision', 'transformer', 'datum', 'augmentation', 'advance', 'neural', 'information', 'processing', 'system', 'hansen', 'n', 'generalization', 'rein', 'forcement', 'learning', 'soft', 'datum', 'augmentation', 'ieee', 'international', 'conference', 'robotic', 'automation', 'icra', 'ieee', 'z', 'agent', 'centric', 'relation', 'graph', 'object', 'visual', 'navigation', 'ieee', 'transaction', 'circuit', 'system', 'video', 'technology', 'jangir', 'r', 'hansen', 'jain', 'look', 'close', 'bridge', 'egocentric', 'thirdperson', 'ieee', 'view', 'transformer', 'robotic', 'manipulation', 'robotic', 'automation', 'letter', 'kaelble', 'l', 'p', 'littman', 'l', 'cassandra', 'r', 'planning', 'act', 'partially', 'observable', 'stochastic', 'main', 'artificial', 'intelligence', 'j', 'selfpredictive', 'dy', 'namic', 'generalization', 'visionbase', 'reinforcement', 'learning', 'international', 'joint', 'conference', 'ar', 'tificial', 'intelligence', 'international', 'joint', 'confer', 'ence', 'artificial', 'intelligence', 'bidirectional', 'modelbase', 'policy', 'optimization', 'international', 'ence', 'machine', 'learn', 'pmlr', 'stooke', 'pinto', 'l', 'abbeel', 'p', 'srinivas', 'reinforcement', 'learning', 'augmented', 'datum', 'advance', 'neural', 'information', 'processing', 'system', 'srinivas', 'abbeel', 'p', 'contrastive', 'unsupervised', 'representation', 'reinforcement', 'learning', 'international', 'conference', 'machine', 'learn', 'pmlr', 'network', 'run', 'domization', 'simple', 'technique', 'generalization', 'deep', '8th', 'international', 'conference', 'reinforcement', 'learning', 'learn', 'representation', 'iclr', 'openreviewnet', 'c', 'darrell', 'abbeel', 'p', 'end', 'toend', 'training', 'deep', 'visuomotor', 'policy', 'journal', 'machine', 'learn', 'research', 'normalization', 'enhance', 'generalization', 'visual', 'reinforcement', 'learning', 'arxiv', 'preprint', 'z', 'double', 'check', 'state', 'trust', 'modelbase', 'imagination', 'advance', 'neural', 'information', 'processing', 'system', 'yuan', 'comprehensive', 'survey', 'data', 'augman', 'arxiv', 'preprint', 'tation', 'visual', 'reinforcement', 'learning', 'arxiv221004561', 'silver', 'grave', 'antonoglou', 'riedmiller', 'play', 'atari', 'deep', 'reinforcement', 'learning', 'arxiv', 'preprint', 'park', 'j', 'robust', 'imitation', 'demonstration', 'backwards', 'model', 'mohame', 'agarwal', 'belgrave', 'cho', 'ed', 'advance', 'neural', 'information', 'process', 'sys', 'tem', 'volume', 'raileanu', 'r', 'yarat', 'kostrikov', 'fergus', 'r', 'automatic', 'datum', 'augmentation', 'general', 'ization', 'reinforcement', 'learning', 'advance', 'neural', 'mation', 'processing', 'system', 'sutton', 'r', 'reinforcement', 'learn', 'introduction', 'mit', 'press', 'tassa', 'doron', 'muldal', 'erez', 'l', 'budden', 'merel', 'j', 'lefrancq', 'et', 'deepmind', 'control', 'suite', 'arxiv', 'preprint', 'offline', 'reinforcement', 'learning', 'reverse', 'model', 'base', 'imagination', 'advance', 'neural', 'information', 'pro', 'cesse', 'system', 'yarat', 'kostrikov', 'fergus', 'r', 'image', 'need', 'regularize', 'deep', 'reinforcement', 'learning', 'pixel', 'international', 'conference', 'learn', 'ing', 'representation', 'zou', 'c', 'modelbase', 'offline', 'policy', 'optimization', 'advance', 'neural', 'information', 'pro', 'cesse', 'system', 'yuan', 'mu', 'yuan', 'p', 'touch', 'matter', 'task', 'aware', 'lipschitz', 'datum', 'augmentation', 'visual', 'reinforce', 'ed', 'proceeding', 'ment', 'learn', 'international', 'joint', 'conference', 'artificial', 'telligence', 'ijcai', 'ijcaiorg', 'mcallister', 'r', 'calandra', 'r', 'gal', 'learn', 'invariant', 'representation', 'inforcement', 'learning', 'reconstruction', 'arxiv', 'preprint', 'arxiv200610742', 'c', 'vinyal', 'muno', 'r', 'study', 'overfitting', 'deep', 'reinforcement', 'learning', 'arxiv', 'preprint', 'arxiv180406893']"
