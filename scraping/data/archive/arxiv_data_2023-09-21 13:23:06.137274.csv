title,url,date,text,cleaning,tokens
ORL-AUDITOR: Dataset Auditing in Offline Deep Reinforcement Learning,"[{'title': 'doi', 'href': 'http://dx.doi.org/10.14722/ndss.2024.23184', 'rel': 'related', 'type': 'text/html'}, {'href': 'http://arxiv.org/abs/2309.03081v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2309.03081v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-09-06 15:28:43,"Field evaluation of a mobile app for assisting blind and visually 
impaired travelers to find bus stops  

Shrinivas Pundlik 1, Prerana Shivshanker 1, Tim Traut-Savino 2, Gang Luo 1  

1. Schepens Eye Research Institute of Mass Eye & Ear, Harvard Medical School Boston, MA 

2. The Carroll Center for the Blind, MA 

Corresponding Author: 
Gang Luo (gang.luo@schepens.harvard.edu) 

Keywords: vision aid, navigation, mobility, accessibility, deep learning, computer vision, public 
transportation   

Commercial Relationships: The authors declared no potential conflicts of interest with respect to 
the research, authorship, and/or publication of this article. The All_Aboard app evaluated in this 
study is released to public for free. There is no revenue from app sale or in-app advertisements. 

 
 
 
 
 
 
 
Abstract 

Purpose: It is reported that there can be considerable gaps due to GPS inaccuracy and 

mapping errors if blind and visually impaired (BVI) travelers rely on digital maps to go to their 

desired bus stops. We evaluated the ability of a mobile app, All_Aboard, to guide BVI travelers 

precisely to the bus-stops. 

Methods: The All_Aboard app detected bus-stop signs in real-time via smartphone camera 

using a neural network model, and provided distance coded audio feedback to help localize the 

detected sign. BVI individuals used the All_Aboard and Google Maps app to localize 10 bus-

stop locations in Boston downtown and another 10 in a sub-urban area. For each bus stop, the 

subjects used the apps to navigate as close as possible to the physical bus-stop sign, starting 

from 30 to 50 meters away. The outcome measures were success rate and gap distance 

between the app-indicated location and the actual physical location of the bus stop. 

Results: The study was conducted with 24 legally blind participants (mean age [SD]: 51[14] 

years; 11 (46%) Female). The success rate of the All_Aboard app (91%) was significantly 

higher than the Google Maps (52%, p<0.001). The gap distance when using the All_Aboard app 

was significantly lower (mean [95%CI]: 1.8 [1.2-2.3] meters) compared to the Google Maps (7 

[6.5-7.5] meters; p<0.001).  

Conclusion: The All_Aboard app localizes bus stops more accurately and reliably than GPS-

based smartphone navigation options in real-world environments.  

Translational Relevance: The All_Aboard mobile app navigation aid can be potentially help BVI 

individuals independently travel via public transportation.  

 
Introduction 

Blind and visually impaired (BVI) people often rely on public transportation, such as buses and 

subways, to travel for employment, leisure or for other needs.1 Geolocation and transportation 

information accessed through smartphones has greatly facilitated macro-navigation for BVI 

people. For example, one can plan a route and get detailed instructions on mobile devices for 

point-to-point navigation using public transits. Navigation apps make up one of the major groups 

of vision assistance mobile apps available in App store and Play store. 2 On the other hand, 

micro-navigation – navigating precisely to the desired destination at any stage of the journey, 

remains a largely unsolved issue for BVI individuals. To comply with the Americans with 

Disabilities Act (1990), regional transit agencies are required to comply with regulations 

regarding the accessibility of transit infrastructures.3 In the context of vision disabilities, the 

requirements include placing of large-print signage at bus stops, providing braille and tactile 

information within transit stations, and making stop announcements inside transit vehicles at 

main points, among others. However, poor interface and lack of cues accessible from distance, 

for example transit stop signage, are one of the main barriers to equal access to public 

transportation.4-9  

Systemic inaccuracies in the GPS based location services is the underlying problem that leads 

to micro-navigation challenges faced by people with BVI. This is also referred to as the last 30 

feet or last 10 m problem in wayfinding. For example, when navigating to a bus stop, a blind 

person following any GPS-based navigation app, may arrive at the app indicated location that 

has a considerable gap (typically 10 m or 30 feet) from the actual bus stop due to the 

localization error in the GPS service. For perspective, this 10 m gap could be almost equal to an 

entire bus length in certain regions. According to the feedback from blind travelers, sometimes 

even a small gap can be large enough for them to miss the bus because the bus drivers 

misunderstand their intention and not stop for them.10-13 In the worst-case scenario, especially in 

crowded cities, the GPS localization may be off by more than a block, making the macro 

navigation apps essentially useless in pedestrian mode.14  

Weather and location (density of tall buildings in downtown areas for example) can further affect 

GPS-based localization. In addition to localization error, there is a possibility of mapping errors 

(sometimes large) in the stop locations made publicly available by the transit agencies. In our 

survey of 174 bus stop locations in Boston metro area, about 23% were mapped more than 2 

bus lengths away. 15 Mapping and localization errors together contribute towards making purely 

location-based services unreliable for micro-navigation tasks, such as finding bus stops. Making 

matters worse, bus stop signs can be one of many signs on a typical urban street (among 

traffic/parking signs and street signs), and thus finding it becomes a visual search task, in 

addition to a plain geolocation task. Since visual search performance is known to be significantly 

degraded in people with low vision,16,17 it is evident that a navigation aid is needed for micro-

navigation with visual search capabilities. 

One of the conventional wayfinding solutions is the use of Bluetooth beacons to provide micro-

location information with high accuracy on nearby landmarks.18-22 This approach’s scalability 

and applicability in outdoor environments are restricted due to the high cost for infrastructure 

modification and maintenance. On the other hand, smartphones could allow rapid scaling of 

accessibility. A few smartphone apps have been developed, tested, or released to help blind 

and visually impaired people access public transportation specifically, or to navigate to 

destinations in general.23-25 These apps are primarily GPS-based, and therefore still subject to 

the limitations of GPS-based navigation systems detailed above. In order to achieve localization 

more accurately, some apps combine location information together with landmark 

recognition.12,13,26,27 However, landmark maps around the various locations have to be built, 

maintained, and made widely available prior to use. Combing signage information extracted 

from GTFS with optical character recognition could provide a viable micro-navigation solution.28 

For the purpose of bus stop navigation, a purely visual approach can work well if combined with 

a typical macro-navigation apps. 

We have developed a mobile app, All_Aboard that recognizes bus stop signs to help the users 

navigate within a very short range of the physical location of the sign.29 When using the app, 

users can first use commonly available macro-navigation tools, such as Google Maps, to arrive 

within the vicinity of the bus stop location, and then they can scan the surroundings with their 

smartphone camera. The All_Aboard app detects the bus stop signs in real-time in the 

smartphone camera imagery, and can guide the users to approach bus stops through auditory 

cues, with the auditory pitch coding the distance to the target. Our preliminary testing of the 

All_Aboard app indicated its superior performance compared to Google Maps app.14  

The goal of this study was to evaluate All_Aboard in real-world conditions with BVI transit users 

and compare its localization ability with navigation via Google Maps app. Our primary 

hypothesis was that the localization based on All_Aboard app was significantly better than just 

using a conventional navigation app (Google Maps) in terms of distance to the desired bus-stop 

location and rate of successful localizations. Given that GPS-based localization typically suffers 

in densely built downtown areas, we further hypothesized that All_Aboard might be more 

effective in these locations compared to more sparsely populated sub-urban areas.   

Methods 

All_Aboard App 

One of the underlying ideas behind the All Aboard app is that the bus stop signage is unique 

(different than other road signs), uniform in appearance (typically, but not always), and 

standardized across the entire area of a transit agency (Figure 1A). Moreover, since the bus 

stop signs for a given transit agency have the same known physical size, one can estimate the 

approximate distance based on the image size (width) of the detected bus stop sign (the farther 

the distance, the smaller the image, and vice versa). Therefore, it is feasible for computer vision 

algorithms to learn the appearance of the bus stop signs, detect them in the images captured by 

smartphone cameras, and estimate the distance to the actual sign. Bus stop detection in 

All_Aboard is performed in real-time using a MobileNetv2 deep learning neural network,30 

trained on about 10000 images of bus stops collected for a given city/region. Images of bus stop 

signs were collected from the Google Street View imagery based on the publicly available bus 

stop coordinates via General Transit Feed Specification (GTFS) standard. The stop signs were 

manually labeled by placing a bounding box in the collected images. The trained model runs 

natively on the smartphone device (no cloud processing).  

Another key idea behind the operation of All_Aboard is that it supplements a macro-navigation 

app and thus only need to be operational in the general vicinity of the bus stop. In a typical 

usage scenario (Figure 1B), the user launches All_Aboard when a macro-navigation app 

(Google Maps etc.) indicates that the user is near the desired bus stop location. The All_Aboard 

app senses phone orientation and searches only when the device is held in an upright position. 

The user can then scan with the phone camera in an arc to first determine the angular 

orientation of the sign. A positive detection leads to a beeping sound and a true positive 

detection is typically indicated by a series of continuous auditory tones. Once locked in the 

direction of the sign, the auditory tones change in frequency as the user get near the bus stop 

sign (similar to a homing signal). Thus, the app can help users gauge relative distance to the 

sign and adjust their approach. There were four levels of audio tones, with the highest 

frequency indicated that the detected sign was within 2 meters (≈ 6 feet). After it is launched, 

the apps works without needing any active intervention from the user, as long as the device is 

held in an upright manner.  

The All_Aboard is available in App store and Play store for free, and it is capable of recognizing 

bus stops in 10 major cities/regions around the world. Once installed, the users can download 

the available trained neural network models for the corresponding transit agencies. In this study, 

the All_Aboard app was loaded with the model trained to detect bus stop signs of the 

Massachusetts Bay Transportation Authority (MBTA) that operates public transit in Boston 

metro area.   

B 

A 
Figure 1: (A) A typical MBTA bus stop sign at one of the trial location in downtown Boston. This is the 
most recent version of the signage, however, older versions with slightly different appearance but similar 
shapes persist throughout the coverage area. Very few bus stops in the area covered by the transit 
agency are sheltered, and the distinctive sign is often the only visual identification of the bus stop. (B) 
Operation of the All_Aboard app in the general vicinity of a bus stop. The lower inset shows the app 
detecting the bus stop sign (the bounding box is drawn around the detected sign in the camera view 
displayed on the smartphone screen. The upper inset shows a successful detection at night in low light 
conditions. A demonstration video of All_Aboard app in action can be found at 
https://www.youtube.com/watch?v=VUVpqEw1_2k.  

Participants 

The inclusion criteria were: vision status of legal blindness, independent mobility without 

assistance from a sighted guide, physical ability to walk over a distance of about 1 mile at a 

given time, and familiarity with smartphone/mobile devices. Participants for this study was 

recruited via referrals from the Carroll Center for the Blind Newton Massachusetts, practitioners 

at vision rehabilitation clinics, and via a pool of volunteers who had participated in prior studies. 

The study protocol was approved by the Institutional Review Board at Mass Eye & Ear. The 

study followed the tenets of the Declaration of Helsinki and written informed consent was 

 
 
obtained from all the participants. The participants were reimbursed for travel to the study sites 

and for their time. 

Study Design 

The study involved 2 visits at 2 separate study sites: downtown Boston (City) and near the 

campus of the Carroll Center for the Blind in Newton, Massachusetts (Suburb). Each study site 

involved navigating to 10 bus stops following a specific route (Figure 2). For each bus stop, 

performance with All_Aboard and Google Maps apps was evaluated with both the apps running 

simultaneously. During the study, the participants were accompanied by a certified orientation 

and mobility instructor (O&M) who provided directions along the route and ensured the safety of 

the participants during the study. Members of the study team also accompanied the participant 

and the O&M instructor, who administered the study and recorded measurements. For all trials, 

a preconfigured Android smartphone was provided to the participants. 

Before starting the study, each participant was provided oral instructions and hands-on training 

with using the All_Aboard app at a practice location. At the start of the trial at each bus stop 

location, the participant was guided by O&M instructor to a location that was about 30 to 50 

meters (≈100 to 150 feet) away from the bus stop sign along the direction of travel in 

approximately straight ahead direction. The starting distance from the stop sign was varied at 

each stop location to dissuade participants from guessing the stop location based on step 

counting. The path from the starting location to bus stop sign did not involve crossing streets, 

except in the case of one bus stop location in Newton, where the stop sign was affixed very 

close to the intersection. At the starting point for each trial, Google Maps app (operating in the 

pedestrian directions mode) was launched by the experimenter, StreetView calibration was 

done (this was one of the features of the Google Maps app that uses live camera imagery to 

geo-locate more accurately), and the mapped location of the said bus stop was set as the 

destination. Then, the All_Aboard app was launched such that both apps were running 

simultaneously, with Google Maps navigation window in the inset at the bottom of the screen 

(Figure 3A).  

Figure 2: Routes at the two study sites: downtown Boston (Left) and in Newton (Right).Each site had 
10 bus stop locations (indicated by numbers). The route is indicated by dashed black line. The bus 
stops in Newton were on the opposite side of the street such that the route was a loop that was 
traversed in the direction shown by the arrows.   

Then, the smartphone device was handed over to the participants. From this starting location, 

the participants was instructed to navigate as close to the bus stop sign as possible. They were 

also instructed to hold the smartphone upright with its rear camera pointing straight ahead 

(Figure 3B), and scan side-to-side to determine the relative orientation of the bus stop sign from 

their walking trajectory. After this point, the participants walked on their own, relying on their 

habitual mobility aid and their residual vision if present, along with the auditory feedback from 

the All_Aboard app. Meanwhile, the Google Maps app provided intermittent voice instructions, 

including distance to the destination in feet (which the participants soon learned were often 

unreliable). 

At the end of the trial at a bus stop location, the participants stopped and notified the 

experimenters when they thought they were closest to the bus stop sign as per their judgment. 

This was primarily based on the audio feedback by the All_Aboard app – when the audio tone 

 
frequency and pitch were at the highest levels indicating the detected sign was very close. A 

few participants could use their residual vision from this point onward to get even closer. 

Distance from where they stopped to the actual stop sign was measured with a tape measure. 

This was the localization distance for All_Aboard app. Google Maps app also indicated via 

auditory feedback when it determined that the participant arrived at the destination (Figure 3C). 

The distance between the bus stop sign and the arrival point according to Google Maps was 

also measured with the tape measure. 

At the time of their first study visit, the participants answered a brief survey that collected basic 

demographic information, vision status, use of vision aids, and their preferred transit options 

(public transit, rideshare, or private vehicle –family member driving). The level of vision was 

recorded either in terms of self-reported visual acuity in Snellen, or as light perception, or no 

light perception (in case of completely blind individuals).  

Figure 3: Running All_Aboard and Google Maps simultaneously to find bus stops. (A) 
Screenshot of the device at the start point. Both All_Aboard and Google Maps (inset) launched 
and run simultaneously. (B) An user holds the phone upright with the rear camera facing straight 
ahead. (C) Screenshot of the device when Google Maps indicate arrival at the destination. The 
All_Aboard app indicates the physical bus stop sign is still some distance ahead.     

 Outcome Measures 

The two main outcome measures, separately obtained for each app (All_Aboard and Google 

Maps), were: the localization error (gap distance) in meters and the rate of successful 

localizations (success rate). As mentioned above, the gap distance was obtained via direct 

measurement of the distance between app indicated/subject determined location of the bus stop 

and the physical location of the bus stop sign. When the All_Aboard guided the participant close 

enough for them to spot (via their residual vision) or identify the bus stop sign or touch the pole 

or post, the gap distance was marked as 0. If the app indicated location on the ground was 

beyond the physical bus stop sign with respect to the direction of travel, then the measured gap 

distance was recorded as negative. A trial instance was deemed as a failure if a reasonable 

 
measurable distance was not obtained. Success rate for each app was defined as % of 

locations for which a valid measurable distance along the travel path was available. 

At any given bus stop location, trial failures could occur because of various reasons.  In case of 

Google Maps app, incorrect mapping of the bus stops was one of the reasons. Such failures 

were predictable and repetitive across all the subjects because the location of the bus stop in 

the map was fundamentally incorrect. One cause of trial failure was the mapped location being 

more than 100 feet away from the physical bus stop. Another cause of trial failure with Google 

Maps app was catastrophic inaccuracies in geolocation and consequent navigation directions, 

for example, when the app directed the users to cross streets, double-back, or go around a 

corner, which would lead them completely miss the bus stop. These failures were more 

prevalent in the downtown Boston area with tall buildings and/or on overcast/rainy days.  

In the case of All_Aboard app, trial failure could occur because of detection failures due to false 

negatives or deficient technique by the subjects while using the app. Shadows and occlusions 

could lead to the app to fail to recognize a bus stop sign. Signage largely slanting away from the 

side walk direction can cause the app fail to detect. On other occasions, the subjects did not 

scan sufficiently while walking towards the bus stop sign and lost the audio signal. If the bus 

stop sign was initially detected but then went outside the field of view of the camera as the 

subject approached, the continuous audio signal suddenly stopped. This was an indicator to the 

subjects that they either passed the sign or are too close to it. They were allowed to retrace their 

steps and try again once to zero-in or confirm the presence of the stop sign in the near vicinity. 

If major intervention by O&M or the experimenter was needed to reorient the subject after initial 

failure to detect, then the trail was considered as a failure for the All_Aboard app for the given 

location, even if the sign was successfully detected in the subsequent tries. 

Statistical Analysis 

Potential factors of interest affecting the outcome measures were app used (All_Aboard or 

Google Maps), the study location (City vs. Suburb), and the vision status (with or without 

residual vision). Completely blind subjects without light perception were categorized as without 

residual vision, while the rest were with residual vision. Vision in the better eye was used for this 

categorization. Association of gap distance with these above potential variables was analyzed 

within-subject via a linear model in repeated measures framework. The success rate was 

analyzed using a binary logistic regression. In addition to the main effects, the interaction 

between the above 3 factors were also examined. Estimated marginal means with their 95% 

confidence intervals and contrasts are reported for gap distance. Estimated mean marginal 

probability of success and the 95% confidence interval is reported from the logistic regression 

model for success rate. P values <0.05 were considered statistically significant. Statistical 

analysis was performed using statistical packages in R (ver. 4.0.4).31-36         

Results 

Total 25 subjects were recruited, of which, data for both study sites was available for 24 

subjects (see Table 1 for summary of subject characteristics). One subject was dropped from 

the trial after first visit due to the concerns about overall physical fitness required to complete 

the study. Eleven participants (46%) were female. A variety of conditions affected the vision of 

the participants. While all were legally blind in the US, their vision ranged from completely blind 

to 20/200 vision. The majority walked with long cane and all except one used an iPhone in their 

daily lives. Public transit was the most preferred transit option, followed by rideshare and private 

vehicle.   

N 

24 

Table 1: Study participant characteristics. 

Age (years) 

Median: 55, IQR: 41 – 61, Min.: 20, Max.: 71 

Gender  

Female: 11 (46%) 

Vision 

Vision disorders 

Available VA measure – N: 11 (46%), range: [20/200 – 20/1200] 
Light Perception – N: 6 (25%) 
No Light Perception – N: 7 (29%) 

RoP: 5, retinitis pigmentosa: 4, retinal detachment: 3, glaucoma: 2;  
One case each of: age-related macular degeneration, optic atrophy, 
aniridia, cone dystrophy, retinal artery occlusion, charge syndrome, 
monochromacy, diabetic retinopathy, Norrie syndrome 

Duration of vision 
loss 

At birth: 14 (58%) 
Acquired: 8, Median duration: 18 years, range: [3 – 41 years]  
Data not available: 2 

Mobility aids used 

Long cane: 16 (67%) 
Guide dog: 6 (25%) 
None: 2 (8%) 

Most preferred 
transit option 

Habitual 
smartphone 

Public Transit - 1st: 11, 2nd: 7, 3rd: 3, NA: 3 
Rideshare -  1st: 9, 2nd: 11, 3rd: 2, NA: 2 
Private car -  1st: 4, 2nd: 5, 3rd: 8, NA: 7 

iPhone 23 (96%) 

Table 2 shows the trial instances and other data for both apps and at each study site. Across 24 

subjects, there were supposed to be trials at 480 designated bus stops. However, over the 

course of the study, some bus stops were skipped due to construction or missing bus stop 

signs, resulting in a total of 48 instances with missing data. Therefore, each app was evaluated 

in a total of 432 instances. Overall success rate and gap distance measures were substantially 

better with All_Aboard app than Google Maps. 

Table 2: Cumulative statistics for trial data. 

Both Apps  Google Maps  All_Aboard 

Bus stop 
instances 
with 
available 
data 

Skipped 
instances 

Both sites 

City 

Suburb 

Both sites 

City 

864 

458 

406 

96 

22 

432 

229 

203 

48 

11 

432 

229 

203 

48 

11 

 
(missing 
data) 

Number of 
successful 
instances 

Success 
rate (%) 

Average 
[SD] gap 
distance 
(m) 

Suburb 

Both sites 

City 

Suburb 

Both sites 

City 

Suburb 

74 

626 

329 

297 

72 

72 

73 

37 

225 

112 

113 

52 

49 

56 

37 

401 

217 

184 

93 

95 

91 

Both sites 

3.36 [3.65] 

6.62 [4.15] 

1.54 [1.36] 

City 

3.04 [3.82] 

6.26 [4.89] 

1.38 [1.34] 

Suburb 

3.72 [3.41] 

6.97 [3.24] 

1.72 [1.36] 

 In Table 2, successful instances with each app are listed independently of each other. When 

compared pairwise at each bus stop instance (Table 3), there were only a handful of instances 

where both apps failed (18 out of 432 or about 4%). There were 13 (3%) instances where 

All_Aboard failed but Google Maps succeeded, and there were 189 (44%) instances where 

Google Maps failed but All_Aboard succeeded. For the former cases, the average [SD] gap 

distance was 9.3[5] meters, and for the latter cases, the average [SD] gap distance with 

All_Aboard was 1.6[1.4] meters. From 225 successful instances with Google Maps, the arrival 

location was mapped past the bus stop sign along the direction of travel in 60 instances (about 

27%), with an average gap distance of 7.2[2.9] meters.  

Table 3: 2x2 tables showing joint successes or failures of the All_Aboard and Google Maps over all 432 
bus stop instances.  

Overall 

City 

Suburb 

Google 
Maps 
Success 

Google 
Maps 
Failure 

Google 
Maps 
Success 

Google 
Maps 
Failure 

Google 
Maps 
Success 

Google 
Maps 
Failure 

All_Aboard 
Success 

All_Aboard 
Failure 

212 

189 

106 

116 

106 

13 

18 

6 

6 

7 

78 

12 

 
There was no significant effect of subject age, gender, or the kind of mobility aid used on the 

gap distance or on the success rate.  The results and discussion is mostly related to 3 key 

factors: the app used, study site, and subject group based on their vision status. 

Gap distance (in meters), averaged over vision status and study sites, was significantly smaller 

with All_Aboard (mean: 1.8, 95% CI: 1.3-2.3) compared to Google Maps (mean: 7.0, 95% CI: 

6.5-7.5; p<0.001). Gap distance with All_Aboard was significantly smaller than Google Maps in 

City and Suburb, as well as in subjects with or without residual vision (Figure 4A). The gap 

distance was significantly larger in completely blind group (mean: 8.4, 95% CI: 7.3-9.5) 

compared to those with residual vision (mean: 5.4, 95% CI: 4.7-6.1; p<0.001) in the City with 

Google Maps. No significant effect of vision status on the gap distance with All_Aboard was 

observed. A significant effect of study site was seen only in the case of Google Maps in subjects 

with residual vision, where gap distance in the Suburb (mean: 6.8, 95% CI: 6.1-7.5) was 

significantly larger than that observed in the City (mean: 5.4, 95% CI: 4.7-6.1; p<0.022). Again, 

no significant effect of study site was observed for gap distance resulting from the All_Aboard 

app.  

A 

B 

Figure 4: Outcome measures by app, location, and vision status. (A) The gap distance with All_Aboard 
was significantly smaller than Google Maps in both sites and in both subject groups. Those with 
residual vision achieved significantly smaller gap distance compared to completely blind with Google 
Maps in City. Gap distance in City was significantly lower than Suburb in the case of subjects with 
residual vision with Google Maps. (B)  The success rate with All_Aboard was significantly higher in both 
sites and in subjects with and without residual vision. Completely blind individuals when using 
All_Aboard in the Suburb had significantly lower success rate compared to those with residual vision. 
For all panels: error bars show 95% confidence interval of the mean; significance levels:  *** : p<0.001, 
** : p=0.001 – 0.01, and * : p=0.01 – 0.05; P value adjustment: BH method for 4 tests. 

The success rate with All_Aboard was significantly higher than Google Maps across both study 

sites and both the subject groups (Figure 4B). The overall success rate with All_Aboard (mean: 

0.91, 95% CI: 0.87-0.94), averaged over study sites and subject group factors, was about 75% 

higher than Google Maps (mean: 0.52, 95% CI: 0.47-0.58; p<0.001). When using All_Aboard in 

the Suburban location, the success rate for completely blind subjects (mean: 0.8, 95% CI: 0.69-

0.90; p<0.001) was slightly but statistically significantly lower compared to those with residual 

vision (mean: 0.95, 95% CI: 0.91-0.98; p<0.001). Otherwise, there was no significant difference 

in success rates for any other conditions.  

Discussion 

 
 
When people (normally sighted or BVI) take buses in areas like Boston metro region, where 

most bus stops are indicated just by a sign on a post, standing even a short distance away from 

the sign may cause the buses do not stop for them. This accessibility challenge may diminish 

independence, compromise adoption of affordable transportation for BVI travelers.1 This is just 

one of the last-10-meter navigation assistance needs of BVI individuals that is unmet. In this 

study, we evaluated the ability of All_Aboard app relative to the Google Maps navigation app in 

guiding BVI travelers accurately to bus stop locations in urban and suburban settings. The rate 

of successful localization of bus stops was substantially higher and the gap distance was much 

smaller when using All_Aboard app compared to Google Maps navigation. On average, the 

All_Aboard app was able to guide the subjects within about 2 meters (6 feet) of the bus stop 

sign, whereas with Google Maps they were likely to be about 7 meters (23 feet) away. The large 

effect size of All_Aboard app in terms of success rate of localization and the gap distance was 

observed irrespective of the location of testing, the vision status of the subjects, other 

demographic characteristics, and the kind of mobility aids they used. Thus, our findings 

demonstrate that All_Aboard app could provide a reliable benefit in navigation by accurately 

detecting the bus stop sings and guiding the users close enough to the designated stop that 

makes it less likely that a bus will pass by them for standing too far from the bus stops. 

Importantly, this study validates that computer vision-based object recognition capabilities can 

be used in a complementary way and provide added benefit to purely location-based navigation 

services in real-world settings. 

During the study design, we were expecting some difference in performance in a city vs. 

suburban location based on our previous preliminary study,14 due to the well-known limitations 

of location-based services in areas with tall structures. Therefore, we did not expect a significant 

effect of location on All_Aboard app, and the findings were more or less consistent with this 

expectation. In case of Google Maps, City vs. Suburb setting did not have any significant effect 

on the success rate, and its effect on gap distance relatively modest (slight but statistically 

significant difference was seen only in subjects with residual vision). The primary reason for this 

lack of a location effect was that the localization error in the City was somewhat balanced or 

counteracted by large mapping errors in the Suburb. Thus, despite better localization accuracy 

of Google Maps in the Suburb, large mapping errors meant that almost the same proportion of 

trials were unsuccessful as in the City.      

While we enrolled participants with a wide range of visual abilities – from completely blind up to 

visual acuity of 20/200, we analyzed only the effect residual vision presence on the performance 

with the navigation apps. If the All_Aboard app could successfully guide low vision travelers 

close to the bus stop sign, it was possible that they could use their residual vision (even if it was 

only restricted to shape or perform perception) from there on to navigate further close to the 

sign. We indeed observed this behavior in a few participants. However, as a whole, gap 

distance was not significantly different between those with or without residual vision – indicating 

that the app already guided the subjects close enough to the bus stop sign, such that any 

further change due to residual vision was not large in terms of distance. However, trial success 

rate was affected by residual vision presence in the Suburb, as completely blind subjects 

experienced significantly more failures with All_Aboard app compared to those with residual 

vision. A possible reason for higher failure rate in the Suburb could be because some of the bus 

stop signs on that site were not properly placed. Some were occluded by trees, slanting towards 

the street instead of the sidewalk, or not at the edge of street curb. In these situations, scanning 

sufficiently wide is crucial. However, completely blind subjects tended to scan across a narrow 

range or not scan at all due to complete loss of visual input to help with orientation. Therefore, 

they were more likely to miss signs that are slightly more difficult to find. More training and 

practicing on scanning skills might help improve their success rate in these situations. 

Acknowledgments 

The All_aboard app development was funded in part by Microsoft AI4A award. The authors 

would like thank Nick Corbett and Dinna Rosenbaum from the Carroll Center for the Blind for 

their help with participant recruitment and coordination.           

References 

1 

2 

3 

4 

5 

6 

7 

8 

9 

Crudden, A., McDonnall, M. C. & Hierholzer, A. Transportation: An Electronic Survey of 
Persons who Are Blind or Have Low Vision. Journal of Visual Impairment & Blindness 
109, 445-456, doi:10.1177/0145482x1510900603 (2015). 

Pundlik, S., Shivshanker, P. & Luo, G. Impact of Apps as Assistive Devices for Visually 
Impaired Persons. Annual Review of Vision Science 9, null, doi:10.1146/annurev-vision-
111022-123837 (2023). 

US Department of Justice Civil Rights Division.     (2010). 

Marston, J. R. & Golledge, R. G. The Hidden Demand for Participation in Activities and 
Travel by Persons who are Visually Impaired. Journal of Visual Impairment & Blindness 
97, 475-488, doi:10.1177/0145482x0309700803 (2003). 

Park, J. & Chowdhury, S. Investigating the barriers in a typical journey by public 
transport users with disabilities. Journal of Transport & Health 10, 361-368, 
doi:https://doi.org/10.1016/j.jth.2018.05.008 (2018). 

Visnes Øksenholt, K. & Aarhaug, J. Public transport and people with impairments – 
exploring non-use of public transport through the case of Oslo, Norway. Disability & 
Society 33, 1280-1302, doi:10.1080/09687599.2018.1481015 (2018). 

Wong, S. Traveling with blindness: A qualitative space-time approach to understanding 
visual impairment and urban mobility. Health & Place 49, 85-92, 
doi:https://doi.org/10.1016/j.healthplace.2017.11.009 (2018). 

Low, W.-Y., Cao, M., De Vos, J. & Hickman, R. The journey experience of visually 
impaired people on public transport in London. Transport Policy 97, 137-148, 
doi:https://doi.org/10.1016/j.tranpol.2020.07.018 (2020). 

Jonnalagedda, A. et al. Enhancing the Safety of Visually Impaired Travelers in and 
around Transit Stations. (The Robotics Institute Carnegie Mellon University, 2014). 

10 

11 

12 

13 

14 

15 

16 

17 

18 

Golledge, R. G., Marston, J. R. & Costanzo, C. M. Attitudes of Visually Impaired Persons 
toward the Use of Public Transportation. Journal of Visual Impairment & Blindness 91, 
446-459, doi:10.1177/0145482x9709100505 (1997). 

Azenkot, S. et al. in Proceedings of the SIGCHI Conference on Human Factors in 
Computing Systems    3247–3256 (Association for Computing Machinery, Vancouver, 
BC, Canada, 2011). 

Hara, K. et al. Improving Public Transit Accessibility for Blind Riders by Crowdsourcing 
Bus Stop Landmark Locations with Google Street View: An Extended Analysis. ACM 
Trans. Access. Comput. 6, Article 5, doi:10.1145/2717513 (2015). 

Perkins School for the Blind. BlindWays: a crowdsourced bus stop location app 
https://www.perkins.org/resource/blindways-crowdsourced-bus-stop-location-app/, (last 
accessed Aug. 2023)). 

Jiang, E. et al. Field testing of All Aboard, an AI app for helping blind individuals to find 
bus stops. Investigative Ophthalmology & Visual Science 62, 3529-3529 (2021). 

Luo, G. & Pundlik, S. Widespread Errors in Bus Stop Location Mapping is an 
Accessibility Barrier for Passengers Who are Blind or Have Low Vision. Journal of Visual 
Impairment & Blindness, doi:10.1177/0145482X231201807 (2023). 

Kuyk, T. K., Liu, L. & Fuhr, P. S. Feature Search in Persons with Severe Visual 
Impairment. Vision Research 45, 3224–3234 (2005). 

Luo, G., Satgunam, P. & Peli, E. Visual Search Performance of Patients with Vision 
Impairment: Effect of Jpeg Image Enhancement. Ophthalmic Physiol Opt 32, 421–428 
(2012). 

Sáez, Y., Muñoz, J., Canto, F., García, A. & Montes, H. Assisting Visually Impaired 
People in the Public Transport System through RF-Communication and Embedded 
Systems. Sensors 19, 1282 (2019). 

19 

Alvarado, A. et al. in Transportation Research Board. 

20 

Chen, H.-E., Lin, Y.-Y., Chen, C.-H. & Wang, I.-F. in Proceedings of the 33rd Annual 
ACM Conference Extended Abstracts on Human Factors in Computing Systems    19–
24 (Association for Computing Machinery, Seoul, Republic of Korea, 2015). 

21 

22 

23 

Parker, A. T. et al. Wayfinding Tools for People With Visual Impairments in Real-World 
Settings: A Literature Review of Recent Studies. Frontiers in Education 6, 
doi:10.3389/feduc.2021.723816 (2021). 

El-taher, F. E.-z., Taha, A., Courtney, J. & Mckeever, S. A Systematic Review of Urban 
Navigation Systems for Visually Impaired People. Sensors 21, 3103 (2021). 

Campbell, M., Bennett, C., Bonnar, C. & Borning, A. in Proceedings of the 16th 
international ACM SIGACCESS conference on Computers & accessibility    11–18 
(Association for Computing Machinery, Rochester, New York, USA, 2014). 

24 

BlindSquare. https://www.blindsquare.com/about/, accessed Aug. 2023). 

25 

Lazarillo. Inclusive navigation and digital maps, accessed Aug. 2023). 

26 

Lock, J. C., Cielniak, G. & Bellotto, N. in AAAI Spring Symposia. 

27 

28 

29 

30 

31 

32 

Saha, M., Fiannaca, A. J., Kneisel, M., Cutrell, E. & Morris, M. R. in Proceedings of the 
21st International ACM SIGACCESS Conference on Computers and Accessibility    
222–235 (Association for Computing Machinery, Pittsburgh, PA, USA, 2019). 

Feng, J. et al. Commute Booster: A Mobile Application for First/Last Mile and Middle Mile 
Navigation Support for People with Blindness and Low Vision. IEEE Journal of 
Translational Engineering in Health and Medicine, 1-1, 
doi:10.1109/JTEHM.2023.3293450 (2023). 

Massachusetts Eye & Ear Infirmary. All_Aboard. Find bus stops for the blind 
https://apps.apple.com/us/app/all-aboard/id1580638469, accessed Aug. 2023). 

Sandler, M. & Howard, A. MobileNetV2: The Next Generation of On-Device Computer 
Vision Networks https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-
on.html, 2018). 

Bates, D., Mächler, M., Bolker, B. & Walker, S. Fitting Linear Mixed-Effects Models 
Using lme4. Journal of Statistical Software 67, 1 - 48, doi:10.18637/jss.v067.i01 (2015). 

Brooks, M. E. et al. glmmTMB Balances Speed and Flexibility Among Packages for 
Zero-inflated Generalized Linear Mixed Modeling. The R Journal 9, 378–400, 
doi:10.32614/RJ-2017-066 (2017). 

33 

34 

35 

emmeans: Estimated Marginal Means, aka Least-Squares Means. R package version 
1.7.2. https://CRAN.R-project.org/package=emmeans (2022). 

Lüdecke, D., Ben-Shachar, M., Patil, I., Waggoner, P. & Makowski, D. performance: An 
R Package for Assessment, Comparison and Testing of Statistical Models. Journal of 
Open Source Software 6, 3139, doi:10.21105/joss.03139 (2021). 

DHARMa: Residual Diagnostics for Hierarchical (Multi-Level / Mixed) Regression 
Models. R package version 0.4.1. https://CRAN.R-project.org/package=DHARMa 
(2021). 

36  Wickham, H. ggplot2: Elegant Graphics for Data Analysis Vol. 
https://ggplot2.tidyverse.org. (Springer-Verlag, 2016). 

 
","Field evaluation of a mobile app for assisting blind and visually impaired travelers to find bus stops Shrinivas Pundlik 1 , Prerana Shivshanker 1 , Tim Traut-Savino 2 , Gang Luo 1 1 . Schepens Eye Research Institute of Mass Eye & Ear , Harvard Medical School Boston , MA 2 . The Carroll Center for the Blind , MA Corresponding Author : Gang Luo ( gang.luo @ schepens.harvard.edu ) Keywords : vision aid , navigation , mobility , accessibility , deep learning , computer vision , public transportation Commercial Relationships : The authors declared no potential conflicts of interest with respect to the research , authorship , and/or publication of this article . The All_Aboard app evaluated in this study is released to public for free . There is no revenue from app sale or in-app advertisements . Abstract Purpose : It is reported that there can be considerable gaps due to GPS inaccuracy and mapping errors if blind and visually impaired ( BVI ) travelers rely on digital maps to go to their desired bus stops . We evaluated the ability of a mobile app , All_Aboard , to guide BVI travelers precisely to the bus-stops . Methods : The All_Aboard app detected bus-stop signs in real-time via smartphone camera using a neural network model , and provided distance coded audio feedback to help localize the detected sign . BVI individuals used the All_Aboard and Google Maps app to localize 10 bus- stop locations in Boston downtown and another 10 in a sub-urban area . For each bus stop , the subjects used the apps to navigate as close as possible to the physical bus-stop sign , starting from 30 to 50 meters away . The outcome measures were success rate and gap distance between the app-indicated location and the actual physical location of the bus stop . Results : The study was conducted with 24 legally blind participants ( mean age [ SD ] : 51 [ 14 ] years ; 11 ( 46 % ) Female ) . The success rate of the All_Aboard app ( 91 % ) was significantly higher than the Google Maps ( 52 % , p < 0.001 ) . The gap distance when using the All_Aboard app was significantly lower ( mean [ 95 % CI ] : 1.8 [ 1.2-2.3 ] meters ) compared to the Google Maps ( 7 [ 6.5-7.5 ] meters ; p < 0.001 ) . Conclusion : The All_Aboard app localizes bus stops more accurately and reliably than GPS- based smartphone navigation options in real-world environments . Translational Relevance : The All_Aboard mobile app navigation aid can be potentially help BVI individuals independently travel via public transportation . Introduction Blind and visually impaired ( BVI ) people often rely on public transportation , such as buses and subways , to travel for employment , leisure or for other needs.1 Geolocation and transportation information accessed through smartphones has greatly facilitated macro-navigation for BVI people . For example , one can plan a route and get detailed instructions on mobile devices for point-to-point navigation using public transits . Navigation apps make up one of the major groups of vision assistance mobile apps available in App store and Play store . 2 On the other hand , micro-navigation – navigating precisely to the desired destination at any stage of the journey , remains a largely unsolved issue for BVI individuals . To comply with the Americans with Disabilities Act ( 1990 ) , regional transit agencies are required to comply with regulations regarding the accessibility of transit infrastructures.3 In the context of vision disabilities , the requirements include placing of large-print signage at bus stops , providing braille and tactile information within transit stations , and making stop announcements inside transit vehicles at main points , among others . However , poor interface and lack of cues accessible from distance , for example transit stop signage , are one of the main barriers to equal access to public transportation.4-9 Systemic inaccuracies in the GPS based location services is the underlying problem that leads to micro-navigation challenges faced by people with BVI . This is also referred to as the last 30 feet or last 10 m problem in wayfinding . For example , when navigating to a bus stop , a blind person following any GPS-based navigation app , may arrive at the app indicated location that has a considerable gap ( typically 10 m or 30 feet ) from the actual bus stop due to the localization error in the GPS service . For perspective , this 10 m gap could be almost equal to an entire bus length in certain regions . According to the feedback from blind travelers , sometimes even a small gap can be large enough for them to miss the bus because the bus drivers misunderstand their intention and not stop for them.10-13 In the worst-case scenario , especially in crowded cities , the GPS localization may be off by more than a block , making the macro navigation apps essentially useless in pedestrian mode.14 Weather and location ( density of tall buildings in downtown areas for example ) can further affect GPS-based localization . In addition to localization error , there is a possibility of mapping errors ( sometimes large ) in the stop locations made publicly available by the transit agencies . In our survey of 174 bus stop locations in Boston metro area , about 23 % were mapped more than 2 bus lengths away . 15 Mapping and localization errors together contribute towards making purely location-based services unreliable for micro-navigation tasks , such as finding bus stops . Making matters worse , bus stop signs can be one of many signs on a typical urban street ( among traffic/parking signs and street signs ) , and thus finding it becomes a visual search task , in addition to a plain geolocation task . Since visual search performance is known to be significantly degraded in people with low vision,16,17 it is evident that a navigation aid is needed for micro- navigation with visual search capabilities . One of the conventional wayfinding solutions is the use of Bluetooth beacons to provide micro- location information with high accuracy on nearby landmarks.18-22 This approach ’ s scalability and applicability in outdoor environments are restricted due to the high cost for infrastructure modification and maintenance . On the other hand , smartphones could allow rapid scaling of accessibility . A few smartphone apps have been developed , tested , or released to help blind and visually impaired people access public transportation specifically , or to navigate to destinations in general.23-25 These apps are primarily GPS-based , and therefore still subject to the limitations of GPS-based navigation systems detailed above . In order to achieve localization more accurately , some apps combine location information together with landmark recognition.12,13,26,27 However , landmark maps around the various locations have to be built , maintained , and made widely available prior to use . Combing signage information extracted from GTFS with optical character recognition could provide a viable micro-navigation solution.28 For the purpose of bus stop navigation , a purely visual approach can work well if combined with a typical macro-navigation apps . We have developed a mobile app , All_Aboard that recognizes bus stop signs to help the users navigate within a very short range of the physical location of the sign.29 When using the app , users can first use commonly available macro-navigation tools , such as Google Maps , to arrive within the vicinity of the bus stop location , and then they can scan the surroundings with their smartphone camera . The All_Aboard app detects the bus stop signs in real-time in the smartphone camera imagery , and can guide the users to approach bus stops through auditory cues , with the auditory pitch coding the distance to the target . Our preliminary testing of the All_Aboard app indicated its superior performance compared to Google Maps app.14 The goal of this study was to evaluate All_Aboard in real-world conditions with BVI transit users and compare its localization ability with navigation via Google Maps app . Our primary hypothesis was that the localization based on All_Aboard app was significantly better than just using a conventional navigation app ( Google Maps ) in terms of distance to the desired bus-stop location and rate of successful localizations . Given that GPS-based localization typically suffers in densely built downtown areas , we further hypothesized that All_Aboard might be more effective in these locations compared to more sparsely populated sub-urban areas . Methods All_Aboard App One of the underlying ideas behind the All Aboard app is that the bus stop signage is unique ( different than other road signs ) , uniform in appearance ( typically , but not always ) , and standardized across the entire area of a transit agency ( Figure 1A ) . Moreover , since the bus stop signs for a given transit agency have the same known physical size , one can estimate the approximate distance based on the image size ( width ) of the detected bus stop sign ( the farther the distance , the smaller the image , and vice versa ) . Therefore , it is feasible for computer vision algorithms to learn the appearance of the bus stop signs , detect them in the images captured by smartphone cameras , and estimate the distance to the actual sign . Bus stop detection in All_Aboard is performed in real-time using a MobileNetv2 deep learning neural network,30 trained on about 10000 images of bus stops collected for a given city/region . Images of bus stop signs were collected from the Google Street View imagery based on the publicly available bus stop coordinates via General Transit Feed Specification ( GTFS ) standard . The stop signs were manually labeled by placing a bounding box in the collected images . The trained model runs natively on the smartphone device ( no cloud processing ) . Another key idea behind the operation of All_Aboard is that it supplements a macro-navigation app and thus only need to be operational in the general vicinity of the bus stop . In a typical usage scenario ( Figure 1B ) , the user launches All_Aboard when a macro-navigation app ( Google Maps etc . ) indicates that the user is near the desired bus stop location . The All_Aboard app senses phone orientation and searches only when the device is held in an upright position . The user can then scan with the phone camera in an arc to first determine the angular orientation of the sign . A positive detection leads to a beeping sound and a true positive detection is typically indicated by a series of continuous auditory tones . Once locked in the direction of the sign , the auditory tones change in frequency as the user get near the bus stop sign ( similar to a homing signal ) . Thus , the app can help users gauge relative distance to the sign and adjust their approach . There were four levels of audio tones , with the highest frequency indicated that the detected sign was within 2 meters ( ≈ 6 feet ) . After it is launched , the apps works without needing any active intervention from the user , as long as the device is held in an upright manner . The All_Aboard is available in App store and Play store for free , and it is capable of recognizing bus stops in 10 major cities/regions around the world . Once installed , the users can download the available trained neural network models for the corresponding transit agencies . In this study , the All_Aboard app was loaded with the model trained to detect bus stop signs of the Massachusetts Bay Transportation Authority ( MBTA ) that operates public transit in Boston metro area . B A Figure 1 : ( A ) A typical MBTA bus stop sign at one of the trial location in downtown Boston . This is the most recent version of the signage , however , older versions with slightly different appearance but similar shapes persist throughout the coverage area . Very few bus stops in the area covered by the transit agency are sheltered , and the distinctive sign is often the only visual identification of the bus stop . ( B ) Operation of the All_Aboard app in the general vicinity of a bus stop . The lower inset shows the app detecting the bus stop sign ( the bounding box is drawn around the detected sign in the camera view displayed on the smartphone screen . The upper inset shows a successful detection at night in low light conditions . A demonstration video of All_Aboard app in action can be found at https : //www.youtube.com/watch ? v=VUVpqEw1_2k . Participants The inclusion criteria were : vision status of legal blindness , independent mobility without assistance from a sighted guide , physical ability to walk over a distance of about 1 mile at a given time , and familiarity with smartphone/mobile devices . Participants for this study was recruited via referrals from the Carroll Center for the Blind Newton Massachusetts , practitioners at vision rehabilitation clinics , and via a pool of volunteers who had participated in prior studies . The study protocol was approved by the Institutional Review Board at Mass Eye & Ear . The study followed the tenets of the Declaration of Helsinki and written informed consent was obtained from all the participants . The participants were reimbursed for travel to the study sites and for their time . Study Design The study involved 2 visits at 2 separate study sites : downtown Boston ( City ) and near the campus of the Carroll Center for the Blind in Newton , Massachusetts ( Suburb ) . Each study site involved navigating to 10 bus stops following a specific route ( Figure 2 ) . For each bus stop , performance with All_Aboard and Google Maps apps was evaluated with both the apps running simultaneously . During the study , the participants were accompanied by a certified orientation and mobility instructor ( O & M ) who provided directions along the route and ensured the safety of the participants during the study . Members of the study team also accompanied the participant and the O & M instructor , who administered the study and recorded measurements . For all trials , a preconfigured Android smartphone was provided to the participants . Before starting the study , each participant was provided oral instructions and hands-on training with using the All_Aboard app at a practice location . At the start of the trial at each bus stop location , the participant was guided by O & M instructor to a location that was about 30 to 50 meters ( ≈100 to 150 feet ) away from the bus stop sign along the direction of travel in approximately straight ahead direction . The starting distance from the stop sign was varied at each stop location to dissuade participants from guessing the stop location based on step counting . The path from the starting location to bus stop sign did not involve crossing streets , except in the case of one bus stop location in Newton , where the stop sign was affixed very close to the intersection . At the starting point for each trial , Google Maps app ( operating in the pedestrian directions mode ) was launched by the experimenter , StreetView calibration was done ( this was one of the features of the Google Maps app that uses live camera imagery to geo-locate more accurately ) , and the mapped location of the said bus stop was set as the destination . Then , the All_Aboard app was launched such that both apps were running simultaneously , with Google Maps navigation window in the inset at the bottom of the screen ( Figure 3A ) . Figure 2 : Routes at the two study sites : downtown Boston ( Left ) and in Newton ( Right ) .Each site had 10 bus stop locations ( indicated by numbers ) . The route is indicated by dashed black line . The bus stops in Newton were on the opposite side of the street such that the route was a loop that was traversed in the direction shown by the arrows . Then , the smartphone device was handed over to the participants . From this starting location , the participants was instructed to navigate as close to the bus stop sign as possible . They were also instructed to hold the smartphone upright with its rear camera pointing straight ahead ( Figure 3B ) , and scan side-to-side to determine the relative orientation of the bus stop sign from their walking trajectory . After this point , the participants walked on their own , relying on their habitual mobility aid and their residual vision if present , along with the auditory feedback from the All_Aboard app . Meanwhile , the Google Maps app provided intermittent voice instructions , including distance to the destination in feet ( which the participants soon learned were often unreliable ) . At the end of the trial at a bus stop location , the participants stopped and notified the experimenters when they thought they were closest to the bus stop sign as per their judgment . This was primarily based on the audio feedback by the All_Aboard app – when the audio tone frequency and pitch were at the highest levels indicating the detected sign was very close . A few participants could use their residual vision from this point onward to get even closer . Distance from where they stopped to the actual stop sign was measured with a tape measure . This was the localization distance for All_Aboard app . Google Maps app also indicated via auditory feedback when it determined that the participant arrived at the destination ( Figure 3C ) . The distance between the bus stop sign and the arrival point according to Google Maps was also measured with the tape measure . At the time of their first study visit , the participants answered a brief survey that collected basic demographic information , vision status , use of vision aids , and their preferred transit options ( public transit , rideshare , or private vehicle –family member driving ) . The level of vision was recorded either in terms of self-reported visual acuity in Snellen , or as light perception , or no light perception ( in case of completely blind individuals ) . Figure 3 : Running All_Aboard and Google Maps simultaneously to find bus stops . ( A ) Screenshot of the device at the start point . Both All_Aboard and Google Maps ( inset ) launched and run simultaneously . ( B ) An user holds the phone upright with the rear camera facing straight ahead . ( C ) Screenshot of the device when Google Maps indicate arrival at the destination . The All_Aboard app indicates the physical bus stop sign is still some distance ahead . Outcome Measures The two main outcome measures , separately obtained for each app ( All_Aboard and Google Maps ) , were : the localization error ( gap distance ) in meters and the rate of successful localizations ( success rate ) . As mentioned above , the gap distance was obtained via direct measurement of the distance between app indicated/subject determined location of the bus stop and the physical location of the bus stop sign . When the All_Aboard guided the participant close enough for them to spot ( via their residual vision ) or identify the bus stop sign or touch the pole or post , the gap distance was marked as 0 . If the app indicated location on the ground was beyond the physical bus stop sign with respect to the direction of travel , then the measured gap distance was recorded as negative . A trial instance was deemed as a failure if a reasonable measurable distance was not obtained . Success rate for each app was defined as % of locations for which a valid measurable distance along the travel path was available . At any given bus stop location , trial failures could occur because of various reasons . In case of Google Maps app , incorrect mapping of the bus stops was one of the reasons . Such failures were predictable and repetitive across all the subjects because the location of the bus stop in the map was fundamentally incorrect . One cause of trial failure was the mapped location being more than 100 feet away from the physical bus stop . Another cause of trial failure with Google Maps app was catastrophic inaccuracies in geolocation and consequent navigation directions , for example , when the app directed the users to cross streets , double-back , or go around a corner , which would lead them completely miss the bus stop . These failures were more prevalent in the downtown Boston area with tall buildings and/or on overcast/rainy days . In the case of All_Aboard app , trial failure could occur because of detection failures due to false negatives or deficient technique by the subjects while using the app . Shadows and occlusions could lead to the app to fail to recognize a bus stop sign . Signage largely slanting away from the side walk direction can cause the app fail to detect . On other occasions , the subjects did not scan sufficiently while walking towards the bus stop sign and lost the audio signal . If the bus stop sign was initially detected but then went outside the field of view of the camera as the subject approached , the continuous audio signal suddenly stopped . This was an indicator to the subjects that they either passed the sign or are too close to it . They were allowed to retrace their steps and try again once to zero-in or confirm the presence of the stop sign in the near vicinity . If major intervention by O & M or the experimenter was needed to reorient the subject after initial failure to detect , then the trail was considered as a failure for the All_Aboard app for the given location , even if the sign was successfully detected in the subsequent tries . Statistical Analysis Potential factors of interest affecting the outcome measures were app used ( All_Aboard or Google Maps ) , the study location ( City vs . Suburb ) , and the vision status ( with or without residual vision ) . Completely blind subjects without light perception were categorized as without residual vision , while the rest were with residual vision . Vision in the better eye was used for this categorization . Association of gap distance with these above potential variables was analyzed within-subject via a linear model in repeated measures framework . The success rate was analyzed using a binary logistic regression . In addition to the main effects , the interaction between the above 3 factors were also examined . Estimated marginal means with their 95 % confidence intervals and contrasts are reported for gap distance . Estimated mean marginal probability of success and the 95 % confidence interval is reported from the logistic regression model for success rate . P values < 0.05 were considered statistically significant . Statistical analysis was performed using statistical packages in R ( ver . 4.0.4 ) .31-36 Results Total 25 subjects were recruited , of which , data for both study sites was available for 24 subjects ( see Table 1 for summary of subject characteristics ) . One subject was dropped from the trial after first visit due to the concerns about overall physical fitness required to complete the study . Eleven participants ( 46 % ) were female . A variety of conditions affected the vision of the participants . While all were legally blind in the US , their vision ranged from completely blind to 20/200 vision . The majority walked with long cane and all except one used an iPhone in their daily lives . Public transit was the most preferred transit option , followed by rideshare and private vehicle . N 24 Table 1 : Study participant characteristics . Age ( years ) Median : 55 , IQR : 41 – 61 , Min . : 20 , Max . : 71 Gender Female : 11 ( 46 % ) Vision Vision disorders Available VA measure – N : 11 ( 46 % ) , range : [ 20/200 – 20/1200 ] Light Perception – N : 6 ( 25 % ) No Light Perception – N : 7 ( 29 % ) RoP : 5 , retinitis pigmentosa : 4 , retinal detachment : 3 , glaucoma : 2 ; One case each of : age-related macular degeneration , optic atrophy , aniridia , cone dystrophy , retinal artery occlusion , charge syndrome , monochromacy , diabetic retinopathy , Norrie syndrome Duration of vision loss At birth : 14 ( 58 % ) Acquired : 8 , Median duration : 18 years , range : [ 3 – 41 years ] Data not available : 2 Mobility aids used Long cane : 16 ( 67 % ) Guide dog : 6 ( 25 % ) None : 2 ( 8 % ) Most preferred transit option Habitual smartphone Public Transit - 1st : 11 , 2nd : 7 , 3rd : 3 , NA : 3 Rideshare - 1st : 9 , 2nd : 11 , 3rd : 2 , NA : 2 Private car - 1st : 4 , 2nd : 5 , 3rd : 8 , NA : 7 iPhone 23 ( 96 % ) Table 2 shows the trial instances and other data for both apps and at each study site . Across 24 subjects , there were supposed to be trials at 480 designated bus stops . However , over the course of the study , some bus stops were skipped due to construction or missing bus stop signs , resulting in a total of 48 instances with missing data . Therefore , each app was evaluated in a total of 432 instances . Overall success rate and gap distance measures were substantially better with All_Aboard app than Google Maps . Table 2 : Cumulative statistics for trial data . Both Apps Google Maps All_Aboard Bus stop instances with available data Skipped instances Both sites City Suburb Both sites City 864 458 406 96 22 432 229 203 48 11 432 229 203 48 11 ( missing data ) Number of successful instances Success rate ( % ) Average [ SD ] gap distance ( m ) Suburb Both sites City Suburb Both sites City Suburb 74 626 329 297 72 72 73 37 225 112 113 52 49 56 37 401 217 184 93 95 91 Both sites 3.36 [ 3.65 ] 6.62 [ 4.15 ] 1.54 [ 1.36 ] City 3.04 [ 3.82 ] 6.26 [ 4.89 ] 1.38 [ 1.34 ] Suburb 3.72 [ 3.41 ] 6.97 [ 3.24 ] 1.72 [ 1.36 ] In Table 2 , successful instances with each app are listed independently of each other . When compared pairwise at each bus stop instance ( Table 3 ) , there were only a handful of instances where both apps failed ( 18 out of 432 or about 4 % ) . There were 13 ( 3 % ) instances where All_Aboard failed but Google Maps succeeded , and there were 189 ( 44 % ) instances where Google Maps failed but All_Aboard succeeded . For the former cases , the average [ SD ] gap distance was 9.3 [ 5 ] meters , and for the latter cases , the average [ SD ] gap distance with All_Aboard was 1.6 [ 1.4 ] meters . From 225 successful instances with Google Maps , the arrival location was mapped past the bus stop sign along the direction of travel in 60 instances ( about 27 % ) , with an average gap distance of 7.2 [ 2.9 ] meters . Table 3 : 2x2 tables showing joint successes or failures of the All_Aboard and Google Maps over all 432 bus stop instances . Overall City Suburb Google Maps Success Google Maps Failure Google Maps Success Google Maps Failure Google Maps Success Google Maps Failure All_Aboard Success All_Aboard Failure 212 189 106 116 106 13 18 6 6 7 78 12 There was no significant effect of subject age , gender , or the kind of mobility aid used on the gap distance or on the success rate . The results and discussion is mostly related to 3 key factors : the app used , study site , and subject group based on their vision status . Gap distance ( in meters ) , averaged over vision status and study sites , was significantly smaller with All_Aboard ( mean : 1.8 , 95 % CI : 1.3-2.3 ) compared to Google Maps ( mean : 7.0 , 95 % CI : 6.5-7.5 ; p < 0.001 ) . Gap distance with All_Aboard was significantly smaller than Google Maps in City and Suburb , as well as in subjects with or without residual vision ( Figure 4A ) . The gap distance was significantly larger in completely blind group ( mean : 8.4 , 95 % CI : 7.3-9.5 ) compared to those with residual vision ( mean : 5.4 , 95 % CI : 4.7-6.1 ; p < 0.001 ) in the City with Google Maps . No significant effect of vision status on the gap distance with All_Aboard was observed . A significant effect of study site was seen only in the case of Google Maps in subjects with residual vision , where gap distance in the Suburb ( mean : 6.8 , 95 % CI : 6.1-7.5 ) was significantly larger than that observed in the City ( mean : 5.4 , 95 % CI : 4.7-6.1 ; p < 0.022 ) . Again , no significant effect of study site was observed for gap distance resulting from the All_Aboard app . A B Figure 4 : Outcome measures by app , location , and vision status . ( A ) The gap distance with All_Aboard was significantly smaller than Google Maps in both sites and in both subject groups . Those with residual vision achieved significantly smaller gap distance compared to completely blind with Google Maps in City . Gap distance in City was significantly lower than Suburb in the case of subjects with residual vision with Google Maps . ( B ) The success rate with All_Aboard was significantly higher in both sites and in subjects with and without residual vision . Completely blind individuals when using All_Aboard in the Suburb had significantly lower success rate compared to those with residual vision . For all panels : error bars show 95 % confidence interval of the mean ; significance levels : * * * : p < 0.001 , * * : p=0.001 – 0.01 , and * : p=0.01 – 0.05 ; P value adjustment : BH method for 4 tests . The success rate with All_Aboard was significantly higher than Google Maps across both study sites and both the subject groups ( Figure 4B ) . The overall success rate with All_Aboard ( mean : 0.91 , 95 % CI : 0.87-0.94 ) , averaged over study sites and subject group factors , was about 75 % higher than Google Maps ( mean : 0.52 , 95 % CI : 0.47-0.58 ; p < 0.001 ) . When using All_Aboard in the Suburban location , the success rate for completely blind subjects ( mean : 0.8 , 95 % CI : 0.69- 0.90 ; p < 0.001 ) was slightly but statistically significantly lower compared to those with residual vision ( mean : 0.95 , 95 % CI : 0.91-0.98 ; p < 0.001 ) . Otherwise , there was no significant difference in success rates for any other conditions . Discussion When people ( normally sighted or BVI ) take buses in areas like Boston metro region , where most bus stops are indicated just by a sign on a post , standing even a short distance away from the sign may cause the buses do not stop for them . This accessibility challenge may diminish independence , compromise adoption of affordable transportation for BVI travelers.1 This is just one of the last-10-meter navigation assistance needs of BVI individuals that is unmet . In this study , we evaluated the ability of All_Aboard app relative to the Google Maps navigation app in guiding BVI travelers accurately to bus stop locations in urban and suburban settings . The rate of successful localization of bus stops was substantially higher and the gap distance was much smaller when using All_Aboard app compared to Google Maps navigation . On average , the All_Aboard app was able to guide the subjects within about 2 meters ( 6 feet ) of the bus stop sign , whereas with Google Maps they were likely to be about 7 meters ( 23 feet ) away . The large effect size of All_Aboard app in terms of success rate of localization and the gap distance was observed irrespective of the location of testing , the vision status of the subjects , other demographic characteristics , and the kind of mobility aids they used . Thus , our findings demonstrate that All_Aboard app could provide a reliable benefit in navigation by accurately detecting the bus stop sings and guiding the users close enough to the designated stop that makes it less likely that a bus will pass by them for standing too far from the bus stops . Importantly , this study validates that computer vision-based object recognition capabilities can be used in a complementary way and provide added benefit to purely location-based navigation services in real-world settings . During the study design , we were expecting some difference in performance in a city vs. suburban location based on our previous preliminary study,14 due to the well-known limitations of location-based services in areas with tall structures . Therefore , we did not expect a significant effect of location on All_Aboard app , and the findings were more or less consistent with this expectation . In case of Google Maps , City vs . Suburb setting did not have any significant effect on the success rate , and its effect on gap distance relatively modest ( slight but statistically significant difference was seen only in subjects with residual vision ) . The primary reason for this lack of a location effect was that the localization error in the City was somewhat balanced or counteracted by large mapping errors in the Suburb . Thus , despite better localization accuracy of Google Maps in the Suburb , large mapping errors meant that almost the same proportion of trials were unsuccessful as in the City . While we enrolled participants with a wide range of visual abilities – from completely blind up to visual acuity of 20/200 , we analyzed only the effect residual vision presence on the performance with the navigation apps . If the All_Aboard app could successfully guide low vision travelers close to the bus stop sign , it was possible that they could use their residual vision ( even if it was only restricted to shape or perform perception ) from there on to navigate further close to the sign . We indeed observed this behavior in a few participants . However , as a whole , gap distance was not significantly different between those with or without residual vision – indicating that the app already guided the subjects close enough to the bus stop sign , such that any further change due to residual vision was not large in terms of distance . However , trial success rate was affected by residual vision presence in the Suburb , as completely blind subjects experienced significantly more failures with All_Aboard app compared to those with residual vision . A possible reason for higher failure rate in the Suburb could be because some of the bus stop signs on that site were not properly placed . Some were occluded by trees , slanting towards the street instead of the sidewalk , or not at the edge of street curb . In these situations , scanning sufficiently wide is crucial . However , completely blind subjects tended to scan across a narrow range or not scan at all due to complete loss of visual input to help with orientation . Therefore , they were more likely to miss signs that are slightly more difficult to find . More training and practicing on scanning skills might help improve their success rate in these situations . Acknowledgments The All_aboard app development was funded in part by Microsoft AI4A award . The authors would like thank Nick Corbett and Dinna Rosenbaum from the Carroll Center for the Blind for their help with participant recruitment and coordination . References 1 2 3 4 5 6 7 8 9 Crudden , A. , McDonnall , M. C. & Hierholzer , A . Transportation : An Electronic Survey of Persons who Are Blind or Have Low Vision . Journal of Visual Impairment & Blindness 109 , 445-456 , doi:10.1177/0145482x1510900603 ( 2015 ) . Pundlik , S. , Shivshanker , P. & Luo , G. Impact of Apps as Assistive Devices for Visually Impaired Persons . Annual Review of Vision Science 9 , null , doi:10.1146/annurev-vision- 111022-123837 ( 2023 ) . US Department of Justice Civil Rights Division . ( 2010 ) . Marston , J. R. & Golledge , R. G. The Hidden Demand for Participation in Activities and Travel by Persons who are Visually Impaired . Journal of Visual Impairment & Blindness 97 , 475-488 , doi:10.1177/0145482x0309700803 ( 2003 ) . Park , J . & Chowdhury , S. Investigating the barriers in a typical journey by public transport users with disabilities . Journal of Transport & Health 10 , 361-368 , doi : https : ( 2018 ) . Visnes Øksenholt , K. & Aarhaug , J . Public transport and people with impairments – exploring non-use of public transport through the case of Oslo , Norway . Disability & Society 33 , 1280-1302 , doi:10.1080/09687599.2018.1481015 ( 2018 ) . Wong , S. Traveling with blindness : A qualitative space-time approach to understanding visual impairment and urban mobility . Health & Place 49 , 85-92 , doi : https : ( 2018 ) . Low , W.-Y. , Cao , M. , De Vos , J . & Hickman , R. The journey experience of visually impaired people on public transport in London . Transport Policy 97 , 137-148 , doi : https : ( 2020 ) . Jonnalagedda , A. et al . Enhancing the Safety of Visually Impaired Travelers in and around Transit Stations . ( The Robotics Institute Carnegie Mellon University , 2014 ) . 10 11 12 13 14 15 16 17 18 Golledge , R. G. , Marston , J. R. & Costanzo , C. M. Attitudes of Visually Impaired Persons toward the Use of Public Transportation . Journal of Visual Impairment & Blindness 91 , 446-459 , doi:10.1177/0145482x9709100505 ( 1997 ) . Azenkot , S. et al . in Proceedings of the SIGCHI Conference on Human Factors in Computing Systems 3247–3256 ( Association for Computing Machinery , Vancouver , BC , Canada , 2011 ) . Hara , K. et al . Improving Public Transit Accessibility for Blind Riders by Crowdsourcing Bus Stop Landmark Locations with Google Street View : An Extended Analysis . ACM Trans . Access . Comput . 6 , Article 5 , doi:10.1145/2717513 ( 2015 ) . Perkins School for the Blind . BlindWays : a crowdsourced bus stop location app https : , ( last accessed Aug. 2023 ) ) . Jiang , E. et al . Field testing of All Aboard , an AI app for helping blind individuals to find bus stops . Investigative Ophthalmology & Visual Science 62 , 3529-3529 ( 2021 ) . Luo , G. & Pundlik , S. Widespread Errors in Bus Stop Location Mapping is an Accessibility Barrier for Passengers Who are Blind or Have Low Vision . Journal of Visual Impairment & Blindness , doi:10.1177/0145482X231201807 ( 2023 ) . Kuyk , T. K. , Liu , L. & Fuhr , P. S. Feature Search in Persons with Severe Visual Impairment . Vision Research 45 , 3224–3234 ( 2005 ) . Luo , G. , Satgunam , P. & Peli , E. Visual Search Performance of Patients with Vision Impairment : Effect of Jpeg Image Enhancement . Ophthalmic Physiol Opt 32 , 421–428 ( 2012 ) . Sáez , Y. , Muñoz , J. , Canto , F. , García , A . & Montes , H. Assisting Visually Impaired People in the Public Transport System through RF-Communication and Embedded Systems . Sensors 19 , 1282 ( 2019 ) . 19 Alvarado , A. et al . in Transportation Research Board . 20 Chen , H.-E. , Lin , Y.-Y. , Chen , C.-H. & Wang , I.-F. in Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems 19– 24 ( Association for Computing Machinery , Seoul , Republic of Korea , 2015 ) . 21 22 23 Parker , A. T. et al . Wayfinding Tools for People With Visual Impairments in Real-World Settings : A Literature Review of Recent Studies . Frontiers in Education 6 , doi:10.3389/feduc.2021.723816 ( 2021 ) . El-taher , F . E.-z. , Taha , A. , Courtney , J . & Mckeever , S. A Systematic Review of Urban Navigation Systems for Visually Impaired People . Sensors 21 , 3103 ( 2021 ) . Campbell , M. , Bennett , C. , Bonnar , C. & Borning , A. in Proceedings of the 16th international ACM SIGACCESS conference on Computers & accessibility 11–18 ( Association for Computing Machinery , Rochester , New York , USA , 2014 ) . 24 BlindSquare . https : //www.blindsquare.com/about/ , accessed Aug. 2023 ) . 25 Lazarillo . Inclusive navigation and digital maps , accessed Aug. 2023 ) . 26 Lock , J. C. , Cielniak , G. & Bellotto , N. in AAAI Spring Symposia . 27 28 29 30 31 32 Saha , M. , Fiannaca , A. J. , Kneisel , M. , Cutrell , E. & Morris , M. R. in Proceedings of the 21st International ACM SIGACCESS Conference on Computers and Accessibility 222–235 ( Association for Computing Machinery , Pittsburgh , PA , USA , 2019 ) . Feng , J. et al . Commute Booster : A Mobile Application for First/Last Mile and Middle Mile Navigation Support for People with Blindness and Low Vision . IEEE Journal of Translational Engineering in Health and Medicine , 1-1 , doi:10.1109/JTEHM.2023.3293450 ( 2023 ) . Massachusetts Eye & Ear Infirmary . All_Aboard . Find bus stops for the blind https : , accessed Aug. 2023 ) . Sandler , M. & Howard , A. MobileNetV2 : The Next Generation of On-Device Computer Vision Networks https : on.html , 2018 ) . Bates , D. , Mächler , M. , Bolker , B . & Walker , S. Fitting Linear Mixed-Effects Models Using lme4 . Journal of Statistical Software 67 , 1 - 48 , doi:10.18637/jss.v067.i01 ( 2015 ) . Brooks , M. E. et al . glmmTMB Balances Speed and Flexibility Among Packages for Zero-inflated Generalized Linear Mixed Modeling . The R Journal 9 , 378–400 , doi:10.32614/RJ-2017-066 ( 2017 ) . 33 34 35 emmeans : Estimated Marginal Means , aka Least-Squares Means . R package version 1.7.2. https : ( 2022 ) . Lüdecke , D. , Ben-Shachar , M. , Patil , I. , Waggoner , P. & Makowski , D. performance : An R Package for Assessment , Comparison and Testing of Statistical Models . Journal of Open Source Software 6 , 3139 , doi:10.21105/joss.03139 ( 2021 ) . DHARMa : Residual Diagnostics for Hierarchical ( Multi-Level / Mixed ) Regression Models . R package version 0.4.1. https : ( 2021 ) . 36 Wickham , H. ggplot2 : Elegant Graphics for Data Analysis Vol . https : //ggplot2.tidyverse.org . ( Springer-Verlag , 2016 ) .","['field', 'evaluation', 'mobile', 'app', 'assist', 'blind', 'visually', 'impair', 'traveler', 'find', 'bus', 'stop', 'shivshanker', 'trautsavino', 'gang', 'schepen', 'eye', 'ear', 'medical', 'school', 'carroll', 'center', 'blind', 'corresponding', 'author', 'keyword', 'vision', 'aid', 'navigation', 'mobility', 'accessibility', 'deep', 'learning', 'computer', 'vision', 'public', 'transportation', 'commercial', 'relationship', 'author', 'declare', 'potential', 'conflict', 'interest', 'respect', 'research', 'authorship', 'andor', 'publication', 'article', 'allaboard', 'app', 'evaluate', 'study', 'release', 'public', 'free', 'revenue', 'app', 'sale', 'inapp', 'advertisement', 'abstract', 'purpose', 'report', 'considerable', 'gap', 'gps', 'inaccuracy', 'mapping', 'error', 'blind', 'visually', 'impair', 'bvi', 'traveler', 'rely', 'digital', 'map', 'go', 'desire', 'bus', 'stop', 'evaluate', 'ability', 'mobile', 'app', 'allaboard', 'guide', 'bvi', 'traveler', 'precisely', 'busstop', 'method', 'allaboard', 'app', 'detect', 'busstop', 'sign', 'realtime', 'camera', 'use', 'neural', 'network', 'model', 'provide', 'distance', 'code', 'audio', 'feedback', 'help', 'localize', 'detect', 'sign', 'bvi', 'individual', 'use', 'allaboard', 'localize', 'bus', 'stop', 'location', 'suburban', 'area', 'bus', 'stop', 'subject', 'use', 'app', 'navigate', 'close', 'possible', 'physical', 'busstop', 'sign', 'start', 'meter', 'away', 'outcome', 'measure', 'success', 'rate', 'gap', 'distance', 'appindicate', 'location', 'actual', 'physical', 'location', 'bus', 'stop', 'result', 'study', 'conduct', 'legally', 'blind', 'participant', 'mean', 'age', 'sd', 'year', 'female', 'success', 'rate', 'allaboard', 'app', 'significantly', 'high', 'map', 'p', 'gap', 'distance', 'use', 'allaboard', 'app', 'significantly', 'low', 'mean', 'ci', 'meter', 'compare', 'map', 'meter', 'p', 'conclusion', 'localize', 'bus', 'stop', 'accurately', 'reliably', 'base', 'navigation', 'option', 'realworld', 'environment', 'translational', 'relevance', 'navigation', 'aid', 'potentially', 'help', 'bvi', 'individual', 'independently', 'travel', 'public', 'transportation', 'introduction', 'blind', 'visually', 'impair', 'bvi', 'people', 'often', 'rely', 'public', 'transportation', 'bus', 'subway', 'travel', 'employment', 'leisure', 'needs1', 'geolocation', 'transportation', 'information', 'access', 'smartphone', 'greatly', 'facilitated', 'macronavigation', 'bvi', 'people', 'example', 'plan', 'route', 'get', 'detailed', 'instruction', 'mobile', 'device', 'pointtopoint', 'navigation', 'use', 'public', 'transit', 'navigation', 'app', 'make', 'major', 'group', 'vision', 'assistance', 'mobile', 'app', 'available', 'app', 'store', 'play', 'store', 'hand', 'micronavigation', 'navigate', 'precisely', 'desire', 'destination', 'stage', 'journey', 'remain', 'largely', 'unsolved', 'issue', 'bvi', 'individual', 'comply', 'disability', 'regional', 'transit', 'agency', 'require', 'comply', 'regulation', 'regard', 'accessibility', 'transit', 'context', 'vision', 'disability', 'requirement', 'include', 'place', 'largeprint', 'signage', 'bus', 'stop', 'provide', 'braille', 'tactile', 'information', 'transit', 'station', 'make', 'stop', 'announcement', 'transit', 'vehicle', 'main', 'point', 'however', 'poor', 'interface', 'lack', 'cue', 'accessible', 'distance', 'example', 'transit', 'stop', 'signage', 'main', 'barrier', 'equal', 'access', 'public', 'transportation49', 'systemic', 'inaccuracy', 'gps', 'base', 'location', 'service', 'underlie', 'problem', 'lead', 'micronavigation', 'challenge', 'face', 'people', 'bvi', 'also', 'refer', 'last', 'foot', 'last', 'problem', 'wayfinde', 'example', 'navigate', 'bus', 'stop', 'blind', 'person', 'follow', 'gpsbased', 'navigation', 'app', 'arrive', 'app', 'indicate', 'location', 'considerable', 'gap', 'typically', 'foot', 'actual', 'bus', 'stop', 'localization', 'error', 'gps', 'service', 'perspective', 'gap', 'almost', 'equal', 'entire', 'bus', 'length', 'certain', 'region', 'accord', 'feedback', 'blind', 'traveler', 'sometimes', 'even', 'small', 'gap', 'large', 'enough', 'miss', 'bus', 'bus', 'driver', 'misunderstand', 'intention', 'stop', 'worstcase', 'scenario', 'especially', 'crowd', 'city', 'localization', 'block', 'make', 'macro', 'navigation', 'app', 'essentially', 'useless', 'pedestrian', 'mode14', 'weather', 'location', 'density', 'tall', 'building', 'downtown', 'area', 'example', 'far', 'affect', 'gpsbased', 'localization', 'addition', 'localization', 'error', 'possibility', 'mapping', 'error', 'sometimes', 'large', 'stop', 'location', 'make', 'publicly', 'available', 'transit', 'agency', 'survey', 'bus', 'stop', 'location', 'area', 'map', 'bus', 'length', 'away', 'mapping', 'localization', 'error', 'together', 'contribute', 'make', 'purely', 'locationbase', 'service', 'unreliable', 'micronavigation', 'task', 'find', 'bus', 'stop', 'make', 'matter', 'bad', 'bus', 'stop', 'sign', 'many', 'sign', 'typical', 'urban', 'street', 'trafficparke', 'sign', 'street', 'sign', 'thus', 'find', 'become', 'visual', 'search', 'task', 'addition', 'plain', 'geolocation', 'task', 'visual', 'search', 'performance', 'know', 'significantly', 'degrade', 'people', 'low', 'vision1617', 'evident', 'navigation', 'aid', 'need', 'navigation', 'visual', 'search', 'capability', 'conventional', 'wayfinde', 'solution', 'use', 'beacon', 'provide', 'micro', 'location', 'information', 'high', 'accuracy', 'nearby', 'landmarks1822', 'approach', 'scalability', 'applicability', 'outdoor', 'environment', 'restrict', 'high', 'cost', 'infrastructure', 'modification', 'maintenance', 'hand', 'smartphone', 'allow', 'rapid', 'scaling', 'accessibility', 'smartphone', 'app', 'develop', 'test', 'release', 'help', 'blind', 'visually', 'impair', 'people', 'access', 'public', 'transportation', 'specifically', 'navigate', 'destination', 'app', 'primarily', 'gpsbase', 'therefore', 'still', 'subject', 'limitation', 'gpsbased', 'navigation', 'system', 'detail', 'order', 'achieve', 'localization', 'accurately', 'app', 'combine', 'location', 'information', 'together', 'however', 'landmark', 'map', 'various', 'location', 'build', 'maintain', 'make', 'widely', 'available', 'prior', 'use', 'comb', 'signage', 'information', 'extract', 'gtfs', 'optical', 'character', 'recognition', 'provide', 'viable', 'micronavigation', 'solution28', 'purpose', 'bus', 'stop', 'navigation', 'purely', 'visual', 'approach', 'work', 'well', 'combine', 'typical', 'macronavigation', 'app', 'develop', 'mobile', 'app', 'allaboard', 'recognize', 'bus', 'stop', 'sign', 'help', 'user', 'navigate', 'short', 'range', 'physical', 'location', 'sign29', 'use', 'app', 'user', 'first', 'use', 'commonly', 'available', 'macronavigation', 'tool', 'map', 'arrive', 'vicinity', 'bus', 'stop', 'location', 'scan', 'surrounding', 'smartphone', 'camera', 'allaboard', 'app', 'detect', 'bus', 'stop', 'sign', 'realtime', 'smartphone', 'camera', 'imagery', 'guide', 'user', 'approach', 'bus', 'stop', 'auditory', 'cue', 'auditory', 'pitch', 'code', 'distance', 'target', 'preliminary', 'testing', 'allaboard', 'app', 'indicate', 'superior', 'performance', 'compare', 'map', 'app14', 'goal', 'study', 'evaluate', 'allaboard', 'realworld', 'condition', 'bvi', 'transit', 'user', 'compare', 'localization', 'ability', 'navigation', 'primary', 'hypothesis', 'localization', 'base', 'app', 'significantly', 'well', 'use', 'conventional', 'navigation', 'app', 'map', 'term', 'distance', 'desire', 'busstop', 'location', 'rate', 'successful', 'localization', 'give', 'gpsbase', 'localization', 'typically', 'suffer', 'densely', 'build', 'downtown', 'area', 'far', 'hypothesize', 'allaboard', 'effective', 'location', 'compare', 'sparsely', 'populated', 'suburban', 'area', 'method', 'underlie', 'idea', 'app', 'bus', 'stop', 'signage', 'unique', 'different', 'road', 'sign', 'uniform', 'appearance', 'typically', 'always', 'standardize', 'entire', 'area', 'transit', 'agency', 'figure', '1a', 'moreover', 'bus', 'stop', 'sign', 'give', 'transit', 'agency', 'know', 'physical', 'size', 'estimate', 'approximate', 'distance', 'base', 'image', 'size', 'width', 'detect', 'bus', 'stop', 'sign', 'far', 'distance', 'small', 'image', 'vice', 'versa', 'therefore', 'feasible', 'computer', 'vision', 'algorithm', 'learn', 'appearance', 'bus', 'stop', 'sign', 'detect', 'image', 'capture', 'smartphone', 'camera', 'estimate', 'distance', 'actual', 'sign', 'bus', 'stop', 'detection', 'allaboard', 'perform', 'realtime', 'use', 'mobilenetv2', 'deep', 'learn', 'neural', 'network30', 'train', 'image', 'bus', 'stop', 'collect', 'give', 'cityregion', 'image', 'bus', 'stop', 'sign', 'collect', 'view', 'imagery', 'base', 'publicly', 'available', 'bus', 'stop', 'coordinate', 'general', 'transit', 'feed', 'specification', 'gtfs', 'standard', 'stop', 'sign', 'manually', 'label', 'place', 'bounding', 'box', 'collect', 'image', 'train', 'model', 'run', 'natively', 'smartphone', 'device', 'cloud', 'process', 'key', 'idea', 'operation', 'allaboard', 'supplement', 'macronavigation', 'app', 'thus', 'need', 'operational', 'general', 'vicinity', 'bus', 'stop', 'typical', 'usage', 'scenario', 'figure', 'user', 'launch', 'allaboard', 'macronavigation', 'app', 'map', 'indicate', 'user', 'desire', 'bus', 'stop', 'location', 'allaboard', 'app', 'sense', 'phone', 'orientation', 'search', 'device', 'hold', 'upright', 'position', 'user', 'scan', 'phone', 'camera', 'arc', 'first', 'determine', 'angular', 'orientation', 'sign', 'positive', 'detection', 'lead', 'beep', 'sound', 'true', 'positive', 'detection', 'typically', 'indicate', 'series', 'continuous', 'auditory', 'tone', 'lock', 'direction', 'sign', 'auditory', 'tone', 'change', 'frequency', 'user', 'get', 'bus', 'stop', 'sign', 'similar', 'home', 'signal', 'thus', 'app', 'help', 'user', 'gauge', 'relative', 'distance', 'sign', 'adjust', 'approach', 'level', 'audio', 'tone', 'high', 'frequency', 'indicate', 'detect', 'sign', 'meter', 'foot', 'launch', 'app', 'work', 'need', 'active', 'intervention', 'user', 'long', 'device', 'hold', 'upright', 'manner', 'allaboard', 'available', 'app', 'store', 'play', 'store', 'free', 'capable', 'recognize', 'bus', 'stop', 'major', 'citiesregion', 'world', 'instal', 'user', 'download', 'available', 'train', 'neural', 'network', 'model', 'correspond', 'transit', 'agency', 'study', 'allaboard', 'app', 'load', 'model', 'train', 'detect', 'bus', 'stop', 'sign', 'authority', 'operate', 'public', 'transit', 'figure', 'typical', 'mbta', 'bus', 'stop', 'sign', 'trial', 'location', 'downtown', 'recent', 'version', 'signage', 'however', 'old', 'version', 'slightly', 'different', 'appearance', 'similar', 'shape', 'persist', 'coverage', 'area', 'bus', 'stop', 'area', 'cover', 'transit', 'agency', 'shelter', 'distinctive', 'sign', 'often', 'visual', 'identification', 'bus', 'stop', 'b', 'operation', 'allaboard', 'app', 'general', 'vicinity', 'bus', 'stop', 'lower', 'inset', 'show', 'app', 'detect', 'bus', 'stop', 'sign', 'draw', 'detect', 'sign', 'camera', 'view', 'display', 'smartphone', 'screen', 'upper', 'inset', 'show', 'successful', 'detection', 'night', 'low', 'light', 'condition', 'demonstration', 'video', 'app', 'action', 'find', 'https', 'wwwyoutubecomwatch', 'participant', 'inclusion', 'criterion', 'vision', 'status', 'legal', 'blindness', 'independent', 'mobility', 'assistance', 'sighted', 'guide', 'physical', 'ability', 'walk', 'distance', 'mile', 'give', 'time', 'familiarity', 'smartphonemobile', 'device', 'participant', 'study', 'recruit', 'referral', 'carroll', 'center', 'practitioner', 'vision', 'rehabilitation', 'clinic', 'pool', 'volunteer', 'participate', 'prior', 'study', 'study', 'protocol', 'approve', 'institutional', 'review', 'board', 'eye', 'ear', 'study', 'follow', 'tenet', 'declaration', 'write', 'inform', 'consent', 'obtain', 'participant', 'participant', 'reimburse', 'travel', 'study', 'site', 'time', 'study', 'design', 'study', 'involve', 'visit', 'separate', 'study', 'site', 'downtown', 'city', 'campus', 'carroll', 'center', 'blind', 'suburb', 'study', 'site', 'involve', 'navigate', 'bus', 'stop', 'follow', 'specific', 'route', 'figure', 'bus', 'stop', 'performance', 'allaboard', 'map', 'app', 'evaluate', 'app', 'run', 'simultaneously', 'study', 'participant', 'accompany', 'certify', 'orientation', 'mobility', 'instructor', 'provide', 'direction', 'route', 'ensure', 'safety', 'participant', 'study', 'member', 'study', 'team', 'also', 'accompany', 'participant', 'instructor', 'administer', 'study', 'recorded', 'measurement', 'trial', 'preconfigure', 'android', 'smartphone', 'provide', 'participant', 'start', 'study', 'participant', 'provide', 'oral', 'instruction', 'handson', 'training', 'use', 'allaboard', 'app', 'practice', 'location', 'start', 'trial', 'bus', 'stop', 'location', 'participant', 'guide', 'instructor', 'location', 'meter', 'foot', 'away', 'bus', 'stop', 'sign', 'direction', 'travel', 'approximately', 'straight', 'ahead', 'direction', 'starting', 'distance', 'stop', 'sign', 'varied', 'stop', 'location', 'dissuade', 'participant', 'guess', 'stop', 'location', 'base', 'step', 'count', 'path', 'start', 'location', 'bus', 'stop', 'sign', 'involve', 'cross', 'street', 'case', 'bus', 'stop', 'location', 'stop', 'sign', 'affix', 'close', 'intersection', 'starting', 'point', 'trial', 'operate', 'pedestrian', 'direction', 'mode', 'launch', 'experimenter', 'streetview', 'calibration', 'feature', 'use', 'live', 'camera', 'imagery', 'geolocate', 'accurately', 'map', 'location', 'say', 'bus', 'stop', 'set', 'destination', 'allaboard', 'app', 'launch', 'app', 'run', 'simultaneously', 'navigation', 'window', 'inset', 'bottom', 'screen', 'figure', 'figure', 'route', 'study', 'site', 'downtown', 'boston', 'leave', 'right', 'site', 'bus', 'stop', 'location', 'indicate', 'number', 'route', 'indicate', 'dash', 'black', 'line', 'bus', 'stop', 'opposite', 'side', 'street', 'route', 'loop', 'traverse', 'direction', 'show', 'arrow', 'smartphone', 'device', 'hand', 'participant', 'start', 'location', 'participant', 'instruct', 'navigate', 'close', 'bus', 'stop', 'sign', 'possible', 'also', 'instruct', 'hold', 'smartphone', 'upright', 'rear', 'camera', 'pointing', 'straight', 'ahead', 'figure', '3b', 'scan', 'sidetoside', 'determine', 'relative', 'orientation', 'bus', 'stop', 'sign', 'walk', 'trajectory', 'point', 'participant', 'walk', 'rely', 'habitual', 'mobility', 'aid', 'residual', 'vision', 'present', 'auditory', 'feedback', 'allaboard', 'app', 'meanwhile', 'provide', 'intermittent', 'voice', 'instruction', 'include', 'distance', 'destination', 'foot', 'participant', 'soon', 'learn', 'often', 'unreliable', 'end', 'trial', 'bus', 'stop', 'location', 'participant', 'stop', 'notify', 'experimenter', 'think', 'close', 'bus', 'stop', 'sign', 'judgment', 'primarily', 'base', 'audio', 'feedback', 'allaboard', 'app', 'audio', 'tone', 'frequency', 'pitch', 'high', 'level', 'indicate', 'detect', 'sign', 'close', 'participant', 'use', 'residual', 'vision', 'point', 'onward', 'get', 'even', 'close', 'distance', 'stop', 'actual', 'stop', 'sign', 'measure', 'tape', 'measure', 'localization', 'distance', 'also', 'indicate', 'auditory', 'feedback', 'determine', 'participant', 'arrive', 'destination', 'figure', 'distance', 'bus', 'stop', 'sign', 'arrival', 'point', 'accord', 'map', 'also', 'measure', 'tape', 'measure', 'time', 'first', 'study', 'visit', 'participant', 'answer', 'brief', 'survey', 'collect', 'basic', 'demographic', 'information', 'vision', 'status', 'use', 'vision', 'aid', 'preferred', 'transit', 'option', 'public', 'transit', 'rideshare', 'private', 'vehicle', 'family', 'member', 'drive', 'level', 'vision', 'record', 'term', 'selfreporte', 'visual', 'acuity', 'light', 'perception', 'light', 'perception', 'case', 'completely', 'blind', 'individual', 'figure', 'run', 'allaboard', 'map', 'simultaneously', 'find', 'bus', 'stop', 'screenshot', 'device', 'start', 'point', 'allaboard', 'map', 'inset', 'launch', 'run', 'simultaneously', 'b', 'user', 'hold', 'phone', 'upright', 'rear', 'camera', 'face', 'straight', 'ahead', 'c', 'screenshot', 'device', 'map', 'indicate', 'arrival', 'destination', 'app', 'indicate', 'physical', 'bus', 'stop', 'sign', 'still', 'distance', 'ahead', 'outcome', 'measure', 'main', 'outcome', 'measure', 'separately', 'obtain', 'app', 'allaboard', 'map', 'localization', 'error', 'gap', 'distance', 'meter', 'rate', 'successful', 'localization', 'success', 'rate', 'mention', 'gap', 'distance', 'obtain', 'direct', 'measurement', 'distance', 'indicatedsubject', 'determined', 'location', 'bus', 'stop', 'physical', 'location', 'bus', 'stop', 'sign', 'allaboard', 'guide', 'participant', 'close', 'enough', 'spot', 'residual', 'vision', 'identify', 'bus', 'stop', 'sign', 'touch', 'pole', 'post', 'gap', 'distance', 'mark', 'app', 'indicate', 'location', 'ground', 'physical', 'bus', 'stop', 'sign', 'respect', 'direction', 'travel', 'measured', 'gap', 'distance', 'record', 'negative', 'trial', 'instance', 'deem', 'failure', 'reasonable', 'measurable', 'distance', 'obtain', 'success', 'rate', 'app', 'define', 'location', 'valid', 'measurable', 'distance', 'travel', 'path', 'available', 'give', 'bus', 'stop', 'location', 'trial', 'failure', 'occur', 'various', 'reason', 'case', 'incorrect', 'mapping', 'bus', 'stop', 'reason', 'failure', 'predictable', 'repetitive', 'subject', 'location', 'bus', 'stop', 'map', 'fundamentally', 'incorrect', 'cause', 'trial', 'failure', 'mapped', 'location', 'foot', 'away', 'physical', 'bus', 'stop', 'cause', 'trial', 'failure', 'catastrophic', 'inaccuracy', 'geolocation', 'consequent', 'navigation', 'direction', 'example', 'app', 'direct', 'user', 'cross', 'street', 'doubleback', 'go', 'corner', 'lead', 'completely', 'miss', 'bus', 'stop', 'failure', 'prevalent', 'downtown', 'area', 'tall', 'building', 'andor', 'overcastrainy', 'day', 'case', 'trial', 'failure', 'occur', 'detection', 'failure', 'false', 'negative', 'deficient', 'technique', 'subject', 'use', 'app', 'shadow', 'occlusion', 'lead', 'app', 'fail', 'recognize', 'bus', 'stop', 'sign', 'signage', 'largely', 'slant', 'away', 'side', 'walk', 'direction', 'cause', 'app', 'fail', 'detect', 'occasion', 'subject', 'scan', 'sufficiently', 'walk', 'bus', 'stop', 'sign', 'lose', 'audio', 'signal', 'bus', 'stop', 'sign', 'initially', 'detect', 'go', 'field', 'view', 'camera', 'subject', 'approach', 'continuous', 'audio', 'signal', 'suddenly', 'stop', 'indicator', 'subject', 'pass', 'sign', 'close', 'allow', 'retrace', 'step', 'try', 'zeroin', 'confirm', 'presence', 'stop', 'sign', 'near', 'vicinity', 'major', 'intervention', 'experimenter', 'need', 'reorient', 'subject', 'initial', 'failure', 'detect', 'trail', 'consider', 'failure', 'allaboard', 'app', 'give', 'location', 'even', 'sign', 'successfully', 'detect', 'subsequent', 'try', 'statistical', 'analysis', 'potential', 'factor', 'interest', 'affect', 'outcome', 'measure', 'app', 'use', 'allaboard', 'map', 'study', 'location', 'city', 'suburb', 'vision', 'status', 'residual', 'vision', 'completely', 'blind', 'subject', 'light', 'perception', 'categorize', 'residual', 'vision', 'rest', 'residual', 'vision', 'vision', 'well', 'eye', 'use', 'categorization', 'association', 'gap', 'distance', 'potential', 'variable', 'analyze', 'withinsubject', 'linear', 'model', 'repeat', 'measure', 'framework', 'success', 'rate', 'analyze', 'use', 'binary', 'logistic', 'regression', 'addition', 'main', 'effect', 'interaction', 'factor', 'also', 'examine', 'estimate', 'marginal', 'mean', 'confidence', 'interval', 'contrast', 'report', 'gap', 'distance', 'estimate', 'mean', 'marginal', 'probability', 'success', 'confidence', 'interval', 'report', 'logistic', 'regression', 'model', 'success', 'rate', 'p', 'value', 'consider', 'statistically', 'significant', 'statistical', 'analysis', 'perform', 'use', 'statistical', 'package', 'r', 'ver', 'result', 'total', 'subject', 'recruit', 'datum', 'study', 'site', 'available', 'subject', 'see', 'table', 'summary', 'subject', 'characteristic', 'subject', 'drop', 'trial', 'first', 'visit', 'concern', 'overall', 'physical', 'fitness', 'require', 'complete', 'study', 'participant', 'female', 'variety', 'condition', 'affect', 'vision', 'participant', 'legally', 'blind', 'vision', 'range', 'completely', 'blind', 'vision', 'majority', 'walk', 'long', 'cane', 'use', 'iphone', 'daily', 'life', 'public', 'transit', 'preferred', 'transit', 'option', 'follow', 'rideshare', 'private', 'vehicle', 'table', 'study', 'participant', 'characteristic', 'age', 'year', 'median', 'iqr', 'min', 'max', 'gender', 'female', 'vision', 'vision', 'disorder', 'available', 'measure', 'range', 'light', 'perception', 'light', 'perception', 'rop', 'retinitis', 'retinal', 'detachment', 'glaucoma', 'case', 'agerelate', 'macular', 'degeneration', 'optic', 'atrophy', 'aniridia', 'cone', 'dystrophy', 'retinal', 'artery', 'occlusion', 'charge', 'syndrome', 'monochromacy', 'duration', 'vision', 'loss', 'birth', 'acquire', 'median', 'duration', 'year', 'range', 'year', 'datum', 'available', 'mobility', 'aid', 'use', 'long', 'cane', 'guide', 'dog', 'none', 'preferred', 'transit', 'option', 'habitual', 'smartphone', 'public', 'transit', '1st', '2nd', '3rd', 'rideshare', '1st', '2nd', '3rd', 'private', 'car', '1st', '2nd', '3rd', 'iphone', 'table', 'show', 'trial', 'instance', 'datum', 'app', 'study', 'site', 'subject', 'suppose', 'trial', 'designate', 'bus', 'stop', 'however', 'course', 'study', 'bus', 'stop', 'skip', 'construction', 'missing', 'bus', 'stop', 'sign', 'result', 'total', 'instance', 'miss', 'datum', 'therefore', 'app', 'evaluate', 'total', 'instance', 'overall', 'success', 'rate', 'gap', 'distance', 'measure', 'substantially', 'well', 'app', 'map', 'table', 'cumulative', 'statistic', 'trial', 'datum', 'app', 'bus', 'stop', 'instance', 'available', 'datum', 'skip', 'instance', 'site', 'city', 'suburb', 'site', 'city', 'miss', 'data', 'number', 'successful', 'instance', 'success', 'rate', 'average', 'sd', 'gap', 'distance', 'suburb', 'site', 'city', 'suburb', 'site', 'city', 'suburb', 'site', 'city', 'suburb', 'table', 'successful', 'instance', 'app', 'list', 'independently', 'compare', 'pairwise', 'bus', 'stop', 'instance', 'table', 'handful', 'instance', 'app', 'fail', 'instance', 'fail', 'map', 'succeed', 'instance', 'map', 'fail', 'succeed', 'former', 'case', 'average', 'sd', 'gap', 'distance', 'meter', 'latter', 'case', 'average', 'sd', 'gap', 'distance', 'allaboard', 'meter', 'successful', 'instance', 'map', 'arrival', 'location', 'map', 'bus', 'stop', 'sign', 'direction', 'travel', 'instance', 'average', 'gap', 'distance', 'meter', 'table', 'table', 'show', 'joint', 'success', 'failure', 'allaboard', 'map', 'bus', 'stop', 'instance', 'overall', 'city', 'suburb', 'map', 'failure', 'map', 'map', 'failure', 'map', 'map', 'failure', 'allaboard', 'success', 'allaboard', 'failure', 'significant', 'effect', 'subject', 'age', 'gender', 'kind', 'mobility', 'aid', 'use', 'gap', 'distance', 'success', 'rate', 'result', 'discussion', 'mostly', 'relate', 'key', 'factor', 'app', 'use', 'study', 'site', 'subject', 'group', 'base', 'vision', 'status', 'gap', 'distance', 'meter', 'average', 'vision', 'status', 'study', 'site', 'significantly', 'small', 'allaboard', 'mean', 'ci', 'compare', 'map', 'mean', 'ci', 'p', 'gap', 'distance', 'allaboard', 'significantly', 'small', 'map', 'city', 'suburb', 'well', 'subject', 'residual', 'vision', 'figure', '4a', 'gap', 'distance', 'significantly', 'large', 'completely', 'blind', 'group', 'mean', 'compare', 'residual', 'vision', 'mean', 'ci', 'p', 'city', 'map', 'significant', 'effect', 'vision', 'status', 'gap', 'distance', 'allaboard', 'observe', 'significant', 'effect', 'study', 'site', 'see', 'case', 'map', 'subject', 'residual', 'vision', 'gap', 'distance', 'suburb', 'mean', 'ci', 'significantly', 'large', 'observe', 'city', 'mean', 'ci', 'p', '0022', 'significant', 'effect', 'study', 'site', 'observe', 'gap', 'distance', 'result', 'allaboard', 'app', 'b', 'figure', 'outcome', 'measure', 'app', 'location', 'vision', 'status', 'gap', 'distance', 'allaboard', 'significantly', 'small', 'map', 'site', 'subject', 'group', 'residual', 'vision', 'achieve', 'significantly', 'small', 'gap', 'distance', 'compare', 'completely', 'blind', 'map', 'city', 'gap', 'distance', 'city', 'significantly', 'low', 'suburb', 'case', 'subject', 'residual', 'vision', 'success', 'rate', 'allaboard', 'significantly', 'high', 'site', 'subject', 'residual', 'vision', 'completely', 'blind', 'individual', 'use', 'allaboard', 'suburb', 'significantly', 'low', 'success', 'rate', 'compare', 'residual', 'vision', 'panel', 'error', 'bar', 'show', 'confidence', 'interval', 'mean', 'significance', 'level', 'p', 'value', 'adjustment', 'bh', 'method', 'test', 'success', 'rate', 'allaboard', 'significantly', 'high', 'map', 'study', 'site', 'subject', 'group', 'figure', 'overall', 'success', 'rate', 'allaboard', 'mean', 'ci', 'average', 'study', 'site', 'subject', 'group', 'factor', 'high', 'map', 'mean', 'p', 'use', 'allaboard', 'suburban', 'location', 'success', 'rate', 'completely', 'blind', 'subject', 'mean', 'p', 'slightly', 'statistically', 'significantly', 'low', 'compare', 'residual', 'vision', 'mean', 'p', 'otherwise', 'significant', 'difference', 'success', 'rate', 'condition', 'discussion', 'people', 'normally', 'sight', 'bvi', 'take', 'bus', 'area', 'bus', 'stop', 'indicate', 'sign', 'post', 'stand', 'even', 'short', 'distance', 'away', 'sign', 'cause', 'bus', 'stop', 'accessibility', 'challenge', 'diminish', 'independence', 'compromise', 'adoption', 'affordable', 'transportation', 'last10met', 'navigation', 'assistance', 'need', 'bvi', 'individual', 'unmet', 'study', 'evaluate', 'ability', 'app', 'relative', 'app', 'guide', 'bvi', 'traveler', 'accurately', 'bus', 'stop', 'location', 'urban', 'suburban', 'setting', 'rate', 'successful', 'localization', 'bus', 'stop', 'substantially', 'high', 'gap', 'distance', 'much', 'small', 'use', 'allaboard', 'app', 'compare', 'map', 'navigation', 'average', 'allaboard', 'app', 'able', 'guide', 'subject', 'meter', 'foot', 'bus', 'stop', 'sign', 'map', 'likely', 'meter', 'foot', 'away', 'large', 'effect', 'size', 'app', 'term', 'success', 'rate', 'localization', 'gap', 'distance', 'observe', 'irrespective', 'location', 'test', 'vision', 'status', 'subject', 'demographic', 'characteristic', 'kind', 'mobility', 'aid', 'use', 'thus', 'finding', 'demonstrate', 'app', 'provide', 'reliable', 'benefit', 'navigation', 'accurately', 'detect', 'bus', 'stop', 'sing', 'guide', 'user', 'close', 'enough', 'designate', 'stop', 'make', 'less', 'likely', 'bus', 'pass', 'stand', 'far', 'bus', 'stop', 'importantly', 'study', 'validate', 'computer', 'visionbase', 'object', 'recognition', 'capability', 'use', 'complementary', 'way', 'provide', 'add', 'benefit', 'purely', 'locationbase', 'navigation', 'service', 'realworld', 'setting', 'study', 'design', 'expect', 'difference', 'performance', 'city', 'suburban', 'location', 'base', 'previous', 'preliminary', 'study14', 'wellknown', 'limitation', 'locationbase', 'service', 'area', 'tall', 'structure', 'therefore', 'expect', 'significant', 'effect', 'location', 'app', 'finding', 'less', 'consistent', 'expectation', 'case', 'city', 'suburb', 'setting', 'significant', 'effect', 'success', 'rate', 'effect', 'gap', 'distance', 'relatively', 'modest', 'slight', 'statistically', 'significant', 'difference', 'see', 'subject', 'residual', 'vision', 'primary', 'reason', 'lack', 'location', 'effect', 'localization', 'error', 'city', 'somewhat', 'balanced', 'counteract', 'large', 'mapping', 'error', 'suburb', 'thus', 'well', 'localization', 'accuracy', 'map', 'suburb', 'large', 'mapping', 'error', 'mean', 'almost', 'proportion', 'trial', 'unsuccessful', 'city', 'enrol', 'participant', 'wide', 'range', 'visual', 'ability', 'completely', 'blind', 'visual', 'acuity', 'analyze', 'effect', 'residual', 'vision', 'presence', 'performance', 'navigation', 'app', 'allaboard', 'app', 'successfully', 'guide', 'low', 'vision', 'traveler', 'close', 'bus', 'stop', 'sign', 'possible', 'use', 'residual', 'vision', 'even', 'restrict', 'shape', 'perform', 'perception', 'navigate', 'far', 'close', 'sign', 'indeed', 'observe', 'behavior', 'participant', 'however', 'whole', 'gap', 'distance', 'significantly', 'different', 'residual', 'vision', 'indicate', 'app', 'already', 'guide', 'subject', 'close', 'enough', 'bus', 'stop', 'sign', 'change', 'residual', 'vision', 'large', 'term', 'distance', 'however', 'trial', 'success', 'rate', 'affect', 'residual', 'vision', 'presence', 'suburb', 'completely', 'blind', 'subject', 'experience', 'significantly', 'failure', 'app', 'compare', 'residual', 'vision', 'possible', 'reason', 'high', 'failure', 'rate', 'suburb', 'bus', 'stop', 'sign', 'site', 'properly', 'place', 'occlude', 'tree', 'slant', 'street', 'instead', 'sidewalk', 'edge', 'street', 'curb', 'situation', 'scan', 'sufficiently', 'wide', 'crucial', 'however', 'completely', 'blind', 'subject', 'tend', 'scan', 'narrow', 'range', 'scan', 'due', 'complete', 'loss', 'visual', 'input', 'help', 'orientation', 'therefore', 'likely', 'miss', 'sign', 'slightly', 'difficult', 'find', 'training', 'practice', 'scan', 'skill', 'help', 'improve', 'success', 'rate', 'situation', 'acknowledgment', 'allaboard', 'development', 'fund', 'part', 'award', 'author', 'like', 'rosenbaum', 'carroll', 'center', 'blind', 'help', 'participant', 'recruitment', 'coordination', 'reference', 'crudden', 'mcdonnall', 'c', 'hierholzer', 'transportation', 'electronic', 'survey', 'person', 'blind', 'low', 'vision', 'journal', 'visual', 'impairment', 'blindness', 'shivshanker', 'p', 'impact', 'app', 'assistive', 'device', 'visually', 'impair', 'person', 'annual', 'review', 'vision', 'null', 'doi101146annurevvision', 'civil', 'right', 'division', 'r', 'golledge', 'r', 'g', 'hidden', 'demand', 'participation', 'activity', 'travel', 'person', 'visually', 'impair', 'journal', 'visual', 'impairment', 'blindness', 'doi1011770145482x0309700803', 'park', 'j', 'chowdhury', 'investigate', 'barrier', 'typical', 'journey', 'public', 'transport', 'user', 'journal', 'transport', 'health', 'https', 'visne', 'øksenholt', 'aarhaug', 'public', 'transport', 'people', 'impairment', 'explore', 'nonuse', 'public', 'transport', 'case', 'norway', 'disability', 'society', 'travel', 'blindness', 'qualitative', 'spacetime', 'approach', 'understand', 'visual', 'impairment', 'urban', 'mobility', 'health', 'place', 'low', 'wy', 'hickman', 'r', 'journey', 'experience', 'visually', 'impair', 'people', 'public', 'transport', 'transport', 'policy', 'https', 'et', 'enhance', 'safety', 'visually', 'impair', 'traveler', 'transit', 'station', 'robotic', 'golledge', 'r', 'g', 'r', 'costanzo', 'attitude', 'visually', 'impair', 'person', 'use', 'public', 'transportation', 'journal', 'visual', 'impairment', 'blindness', 'doi1011770145482x9709100505', 'azenkot', 'et', 'proceeding', 'human', 'factor', 'computing', 'system', 'association', 'compute', 'machinery', 'hara', 'improve', 'public', 'transit', 'accessibility', 'blind', 'rider', 'crowdsource', 'bus', 'stop', 'landmark', 'location', 'view', 'extended', 'analysis', 'acm', 'tran', 'access', 'comput', 'article', 'doi1011452717513', 'perkin', 'school', 'blind', 'blindway', 'crowdsource', 'bus', 'stop', 'location', 'app', 'https', 'last', 'access', 'field', 'testing', 'app', 'help', 'blind', 'individual', 'find', 'bus', 'stop', 'investigative', 'ophthalmology', 'visual', 'science', 'widespread', 'error', 'bus', 'stop', 'location', 'mapping', 'accessibility', 'barrier', 'passenger', 'blind', 'low', 'vision', 'journal', 'visual', 'impairment', 'blindness', 'kuyk', 'fuhr', 'p', 'feature', 'search', 'person', 'severe', 'visual', 'impairment', 'vision', 'satgunam', 'p', 'peli', 'e', 'visual', 'search', 'performance', 'patient', 'vision', 'impairment', 'effect', 'image', 'enhancement', 'ophthalmic', 'opt', 'sáez', 'garcía', 'monte', 'h', 'assist', 'visually', 'impair', 'people', 'public', 'transport', 'system', 'rfcommunication', 'embed', 'system', 'sensor', 'et', 'transportation', 'research', 'board', 'ch', 'proceeding', '33rd', 'annual', 'acm', 'conference', 'extend', 'abstract', 'human', 'factor', 'compute', 'system', 'association', 'compute', 'machinery', 'parker', 'et', 'wayfinde', 'tool', 'people', 'visual', 'impairment', 'realworld', 'setting', 'literature', 'review', 'recent', 'study', 'frontier', 'education', 'eltaher', 'taha', 'courtney', 'systematic', 'review', 'urban', 'navigation', 'system', 'visually', 'impair', 'people', 'sensor', 'campbell', 'c', 'bonnar', 'borne', 'proceeding', '16th', 'international', 'acm', 'sigaccess', 'conference', 'computer', 'accessibility', 'association', 'compute', 'machinery', 'blindsquare', 'https', 'wwwblindsquarecomabout', 'access', 'lazarillo', 'inclusive', 'navigation', 'digital', 'map', 'access', 'lock', 'j', 'cielniak', 'bellotto', 'saha', 'fiannaca', 'j', 'kneisel', 'e', 'r', 'proceeding', '21st', 'international', 'acm', 'sigaccess', 'conference', 'computer', 'accessibility', 'association', 'compute', 'machinery', 'commute', 'booster', 'mobile', 'application', 'firstlast', 'mile', 'middle', 'mile', 'navigation', 'support', 'people', 'blindness', 'low', 'vision', 'ieee', 'translational', 'engineering', 'health', 'medicine', 'doi101109jtehm20233293450', 'eye', 'ear', 'infirmary', 'allaboard', 'find', 'bus', 'stop', 'blind', 'https', 'access', 'sandler', 'howard', 'mobilenetv2', 'next', 'generation', 'ondevice', 'computer', 'vision', 'network', 'https', 'bate', 'mächler', 'walker', 'fitting', 'linear', 'mixedeffect', 'model', 'use', 'journal', 'statistical', 'software', 'doi1018637jssv067i01', 'balance', 'speed', 'flexibility', 'package', 'zeroinflate', 'generalize', 'linear', 'mixed', 'modeling', 'r', 'journal', 'doi1032614rj2017066', 'emmean', 'estimate', 'marginal', 'mean', 'leastsquare', 'mean', 'r', 'package', 'version', 'http', 'lüdecke', 'benshachar', 'waggoner', 'p', 'makowski', 'performance', 'r', 'package', 'assessment', 'comparison', 'testing', 'statistical', 'model', 'journal', 'open', 'source', 'software', 'dharma', 'residual', 'diagnostic', 'hierarchical', 'multilevel', 'mixed', 'regression', 'model', 'r', 'package', 'version', 'https', 'ggplot2', 'elegant', 'graphic', 'datum', 'analysis', 'vol', 'https']"
"Go Beyond Imagination: Maximizing Episodic Reachability with World
  Models","[{'href': 'http://arxiv.org/abs/2308.13661v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2308.13661v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-08-25 20:30:20,"ORL-AUDITOR: Dataset Auditing in Offline Deep
Reinforcement Learning

3
2
0
2

p
e
S
6

]

R
C
.
s
c
[

1
v
1
8
0
3
0
.
9
0
3
2
:
v
i
X
r
a

Linkang Du†∗, Min Chen‡∗, Mingyang Sun†, Shouling Ji†, Peng Cheng†, Jiming Chen†, Zhikun Zhang†‡§¶
† Zhejiang University, Hangzhou 310017, China
Email: linkangd@gmail.com, sji@zju.edu.cn, saodiseng@gmail.com, cjm@zju.edu.cn
‡CISPA Helmholtz Center for Information Security, Saarbr¨ucken 66123, Germany
Email: min.chen@cispa.de
§Stanford University, Stanford, California 94305, USA
Email: zhikun@stanford.edu

Abstract—Data is a critical asset in AI, as high-quality datasets
can significantly improve the performance of machine learning
models. In safety-critical domains such as autonomous vehicles,
offline deep reinforcement learning (offline DRL) is frequently
used to train models on pre-collected datasets, as opposed to train-
ing these models by interacting with the real-world environment
as the online DRL. To support the development of these models,
many institutions make datasets publicly available with open-
source licenses, but these datasets are at risk of potential misuse
or infringement. Injecting watermarks to the dataset may protect
the intellectual property of the data, but it cannot handle datasets
that have already been published and is infeasible to be altered
afterward. Other existing solutions, such as dataset inference
and membership inference, do not work well in the offline DRL
scenario due to the diverse model behavior characteristics and
offline setting constraints.

In this paper, we advocate a new paradigm by leveraging the
fact that cumulative rewards can act as a unique identifier that
distinguishes DRL models trained on a specific dataset. To this
end, we propose ORL-AUDITOR, which is the first trajectory-
level dataset auditing mechanism for offline RL scenarios. Our
experiments on multiple offline DRL models and tasks reveal
the efficacy of ORL-AUDITOR, with auditing accuracy over
95% and false positive rates less than 2.88%. We also provide
valuable insights into the practical
implementation of ORL-
AUDITOR by studying various parameter settings. Furthermore,
we demonstrate the auditing capability of ORL-AUDITOR on
open-source datasets from Google and DeepMind, highlighting
its effectiveness in auditing published datasets. ORL-AUDITOR
is open-sourced at https://github.com/link-zju/ORL-Auditor.

I.

INTRODUCTION

Deep reinforcement learning (DRL) has been successfully
applied to many complex decision-making tasks, such as
autopilot [17], robot control [3], [51], power systems [70],
intrusions detection [42], [67]. However, for safety-critical
domains, such as robot control, directly interacting with the
environment is unsafe since the partially trained policy may

∗The first two authors made equal contribution.
¶Zhikun Zhang is the corresponding author.

Network and Distributed System Security (NDSS) Symposium 2024
26 February - 1 March 2024, San Diego, CA, USA
ISBN 1-891562-93-2
https://dx.doi.org/10.14722/ndss.2024.23184
www.ndss-symposium.org

risk damage to robot hardware or surrounding objects [55].
To address this issue, researchers propose the offline deep
reinforcement
learning (Offline DRL) [37] paradigm, also
known as full batch DRL [36]. The general idea is learning
from pre-collected data generated by the expert, handcrafted
controller, or even random strategy respecting the system’s
constraints.

[4], Berkeley Artificial

To facilitate the research of offline DRL, several high-
quality datasets are published by third parties such as Deep-
Mind [26],
Intelligence Research
(BAIR) [18], Polixir Technologies [52], TensorFlow [1], and
Max Planck Institute [27]. These datasets are published with
strict open-source licenses, such as GNU General Public
License [4], Apache License [26], [18], [1], [52], and BSD 3-
Clause License [27], to protect the intellectual property (IP) of
the data owner. The licenses typically encompass two essential
terms. 1) Attribution requires you (the users) to appropriately
acknowledge the source, provide a link to the license, and
indicate any modifications made. 2) ShareAlike stipulates that
if you remix,
transform, or build upon the material, you
must distribute your contributions under the same license as
the original. Furthermore, some datasets are accompanied by
additional patent grants aimed at safeguarding the rights of
data publishers, e.g. StarData [40]. Additionally, closed-form
datasets have the potential to face misuse from insider attacks
or intellectual property infringement (e.g., ex-employees steal-
ing data). Biscom’s 2021 survey finds that 25% of respondents
admitted to taking the valuable data when leaving their job,
with 95% citing a lack of policies or technologies to prevent
data theft [5]. Tessian reports that 40% of US employees
take their generated data or trained models when leaving their
job [61]. The defense against the above threats comes to the
question of how a data owner can prove that a suspect model
was derived from its dataset.

Existing Solutions. Recent mainstream solutions for dataset
copyright protection can be classified into three categories:
Watermarking, dataset inference, and membership inference.
The watermarking approach aims to inject samples from
a specific distribution prior to publishing the dataset [39],
the auditor needs a post-event mechanism
[38]. However,
for open-source data since they are already published in the
real world. In contrast to watermarking techniques, dataset
inference strategies [43], [16] do not require the injection of
explicit watermarks [6] into the datasets or trained models.

 
 
 
 
 
 
To implement the auditing, we first train a critic model
to predict the cumulative rewards of the state-action pairs in
the dataset to be audited, i.e., the target dataset. A straightfor-
ward strategy to derive the auditing result is to compare the
cumulative reward of the state-action pairs from the suspect
model to that of the target dataset through a preset judgment
threshold of the similarity. However, designing the threshold
value is challenging, as it depends on the distributions of pre-
collected datasets, which can vary due to different task settings,
collection procedures, and data post-processing methods. To
address this issue, we recognize that the cumulative rewards
embedded in the state-action pairs of the models are the esti-
mated cumulative rewards of the target dataset, as the offline
DRL models fit the cumulative reward of the dataset during
training. Thus, we train multiple models on the target dataset
with varying initializations and optimization, i.e., the shadow
models, and collect the cumulative rewards of their state-action
pairs. Finally, by comparing the cumulative rewards from the
suspect model and the shadow models, we make the audit
decision through hypothesis testing.

Evaluation. The experimental results show that the auditing
accuracy of ORL-AUDITOR exceeds 95% with false positive
rates less than 2.88% across multiple DRL models and tasks.
By visualizing the cumulative rewards from the shadow models
trained on different datasets, we demonstrate that the cumula-
tive reward is a distinguishable feature for the dataset audit. We
further evaluate three influential factors for the practical adop-
tion of ORL-AUDITOR, i.e., the number of shadow models, the
significance level in hypothesis testing, and the trajectory size.
First, more shadow models improve the audit accuracy, and
ORL-AUDITOR demonstrates exceptional performance with
an audit accuracy exceeding 90%, utilizing a mere 9 shadow
models as illustrated in Table VIII. Second, the minimum sig-
nificance level α of ORL-AUDITOR is about 0.001, meaning
that the auditor outputs a single result with 99.9% confidence.
Third, ORL-AUDITOR tends to obtain higher accuracy with a
larger trajectory size, yet we also notice that a small trajectory
size achieves better results under some tasks [46]. We further
implement ORL-AUDITOR to audit the open-source datasets
from Google [18] and DeepMind [26], and the experimental
results again demonstrate the effectiveness of ORL-AUDITOR
in practice.

Robustness. To evaluate the robustness of ORL-AUDITOR,
we have implemented two defense strategies to prevent the
auditing. The first strategy involves using state-of-the-art mem-
bership inference defense techniques, such as the ensemble
architecture proposed by Tang et al. [60] and Jarin et al. [31].
Despite these defense mechanisms,
the audit accuracy of
ORL-AUDITOR is still over 85%. In addition to the ensem-
ble architecture, the suspect models may distort actions to
hide their training dataset. The offline DRL models for real-
world decision-making tasks (i.e., self-driving cars) often use
Gaussian noise to model natural distortions [2]. Thus, adding
Gaussian noise to the actions is stealthy to avoid the auditor’s
detection, and Gaussian noise is convenient for mathematical
manipulation. To simulate strong and weak action distortion,
we normalize all dimensions of the action space to [−1, 1]
and use Gaussian noise with (µ = 0, σ = 0.1) and (µ =
0, σ = 0.01), respectively. Our experiments show that ORL-
AUDITOR is only slightly affected by Gaussian noise with

Fig. 1: Intuitive explanation of ORL-AUDITOR. The middle
surface is the cumulative rewards of the state-action pairs from
a dataset. The auditor outputs a positive result if the cumulative
rewards of a suspect model’s state-action pairs are between the
two outer surfaces.

Maini et al. [43] and Dziedzic et al. [16] have separately
proposed dataset inference methods for supervised learning
and self-supervised learning models, enabling the model owner
to provide a convincing statistical argument that a particular
model is trained on their private data. However, the dataset
inference with labels [43] needs distances between data and
decision boundaries, which is not possible to obtain in RL with
continuous outputs. The dataset inference without labels [16]
uses the similarity of model behaviors to detect unauthorized
dataset usage. It requires a public dataset to generate some
surrogate models, and forms the auditing basis by comparing
the behavioral difference between the surrogate models and
the models trained on their private data. In offline RL scenes,
since the distributions of the collected datasets depend on both
environment and operator [18], it is difficult to determine a
suitable public dataset to train the surrogate model, making
the audit basis hard to establish. The third category adopts the
notion of membership inference [47], [24], [23]. By collecting
the RL models’ behaviors on the trained examples (members)
and the untrained examples (non-members), a classifier is
constructed to determine whether a data sample is used in the
model’s learning process. However, unlike online scenarios in
[47], [24], [23], the auditor cannot collect additional data from
the environment as the non-member examples in offline cases,
where the auditor does not have access to the environment.

Our Proposal.
In this paper, we propose the first practical
dataset auditing paradigm for the offline RL model (ORL-
AUDITOR). Concretely, we are inspired by the fact that the
cumulative reward, i.e., the sum of all rewards received over a
period of time starting from a given state-action pair, guiding
the RL model to learn the behavior policy. Thus, the cumu-
lative reward is an intrinsic feature of the datasets, making
it suitable as an audit basis. Figure 1 provides a schematic
diagram of ORL-AUDITOR, where the state, the action, and
the cumulative reward compose a three-dimensional space. The
middle surface illustrates the exact cumulative reward of the
dataset, and the other two surfaces show possible offsets of the
exact cumulative reward learned by the offline DRL models
due to the randomness in the initialization and the learning
processes. For a suspect model, the auditor outputs a positive
result, i.e., the data is used to train this model, if the cumulative
reward from its state-action pair falls between the two surfaces;
otherwise, a negative outcome.

2

Cumulative Reward

𝑄𝑄 𝑠𝑠, 𝑎𝑎 + ∆

𝑄𝑄(𝑠𝑠, 𝑎𝑎)

𝑄𝑄 𝑠𝑠, 𝑎𝑎 − ∆

State:

𝑠𝑠

Action:

𝑎𝑎

Positive
Negative

Share

Help/Contact

 
 
 
 
 
 
(µ = 0, σ = 0.01). For σ = 0.1, the TPR values of ORL-
AUDITOR decline, yet the strong distortion also impacts the
performance of the suspect model, especially in complex tasks.

Contributions. Our contributions are three-fold:

• To our knowledge, ORL-AUDITOR is the first dataset audit-
ing method for the offline DRL models, using the cumulative
reward as an intrinsic and stable fingerprint of the dataset.
• We demonstrate the effectiveness of ORL-AUDITOR on four
offline DRL models and three tasks. We also systematically
analyze various experimental factors, i.e., the hyperparam-
eter settings and the robustness of ORL-AUDITOR, and
summarize some important guidelines for adopting ORL-
AUDITOR in practice.

• By implementing ORL-AUDITOR on the open-source
datasets from DeepMind [26] and Google [18], we show
that ORL-AUDITOR can serve as a potent audit solution in
real-world offline DRL scenarios.

II. BACKGROUND

A. Offline RL Problem

The offline reinforcement learning (offline RL) model aims
to learn an optimal (or nearly optimal) policy from a pre-
collected dataset D without an interactive environment. We use
S and A to represent the RL models’ input and output space,
formally called state and action in RL scenes. rt ∈ R is the
temporal reward for each time step, where R is the real number
set. A unit in a pre-collected dataset called transition is a four-
element set: {st, at, rt, st+1}, where st ∈ S, at ∈ A, and
st+1 ∈ S is the successive state of st. And a set of transitions
in chronological order forms a trajectory in dataset D. Based
on the transitions, the offline RL model learns the Markov
Decision Process underneath the datasets and forms a policy
πθ(a | s) to maximize J(π).

J(π) = Est∼dβ (s, a), at∼πθ(a|s)

(cid:35)

γtrt

,

(cid:34) H
(cid:88)

t=0

where we use dβ to denote the distribution over states and
actions in dataset D, and the actions are sampled according to
the behavior policy at ∼ πθ(a | s). The discount factor γ is
applied to discount future rewards in the accumulated reward.
H is the terminal time step of one trajectory.

Example. Figure 2 shows an example based on the “CartPole”
task. 1 In the data collection process, the dataset is generated
from the operation logs between the operator and the envi-
ronment, which contains the position and velocity of the cart
and the pole (i.e., state), the operator’s force direction (i.e.,
action), and the corresponding rewards. Then, in the training
and evaluation process, the offline RL model learns how to
play the “Cartpole” task from only the pre-collected dataset
generated through the data collection process. Finally, we
deploy the well-trained offline RL model in the environment
to perform the task.

1https://www.gymlibrary.dev/environments/classic control/cart pole/

Fig. 2: A running example of the offline DRL models.

B. Offline RL Models

In this section, we first introduce two offline RL algo-
rithms [21], [19], [35] separately representing two basic ideas
of the offline RL models, i.e., the policy constraints strategy
and the value function regularization strategy [50]. Many state-
of-the-art model-free offline RL methods [68], [32], [20], [35]
have been modified from these two approaches. We further
present a state-of-the-art algorithm [20] which is minimalistic
with light computation and hyperparameter setting overhead.
In addition, we briefly describe the behavior clone method
(BC) [49], which learns the state-action distribution over the
dataset via a supervised learning approach. Though BC is not a
typical reinforcement learning method, it can solve the offline
RL problem and usually serves as the baseline method in the
offline RL evaluation.

Behavior Clone (BC) [49]. BC separately takes the pairwise
state s and action a in the datasets as input and label, then it
optimizes the policy through the following function.

θ∗ = arg min

θ

E(s,a)∼D [L (πθ(s), a)] ,

where D is the pre-collected dataset and L is the loss function.
Since BC only imitates action distributions, the performance is
close to the mean of the dataset, even though BC works better
than online RL algorithms in most cases.

Batch-Constrained Q-learning (BCQ) [21], [19]. BCQ is
the first practical data-driven offline RL algorithm. The key
idea of BCQ is to integrate a generative model to achieve
the notion of batch-constrained, i.e., minimizing the deviation
between the candidate actions with the action records of the
dataset. To maintain the diversity of action, BCQ builds a
perturbation model to perturb each selected action. Then it
chooses the highest-valued action through a Q-network, that
learns to estimate the expected cumulative reward of a given
state and action pair. Thus, the objective function of BCQ can
be defined as the following.

π(s) = argmax

Qθ (s, ai + ξϕ (s, ai, Φ))

ai+ξϕ(s,ai,Φ)
{ai ∼ Gω(s)}n

i=1 ,

where Gω(s) is a conditional variational auto-encoder (VAE)-
based [33] generative model that can be used to generate
candidate actions. The value function Qθ is used to score
the n candidate actions and finds the action with the highest
value. ξϕ (s, ai, Φ) is the perturbation model, which outputs

3

Dataset

… , 𝒔𝒔𝒕𝒕, 𝒂𝒂𝒕𝒕, 𝒓𝒓𝒕𝒕, 𝒔𝒔𝒕𝒕""𝟏𝟏 , …

State, Reward

Move Left, R = 1

Move Right, R = 1

Move Left, R = 1

Action

Environment

Operator

Offline DRL Model

Environment

Action

Offline DRL Model

State

Data Collection

Training and Evaluation

Deployment

an adjustment to an action a in the range [−Φ, Φ]. Then,
the perturbation model can be optimized by the deterministic
policy gradient algorithm [58] as follows.

ϕ ← argmax

(cid:88)

ϕ

(s,a)∈B

Qθ (s, a + ξϕ(s, a, Φ)) ,

where B represents a mini-batch state-action pair in the dataset.
To penalize rare states, BCQ takes a convex combination of
the values from two Q-networks and sets a new target value
y to update both Q-networks.
(cid:20)

y = r+γ max

ai

λ min
j=1,2

Qθ′

j

(s′, ai) + (1 − λ) max
j=1,2

Qθ′

j

(cid:21)
(s′, ai)

where ai corresponds to the perturbed actions, sampled from
the generative model Gω(s).

Implicit Q-Learning (IQL) [35]. Compared to the batch-
constrained idea of BCQ [21], [19], IQL strictly avoids query-
ing values of the actions, which are not in the pre-collected
dataset. IQL first constructs a model to evaluate the expected
returns of state-action pairs. The objective function is defined
as shown in Equation 1.

L(θ) = ED

(cid:2)Lτ

2

(cid:0)r(s, a) + γQˆθ (s′, a′) − Qθ(s, a)(cid:1)(cid:3) ,

(1)

2 (u) = |τ − 1(u < 0)|u2, and s′ and a′ represent
where Lτ
the successor state and action of s and a. Both Qθ(s, a)
and Qˆθ are used to assess the expected returns of state-
action pairs. The parameters of Qθ(s, a) are adjusted in each
optimization round, while the parameters of Qˆθ are updated
periodically based on Qθ(s, a) to reduce parameter fluctuations
during model updates. Equation 1 involves the dynamics of the
environment, where the environment state s transitions to the
next environment state s′, potentially introducing interference
in the evaluation of expected returns for state-action pairs. IQL
addresses this issue by introducing a new state value model,
splitting Equation 1 into two objective functions. Equation 2
shows the objective function of the state value model Vψ.

LV (ψ) = ED

(cid:2)Lτ

2

(cid:0)Qˆθ(s, a) − Vψ(s)(cid:1)(cid:3) .

(2)

Then, IQL utilizes Vψ(s) to construct Equation 3 for

updating the parameters of the state-action value model Qθ.

LQ(θ) = ED

(cid:104)

(r(s, a) + γVψ (s′) − Qθ(s, a))2(cid:105)

.

(3)

Finally, IQL considers using the state-action value model
to construct a behavior policy for deployment. This behavior
policy also needs to avoid actions that are outside the dataset
distribution. Thus, IQL employs advantage-weighted regres-
sion to update the policy model.
Lπ(ϕ) = ED [exp (β (Qθ(s, a) − Vψ(s))) log πϕ(a | s)] , (4)

where β ∈ [0, ∞) represents the inverse temperature. For
smaller values of β, IQL is similar to behavior clone, tending
to mimic the data collection policy. For larger values of β,
IQL is more inclined to select actions corresponding to the
highest expected returns according to the state-action value
model. Throughout the entire training process, IQL alternates
between optimizing the parameters θ and ψ, and then updates
ϕ while keeping θ and ψ fixed.

TD3PlusBC [20]. The former methods [21], [19], [35] limit or
regularize action selection such that the learned policy is easier
to evaluate with the given dataset. However, they introduce new
hyperparameters and often leverage secondary components,
such as generative models, while adjusting the underlying RL
algorithm. TD3PlusBC is a minimalist and highly effective
offline RL algorithm based Twin Delayed Deep Deterministic
Policy Gradient (TD3) [22] with BC regularization term, which
pushes the policy towards favoring actions contained in the
dataset D:

π = argmax

E(s,a)∼D

,

π

(cid:2)λQ(s, π(s)) − (π(s) − a)2(cid:3) ,

α

1
N

(cid:80)

where λ =
(s,a)|Q(s,a)| for the dataset of N transitions
(s, a). To facilitate the policy training, TD3PlusBC normalizes
each state in the given dataset by si = si−µ
σ+ϵ , where µ and σ
are the mean and standard deviation respectively.

The model architectures vary significantly regarding objec-
tive function and basic model structure. 1) Objective Function:
BCQ [21], [19] and TD3PlusBC [20] use a policy constraints
strategy to maintain the learned policy similar to the one
used for collecting the dataset. In contrast, IQL [35] adopts
a regularization strategy to improve the stochasticity of the
learned policy or obtain more accurate Q-value estimations.
2) Basic Model Structures: BCQ [21], [19] and IQL [35]
are based on the Q-learning model, while TD3PlusBC [20]
builds upon TD3 [22]. In Section V, our experiments are
mainly conducted on the above four algorithms. However,
ORL-AUDITOR can also be applied to any type of offline
DRL model as long as the auditor has black-box access to
the suspect model.

III. PROBLEM STATEMENT AND EXISTING SOLUTIONS

A. System and Threat Model

the dataset

Application Scenarios.
Figure 3 illustrates a typical ap-
plication scenario where the data providers collect and then
publish or sell
to the customers. A malicious
customer (adversary) with access to the datasets makes a piracy
distribution or illegally builds a Model-as-a-Service (MaaS)
platform. Institution 1 suspects the models are generated by
its dataset, and thus hires an auditor to determine whether the
model trainers pirate the trajectories of the dataset D1.

Auditor’s Background Knowledge and Capability. The
auditor has full knowledge of the target dataset, such as the
number of trajectories and the spaces of state and action. In
offline RL settings, the auditor is prohibited from interacting
with the online environment to collect more data, meaning the
entire auditing only depends on the target dataset. We consider
the auditor has black-box access to the suspect RL model.
Note that this is the most general and challenging scenario
for the auditor. A typical application scenario is that an adver-
sary receives the model settings from customers, such as the
selected offline RL framework, the model’s hyperparameter,
and the desired training episodes. Then, the adversary trains
an offline RL model and provides a service interface to the
customers. The auditor utilizes the states of the dataset (inputs)
to query the suspect model and obtain the corresponding
actions (outputs).

4

explicit watermarks [6] to the datasets or the trained models.
Existing methods [43], [16] can be divided into two categories
according to whether they have explicit classification labels.
With the explicit classification labels, [43] rely on computing
the distances between data points and decision boundaries.
Without
the explicit classification labels, [16] utilizes the
similarity of the models’ behaviors to detect the unauthorized
usage of the dataset, which requires the assumption of an
additional public dataset with a similar distribution to form
the auditing basis.

However, the above methods cannot directly be applied
to reinforcement learning cases due to two reasons. First, the
label-based dataset inference [43] cannot be implemented in
the RL models since their outputs are usually continuous, and
they are guided by the rough reward signals instead of the exact
labels. Second, the distribution of the offline RL dataset not
only depends on the environment but also relies on the strategy
of interacting with the environment [18]. Thus, it is challenging
to find a proper public dataset in offline RL scenarios. As we
delve into Appendix A, it becomes evident that the behavior
similarity of the DRL models varies across different public
training data. Furthermore,
the behavior similarity is also
influenced by various offline DRL frameworks.

Membership Inference Attack against RL [47], [24], [23].
Several membership inference attacks exist against DRL,
which seem to address the problem studied in this paper. Most
of them are targeted at the online RL scenes, assuming that
the attacker owns the environment. Thus, they can utilize the
environment to collect more data and even manipulate some
adversarial states to facilitate the inference.

However, in this paper, we aim at the offline RL cases,
which are more challenging since the only thing the auditor can
use is the pre-collected dataset. That is, in offline RL scenarios,
the existing MIA against RL cannot rely on the environment
to generate non-member data.

IV. ORL-AUDITOR

We instantiate Q of Figure 1 with the cumulative reward,
which is an intrinsic feature of the dataset and suitable for
auditing. ∆ is determined by the shadow models trained on the
datasets instead of a preset threshold to adapt the distribution of
different datasets. Thus, the well-designed Q and ∆ guarantee
the adaptiveness and effectiveness of ORL-AUDITOR.

A. Workflow

For ease of understanding, we refer to the target dataset as
the dataset to be audited and the actual dataset as the dataset
used by the suspect model. If the suspect model is trained
on the target dataset, the actual dataset is the same as the
target dataset, i.e., positive audit result for the suspect model;
otherwise, the suspect model does not use the target dataset,
i.e., negative audit result for the suspect model. Figure 4
illustrates the workflow of ORL-AUDITOR.

Fig. 3: An example of the application scenario. The auditor can
obtain all information about dataset D1 but has no knowledge
about the datasets from other institutions.

Discussion. Compared to the sample-level and dataset-level
data in DNN scenes, RL has trajectory-level data, which is
the minimum record unit of sequential interactions between
the operator and environment. Since a single trajectory can
guide the model from the initial state to the terminal, the
trajectory-level data is regarded as the value unit of the dataset.
Thus, ORL-AUDITOR is designed to audit the dataset from
the trajectory level, where the auditor tries to decide whether
the suspect model uses a specific trajectory in the dataset. In
addition, the auditor can easily extend ORL-AUDITOR to the
dataset-level data by setting a piracy alarm threshold. If the
ratio of misappropriation using trajectories exceeds the preset
threshold, the auditor can claim the dataset-level pirate.

B. Existing Solutions

Watermarking [39], [38]. Watermarking-based dataset copy-
right protection methods inject samples of a specific distribu-
tion before publishing the target dataset. One of its kind is
implemented with backdoor attacks against the ML model. Li
et al. [39] proposed to modify a dataset by adding a trigger,
such as a local patch, to innocent samples in order to make
them appear as a pre-defined target class. To verify the integrity
of the dataset after the attack,
they use a hypothesis test
approach based on posterior probabilities generated by a third-
party model. Inspired by this idea, the auditor can employ the
backdoor attack against the DRL model [34], [64], [66] to
generate a watermark for the offline RL dataset.

However, since the open-source datasets are already pub-
lished, the auditor needs a post-event mechanism that does
not require injecting manipulated samples before publishing
the dataset. Watermarking, on the other hand, is a pre-event
mechanism that involves injecting manipulated samples into
the dataset before publishing. Additionally, it is difficult for
the auditor to guarantee that one effective watermarking has
a consistent distribution with the original dataset, which in-
evitably disturbs the model’s normal behavior.

Dataset Inferences [43], [16]. The core idea of dataset
inference is empowering the model owner to make a com-
pelling statistical argument that a particular model is a copied
version of their own model by demonstrating that it is based
on their private training data. It does not require injecting

Step 1: Model Preparation (MP).
In the left box of
Figure 4, the auditor prepares the critic model and the shadow
DRL models based on the target dataset, which contains m
trajectories T with the length of ni (i ∈ {1, 2, . . . , m}). The
critic model is optimized to estimate the cumulative reward

5

𝟏𝟏
𝒔𝒔𝟏𝟏

𝟏𝟏
, 𝒂𝒂𝟏𝟏

𝟏𝟏
, 𝒓𝒓𝟏𝟏

𝟏𝟏
, 𝒔𝒔𝟐𝟐

𝟏𝟏
𝒔𝒔𝟐𝟐

𝟏𝟏
, 𝒂𝒂𝟐𝟐

𝟏𝟏
, 𝒓𝒓𝟐𝟐

𝟏𝟏
, 𝒔𝒔𝟑𝟑

𝒋𝒋
𝒔𝒔𝟏𝟏
𝒎𝒎
𝒔𝒔𝟏𝟏

𝒋𝒋
, 𝒂𝒂𝟏𝟏
𝒎𝒎
, 𝒂𝒂𝟏𝟏

𝒋𝒋
𝟐𝟐
, 𝒔𝒔𝟐𝟐
, 𝒓𝒓𝟏𝟏
𝒎𝒎
𝒎𝒎
, 𝒔𝒔𝟐𝟐
, 𝒓𝒓𝟏𝟏

𝒋𝒋
𝒋𝒋
, 𝒂𝒂𝟐𝟐
𝒔𝒔𝟐𝟐
𝒎𝒎
𝒔𝒔𝟐𝟐

𝒋𝒋
, 𝒓𝒓𝟐𝟐
𝒎𝒎
, 𝒂𝒂𝟐𝟐

𝒋𝒋
, 𝒔𝒔𝟑𝟑
𝒎𝒎
, 𝒓𝒓𝟐𝟐

𝒎𝒎
, 𝒔𝒔𝟑𝟑

…

…

…

𝟏𝟏
𝒔𝒔𝒏𝒏𝟏𝟏

𝟏𝟏
, 𝒂𝒂𝒏𝒏𝟏𝟏

𝟏𝟏
, 𝒓𝒓𝒏𝒏𝟏𝟏

𝟏𝟏
, 𝒔𝒔𝒆𝒆𝒏𝒏𝒆𝒆

𝒋𝒋
𝒋𝒋
𝒋𝒋
, 𝒂𝒂𝒏𝒏𝒋𝒋
𝒔𝒔𝒏𝒏𝒋𝒋
, 𝒓𝒓𝒏𝒏𝒋𝒋
𝒎𝒎
𝒎𝒎
, 𝒂𝒂𝒏𝒏𝒎𝒎
𝒔𝒔𝒏𝒏𝒎𝒎

𝒋𝒋
, 𝒔𝒔𝒆𝒆𝒏𝒏𝒆𝒆
𝒎𝒎
𝒎𝒎
, 𝒓𝒓𝒏𝒏𝒎𝒎
, 𝒔𝒔𝒆𝒆𝒏𝒏𝒆𝒆

Transition

Trajectory

Institution 1

Dataset

Institution 2

Dataset

Institution 3

Dataset

𝐷𝐷""

𝐷𝐷#

𝐷𝐷$

A
d
v
e
r
s
a
r
y

Model

𝜋𝜋!Model

𝜋𝜋""Model

𝜋𝜋""

Auditor for 
Institution 1 

The models do (or do not)
pirate the
-th Trajectory
of Dataset

.

𝒋𝒋

𝑫𝑫𝟏𝟏

Fig. 4: The workflow of ORL-AUDITOR contains three steps, i.e., model preparation, cumulative reward collection, and audit
process. ORL-AUDITOR first trains a set of shadow DRL models and a critic model on the target dataset, then collects the
cumulative rewards from the state-action pairs of the shadow models and the suspect model. Finally, ORL-AUDITOR audits
every trajectory based on hypothesis testing.

of each state-action pair. For each trajectory in the dataset,
a series of predictions for its state-action pairs compose the
exclusive feature for auditing. There are two ways to optimize
the critic model, i.e., the Monte-Carlo-based (MC-based) and
the temporal-difference-based (TD-based) strategies. We adopt
the TD-based learning method and explain the reasons in
Section IV-B. In addition, the auditor trains a set of shadow
models following the model’s objective function introduced in
Section II with different model initializations.

Step 2: Cumulative Reward Collection (CRC).
In the
middle box,
the shadow models observe the states of the
dataset and take actions. For i-th trajectory in the dataset,
the auditor records the state si
t and the action ai
t of each
shadow model, where ai
t represents the shadow model’s action
at the t-th step of trajectory Ti. After finishing the action
collection, the auditor obtains the k sets of state-action pairs
from the shadow models, representing the learned policies
with different initialization and training processes on the target
dataset. Using the critic model in Step 1, the auditor calculates
the estimations for all state-action records, i.e., the estimated
cumulative rewards, which are the samplings of the exact
cumulative rewards of the corresponding state-action pairs in
the dataset. Similarly, the auditor queries the suspect model
with state si
t. The state-action pairs
are then put into the critic model and to obtain the estimations
for the suspect model.

t and observes the action ai

Step 3: Audit Process (AP). After the above two steps,
the auditor obtains the estimated cumulative rewards from
the shadow models and the suspect model and then con-
ducts the audit process. For j-th (j ∈ {1, 2, . . . , m}) tra-
jectory of the dataset, the auditor collects k series of the
estimated cumulative rewards from the shadow models, i.e.,
{Qi
j | i ∈ {1, 2, . . . , k}}, and one from the suspect model,
i.e., Qs
j. ORL-AUDITOR conducts hypothesis testing based
j from ¯Qj. The auditor can
on the distances of Qi
j, ¯Qj) is out of the distribution of
rule out suspicion if d(Qs
j, ¯Qj) | i ∈ {1, 2, . . . , k}}. Otherwise, the auditor will
{d(Qi
conclude a positive decision, i.e., the suspect model is trained
using this trajectory. The auditor repeatedly implements the
above processes for other trajectories of the dataset and obtains

j and Qs

the final audit report with judgment for all trajectories. We
discuss more details of the distance metric and the hypothesis
testing in Section IV-C.

B. The Selection of Critic Model

The auditor can use either Monte Carlo (MC) based or
Temporal-Difference (TD) based algorithms to train a critic
model from the trajectories of the dataset. The main distinction
between the two methods lies in their learning targets, which
leads to differences in their objective functions. In the case
of MC-based methods, the learning target G is the empirical
cumulative rewards from the dataset.

G(st, at) = rt + γrt+1 + . . . + γH−1rH ,

where G(st, at) represents the exact cumulative reward from
(st, at) to the terminal time step H of one trajectory. The
discount factor γ is applied to discount future rewards. The
critic model is trained by minimizing the following objective.

E(st,at,rt+1,st+1)∼D

(cid:104)

(G (st, at) − Qθ (st, at))2(cid:105)

.

For TD-based methods, the learning target changes to the
expected cumulative reward in a heuristic form, i.e., rt +
γQ (st+1, at+1). Thus, the critic model is trained by mini-
mizing the following loss function.

E

(st,at,rt+1,st+1)∼D

(cid:2)(rt+1 + γQθ′ (st+1, at+1) − Qθ (st, at))2(cid:3) ,

where the critic model starts with arbitrary initialization θ.
Then, it repeatedly evaluates Qθ (st, at), obtains a reward rt+1,
and updates the weights. The θ′ is a snapshot of θ and copies
from θ every few updates of θ. The MC-based method utilizes
the exact cumulative rewards from the dataset to train the critic
model, resulting in an unbiased prediction. It also has strong
convergence properties due to the stationary of Gt. However,
it cannot be applied to situations where the collected data is
truncated, and all trajectories in the dataset must be completed.
In practice, many sequential decision-making tasks usually
have long or infinite time steps. Thus, the dataset provider
segments the interaction record into trajectories by a preset
maximum length. The TD-based method tackles the limitation
of the MC-based algorithm and can learn from incomplete
sequences. Nevertheless, due to the heuristic learning process,

6

Step 1: Model Preparation

Step 2: Cumulative Reward Collection

Dataset

1, 𝑎𝑡
𝑠𝑡

1, 𝑟𝑡

1
1, 𝑠𝑡+1

2, 𝑎𝑡
𝑠𝑡

2, 𝑟𝑡

2
2, 𝑠𝑡+1

|𝑡 = 1 … 𝑛1

|𝑡 = 1 … 𝑛2
…

𝑚, 𝑎𝑡
𝑠𝑡

𝑚, 𝑟𝑡

𝑚, 𝑠𝑡+1

𝑚 |𝑡 = 1 … 𝑛𝑚

Training

𝑇1:

𝑇2:

𝑇𝑚:

1

2

3

4

…

𝑘

Shadow DRL Models

Critic Model 𝑄(𝑠, 𝑎)

1

2

3

4

…

𝑘

Shadow 
DRL Models

𝑆1: 𝑠𝑡

1|𝑡 = 1 … 𝑛1

𝑆2: 𝑠𝑡

2|𝑡 = 1 … 𝑛2

…

𝑆𝑚: 𝑠𝑡

𝑚|𝑡 = 1 … 𝑛𝑚

States

Model 1
1)|𝑡 = 1 … 𝑛1

1, 𝑎𝑡
𝑠𝑡

(𝑠𝑡

2, 𝑎𝑡

2)|𝑡 = 1 … 𝑛2

…

(𝑠𝑡

𝑚, 𝑎𝑡

𝑚)|𝑡 = 1 … 𝑛𝑚

Model 𝑘
1)|𝑡 = 1 … 𝑛1

(𝑠𝑡

1, 𝑎𝑡

Model 𝑖: 1~𝑘

ℚ1

𝑖 : 𝑄 𝑠𝑡

1, 𝑎𝑡

1 |𝑡 = 1 … 𝑛1

…

(𝑠𝑡

2, 𝑎𝑡

2)|𝑡 = 1 … 𝑛2

…

ℚ2

𝑖 : 𝑄 𝑠𝑡

2, 𝑎𝑡
2 |𝑡 = 1 … 𝑛2
…

(𝑠𝑡

𝑚, 𝑎𝑡

𝑚)|𝑡 = 1 … 𝑛𝑚

ℚ𝑚

𝑖 : 𝑄 𝑠𝑡

𝑚, 𝑎𝑡

𝑚 |𝑡 = 1 … 𝑛𝑚

States & Actions

Critic Model Q(𝑠, 𝑎)

Cumulative Rewards

(𝑠𝑡

1, 𝑎𝑡

1)|𝑡 = 1 … 𝑛1

(𝑠𝑡

2, 𝑎𝑡

2)|𝑡 = 1 … 𝑛2

…

(𝑠𝑡

𝑚, 𝑎𝑡

𝑚)|𝑡 = 1 … 𝑛𝑚

ℚ1

𝑆: 𝑄 𝑠𝑡

1, 𝑎𝑡

1 |𝑡 = 1 … 𝑛1

ℚ2

𝑆: 𝑄 𝑠𝑡

2, 𝑎𝑡
2 |𝑡 = 1 … 𝑛2
…

ℚ𝑚

𝑆 : 𝑄 𝑠𝑡

𝑚, 𝑎𝑡

𝑚 |𝑡 = 1 … 𝑛𝑚

Suspect
DRL Model

States & Actions

Critic Model Q(𝑠, 𝑎)

Cumulative Rewards

𝑘
ℚ𝑗

Audit Metric

Step3 Audit Process
For 𝒋-th trajectory of the dataset
(𝑗 ∈ {1,2, … , 𝑚} )

1:
ℚ𝑗
2:
ℚ𝑗

𝑘:
ℚ𝑗

𝑠:
ℚ𝑗

0.7  1.2  1.3  0.6  …  1.1
0.7  0.9  0.8  0.9  …  0.9

⋯

1.3  0.9  0.7  0.5  …  1.3

0.6  1.3  1.1  1.4  …  1.1

Length of Trajectory

1, ഥℚ) 𝑑(ℚ𝑗

2, ഥℚ)
𝑑(ℚ𝑗
ഥℚ is element-wise mean of {ℚ𝑗

𝑑(ℚ𝑗

⋯

𝑘, ഥℚ) 𝑑(ℚ𝑗

𝑠, ഥℚ)
𝑖 |𝑖: 1~𝑘}.

2
ℚ𝑗

1
ℚ𝑗

4
ℚ𝑗

ഥℚ

𝑠
ℚ𝑗

3
ℚ𝑗
∆

5
ℚ𝑗

Positive

𝑠
ℚ𝑗

Negative

Hypothesis testing

If  𝝁

𝑄𝑆 >

, Negative for 𝑇

Algorithm 1 Workflow of ORL-AUDITOR
Input: Dataset D, suspect model πs, number of shadow

models k, significance level α

Output: The trajectory-level audit report

1: // Step 1: Model Preparation
2: Train shadow models {πi | i = 1, . . . , k} and critic model
3: // Step 2: Data Preparation
4: for each model π in {πi | i = 1, . . . , k} ∪ {πs} do
Query π by states s ∈ D and obtain the actions.
5:
Evaluate each (s, a) pair based on the critic model Q.
6:
Record the cumulative reward in sequential form {Qj |
7:

j = 1, . . . , m}.

8: end for
9: // Step 3: Audit Process
10: audit report = []
11: for each trajectory in {Tj | j = 1, . . . , m} do
12:

Calculate the element-wise mean ¯Qj of {Qi

j | i =

1, . . . , k}

13:
14:
15:

Measure the d(Qj, ¯Qj) of each Qi
// Hypothesis testing
From {di | i = 1, . . . , k} and ds, decide whether the

j from ¯Qj.

j and Qs

suspect model Ms pirates Tj with significance level α.

audit report.append(j-th audit result)

16:
17: end for
18: Return audit report

the TD-based method has some bias and is more sensitive to
model initialization. Therefore, we choose the element-wise
mean of the shadow models’ cumulative rewards ¯Q as the
auditing directrix in Section IV-A instead of relying solely on
the critic model’s predictions to compensate for the shortages
of TD-based methods.

C. The Details of Audit Process

In the audit process, the choice of distance metric and
the hypothesis testing method play a critical role in ORL-
AUDITOR’s performance. A proper metric is sensitive to the
deviations between the estimated cumulative rewards, which
can facilitate the hypothesis testing. A suitable hypothesis test-
ing method can provide precise results with high confidence.

Distance Metric. We consider three types of distance metrics,
i.e., ℓp norm, Cosine distance, and Wasserstein distance. ℓp
norm is a popular method of measuring the distance between
vectors, i.e., the sum of the absolute difference of the compo-
nents of the vectors. In the RL scene, the states and actions are
sequential data, meaning the distance metric should measure
both the value and the position deviation of the cumulative
rewards. However, ℓp norm may fail to reflect the difference
from the sequence aspect of the same set of values. Cosine
distance is a derivative of Cosine similarity, defined as the
cosine of the angle between two vectors. Cosine distance
embodies the difference from both the value and position
aspects of the vectors. However, Cosine distance normalizes
the inner product using the two vectors’ norm, which weakens
the numerical differences between the cumulative rewards. The
Wasserstein distance, a.k.a. earth mover’s distance (EMD), is a
metric of the difference between two probability distributions

over a region [54]. It can be defined as follows.

l1(u, v) = inf

π∈Γ(u,v)

(cid:90)

R×R

|x − y|dπ(x, y),

where Γ(u, v) is the set of distributions on R × R whose
marginals are u and v on the first and second factors respec-
tively. Wasserstein distance fits well with audit requirements,
reflecting numerical and positional deviations of the cumula-
tive rewards. Thus, we set Wasserstein distance by default and
compare different distance metrics in Section V.

Hypothesis Testing. After the selection of the distance metric,
the auditor proceeds to hypothesis testing with the distances
of Qi

j and Qs

j from ¯Qj.
H0 : d(Qs
H1 : d(Qs

j, ¯Qj)is not an outlier.
j, ¯Qj)is an outlier.

An intuitive method is to leverage the 3σ principle, i.e.,
the normal samples should be distributed within the range
of three times the standard deviation σd from the mean µd.
The 3σ principle is an efficient hypothesis testing method,
yet the mean µd is easily misled by outliers. Compared to
the 3σ principle, Grubbs’ test [25] is a more robust hypothe-
sis testing method for detecting single outliers in univariate
j, ¯Qj) exceeds
datasets. If the Grubbs’ test statistic of d(Qs
the threshold derived on the significance level, the auditor
j, ¯Qj) deviate from the mean value, i.e., reject
can claim d(Qs
H0 and output negative audit result. For a set of samples
{di | i = 1, 2, . . . , n}, Grubbs’ Test locates the outlier by the
procedures.

1) Calculate the mean µd and standard deviation σd.
2) Calculate the Grubbs’ test statistic by G =
(cid:114) t2

|d(Qs

σd

j , ¯Qj )−µd|

.

3) If G > n−1√
n

α/(n),n−2

n−2+t2

α/(n),n−2

, H0 is invalid,

i.e.,

the

suspect model is not trained by this trajectory. In the above
inequation, t2
α/(n),n−2 represents the upper critical value in
the t-distribution when the degree of freedom is n − 2, and
the significance level is α
n .

Both hypothesis testing methods are based on the assump-
tion that the distance values follow Gaussian distribution. Thus,
ORL-AUDITOR needs to pre-check that the distance values of
the shadow models satisfy the Gaussian distribution. We adopts
Anderson-Darling test [59] since it fits the scenarios where
the auditor has a small number of samplings, and the actual
distribution is unknown. In the evaluation, all the distance
values of the shadow models can pass the Anderson-Darling
test due to the randomness of the models’ initialization and
training. After that, ORL-AUDITOR conducts the hypothesis
testing.

V. EVALUATION

We first introduce the tasks and the experimental setup
in Section V-A. We validate the effectiveness of ORL-
AUDITOR on Behavior Clone and three offline DRL models,
i.e., Batch-Constrained Q-learning (BCQ) [21], Implicit Q-
Learning (IQL) [35], and TD3PlusBC [20] in Section V-B.
Then, we visualize the cumulative rewards by t-SNE [62] to
demonstrate that the cumulative rewards are intrinsic and stable

7

TABLE I: The Overview of Tasks. The “continuous” and
“discrete” illustrate the data type of the state and action with
the corresponding number of dimensions in parentheses.

Task Name

Lunar Lander
(Continuous)

State Shape

Action Shape

Continuous(6-dim)
Discrete(2-dim)

Continuous(2-dim)

Bipedal Walker

Continuous(24-dim)

Continuous(4-dim)

Ant

Continuous(111-dim)

Continuous(8-dim)

features for dataset auditing in Section V-C. After that, we
further evaluate the impact of three factors on ORL-AUDITOR,
i.e., the number of shadow models, the significance level in
hypothesis testing, and the trajectory size in Section V-D.
Finally, we utilize ORL-AUDITOR to audit the open-source
datasets from Google [18] and DeepMind [26] in Section V-E.

A. Experimental Setup

Tasks. We adopt Lunar Lander, Bipedal Walker, and Ant tasks
in Gym [7], which are widely used in the prior works [9],
[30], [48]. The tasks stem from distinct real-world problems,
each with numerical vectors containing different physical in-
formation, e.g., position, velocity, and acceleration. These tasks
involve both discrete and continuous variables in observation
and action spaces, with the dimension ranging from low (2-
dim) to high (111-dim). We give an overview in Table I and
put their details in Appendix B.

Dataset Generation and Offline Model Preparation. To
obtain the datasets for tasks in Table I, we adopt the same
idea as the existing dataset publishers [26], [18], [52], [1],
i.e., training the online RL models in the interactive envi-
ronment and recording the interactions as the datasets. The
datasets consist of numerical vectors. In Lunar Lander, each
transition includes state, next state (6-dimensional continuous
and 2-dimensional discrete variables), action (2-dimensional
continuous variables), and reward (scalar). Therefore, each
transition is a 19-dimensional numerical vector. Similarly, the
data types of Bipedal Walker and Ant are 53-dimensional and
231-dimensional numerical vectors, respectively. The number
of transitions for each task is 5 × 105 (Lunar Lander), 106
(Bipedal Walker), and 2 × 106 (Ant).

The offline RL models learn from the datasets. Table II
summarizes the whole process. For each task, we use five
global random seeds to train five online models separately.
We collect the datasets from five online models with random
seed 0, where every online model only generates one dataset.
For ease of reading, the datasets share the same name with
their online models. We train thirty offline DRL models for
every dataset with distinct global random seeds in initialization
and optimization processes. All the online and offline models
are implemented by open-source RL libraries [53], [56] with
default hyperparameter settings.

Critic Model. We adopt the fully connected neural network
as the critic model, which has four hidden layers with 1024
neurons on each layer. We optimize the critic model following
the TD-based method in Section IV-B by Adam optimizer with
a learning rate of 0.001 and a mini-batch size of 4096. The

TABLE II: The main steps in dataset generation and offline
model preparation with the details of the input and output.

For each combination of task and
offline RL model in the experiment
↓
Train with 5 random seeds: {0, 1, . . . , 4}
↓
5 online RL models detailed in Table XIV
↓
Collect with 1 random seed: {0}
↓
5x1 offline Datasets detailed in Table XV
↓
Train with 30 random seeds: {42, 43, . . . , 72}
↓
5x1x30 offline RL models detailed in
Table XVI, Table XVII, Table XVIII, and Table XIX

entire training takes 150 epochs, and the learning rate decays
to half every 50 epochs.

Evaluation Metrics. Recalling ORL-AUDITOR’s application
scenario in Figure 3, for a single suspect model, the audit
accuracy can well characterize the performance of ORL-
AUDITOR, i.e., the ratio of the number of correctly auditing
trajectory to the total auditing trajectory. In our experiment, the
positive models (trained on the target dataset) and the negative
models (trained on other datasets) are randomly mixed, where
the majority may dominate the accuracy. Thus, we provide the
true positive rate (TPR) and the true negative rate (TNR).

Methods. We provide the audit performance of 3σ principle
and Grubbs’ test with four distance metrics, i.e., ℓ1 norm, ℓ2
norm, Cosine distance, and Wasserstein distance.

Competitors. Recalling Section III-B, existing methods [47],
[24], [23] are designed for the online reinforcement learning
scenes, assuming that the auditor can continuously interact
with the environment to obtain new data as the non-member
example. Based on the behavioral difference of the model
between the member examples and the non-member examples,
they build the member inference method to detect whether
an example is used to train the suspect model. In the offline
scenarios, without access to the environment, the auditor only
has the pre-collected target dataset. Thus, we randomly divide
the target dataset into two parts and train offline RL models
on the subsets separately. Either subset is regarded as the set
of non-member examples for the offline RL models trained on
the other subset. We adopt the same data augmentation, attack
classifier architecture, and hyperparameter settings with [23].

Implementation. We use stable-baselines [53] and d3rlpy [56]
to implement online and offline DRL models separately. All
audit methods are realized with Python 3.8 on a server with 8
NVIDIA GeForce RTX 3090 and 512GB memory.

B. Overall Audit Performance

We assess the effectiveness of ORL-AUDITOR across
twelve combinations of three tasks and four models. Fur-
thermore, we present an evaluation of the efficacy of the
competitors on offline DRL models.

Setup. From Table II, we train 30 offline RL models for
each dataset and obtain 150 offline DRL models for every

8

TABLE III: The performance of existing membership inference
attack against offline DRL models.

Task
Name

Lunar
Lander

Bipedal
Walker

Ant

Offline
Model
BC
BCQ
IQL
TD3PlusBC
BC
BCQ
IQL
TD3PlusBC
BC
BCQ
IQL
TD3PlusBC

Accuracy

Training
50.09±0.68
49.84±1.39
49.88±0.76
50.08±0.92
50.00±0.63
49.97±0.69
50.17±0.95
49.87±0.94
50.44±0.64
50.22±0.52
50.33±0.35
50.13±0.67

Test
48.41±1.87
47.69±1.45
47.34±1.83
48.27±1.81
46.27±2.42
47.38±2.41
47.19±1.90
45.48±1.46
46.74±2.37
45.38±2.16
45.89±1.90
45.03±1.55

experimental setting. We audit the 5 datasets separately, where
the auditor randomly selects 15 models from the target dataset
as the shadow models, and the remaining 15 models along with
the 120 models from other datasets are the positive and the
negative suspect models. For the target dataset, we randomly
select fifty auditing trajectories to audit. Since the unbalanced
amount of the positive and the negative models, we report the
aggregated mean with a standard deviation of both TPR and
TNR for each setting in Table IV and provide the audit results
between every two datasets in Figure 11 (Lunar Lander),
Figure 12 (Bipedal Walker), and Figure 13 (Ant). Each pair
of TPR and TNR in Table IV is derived from the diagonal
and non-diagonal values of the corresponding heatmap. As a
supplementary of [13], we also show the audit result by 3σ
principle in Table VII. The competitors’ performance is shown
in Table III, where the values of mean and standard variation
are calculated by repeating experiment ten times.

Observations. We have the following observations from
Table IV, Table VII, and Table III. 1) Most TPR and TNR
values are higher than 95%, meaning that ORL-AUDITOR is
a valid solution to audit the learned dataset of the offline DRL
models. For instance, all results for ORL-AUDITOR with ℓ1
norm are beyond 94% across the experiment settings.

2) ORL-AUDITOR obtains different audit accuracy over
four distance metrics. The audit effectiveness with ℓ1 norm and
Wasserstein distance is better than that of ℓ2 norm and Cosine
distance. In Table IV and Table VII, ORL-AUDITOR with
Wasserstein distance always performs the best or the second
place. And results of ℓ2 norm are usually behind the other three
distance metrics. Recalling Section IV-C, Wasserstein distance
characterizes both the numerical and the positional deviations
of the cumulative rewards, which is more sensitive. Since
the numerical differences between the cumulative rewards are
slight, e.g., from 0.01 to 0.1 in our experiment, ℓ2 norm may
undercut these small but potential differences.

3) The accuracy of the audit as determined by Grubbs’ test
outperforms that of the 3σ principle. The 3σ principle is an
empirical method, which is easily misled by the outlier cumu-
lative rewards of the shadow models. Recalling Section IV-C,
Grubbs’ test first calculates the statistic G and compares G
with an adaptive threshold, where the number of samples is
also considered in the hypothesis testing.

4) Without the new data from the environment, the ef-
fectiveness of the existing membership inference methods is

attenuated. From one perspective, the similarity between sub-
datasets splited from the same dataset can result in the trained
RL models exhibiting undifferentiated behavior, making it
difficult to effectively distinguish between members and non-
members. On the other hand, when considering the results
presented in Figure 10, we conclude that the actions of RL
models should not be directly utilized as the foundation for
membership inference.

C. Visualization of Cumulative Rewards

To further explain the audit results in Section V-B, we
analyze the cumulative rewards from the shadow models and
j and Qs
the suspect models, i.e., Qi

j, by using t-SNE [62].

j (positive) or Qs

Setup. The caption of each plot in Figure 5 indicates the used
task and offline DRL model. Each point in the plots shows the
visualization of a single Qi
j (negative). In
a single plot, we demonstrate the results of three trajectories
from each tasks’ first datasets. For instance, the target dataset
of the plot titled “Lunar Lander, BC” is dataset “1171” in
Table XV. The thirty positive points for each trajectory are
collected from the shadow models trained on dataset “1171”,
while the thirty negative points are randomly sampled from
the shadow models from the other four datasets.

Observations. From Figure 5, we have the following obser-
vations. 1) For a trajectory of the target dataset, the cumulative
rewards from the shadow models and the suspect models are
clearly divided into different groups, meaning that the critic
model well reflects the differences in the models’ actions.
Thus, the cumulative reward generated by the critic model is
a qualified post-event fingerprint for trajectory-level auditing.

2) The distribution of points varies on the different trajec-
tories. For example, trajectory 1 from the Lunar Lander dataset
is harder to cluster than the other two trajectories. We speculate
that this is because trajectory 1 represents a basic policy, e.g., a
local optimum policy to fire the lander’s thrusters all the way,
and similar trajectories exist in the other four datasets. Due to
the non-uniqueness of the optimal strategy in RL problems and
the impact of randomness in the model training process, the
collected trajectories have unique characteristics. Thus, other
trajectories’ cumulative rewards are clearly divided.

D. Hyperparameter Study

impact

We extend our assessment to scrutinize three pivotal de-
terminants that
the pragmatic integration of ORL-
AUDITOR. Specifically, we consider the amount of shadow
models, the level of significance in hypothesis testing, and the
magnitude of the trajectory size. Due to space limitations, we
only give brief conclusions in this section. Please refer to the
specific analysis in Appendix C, Appendix D, and Appendix E.

Impact of Shadow Models’ Amount. We change the shadow
models’ amount to 9 and 21 with the other settings the same
as Section V-B. Figure 6 shows the value change of TPR and
TNR compared with that of 15 shadow models. Each figure’s
title illustrates the settings of the model and the task, the x-axis
indicates the four metrics, and the y-axis is the absolute value
change. As a supplementary of [13], we provide the detailed
results in Table VIII (9 Shadow Models) and Table IX (21
Shadow Models).

9

TABLE IV: The TPR and TNR results based on Grubbs’ test. The mean and standard deviation of TPR and TNR in each row
represent the audit results for one combination of task and model by four distance metrics. Bold indicates the highest sum of
TPR and TNR, i.e., accuracy, in a row. Each pair of TPR and TNR is derived from the diagonal and non-diagonal values of the
corresponding heatmap in Figure 11, Figure 12 and Figure 13, which are supplementary to [13].

Task
Name

Offline
Model

Lunar
Lander

Bipedal
Walker

Ant

BC
BCQ
IQL
TD3PlusBC
BC
BCQ
IQL
TD3PlusBC
BC
BCQ
IQL
TD3PlusBC

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TPR
99.01±0.46
98.29±1.14
98.61±1.51
98.29±2.04
99.20±1.47
99.52±0.77
95.10±7.41
99.36±1.28
97.42±1.66
97.17±2.96
97.20±2.33
98.53±1.80

TNR
100.00±0.00
100.00±0.00
99.91±0.32
99.48±0.79
100.00±0.00
100.00±0.00
100.00±0.00
94.77±19.42
99.94±0.11
99.80±0.43
99.66±0.73
99.18±1.72

TPR
96.96±0.73
96.03±1.15
97.52±2.51
96.35±3.01
98.40±2.70
98.16±2.89
95.04±5.45
97.15±5.71
96.48±1.66
95.68±2.54
96.61±2.50
97.17±1.79

TNR
100.00±0.00
100.00±0.00
99.97±0.12
99.89±0.22
100.00±0.00
100.00±0.00
100.00±0.00
93.36±21.46
99.90±0.36
99.84±0.43
99.69±0.59
99.35±1.74

TPR
96.93±0.77
95.97±1.07
97.49±2.56
96.27±3.16
98.56±2.68
99.87±0.15
99.84±0.32
96.96±5.82
99.20±1.08
99.66±0.43
99.57±0.79
99.72±0.40

TNR
100.00±0.00
99.99±0.04
99.92±0.19
99.91±0.23
100.00±0.00
100.00±0.00
100.00±0.00
91.98±21.75
85.66±28.23
86.70±26.89
86.25±27.90
87.79±26.43

TPR
98.40±0.74
97.57±1.17
98.32±1.79
98.53±1.25
99.31±1.32
99.89±0.13
95.01±6.72
98.08±3.84
98.00±1.19
98.67±1.65
99.36±0.42
99.25±1.24

TNR
99.94±0.16
99.91±0.14
97.10±5.66
95.59±3.77
100.00±0.00
100.00±0.00
100.00±0.00
88.26±25.34
99.92±0.14
99.79±0.46
99.63±0.78
99.14±1.81

From Figure 6, we have the following observations. 1)
The audit accuracy increases with a larger amount of shadow
models. 2) There exists a saturation point for audit accuracy
with the expansion of shadow models.

Impact of Significance Level. The significance level rep-
resents the auditor’s confidence in the auditing results. In
the significance level α = 0.01,
Section V-B, we adopt
meaning that the auditor has 99% confidence in the judg-
ments. Generally speaking, the significance level represents
the maximum audit capacity of ORL-AUDITOR instead of
a hyperparameter setting since it is an audit requirement by
the dataset owner. We demand the auditor to output a more
confident
judgment, where the error possibility should be
limited to 1‰ and 0.1‰, i.e., α = 0.001 and α = 0.0001.
Figure 7 shows the value change of TPR and TNR compared
with that when α = 0.01. As a supplementary of [13], the
detailed results between every two datasets are in Table X
(α = 0.001) and Table XI (α = 0.0001).

From Figure 7, we have the following observations. 1)
For a complicated task, we recommend the auditor select a
large significance level for ORL-AUDITOR. 2) For the suspect
models with low performance, ORL-AUDITOR should adopt
a large significance level to guarantee audit accuracy. 3) In
general, α = 0.01 is a safe bound of ORL-AUDITOR, and a
lower α may break through the capability boundary of ORL-
AUDITOR, inducing the auditor to misclassify the negative
model to the positive set.

Impact of Trajectory Size. We investigate the relationship
between the trajectory size and audit accuracy. In Section V-B,
we adopt the full-length trajectory, meaning that the auditor
utilizes all states of each trajectory to query the suspect model
and obtains the corresponding actions to conduct the dataset
auditing. We change the trajectory size to 25% and 50% of
the full length with the other settings the same as Section V-B.
Figure 8 shows the value change of TPR and TNR compared
with that of the full-length trajectory. As a supplementary
of [13], we also provide the detailed results in Table XII (25%)
and Table XIII (50%).

From Figure 8, we have the following observations. 1)
ORL-AUDITOR tends to achieve higher accuracy with a larger
trajectory size. 2) A small trajectory size achieves better results
under some tasks since the front states of each trajectory are
able to reflect more behavioral information of the model [46].

E. Real-world Application

In this section, we apply ORL-AUDITOR to audit the open-
source datasets from DeepMind [26] and Google [18]. We
choose the “halfcheetah” task published by both, where the
operator controls a 2-dimensional cheetah robot consisting of
9 links and 8 joints connecting them (including two paws) to
make the cheetah run forward (right) as fast as possible. The
details of the halfcheetah dataset and the offline DRL models
are in Table XX and Table XXI. All experimental settings are
consistent with these in Section V-B.

Observations.
From Table XXII, we have the following
observations. 1) ORL-AUDITOR can be effective in real-world
applications. The TPR and TNR of ORL-AUDITOR exceed
95% with ℓ1 norm and Wasserstein distance, meaning that
ORL-AUDITOR remains valid for the existing open-source
datasets. 2) Wasserstein distance has stable performance on the
experimental and the real-world datasets. The overall accuracy
of ORL-AUDITOR with Wasserstein distance are all higher
than the other three metrics.

VI. ROBUSTNESS

A. Ensemble Architecture

To hinder the audit of a dataset, an adversary may uti-
lize state-of-the-art membership inference defense strategies
proposed in recent research works [60], [31]. These defense
strategies aim to mitigate the influence of a member example
on the behavior of a machine learning model. Based on the
idea of model ensemble, in particular, [60], [31], [11] proposed
to split the training set into several subsets and train sub-
models on each of these subsets. Then, when an auditor uses
an example from the target dataset to query a suspect model,

10

Fig. 5: Visualization of cumulative rewards by t-SNE. The caption of each plot demonstrates the offline DRL model’s type and
task. In a single plot, we randomly select three trajectories from the first dataset for the task, i.e., Lunar Lander dataset 1171,
Bipedal Walker dataset 0841, and Ant dataset 2232 in Table XV, and then show the cumulative rewards from 30 positive models
and 30 negative models for each trajectory.

Fig. 6: Impact of shadow models’ amount. The change value of TPR and TNR when the number of shadow models varies to
9 and 21 compared to the default 15 shadow models. The caption of each plot demonstrates the offline DRL model’s type and
task. The x labels display the four distance metrics. The y labels show the absolute fluctuating values of TPR and TNR.

the adversary aggregates the outputs of the sub-models that
have not been trained on this example.

Setup. The number of divided subsets, denoted by K, repre-
sents a crucial hyperparameter for ensemble-based methods, as
discussed in [60], [31]. Considering the analysis conducted in
these studies, as well as the size of the offline RL datasets, we
have established K = 5 for the present investigation. All other
experimental settings remain unchanged from those described
in Section V-B, and the corresponding audit outcomes are
presented in Table V. As a supplementary of [13], the results
between every two datasets are in Figure 14 (Lunar Lander),
Figure 15 (Bipedal Walker), Figure 16 (Ant), and Figure 17

(Half Cheetah).

Observations. We conclude the following observations based
on the above results. 1) Even when faced with ensemble
architecture, ORL-AUDITOR maintains a high level of audit
accuracy. As shown in Table V, both TPR and TNR con-
sistently exceed 80%. As described in Section IV-A, ORL-
AUDITOR uses predicted cumulative rewards from the critic
model as the basis for auditing. During training, the critic
model captures the overall features of the dataset distribution,
instead of memorizing features from individual samples. Since
the ensemble model is trained on the target dataset, its behavior
embeds the distribution characteristics of the dataset, which

11

Lunar Lander, BC

Lunar Lander, BCQ

Lunar Lander, IQL

Lunar Lander, TD3PlusBC

Trajectory
0
1
2
Audit Result
Positive
Negative

Trajectory
0
1
2
Audit Result
Positive
Negative

Trajectory
0
1
2
Audit Result
Positive
Negative

Trajectory
0
1
2
Audit Result
Positive
Negative

Bipedal Walker, BC

Bipedal Walker, BCQ

Bipedal Walker, IQL

Bipedal Walker, TD3PlusBC

Trajectory
0
1
2
Audit Result
Positive
Negative

Trajectory
0
1
2
Audit Result
Positive
Negative

Trajectory
0
1
2
Audit Result
Positive
Negative

Trajectory
0
1
2
Audit Result
Positive
Negative

Ant, BC

Ant, BCQ

Ant, IQL

Ant, TD3PlusBC

Trajectory
0
1
2
Audit Result
Positive
Negative

Trajectory
0
1
2
Audit Result
Positive
Negative

Trajectory
0
1
2
Audit Result
Positive
Negative

Trajectory
0
1
2
Audit Result
Positive
Negative

Lunar Lander, BC

Bipedal Walker, BC

Ant, BC

5.0

0

-5.0

-10.0

l

e
u
a
V
∆

5.0

0

-5.0

-10.0

l

e
u
a
V
∆

5.0

0

-5.0

-10.0

l

e
u
a
V
∆

Lunar Lander, BCQ

Bipedal Walker, BCQ

Ant, BCQ

5.0

0

-5.0

-10.0

5.0

0

-5.0

-10.0

5.0

0

-5.0

-10.0

5.0

0

-5.0

-10.0

5.0

0

-5.0

-10.0

5.0

0

-5.0

-10.0

Lunar Lander, IQL

Bipedal Walker, IQL

Ant, IQL

Lunar Lander, TD3PlusBC

Bipedal Walker, TD3PlusBC

Ant, TD3PlusBC

5.0

0

-5.0

-10.0

5.0

0

-5.0

-10.0

5.0

0

-5.0

-10.0

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

C

C

W

W

C

C

W

W

C

C

W

W

C

C

W

W

Distance Metric

Distance Metric

Distance Metric

Distance Metric

9 Shadow Models 

21 Shadow Models 

Fig. 7: Impact of the significance level. The change value of TPR and TNR when the significance level varies to 0.001 and
0.0001 compared to the default 0.01. The caption of each plot demonstrates the offline DRL model’s type and task. The x labels
display the four distance metrics. The y labels show the absolute fluctuating values of TPR and TNR.

Fig. 8: Impact of the trajectory size. The change value of TPR and TNR when the trajectory size varies to 25% and 50%
compared to the entire trajectories (100%). The caption of each plot demonstrates the offline DRL model’s type and task. The
x labels display the four distance metrics. The y labels show the absolute fluctuating values of TPR and TNR.

Fig. 9: Robustness against action distortion. The change value of TPR and TNR when the suspect model adds Gaussian noise
parameterized with (µ = 0, σ = 0.01) and (µ = 0, σ = 0.1) to its output. The caption of each plot demonstrates the offline DRL
model’s type and task. The x labels display the four distance metrics. The y labels show the absolute fluctuating values.

ORL-AUDITOR can detect.

2) The use of ensemble architecture may result in a de-
crease in model performance for certain tasks. Our experimen-
tal results, as shown in column “Model Performance (Model
Ensemble)” of Tables Table XVI, Table XVII, Table XVIII,
and Table XIX, demonstrate a decline in the performance of
offline RL models when utilizing ensemble architecture. For

instance, when BCQ models learn from the Ant dataset “3569”,
the mean values of cumulative reward decrease significantly.
Furthermore, due to the sub-models being trained on subsets of
data, they only fit a partial dataset’s distribution. Consequently,
when applying the model ensemble to practical scenarios, the
standard deviations of the model’s performance are large.

12

Lunar Lander, BC

Bipedal Walker, BC

Ant, BC

l

e
u
a
V
∆

l

e
u
a
V
∆

l

e
u
a
V
∆

5.0
0.0
-5.0
-10.0
-15.0
-20.0

5.0
0.0
-5.0
-10.0
-15.0
-20.0

5.0
0.0
-5.0
-10.0
-15.0
-20.0

Lunar Lander, BCQ

Bipedal Walker, BCQ

Ant, BCQ

5.0
0.0
-5.0
-10.0
-15.0
-20.0

5.0
0.0
-5.0
-10.0
-15.0
-20.0

5.0
0.0
-5.0
-10.0
-15.0
-20.0

5.0
0.0
-5.0
-10.0
-15.0
-20.0

5.0
0.0
-5.0
-10.0
-15.0
-20.0

5.0
0.0
-5.0
-10.0
-15.0
-20.0

Lunar Lander, IQL

Bipedal Walker, IQL

Ant, IQL

Lunar Lander, TD3PlusBC

Bipedal Walker, TD3PlusBC

Ant, TD3PlusBC

5.0
0.0
-5.0
-10.0
-15.0
-20.0

5.0
0.0
-5.0
-10.0
-15.0
-20.0

5.0
0.0
-5.0
-10.0
-15.0
-20.0

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

C

C

W

W

C

C

W

W

C

C

W

W

C

C

W

W

Distance Metric

Distance Metric

Distance Metric

Distance Metric

0.001

0.0001

Lunar Lander, BC

Lunar Lander, BCQ

Lunar Lander,

IQL

Lunar Lander, TD3PlusBC

l

e
u
a
V
∆

10.0
5.0
0.0
-5.0
-10.0

l

e
u
a
V
∆

10.0
5.0
0.0
-5.0
-10.0

l

e
u
a
V
∆

10.0
5.0
0.0
-5.0
-10.0

Bipedal Walker, BC

Ant, BC

10.0
5.0
0.0
-5.0
-10.0

10.0
5.0
0.0
-5.0
-10.0

10.0
5.0
0.0
-5.0
-10.0

Bipedal Walker, BCQ

Ant, BCQ

10.0
5.0
0.0
-5.0
-10.0

10.0
5.0
0.0
-5.0
-10.0

10.0
5.0
0.0
-5.0
-10.0

Bipedal Walker,

IQL

Ant,

IQL

10.0
5.0
0.0
-5.0
-10.0

10.0
5.0
0.0
-5.0
-10.0

10.0
5.0
0.0
-5.0
-10.0

Bipedal Walker, TD3PlusBC

Ant, TD3PlusBC

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

s

s
.

a

s

s
.

P

N

T

T

R

R

P

N

R

R

C

C

W

W

C

C

W

W

C

C

W

W

C

C

W

W

Distance Metric

Distance Metric

Distance Metric

Distance Metric

25% of full trajectory

50% of full trajectory

Lunar Lander, BC

Lunar Lander, BCQ

Lunar Lander, IQL

Lunar Lander, TD3PlusBC

l

e
u
a
V
∆

0
-20.0
-40.0
-60.0
-80.0

l

e
u
a
V
∆

0
-20.0
-40.0
-60.0
-80.0

l

e
u
a
V
∆

0
-20.0
-40.0
-60.0
-80.0

Bipedal Walker, BC

Ant, BC

0
-20.0
-40.0
-60.0
-80.0

0
-20.0
-40.0
-60.0
-80.0

0
-20.0
-40.0
-60.0
-80.0

Bipedal Walker, BCQ

Ant, BCQ

0
-20.0
-40.0
-60.0
-80.0

0
-20.0
-40.0
-60.0
-80.0

0
-20.0
-40.0
-60.0
-80.0

Bipedal Walker, IQL

Ant, IQL

0
-20.0
-40.0
-60.0
-80.0

0
-20.0
-40.0
-60.0
-80.0

0
-20.0
-40.0
-60.0
-80.0

Bipedal Walker, TD3PlusBC

Ant, TD3PlusBC

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

a

s

s
.

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

a

s

s
.

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

a

s

s
.

s

s
.

P

N

T

T

R

R

P

N

R

R

L

1

L

1

L

2

L

2

T

T

T

T

P

N

P

N

R

R

R

R

o

s
.

o

s
.

T

T

a

a

s

s
.

s

s
.

P

N

T

T

R

R

P

N

R

R

C

C

W

W

C

C

W

W

C

C

W

W

C

C

W

W

Distance Metric

Distance Metric

Distance Metric

Distance Metric

sigma=0.01

sigma=0.1

TABLE V: The TPR and TNR results of ORL-AUDITOR against model ensemble (K = 5). The mean and standard deviation
of TPR and TNR in each row represent the audit results for one combination of task and model by four distance metrics. Each
pair of TPR and TNR is derived from the diagonal and non-diagonal values of the corresponding heatmap in Figure 14 (Lunar
Lander), Figure 15 (Bipedal Walker), Figure 16 (Ant), and Figure 17 (Half Cheetah), which are supplementary to [13].

Task
Name

Lunar
Lander

Bipedal
Walker

Ant

Half
Cheetah

Offline
Model

BC
BCQ
IQL

BC
BCQ
IQL

TPR
100.00±0.00
99.60±0.80
100.00±0.00
TD3PlusBC 100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00
TD3PlusBC 100.00±0.00
99.60±0.80
100.00±0.00
100.00±0.00
TD3PlusBC 99.60±0.80
85.00±25.98
91.00±15.59
90.00±12.81
TD3PlusBC 61.50±20.32

BC
BCQ
IQL

BC
BCQ
IQL

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TNR
100.00±0.00
100.00±0.00
99.90±0.44
99.30±0.95
100.00±0.00
100.00±0.00
100.00±0.00
94.90±19.07
100.00±0.00
99.70±0.71
99.80±0.60
99.30±1.82
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00

TPR
99.20±0.98
98.00±2.19
99.20±0.98
99.60±0.80
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00
99.60±0.80
99.60±0.80
99.20±0.98
100.00±0.00
84.50±25.71
89.00±16.76
86.50±16.70
77.00±19.42

TNR
100.00±0.00
100.00±0.00
100.00±0.00
99.90±0.44
100.00±0.00
100.00±0.00
100.00±0.00
93.80±21.63
99.90±0.44
99.80±0.60
99.70±0.71
99.40±2.20
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00

TPR
99.20±0.98
98.00±2.19
99.60±0.80
99.60±0.80
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00
99.60±0.80
100.00±0.00
99.20±0.98
100.00±0.00
94.00±10.39
95.00±8.66
94.50±9.53
95.00±8.66

TNR
100.00±0.00
100.00±0.00
99.90±0.44
99.80±0.60
100.00±0.00
100.00±0.00
100.00±0.00
92.70±21.62
83.20±31.99
85.70±28.31
86.80±28.32
87.80±25.87
67.50±43.20
67.17±42.30
71.00±41.37
65.67±41.28

TPR
99.60±0.80
99.60±0.80
99.60±0.80
99.60±0.80
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00
99.20±1.60
100.00±0.00
100.00±0.00
99.60±0.80
87.00±21.38
93.00±12.12
91.50±12.52
52.00±33.26

TNR
99.90±0.44
100.00±0.00
97.60±4.27
95.80±3.57
100.00±0.00
100.00±0.00
100.00±0.00
89.20±23.94
100.00±0.00
99.70±0.71
99.80±0.60
98.50±3.79
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00

B. Action Distortion

The suspect models may perturb the actions, i.e., changing
the original models’ outputs, to conceal its training dataset in
practice. The action distortion mechanism should be stealthy
and cannot be detected by the auditor easily. Considering that
the DRL models are usually applied to real-world decision-
making tasks, such as self-driving cars and industry automa-
the natural distortion is often modeled as
tion [44], [28],
Gaussian noise. For example, thermal noise, which is caused
by the random motion of electrons in a conductor, can be
modeled as a Gaussian noise with a constant power spec-
trum [2]. In addition, Gaussian noise is easy to manipulate
mathematically. For ease of evaluating the effects of different
distortion intensities, all dimensions of the models’ action
space are normalized into [−1, 1]. Then, we utilize Gaussian
noise with mean (µ = 0) and standard deviation (σ = 0.1)
and (σ = 0.01) to represent the two levels of distortion.

Setup. Figure 9 depicts the impact of “with” or “without”
the action distortion. The information about the used offline
DRL model and task is shown in each figure’s title. The x-
axis indicates the four metrics, and the y-axis is the absolute
value change. As a supplementary of [13], the detailed results
between every two datasets are in Figure 18, Figure 19 (Lunar
Lander), Figure 20, Figure 21 (Bipedal Walker), Figure 22,
and Figure 23 (Ant).

Observations. We conclude the following observations based
on the above results. 1) ORL-AUDITOR is able to resist the
potential action distortion from the suspect model, especially
with the Cosine metric. From Figure 9, the TPR and TNR
vary slightly across most of the settings with weak noise,
where the maximum accuracy attenuation is within 3% for
Cosine distance. We speculate that Cosine distance has a
noise suppression ability when calculating the inner product of

two series of cumulative rewards. Also, the weak noise may
facilitate the dataset auditing since it will move the negative
samples farther away from the positive set.

2) ORL-AUDITOR with a single distance metric faces
limitations for heavy distortion. The TPR of ORL-AUDITOR
suffers an obvious decline with strong noise. Since the strong
distortion thoroughly changes the distribution of the models’
actions, the cumulative rewards of the suspect model trained
on the target dataset are different from those of the auditor’s
shadow models. In this case, the auditor cannot identify the
positive models from the negative just by a single kind of
distance metric. From Figure 23, Cosine distance is good at
discriminating the positive models (results in the diagonal),
and Wasserstein distance is proper for the negative models
(results in the non-diagonal). Thus, for strong distortion, the
combination of multiple distance metrics can enhance the
auditing robustness of ORL-AUDITOR. In addition, we should
note that the models’ normal behavior is also destroyed by
the strong distortion. For example, in Table XVIII, the noise
induces the model performance of IQL to decrease up to 25%,
and the better the model’s quality, the more pronounced the
performance drop.

VII. RELATED WORK

Membership and Dataset Inferences. To infer whether an
individual data record was used to train the target model,
Shokri et al. [57] proposed the first practical membership
inference strategy by training a number of shadow classifiers to
distinguish the target model’s outputs on members versus non-
members of its training dataset. Since then, researchers have
investigated membership inference in various systems, such as
machine unlearning [10], facial recognition systems [12], and
neural architecture search [29]. Liu et al. [41] presenting a
first-of-its-kind holistic risk assessment of different inference

13

attacks against machine learning models. Maini et al. [43]
introduced the definition of dataset inference and designed the
first mechanism to identify whether a suspect model copy has
private knowledge from the dataset.

Compared with the existing works, ORL-AUDITOR is a
well-designed solution built for the offline DRL scenes, which
overcomes several new challenges. First, ORL-AUDITOR is
a post-event mechanism that can be directly applied to the
existing open-source datasets. Second, ORL-AUDITOR does
not use any auxiliary datasets.

Knowledge Extraction Against DRL. The DRL models
learn from the interaction with the environment, which can
be valuable information in some cases, e.g.,
indoor robot
navigation. Pan et al. [47] demonstrated such knowledge
extraction vulnerabilities in DRL under various settings and
proposed algorithms to infer floor plans from some trained
Grid World navigation DRL models with LiDAR perception.
For exacting the model functionality, Chen et al. [9] proposed
the first method to acquire the approximation model from the
victim DRL. They built a classifier to reveal the targeted black-
box DRL model’s training algorithm family based only on its
predicted actions and then leveraged state-of-the-art imitation
learning techniques to replicate the model from the identi-
fied algorithm family. Ono et al. [45] integrated differential
privacy [72], [69], [63] into the distributed RL algorithm to
defend the extraction. The local models report noisy gradients
designed to satisfy local differential privacy [14], [15], [65],
[71], i.e., keeping the local information from being exploited
by adversarial reverse engineering. Chen et al. [8] proposed a
novel testing framework for deep learning copyright protection,
which can be adjusted to detect
the knowledge extraction
against DRL.

VIII. DISSCUSION

Highlights of ORL-AUDITOR. 1) ORL-AUDITOR is the first
approach to conduct trajectory-level dataset auditing for offline
DRL models. 2) By conducting a comprehensive analysis of
ORL-AUDITOR under different experimental settings, such
as the shadow model’s amount, the significance level in hy-
pothesis testing, the trajectory size, and the robustness against
ensemble architecture and action distortion, we conclude some
useful observations for adopting ORL-AUDITOR. 3) We apply
ORL-AUDITOR to audit the models trained on the open-source
datasets from Google and DeepMind. All TPR and TNR results
are superior than 95%, demonstrating ORL-AUDITOR is an
effective and efficient strategy for the published datasets.

Limitations and Future Work. Below, we discuss the
limitations of ORL-AUDITOR and promising directions for
further improvements. 1) From Appendix D, the accuracy of
ORL-AUDITOR decreases when the significance level downs
to 0.001. Thus, it is interesting to enhance ORL-AUDITOR
to satisfy stricter auditing demands in the future. 2) ORL-
AUDITOR based on a single distance metric may not be suffi-
ciently robust to strong distortion. Based on the observations
in Section VI-B, integrating more distance metrics in the audit
process may be a further promising direction.

IX. CONCLUSION

In this work, we propose a novel trajectory-level dataset
auditing method for offline DRL models relying on the insight
that cumulative rewards can serve as the dataset’s intrinsic
fingerprint and exist in all models trained on the target dataset.
Both the true positive rate and the true negative rate of
ORL-AUDITOR exceed 90% on four offline DRL models and
three task combinations. We show that ORL-AUDITOR is an
effective and efficient solution to protect the IP of the dataset
owners through multiple experiments. By studying parameter
settings about the number of shadow models, the significance
level in hypothesis testing, and the trajectory size, we conclude
several important observations for adopting ORL-AUDITOR in
practice. The robustness evaluation demonstrates that ORL-
AUDITOR can resist
the defenses of the model ensemble
and the action distortion of the suspect model. Integrating
multiple distance metrics to improve the robustness of ORL-
AUDITOR against action distortion is a promising direction for
future work. Finally, we utilize the open-source datasets from
Google [18] and DeepMind [26] to examine the practicality
of ORL-AUDITOR, and show that ORL-AUDITOR behaves
excellently on existing published datasets.

ACKNOWLEDGMENT

We would like to thank the anonymous reviewers for
their constructive comments. We also thank Yanchao Sun for
sharing her expertise in reinforcement learning. This work was
partly supported by the National Key Research and Develop-
ment Program of China under No. 2022YFB3102100, NSFC
under Grants 62088101, 61833015, 62103371, U20A20159,
and the Fundamental Research Funds for the Central Univer-
sities 226-2022-00107, 226-2023-00111. Min Chen was partly
sponsored by the Helmholtz Association within the project
“Trustworthy Federated Data Analytics” (TFDA) (No. ZT-I-
OO1 4). Zhikun Zhang was supported by the CISPA-Stanford
Center for Cybersecurity (FKZ:13N1S0762).

REFERENCES

[1] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S.
Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow,
A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur,
J. Levenberg, D. Man´e, R. Monga, S. Moore, D. Murray, C. Olah,
M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker,
V. Vanhoucke, V. Vasudevan, F. Vi´egas, O. Vinyals, P. Warden, M. Wat-
tenberg, M. Wicke, Y. Yu, and X. Zheng. TensorFlow: Large-Scale Ma-
chine Learning on Heterogeneous Systems. https://www.tensorflow.org/,
2015.

[2] N. AlHinai. Introduction to Biomedical Signal Processing and Artificial
Intelligence. In Biomedical Signal Processing and Artificial Intelligence
in Healthcare, Developments in Biomedical Engineering and Bioelec-
tronics, pages 1–28. Elsevier, 2020.

[3] S. Amarjyoti. Deep Reinforcement Learning for Robotic Manipulation

- The State of the Art. CoRR abs/1701.08878, 2017.

[4] C. Beattie, J. Z. Leibo, D. Teplyashin, T. Ward, M. Wainwright,
H. K¨uttler, A. Lefrancq, S. Green, V. Vald´es, A. Sadik, J. Schrittwieser,
K. Anderson, S. York, M. Cant, A. Cain, A. Bolton, S. Gaffney,
H. King, D. Hassabis, S. Legg, and S. Petersen. DeepMind Lab. CoRR,
abs/1612.03801, 2016.

[5] Biscom.

Employee Departure Creates Gaping Security Hole.
https://www.biscom.com/employee-departure-creates-gaping-security-
hole-says-new-data, 2021.

[6] F. Boenisch. A Systematic Review on Model Watermarking for Neural

Networks. Frontiers Big Data, 4:729663, 2021.

14

[7] G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman,
J. Tang, and W. Zaremba. OpenAI Gym. CoRR, abs/1606.01540, 2016.
J. Chen, J. Wang, T. Peng, Y. Sun, P. Cheng, S. Ji, X. Ma, B. Li, and
D. Song. Copy, Right? a Testing Framework for Copyright Protection
of Deep Learning Models. In IEEE S&P, pages 824–841, 2022.

[8]

Stealing Deep
[9] K. Chen, S. Guo, T. Zhang, X. Xie, and Y. Liu.
In ACM Asia
Reinforcement Learning Models for Fun and Profit.
Conference on Computer and Communications Security (ASIACCS),
pages 307–319, 2021.

[30]

[31]

I. Ilahi, M. Usama, J. Qadir, M. U. Janjua, A. I. Al-Fuqaha, D. T.
Hoang, and D. Niyato. Challenges and Countermeasures for Adversarial
Attacks on Deep Reinforcement Learning. CoRR abs/2001.09684, 2020.
I. Jarin and B. Eshete. MIAShield: Defending Membership Inference
Attacks via Preemptive Exclusion of Members. In Privacy Enhancing
Technologies Symposium, pages 400–416, 2023.

[32] R. Kidambi, A. Rajeswaran, P. Netrapalli, and T. Joachims. MOReL:
Model-Based Offline Reinforcement Learning. In NeurIPS, 2020.
[33] D. P. Kingma and M. Welling. Auto-Encoding Variational Bayes. In

[10] M. Chen, Z. Zhang, T. Wang, M. Backes, M. Humbert, and Y. Zhang.

ICLR, 2014.

When Machine Unlearning Jeopardize Privacy. In ACM CCS, 2021.

[11] M. Chen, Z. Zhang, T. Wang, M. Backes, M. Humbert, and Y. Zhang.

Graph Unlearning. In ACM CCS, 2022.

[12] M. Chen, Z. Zhang, T. Wang, M. Backes, and Y. Zhang. FACE-
AUDITOR: Data Auditing in Facial Recognition Systems. In USENIX
Security, 2023.

[13] L. Du, M. Chen, M. Sun, S. Ji, P. Cheng, J. Chen, and Z. Zhang. ORL-
Auditor: Dataset Auditing in Offline Deep Reinforcement Learning. In
Network and Distributed System Security Symposium (NDSS). Internet
Society, 2024.

[14] L. Du, Z. Zhang, S. Bai, C. Liu, S. Ji, P. Cheng, and J. Chen. AHEAD:
Adaptive Hierarchical Decomposition for Range Query under Local
Differential Privacy. In ACM CCS, 2021.

[15] Y. Du, Y. Hu, Z. Zhang, Z. Fang, L. Chen, B. Zheng, and Y. Gao.
LDPTrace: Locally Differentially Private Trajectory Synthesis.
In
VLDB, 2023.

[16] A. Dziedzic, H. Duan, M. A. Kaleem, N. Dhawan, J. Guan, Y. Cattan,
F. Boenisch, and N. Papernot. Dataset Inference for Self-Supervised
Models. CoRR, abs/2209.09024, 2022.

[17] A. R. Fayjie, S. Hossain, D. Oualid, and D. Lee. Driverless Car:
Autonomous Driving Using Deep Reinforcement Learning in Urban
Environment. In International Conference on Ubiquitous Robots (UR),
pages 896–901, 2018.

[18]

J. Fu, A. Kumar, O. Nachum, G. Tucker, and S. Levine. D4RL: Datasets
for Deep Data-Driven Reinforcement Learning. CoRR, abs/2004.07219,
2020.

[19] S. Fujimoto, E. Conti, M. Ghavamzadeh, and J. Pineau. Bench-
marking Batch Deep Reinforcement Learning Algorithms. CoRR,
abs/1910.01708, 2019.

[20] S. Fujimoto and S. S. Gu. A Minimalist Approach to Offline Rein-

forcement Learning. In NeurIPS, pages 20132–20145, 2021.

[21] S. Fujimoto, D. Meger, and D. Precup. Off-Policy Deep Reinforcement
Learning without Exploration. In ICML, pages 2052–2062, 2019.
[22] S. Fujimoto, H. van Hoof, and D. Meger. Addressing Function
Approximation Error in Actor-Critic Methods. In ICML, pages 1582–
1591, 2018.

[23] M. Gomrokchi, S. Amin, H. Aboutalebi, A. Wong, and D. Precup.
Where Did You Learn That From? Surprising Effectiveness of Mem-
bership Inference Attacks Against Temporally Correlated Data in Deep
Reinforcement Learning. CoRR, abs/2109.03975, 2021.

[24] M. Gomrokchi, S. Main, S. Amin, and D. Precup. PrivAttack: A
Membership Inference Attack Framework Against Deep Reinforcement
Learning Agents. In NeurlPS Workshop, 2020.

[25] F. E. Grubbs. Sample Criteria for Testing Outlying Observations. The

Annals of Mathematical Statistics, pages 27–58, 1950.

[26] C¸ . G¨ulc¸ehre, Z. Wang, A. Novikov, T. Paine, S. G. Colmenarejo,
K. Zolna, R. Agarwal, J. Merel, D. J. Mankowitz, C. Paduraru,
G. Dulac-Arnold, J. Li, M. Norouzi, M. Hoffman, N. Heess, and
N. de Freitas. RL Unplugged: A Collection of Benchmarks for Offline
Reinforcement Learning. In NeurIPS 2020, 2020.

[27] N. G¨urtler, S. Blaes, P. Kolev, F. Widmaier, M. Wuthrich, S. Bauer,
B. Sch¨olkopf, and G. Martius. Benchmarking Offline Reinforcement
Learning on Real-Robot Hardware. In ICLR, 2023.

[28] S. He, K. Shi, C. Liu, B. Guo, J. Chen, and Z. Shi. Collaborative Sensing
in Internet of Things: A Comprehensive Survey. IEEE Communications
Surveys & Tutorials, 2022.

[29] H. Huang, Z. Zhang, Y. Shen, M. Backes, Q. Li, and Y. Zhang. On the
Privacy Risks of Cell-Based NAS Architectures. In ACM CCS, 2022.

[34] P. Kiourti, K. Wardega, J. Susmit, and W. Li. TrojDRL: Evaluation of

[35]

Backdoor Attacks on Deep Reinforcement Learning. In DAC, 2020.
I. Kostrikov, A. Nair, and S. Levine. Offline Reinforcement Learning
with Implicit Q-Learning. In ICLR, 2022.

[36] S. Lange, T. Gabel, and M. A. Riedmiller. Batch Reinforcement
In Reinforcement Learning, volume 12 of Adaptation,

Learning.
Learning, and Optimization, pages 45–73. Springer, 2012.

[37] S. Levine, A. Kumar, G. Tucker, and J. Fu. Offline Reinforcement
Learning: Tutorial, Review, and Perspectives on Open Problems. CoRR,
abs/2005.01643, 2020.

[38] Y. Li, Y. Bai, Y. Jiang, Y. Yang, S. Xia, and B. Li. Untargeted Backdoor
Watermark: Towards Harmless and Stealthy Dataset Copyright Protec-
tion. CoRR, abs/2210.00875, 2022.

[39] Y. Li, Z. Zhang, J. Bai, B. Wu, Y. Jiang, and S. Xia. Open-sourced
Dataset Protection via Backdoor Watermarking. CoRR, abs/2010.05821,
2020.

[40] Z. Lin, J. Gehring, V. Khalidov, and G. Synnaeve. STARDATA: A
StarCraft AI Research Dataset. CoRR, abs/1708.02139, 2017.
[41] Y. Liu, R. Wen, X. He, A. Salem, Z. Zhang, M. Backes, E. D. Cristofaro,
M. Fritz, and Y. Zhang. ML-Doctor: Holistic Risk Assessment of
In USENIX
Inference Attacks Against Machine Learning Models.
Security, 2022.

[42] M. Lopez-Martin, B. Carro, and A. Sanchez-Esguevillas. Application
of Deep Reinforcement Learning to Intrusion Detection for Supervised
Problems. Expert Systems with Applications, 141:112963, 2020.
[43] P. Maini, M. Yaghini, and N. Papernot. Dataset inference: Ownership

resolution in machine learning. In ICLR, 2021.

[44] D. Mwiti. 10 Real-Life Applications of Reinforcement Learning. https:

//neptune.ai/blog/reinforcement-learning-applications, 2021.

[45] H. Ono and T. Takahashi. Locally Private Distributed Reinforcement

Learning. CoRR abs/2001.11718, 2020.

[46] T. L. Paine, C. Paduraru, A. Michi, C¸ . G¨ulc¸ehre, K. Zolna, A. Novikov,
Z. Wang, and N. de Freitas. Hyperparameter Selection for Offline
Reinforcement Learning. CoRR, abs/2007.09055, 2020.

[47] X. Pan, W. Wang, X. Zhang, B. Li, J. Yi, and D. Song. How You Act
Tells a Lot: Privacy-Leaking Attack on Deep Reinforcement Learning.
In AAMAS, pages 368–376, 2019.

[48] A. Pattanaik, Z. Tang, S. Liu, G. Bommannan, and G. Chowdhary.
Robust Deep Reinforcement Learning with Adversarial Attacks.
In
AAMAS, pages 2040–2042, 2018.

[49] D. Pomerleau. ALVINN: An Autonomous Land Vehicle in a Neural

Network. In NeurIPS, pages 305–313, 1988.

[50] R. F. Prudencio, M. R. O. A. M´aximo, and E. L. Colombini. A
Survey on Offline Reinforcement Learning: Taxonomy, Review, and
Open Problems. CoRR, abs/2203.01387, 2022.

[51] H. Pu, L. He, P. Cheng, M. Sun, and J. Chen. Security of Industrial
Robots: Vulnerabilities, Attacks, and Mitigations. IEEE Network, 2022.
[52] R. Qin, S. Gao, X. Zhang, Z. Xu, S. Huang, Z. Li, W. Zhang, and Y. Yu.
NeoRL: A Near Real-World Benchmark for Offline Reinforcement
Learning. CoRR, abs/2102.00714, 2021.

[53] A. Raffin, A. Hill, A. Gleave, A. Kanervisto, M. Ernestus, and
Stable-Baselines3: Reliable Reinforcement Learning
N. Dormann.
Implementations. Journal of Machine Learning Research, 22(268):1–8,
2021.

[54] Y. Rubner, C. Tomasi, and L. J. Guibas. A Metric for Distributions

with Applications to Image Databases. In ICCV, pages 59–66, 1998.

[55] T. Rupprecht and Y. Wang. A Survey for Deep Reinforcement

15

Learning in Markovian Cyber-physical Systems: Common Problems
and Solutions. Neural Networks, 153:13–36, 2022.

[56] T. Seno and M. Imai. d3rlpy: An Offline Deep Reinforcement Learning
Library. Journal of Machine Learning Research, 23(315):1–20, 2022.
[57] R. Shokri, M. Stronati, C. Song, and V. Shmatikov. Membership
Inference Attacks Against Machine Learning Models. In IEEE S&P,
pages 3–18, 2017.

[58] D. Silver, G. Lever, N. Heess, T. Degris, D. Wierstra, and M. A.
Riedmiller. Deterministic Policy Gradient Algorithms. In ICML, pages
387–395, 2014.

[59] M. A. Stephens. EDF Statistics for Goodness of Fit and Some Compar-
isons. Journal of the American statistical Association, 69(347):730–737,
1974.

[60] X. Tang, S. Mahloujifar, L. Song, V. Shejwalkar, M. Nasr,
A. Houmansadr, and P. Mittal. Mitigating Membership Inference
Attacks by Self-Distillation Through a Novel Ensemble Architecture.
In USENIX Security, pages 1433–1450, 2022.

[61] Tessian. How the Great Resignation is Creating More Security Chal-
lenges. https://www.tessian.com/blog/how-the-great-resignation-is-crea
ting-more-security-challenges/, 2021.

[62] L. Van der Maaten and G. Hinton. Visualizing Data Using t-SNE.

Journal of machine learning research, 9(11), 2008.

[63] H. Wang, Z. Zhang, T. Wang, S. He, M. Backes, J. Chen, and
Y. Zhang. PrivTrace: Differentially Private Trajectory Synthesis by
Adaptive Markov Model. In USENIX Security, 2023.

[64] L. Wang, Z. Javed, X. Wu, W. Guo, X. Xing, and D. Song. BACK-
DOORL: Backdoor Attack against Competitive Reinforcement Learn-
ing. In IJCAI, pages 3699–3705, 2021.

[65] T. Wang, J. Q. Chen, Z. Zhang, D. Su, Y. Cheng, Z. Li, N. Li, and
S. Jha. Continuous Release of Data Streams under both Centralized
and Local Differential Privacy. In ACM CCS, 2021.

[66] Y. Wang, E. Sarkar, W. Li, M. Maniatakos, and S. E. Jabari. Stop-
and-Go: Exploring Backdoor Attacks on Deep Reinforcement Learning-
Based Traffic Congestion Control Systems. IEEE TIFS, 16:4772–4787,
2021.

[67] Z. Yang, L. He, H. Yu, C. Zhao, P. Cheng, and J. Chen. Detecting
PLC Intrusions using Control Invariants. IEEE IoT J, 9(12):9934–9947,
2022.

[68] T. Yu, A. Kumar, R. Rafailov, A. Rajeswaran, S. Levine, and C. Finn.
COMBO: Conservative Offline Model-Based Policy Optimization. In
NeurIPS, pages 28954–28967, 2021.

[69] Q. Yuan, Z. Zhang, L. Du, M. Chen, P. Cheng, and M. Sun. PrivGraph:
Differentially Private Graph Data Publication by Exploiting Community
Information. In USENIX Security, 2023.

[70] L. Zeng, M. Sun, X. Wan, Z. Zhang, R. Deng, and Y. Xu. Physics-
constrained Vulnerability Assessment of Deep Reinforcement Learning-
based SCOPF. IEEE TPS, 2022.

[71] Z. Zhang, T. Wang, N. Li, S. He, and J. Chen. CALM: Consistent
Adaptive Local Marginal for Marginal Release under Local Differential
Privacy. In ACM CCS, 2018.

[72] Z. Zhang, T. Wang, N. Li, J. Honorio, M. Backes, S. He, J. Chen, and
Y. Zhang. PrivSyn: Differentially Private Data Synthesis. In USENIX
Security, 2021.

A. The Behavior Similarity of Models

APPENDIX

In Figure 10, we provide the behavior similarity of the
offline RL models trained on the datasets in Table XV. Taking
the Bipedal Walker task as an example, the dataset “0841”
is regarded as the target dataset, and the other four are the
public datasets. We observe that the behavior similarity of the
RL models waves heavily among the different public training
data. If the auditor adopts the dataset “1203” as the public
training data, the auditor likely misclassifies the RL models
trained on the other three public datasets into the bootleg
models. In addition, the behavior similarity is also affected

by different offline RL frameworks, i.e., BC [49], BCQ [21],
[19], IQL [35], and TD3PlusBC [20] (detailed in Section II-B).

B. The Details of Tasks

Lunar Lander (continuous version). The LunarLander task
is to smoothly land a spaceship between two flags on the
target pad. The landing pad is always at coordinates (0,0).
The ship has three throttles; one throttle points downward (the
main engine) and the other two points in the left and right
direction (the left and right engines). The observation is an
8-dimensional vector: the coordinates of the lander in the x-
axis and y-axis, its linear velocities in the x-axis and y-axis,
its angle, its angular velocity, and two booleans that represent
whether each leg is in contact with the ground or not. The
action is two real values ranging in [−1, 1]. The first dimension
controls the main engine, where the engine is off when the
value is in [−1, 0) and increases from 50% to 100% throttle
when the value rises from 0 to 1. The other two points are
controlled by the second value, where the spaceship fires the
left engine if the value in [−1.0, −0.5), fires the right engine
if the value in [0.5, 1), and shuts down both engines if the
value in [−0.5, 0.5]. The reward for moving from the top of
the screen to the landing pad and zero speed is about 140
points. Landing outside the landing pad is possible. Thus, the
player loses the terminal reward if the lander moves away from
the landing pad. The player gets 10 additional points for each
leg touching the ground. Firing the main engine is -0.3 points
in each frame. The episode finishes if the lander crashes or
lands smoothly, receiving -100 or 100 points.

Bipedal Walker. The Bipedal Walker task is to operate a
4-joint walker robot
to move forward as fast as possible.
The robot is made of a hull and two legs. Each leg has 2
joints at both the hip and knee. The observation of the task
includes eight continuous physical variables, i.e., hull angle
speed, angular velocity, horizontal speed, vertical speed, the
position of joints and joints angular speed, legs contact with
ground, and 10 lidar rangefinder measurements. Actions are
motor speed values in the [-1, 1] range for each of the 4 joints
at both hips and knees. The walker starts standing at the left
end of the terrain with the hull horizontal, and both legs in the
same position with a slight knee angle. The reward is given
for moving forward, totaling 300+ points up to the far end.
If the robot falls, it gets -100. Applying motor torque costs
a small amount of points. A more optimal model will get a
better score. The episode will terminate if the hull gets in
contact with the ground or the walker exceeds the right end of
the terrain length.

Ant.
In this task, the player manipulates a 3D robot (ant),
which consists of one torso (free rotational body) with four legs
attached to it, with each leg having two links, to move in the
forward (right) direction. The observation contains positional
values of different body parts of the ant, followed by the
velocities of those individual parts (their derivatives), with all
the positions ordered before all the velocities. By default, an
observation is a vector with shape (111,) where the elements
correspond to the following: position (1-dim), angles (12-
dim), velocities(14-dim), and the information about the contact
forces (84-dim). The player can apply torques on the eight
hinges connecting the two links of each leg and the torso

16

Fig. 10: Models’ behavior similarity measured by ℓ1 Norm, ℓ2 Norm, Cosine Distance, and Wasserstein Distance. From Table XV,
we use the first dataset of each task as the private training data and the remaining four datasets are the public training data.
For each plot, the x-axis displays the four public training data, and the y-axis shows the absolute fluctuating values of the
behavior similarity between the models trained on the private dataset and the public datasets. BC, BCQ, IQL, and TD3PlusBC
are abbreviations for different offline RL frameworks.

(nine parts and eight hinges). Thus, the action space is an
8-dim continuous vector representing the torques applied at
the hinge joints. The reward of the “Ant” task consists of four
parts: healthy reward, forward reward, control cost, and contact
cost. The total reward returned is reward = healthy reward +
forward reward - control cost - contact cost. The task ends
when either the ant state is unhealthy, or the episode duration
reaches 1000 timesteps.

C. Impact of Shadow Models’ Amount

We investigate the relationship between the number of

shadow models and the audit accuracy.

Setup. We change the shadow models’ amount to 9 and 21
with the other settings the same as Section V-B. Figure 6 shows
the value change of TPR and TNR compared with that of 15
shadow models. Each figure’s title illustrates the settings of the
model and the task, the x-axis indicates the four metrics, and
the y-axis is the absolute value change. Also, we provide the
detailed results in Table VIII (9 Shadow Models) and Table IX
(21 Shadow Models).

Observations. From Figure 6, we have the following obser-
vations. 1) The audit accuracy increases with a larger amount
of shadow models. Since the values of shadow models are
the multi-sampling of the true value Q (s, a) of the dataset,
the mean and standard deviation will be more precise with
more shadow models. For example, ORL-AUDITOR suffers an
obvious TPR decline (more than 30%) with 9 shadow models.
Since the insufficient knowledge about the diversity of models

trained on the target dataset, the auditor easily misclassifies
the positive models to the negative group.

2) There exists a saturation point for audit accuracy with
the expansion of shadow models. When the shadow models’
amount rises from 15 to 21, the TPR usually increases since the
auditor observes more possible cumulative rewards originating
from the model trained on the target dataset. We should note
that the value changes slightly in most plots, meaning that
similar cumulative rewards appear in the shadow model set,
and the diversity does not increase significantly compared to
that of 15 shadow models. Therefore, excessive shadow models
are unnecessary, and the auditor needs to burden more training
overhead.

D. Impact of Significance Level

The significance level represents the auditor’s confidence
in the audit results. In Section V-B, we adopt the significance
level α = 0.01, meaning that the auditor has 99% confidence in
the judgments made. Generally speaking, the significance level
represents the maximum audit capacity of ORL-AUDITOR
instead of a hyperparameter setting since it is an audit re-
quirement by the dataset owner.

Setup. We demand the auditor to output a more confident
judgment, where the error possibility should be limited to
1‰ and 0.1‰, i.e., α = 0.001 and α = 0.0001. Figure 7
shows the value change of TPR and TNR compared with that
when significance level α = 0.01. The used offline DRL model
and task is shown in each figure’s title. The x-axis indicates
the four metrics and the y-axis is the absolute value change.

17

l

e
u
a
V

l

e
u
a
V

1400.0
1200.0
1000.0
800.0
600.0
400.0
200.0
0.0

4000.0
3500.0
3000.0
2500.0
2000.0
1500.0
1000.0
500.0
0.0

4000.0

3000.0

2000.0

l

e
u
a
V

1000.0

0.0

l

e
u
a
V

5000.0

4000.0

3000.0

2000.0

1000.0

0.0

Lunar Lander, L1 Norm

Lunar Lander, L2 Norm

Lunar Lander, Cosine Distance

BC
BCQ
IQL
TD3PlusBC

2094

4496

6518

9906

Bipedal Walker, L1 Norm

BC
BCQ
IQL
TD3PlusBC

1203

2110
3813
Ant, L1 Norm

6558

BC
BCQ
IQL
TD3PlusBC

3569

4603

5766

7490

Half Cheetah, L1 Norm

BC
BCQ
IQL
TD3PlusBC

medium

random
Dataset Name

rluply

1400.0

1200.0

1000.0

800.0

600.0

400.0

200.0

0.0

5000.0

4000.0

3000.0

2000.0

1000.0

0.0

4000.0
3500.0
3000.0
2500.0
2000.0
1500.0
1000.0
500.0
0.0

8000.0
7000.0
6000.0
5000.0
4000.0
3000.0
2000.0
1000.0
0.0

BC
BCQ
IQL
TD3PlusBC

2094

4496

6518

9906

Bipedal Walker, L2 Norm

BC
BCQ
IQL
TD3PlusBC

1203

2110
3813
Ant, L2 Norm

6558

BC
BCQ
IQL
TD3PlusBC

3569

4603

5766

7490

Half Cheetah, L2 Norm

BC
BCQ
IQL
TD3PlusBC

medium

random
Dataset Name

rluply

1.2

1.0

0.8

0.6

0.4

0.2

0.0

1.2

1.0

0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0

1.2

1.0

0.8

0.6

0.4

0.2

0.0

BC
BCQ
IQL
TD3PlusBC

2094

4496

6518

9906

Bipedal Walker, Cosine Distance

BC
BCQ
IQL
TD3PlusBC

1203

2110

3813

6558

Ant, Cosine Distance

BC
BCQ
IQL
TD3PlusBC

3569

4603

5766

7490

Half Cheetah, Cosine Distance

BC
BCQ
IQL
TD3PlusBC

medium

random
Dataset Name

rluply

0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0.0

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

0.2
0.18
0.15
0.12
0.1
0.08
0.05
0.02
0.0

0.6

0.5

0.4

0.3

0.2

0.1

0.0

Lunar Lander, Wasserstein Distance

BC
BCQ
IQL
TD3PlusBC

2094
9906
Bipedal Walker, Wasserstein Distance

4496

6518

BC
BCQ
IQL
TD3PlusBC

1203

2110

3813

6558

Ant, Wasserstein Distance

BC
BCQ
IQL
TD3PlusBC

3569
7490
Half Cheetah, Wasserstein Distance

4603

5766

BC
BCQ
IQL
TD3PlusBC

medium

random
Dataset Name

rluply

2) It should be noticed that a small trajectory size achieves
better results under some tasks. For the Ant
task, ORL-
AUDITOR auditing with 25% of the full length obtains at most
7% promotion on the TNR results. Based on the analysis of
[46], the front states of each trajectory are able to reflect more
behavioral information of the model. Thus, in this case, a
shorter trajectory truncates the rear state-action pairs, which
might be unimportant or even weaken the significance of
the hypothesis testing. Exploring effective data auditing with
shorter trajectory sizes or even using only the first state of each
trajectory would be an interesting future direction.

F. Additional Results

As a supplementary of [13], we provide additional results
about ORL-AUDITOR. For ease of reading, we summarize the
main figures and tables in Table VI.

The detailed results between every two datasets are in Table X
(α = 0.001) and Table XI (α = 0.0001).

Observations. From Figure 7, we have the following obser-
vations. 1) For a complicated task, we recommend the auditor
to select a large significance level for ORL-AUDITOR. The
task’s complexity affects the minimum significance level of
ORL-AUDITOR. For example, TPR and TNP change a little
on the Lunar Lander task when the significance level reduces
to 0.001, while they highly shrink on the Ant task. From
Table I, Ant’s state and action space are larger than that of
Lunar Lander. When the auditor leverages the critic model to
compress each model’s state and action pair into a scalar, the
deviation between Qi
j (recalling Figure 4) on the Ant
task is more imperceptible.

j and Qs

2) For the suspect models with low performance, ORL-
AUDITOR should adopt a large significance level to guarantee
audit accuracy. For instance, in the figure titled with “Bipedal
Walker, TD3PlusBC”, all TNR results from four distance
metrics decrease when α reduces to 0.001 and 0.0001. From
Table XIX, most of the TD3PlusBC models’ performance on
the Bipedal Walker task is around -100, meaning that the
TD3PlusBC models do not fully master the knowledge of the
dataset. Thus, the dataset features reflected in their behavior
are ambiguous, which weakens the difference between positive
and negative samples. Meanwhile, the confidence interval, i.e.,
∆ in Figure 1, expands with a lower significance level. For the
above two reasons, the TNR results of the TD3PlusBC models
on the Bipedal Walker task drop more than 10% compared with
these when α = 0.01.

From the above analysis, α = 0.01 is a safe bound
of ORL-AUDITOR, and a lower α may break through the
capability boundary of ORL-AUDITOR, inducing the auditor
to misclassify the negative model to the positive set.

E. Impact of Trajectory Size

We investigate the relationship between the trajectory size
and audit accuracy. In Section V-B, we adopt the full-length
trajectory, meaning that the auditor utilizes all states of each
trajectory to query the suspect model and obtains the corre-
sponding actions to conduct the dataset audit.

Setup. We change the trajectory size to 25% and 50% of the
full length with the other settings the same as Section V-B.
Figure 8 shows the value change of TPR and TNR compared
with that of the full-length trajectory. Each figure’s title illus-
trates the settings of the model and the task, the x-axis indicates
the four metrics, and the y-axis is the absolute value change.
Also, we provide the detailed results in Table XII (25%) and
Table XIII (50%).

Observation. From Figure 8, we have the following observa-
tions. 1) ORL-AUDITOR tends to achieve higher accuracy with
a larger trajectory size. Since the predicted cumulative rewards
of state-action pairs from the critic model are the audit basis, a
longer trajectory collects more actions from the suspect model
to enhance the significance of hypothesis testing. For example,
the TNP results decrease at most 13% when ORL-AUDITOR
only leverages 25% of the trajectory.

18

TABLE VI: The roadmap of the main figures and tables.

Information
Overview of tasks
Online DRL models

Involved Content
Section V-A
Section V-A

Name
Table I
Table XIV

Offline Datasets

Section V-A

Table XV

Offline DRL models

Section V

Overall audit performance

Section V-B

Impact of shadow models’ amount

Appendix C

Impact of significance level

Appendix D

Impact of trajectory size

Appendix E

Real-world application

Section V-E

Robustness: ensemble architecture

Section VI-A

Robustness: perturbing models output

Section VI-B

Table XVI
Table XVII
Table XVIII
Table XIX

Table IV
Table VII
Figure 11
Figure 12
Figure 13

Figure 6
Table VIII
Table IX

Figure 7
Table X
Table XI

Figure 8
Table XII
Table XIII

Table XXII
Table XX
Table XXI

Table V
Figure 14
Figure 16
Figure 17

Figure 9
Figure 18
Figure 19
Figure 20
Figure 21
Figure 22
Figure 23

Description
The state shape and the action shape of each task.
The performance of the used online models for collecting the offline
datasets.
The name, the number of trajectories, and the length of trajectory for
each offline dataset.
The offline models’ performance with or without defense against ORL-
AUDITOR: normal performance (without defense), defended by model
ensemble, and defended by perturbing models’ output.

The true positive rate (TPR) and true negative rate (TNR) results based
on Grubbs’ test and 3σ principle.

The change values of TPR and TNR when the number of shadow
models varies to 9 and 21 compared to the default 15 shadow models.

The change value of TPR and TNR when the significance level (σ)
varies to 0.001 and 0.0001 compared to the default 0.01.

The change value of TPR and TNR when the trajectory size varies to
25% and 50% compared to the default 100% (full length).

The TPR and TNR results on the Half Cheetah datasets, which are
published by DeepMind and Google separately.

The TPR and TNR results of ORL-AUDITOR against model ensemble
(K = 5).

The TPR and TNR results of ORL-AUDITOR against models’ action
distortion.

TABLE VII: As a supplementary of [13], we provide the TPR and TNR results of ORL-AUDITOR based on 3σ principle. The
mean and standard deviation of TPR and TNR in each row represent the audit results for one combination of task and model
by four distance metrics. Bold indicates the highest sum of TPR and TNR, i.e., accuracy, in a row.

Task
Name

Offline
Model

Lunar
Lander

Bipedal
Walker

Ant

BC
BCQ
IQL
TD3PlusBC
BC
BCQ
IQL
TD3PlusBC
BC
BCQ
IQL
TD3PlusBC

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TPR
96.53±1.36
96.13±3.01
97.20±3.24
95.60±4.39
96.56±4.27
96.67±4.20
94.33±7.45
97.00±4.46
90.67±5.30
90.40±8.68
90.67±6.93
95.62±5.19

TNR
100.00±0.00
100.00±0.00
99.97±0.28
99.54±2.53
100.00±0.00
100.00±0.00
100.00±0.00
99.90±1.16
100.00±0.00
99.96±0.42
100.00±0.00
99.74±1.79

TPR
95.47±2.81
94.80±3.18
96.27±2.44
92.80±5.07
95.78±4.58
94.78±7.43
93.78±7.25
94.11±8.63
93.33±4.62
94.13±3.83
89.60±3.99
94.12±5.03

TNR
100.00±0.00
100.00±0.00
100.00±0.00
99.91±0.47
100.00±0.00
100.00±0.00
100.00±0.00
97.80±12.09
100.00±0.00
99.94±0.56
100.00±0.00
99.35±2.58

TPR
95.73±2.58
94.67±2.92
96.53±2.40
93.33±5.40
98.33±2.50
98.67±1.63
98.89±2.17
95.33±6.66
99.20±0.88
98.00±2.00
97.20±3.89
99.08±1.54

TNR
100.00±0.00
100.00±0.00
100.00±0.00
99.93±0.40
100.00±0.00
100.00±0.00
100.00±0.00
97.78±12.19
88.00±27.55
88.47±26.83
88.30±27.38
88.52±26.25

TPR
96.13±2.02
96.40±2.92
96.53±4.14
96.67±2.88
97.22±4.05
97.11±3.69
94.00±9.45
96.44±5.95
95.20±2.99
93.47±6.81
91.20±9.03
97.74±2.66

TNR
100.00±0.00
99.95±0.36
98.90±3.33
96.86±7.24
100.00±0.00
100.00±0.00
100.00±0.00
93.87±19.73
99.99±0.07
99.95±0.49
100.00±0.00
99.60±2.13

19

Fig. 11: The audit accuracy between every two Lunar Lander datasets. The caption of each plot demonstrates the offline DRL
model’s type, the task, and the distance metric. The x labels are the names of datasets to be audited, i.e., the target datasets. The
y labels are the names of datasets the suspect models learned, i.e., the actual datasets. Thus, the diagonal values show the audit
accuracy when the actual dataset is the same as the target dataset, i.e., TPR, and the non-diagonal values are the TNR results.
The positions without value mean 100% accuracy.

Fig. 12: The audit accuracy between every two Bipedal Walker datasets. The caption of each plot demonstrates the offline DRL
model’s type, the task, and the distance metric. The x labels are the names of datasets to be audited, i.e., the target datasets. The
y labels are the names of datasets the suspect models learned, i.e., the actual datasets. Thus, the diagonal values show the audit
accuracy when the actual dataset is the same as the target dataset, i.e., TPR, and the non-diagonal values are the TNR results.
The positions without value mean 100% accuracy.

20

Lunar Lander, BC, L1 Norm

Lunar Lander, BC, L2 Norm

Lunar Lander, BC, Cosine Distance

98.5

98.8

99.9

2094

4496
Lunar Lander, BCQ, L1 Norm

6518

96.9

1171

95.6

98.8
9906

95.9

97.2

96.8

95.7

97.2

98.1

98.1

2094

4496
Lunar Lander, BCQ, L2 Norm

6518

1171

2094

4496
Lunar Lander, BCQ, Cosine Distance

6518

96.8
9906

95.5

99.8

Lunar Lander, BC, Wasserstein Distance
99.5

99.8

99.9

98.1

99.9

99.3

97.2

98.7

99.9
2094

98.5
9906
4496
1171
Lunar Lander, BCQ, Wasserstein Distance
99.9
99.7
97.7

6518

1171

99.1

2094

4496

6518

9906

1171

1171

98.5

1171

2094

4496

6518

9906

1171

2094

4496

6518

9906

96.4

99.6

94.3

96.9

97.7

95.7

2094

4496
Lunar Lander, IQL, L1 Norm

6518

99.2
9906

1171

2094

4496
Lunar Lander, IQL, L2 Norm

6518

99.5

99.7

99.1

99.9

96.1

99.6

94.4

96.7
9906

97.6
9906

99.5

98.5
2094

1171

4496
Lunar Lander, TD3PlusBC, L1 Norm

99.9
6518

97.6
9906

1171

2094

4496
Lunar Lander, TD3PlusBC, L2 Norm

6518

94.5
9906

1171

97.7

2094

4496

6518

9906

99.9

98.1

94.5

98.9
1171

98.5
2094

99.7
4496

98.1

99.5

98.0
6518

98.3

99.9
9906

92.8

99.9

98.9

99.9

92.5

99.1
1171

99.9
2094

99.7
4496

99.9

98.7
9906

98.8

99.5
6518

92.4

99.9

98.8

99.5

99.1
1171

2094

94.4

96.8

95.7

96.4

99.9

99.9

99.9

99.2

99.5

99.6

96.1

1171

2094

4496
Lunar Lander, IQL, Cosine Distance

6518

97.5
9906

99.1

99.6

99.6

99.4

99.4

99.9

94.0

94.8
1171
9906
4496
Lunar Lander, TD3PlusBC, Cosine Distance

6518

2094

99.8
2094

98.4
9906
4496
1171
Lunar Lander, IQL, Wasserstein Distance
89.4
74.8

6518

99.6

97.6

98.9

98.5

99.1

99.2

99.5

98.4

98.9

99.7

94.9

95.5

99.9

96.9

95.7
2094

98.9
1171

99.9
4496
Lunar Lander, TD3PlusBC, Wasserstein Distance
87.1

99.9
6518

98.3
9906

97.9

99.5

93.4

98.7

92.4

99.7
4496

98.7

6518

99.1
9906

98.9

94.7

93.9
1171

99.6

97.3

99.1

93.3
2094

98.9

96.4

98.6

94.5
4496

94.4

94.1

99.1

96.7
6518

85.6

96.5

96.7

99.7
9906

Bipedal Walker, BC, L1 Norm

Bipedal Walker, BC, L2 Norm

Bipedal Walker, BC, Cosine Distance

Bipedal Walker, BC, Wasserstein Distance

96.3

98.9

99.9

99.7

96.7

1203

2110
Bipedal Walker, BCQ, L1 Norm

3813

99.7
6558

0841

1203

2110
Bipedal Walker, BCQ, L2 Norm

3813

93.1
6558

0841

1203

2110
Bipedal Walker, BCQ, Cosine Distance

3813

93.2
6558

99.9
6558
2110
0841
Bipedal Walker, BCQ, Wasserstein Distance

1203

3813

0841

1203

2110

3813

6558

0841

0841

99.9

1203

2110

3813

6558

0841

1203

2110

3813

6558

0841

1203

2110

98.0

92.5

99.9

99.7

99.7

98.3

99.9

99.7

0841

1203

2110
Bipedal Walker, IQL, L1 Norm

3813

6558

0841

1203

2110
Bipedal Walker, IQL, L2 Norm

3813

6558

0841

1203

2110
Bipedal Walker, IQL, Cosine Distance

3813

99.6
6558

1203

6558
2110
0841
Bipedal Walker, IQL, Wasserstein Distance

3813

99.5

80.7

93.7

85.2

95.5

96.4

99.2

95.5

82.0

97.6

0841

1203

2110
Bipedal Walker, TD3PlusBC, L1 Norm

3813

99.9
6558

10.4

0841

1203

2110
Bipedal Walker, TD3PlusBC, L2 Norm
89.1

3813

0.7

99.9
6558

0841

1203

2110
Bipedal Walker, TD3PlusBC, Cosine Distance
87.9

6558

3813

99.7

0.1

0841

2110
Bipedal Walker, TD3PlusBC, Wasserstein Distance

3813

1203

6558

1.9

48.7

3813

96.0

98.0

94.9

6558

0841

1203

2110

3813

96.0

96.8
6558

94.0

96.0

96.5

0841

1203

2110

3813

99.5

92.0

94.0

94.4

0841

1203

2110

3813

97.1

94.0

85.7
6558

79.6

92.0

85.3
6558

92.0

94.2

98.0

94.5

43.8

0841

1203

2110

3813

92.0

90.4
6558

Fig. 13: The audit accuracy between every two Ant datasets. The caption of each plot demonstrates the offline DRL model’s
type, the task, and the distance metric. The x labels are the names of datasets to be audited, i.e., the target datasets. The y
labels are the names of datasets the suspect models learned, i.e., the actual datasets. Thus, the diagonal values show the audit
accuracy when the actual dataset is the same as the target dataset, i.e., TPR, and the non-diagonal values are the TNR results.
The positions without value mean 100% accuracy.

TABLE VIII: The impact of shadow models’ amount. The TPR and TNR results of ORL-AUDITOR with 9 shadow models.

Task
Name

Lunar
Lander

Bipedal
Walker

Ant

Offline
Model

BC
BCQ
IQL

TPR
97.09±1.09
96.97±1.65
96.89±1.96
TD3PlusBC 97.24±2.17
95.14±3.54
93.90±5.98
88.55±10.61
TD3PlusBC 97.39±5.22
90.61±6.99
92.65±3.46
97.05±1.06
TD3PlusBC 93.57±7.04

BC
BCQ
IQL

BC
BCQ
IQL

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TNR
100.00±0.00
100.00±0.00
99.90±0.37
99.32±0.84
100.00±0.00
100.00±0.00
100.00±0.00
94.30±20.23
99.93±0.16
99.78±0.50
99.58±0.92
99.35±1.27

TPR
94.97±1.31
94.53±1.20
95.22±2.85
93.77±3.64
89.68±10.06
95.47±3.37
87.79±8.56
96.57±6.86
92.25±4.98
90.00±5.47
94.44±2.40
93.15±4.39

TNR
100.00±0.00
100.00±0.00
99.98±0.07
99.82±0.45
100.00±0.00
100.00±0.00
100.00±0.00
90.88±22.63
99.95±0.17
99.88±0.27
99.63±0.72
99.59±1.05

TPR
95.09±1.41
94.48±1.09
95.03±3.13
93.81±3.71
97.70±3.59
98.69±0.93
98.80±1.27
97.30±4.95
98.91±0.99
98.02±1.01
99.12±0.43
99.35±0.75

TNR
100.00±0.00
99.98±0.10
99.91±0.22
99.78±0.49
100.00±0.00
100.00±0.00
100.00±0.00
88.39±24.21
85.17±28.30
85.88±28.10
85.16±28.62
87.99±26.18

TPR
96.55±1.98
97.03±1.51
96.82±2.14
97.54±1.16
94.80±3.69
95.35±4.04
90.68±8.87
96.08±7.85
96.23±3.90
98.11±1.42
98.50±1.30
97.86±1.32

TNR
99.93±0.26
99.78±0.38
96.85±6.45
95.45±3.71
100.00±0.00
100.00±0.00
100.00±0.00
84.40±30.65
99.92±0.16
99.76±0.52
99.57±0.93
99.30±1.36

21

Ant, BC, L1 Norm

Ant, BC, L2 Norm

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

97.5

99.7

99.9

2232

96.4

98.9

2232

93.7

98.5

99.8

2232

99.9

98.0

99.6

99.1

99.9

99.8

94.3

3569

4603
Ant, BCQ, L1 Norm

5766

99.9

97.9

98.7

98.7

99.9

91.9

3569

4603
Ant, IQL, L1 Norm

5766

99.9

99.6

97.5

97.1

97.9

99.9

99.9

3569

4603
Ant, TD3PlusBC, L1 Norm

5766

99.9

98.3
7490

99.9

99.7
7490

99.6

99.9

95.7
7490

2232

3569

99.1

4603

99.8

96.4

5766

97.5

99.5

7490

98.3

96.2

92.5

98.0

98.8

95.9

99.9

2232

94.0

99.1

2232

91.9

98.9

99.9

2232

97.9

99.5

98.3

96.3

99.9

99.1

94.0

3569

4603
Ant, BCQ, L2 Norm

5766

98.3

94.9

99.5

98.4

92.3

3569

4603
Ant, IQL, L2 Norm

5766

99.9

97.2
7490

99.5

99.9

9.0
2232

99.9

99.5

98.8
7490

10.7
2232

Ant, BC, Cosine Distance
99.9

98.0

56.1

97.1

99.9

93.8

99.6

88.6
3569

99.9
4603
Ant, BCQ, Cosine Distance

56.1
5766

12.0

99.9

99.9
7490

Ant, BC, Wasserstein Distance

99.9

97.9

99.5

99.7

99.9

99.5

99.1

99.9

99.7

99.8

97.5

2232

3569

4603
Ant, BCQ, Wasserstein Distance

5766

96.1
7490

98.1

98.8

65.9

14.7

99.5

99.9

92.9

99.9

99.9

97.1

98.9

98.6

99.9

98.6

99.9

96.3

90.9
3569

99.9
4603
Ant, IQL, Cosine Distance

62.0
5766

99.9
7490

11.9

2232

99.6

98.5

99.8

3569

4603
Ant, IQL, Wasserstein Distance

5766

99.9

99.1

97.5

99.3

97.6

99.9

99.9

7490

99.6

99.8

98.7

97.3

98.1

96.7

98.5

99.9

98.3

99.8

99.3

98.7

98.0

99.1

74.7

99.7

92.4

99.9

3569

4603
Ant, TD3PlusBC, L2 Norm

5766

98.9
7490

8.8
2232

90.5
3569

99.6
4603
Ant, TD3PlusBC, Cosine Distance

50.3
5766

7490

2232

3569

4603
Ant, TD3PlusBC, Wasserstein Distance

5766

98.8
7490

96.1

99.0

94.6

92.0

98.2

99.7

99.0

99.5

99.9

99.6

99.9

98.9

98.2

7.1
2232

99.7

91.5
3569

97.2
7490

75.2

99.1

91.3

99.9

89.3
5766

99.2

99.9

92.2

100.0
4603

14.1

99.5

99.7

99.5

99.1

97.5

99.5

98.3

96.8

92.0

97.8

98.8

7490

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

2232

3569

4603

5766

TABLE IX: The impact of shadow models’ amount. The TPR and TNR results of ORL-AUDITOR with 21 shadow models.

Task
Name

Lunar
Lander

Bipedal
Walker

Ant

Offline
Model

BC
BCQ
IQL

TPR
99.25±0.97
99.56±0.32
97.95±2.45
TD3PlusBC 97.87±3.45
97.07±3.60
100.00±0.00
95.91±4.93
TD3PlusBC 99.91±0.18
98.13±1.55
97.16±2.73
95.91±3.87
TD3PlusBC 99.44±0.60

BC
BCQ
IQL

BC
BCQ
IQL

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TNR
100.00±0.00
100.00±0.00
99.96±0.17
99.45±0.84
100.00±0.00
100.00±0.00
100.00±0.00
95.05±19.14
99.91±0.18
99.81±0.42
99.64±0.77
99.23±1.53

TPR
98.13±1.88
98.40±0.68
97.11±3.12
96.09±3.91
97.24±4.49
99.56±0.69
96.36±4.57
99.87±0.27
97.73±1.19
96.67±2.18
96.49±3.89
98.27±1.03

TNR
100.00±0.00
100.00±0.00
99.98±0.09
99.73±0.58
100.00±0.00
100.00±0.00
100.00±0.00
93.96±20.97
99.86±0.41
99.84±0.42
99.68±0.63
99.36±1.64

TPR
98.00±1.84
98.27±0.47
96.85±3.40
95.78±4.29
97.69±4.51
99.07±1.65
99.51±0.26
99.82±0.36
99.73±0.53
99.69±0.41
99.51±0.67
99.76±0.33

TNR
100.00±0.00
99.99±0.04
99.92±0.19
99.95±0.14
100.00±0.00
100.00±0.00
100.00±0.00
92.79±21.27
86.82±26.97
87.53±26.74
86.53±27.80
88.42±25.93

TPR
99.11±0.93
98.80±0.78
97.11±3.65
98.00±2.60
98.36±2.67
99.96±0.09
96.44±4.54
99.91±0.18
97.55±1.57
98.58±1.69
97.65±2.19
99.79±0.27

TNR
99.96±0.10
99.75±0.41
97.47±5.34
96.27±3.43
100.00±0.00
100.00±0.00
100.00±0.00
91.78±21.28
99.90±0.21
99.80±0.43
99.64±0.78
99.18±1.65

TABLE X: The impact of significance level. The TPR and TNR results of ORL-AUDITOR with σ = 0.001.

Task
Name

Lunar
Lander

Bipedal
Walker

Ant

Offline
Model

BC
BCQ
IQL

TPR
99.63±0.19
99.15±0.67
99.31±0.90
TD3PlusBC 99.20±1.10
99.97±0.05
99.95±0.06
97.04±5.47
TD3PlusBC 99.92±0.16
99.52±0.50
98.91±1.68
98.88±1.27
TD3PlusBC 99.62±0.46

BC
BCQ
IQL

BC
BCQ
IQL

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TNR
100.00±0.00
100.00±0.00
99.83±0.40
99.22±0.89
100.00±0.00
100.00±0.00
100.00±0.00
89.69±22.99
99.86±0.25
99.71±0.60
99.53±0.97
98.92±2.08

TPR
98.21±0.55
97.60±1.13
98.56±1.51
97.47±2.33
98.67±2.67
99.73±0.34
95.81±5.06
97.17±5.65
98.48±0.80
97.97±1.43
98.42±1.80
98.73±0.97

TNR
100.00±0.00
100.00±0.00
99.96±0.16
99.61±0.55
100.00±0.00
100.00±0.00
100.00±0.00
85.59±27.05
99.88±0.40
99.81±0.47
99.60±0.73
99.24±1.91

TPR
98.21±0.63
97.63±1.04
98.51±1.59
97.55±2.22
98.64±2.66
99.95±0.06
99.87±0.27
97.20±5.60
99.55±0.66
99.87±0.15
99.71±0.52
99.79±0.36

TNR
100.00±0.00
99.97±0.13
99.79±0.51
99.75±0.51
100.00±0.00
100.00±0.00
100.00±0.00
82.52±30.48
80.58±33.24
81.88±31.60
80.90±32.60
84.36±28.07

TPR
99.31±0.38
98.59±0.95
99.04±1.21
99.49±0.56
100.00±0.00
99.97±0.05
97.68±4.51
99.68±0.64
99.36±0.49
99.52±0.64
99.92±0.06
99.71±0.58

TNR
99.84±0.38
99.61±0.53
94.88±8.21
92.45±5.32
100.00±0.00
100.00±0.00
100.00±0.00
80.18±35.21
99.85±0.25
99.69±0.63
99.49±1.05
98.78±2.15

TABLE XI: The impact of significance level. The TPR and TNR results of ORL-AUDITOR with σ = 0.0001.

Task
Name

Lunar
Lander

Bipedal
Walker

Ant

Offline
Model

BC
BCQ
IQL

TPR
99.87±0.12
99.49±0.46
99.71±0.52
TD3PlusBC 99.55±0.56
100.00±0.00
100.00±0.00
98.53±2.87
TD3PlusBC 100.00±0.00
99.95±0.11
99.33±1.21
99.73±0.29
TD3PlusBC 99.96±0.05

BC
BCQ
IQL

BC
BCQ
IQL

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TNR
100.00±0.00
100.00±0.00
99.66±0.55
98.80±1.27
100.00±0.00
100.00±0.00
100.00±0.00
79.08±38.26
99.80±0.41
99.56±0.76
99.35±1.25
98.65±2.42

TPR
98.93±0.34
98.48±0.79
98.99±1.04
98.48±1.48
98.67±2.67
99.81±0.26
96.27±4.74
97.23±5.55
99.15±0.67
98.75±1.11
98.91±1.45
99.35±0.50

TNR
100.00±0.00
100.00±0.00
99.91±0.21
98.96±1.24
100.00±0.00
100.00±0.00
100.00±0.00
75.43±39.10
99.85±0.43
99.80±0.48
99.56±0.80
99.11±2.07

TPR
99.04±0.35
98.48±0.82
98.91±1.17
98.56±1.49
98.80±2.40
100.00±0.00
99.87±0.27
97.33±5.33
99.73±0.41
99.92±0.11
99.89±0.21
99.92±0.11

TNR
100.00±0.00
99.95±0.20
99.49±1.15
99.38±0.87
100.00±0.00
100.00±0.00
100.00±0.00
74.60±39.23
77.36±35.68
78.87±33.94
77.78±34.93
81.33±29.74

TPR
99.79±0.22
99.33±0.54
99.52±0.70
99.84±0.16
100.00±0.00
100.00±0.00
98.67±2.67
99.97±0.05
99.73±0.22
99.81±0.23
100.00±0.00
99.90±0.19

TNR
99.56±0.79
98.88±1.54
91.46±10.53
88.16±6.84
100.00±0.00
100.00±0.00
100.00±0.00
73.98±38.98
99.79±0.42
99.52±0.79
99.32±1.31
98.06±3.18

22

TABLE XII: The impact of trajectory size. The TPR and TNR results of ORL-AUDITOR with 25% trajectory size.

Task
Name

Lunar
Lander

Bipedal
Walker

Ant

Offline
Model

BC
BCQ
IQL

TPR
98.13±1.05
98.45±0.51
98.11±1.65
TD3PlusBC 98.00±2.42
99.20±0.97
98.59±2.63
96.80±5.37
TD3PlusBC 97.55±4.91
98.85±0.67
98.11±1.40
98.45±1.00
TD3PlusBC 98.80±1.33

BC
BCQ
IQL

BC
BCQ
IQL

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TNR
99.53±1.30
99.28±1.19
95.42±5.71
95.44±4.57
100.00±0.00
100.00±0.00
100.00±0.00
94.08±21.64
99.90±0.35
99.85±0.34
99.90±0.30
99.76±0.43

TPR
96.27±2.00
97.33±0.76
96.72±2.57
96.43±3.13
97.47±3.12
97.68±2.95
95.73±5.42
97.20±5.60
97.04±1.24
97.36±1.61
96.45±1.47
96.92±1.60

TNR
99.64±1.09
99.59±0.71
97.10±3.96
96.86±3.24
100.00±0.00
100.00±0.00
100.00±0.00
89.72±24.95
99.84±0.47
99.78±0.46
99.85±0.40
99.70±0.67

TPR
96.29±1.97
96.91±1.06
96.80±2.25
95.95±2.56
98.61±2.71
99.68±0.27
99.41±0.45
96.93±5.74
99.49±0.88
99.49±0.76
99.68±0.51
99.22±1.18

TNR
99.13±2.41
99.01±1.33
92.42±5.78
92.95±3.92
100.00±0.00
100.00±0.00
100.00±0.00
90.65±23.69
92.58±19.10
92.64±19.34
92.56±20.01
93.58±17.31

TPR
98.10±0.92
98.56±1.10
98.19±1.55
98.45±1.43
99.36±0.90
98.61±2.45
97.01±5.45
97.41±5.17
98.96±0.81
99.12±0.59
99.04±0.55
99.28±1.07

TNR
97.74±2.30
94.02±4.44
84.64±9.09
81.51±9.13
100.00±0.00
100.00±0.00
100.00±0.00
84.06±33.72
99.90±0.35
99.84±0.34
99.80±0.49
99.74±0.45

TABLE XIII: The impact of trajectory size. The TPR and TNR results of ORL-AUDITOR with 50% trajectory size.

Task
Name

Lunar
Lander

Bipedal
Walker

Ant

Offline
Model

BC
BCQ
IQL

TPR
98.37±0.68
98.16±0.55
98.03±2.25
TD3PlusBC 98.03±2.33
99.44±0.75
98.75±2.38
95.68±6.60
TD3PlusBC 98.35±3.31
98.21±0.98
97.76±2.05
97.71±1.81
TD3PlusBC 98.52±1.81

BC
BCQ
IQL

BC
BCQ
IQL

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TNR
100.00±0.00
99.96±0.19
98.93±1.35
98.28±2.03
100.00±0.00
100.00±0.00
100.00±0.00
94.29±21.47
99.92±0.24
99.85±0.36
99.73±0.61
99.61±0.77

TPR
97.07±0.90
96.11±0.83
96.80±2.84
96.37±3.41
97.81±2.83
97.92±2.81
95.47±5.34
97.20±5.60
97.04±1.33
96.72±1.50
96.53±1.65
96.99±1.57

TNR
100.00±0.00
99.95±0.20
99.29±1.06
99.27±0.97
100.00±0.00
100.00±0.00
100.00±0.00
91.75±22.51
99.85±0.43
99.81±0.44
99.82±0.40
99.74±0.64

TPR
97.25±0.72
96.40±0.84
97.25±2.18
96.51±2.98
98.67±2.67
99.89±0.10
99.81±0.31
96.96±6.02
99.49±0.83
99.60±0.60
99.79±0.30
99.82±0.25

TNR
100.00±0.02
99.58±0.80
96.38±2.48
95.94±4.14
100.00±0.00
100.00±0.00
100.00±0.00
90.88±23.07
88.52±25.25
89.27±24.10
88.67±25.63
90.62±24.30

TPR
98.58±0.50
97.57±1.64
98.27±2.29
98.24±1.79
99.41±0.86
99.55±0.72
96.40±6.11
97.41±5.17
98.59±0.81
98.88±1.30
98.99±0.65
99.13±1.29

TNR
98.50±1.91
96.28±3.72
86.89±10.96
84.30±8.08
100.00±0.00
100.00±0.00
100.00±0.00
89.04±27.90
99.92±0.24
99.84±0.36
99.70±0.66
99.58±0.79

TABLE XIV: The details of the online models for generating the offline datasets. The model performance shows the cumulative
reward for 10 separate evaluations.

Task Name Online Model Train Step Model Name Model Performance

Lunar Lander

SAC

1e6

Bipedal Walker

PPO

1e6

Ant

SAC

2e6

1171
2094
4496
6518
9906
0841
1203
2110
3813
6558
2232
3569
4603
5766
7490

275.47±14.38
50.79±65.95
195.02±143.15
246.40±33.91
209.33±91.73
285.55±60.84
286.94±53.46
283.58±47.35
235.88±103.83
285.16±65.92
5377.70±1653.17
1924.58±1180.96
5531.45±844.10
3025.89±547.36
5897.37±477.34

23

Fig. 14: The audit accuracy against model ensemble for Lunar Lander. The caption of each plot demonstrates the offline DRL
model’s type, the task, the distance metric, and the hyperparameter K of the model ensemble. The x labels are the names of
datasets to be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models learned, i.e., the actual
datasets. Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset, i.e., TPR,
and the non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

TABLE XV: The details of the offline DRL datasets

Task Name

Number of Transitions Dataset Name Number of Trajectories Length of trajectory

Lunar Lander

5e5

Bipedal Walker

1e6

Ant

2e6

2175
578
1252
1878
1566
1019
1027
877
887
1041
2093
3497
2096
2217
2103

229.83±83.51
864.19±231.88
399.30±240.88
266.13±99.65
319.21±231.06
981.03±190.79
973.07±118.42
1139.55±151.10
1126.63±379.05
959.77±146.13
955.46±177.72
571.66±375.40
954.01±175.82
901.84±236.93
951.02±187.93

1171
2094
4496
6518
9906
0841
1203
2110
3813
6558
2232
3569
4603
5766
7490

24

Lunar Lander, BC, L1 Norm, K = 5

Lunar Lander, BC, L2 Norm, K = 5

Lunar Lander, BC, Cosine, K = 5

Lunar Lander, BC, Wasserstein, K = 5

98.0

98.0

98.0

98.0

98.0

98.0

1171

2094

4496

6518

9906

1171

2094

4496
Lunar Lander, BCQ, L1 Norm, K = 5

6518

9906

1171

2094

4496
Lunar Lander, BCQ, L2 Norm, K = 5

6518

9906

1171

2094

4496
Lunar Lander, BCQ, Cosine, K = 5

6518

9906

1171

98.0

98.0

98.0

2094

4496

6518

9906

1171

2094

4496

6518

9906

1171

2094

4496

6518

9906

1171

2094

4496
Lunar Lander, IQL, L1 Norm, K = 5

6518

9906

1171

2094

4496
Lunar Lander, IQL, L2 Norm, K = 5

6518

94.0
9906

1171

2094

4496
Lunar Lander, IQL, Cosine, K = 5

6518

94.0
9906

98.0

98.0

98.0

98.0

98.0

98.0

94.0

98.0

98.0
2094

9906
4496
1171
Lunar Lander, TD3PlusBC, L1 Norm, K = 5

6518

98.0
9906
4496
1171
Lunar Lander, TD3PlusBC, L2 Norm, K = 5

2094

6518

2094

9906
4496
1171
Lunar Lander, TD3PlusBC, Cosine, K = 5

6518

96.0
1171

96.0
2094

4496
Lunar Lander, TD3PlusBC, Wasserstein, K = 5
92.0

6518

98.0

92.0

98.0
9906

98.0

98.0

98.0

98.0

98.0
1171

98.0
2094

98.0
4496

98.0
6518

9906

98.0
1171

2094

4496

6518

9906

98.0
1171

2094

98.0

98.0
4496

6518

9906

96.0

96.0

98.0

96.0
1171

92.0
2094

94.0

94.0

98.0
6518

86.0

98.0

96.0

9906

98.0

98.0

92.0
4496

2094

1171
9906
4496
Lunar Lander, BCQ, Wasserstein, K = 5

6518

1171

2094

4496
Lunar Lander, IQL, Wasserstein, K = 5
88.0
84.0

6518

98.0

98.0
9906

Fig. 15: The audit accuracy against model ensemble for Bipedal Walker. The caption of each plot demonstrates the offline DRL
model’s type, the task, the distance metric, and the hyperparameter K of the model ensemble. The x labels are the names of
datasets to be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models learned, i.e., the actual
datasets. Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset, i.e., TPR,
and the non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

TABLE XVI: As a supplementary of [13], we provide more details of the BC offline models. The model performance shows
the cumulative reward for 10 separate evaluations.

Offline
Model

Task
Name

Lunar
Lander

BC

Bipedal
Walker

Ant

Dataset
Name
1171
2094
4496
6518
9906
0841
1203
2110
3813
6558
2232
3569
4603
5766
7490

Model Performance
(No Defense)
272.06±5.14
39.04±34.07
173.62±58.93
211.85±43.52
225.45±32.91
264.92±29.11
288.85±15.39
276.80±26.03
164.56±46.14
281.02±48.65
5479.72±354.79
1493.77±413.96
5424.74±422.83
2806.80±286.57
5514.17±441.78

Model Performance
(Trajectory Splitting)
269.17±11.28
46.65±37.73
183.34±47.00
215.13±57.35
213.70±40.65
277.42±18.00
287.12±16.88
277.15±24.63
156.62±47.94
277.24±54.87
5427.47±609.23
1523.73±473.18
5463.20±511.58
2863.00±291.50
5410.28±467.33

Model Performance
(Model Ensemble)
266.20±13.81
45.74±116.66
189.41±102.32
199.44±118.66
234.34±67.54
241.77±117.88
298.62±1.29
265.78±98.38
66.65±97.36
308.01±0.87
5933.60±98.05
1695.64±1255.83
5269.72±1692.57
2951.89±728.14
5785.87±630.97

Model Performance
(Gauss. 0.01)
270.84±6.38
55.03±34.09
161.95±54.27
223.84±41.63
215.19±35.72
257.99±26.73
287.64±16.36
283.05±20.17
160.48±56.24
284.69±22.77
5324.99±441.27
1460.97±436.37
5470.37±473.25
2899.11±313.43
5451.01±430.96

Model Performance
(Gauss. 0.1)
269.01±11.12
53.99±30.89
177.23±35.35
219.14±44.10
215.76±33.81
268.83±25.55
285.91±15.71
286.19±14.48
182.20±55.79
268.39±39.12
4332.23±589.30
1412.06±391.99
4679.76±496.30
2458.92±272.67
4417.19±687.25

25

Bipedal Walker, BC, L1 Norm, K = 5

Bipedal Walker, BC, L2 Norm, K = 5

Bipedal Walker, BC, Cosine, K = 5

Bipedal Walker, BC, Wasserstein, K = 5

0841

1203

2110

3813

6558

0841

1203

2110

3813

6558

0841

1203

2110

3813

6558

0841

1203

2110

0841

1203

2110
Bipedal Walker, BCQ, L1 Norm, K = 5

3813

6558

0841

1203

2110
Bipedal Walker, BCQ, L2 Norm, K = 5

3813

6558

0841

1203

2110
Bipedal Walker, IQL, L1 Norm, K = 5

3813

6558

0841

1203

2110
Bipedal Walker, IQL, L2 Norm, K = 5

3813

6558

0841

1203

2110
Bipedal Walker, BCQ, Cosine, K = 5

3813

6558

0841

1203

2110
Bipedal Walker, IQL, Cosine, K = 5

3813

6558

0841

2110
Bipedal Walker, TD3PlusBC, L1 Norm, K = 5

6558

1203

3813

12.0

0841

1203

2110
Bipedal Walker, TD3PlusBC, L2 Norm, K = 5
94.0

3813

6558

0.0

1203

6558
2110
0841
Bipedal Walker, TD3PlusBC, Cosine, K = 5
94.0

3813

0.0

1203

0841
6558
2110
Bipedal Walker, BCQ, Wasserstein, K = 5

3813

1203

0841
6558
2110
Bipedal Walker, IQL, Wasserstein, K = 5

3813

0841

2110
Bipedal Walker, TD3PlusBC, Wasserstein, K = 5

3813

1203

6558

4.0

52.0

54.0

98.0

96.0

92.0

86.0

92.0

94.0

94.0

3813

96.0

98.0

96.0

96.0

94.0

96.0

98.0

94.0

92.0

94.0

96.0

6558

0841

1203

2110

3813

6558

0841

1203

2110

3813

6558

0841

1203

2110

3813

6558

0841

1203

2110

3813

6558

Fig. 16: The audit accuracy against model ensemble for Ant. The caption of each plot demonstrates the offline DRL model’s
type, the task, the distance metric, and the hyperparameter K of the model ensemble. The x labels are the names of datasets to
be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models learned, i.e., the actual datasets.
Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset, i.e., TPR, and the
non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

TABLE XVII: As a supplementary of [13], we provide more details of the BCQ offline models. The model performance shows
the cumulative reward for 10 separate evaluations.

Offline
Model

Task
Name

Lunar
Lander

BCQ

Bipedal
Walker

Ant

Dataset
Name
1171
2094
4496
6518
9906
0841
1203
2110
3813
6558
2232
3569
4603
5766
7490

Model Performance
(No Defense)
270.69±8.51
52.67±26.38
166.13±57.37
234.99±30.93
243.74±24.43
228.05±43.06
269.87±28.93
281.34±18.56
166.87±55.81
271.52±57.34
3844.45±875.84
1032.55±327.13
4554.06±676.32
2583.27±268.12
3653.48±1108.85

Model Performance
(Trajectory Splitting)
270.45±12.51
64.70±22.08
195.16±37.67
227.41±36.30
236.93±23.49
235.75±39.17
276.35±23.98
282.23±20.88
181.39±45.03
271.09±75.34
3651.94±943.58
951.30±312.96
4562.26±828.88
2502.33±323.71
3755.22±1159.16

Model Performance
(Model Ensemble)
278.43±9.57
30.79±81.96
88.06±182.38
233.08±45.90
236.40±41.93
229.03±117.30
243.15±112.91
264.16±97.68
131.04±165.52
306.09±4.03
4295.42±2225.70
435.72±420.34
3980.17±2203.92
2603.11±1075.03
4012.54±2267.61

Model Performance
(Gauss. 0.01)
268.41±13.91
57.80±30.64
188.89±38.33
236.13±33.25
237.51±31.45
247.17±37.65
276.78±21.02
270.97±24.22
177.90±52.03
275.55±30.70
3587.01±816.81
1013.29±283.76
4480.04±639.38
2640.93±323.35
3552.11±1115.43

Model Performance
(Gauss. 0.1)
270.25±13.45
55.73±28.36
191.19±46.30
235.19±25.16
233.42±34.97
249.94±28.21
281.59±17.69
270.78±26.49
185.86±45.97
262.56±43.95
2514.55±772.19
942.25±266.46
3412.76±804.53
2031.98±293.49
2432.82±892.02

26

Ant, BC, L1 Norm, K = 5

2232

98.0

Ant, BC, L2 Norm, K = 5
98.0

98.0

Ant, BC, Cosine, K = 5
98.0
28.0

98.0

10.0

96.0

Ant, BC, Wasserstein, K = 5

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

3569

4603
Ant, BCQ, L1 Norm, K = 5

5766

7490

2232

3569

4603
Ant, BCQ, L2 Norm, K = 5

5766

98.0

98.0

98.0

98.0

98.0

98.0

2232

3569
5766
4603
Ant, IQL, L1 Norm, K = 5

7490

2232

3569
5766
4603
Ant, IQL, L2 Norm, K = 5

7490

2232

3569

98.0

98.0

98.0

98.0

98.0

98.0

98.0

92.0

7490

10.0
2232

32.0
94.0
3569
5766
4603
Ant, BCQ, Cosine, K = 5
44.0
98.0

7490

2232

18.0

3569

4603
Ant, BCQ, Wasserstein, K = 5

5766

98.0

98.0

98.0

98.0

54.0
94.0
3569
5766
4603
Ant, IQL, Cosine, K = 5
82.0
98.0

7490

2232

14.0

3569

4603
Ant, IQL, Wasserstein, K = 5

5766

98.0

98.0

98.0

98.0

7490

98.0

7490

2232

3569

4603
Ant, TD3PlusBC, L1 Norm, K = 5

5766

7490

2232

3569

4603
Ant, TD3PlusBC, L2 Norm, K = 5

5766

7490

4603
Ant, TD3PlusBC, Cosine, K = 5

98.0

98.0

98.0

98.0

92.0

98.0

90.0

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

74.0

98.0

90.0

84.0
5766

8.0
2232

94.0
3569

90.0

4603

7490

18.0

2232

3569

4603
Ant, TD3PlusBC, Wasserstein, K = 5

5766

7490

98.0

98.0

98.0

84.0

92.0

98.0

7490

2232

3569

4603

5766

7490

94.0
3569

46.0
5766

4603

5766

7490

2232

3569

4603

5766

7490

10.0
2232

98.0

98.0

6.0
2232

Fig. 17: The audit accuracy against model ensemble for Half Cheetah. The caption of each plot demonstrates the offline DRL
model’s type, the task, the distance metric, and the hyperparameter K of the model ensemble. The x labels are the names of
datasets to be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models learned, i.e., the actual
datasets. Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset, i.e., TPR,
and the non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

TABLE XVIII: As a supplementary of [13], we provide more details of the IQL offline models. The model performance shows
the cumulative reward for 10 separate evaluations.

Offline
Model

Task
Name

Lunar
Lander

IQL

Bipedal
Walker

Ant

Dataset
Name
1171
2094
4496
6518
9906
0841
1203
2110
3813
6558
2232
3569
4603
5766
7490

Model Performance
(No Defense)
268.55±10.81
57.92±31.14
181.48±40.09
226.85±43.37
237.33±29.23
261.23±33.91
284.63±17.38
285.24±28.87
169.20±38.88
279.97±33.62
4577.36±865.63
1406.45±447.39
5248.48±477.42
2846.64±295.47
4814.81±556.16

Model Performance
(Trajectory Splitting)
271.91±5.10
39.17±27.55
190.44±51.16
240.15±27.03
238.88±20.10
254.33±34.94
291.47±14.52
288.77±21.97
155.45±57.20
285.89±23.26
4437.55±766.02
1415.31±336.28
5148.72±476.71
2779.50±233.82
4715.59±628.54

Model Performance
(Model Ensemble)
275.03±21.12
47.20±86.05
138.19±219.58
237.64±32.00
221.57±104.60
272.50±54.24
271.86±54.77
299.45±4.43
172.28±123.79
159.33±182.92
4968.65±1337.85
1563.86±1225.73
5822.61±164.84
2680.32±1019.01
3367.15±2159.49

Model Performance
(Gauss. 0.01)
266.55±13.58
49.96±28.60
194.79±43.22
218.41±45.31
245.07±20.08
254.18±35.26
285.79±17.42
287.20±19.29
172.41±43.21
284.75±21.41
4678.37±804.33
1421.81±459.03
5232.36±536.94
2879.16±262.72
4877.90±707.65

Model Performance
(Gauss. 0.1)
265.35±14.22
46.82±29.83
181.89±38.97
245.00±20.38
231.25±25.67
264.38±34.52
285.38±14.02
281.40±23.24
163.51±55.19
268.64±40.07
3420.01±912.08
1239.03±328.98
4135.40±708.39
2338.67±263.68
3461.92±694.92

27

Half Cheetah, BC, L1 Norm, K = 5

Half Cheetah, BC, L2 Norm, K = 5

Half Cheetah, BC, Cosine, K = 5

Half Cheetah, BC, Wasserstein, K = 5

expert

medium

random

rluply

expert

medium

random

rluply

98.0

2.0

4.0

22.0

90.0

40.0

40.0

0.0

92.0

76.0

expert

medium random
Half Cheetah, BCQ, L1 Norm, K = 5

rluply

expert

medium random
Half Cheetah, BCQ, L2 Norm, K = 5

rluply

expert

medium random
Half Cheetah, BCQ, Cosine, K = 5

rluply

98.0

98.0

96.0

2.0

2.0

30.0

64.0

60.0

2.0

74.0

80.0

expert

medium random
Half Cheetah, IQL, L1 Norm, K = 5

rluply

expert

medium random
Half Cheetah, IQL, L2 Norm, K = 5

rluply

expert

medium random
Half Cheetah, IQL, Cosine, K = 5

rluply

expert

96.0

96.0

medium

random

rluply

96.0

68.0

92.0

58.0

expert

medium random
Half Cheetah, TD3PlusBC, L1 Norm, K = 5

rluply

expert

medium random
Half Cheetah, TD3PlusBC, L2 Norm, K = 5

rluply

8.0

0.0

50.0

92.0

2.0

78.0

rluply
medium random
expert
Half Cheetah, TD3PlusBC, Cosine, K = 5

98.0

expert
rluply
medium random
Half Cheetah, BCQ, Wasserstein, K = 5

50.0

expert
rluply
medium random
Half Cheetah, IQL, Wasserstein, K = 5

72.0

96.0

70.0

expert

medium random
Half Cheetah, TD3PlusBC, Wasserstein, K = 5

rluply

expert

74.0

84.0

38.0

88.0

86.0

80.0

94.0

medium

random

rluply

expert

medium random

46.0

rluply

expert

medium random

44.0

rluply

expert

medium random

2.0

2.0

34.0

2.0

68.0

80.0

rluply

54.0

4.0

98.0

expert

medium random

52.0

rluply

Fig. 18: The audit accuracy with Gaussian noise (µ = 0, σ = 0.01) on the suspect models’ action for Lunar Lander. The caption
of each plot demonstrates the offline DRL model’s type, the task, the distance metric, and the noise strength. The x labels are the
names of datasets to be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models learned, i.e.,
the actual datasets. Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset,
i.e., TPR, and the non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

TABLE XIX: As a supplementary of [13], we provide more details of the TD3PlusBC offline models. The model performance
shows the cumulative reward for 10 separate evaluations.

Offline
Model

Task
Name

Lunar
Lander

TD3PlusBC

Bipedal
Walker

Ant

Dataset
Name
1171
2094
4496
6518
9906
0841
1203
2110
3813
6558
2232
3569
4603
5766
7490

Model Performance
(No Defense)
263.65±21.47
99.72±47.21
201.58±42.49
242.58±21.54
235.98±25.48
-102.88±56.03
-86.65±22.94
-101.94±22.86
-114.96±14.97
154.70±148.81
259.94±116.75
549.14±192.30
374.17±199.78
396.13±130.69
314.48±222.06

Model Performance
(Trajectory Splitting)
266.03±13.80
95.78±34.82
207.92±33.77
229.34±29.64
241.78±21.68
-100.63±59.89
-87.17±22.47
-100.43±26.01
-115.04±14.37
138.26±165.87
216.71±118.76
563.13±156.03
370.58±217.99
368.56±115.13
326.59±153.02

Model Performance
(Model Ensemble)
263.34±16.97
71.96±111.26
159.76±135.46
248.09±30.91
206.93±113.68
-108.40±0.22
-95.59±17.13
-80.32±14.02
-126.18±2.36
303.03±2.30
258.28±297.07
566.88±655.52
151.13±112.93
369.73±275.57
689.21±637.77

Model Performance
(Gauss. 0.01)
267.15±12.96
100.67±34.95
207.07±28.13
238.51±21.01
230.41±34.05
-101.93±54.70
-87.64±22.35
-101.02±23.63
-113.97±12.93
165.64±136.38
243.30±121.39
579.86±213.98
372.37±194.00
334.74±172.22
365.24±212.09

Model Performance
(Gauss. 0.1)
265.12±10.36
90.74±37.66
194.69±42.59
243.96±16.41
229.55±36.81
-97.05±73.10
-86.95±25.50
-98.78±26.75
-119.21±10.67
168.47±68.50
222.48±139.45
495.19±160.81
367.64±279.00
361.40±117.68
275.81±130.30

TABLE XX: The details of the HalfCheetah dataset

Task Name

Half Cheetah

Number of Transitions
1e6
1e6
1e6
3.003e5

Dataset Name
D4RL Expert
D4RL Medium
D4RL Random
RL Unplugged

Number of Trajectories
1001
1001
1001
300

Length of trajectory
998.00 ±0.06
997.90 ±3.13
998.00±0.00
1001.00±0.00

28

Lunar Lander, BC, L1 Norm, 0.01

Lunar Lander, BC, L2 Norm, 0.01

Lunar Lander, BC, Cosine, 0.01

Lunar Lander, BC, Wasserstein, 0.01

1171

98.9

96.7

96.5

2094

4496

6518

9906

98.4

98.5

95.7

96.5

95.1

96.4

99.7

98.1

97.7

1171

2094

4496
Lunar Lander, BCQ, L1 Norm, 0.01

6518

98.1
9906

1171

2094

4496
Lunar Lander, BCQ, L2 Norm, 0.01

6518

96.1
9906

1171

2094

4496
Lunar Lander, BCQ, Cosine, 0.01

6518

96.3
9906

1171

98.4

95.6

95.3

99.8

99.5

99.8

99.9

98.0

97.1

99.2

99.9

99.9

98.8

99.9
2094

1171

4496
Lunar Lander, BCQ, Wasserstein, 0.01
99.6

6518

97.7

99.9

98.7
9906

2094

4496

6518

9906

1171

2094

4496

6518

9906

1171

2094

4496

6518

9906

95.3

99.5

93.2

96.8

93.9

96.7

97.5

95.6

95.7

99.9

99.9

96.3

99.9

99.2

99.6

99.6

95.7

1171

2094

4496
Lunar Lander, IQL, L1 Norm, 0.01

6518

98.9
9906

1171

2094

4496
Lunar Lander, IQL, L2 Norm, 0.01

6518

96.9
9906

1171

2094

4496
Lunar Lander, IQL, Cosine, 0.01

6518

96.8
9906

99.9

99.9

99.3

99.7

98.9

99.5

99.7

96.0

99.6

94.3

99.1

99.6

99.6

99.4

99.4

99.9

94.0

98.6
2094

97.6
1171
9906
4496
Lunar Lander, TD3PlusBC, L1 Norm, 0.01
97.6

99.9
6518

2094

94.3
1171
9906
4496
Lunar Lander, TD3PlusBC, L2 Norm, 0.01
92.4

6518

2094

94.3
1171
9906
4496
Lunar Lander, TD3PlusBC, Cosine, 0.01
92.1

6518

99.9
1171

99.7
2094

4496
Lunar Lander, IQL, Wasserstein, 0.01
74.7

6518

99.6

97.7

89.4

98.7
9906

98.9

98.5

99.1

99.2

99.5

98.4

98.9

99.7

95.1

95.5

99.9

96.9

98.7
1171

95.7
2094

99.9
4496
Lunar Lander, TD3PlusBC, Wasserstein, 0.01
87.1

99.9
6518

98.3
9906

98.0

99.5

98.8

93.4

99.9

98.1

94.3

98.9
1171

98.5
2094

99.7
4496

98.1

99.5

98.0
6518

98.3

99.9
9906

99.9

98.9

99.9

92.3

99.1
1171

99.9
2094

99.7
4496

99.9

98.5
9906

98.7

99.5
6518

99.9

98.8

99.5

99.1
1171

2094

92.4

99.7
4496

98.7

6518

98.9
9906

98.9

94.6

93.9
1171

99.6

97.4

99.1

93.3
2094

98.9

96.4

98.6

94.5
4496

94.5

94.1

99.1

96.7
6518

85.6

96.4

96.7

99.7
9906

Fig. 19: The audit accuracy with Gaussian noise (µ = 0, σ = 0.1) on the suspect models’ action for Lunar Lander. The caption
of each plot demonstrates the offline DRL model’s type, the task, the distance metric, and the noise strength. The x labels are the
names of datasets to be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models learned, i.e.,
the actual datasets. Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset,
i.e., TPR, and the non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

TABLE XXI: As a supplementary of [13], we provide more details of the models trained on the HalfCheetah dataset. The model
performance shows the cumulative reward for 10 separate evaluations.

Task Name

Offline Model

Dataset Name

Half Cheetah

BC

BCQ

IQL

TD3PlusBC

D4RL Expert
D4RL Medium
D4RL Random
RL Unplugged
D4RL Expert
D4RL Medium
D4RL Random
RL Unplugged
D4RL Expert
D4RL Medium
D4RL Random
RL Unplugged
D4RL Expert
D4RL Medium
D4RL Random
RL Unplugged

Model Performance
(No Defense)
12620.94±307.84
4223.77±134.67
-0.33±0.24
-427.50±113.42
10974.19±842.10
4765.24±98.75
-1.13±0.43
-421.91±212.36
10163.20±1106.70
4808.11±46.99
1649.55±518.47
-378.74±151.65
12712.69±383.33
4969.74±56.31
1046.23±226.61
-181.50±205.29

Model Performance
(Trajectory Splitting)
12624.61±333.32
4265.82±96.17
-0.33±0.22
-431.01±110.15
10735.35±1345.57
4746.03±108.99
-1.15±0.54
-419.59±219.29
9920.53±879.89
4800.87±59.75
1644.31±551.32
-367.87±156.81
12752.25±274.38
4964.48±57.44
1050.03±214.80
-175.49±225.09

Model Performance
(Model Ensemble)
12868.22±180.39
4293.35±75.67
-0.37±0.62
-427.06±56.30
12334.59±539.99
4512.03±99.46
-0.54±0.78
-378.28±64.55
11268.02±2640.57
4671.25±99.09
1822.31±31.63
-311.62±16.31
11468.00±872.43
4871.85±82.15
1128.32±3.15
-385.80±54.32

TABLE XXII: The TPR and TNR results on the Half Cheetah task. The mean and standard deviation of TPR and TNR in each
row represent the audit results for one combination of task and model by four distance metrics. Bold indicates the highest sum
of TPR and TNR, i.e., accuracy, in a row. Each pair of TPR and TNR is derived from the diagonal and non-diagonal values of
the corresponding heatmap in Figure 24.

Task
Name

Half
Cheetah

Offline
Model

TPR
96.07±3.15
95.37±0.55
95.47±0.77
TD3PlusBC 95.00±2.87

BC
BCQ
IQL

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TNR
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00

TPR
96.07±2.34
95.83±1.20
95.68±1.02
95.50±1.99

TNR
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00

TPR
99.80±0.35
99.57±0.47
99.78±0.23
99.87±0.16

TNR
68.62±42.47
70.14±41.14
71.38±41.05
70.57±40.85

TPR
98.47±1.13
97.47±1.35
97.12±2.70
98.27±1.09

TNR
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00

29

1171

2094

4496

6518

9906

1171

2094

4496

6518

9906

Lunar Lander, BC, L1 Norm, 0.1

Lunar Lander, BC, L2 Norm, 0.1

Lunar Lander, BC, Cosine, 0.1

2.0

3.2

2.0

4.4

0.0

4.0

0.1

4.0

0.1

0.5

3.7

2.0

Lunar Lander, BC, Wasserstein, 0.1
99.9

71.9

99.9

85.6

99.9

99.5

57.1

63.6

1171

2094

4496
Lunar Lander, BCQ, L1 Norm, 0.1

6518

2.0
9906

1171

2094

4496
Lunar Lander, BCQ, L2 Norm, 0.1

6518

2.0
9906

1171

2094

4496
Lunar Lander, BCQ, Cosine, 0.1

6518

2.0
9906

1171

2094

4496
Lunar Lander, BCQ, Wasserstein, 0.1
99.4

6518

99.9

87.2

64.4
9906

5.9

11.7

15.3

0.4

8.5

9.9

4.8

3.7

8.5

10.0

4.9

3.3

77.2

99.9

99.6

99.9

96.1

99.7

99.8

73.9

1171

2094

4496
Lunar Lander, IQL, L1 Norm, 0.1

6518

13.3
9906

1171

2094

4496
Lunar Lander, IQL, L2 Norm, 0.1

6518

13.1
9906

1171

56.7

42.1

2094

4496

6518

9906

1171

2094

4496

6518

9906

25.7

99.9

22.8

99.7

40.5

46.1

45.1

41.9

2094

19.7
1171
9906
4496
Lunar Lander, TD3PlusBC, L1 Norm, 0.1
46.7

6518

2094

12.0
1171
9906
4496
Lunar Lander, TD3PlusBC, L2 Norm, 0.1
32.5

6518

96.3

98.1

53.9

99.3
1171

98.6
2094

99.9
4496

98.1

31.7

98.0
6518

98.3

82.5
9906

87.7

47.7

99.7
1171

2094

4496

99.9

72.0
9906

40.8

99.6
6518

1171

43.7

2094

4496
Lunar Lander, IQL, Cosine, 0.1

6518

22.4

99.8

45.6

99.9

38.3

13.1
9906

99.9

99.6

1171

2094

4496
Lunar Lander, TD3PlusBC, Cosine, 0.1

6518

11.2
9906

99.9
1171

99.7
2094

4496
Lunar Lander, IQL, Wasserstein, 0.1
73.4

6518

99.7

98.7

90.4

85.2
9906

95.7

98.5

99.3

99.5

96.7

98.9

98.7

99.7

91.2

95.5

96.5

98.3
1171

96.7
2094

4496
Lunar Lander, TD3PlusBC, Wasserstein, 0.1
87.9

99.4

96.3

94.0

99.1

99.9
6518

95.7
9906

86.0

99.8

46.0

37.7

2094

4496

6518

72.3
9906

99.0

94.7

93.9
1171

99.6

97.6

99.1

93.5
2094

98.9

95.2

98.7

94.5
4496

95.1

94.3

96.4

97.0
6518

85.1

96.5

96.7

99.6
9906

33.1

99.9

99.7
1171

Fig. 20: The audit accuracy with Gaussian noise (µ = 0, σ = 0.01) on the suspect models’ action for Bipedal Walker. The
caption of each plot demonstrates the offline DRL model’s type, the task, the distance metric, and the noise strength. The x
labels are the names of datasets to be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models
learned, i.e., the actual datasets. Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the
target dataset, i.e., TPR, and the non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

TABLE XXIII: The TPR and TNR results of ORL-AUDITOR when splitting each trajectory into shorter ones (S = 5). The
mean and standard deviation of TPR and TNR in each row represent the audit results for one combination of task and model by
four distance metrics. Each pair of TPR and TNR is derived from the diagonal and non-diagonal values of the corresponding
heatmap in Figure 25 (Lunar Lander), Figure 26 (Bipedal Walker), Figure 27 (Ant), and Figure 28 (Half Cheetah).

Task
Name

Offline
Model

Lunar
Lander

Bipedal
Walker

Ant

Half
Cheetah

BC
BCQ
IQL
TD3PlusBC
BC
BCQ
IQL
TD3PlusBC
BC
BCQ
IQL
TD3PlusBC
BC
BCQ
IQL
TD3PlusBC

L1 Norm

L2 Norm

Cosine
Distance

Wasserstein
Distance

TPR
99.01±0.46
98.29±1.10
98.59±1.55
98.29±2.04
99.65±0.57
99.55±0.71
95.17±7.39
99.39±1.23
98.03±1.38
97.47±2.93
97.68±2.08
98.71±1.63
98.50±1.50
96.83±1.54
97.00±2.00
97.53±1.30

TNR
100.00±0.00
100.00±0.00
99.91±0.31
99.48±0.79
100.00±0.00
100.00±0.00
100.00±0.00
94.77±19.42
99.93±0.12
99.80±0.44
99.65±0.73
99.18±1.71
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00

TPR
96.96±0.73
95.87±1.12
97.52±2.51
96.35±3.01
98.45±2.71
98.19±2.84
95.01±5.49
97.15±5.71
96.77±1.49
95.89±2.32
96.77±2.50
97.20±1.79
96.87±2.14
96.27±1.36
96.25±1.13
96.53±1.20

TNR
100.00±0.00
100.00±0.00
99.97±0.12
99.89±0.22
100.00±0.00
100.00±0.00
100.00±0.00
93.37±21.46
99.90±0.36
99.84±0.41
99.69±0.59
99.35±1.72
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00

TPR
96.96±0.73
95.87±1.06
97.49±2.56
96.27±3.16
98.64±2.66
99.68±0.45
99.81±0.31
96.93±6.00
99.39±0.91
99.65±0.63
99.63±0.62
99.81±0.31
99.74±0.27
99.93±0.12
99.56±0.20
99.56±0.61

TNR
100.00±0.00
99.99±0.03
99.92±0.19
99.91±0.23
100.00±0.00
100.00±0.00
100.00±0.00
91.98±21.75
86.07±27.76
86.86±27.33
85.74±28.43
88.35±25.99
69.56±41.70
68.58±41.88
72.63±40.22
71.21±40.66

TPR
98.43±0.73
97.60±1.14
98.32±1.79
98.53±1.25
99.79±0.43
99.89±0.10
95.33±7.01
98.13±3.73
98.05±1.43
98.83±1.55
99.31±0.49
99.22±1.31
98.60±0.92
97.43±1.38
97.06±2.73
98.37±1.09

TNR
99.94±0.18
99.91±0.15
97.10±5.66
95.59±3.77
100.00±0.00
100.00±0.00
100.00±0.00
88.23±25.40
99.91±0.15
99.79±0.47
99.63±0.78
99.14±1.81
100.00±0.00
100.00±0.00
100.00±0.00
100.00±0.00

30

0841

99.9

1203

2110

3813

6558

0841

99.9

0841

1203

2110

3813

6558

1203

2110

3813

6558

0841

1203

2110

Bipedal Walker, BC, L1 Norm, 0.01

Bipedal Walker, BC, L2 Norm, 0.01

Bipedal Walker, BC, Cosine, 0.01

Bipedal Walker, BC, Wasserstein, 0.01

7.5

3.9

99.2

78.9

45.1

68.7

99.9

99.9

39.2

4.1

66.1

0841

1203

2110
Bipedal Walker, BCQ, L1 Norm, 0.01

3813

93.9
6558

0841

1203

2110
Bipedal Walker, BCQ, L2 Norm, 0.01

3813

93.2
6558

0841

1203

2110
Bipedal Walker, BCQ, Cosine, 0.01

3813

93.1
6558

1203

96.9
0841
6558
2110
Bipedal Walker, BCQ, Wasserstein, 0.01
99.9

3813

96.8

92.1

98.5

95.3

99.9

99.7

99.6

99.2

0841

1203

2110
Bipedal Walker, IQL, L1 Norm, 0.01

3813

6558

0841

1203

2110
Bipedal Walker, IQL, L2 Norm, 0.01

3813

6558

0841

1203

2110
Bipedal Walker, IQL, Cosine, 0.01

3813

98.8
6558

0841

1203

2110
Bipedal Walker, IQL, Wasserstein, 0.01

3813

6558

86.8

43.2

91.5

99.3

89.6

77.1

89.7

99.9

98.8

85.1

68.4

94.5

97.7
0841
6558
2110
Bipedal Walker, TD3PlusBC, L1 Norm, 0.01

1203

3813

10.4

98.4
0841
6558
2110
Bipedal Walker, TD3PlusBC, L2 Norm, 0.01
88.8

1203

3813

0.7

1203

0841
6558
2110
Bipedal Walker, TD3PlusBC, Cosine, 0.01
87.9

3813

99.7

0.1

0841

2110
Bipedal Walker, TD3PlusBC, Wasserstein, 0.01

1203

3813

98.4
6558

1.9

48.9

3813

96.0

98.0

94.9

6558

0841

1203

2110

3813

96.0

95.2
6558

94.0

96.0

96.5

0841

1203

2110

3813

99.6

92.0

94.0

94.4

0841

1203

2110

3813

96.9

94.0

84.3
6558

79.5

92.0

86.0
6558

92.2

94.1

98.0

94.5

43.7

0841

1203

2110

3813

92.0

89.6
6558

Fig. 21: The audit accuracy with Gaussian noise (µ = 0, σ = 0.1) on the suspect models’ action for Bipedal Walker. The caption
of each plot demonstrates the offline DRL model’s type, the task, the distance metric, and the noise strength. The x labels are the
names of datasets to be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models learned, i.e.,
the actual datasets. Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset,
i.e., TPR, and the non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

31

0841

1203

2110

3813

6558

0841

1203

2110

3813

6558

0841

1203

2110

3813

6558

0841

1203

2110

Bipedal Walker, BC, L1 Norm, 0.1

Bipedal Walker, BC, L2 Norm, 0.1

Bipedal Walker, BC, Cosine, 0.1

Bipedal Walker, BC, Wasserstein, 0.1

0.0

0.0

0.0

0.0

5.6

93.2

0.0

0.0

0.0

0.0

0.0

0.0

24.9

30.7

0.0

0.0

0841

1203

2110
Bipedal Walker, BCQ, L1 Norm, 0.1

3813

0.0
6558

0841

1203

2110
Bipedal Walker, BCQ, L2 Norm, 0.1

3813

19.1
6558

0841

1203

2110
Bipedal Walker, BCQ, Cosine, 0.1

3813

35.5
6558

0.0

0.0

1.1

0.0

8.8

93.9

0.0

0.0

0.0

0.0

17.2

28.1

0841

1203

2110
Bipedal Walker, IQL, L1 Norm, 0.1

3813

0.0
6558

0841

1203

2110
Bipedal Walker, IQL, L2 Norm, 0.1

3813

39.6
6558

0841

1203

2110
Bipedal Walker, IQL, Cosine, 0.1

3813

38.0
6558

0.0

0.0

0.0

0.0

7.1

92.1

0.0

0.0

0.0

0.0

19.9

29.3

0.0
0841
6558
2110
Bipedal Walker, TD3PlusBC, L1 Norm, 0.1

1203

3813

11.6

1203

0.0
0841
6558
2110
Bipedal Walker, TD3PlusBC, L2 Norm, 0.1
99.9
91.1

3813

0.7

1203

19.3
0841
6558
2110
Bipedal Walker, TD3PlusBC, Cosine, 0.1
99.5
90.3

3813

99.9

0.1

0841

1203

2110
Bipedal Walker, BCQ, Wasserstein, 0.1
2.5

3813

0.0
6558

0.4

0.0

0.0

0841

1203

2110
Bipedal Walker, IQL, Wasserstein, 0.1
0.0

3813

0.3
6558

0.0

0.0

0.0

0841

2110
Bipedal Walker, TD3PlusBC, Wasserstein, 0.1

3813

1203

0.0
6558

2.3

50.9

3813

96.0

98.0

94.9

6558

0841

1203

2110

3813

96.0

0.0
6558

91.1

91.9

94.1

96.0

96.8

99.7

98.4

0841

1203

2110

3813

97.8

94.0

3.7
6558

92.0

94.0

95.0

99.8

97.6

0841

1203

2110

3813

83.7

92.0

13.5
6558

92.3

94.4

98.0

94.4

45.4

0841

1203

2110

3813

92.0

7.7
6558

Fig. 22: The audit accuracy with Gaussian noise (µ = 0, σ = 0.01) on the suspect models’ action for Ant. The caption of each
plot demonstrates the offline DRL model’s type, the task, the distance metric, and the noise strength. The x labels are the names
of datasets to be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models learned, i.e., the
actual datasets. Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset, i.e.,
TPR, and the non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

32

Ant, BC, L1 Norm, 0.01
99.9

97.5

99.6

96.9

99.8

84.4

5766
4603
3569
Ant, BCQ, L1 Norm, 0.01

99.9

97.2

98.7

99.9

98.7

99.9

87.1

3569
5766
4603
Ant, IQL, L1 Norm, 0.01
99.9

99.3

97.5

93.2

97.9

99.9

99.7

99.9

96.1
7490

99.9

99.6
7490

99.6

99.9

95.1

99.9

2232

93.5

99.1

2232

91.3

98.9

99.9

Ant, BC, L2 Norm, 0.01
98.3

95.2

99.9

98.8

89.7

5766
4603
3569
Ant, BCQ, L2 Norm, 0.01

98.3

94.0

99.5

97.9

88.7

3569
5766
4603
Ant, IQL, L2 Norm, 0.01
98.7

97.5

98.2

96.1

98.5

99.9

96.7

99.9

96.7
7490

99.9

99.5

99.9

8.8
2232

99.9

99.5

Ant, BC, Cosine, 0.01
97.9
57.0

97.1

99.9

11.7

99.9

94.3

99.9

57.3
99.7
88.2
5766
4603
3569
Ant, BCQ, Cosine, 0.01
98.2
62.9

98.3

99.7

99.9

94.3

99.7

Ant, BC, Wasserstein, 0.01

99.9

97.7

99.2

99.7

99.9

99.5

99.3

99.8

99.8

97.1

7490

2232

3569

4603
Ant, BCQ, Wasserstein, 0.01

5766

15.4

99.9

96.9

98.9

98.6

99.9

99.9

98.6

99.9

96.3

98.9
7490

10.1
2232

65.7
92.4
3569
5766
4603
Ant, IQL, Cosine, 0.01
73.5
98.7

99.9
7490

12.3

99.8

99.5

98.4

99.2

99.7

92.9

99.9

2232

99.7

98.5

99.8

3569

4603
Ant, IQL, Wasserstein, 0.01

5766

99.9

98.9

97.5

98.7

97.6

99.9

99.9

96.5
7490

99.9

7490

99.6

99.9

94.5

99.7

99.9

2232

95.5

98.9

2232

93.1

98.5

99.8

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

2232

3569

4603
Ant, TD3PlusBC, L1 Norm, 0.01

5766

94.9
7490

2232

3569

4603
Ant, TD3PlusBC, L2 Norm, 0.01

5766

98.7
7490

2232

3569

99.1

4603

99.8

95.2

5766

97.5

99.6

7490

98.3

93.6

92.5

98.0

98.8

98.0

99.5

95.9

98.2

99.7

99.0

92.9

92.1

99.0

99.5

2232

3569

4603

5766

99.5
7490

2232

3569

4603

5766

95.7
7490

8.1
2232

99.9

99.6

98.2

7.0
2232

90.9
3569

99.5
4603
Ant, TD3PlusBC, Cosine, 0.01

51.3
5766

99.5

99.7

92.1
3569

99.2

99.9

92.2

4603

75.4

99.1

91.9

87.3
5766

7490

14.7

99.5

2232

3569

4603
Ant, TD3PlusBC, Wasserstein, 0.01

5766

98.1
7490

99.8

99.1

99.1

97.5

99.5

98.3

96.6

92.0

97.8

98.8

7490

2232

3569

4603

5766

7490

Fig. 23: The audit accuracy with Gaussian noise (µ = 0, σ = 0.1) on the suspect models’ action for Ant. The caption of each
plot demonstrates the offline DRL model’s type, the task, the distance metric, and the noise strength. The x labels are the names
of datasets to be audited, i.e., the target datasets. The y labels are the names of datasets the suspect models learned, i.e., the
actual datasets. Thus, the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset, i.e.,
TPR, and the non-diagonal values are the TNR results. The positions without value mean 100% accuracy.

33

8.7

2232

3569

4603

99.9

5766

7490

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

2232

10.0

98.9

2232

9.7

98.9

99.9

2232

Ant, BC, L1 Norm, 0.1
99.9

13.6

99.9

2.0

2.3

5766
4603
3569
Ant, BCQ, L1 Norm, 0.1
99.9

24.4

99.0

2.0

99.3

99.9

9.5

3569
5766
4603
Ant, IQL, L1 Norm, 0.1
99.9

25.3

98.5

2.0

98.1

99.9

8.4

3569

4603
Ant, TD3PlusBC, L1 Norm, 0.1

5766

3.6
7490

99.9

99.9

3.9
7490

99.9

3.2
7490

Ant, BC, Cosine, 0.1

Ant, BC, Wasserstein, 0.1

59.7

13.3

12.9

Ant, BC, L2 Norm, 0.1
98.7

22.5

6.0

2.3

5766
4603
3569
Ant, BCQ, L2 Norm, 0.1
98.3

27.6

99.9

5.6

5.1

3569
5766
4603
Ant, IQL, L2 Norm, 0.1
98.7

40.0

99.3

5.6

98.9

4.5

3569

4603
Ant, TD3PlusBC, L2 Norm, 0.1

5766

4.4
7490

3.3
7490

8.8

99.9

2232

9.9

99.6

2232

9.2

99.9

2232

8.5

99.6

98.7

98.1

74.8

99.1

99.9

95.1

84.7

2.7
7490

10.8
2232

99.9

99.9

62.2
99.8
88.9
5766
4603
3569
Ant, BCQ, Cosine, 0.1
98.2
68.7

99.9
7490

16.7

77.5

99.9

96.5

84.4

10.8
2232

99.9

9.1
2232

99.6

98.8

7.7
2232

94.1
3569

69.3
5766

99.9
4603
Ant, IQL, Cosine, 0.1
78.1
98.9

81.6

99.9

95.7

84.8

91.8
3569

99.6
4603
Ant, TD3PlusBC, Cosine, 0.1

54.9
5766

99.9

80.8

93.5
3569

99.8

99.4

93.7

99.9
4603

78.5

99.4

94.3

99.1

91.3
5766

99.7
7490

13.1

99.7
7490

17.3

99.7
7490

99.9

29.9

99.9

5.6

3.7

3569

4603
Ant, BCQ, Wasserstein, 0.1

5766

99.9

42.5

98.9

7.3

99.3

99.9

14.1

3569

4603
Ant, IQL, Wasserstein, 0.1

5766

99.9

49.1

98.4

4.0

98.1

99.9

10.1

2.9
7490

99.9

99.9

43.1
7490

99.9

99.9

2232

62.3

98.9

2232

12.5

98.9

99.9

2232

3569

4603
Ant, TD3PlusBC, Wasserstein, 0.1

5766

25.7
7490

93.1

99.4

51.3

97.9

99.7

98.8

3.4

93.0

97.9

99.3

2232

3569

4603

5766

65.9
7490

2232

8.3

3569

99.4

27.9

4603

5766

98.1

99.7

7490

98.8

2.0

93.4

98.1

99.3

99.8

59.7

99.5

5.4

93.4

99.4

99.9

94.5

2232

3569

4603

5766

2.3
7490

2232

3569

4603

5766

2.0
7490

Fig. 24: The audit accuracy between every two Half Cheetah datasets. The caption of each plot demonstrates the offline DRL
model’s type, the task, and the distance metric. The x labels are the names of datasets to be audited, i.e., the target datasets. The
y labels are the names of datasets the suspect models learned, i.e., the actual datasets. Thus, the diagonal values show the audit
accuracy when the actual dataset is the same as the target dataset, i.e., TPR, and the non-diagonal values are the TNR results.
The positions without value mean 100% accuracy.

34

Half Cheetah, BC, L1 Norm

Half Cheetah, BC, L2 Norm

Half Cheetah, BC, Cosine Distance

Half Cheetah, BC, Wasserstein Distance

expert

91.2

94.0

medium

random

rluply

96.7

94.7

90.0

96.4

95.6

5.4

3.1

26.9

1.6

96.3

99.2

expert

medium random
Half Cheetah, BCQ, L1 Norm

rluply

expert

medium random
Half Cheetah, BCQ, L2 Norm

rluply

expert

94.8

96.0

medium

random

rluply

95.1

96.3

97.7

94.9

expert

medium random
Half Cheetah, IQL, L1 Norm

95.3

rluply

expert

medium random
Half Cheetah, IQL, L2 Norm

94.7

rluply

expert

95.5

95.2

96.7

94.5

97.3

95.6

95.2

94.6

99.7

expert

medium random
Half Cheetah, BCQ, Cosine Distance

rluply

11.1

5.3

30.2

99.9

98.8

95.2

99.9

3.9

96.1

99.6

expert

medium random
Half Cheetah, IQL, Cosine Distance

rluply

5.9

99.9

92.1

2.9

55.5

99.9

1.4

99.0

99.4

99.1

97.6

medium random
expert
Half Cheetah, BCQ, Wasserstein Distance

rluply

97.2

99.7

96.7

97.2

96.3

expert
rluply
medium random
Half Cheetah, IQL, Wasserstein Distance

99.5

92.5

98.5

98.0

expert

medium random
Half Cheetah, TD3PlusBC, L1 Norm

rluply

expert

medium random
Half Cheetah, TD3PlusBC, L2 Norm

rluply

expert

medium random
Half Cheetah, TD3PlusBC, Cosine Distance

rluply

expert

medium random
Half Cheetah, TD3PlusBC, Wasserstein Distance

rluply

expert

90.3

92.8

95.6

96.1

94.8

96.1

6.9

99.9

4.8

45.1

89.5

expert

medium random

98.0

rluply

expert

medium random

98.3

rluply

expert

medium random

2.2

98.3

99.6

rluply

98.9

96.4

99.1

expert

medium random

98.7

rluply

medium

random

rluply

medium

random

rluply

Fig. 25: The audit accuracy of ORL-AUDITOR on Lunar Lander when splitting each trajectory into shorter ones (S = 5). The
caption of each plot demonstrates the offline DRL model’s type, the task, the distance metric, and the hyperparameter S of
trajectory splitting. The x labels are the names of datasets to be audited, i.e., the target datasets. The y labels are the names of
datasets the suspect models learned, i.e., the actual datasets. Thus, the diagonal values show the audit accuracy when the actual
dataset is the same as the target dataset, i.e., TPR, and the non-diagonal values are the TNR results. The positions without value
mean 100% accuracy.

35

Lunar Lander, BC, L1 Norm, split 5

Lunar Lander, BC, L2 Norm, split 5

Lunar Lander, BC, Cosine, split 5

Lunar Lander, BC, Wasserstein, split 5

96.9

95.9

96.8

95.9

97.2

98.1

97.2

98.1

99.5

99.8

99.9

98.3

99.9

99.2

97.2

98.7

1171

99.1

2094

4496

6518

9906

98.5

98.8

99.9

1171

2094

4496
Lunar Lander, BCQ, L1 Norm, split 5

6518

98.8
9906

1171

2094

4496
Lunar Lander, BCQ, L2 Norm, split 5

6518

96.7
9906

1171

2094

4496
Lunar Lander, BCQ, Cosine, split 5

6518

96.8
9906

1171

98.5

96.4

99.5

97.9

95.5

94.1

95.2

94.4

99.9

96.8

95.6

96.9

95.6

1171

2094

4496
Lunar Lander, IQL, L1 Norm, split 5

6518

99.2
9906

1171

2094

4496
Lunar Lander, IQL, L2 Norm, split 5

6518

97.3
9906

1171

2094

4496
Lunar Lander, IQL, Cosine, split 5

6518

97.2
9906

99.5

99.7

99.1

99.5

99.9

96.0

99.6

94.4

99.1

99.6

99.6

99.4

99.4

99.9

94.0

98.6
2094

97.6
1171
9906
4496
Lunar Lander, TD3PlusBC, L1 Norm, split 5
97.7

99.9
6518

94.5
1171
9906
4496
Lunar Lander, TD3PlusBC, L2 Norm, split 5
92.8

2094

6518

2094

94.8
1171
9906
4496
Lunar Lander, TD3PlusBC, Cosine, split 5
92.4

6518

99.9
2094

98.5
9906
4496
1171
Lunar Lander, BCQ, Wasserstein, split 5
97.7
99.9
99.6

6518

96.5

99.9

99.9

99.9

99.2

99.5

99.6

96.1

99.8
2094

1171

4496
Lunar Lander, IQL, Wasserstein, split 5
74.8

6518

99.6

97.6

89.4

98.4
9906

98.9

98.5

99.1

99.2

99.5

98.4

98.9

99.7

94.9

95.5

99.9

96.9

98.9
1171

95.7
2094

99.9
4496
Lunar Lander, TD3PlusBC, Wasserstein, split 5
87.1

99.9
6518

98.3
9906

99.5

97.9

98.7

93.4

99.9

98.1

94.5

98.9
1171

98.5
2094

99.7
4496

98.1

99.5

98.0
6518

98.3

99.9
9906

99.9

98.9

99.9

92.5

99.1
1171

99.9
2094

99.7
4496

99.9

98.7
9906

98.8

99.5
6518

99.9

98.8

99.5

99.1
1171

2094

92.4

99.7
4496

98.7

6518

99.1
9906

98.9

94.7

93.9
1171

99.6

97.3

99.1

93.3
2094

98.9

96.4

98.6

94.5
4496

94.4

94.1

99.1

96.7
6518

85.6

96.5

96.7

99.7
9906

2094

4496

6518

9906

1171

2094

4496

6518

9906

1171

2094

4496

6518

9906

Fig. 26: The audit accuracy of ORL-AUDITOR on Bipedal Walker when splitting each trajectory into shorter ones (S = 5).
The caption of each plot demonstrates the offline DRL model’s type, the task, the distance metric, and the hyperparameter S of
trajectory splitting. The x labels are the names of datasets to be audited, i.e., the target datasets. The y labels are the names of
datasets the suspect models learned, i.e., the actual datasets. Thus, the diagonal values show the audit accuracy when the actual
dataset is the same as the target dataset, i.e., TPR, and the non-diagonal values are the TNR results. The positions without value
mean 100% accuracy.

36

0841

1203

2110

3813

6558

1203

2110

3813

6558

0841

1203

2110

3813

6558

0841

1203

2110

Bipedal Walker, BC, L1 Norm, split 5

Bipedal Walker, BC, L2 Norm, split 5

Bipedal Walker, BC, Cosine, split 5

Bipedal Walker, BC, Wasserstein, split 5

98.5

98.9

99.2

99.9

0841

1203

2110
Bipedal Walker, BCQ, L1 Norm, split 5

3813

99.7
6558

0841

1203

2110
Bipedal Walker, BCQ, L2 Norm, split 5

3813

93.1
6558

0841

1203

2110
Bipedal Walker, BCQ, Cosine, split 5

3813

93.3
6558

0841

99.9

1203

6558
2110
0841
Bipedal Walker, BCQ, Wasserstein, split 5
99.9

3813

98.1

92.7

99.7

98.3

99.7

99.9

99.7

99.9

0841

1203

2110
Bipedal Walker, IQL, L1 Norm, split 5

3813

6558

0841

1203

2110
Bipedal Walker, IQL, L2 Norm, split 5

3813

6558

0841

1203

2110
Bipedal Walker, IQL, Cosine, split 5

3813

98.8
6558

1203

0841
6558
2110
Bipedal Walker, IQL, Wasserstein, split 5

3813

99.7

80.8

93.7

85.1

99.9

97.6

95.5

96.4

99.2

81.5

97.6

0841

2110
Bipedal Walker, TD3PlusBC, L1 Norm, split 5

3813

1203

99.9
6558

10.4

1203

0841

2110
Bipedal Walker, TD3PlusBC, L2 Norm, split 5
89.3

3813

0.7

99.9
6558

1203

0841
6558
2110
Bipedal Walker, TD3PlusBC, Cosine, split 5
87.9

3813

99.7

0.1

0841

2110
Bipedal Walker, TD3PlusBC, Wasserstein, split 5

3813

6558

1203

1.9

48.0

3813

96.0

98.0

94.9

6558

0841

1203

2110

3813

96.0

96.9
6558

94.0

96.0

96.4

0841

1203

2110

3813

99.7

92.0

94.0

94.4

0841

1203

2110

3813

97.1

94.0

85.7
6558

79.6

92.0

84.9
6558

92.1

94.2

98.0

94.5

43.9

0841

1203

2110

3813

92.0

90.7
6558

Fig. 27: The audit accuracy of ORL-AUDITOR on Ant when splitting each trajectory into shorter ones (S = 5). The caption
of each plot demonstrates the offline DRL model’s type, the task, the distance metric, and the hyperparameter S of trajectory
splitting. The x labels are the names of datasets to be audited, i.e., the target datasets. The y labels are the names of datasets
the suspect models learned, i.e., the actual datasets. Thus, the diagonal values show the audit accuracy when the actual dataset
is the same as the target dataset, i.e., TPR, and the non-diagonal values are the TNR results. The positions without value mean
100% accuracy.

37

Ant, BC, Cosine, split 5
98.0
57.6

97.6

99.9

12.0

99.9

Ant, BC, Wasserstein, split 5

99.9

98.1

99.5

99.7

99.9

99.5

99.5

99.7

99.8

97.6

Ant, BC, L1 Norm, split 5
99.9

98.0

99.6

99.9

99.9

99.8

95.6

3569

4603
Ant, BCQ, L1 Norm, split 5

5766

99.9

97.7

98.7

98.7

99.9

92.0

99.9

98.4
7490

96.8

99.9

2232

94.4

99.1

Ant, BC, L2 Norm, split 5
98.3

96.0

99.9

99.2

94.7

3569

4603
Ant, BCQ, L2 Norm, split 5

5766

98.3

95.2

99.5

98.0

99.9

92.8

3569
5766
4603
Ant, IQL, L1 Norm, split 5

7490

2232

3569
5766
4603
Ant, IQL, L2 Norm, split 5

99.9

99.6

97.5

98.1

97.9

99.9

99.6

99.9

98.7

97.3

92.0

98.9

99.9

98.1

96.9

98.5

99.9

98.7

98.3

99.7

99.9

2232

97.6

98.9

2232

94.5

98.5

99.8

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

2232

3569

4603
Ant, TD3PlusBC, L1 Norm, split 5

5766

96.1
7490

2232

3569

4603
Ant, TD3PlusBC, L2 Norm, split 5

5766

98.9
7490

2232

3569

99.1

99.8

96.1

4603

5766

97.5

99.6

7490

98.3

97.4

92.5

98.0

98.8

98.3

99.5

96.1

98.2

99.7

99.0

94.8

92.2

99.0

99.5

99.9

97.2
7490

99.9

99.6

99.9

11.0
2232

99.9

99.5

99.1
7490

8.9
2232

95.9

99.7

59.1
99.6
88.5
5766
4603
3569
Ant, BCQ, Cosine, split 5
98.1
64.9

98.4

99.5

95.2

65.1
93.0
3569
5766
4603
Ant, IQL, Cosine, split 5
67.0
99.9
98.7

11.6

99.9
7490

15.5

99.5

99.8

99.3

98.4

99.1

99.7

92.3

99.9

8.1
2232

99.9

99.6

98.2

7.9
2232

91.8
3569

99.7
4603
Ant, TD3PlusBC, Cosine, split 5

47.5
5766

99.2

99.2

99.7

92.7
3569

92.2

4603

82.6

99.1

89.2

91.7
5766

96.8
7490

99.9

95.6
7490

99.9

7490

99.6

99.9

7490

2232

3569

4603
Ant, BCQ, Wasserstein, split 5

5766

13.1

99.9

98.0

98.9

98.5

99.9

98.6

99.9

96.1

7490

2232

3569

4603
Ant, IQL, Wasserstein, split 5

5766

99.9

98.9

99.7

98.5

99.8

97.5

99.2

97.6

99.9

2232

3569

4603
Ant, TD3PlusBC, Wasserstein, split 5

5766

98.7
7490

99.8

99.5

99.1

97.5

99.5

98.3

96.6

92.0

97.8

98.7

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

2232

3569

4603

5766

7490

Fig. 28: The audit accuracy of ORL-AUDITOR on Half Cheetah when splitting each trajectory into shorter ones (S = 5). The
caption of each plot demonstrates the offline DRL model’s type, the task, the distance metric, and the hyperparameter S of
trajectory splitting. The x labels are the names of datasets to be audited, i.e., the target datasets. The y labels are the names of
datasets the suspect models learned, i.e., the actual datasets. Thus, the diagonal values show the audit accuracy when the actual
dataset is the same as the target dataset, i.e., TPR, and the non-diagonal values are the TNR results. The positions without value
mean 100% accuracy.

38

Half Cheetah, BC, L1 Norm, split 5

Half Cheetah, BC, L2 Norm, split 5

Half Cheetah, BC, Cosine, split 5

Half Cheetah, BC, Wasserstein, split 5

expert

99.7

medium

random

rluply

98.0

97.6

94.4

99.5

91.7

7.7

3.8

30.6

96.3

95.5

99.8

3.5

97.7

99.5

expert

medium random
Half Cheetah, BCQ, L1 Norm, split 5

rluply

expert

medium random
Half Cheetah, BCQ, L2 Norm, split 5

rluply

expert

medium random
Half Cheetah, BCQ, Cosine, split 5

rluply

expert

99.2

97.3

medium

random

rluply

95.3

97.9

90.5

97.2

95.6

95.2

94.7

99.9

7.6

2.7

26.9

3.1

92.3

99.7

expert

medium random
Half Cheetah, IQL, L1 Norm, split 5

rluply

expert

medium random
Half Cheetah, IQL, L2 Norm, split 5

rluply

expert

medium random
Half Cheetah, IQL, Cosine, split 5

rluply

expert

99.9

medium

random

rluply

97.9

96.9

97.6

99.3

94.2

7.9

99.9

94.9

95.3

95.9

94.6

5.3

61.9

99.6

2.7

99.6

99.5

98.7

98.3

rluply
medium random
expert
Half Cheetah, BCQ, Wasserstein, split 5

97.5

99.7

96.7

97.2

96.1

expert
rluply
medium random
Half Cheetah, IQL, Wasserstein, split 5

99.3

92.4

98.5

98.0

expert

medium random
Half Cheetah, TD3PlusBC, L1 Norm, split 5

rluply

expert

medium random
Half Cheetah, TD3PlusBC, L2 Norm, split 5

rluply

expert
rluply
medium random
Half Cheetah, TD3PlusBC, Cosine, split 5

expert

medium random
Half Cheetah, TD3PlusBC, Wasserstein, split 5

rluply

expert

99.1

96.9

95.6

97.2

94.8

96.3

medium

random

rluply

expert

medium random

98.3

rluply

expert

medium random

98.1

rluply

expert

medium random

99.7

90.9

6.9

4.7

52.3

1.6

98.1

98.5

rluply

98.9

96.5

99.3

expert

medium random

98.7

rluply

","ORL-AUDITOR : Dataset Auditing in Offline Deep Reinforcement Learning 3 2 0 2 p e S 6 ] R C . s c [ 1 v 1 8 0 3 0 . 9 0 3 2 : v i X r a Linkang Du†∗ , Min Chen‡∗ , Mingyang Sun† , Shouling Ji† , Peng Cheng† , Jiming Chen† , Zhikun Zhang†‡§¶ † Zhejiang University , Hangzhou 310017 , China Email : linkangd @ gmail.com , sji @ zju.edu.cn , saodiseng @ gmail.com , cjm @ zju.edu.cn ‡CISPA Helmholtz Center for Information Security , Saarbr¨ucken 66123 , Germany Email : min.chen @ cispa.de §Stanford University , Stanford , California 94305 , USA Email : zhikun @ stanford.edu Abstract—Data is a critical asset in AI , as high-quality datasets can significantly improve the performance of machine learning models . In safety-critical domains such as autonomous vehicles , offline deep reinforcement learning ( offline DRL ) is frequently used to train models on pre-collected datasets , as opposed to train- ing these models by interacting with the real-world environment as the online DRL . To support the development of these models , many institutions make datasets publicly available with open- source licenses , but these datasets are at risk of potential misuse or infringement . Injecting watermarks to the dataset may protect the intellectual property of the data , but it can not handle datasets that have already been published and is infeasible to be altered afterward . Other existing solutions , such as dataset inference and membership inference , do not work well in the offline DRL scenario due to the diverse model behavior characteristics and offline setting constraints . In this paper , we advocate a new paradigm by leveraging the fact that cumulative rewards can act as a unique identifier that distinguishes DRL models trained on a specific dataset . To this end , we propose ORL-AUDITOR , which is the first trajectory- level dataset auditing mechanism for offline RL scenarios . Our experiments on multiple offline DRL models and tasks reveal the efficacy of ORL-AUDITOR , with auditing accuracy over 95 % and false positive rates less than 2.88 % . We also provide valuable insights into the practical implementation of ORL- AUDITOR by studying various parameter settings . Furthermore , we demonstrate the auditing capability of ORL-AUDITOR on open-source datasets from Google and DeepMind , highlighting its effectiveness in auditing published datasets . ORL-AUDITOR is open-sourced at https : //github.com/link-zju/ORL-Auditor . I . INTRODUCTION Deep reinforcement learning ( DRL ) has been successfully applied to many complex decision-making tasks , such as autopilot [ 17 ] , robot control [ 3 ] , [ 51 ] , power systems [ 70 ] , intrusions detection [ 42 ] , [ 67 ] . However , for safety-critical domains , such as robot control , directly interacting with the environment is unsafe since the partially trained policy may ∗The first two authors made equal contribution . ¶Zhikun Zhang is the corresponding author . Network and Distributed System Security ( NDSS ) Symposium 2024 26 February - 1 March 2024 , San Diego , CA , USA ISBN 1-891562-93-2 https : www.ndss-symposium.org risk damage to robot hardware or surrounding objects [ 55 ] . To address this issue , researchers propose the offline deep reinforcement learning ( Offline DRL ) [ 37 ] paradigm , also known as full batch DRL [ 36 ] . The general idea is learning from pre-collected data generated by the expert , handcrafted controller , or even random strategy respecting the system ’ s constraints . [ 4 ] , Berkeley Artificial To facilitate the research of offline DRL , several high- quality datasets are published by third parties such as Deep- Mind [ 26 ] , Intelligence Research ( BAIR ) [ 18 ] , Polixir Technologies [ 52 ] , TensorFlow [ 1 ] , and Max Planck Institute [ 27 ] . These datasets are published with strict open-source licenses , such as GNU General Public License [ 4 ] , Apache License [ 26 ] , [ 18 ] , [ 1 ] , [ 52 ] , and BSD 3- Clause License [ 27 ] , to protect the intellectual property ( IP ) of the data owner . The licenses typically encompass two essential terms . 1 ) Attribution requires you ( the users ) to appropriately acknowledge the source , provide a link to the license , and indicate any modifications made . 2 ) ShareAlike stipulates that if you remix , transform , or build upon the material , you must distribute your contributions under the same license as the original . Furthermore , some datasets are accompanied by additional patent grants aimed at safeguarding the rights of data publishers , e.g . StarData [ 40 ] . Additionally , closed-form datasets have the potential to face misuse from insider attacks or intellectual property infringement ( e.g. , ex-employees steal- ing data ) . Biscom ’ s 2021 survey finds that 25 % of respondents admitted to taking the valuable data when leaving their job , with 95 % citing a lack of policies or technologies to prevent data theft [ 5 ] . Tessian reports that 40 % of US employees take their generated data or trained models when leaving their job [ 61 ] . The defense against the above threats comes to the question of how a data owner can prove that a suspect model was derived from its dataset . Existing Solutions . Recent mainstream solutions for dataset copyright protection can be classified into three categories : Watermarking , dataset inference , and membership inference . The watermarking approach aims to inject samples from a specific distribution prior to publishing the dataset [ 39 ] , the auditor needs a post-event mechanism [ 38 ] . However , for open-source data since they are already published in the real world . In contrast to watermarking techniques , dataset inference strategies [ 43 ] , [ 16 ] do not require the injection of explicit watermarks [ 6 ] into the datasets or trained models . To implement the auditing , we first train a critic model to predict the cumulative rewards of the state-action pairs in the dataset to be audited , i.e. , the target dataset . A straightfor- ward strategy to derive the auditing result is to compare the cumulative reward of the state-action pairs from the suspect model to that of the target dataset through a preset judgment threshold of the similarity . However , designing the threshold value is challenging , as it depends on the distributions of pre- collected datasets , which can vary due to different task settings , collection procedures , and data post-processing methods . To address this issue , we recognize that the cumulative rewards embedded in the state-action pairs of the models are the esti- mated cumulative rewards of the target dataset , as the offline DRL models fit the cumulative reward of the dataset during training . Thus , we train multiple models on the target dataset with varying initializations and optimization , i.e. , the shadow models , and collect the cumulative rewards of their state-action pairs . Finally , by comparing the cumulative rewards from the suspect model and the shadow models , we make the audit decision through hypothesis testing . Evaluation . The experimental results show that the auditing accuracy of ORL-AUDITOR exceeds 95 % with false positive rates less than 2.88 % across multiple DRL models and tasks . By visualizing the cumulative rewards from the shadow models trained on different datasets , we demonstrate that the cumula- tive reward is a distinguishable feature for the dataset audit . We further evaluate three influential factors for the practical adop- tion of ORL-AUDITOR , i.e. , the number of shadow models , the significance level in hypothesis testing , and the trajectory size . First , more shadow models improve the audit accuracy , and ORL-AUDITOR demonstrates exceptional performance with an audit accuracy exceeding 90 % , utilizing a mere 9 shadow models as illustrated in Table VIII . Second , the minimum sig- nificance level α of ORL-AUDITOR is about 0.001 , meaning that the auditor outputs a single result with 99.9 % confidence . Third , ORL-AUDITOR tends to obtain higher accuracy with a larger trajectory size , yet we also notice that a small trajectory size achieves better results under some tasks [ 46 ] . We further implement ORL-AUDITOR to audit the open-source datasets from Google [ 18 ] and DeepMind [ 26 ] , and the experimental results again demonstrate the effectiveness of ORL-AUDITOR in practice . Robustness . To evaluate the robustness of ORL-AUDITOR , we have implemented two defense strategies to prevent the auditing . The first strategy involves using state-of-the-art mem- bership inference defense techniques , such as the ensemble architecture proposed by Tang et al . [ 60 ] and Jarin et al . [ 31 ] . Despite these defense mechanisms , the audit accuracy of ORL-AUDITOR is still over 85 % . In addition to the ensem- ble architecture , the suspect models may distort actions to hide their training dataset . The offline DRL models for real- world decision-making tasks ( i.e. , self-driving cars ) often use Gaussian noise to model natural distortions [ 2 ] . Thus , adding Gaussian noise to the actions is stealthy to avoid the auditor ’ s detection , and Gaussian noise is convenient for mathematical manipulation . To simulate strong and weak action distortion , we normalize all dimensions of the action space to [ −1 , 1 ] and use Gaussian noise with ( µ = 0 , σ = 0.1 ) and ( µ = 0 , σ = 0.01 ) , respectively . Our experiments show that ORL- AUDITOR is only slightly affected by Gaussian noise with Fig . 1 : Intuitive explanation of ORL-AUDITOR . The middle surface is the cumulative rewards of the state-action pairs from a dataset . The auditor outputs a positive result if the cumulative rewards of a suspect model ’ s state-action pairs are between the two outer surfaces . Maini et al . [ 43 ] and Dziedzic et al . [ 16 ] have separately proposed dataset inference methods for supervised learning and self-supervised learning models , enabling the model owner to provide a convincing statistical argument that a particular model is trained on their private data . However , the dataset inference with labels [ 43 ] needs distances between data and decision boundaries , which is not possible to obtain in RL with continuous outputs . The dataset inference without labels [ 16 ] uses the similarity of model behaviors to detect unauthorized dataset usage . It requires a public dataset to generate some surrogate models , and forms the auditing basis by comparing the behavioral difference between the surrogate models and the models trained on their private data . In offline RL scenes , since the distributions of the collected datasets depend on both environment and operator [ 18 ] , it is difficult to determine a suitable public dataset to train the surrogate model , making the audit basis hard to establish . The third category adopts the notion of membership inference [ 47 ] , [ 24 ] , [ 23 ] . By collecting the RL models ’ behaviors on the trained examples ( members ) and the untrained examples ( non-members ) , a classifier is constructed to determine whether a data sample is used in the model ’ s learning process . However , unlike online scenarios in [ 47 ] , [ 24 ] , [ 23 ] , the auditor can not collect additional data from the environment as the non-member examples in offline cases , where the auditor does not have access to the environment . Our Proposal . In this paper , we propose the first practical dataset auditing paradigm for the offline RL model ( ORL- AUDITOR ) . Concretely , we are inspired by the fact that the cumulative reward , i.e. , the sum of all rewards received over a period of time starting from a given state-action pair , guiding the RL model to learn the behavior policy . Thus , the cumu- lative reward is an intrinsic feature of the datasets , making it suitable as an audit basis . Figure 1 provides a schematic diagram of ORL-AUDITOR , where the state , the action , and the cumulative reward compose a three-dimensional space . The middle surface illustrates the exact cumulative reward of the dataset , and the other two surfaces show possible offsets of the exact cumulative reward learned by the offline DRL models due to the randomness in the initialization and the learning processes . For a suspect model , the auditor outputs a positive result , i.e. , the data is used to train this model , if the cumulative reward from its state-action pair falls between the two surfaces ; otherwise , a negative outcome . 2 Cumulative Reward 𝑄𝑄 𝑠𝑠 , 𝑎𝑎 + ∆ 𝑄𝑄 ( 𝑠𝑠 , 𝑎𝑎 ) 𝑄𝑄 𝑠𝑠 , 𝑎𝑎 − ∆ State : 𝑠𝑠 Action : 𝑎𝑎 Positive Negative Share Help/Contact ( µ = 0 , σ = 0.01 ) . For σ = 0.1 , the TPR values of ORL- AUDITOR decline , yet the strong distortion also impacts the performance of the suspect model , especially in complex tasks . Contributions . Our contributions are three-fold : • To our knowledge , ORL-AUDITOR is the first dataset audit- ing method for the offline DRL models , using the cumulative reward as an intrinsic and stable fingerprint of the dataset . • We demonstrate the effectiveness of ORL-AUDITOR on four offline DRL models and three tasks . We also systematically analyze various experimental factors , i.e. , the hyperparam- eter settings and the robustness of ORL-AUDITOR , and summarize some important guidelines for adopting ORL- AUDITOR in practice . • By implementing ORL-AUDITOR on the open-source datasets from DeepMind [ 26 ] and Google [ 18 ] , we show that ORL-AUDITOR can serve as a potent audit solution in real-world offline DRL scenarios . II . BACKGROUND A. Offline RL Problem The offline reinforcement learning ( offline RL ) model aims to learn an optimal ( or nearly optimal ) policy from a pre- collected dataset D without an interactive environment . We use S and A to represent the RL models ’ input and output space , formally called state and action in RL scenes . rt ∈ R is the temporal reward for each time step , where R is the real number set . A unit in a pre-collected dataset called transition is a four- element set : { st , at , rt , st+1 } , where st ∈ S , at ∈ A , and st+1 ∈ S is the successive state of st. And a set of transitions in chronological order forms a trajectory in dataset D. Based on the transitions , the offline RL model learns the Markov Decision Process underneath the datasets and forms a policy πθ ( a | s ) to maximize J ( π ) . J ( π ) = Est∼dβ ( s , a ) , at∼πθ ( a|s ) ( cid:35 ) γtrt , ( cid:34 ) H ( cid:88 ) t=0 where we use dβ to denote the distribution over states and actions in dataset D , and the actions are sampled according to the behavior policy at ∼ πθ ( a | s ) . The discount factor γ is applied to discount future rewards in the accumulated reward . H is the terminal time step of one trajectory . Example . Figure 2 shows an example based on the “ CartPole ” task . 1 In the data collection process , the dataset is generated from the operation logs between the operator and the envi- ronment , which contains the position and velocity of the cart and the pole ( i.e. , state ) , the operator ’ s force direction ( i.e. , action ) , and the corresponding rewards . Then , in the training and evaluation process , the offline RL model learns how to play the “ Cartpole ” task from only the pre-collected dataset generated through the data collection process . Finally , we deploy the well-trained offline RL model in the environment to perform the task . 1https : control/cart pole/ Fig . 2 : A running example of the offline DRL models . B. Offline RL Models In this section , we first introduce two offline RL algo- rithms [ 21 ] , [ 19 ] , [ 35 ] separately representing two basic ideas of the offline RL models , i.e. , the policy constraints strategy and the value function regularization strategy [ 50 ] . Many state- of-the-art model-free offline RL methods [ 68 ] , [ 32 ] , [ 20 ] , [ 35 ] have been modified from these two approaches . We further present a state-of-the-art algorithm [ 20 ] which is minimalistic with light computation and hyperparameter setting overhead . In addition , we briefly describe the behavior clone method ( BC ) [ 49 ] , which learns the state-action distribution over the dataset via a supervised learning approach . Though BC is not a typical reinforcement learning method , it can solve the offline RL problem and usually serves as the baseline method in the offline RL evaluation . Behavior Clone ( BC ) [ 49 ] . BC separately takes the pairwise state s and action a in the datasets as input and label , then it optimizes the policy through the following function . θ∗ = arg min θ E ( s , a ) ∼D [ L ( πθ ( s ) , a ) ] , where D is the pre-collected dataset and L is the loss function . Since BC only imitates action distributions , the performance is close to the mean of the dataset , even though BC works better than online RL algorithms in most cases . Batch-Constrained Q-learning ( BCQ ) [ 21 ] , [ 19 ] . BCQ is the first practical data-driven offline RL algorithm . The key idea of BCQ is to integrate a generative model to achieve the notion of batch-constrained , i.e. , minimizing the deviation between the candidate actions with the action records of the dataset . To maintain the diversity of action , BCQ builds a perturbation model to perturb each selected action . Then it chooses the highest-valued action through a Q-network , that learns to estimate the expected cumulative reward of a given state and action pair . Thus , the objective function of BCQ can be defined as the following . π ( s ) = argmax Qθ ( s , ai + ξϕ ( s , ai , Φ ) ) ai+ξϕ ( s , ai , Φ ) { ai ∼ Gω ( s ) } n i=1 , where Gω ( s ) is a conditional variational auto-encoder ( VAE ) - based [ 33 ] generative model that can be used to generate candidate actions . The value function Qθ is used to score the n candidate actions and finds the action with the highest value . ξϕ ( s , ai , Φ ) is the perturbation model , which outputs 3 Dataset … , 𝒔𝒔𝒕𝒕 , 𝒂𝒂𝒕𝒕 , 𝒓𝒓𝒕𝒕 , 𝒔𝒔𝒕𝒕 '' 𝟏𝟏 , … State , Reward Move Left , R = 1 Move Right , R = 1 Move Left , R = 1 Action Environment Operator Offline DRL Model Environment Action Offline DRL Model State Data Collection Training and Evaluation Deployment an adjustment to an action a in the range [ −Φ , Φ ] . Then , the perturbation model can be optimized by the deterministic policy gradient algorithm [ 58 ] as follows . ϕ ← argmax ( cid:88 ) ϕ ( s , a ) ∈B Qθ ( s , a + ξϕ ( s , a , Φ ) ) , where B represents a mini-batch state-action pair in the dataset . To penalize rare states , BCQ takes a convex combination of the values from two Q-networks and sets a new target value y to update both Q-networks . ( cid:20 ) y = r+γ max ai λ min j=1,2 Qθ′ j ( s′ , ai ) + ( 1 − λ ) max j=1,2 Qθ′ j ( cid:21 ) ( s′ , ai ) where ai corresponds to the perturbed actions , sampled from the generative model Gω ( s ) . Implicit Q-Learning ( IQL ) [ 35 ] . Compared to the batch- constrained idea of BCQ [ 21 ] , [ 19 ] , IQL strictly avoids query- ing values of the actions , which are not in the pre-collected dataset . IQL first constructs a model to evaluate the expected returns of state-action pairs . The objective function is defined as shown in Equation 1 . L ( θ ) = ED ( cid:2 ) Lτ 2 ( cid:0 ) r ( s , a ) + γQˆθ ( s′ , a′ ) − Qθ ( s , a ) ( cid:1 ) ( cid:3 ) , ( 1 ) 2 ( u ) = |τ − 1 ( u < 0 ) |u2 , and s′ and a′ represent where Lτ the successor state and action of s and a . Both Qθ ( s , a ) and Qˆθ are used to assess the expected returns of state- action pairs . The parameters of Qθ ( s , a ) are adjusted in each optimization round , while the parameters of Qˆθ are updated periodically based on Qθ ( s , a ) to reduce parameter fluctuations during model updates . Equation 1 involves the dynamics of the environment , where the environment state s transitions to the next environment state s′ , potentially introducing interference in the evaluation of expected returns for state-action pairs . IQL addresses this issue by introducing a new state value model , splitting Equation 1 into two objective functions . Equation 2 shows the objective function of the state value model Vψ . LV ( ψ ) = ED ( cid:2 ) Lτ 2 ( cid:0 ) Qˆθ ( s , a ) − Vψ ( s ) ( cid:1 ) ( cid:3 ) . ( 2 ) Then , IQL utilizes Vψ ( s ) to construct Equation 3 for updating the parameters of the state-action value model Qθ . LQ ( θ ) = ED ( cid:104 ) ( r ( s , a ) + γVψ ( s′ ) − Qθ ( s , a ) ) 2 ( cid:105 ) . ( 3 ) Finally , IQL considers using the state-action value model to construct a behavior policy for deployment . This behavior policy also needs to avoid actions that are outside the dataset distribution . Thus , IQL employs advantage-weighted regres- sion to update the policy model . Lπ ( ϕ ) = ED [ exp ( β ( Qθ ( s , a ) − Vψ ( s ) ) ) log πϕ ( a | s ) ] , ( 4 ) where β ∈ [ 0 , ∞ ) represents the inverse temperature . For smaller values of β , IQL is similar to behavior clone , tending to mimic the data collection policy . For larger values of β , IQL is more inclined to select actions corresponding to the highest expected returns according to the state-action value model . Throughout the entire training process , IQL alternates between optimizing the parameters θ and ψ , and then updates ϕ while keeping θ and ψ fixed . TD3PlusBC [ 20 ] . The former methods [ 21 ] , [ 19 ] , [ 35 ] limit or regularize action selection such that the learned policy is easier to evaluate with the given dataset . However , they introduce new hyperparameters and often leverage secondary components , such as generative models , while adjusting the underlying RL algorithm . TD3PlusBC is a minimalist and highly effective offline RL algorithm based Twin Delayed Deep Deterministic Policy Gradient ( TD3 ) [ 22 ] with BC regularization term , which pushes the policy towards favoring actions contained in the dataset D : π = argmax E ( s , a ) ∼D , π ( cid:2 ) λQ ( s , π ( s ) ) − ( π ( s ) − a ) 2 ( cid:3 ) , α 1 N ( cid:80 ) where λ = ( s , a ) |Q ( s , a ) | for the dataset of N transitions ( s , a ) . To facilitate the policy training , TD3PlusBC normalizes each state in the given dataset by si = si−µ σ+ϵ , where µ and σ are the mean and standard deviation respectively . The model architectures vary significantly regarding objec- tive function and basic model structure . 1 ) Objective Function : BCQ [ 21 ] , [ 19 ] and TD3PlusBC [ 20 ] use a policy constraints strategy to maintain the learned policy similar to the one used for collecting the dataset . In contrast , IQL [ 35 ] adopts a regularization strategy to improve the stochasticity of the learned policy or obtain more accurate Q-value estimations . 2 ) Basic Model Structures : BCQ [ 21 ] , [ 19 ] and IQL [ 35 ] are based on the Q-learning model , while TD3PlusBC [ 20 ] builds upon TD3 [ 22 ] . In Section V , our experiments are mainly conducted on the above four algorithms . However , ORL-AUDITOR can also be applied to any type of offline DRL model as long as the auditor has black-box access to the suspect model . III . PROBLEM STATEMENT AND EXISTING SOLUTIONS A . System and Threat Model the dataset Application Scenarios . Figure 3 illustrates a typical ap- plication scenario where the data providers collect and then publish or sell to the customers . A malicious customer ( adversary ) with access to the datasets makes a piracy distribution or illegally builds a Model-as-a-Service ( MaaS ) platform . Institution 1 suspects the models are generated by its dataset , and thus hires an auditor to determine whether the model trainers pirate the trajectories of the dataset D1 . Auditor ’ s Background Knowledge and Capability . The auditor has full knowledge of the target dataset , such as the number of trajectories and the spaces of state and action . In offline RL settings , the auditor is prohibited from interacting with the online environment to collect more data , meaning the entire auditing only depends on the target dataset . We consider the auditor has black-box access to the suspect RL model . Note that this is the most general and challenging scenario for the auditor . A typical application scenario is that an adver- sary receives the model settings from customers , such as the selected offline RL framework , the model ’ s hyperparameter , and the desired training episodes . Then , the adversary trains an offline RL model and provides a service interface to the customers . The auditor utilizes the states of the dataset ( inputs ) to query the suspect model and obtain the corresponding actions ( outputs ) . 4 explicit watermarks [ 6 ] to the datasets or the trained models . Existing methods [ 43 ] , [ 16 ] can be divided into two categories according to whether they have explicit classification labels . With the explicit classification labels , [ 43 ] rely on computing the distances between data points and decision boundaries . Without the explicit classification labels , [ 16 ] utilizes the similarity of the models ’ behaviors to detect the unauthorized usage of the dataset , which requires the assumption of an additional public dataset with a similar distribution to form the auditing basis . However , the above methods can not directly be applied to reinforcement learning cases due to two reasons . First , the label-based dataset inference [ 43 ] can not be implemented in the RL models since their outputs are usually continuous , and they are guided by the rough reward signals instead of the exact labels . Second , the distribution of the offline RL dataset not only depends on the environment but also relies on the strategy of interacting with the environment [ 18 ] . Thus , it is challenging to find a proper public dataset in offline RL scenarios . As we delve into Appendix A , it becomes evident that the behavior similarity of the DRL models varies across different public training data . Furthermore , the behavior similarity is also influenced by various offline DRL frameworks . Membership Inference Attack against RL [ 47 ] , [ 24 ] , [ 23 ] . Several membership inference attacks exist against DRL , which seem to address the problem studied in this paper . Most of them are targeted at the online RL scenes , assuming that the attacker owns the environment . Thus , they can utilize the environment to collect more data and even manipulate some adversarial states to facilitate the inference . However , in this paper , we aim at the offline RL cases , which are more challenging since the only thing the auditor can use is the pre-collected dataset . That is , in offline RL scenarios , the existing MIA against RL can not rely on the environment to generate non-member data . IV . ORL-AUDITOR We instantiate Q of Figure 1 with the cumulative reward , which is an intrinsic feature of the dataset and suitable for auditing . ∆ is determined by the shadow models trained on the datasets instead of a preset threshold to adapt the distribution of different datasets . Thus , the well-designed Q and ∆ guarantee the adaptiveness and effectiveness of ORL-AUDITOR . A. Workflow For ease of understanding , we refer to the target dataset as the dataset to be audited and the actual dataset as the dataset used by the suspect model . If the suspect model is trained on the target dataset , the actual dataset is the same as the target dataset , i.e. , positive audit result for the suspect model ; otherwise , the suspect model does not use the target dataset , i.e. , negative audit result for the suspect model . Figure 4 illustrates the workflow of ORL-AUDITOR . Fig . 3 : An example of the application scenario . The auditor can obtain all information about dataset D1 but has no knowledge about the datasets from other institutions . Discussion . Compared to the sample-level and dataset-level data in DNN scenes , RL has trajectory-level data , which is the minimum record unit of sequential interactions between the operator and environment . Since a single trajectory can guide the model from the initial state to the terminal , the trajectory-level data is regarded as the value unit of the dataset . Thus , ORL-AUDITOR is designed to audit the dataset from the trajectory level , where the auditor tries to decide whether the suspect model uses a specific trajectory in the dataset . In addition , the auditor can easily extend ORL-AUDITOR to the dataset-level data by setting a piracy alarm threshold . If the ratio of misappropriation using trajectories exceeds the preset threshold , the auditor can claim the dataset-level pirate . B . Existing Solutions Watermarking [ 39 ] , [ 38 ] . Watermarking-based dataset copy- right protection methods inject samples of a specific distribu- tion before publishing the target dataset . One of its kind is implemented with backdoor attacks against the ML model . Li et al . [ 39 ] proposed to modify a dataset by adding a trigger , such as a local patch , to innocent samples in order to make them appear as a pre-defined target class . To verify the integrity of the dataset after the attack , they use a hypothesis test approach based on posterior probabilities generated by a third- party model . Inspired by this idea , the auditor can employ the backdoor attack against the DRL model [ 34 ] , [ 64 ] , [ 66 ] to generate a watermark for the offline RL dataset . However , since the open-source datasets are already pub- lished , the auditor needs a post-event mechanism that does not require injecting manipulated samples before publishing the dataset . Watermarking , on the other hand , is a pre-event mechanism that involves injecting manipulated samples into the dataset before publishing . Additionally , it is difficult for the auditor to guarantee that one effective watermarking has a consistent distribution with the original dataset , which in- evitably disturbs the model ’ s normal behavior . Dataset Inferences [ 43 ] , [ 16 ] . The core idea of dataset inference is empowering the model owner to make a com- pelling statistical argument that a particular model is a copied version of their own model by demonstrating that it is based on their private training data . It does not require injecting Step 1 : Model Preparation ( MP ) . In the left box of Figure 4 , the auditor prepares the critic model and the shadow DRL models based on the target dataset , which contains m trajectories T with the length of ni ( i ∈ { 1 , 2 , . . . , m } ) . The critic model is optimized to estimate the cumulative reward 5 𝟏𝟏 𝒔𝒔𝟏𝟏 𝟏𝟏 , 𝒂𝒂𝟏𝟏 𝟏𝟏 , 𝒓𝒓𝟏𝟏 𝟏𝟏 , 𝒔𝒔𝟐𝟐 𝟏𝟏 𝒔𝒔𝟐𝟐 𝟏𝟏 , 𝒂𝒂𝟐𝟐 𝟏𝟏 , 𝒓𝒓𝟐𝟐 𝟏𝟏 , 𝒔𝒔𝟑𝟑 𝒋𝒋 𝒔𝒔𝟏𝟏 𝒎𝒎 𝒔𝒔𝟏𝟏 𝒋𝒋 , 𝒂𝒂𝟏𝟏 𝒎𝒎 , 𝒂𝒂𝟏𝟏 𝒋𝒋 𝟐𝟐 , 𝒔𝒔𝟐𝟐 , 𝒓𝒓𝟏𝟏 𝒎𝒎 𝒎𝒎 , 𝒔𝒔𝟐𝟐 , 𝒓𝒓𝟏𝟏 𝒋𝒋 𝒋𝒋 , 𝒂𝒂𝟐𝟐 𝒔𝒔𝟐𝟐 𝒎𝒎 𝒔𝒔𝟐𝟐 𝒋𝒋 , 𝒓𝒓𝟐𝟐 𝒎𝒎 , 𝒂𝒂𝟐𝟐 𝒋𝒋 , 𝒔𝒔𝟑𝟑 𝒎𝒎 , 𝒓𝒓𝟐𝟐 𝒎𝒎 , 𝒔𝒔𝟑𝟑 … … … 𝟏𝟏 𝒔𝒔𝒏𝒏𝟏𝟏 𝟏𝟏 , 𝒂𝒂𝒏𝒏𝟏𝟏 𝟏𝟏 , 𝒓𝒓𝒏𝒏𝟏𝟏 𝟏𝟏 , 𝒔𝒔𝒆𝒆𝒏𝒏𝒆𝒆 𝒋𝒋 𝒋𝒋 𝒋𝒋 , 𝒂𝒂𝒏𝒏𝒋𝒋 𝒔𝒔𝒏𝒏𝒋𝒋 , 𝒓𝒓𝒏𝒏𝒋𝒋 𝒎𝒎 𝒎𝒎 , 𝒂𝒂𝒏𝒏𝒎𝒎 𝒔𝒔𝒏𝒏𝒎𝒎 𝒋𝒋 , 𝒔𝒔𝒆𝒆𝒏𝒏𝒆𝒆 𝒎𝒎 𝒎𝒎 , 𝒓𝒓𝒏𝒏𝒎𝒎 , 𝒔𝒔𝒆𝒆𝒏𝒏𝒆𝒆 Transition Trajectory Institution 1 Dataset Institution 2 Dataset Institution 3 Dataset 𝐷𝐷 '' 𝐷𝐷 # 𝐷𝐷 $ A d v e r s a r y Model 𝜋𝜋 ! Model 𝜋𝜋 '' Model 𝜋𝜋 '' Auditor for Institution 1 The models do ( or do not ) pirate the -th Trajectory of Dataset . 𝒋𝒋 𝑫𝑫𝟏𝟏 Fig . 4 : The workflow of ORL-AUDITOR contains three steps , i.e. , model preparation , cumulative reward collection , and audit process . ORL-AUDITOR first trains a set of shadow DRL models and a critic model on the target dataset , then collects the cumulative rewards from the state-action pairs of the shadow models and the suspect model . Finally , ORL-AUDITOR audits every trajectory based on hypothesis testing . of each state-action pair . For each trajectory in the dataset , a series of predictions for its state-action pairs compose the exclusive feature for auditing . There are two ways to optimize the critic model , i.e. , the Monte-Carlo-based ( MC-based ) and the temporal-difference-based ( TD-based ) strategies . We adopt the TD-based learning method and explain the reasons in Section IV-B . In addition , the auditor trains a set of shadow models following the model ’ s objective function introduced in Section II with different model initializations . Step 2 : Cumulative Reward Collection ( CRC ) . In the middle box , the shadow models observe the states of the dataset and take actions . For i-th trajectory in the dataset , the auditor records the state si t and the action ai t of each shadow model , where ai t represents the shadow model ’ s action at the t-th step of trajectory Ti . After finishing the action collection , the auditor obtains the k sets of state-action pairs from the shadow models , representing the learned policies with different initialization and training processes on the target dataset . Using the critic model in Step 1 , the auditor calculates the estimations for all state-action records , i.e. , the estimated cumulative rewards , which are the samplings of the exact cumulative rewards of the corresponding state-action pairs in the dataset . Similarly , the auditor queries the suspect model with state si t. The state-action pairs are then put into the critic model and to obtain the estimations for the suspect model . t and observes the action ai Step 3 : Audit Process ( AP ) . After the above two steps , the auditor obtains the estimated cumulative rewards from the shadow models and the suspect model and then con- ducts the audit process . For j-th ( j ∈ { 1 , 2 , . . . , m } ) tra- jectory of the dataset , the auditor collects k series of the estimated cumulative rewards from the shadow models , i.e. , { Qi j | i ∈ { 1 , 2 , . . . , k } } , and one from the suspect model , i.e. , Qs j. ORL-AUDITOR conducts hypothesis testing based j from ¯Qj . The auditor can on the distances of Qi j , ¯Qj ) is out of the distribution of rule out suspicion if d ( Qs j , ¯Qj ) | i ∈ { 1 , 2 , . . . , k } } . Otherwise , the auditor will { d ( Qi conclude a positive decision , i.e. , the suspect model is trained using this trajectory . The auditor repeatedly implements the above processes for other trajectories of the dataset and obtains j and Qs the final audit report with judgment for all trajectories . We discuss more details of the distance metric and the hypothesis testing in Section IV-C. B . The Selection of Critic Model The auditor can use either Monte Carlo ( MC ) based or Temporal-Difference ( TD ) based algorithms to train a critic model from the trajectories of the dataset . The main distinction between the two methods lies in their learning targets , which leads to differences in their objective functions . In the case of MC-based methods , the learning target G is the empirical cumulative rewards from the dataset . G ( st , at ) = rt + γrt+1 + . . . + γH−1rH , where G ( st , at ) represents the exact cumulative reward from ( st , at ) to the terminal time step H of one trajectory . The discount factor γ is applied to discount future rewards . The critic model is trained by minimizing the following objective . E ( st , at , rt+1 , st+1 ) ∼D ( cid:104 ) ( G ( st , at ) − Qθ ( st , at ) ) 2 ( cid:105 ) . For TD-based methods , the learning target changes to the expected cumulative reward in a heuristic form , i.e. , rt + γQ ( st+1 , at+1 ) . Thus , the critic model is trained by mini- mizing the following loss function . E ( st , at , rt+1 , st+1 ) ∼D ( cid:2 ) ( rt+1 + γQθ′ ( st+1 , at+1 ) − Qθ ( st , at ) ) 2 ( cid:3 ) , where the critic model starts with arbitrary initialization θ . Then , it repeatedly evaluates Qθ ( st , at ) , obtains a reward rt+1 , and updates the weights . The θ′ is a snapshot of θ and copies from θ every few updates of θ . The MC-based method utilizes the exact cumulative rewards from the dataset to train the critic model , resulting in an unbiased prediction . It also has strong convergence properties due to the stationary of Gt . However , it can not be applied to situations where the collected data is truncated , and all trajectories in the dataset must be completed . In practice , many sequential decision-making tasks usually have long or infinite time steps . Thus , the dataset provider segments the interaction record into trajectories by a preset maximum length . The TD-based method tackles the limitation of the MC-based algorithm and can learn from incomplete sequences . Nevertheless , due to the heuristic learning process , 6 Step 1 : Model Preparation Step 2 : Cumulative Reward Collection Dataset 1 , 𝑎𝑡 𝑠𝑡 1 , 𝑟𝑡 1 1 , 𝑠𝑡+1 2 , 𝑎𝑡 𝑠𝑡 2 , 𝑟𝑡 2 2 , 𝑠𝑡+1 |𝑡 = 1 … 𝑛1 |𝑡 = 1 … 𝑛2 … 𝑚 , 𝑎𝑡 𝑠𝑡 𝑚 , 𝑟𝑡 𝑚 , 𝑠𝑡+1 𝑚 |𝑡 = 1 … 𝑛𝑚 Training 𝑇1 : 𝑇2 : 𝑇𝑚 : 1 2 3 4 … 𝑘 Shadow DRL Models Critic Model 𝑄 ( 𝑠 , 𝑎 ) 1 2 3 4 … 𝑘 Shadow DRL Models 𝑆1 : 𝑠𝑡 1|𝑡 = 1 … 𝑛1 𝑆2 : 𝑠𝑡 2|𝑡 = 1 … 𝑛2 … 𝑆𝑚 : 𝑠𝑡 𝑚|𝑡 = 1 … 𝑛𝑚 States Model 1 1 ) |𝑡 = 1 … 𝑛1 1 , 𝑎𝑡 𝑠𝑡 ( 𝑠𝑡 2 , 𝑎𝑡 2 ) |𝑡 = 1 … 𝑛2 … ( 𝑠𝑡 𝑚 , 𝑎𝑡 𝑚 ) |𝑡 = 1 … 𝑛𝑚 Model 𝑘 1 ) |𝑡 = 1 … 𝑛1 ( 𝑠𝑡 1 , 𝑎𝑡 Model 𝑖 : 1~𝑘 ℚ1 𝑖 : 𝑄 𝑠𝑡 1 , 𝑎𝑡 1 |𝑡 = 1 … 𝑛1 … ( 𝑠𝑡 2 , 𝑎𝑡 2 ) |𝑡 = 1 … 𝑛2 … ℚ2 𝑖 : 𝑄 𝑠𝑡 2 , 𝑎𝑡 2 |𝑡 = 1 … 𝑛2 … ( 𝑠𝑡 𝑚 , 𝑎𝑡 𝑚 ) |𝑡 = 1 … 𝑛𝑚 ℚ𝑚 𝑖 : 𝑄 𝑠𝑡 𝑚 , 𝑎𝑡 𝑚 |𝑡 = 1 … 𝑛𝑚 States & Actions Critic Model Q ( 𝑠 , 𝑎 ) Cumulative Rewards ( 𝑠𝑡 1 , 𝑎𝑡 1 ) |𝑡 = 1 … 𝑛1 ( 𝑠𝑡 2 , 𝑎𝑡 2 ) |𝑡 = 1 … 𝑛2 … ( 𝑠𝑡 𝑚 , 𝑎𝑡 𝑚 ) |𝑡 = 1 … 𝑛𝑚 ℚ1 𝑆 : 𝑄 𝑠𝑡 1 , 𝑎𝑡 1 |𝑡 = 1 … 𝑛1 ℚ2 𝑆 : 𝑄 𝑠𝑡 2 , 𝑎𝑡 2 |𝑡 = 1 … 𝑛2 … ℚ𝑚 𝑆 : 𝑄 𝑠𝑡 𝑚 , 𝑎𝑡 𝑚 |𝑡 = 1 … 𝑛𝑚 Suspect DRL Model States & Actions Critic Model Q ( 𝑠 , 𝑎 ) Cumulative Rewards 𝑘 ℚ𝑗 Audit Metric Step3 Audit Process For 𝒋-th trajectory of the dataset ( 𝑗 ∈ { 1,2 , … , 𝑚 } ) 1 : ℚ𝑗 2 : ℚ𝑗 𝑘 : ℚ𝑗 𝑠 : ℚ𝑗 0.7 1.2 1.3 0.6 … 1.1 0.7 0.9 0.8 0.9 … 0.9 ⋯ 1.3 0.9 0.7 0.5 … 1.3 0.6 1.3 1.1 1.4 … 1.1 Length of Trajectory 1 , ഥℚ ) 𝑑 ( ℚ𝑗 2 , ഥℚ ) 𝑑 ( ℚ𝑗 ഥℚ is element-wise mean of { ℚ𝑗 𝑑 ( ℚ𝑗 ⋯ 𝑘 , ഥℚ ) 𝑑 ( ℚ𝑗 𝑠 , ഥℚ ) 𝑖 |𝑖 : 1~𝑘 } . 2 ℚ𝑗 1 ℚ𝑗 4 ℚ𝑗 ഥℚ 𝑠 ℚ𝑗 3 ℚ𝑗 ∆ 5 ℚ𝑗 Positive 𝑠 ℚ𝑗 Negative Hypothesis testing If 𝝁 𝑄𝑆 > , Negative for 𝑇 Algorithm 1 Workflow of ORL-AUDITOR Input : Dataset D , suspect model πs , number of shadow models k , significance level α Output : The trajectory-level audit report 1 : // Step 1 : Model Preparation 2 : Train shadow models { πi | i = 1 , . . . , k } and critic model 3 : // Step 2 : Data Preparation 4 : for each model π in { πi | i = 1 , . . . , k } ∪ { πs } do Query π by states s ∈ D and obtain the actions . 5 : Evaluate each ( s , a ) pair based on the critic model Q . 6 : Record the cumulative reward in sequential form { Qj | 7 : j = 1 , . . . , m } . 8 : end for 9 : // Step 3 : Audit Process 10 : audit report = [ ] 11 : for each trajectory in { Tj | j = 1 , . . . , m } do 12 : Calculate the element-wise mean ¯Qj of { Qi j | i = 1 , . . . , k } 13 : 14 : 15 : Measure the d ( Qj , ¯Qj ) of each Qi // Hypothesis testing From { di | i = 1 , . . . , k } and ds , decide whether the j from ¯Qj . j and Qs suspect model Ms pirates Tj with significance level α. audit report.append ( j-th audit result ) 16 : 17 : end for 18 : Return audit report the TD-based method has some bias and is more sensitive to model initialization . Therefore , we choose the element-wise mean of the shadow models ’ cumulative rewards ¯Q as the auditing directrix in Section IV-A instead of relying solely on the critic model ’ s predictions to compensate for the shortages of TD-based methods . C. The Details of Audit Process In the audit process , the choice of distance metric and the hypothesis testing method play a critical role in ORL- AUDITOR ’ s performance . A proper metric is sensitive to the deviations between the estimated cumulative rewards , which can facilitate the hypothesis testing . A suitable hypothesis test- ing method can provide precise results with high confidence . Distance Metric . We consider three types of distance metrics , i.e. , ℓp norm , Cosine distance , and Wasserstein distance . ℓp norm is a popular method of measuring the distance between vectors , i.e. , the sum of the absolute difference of the compo- nents of the vectors . In the RL scene , the states and actions are sequential data , meaning the distance metric should measure both the value and the position deviation of the cumulative rewards . However , ℓp norm may fail to reflect the difference from the sequence aspect of the same set of values . Cosine distance is a derivative of Cosine similarity , defined as the cosine of the angle between two vectors . Cosine distance embodies the difference from both the value and position aspects of the vectors . However , Cosine distance normalizes the inner product using the two vectors ’ norm , which weakens the numerical differences between the cumulative rewards . The Wasserstein distance , a.k.a . earth mover ’ s distance ( EMD ) , is a metric of the difference between two probability distributions over a region [ 54 ] . It can be defined as follows . l1 ( u , v ) = inf π∈Γ ( u , v ) ( cid:90 ) R×R |x − y|dπ ( x , y ) , where Γ ( u , v ) is the set of distributions on R × R whose marginals are u and v on the first and second factors respec- tively . Wasserstein distance fits well with audit requirements , reflecting numerical and positional deviations of the cumula- tive rewards . Thus , we set Wasserstein distance by default and compare different distance metrics in Section V. Hypothesis Testing . After the selection of the distance metric , the auditor proceeds to hypothesis testing with the distances of Qi j and Qs j from ¯Qj . H0 : d ( Qs H1 : d ( Qs j , ¯Qj ) is not an outlier . j , ¯Qj ) is an outlier . An intuitive method is to leverage the 3σ principle , i.e. , the normal samples should be distributed within the range of three times the standard deviation σd from the mean µd . The 3σ principle is an efficient hypothesis testing method , yet the mean µd is easily misled by outliers . Compared to the 3σ principle , Grubbs ’ test [ 25 ] is a more robust hypothe- sis testing method for detecting single outliers in univariate j , ¯Qj ) exceeds datasets . If the Grubbs ’ test statistic of d ( Qs the threshold derived on the significance level , the auditor j , ¯Qj ) deviate from the mean value , i.e. , reject can claim d ( Qs H0 and output negative audit result . For a set of samples { di | i = 1 , 2 , . . . , n } , Grubbs ’ Test locates the outlier by the procedures . 1 ) Calculate the mean µd and standard deviation σd . 2 ) Calculate the Grubbs ’ test statistic by G = ( cid:114 ) t2 |d ( Qs σd j , ¯Qj ) −µd| . 3 ) If G > n−1√ n α/ ( n ) , n−2 n−2+t2 α/ ( n ) , n−2 , H0 is invalid , i.e. , the suspect model is not trained by this trajectory . In the above inequation , t2 α/ ( n ) , n−2 represents the upper critical value in the t-distribution when the degree of freedom is n − 2 , and the significance level is α n . Both hypothesis testing methods are based on the assump- tion that the distance values follow Gaussian distribution . Thus , ORL-AUDITOR needs to pre-check that the distance values of the shadow models satisfy the Gaussian distribution . We adopts Anderson-Darling test [ 59 ] since it fits the scenarios where the auditor has a small number of samplings , and the actual distribution is unknown . In the evaluation , all the distance values of the shadow models can pass the Anderson-Darling test due to the randomness of the models ’ initialization and training . After that , ORL-AUDITOR conducts the hypothesis testing . V. EVALUATION We first introduce the tasks and the experimental setup in Section V-A . We validate the effectiveness of ORL- AUDITOR on Behavior Clone and three offline DRL models , i.e. , Batch-Constrained Q-learning ( BCQ ) [ 21 ] , Implicit Q- Learning ( IQL ) [ 35 ] , and TD3PlusBC [ 20 ] in Section V-B . Then , we visualize the cumulative rewards by t-SNE [ 62 ] to demonstrate that the cumulative rewards are intrinsic and stable 7 TABLE I : The Overview of Tasks . The “ continuous ” and “ discrete ” illustrate the data type of the state and action with the corresponding number of dimensions in parentheses . Task Name Lunar Lander ( Continuous ) State Shape Action Shape Continuous ( 6-dim ) Discrete ( 2-dim ) Continuous ( 2-dim ) Bipedal Walker Continuous ( 24-dim ) Continuous ( 4-dim ) Ant Continuous ( 111-dim ) Continuous ( 8-dim ) features for dataset auditing in Section V-C. After that , we further evaluate the impact of three factors on ORL-AUDITOR , i.e. , the number of shadow models , the significance level in hypothesis testing , and the trajectory size in Section V-D . Finally , we utilize ORL-AUDITOR to audit the open-source datasets from Google [ 18 ] and DeepMind [ 26 ] in Section V-E. A . Experimental Setup Tasks . We adopt Lunar Lander , Bipedal Walker , and Ant tasks in Gym [ 7 ] , which are widely used in the prior works [ 9 ] , [ 30 ] , [ 48 ] . The tasks stem from distinct real-world problems , each with numerical vectors containing different physical in- formation , e.g. , position , velocity , and acceleration . These tasks involve both discrete and continuous variables in observation and action spaces , with the dimension ranging from low ( 2- dim ) to high ( 111-dim ) . We give an overview in Table I and put their details in Appendix B. Dataset Generation and Offline Model Preparation . To obtain the datasets for tasks in Table I , we adopt the same idea as the existing dataset publishers [ 26 ] , [ 18 ] , [ 52 ] , [ 1 ] , i.e. , training the online RL models in the interactive envi- ronment and recording the interactions as the datasets . The datasets consist of numerical vectors . In Lunar Lander , each transition includes state , next state ( 6-dimensional continuous and 2-dimensional discrete variables ) , action ( 2-dimensional continuous variables ) , and reward ( scalar ) . Therefore , each transition is a 19-dimensional numerical vector . Similarly , the data types of Bipedal Walker and Ant are 53-dimensional and 231-dimensional numerical vectors , respectively . The number of transitions for each task is 5 × 105 ( Lunar Lander ) , 106 ( Bipedal Walker ) , and 2 × 106 ( Ant ) . The offline RL models learn from the datasets . Table II summarizes the whole process . For each task , we use five global random seeds to train five online models separately . We collect the datasets from five online models with random seed 0 , where every online model only generates one dataset . For ease of reading , the datasets share the same name with their online models . We train thirty offline DRL models for every dataset with distinct global random seeds in initialization and optimization processes . All the online and offline models are implemented by open-source RL libraries [ 53 ] , [ 56 ] with default hyperparameter settings . Critic Model . We adopt the fully connected neural network as the critic model , which has four hidden layers with 1024 neurons on each layer . We optimize the critic model following the TD-based method in Section IV-B by Adam optimizer with a learning rate of 0.001 and a mini-batch size of 4096 . The TABLE II : The main steps in dataset generation and offline model preparation with the details of the input and output . For each combination of task and offline RL model in the experiment ↓ Train with 5 random seeds : { 0 , 1 , . . . , 4 } ↓ 5 online RL models detailed in Table XIV ↓ Collect with 1 random seed : { 0 } ↓ 5x1 offline Datasets detailed in Table XV ↓ Train with 30 random seeds : { 42 , 43 , . . . , 72 } ↓ 5x1x30 offline RL models detailed in Table XVI , Table XVII , Table XVIII , and Table XIX entire training takes 150 epochs , and the learning rate decays to half every 50 epochs . Evaluation Metrics . Recalling ORL-AUDITOR ’ s application scenario in Figure 3 , for a single suspect model , the audit accuracy can well characterize the performance of ORL- AUDITOR , i.e. , the ratio of the number of correctly auditing trajectory to the total auditing trajectory . In our experiment , the positive models ( trained on the target dataset ) and the negative models ( trained on other datasets ) are randomly mixed , where the majority may dominate the accuracy . Thus , we provide the true positive rate ( TPR ) and the true negative rate ( TNR ) . Methods . We provide the audit performance of 3σ principle and Grubbs ’ test with four distance metrics , i.e. , ℓ1 norm , ℓ2 norm , Cosine distance , and Wasserstein distance . Competitors . Recalling Section III-B , existing methods [ 47 ] , [ 24 ] , [ 23 ] are designed for the online reinforcement learning scenes , assuming that the auditor can continuously interact with the environment to obtain new data as the non-member example . Based on the behavioral difference of the model between the member examples and the non-member examples , they build the member inference method to detect whether an example is used to train the suspect model . In the offline scenarios , without access to the environment , the auditor only has the pre-collected target dataset . Thus , we randomly divide the target dataset into two parts and train offline RL models on the subsets separately . Either subset is regarded as the set of non-member examples for the offline RL models trained on the other subset . We adopt the same data augmentation , attack classifier architecture , and hyperparameter settings with [ 23 ] . Implementation . We use stable-baselines [ 53 ] and d3rlpy [ 56 ] to implement online and offline DRL models separately . All audit methods are realized with Python 3.8 on a server with 8 NVIDIA GeForce RTX 3090 and 512GB memory . B . Overall Audit Performance We assess the effectiveness of ORL-AUDITOR across twelve combinations of three tasks and four models . Fur- thermore , we present an evaluation of the efficacy of the competitors on offline DRL models . Setup . From Table II , we train 30 offline RL models for each dataset and obtain 150 offline DRL models for every 8 TABLE III : The performance of existing membership inference attack against offline DRL models . Task Name Lunar Lander Bipedal Walker Ant Offline Model BC BCQ IQL TD3PlusBC BC BCQ IQL TD3PlusBC BC BCQ IQL TD3PlusBC Accuracy Training 50.09±0.68 49.84±1.39 49.88±0.76 50.08±0.92 50.00±0.63 49.97±0.69 50.17±0.95 49.87±0.94 50.44±0.64 50.22±0.52 50.33±0.35 50.13±0.67 Test 48.41±1.87 47.69±1.45 47.34±1.83 48.27±1.81 46.27±2.42 47.38±2.41 47.19±1.90 45.48±1.46 46.74±2.37 45.38±2.16 45.89±1.90 45.03±1.55 experimental setting . We audit the 5 datasets separately , where the auditor randomly selects 15 models from the target dataset as the shadow models , and the remaining 15 models along with the 120 models from other datasets are the positive and the negative suspect models . For the target dataset , we randomly select fifty auditing trajectories to audit . Since the unbalanced amount of the positive and the negative models , we report the aggregated mean with a standard deviation of both TPR and TNR for each setting in Table IV and provide the audit results between every two datasets in Figure 11 ( Lunar Lander ) , Figure 12 ( Bipedal Walker ) , and Figure 13 ( Ant ) . Each pair of TPR and TNR in Table IV is derived from the diagonal and non-diagonal values of the corresponding heatmap . As a supplementary of [ 13 ] , we also show the audit result by 3σ principle in Table VII . The competitors ’ performance is shown in Table III , where the values of mean and standard variation are calculated by repeating experiment ten times . Observations . We have the following observations from Table IV , Table VII , and Table III . 1 ) Most TPR and TNR values are higher than 95 % , meaning that ORL-AUDITOR is a valid solution to audit the learned dataset of the offline DRL models . For instance , all results for ORL-AUDITOR with ℓ1 norm are beyond 94 % across the experiment settings . 2 ) ORL-AUDITOR obtains different audit accuracy over four distance metrics . The audit effectiveness with ℓ1 norm and Wasserstein distance is better than that of ℓ2 norm and Cosine distance . In Table IV and Table VII , ORL-AUDITOR with Wasserstein distance always performs the best or the second place . And results of ℓ2 norm are usually behind the other three distance metrics . Recalling Section IV-C , Wasserstein distance characterizes both the numerical and the positional deviations of the cumulative rewards , which is more sensitive . Since the numerical differences between the cumulative rewards are slight , e.g. , from 0.01 to 0.1 in our experiment , ℓ2 norm may undercut these small but potential differences . 3 ) The accuracy of the audit as determined by Grubbs ’ test outperforms that of the 3σ principle . The 3σ principle is an empirical method , which is easily misled by the outlier cumu- lative rewards of the shadow models . Recalling Section IV-C , Grubbs ’ test first calculates the statistic G and compares G with an adaptive threshold , where the number of samples is also considered in the hypothesis testing . 4 ) Without the new data from the environment , the ef- fectiveness of the existing membership inference methods is attenuated . From one perspective , the similarity between sub- datasets splited from the same dataset can result in the trained RL models exhibiting undifferentiated behavior , making it difficult to effectively distinguish between members and non- members . On the other hand , when considering the results presented in Figure 10 , we conclude that the actions of RL models should not be directly utilized as the foundation for membership inference . C. Visualization of Cumulative Rewards To further explain the audit results in Section V-B , we analyze the cumulative rewards from the shadow models and j and Qs the suspect models , i.e. , Qi j , by using t-SNE [ 62 ] . j ( positive ) or Qs Setup . The caption of each plot in Figure 5 indicates the used task and offline DRL model . Each point in the plots shows the visualization of a single Qi j ( negative ) . In a single plot , we demonstrate the results of three trajectories from each tasks ’ first datasets . For instance , the target dataset of the plot titled “ Lunar Lander , BC ” is dataset “ 1171 ” in Table XV . The thirty positive points for each trajectory are collected from the shadow models trained on dataset “ 1171 ” , while the thirty negative points are randomly sampled from the shadow models from the other four datasets . Observations . From Figure 5 , we have the following obser- vations . 1 ) For a trajectory of the target dataset , the cumulative rewards from the shadow models and the suspect models are clearly divided into different groups , meaning that the critic model well reflects the differences in the models ’ actions . Thus , the cumulative reward generated by the critic model is a qualified post-event fingerprint for trajectory-level auditing . 2 ) The distribution of points varies on the different trajec- tories . For example , trajectory 1 from the Lunar Lander dataset is harder to cluster than the other two trajectories . We speculate that this is because trajectory 1 represents a basic policy , e.g. , a local optimum policy to fire the lander ’ s thrusters all the way , and similar trajectories exist in the other four datasets . Due to the non-uniqueness of the optimal strategy in RL problems and the impact of randomness in the model training process , the collected trajectories have unique characteristics . Thus , other trajectories ’ cumulative rewards are clearly divided . D. Hyperparameter Study impact We extend our assessment to scrutinize three pivotal de- terminants that the pragmatic integration of ORL- AUDITOR . Specifically , we consider the amount of shadow models , the level of significance in hypothesis testing , and the magnitude of the trajectory size . Due to space limitations , we only give brief conclusions in this section . Please refer to the specific analysis in Appendix C , Appendix D , and Appendix E. Impact of Shadow Models ’ Amount . We change the shadow models ’ amount to 9 and 21 with the other settings the same as Section V-B . Figure 6 shows the value change of TPR and TNR compared with that of 15 shadow models . Each figure ’ s title illustrates the settings of the model and the task , the x-axis indicates the four metrics , and the y-axis is the absolute value change . As a supplementary of [ 13 ] , we provide the detailed results in Table VIII ( 9 Shadow Models ) and Table IX ( 21 Shadow Models ) . 9 TABLE IV : The TPR and TNR results based on Grubbs ’ test . The mean and standard deviation of TPR and TNR in each row represent the audit results for one combination of task and model by four distance metrics . Bold indicates the highest sum of TPR and TNR , i.e. , accuracy , in a row . Each pair of TPR and TNR is derived from the diagonal and non-diagonal values of the corresponding heatmap in Figure 11 , Figure 12 and Figure 13 , which are supplementary to [ 13 ] . Task Name Offline Model Lunar Lander Bipedal Walker Ant BC BCQ IQL TD3PlusBC BC BCQ IQL TD3PlusBC BC BCQ IQL TD3PlusBC L1 Norm L2 Norm Cosine Distance Wasserstein Distance TPR 99.01±0.46 98.29±1.14 98.61±1.51 98.29±2.04 99.20±1.47 99.52±0.77 95.10±7.41 99.36±1.28 97.42±1.66 97.17±2.96 97.20±2.33 98.53±1.80 TNR 100.00±0.00 100.00±0.00 99.91±0.32 99.48±0.79 100.00±0.00 100.00±0.00 100.00±0.00 94.77±19.42 99.94±0.11 99.80±0.43 99.66±0.73 99.18±1.72 TPR 96.96±0.73 96.03±1.15 97.52±2.51 96.35±3.01 98.40±2.70 98.16±2.89 95.04±5.45 97.15±5.71 96.48±1.66 95.68±2.54 96.61±2.50 97.17±1.79 TNR 100.00±0.00 100.00±0.00 99.97±0.12 99.89±0.22 100.00±0.00 100.00±0.00 100.00±0.00 93.36±21.46 99.90±0.36 99.84±0.43 99.69±0.59 99.35±1.74 TPR 96.93±0.77 95.97±1.07 97.49±2.56 96.27±3.16 98.56±2.68 99.87±0.15 99.84±0.32 96.96±5.82 99.20±1.08 99.66±0.43 99.57±0.79 99.72±0.40 TNR 100.00±0.00 99.99±0.04 99.92±0.19 99.91±0.23 100.00±0.00 100.00±0.00 100.00±0.00 91.98±21.75 85.66±28.23 86.70±26.89 86.25±27.90 87.79±26.43 TPR 98.40±0.74 97.57±1.17 98.32±1.79 98.53±1.25 99.31±1.32 99.89±0.13 95.01±6.72 98.08±3.84 98.00±1.19 98.67±1.65 99.36±0.42 99.25±1.24 TNR 99.94±0.16 99.91±0.14 97.10±5.66 95.59±3.77 100.00±0.00 100.00±0.00 100.00±0.00 88.26±25.34 99.92±0.14 99.79±0.46 99.63±0.78 99.14±1.81 From Figure 6 , we have the following observations . 1 ) The audit accuracy increases with a larger amount of shadow models . 2 ) There exists a saturation point for audit accuracy with the expansion of shadow models . Impact of Significance Level . The significance level rep- resents the auditor ’ s confidence in the auditing results . In the significance level α = 0.01 , Section V-B , we adopt meaning that the auditor has 99 % confidence in the judg- ments . Generally speaking , the significance level represents the maximum audit capacity of ORL-AUDITOR instead of a hyperparameter setting since it is an audit requirement by the dataset owner . We demand the auditor to output a more confident judgment , where the error possibility should be limited to 1‰ and 0.1‰ , i.e. , α = 0.001 and α = 0.0001 . Figure 7 shows the value change of TPR and TNR compared with that when α = 0.01 . As a supplementary of [ 13 ] , the detailed results between every two datasets are in Table X ( α = 0.001 ) and Table XI ( α = 0.0001 ) . From Figure 7 , we have the following observations . 1 ) For a complicated task , we recommend the auditor select a large significance level for ORL-AUDITOR . 2 ) For the suspect models with low performance , ORL-AUDITOR should adopt a large significance level to guarantee audit accuracy . 3 ) In general , α = 0.01 is a safe bound of ORL-AUDITOR , and a lower α may break through the capability boundary of ORL- AUDITOR , inducing the auditor to misclassify the negative model to the positive set . Impact of Trajectory Size . We investigate the relationship between the trajectory size and audit accuracy . In Section V-B , we adopt the full-length trajectory , meaning that the auditor utilizes all states of each trajectory to query the suspect model and obtains the corresponding actions to conduct the dataset auditing . We change the trajectory size to 25 % and 50 % of the full length with the other settings the same as Section V-B . Figure 8 shows the value change of TPR and TNR compared with that of the full-length trajectory . As a supplementary of [ 13 ] , we also provide the detailed results in Table XII ( 25 % ) and Table XIII ( 50 % ) . From Figure 8 , we have the following observations . 1 ) ORL-AUDITOR tends to achieve higher accuracy with a larger trajectory size . 2 ) A small trajectory size achieves better results under some tasks since the front states of each trajectory are able to reflect more behavioral information of the model [ 46 ] . E. Real-world Application In this section , we apply ORL-AUDITOR to audit the open- source datasets from DeepMind [ 26 ] and Google [ 18 ] . We choose the “ halfcheetah ” task published by both , where the operator controls a 2-dimensional cheetah robot consisting of 9 links and 8 joints connecting them ( including two paws ) to make the cheetah run forward ( right ) as fast as possible . The details of the halfcheetah dataset and the offline DRL models are in Table XX and Table XXI . All experimental settings are consistent with these in Section V-B . Observations . From Table XXII , we have the following observations . 1 ) ORL-AUDITOR can be effective in real-world applications . The TPR and TNR of ORL-AUDITOR exceed 95 % with ℓ1 norm and Wasserstein distance , meaning that ORL-AUDITOR remains valid for the existing open-source datasets . 2 ) Wasserstein distance has stable performance on the experimental and the real-world datasets . The overall accuracy of ORL-AUDITOR with Wasserstein distance are all higher than the other three metrics . VI . ROBUSTNESS A . Ensemble Architecture To hinder the audit of a dataset , an adversary may uti- lize state-of-the-art membership inference defense strategies proposed in recent research works [ 60 ] , [ 31 ] . These defense strategies aim to mitigate the influence of a member example on the behavior of a machine learning model . Based on the idea of model ensemble , in particular , [ 60 ] , [ 31 ] , [ 11 ] proposed to split the training set into several subsets and train sub- models on each of these subsets . Then , when an auditor uses an example from the target dataset to query a suspect model , 10 Fig . 5 : Visualization of cumulative rewards by t-SNE . The caption of each plot demonstrates the offline DRL model ’ s type and task . In a single plot , we randomly select three trajectories from the first dataset for the task , i.e. , Lunar Lander dataset 1171 , Bipedal Walker dataset 0841 , and Ant dataset 2232 in Table XV , and then show the cumulative rewards from 30 positive models and 30 negative models for each trajectory . Fig . 6 : Impact of shadow models ’ amount . The change value of TPR and TNR when the number of shadow models varies to 9 and 21 compared to the default 15 shadow models . The caption of each plot demonstrates the offline DRL model ’ s type and task . The x labels display the four distance metrics . The y labels show the absolute fluctuating values of TPR and TNR . the adversary aggregates the outputs of the sub-models that have not been trained on this example . Setup . The number of divided subsets , denoted by K , repre- sents a crucial hyperparameter for ensemble-based methods , as discussed in [ 60 ] , [ 31 ] . Considering the analysis conducted in these studies , as well as the size of the offline RL datasets , we have established K = 5 for the present investigation . All other experimental settings remain unchanged from those described in Section V-B , and the corresponding audit outcomes are presented in Table V. As a supplementary of [ 13 ] , the results between every two datasets are in Figure 14 ( Lunar Lander ) , Figure 15 ( Bipedal Walker ) , Figure 16 ( Ant ) , and Figure 17 ( Half Cheetah ) . Observations . We conclude the following observations based on the above results . 1 ) Even when faced with ensemble architecture , ORL-AUDITOR maintains a high level of audit accuracy . As shown in Table V , both TPR and TNR con- sistently exceed 80 % . As described in Section IV-A , ORL- AUDITOR uses predicted cumulative rewards from the critic model as the basis for auditing . During training , the critic model captures the overall features of the dataset distribution , instead of memorizing features from individual samples . Since the ensemble model is trained on the target dataset , its behavior embeds the distribution characteristics of the dataset , which 11 Lunar Lander , BC Lunar Lander , BCQ Lunar Lander , IQL Lunar Lander , TD3PlusBC Trajectory 0 1 2 Audit Result Positive Negative Trajectory 0 1 2 Audit Result Positive Negative Trajectory 0 1 2 Audit Result Positive Negative Trajectory 0 1 2 Audit Result Positive Negative Bipedal Walker , BC Bipedal Walker , BCQ Bipedal Walker , IQL Bipedal Walker , TD3PlusBC Trajectory 0 1 2 Audit Result Positive Negative Trajectory 0 1 2 Audit Result Positive Negative Trajectory 0 1 2 Audit Result Positive Negative Trajectory 0 1 2 Audit Result Positive Negative Ant , BC Ant , BCQ Ant , IQL Ant , TD3PlusBC Trajectory 0 1 2 Audit Result Positive Negative Trajectory 0 1 2 Audit Result Positive Negative Trajectory 0 1 2 Audit Result Positive Negative Trajectory 0 1 2 Audit Result Positive Negative Lunar Lander , BC Bipedal Walker , BC Ant , BC 5.0 0 -5.0 -10.0 l e u a V ∆ 5.0 0 -5.0 -10.0 l e u a V ∆ 5.0 0 -5.0 -10.0 l e u a V ∆ Lunar Lander , BCQ Bipedal Walker , BCQ Ant , BCQ 5.0 0 -5.0 -10.0 5.0 0 -5.0 -10.0 5.0 0 -5.0 -10.0 5.0 0 -5.0 -10.0 5.0 0 -5.0 -10.0 5.0 0 -5.0 -10.0 Lunar Lander , IQL Bipedal Walker , IQL Ant , IQL Lunar Lander , TD3PlusBC Bipedal Walker , TD3PlusBC Ant , TD3PlusBC 5.0 0 -5.0 -10.0 5.0 0 -5.0 -10.0 5.0 0 -5.0 -10.0 L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R C C W W C C W W C C W W C C W W Distance Metric Distance Metric Distance Metric Distance Metric 9 Shadow Models 21 Shadow Models Fig . 7 : Impact of the significance level . The change value of TPR and TNR when the significance level varies to 0.001 and 0.0001 compared to the default 0.01 . The caption of each plot demonstrates the offline DRL model ’ s type and task . The x labels display the four distance metrics . The y labels show the absolute fluctuating values of TPR and TNR . Fig . 8 : Impact of the trajectory size . The change value of TPR and TNR when the trajectory size varies to 25 % and 50 % compared to the entire trajectories ( 100 % ) . The caption of each plot demonstrates the offline DRL model ’ s type and task . The x labels display the four distance metrics . The y labels show the absolute fluctuating values of TPR and TNR . Fig . 9 : Robustness against action distortion . The change value of TPR and TNR when the suspect model adds Gaussian noise parameterized with ( µ = 0 , σ = 0.01 ) and ( µ = 0 , σ = 0.1 ) to its output . The caption of each plot demonstrates the offline DRL model ’ s type and task . The x labels display the four distance metrics . The y labels show the absolute fluctuating values . ORL-AUDITOR can detect . 2 ) The use of ensemble architecture may result in a de- crease in model performance for certain tasks . Our experimen- tal results , as shown in column “ Model Performance ( Model Ensemble ) ” of Tables Table XVI , Table XVII , Table XVIII , and Table XIX , demonstrate a decline in the performance of offline RL models when utilizing ensemble architecture . For instance , when BCQ models learn from the Ant dataset “ 3569 ” , the mean values of cumulative reward decrease significantly . Furthermore , due to the sub-models being trained on subsets of data , they only fit a partial dataset ’ s distribution . Consequently , when applying the model ensemble to practical scenarios , the standard deviations of the model ’ s performance are large . 12 Lunar Lander , BC Bipedal Walker , BC Ant , BC l e u a V ∆ l e u a V ∆ l e u a V ∆ 5.0 0.0 -5.0 -10.0 -15.0 -20.0 5.0 0.0 -5.0 -10.0 -15.0 -20.0 5.0 0.0 -5.0 -10.0 -15.0 -20.0 Lunar Lander , BCQ Bipedal Walker , BCQ Ant , BCQ 5.0 0.0 -5.0 -10.0 -15.0 -20.0 5.0 0.0 -5.0 -10.0 -15.0 -20.0 5.0 0.0 -5.0 -10.0 -15.0 -20.0 5.0 0.0 -5.0 -10.0 -15.0 -20.0 5.0 0.0 -5.0 -10.0 -15.0 -20.0 5.0 0.0 -5.0 -10.0 -15.0 -20.0 Lunar Lander , IQL Bipedal Walker , IQL Ant , IQL Lunar Lander , TD3PlusBC Bipedal Walker , TD3PlusBC Ant , TD3PlusBC 5.0 0.0 -5.0 -10.0 -15.0 -20.0 5.0 0.0 -5.0 -10.0 -15.0 -20.0 5.0 0.0 -5.0 -10.0 -15.0 -20.0 L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R C C W W C C W W C C W W C C W W Distance Metric Distance Metric Distance Metric Distance Metric 0.001 0.0001 Lunar Lander , BC Lunar Lander , BCQ Lunar Lander , IQL Lunar Lander , TD3PlusBC l e u a V ∆ 10.0 5.0 0.0 -5.0 -10.0 l e u a V ∆ 10.0 5.0 0.0 -5.0 -10.0 l e u a V ∆ 10.0 5.0 0.0 -5.0 -10.0 Bipedal Walker , BC Ant , BC 10.0 5.0 0.0 -5.0 -10.0 10.0 5.0 0.0 -5.0 -10.0 10.0 5.0 0.0 -5.0 -10.0 Bipedal Walker , BCQ Ant , BCQ 10.0 5.0 0.0 -5.0 -10.0 10.0 5.0 0.0 -5.0 -10.0 10.0 5.0 0.0 -5.0 -10.0 Bipedal Walker , IQL Ant , IQL 10.0 5.0 0.0 -5.0 -10.0 10.0 5.0 0.0 -5.0 -10.0 10.0 5.0 0.0 -5.0 -10.0 Bipedal Walker , TD3PlusBC Ant , TD3PlusBC L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a s s . a s s . P N T T R R P N R R C C W W C C W W C C W W C C W W Distance Metric Distance Metric Distance Metric Distance Metric 25 % of full trajectory 50 % of full trajectory Lunar Lander , BC Lunar Lander , BCQ Lunar Lander , IQL Lunar Lander , TD3PlusBC l e u a V ∆ 0 -20.0 -40.0 -60.0 -80.0 l e u a V ∆ 0 -20.0 -40.0 -60.0 -80.0 l e u a V ∆ 0 -20.0 -40.0 -60.0 -80.0 Bipedal Walker , BC Ant , BC 0 -20.0 -40.0 -60.0 -80.0 0 -20.0 -40.0 -60.0 -80.0 0 -20.0 -40.0 -60.0 -80.0 Bipedal Walker , BCQ Ant , BCQ 0 -20.0 -40.0 -60.0 -80.0 0 -20.0 -40.0 -60.0 -80.0 0 -20.0 -40.0 -60.0 -80.0 Bipedal Walker , IQL Ant , IQL 0 -20.0 -40.0 -60.0 -80.0 0 -20.0 -40.0 -60.0 -80.0 0 -20.0 -40.0 -60.0 -80.0 Bipedal Walker , TD3PlusBC Ant , TD3PlusBC L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a a s s . s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a a s s . s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a a s s . s s . P N T T R R P N R R L 1 L 1 L 2 L 2 T T T T P N P N R R R R o s . o s . T T a a s s . s s . P N T T R R P N R R C C W W C C W W C C W W C C W W Distance Metric Distance Metric Distance Metric Distance Metric sigma=0.01 sigma=0.1 TABLE V : The TPR and TNR results of ORL-AUDITOR against model ensemble ( K = 5 ) . The mean and standard deviation of TPR and TNR in each row represent the audit results for one combination of task and model by four distance metrics . Each pair of TPR and TNR is derived from the diagonal and non-diagonal values of the corresponding heatmap in Figure 14 ( Lunar Lander ) , Figure 15 ( Bipedal Walker ) , Figure 16 ( Ant ) , and Figure 17 ( Half Cheetah ) , which are supplementary to [ 13 ] . Task Name Lunar Lander Bipedal Walker Ant Half Cheetah Offline Model BC BCQ IQL BC BCQ IQL TPR 100.00±0.00 99.60±0.80 100.00±0.00 TD3PlusBC 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 TD3PlusBC 100.00±0.00 99.60±0.80 100.00±0.00 100.00±0.00 TD3PlusBC 99.60±0.80 85.00±25.98 91.00±15.59 90.00±12.81 TD3PlusBC 61.50±20.32 BC BCQ IQL BC BCQ IQL L1 Norm L2 Norm Cosine Distance Wasserstein Distance TNR 100.00±0.00 100.00±0.00 99.90±0.44 99.30±0.95 100.00±0.00 100.00±0.00 100.00±0.00 94.90±19.07 100.00±0.00 99.70±0.71 99.80±0.60 99.30±1.82 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 TPR 99.20±0.98 98.00±2.19 99.20±0.98 99.60±0.80 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 99.60±0.80 99.60±0.80 99.20±0.98 100.00±0.00 84.50±25.71 89.00±16.76 86.50±16.70 77.00±19.42 TNR 100.00±0.00 100.00±0.00 100.00±0.00 99.90±0.44 100.00±0.00 100.00±0.00 100.00±0.00 93.80±21.63 99.90±0.44 99.80±0.60 99.70±0.71 99.40±2.20 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 TPR 99.20±0.98 98.00±2.19 99.60±0.80 99.60±0.80 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 99.60±0.80 100.00±0.00 99.20±0.98 100.00±0.00 94.00±10.39 95.00±8.66 94.50±9.53 95.00±8.66 TNR 100.00±0.00 100.00±0.00 99.90±0.44 99.80±0.60 100.00±0.00 100.00±0.00 100.00±0.00 92.70±21.62 83.20±31.99 85.70±28.31 86.80±28.32 87.80±25.87 67.50±43.20 67.17±42.30 71.00±41.37 65.67±41.28 TPR 99.60±0.80 99.60±0.80 99.60±0.80 99.60±0.80 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 99.20±1.60 100.00±0.00 100.00±0.00 99.60±0.80 87.00±21.38 93.00±12.12 91.50±12.52 52.00±33.26 TNR 99.90±0.44 100.00±0.00 97.60±4.27 95.80±3.57 100.00±0.00 100.00±0.00 100.00±0.00 89.20±23.94 100.00±0.00 99.70±0.71 99.80±0.60 98.50±3.79 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 B . Action Distortion The suspect models may perturb the actions , i.e. , changing the original models ’ outputs , to conceal its training dataset in practice . The action distortion mechanism should be stealthy and can not be detected by the auditor easily . Considering that the DRL models are usually applied to real-world decision- making tasks , such as self-driving cars and industry automa- the natural distortion is often modeled as tion [ 44 ] , [ 28 ] , Gaussian noise . For example , thermal noise , which is caused by the random motion of electrons in a conductor , can be modeled as a Gaussian noise with a constant power spec- trum [ 2 ] . In addition , Gaussian noise is easy to manipulate mathematically . For ease of evaluating the effects of different distortion intensities , all dimensions of the models ’ action space are normalized into [ −1 , 1 ] . Then , we utilize Gaussian noise with mean ( µ = 0 ) and standard deviation ( σ = 0.1 ) and ( σ = 0.01 ) to represent the two levels of distortion . Setup . Figure 9 depicts the impact of “ with ” or “ without ” the action distortion . The information about the used offline DRL model and task is shown in each figure ’ s title . The x- axis indicates the four metrics , and the y-axis is the absolute value change . As a supplementary of [ 13 ] , the detailed results between every two datasets are in Figure 18 , Figure 19 ( Lunar Lander ) , Figure 20 , Figure 21 ( Bipedal Walker ) , Figure 22 , and Figure 23 ( Ant ) . Observations . We conclude the following observations based on the above results . 1 ) ORL-AUDITOR is able to resist the potential action distortion from the suspect model , especially with the Cosine metric . From Figure 9 , the TPR and TNR vary slightly across most of the settings with weak noise , where the maximum accuracy attenuation is within 3 % for Cosine distance . We speculate that Cosine distance has a noise suppression ability when calculating the inner product of two series of cumulative rewards . Also , the weak noise may facilitate the dataset auditing since it will move the negative samples farther away from the positive set . 2 ) ORL-AUDITOR with a single distance metric faces limitations for heavy distortion . The TPR of ORL-AUDITOR suffers an obvious decline with strong noise . Since the strong distortion thoroughly changes the distribution of the models ’ actions , the cumulative rewards of the suspect model trained on the target dataset are different from those of the auditor ’ s shadow models . In this case , the auditor can not identify the positive models from the negative just by a single kind of distance metric . From Figure 23 , Cosine distance is good at discriminating the positive models ( results in the diagonal ) , and Wasserstein distance is proper for the negative models ( results in the non-diagonal ) . Thus , for strong distortion , the combination of multiple distance metrics can enhance the auditing robustness of ORL-AUDITOR . In addition , we should note that the models ’ normal behavior is also destroyed by the strong distortion . For example , in Table XVIII , the noise induces the model performance of IQL to decrease up to 25 % , and the better the model ’ s quality , the more pronounced the performance drop . VII . RELATED WORK Membership and Dataset Inferences . To infer whether an individual data record was used to train the target model , Shokri et al . [ 57 ] proposed the first practical membership inference strategy by training a number of shadow classifiers to distinguish the target model ’ s outputs on members versus non- members of its training dataset . Since then , researchers have investigated membership inference in various systems , such as machine unlearning [ 10 ] , facial recognition systems [ 12 ] , and neural architecture search [ 29 ] . Liu et al . [ 41 ] presenting a first-of-its-kind holistic risk assessment of different inference 13 attacks against machine learning models . Maini et al . [ 43 ] introduced the definition of dataset inference and designed the first mechanism to identify whether a suspect model copy has private knowledge from the dataset . Compared with the existing works , ORL-AUDITOR is a well-designed solution built for the offline DRL scenes , which overcomes several new challenges . First , ORL-AUDITOR is a post-event mechanism that can be directly applied to the existing open-source datasets . Second , ORL-AUDITOR does not use any auxiliary datasets . Knowledge Extraction Against DRL . The DRL models learn from the interaction with the environment , which can be valuable information in some cases , e.g. , indoor robot navigation . Pan et al . [ 47 ] demonstrated such knowledge extraction vulnerabilities in DRL under various settings and proposed algorithms to infer floor plans from some trained Grid World navigation DRL models with LiDAR perception . For exacting the model functionality , Chen et al . [ 9 ] proposed the first method to acquire the approximation model from the victim DRL . They built a classifier to reveal the targeted black- box DRL model ’ s training algorithm family based only on its predicted actions and then leveraged state-of-the-art imitation learning techniques to replicate the model from the identi- fied algorithm family . Ono et al . [ 45 ] integrated differential privacy [ 72 ] , [ 69 ] , [ 63 ] into the distributed RL algorithm to defend the extraction . The local models report noisy gradients designed to satisfy local differential privacy [ 14 ] , [ 15 ] , [ 65 ] , [ 71 ] , i.e. , keeping the local information from being exploited by adversarial reverse engineering . Chen et al . [ 8 ] proposed a novel testing framework for deep learning copyright protection , which can be adjusted to detect the knowledge extraction against DRL . VIII . DISSCUSION Highlights of ORL-AUDITOR . 1 ) ORL-AUDITOR is the first approach to conduct trajectory-level dataset auditing for offline DRL models . 2 ) By conducting a comprehensive analysis of ORL-AUDITOR under different experimental settings , such as the shadow model ’ s amount , the significance level in hy- pothesis testing , the trajectory size , and the robustness against ensemble architecture and action distortion , we conclude some useful observations for adopting ORL-AUDITOR . 3 ) We apply ORL-AUDITOR to audit the models trained on the open-source datasets from Google and DeepMind . All TPR and TNR results are superior than 95 % , demonstrating ORL-AUDITOR is an effective and efficient strategy for the published datasets . Limitations and Future Work . Below , we discuss the limitations of ORL-AUDITOR and promising directions for further improvements . 1 ) From Appendix D , the accuracy of ORL-AUDITOR decreases when the significance level downs to 0.001 . Thus , it is interesting to enhance ORL-AUDITOR to satisfy stricter auditing demands in the future . 2 ) ORL- AUDITOR based on a single distance metric may not be suffi- ciently robust to strong distortion . Based on the observations in Section VI-B , integrating more distance metrics in the audit process may be a further promising direction . IX . CONCLUSION In this work , we propose a novel trajectory-level dataset auditing method for offline DRL models relying on the insight that cumulative rewards can serve as the dataset ’ s intrinsic fingerprint and exist in all models trained on the target dataset . Both the true positive rate and the true negative rate of ORL-AUDITOR exceed 90 % on four offline DRL models and three task combinations . We show that ORL-AUDITOR is an effective and efficient solution to protect the IP of the dataset owners through multiple experiments . By studying parameter settings about the number of shadow models , the significance level in hypothesis testing , and the trajectory size , we conclude several important observations for adopting ORL-AUDITOR in practice . The robustness evaluation demonstrates that ORL- AUDITOR can resist the defenses of the model ensemble and the action distortion of the suspect model . Integrating multiple distance metrics to improve the robustness of ORL- AUDITOR against action distortion is a promising direction for future work . Finally , we utilize the open-source datasets from Google [ 18 ] and DeepMind [ 26 ] to examine the practicality of ORL-AUDITOR , and show that ORL-AUDITOR behaves excellently on existing published datasets . ACKNOWLEDGMENT We would like to thank the anonymous reviewers for their constructive comments . We also thank Yanchao Sun for sharing her expertise in reinforcement learning . This work was partly supported by the National Key Research and Develop- ment Program of China under No . 2022YFB3102100 , NSFC under Grants 62088101 , 61833015 , 62103371 , U20A20159 , and the Fundamental Research Funds for the Central Univer- sities 226-2022-00107 , 226-2023-00111 . Min Chen was partly sponsored by the Helmholtz Association within the project “ Trustworthy Federated Data Analytics ” ( TFDA ) ( No . ZT-I- OO1 4 ) . Zhikun Zhang was supported by the CISPA-Stanford Center for Cybersecurity ( FKZ:13N1S0762 ) . REFERENCES [ 1 ] M. Abadi , A. Agarwal , P. Barham , E. Brevdo , Z. Chen , C. Citro , G. S. Corrado , A. Davis , J . Dean , M. Devin , S. Ghemawat , I. Goodfellow , A. Harp , G. Irving , M. Isard , Y. Jia , R. Jozefowicz , L. Kaiser , M. Kudlur , J. Levenberg , D. Man´e , R. Monga , S. Moore , D. Murray , C. Olah , M. Schuster , J. Shlens , B. Steiner , I. Sutskever , K. Talwar , P. Tucker , V. Vanhoucke , V. Vasudevan , F. Vi´egas , O. Vinyals , P. Warden , M. Wat- tenberg , M. Wicke , Y. Yu , and X. Zheng . TensorFlow : Large-Scale Ma- chine Learning on Heterogeneous Systems . https : //www.tensorflow.org/ , 2015 . [ 2 ] N. AlHinai . Introduction to Biomedical Signal Processing and Artificial Intelligence . In Biomedical Signal Processing and Artificial Intelligence in Healthcare , Developments in Biomedical Engineering and Bioelec- tronics , pages 1–28 . Elsevier , 2020 . [ 3 ] S. Amarjyoti . Deep Reinforcement Learning for Robotic Manipulation - The State of the Art . CoRR abs/1701.08878 , 2017 . [ 4 ] C. Beattie , J . Z. Leibo , D. Teplyashin , T. Ward , M. Wainwright , H. K¨uttler , A. Lefrancq , S. Green , V. Vald´es , A. Sadik , J. Schrittwieser , K. Anderson , S. York , M. Cant , A. Cain , A. Bolton , S. Gaffney , H. King , D. Hassabis , S. Legg , and S. Petersen . DeepMind Lab . CoRR , abs/1612.03801 , 2016 . [ 5 ] Biscom . Employee Departure Creates Gaping Security Hole . https : hole-says-new-data , 2021 . [ 6 ] F. Boenisch . A Systematic Review on Model Watermarking for Neural Networks . Frontiers Big Data , 4:729663 , 2021 . 14 [ 7 ] G. Brockman , V. Cheung , L. Pettersson , J. Schneider , J. Schulman , J. Tang , and W. Zaremba . OpenAI Gym . CoRR , abs/1606.01540 , 2016 . J. Chen , J. Wang , T. Peng , Y . Sun , P. Cheng , S. Ji , X. Ma , B. Li , and D. Song . Copy , Right ? a Testing Framework for Copyright Protection of Deep Learning Models . In IEEE S & P , pages 824–841 , 2022 . [ 8 ] Stealing Deep [ 9 ] K. Chen , S. Guo , T. Zhang , X. Xie , and Y. Liu . In ACM Asia Reinforcement Learning Models for Fun and Profit . Conference on Computer and Communications Security ( ASIACCS ) , pages 307–319 , 2021 . [ 30 ] [ 31 ] I. Ilahi , M. Usama , J. Qadir , M. U. Janjua , A. I. Al-Fuqaha , D. T. Hoang , and D. Niyato . Challenges and Countermeasures for Adversarial Attacks on Deep Reinforcement Learning . CoRR abs/2001.09684 , 2020 . I. Jarin and B. Eshete . MIAShield : Defending Membership Inference Attacks via Preemptive Exclusion of Members . In Privacy Enhancing Technologies Symposium , pages 400–416 , 2023 . [ 32 ] R. Kidambi , A. Rajeswaran , P. Netrapalli , and T. Joachims . MOReL : Model-Based Offline Reinforcement Learning . In NeurIPS , 2020 . [ 33 ] D. P. Kingma and M. Welling . Auto-Encoding Variational Bayes . In [ 10 ] M. Chen , Z. Zhang , T. Wang , M. Backes , M. Humbert , and Y. Zhang . ICLR , 2014 . When Machine Unlearning Jeopardize Privacy . In ACM CCS , 2021 . [ 11 ] M. Chen , Z. Zhang , T. Wang , M. Backes , M. Humbert , and Y. Zhang . Graph Unlearning . In ACM CCS , 2022 . [ 12 ] M. Chen , Z. Zhang , T. Wang , M. Backes , and Y. Zhang . FACE- AUDITOR : Data Auditing in Facial Recognition Systems . In USENIX Security , 2023 . [ 13 ] L. Du , M. Chen , M. Sun , S. Ji , P. Cheng , J. Chen , and Z. Zhang . ORL- Auditor : Dataset Auditing in Offline Deep Reinforcement Learning . In Network and Distributed System Security Symposium ( NDSS ) . Internet Society , 2024 . [ 14 ] L. Du , Z. Zhang , S. Bai , C. Liu , S. Ji , P. Cheng , and J. Chen . AHEAD : Adaptive Hierarchical Decomposition for Range Query under Local Differential Privacy . In ACM CCS , 2021 . [ 15 ] Y . Du , Y. Hu , Z. Zhang , Z. Fang , L. Chen , B. Zheng , and Y. Gao . LDPTrace : Locally Differentially Private Trajectory Synthesis . In VLDB , 2023 . [ 16 ] A. Dziedzic , H. Duan , M. A. Kaleem , N. Dhawan , J. Guan , Y. Cattan , F. Boenisch , and N. Papernot . Dataset Inference for Self-Supervised Models . CoRR , abs/2209.09024 , 2022 . [ 17 ] A. R. Fayjie , S. Hossain , D. Oualid , and D. Lee . Driverless Car : Autonomous Driving Using Deep Reinforcement Learning in Urban Environment . In International Conference on Ubiquitous Robots ( UR ) , pages 896–901 , 2018 . [ 18 ] J. Fu , A. Kumar , O. Nachum , G. Tucker , and S. Levine . D4RL : Datasets for Deep Data-Driven Reinforcement Learning . CoRR , abs/2004.07219 , 2020 . [ 19 ] S. Fujimoto , E. Conti , M. Ghavamzadeh , and J. Pineau . Bench- marking Batch Deep Reinforcement Learning Algorithms . CoRR , abs/1910.01708 , 2019 . [ 20 ] S. Fujimoto and S. S. Gu . A Minimalist Approach to Offline Rein- forcement Learning . In NeurIPS , pages 20132–20145 , 2021 . [ 21 ] S. Fujimoto , D. Meger , and D. Precup . Off-Policy Deep Reinforcement Learning without Exploration . In ICML , pages 2052–2062 , 2019 . [ 22 ] S. Fujimoto , H. van Hoof , and D. Meger . Addressing Function Approximation Error in Actor-Critic Methods . In ICML , pages 1582– 1591 , 2018 . [ 23 ] M. Gomrokchi , S. Amin , H. Aboutalebi , A. Wong , and D. Precup . Where Did You Learn That From ? Surprising Effectiveness of Mem- bership Inference Attacks Against Temporally Correlated Data in Deep Reinforcement Learning . CoRR , abs/2109.03975 , 2021 . [ 24 ] M. Gomrokchi , S. Main , S. Amin , and D. Precup . PrivAttack : A Membership Inference Attack Framework Against Deep Reinforcement Learning Agents . In NeurlPS Workshop , 2020 . [ 25 ] F. E. Grubbs . Sample Criteria for Testing Outlying Observations . The Annals of Mathematical Statistics , pages 27–58 , 1950 . [ 26 ] C¸ . G¨ulc¸ehre , Z. Wang , A. Novikov , T. Paine , S. G. Colmenarejo , K. Zolna , R. Agarwal , J. Merel , D. J. Mankowitz , C. Paduraru , G. Dulac-Arnold , J. Li , M. Norouzi , M. Hoffman , N. Heess , and N. de Freitas . RL Unplugged : A Collection of Benchmarks for Offline Reinforcement Learning . In NeurIPS 2020 , 2020 . [ 27 ] N. G¨urtler , S. Blaes , P. Kolev , F. Widmaier , M. Wuthrich , S. Bauer , B. Sch¨olkopf , and G. Martius . Benchmarking Offline Reinforcement Learning on Real-Robot Hardware . In ICLR , 2023 . [ 28 ] S. He , K. Shi , C. Liu , B. Guo , J. Chen , and Z. Shi . Collaborative Sensing in Internet of Things : A Comprehensive Survey . IEEE Communications Surveys & Tutorials , 2022 . [ 29 ] H. Huang , Z. Zhang , Y. Shen , M. Backes , Q. Li , and Y. Zhang . On the Privacy Risks of Cell-Based NAS Architectures . In ACM CCS , 2022 . [ 34 ] P. Kiourti , K. Wardega , J. Susmit , and W. Li . TrojDRL : Evaluation of [ 35 ] Backdoor Attacks on Deep Reinforcement Learning . In DAC , 2020 . I. Kostrikov , A. Nair , and S. Levine . Offline Reinforcement Learning with Implicit Q-Learning . In ICLR , 2022 . [ 36 ] S. Lange , T. Gabel , and M. A. Riedmiller . Batch Reinforcement In Reinforcement Learning , volume 12 of Adaptation , Learning . Learning , and Optimization , pages 45–73 . Springer , 2012 . [ 37 ] S. Levine , A. Kumar , G. Tucker , and J. Fu . Offline Reinforcement Learning : Tutorial , Review , and Perspectives on Open Problems . CoRR , abs/2005.01643 , 2020 . [ 38 ] Y. Li , Y. Bai , Y. Jiang , Y. Yang , S. Xia , and B. Li . Untargeted Backdoor Watermark : Towards Harmless and Stealthy Dataset Copyright Protec- tion . CoRR , abs/2210.00875 , 2022 . [ 39 ] Y. Li , Z. Zhang , J. Bai , B. Wu , Y. Jiang , and S. Xia . Open-sourced Dataset Protection via Backdoor Watermarking . CoRR , abs/2010.05821 , 2020 . [ 40 ] Z. Lin , J. Gehring , V. Khalidov , and G. Synnaeve . STARDATA : A StarCraft AI Research Dataset . CoRR , abs/1708.02139 , 2017 . [ 41 ] Y. Liu , R. Wen , X . He , A. Salem , Z. Zhang , M. Backes , E. D. Cristofaro , M. Fritz , and Y. Zhang . ML-Doctor : Holistic Risk Assessment of In USENIX Inference Attacks Against Machine Learning Models . Security , 2022 . [ 42 ] M. Lopez-Martin , B. Carro , and A. Sanchez-Esguevillas . Application of Deep Reinforcement Learning to Intrusion Detection for Supervised Problems . Expert Systems with Applications , 141:112963 , 2020 . [ 43 ] P. Maini , M. Yaghini , and N. Papernot . Dataset inference : Ownership resolution in machine learning . In ICLR , 2021 . [ 44 ] D. Mwiti . 10 Real-Life Applications of Reinforcement Learning . https : , 2021 . [ 45 ] H. Ono and T. Takahashi . Locally Private Distributed Reinforcement Learning . CoRR abs/2001.11718 , 2020 . [ 46 ] T. L. Paine , C. Paduraru , A. Michi , C¸ . G¨ulc¸ehre , K. Zolna , A. Novikov , Z. Wang , and N. de Freitas . Hyperparameter Selection for Offline Reinforcement Learning . CoRR , abs/2007.09055 , 2020 . [ 47 ] X. Pan , W. Wang , X. Zhang , B. Li , J. Yi , and D. Song . How You Act Tells a Lot : Privacy-Leaking Attack on Deep Reinforcement Learning . In AAMAS , pages 368–376 , 2019 . [ 48 ] A. Pattanaik , Z. Tang , S. Liu , G. Bommannan , and G. Chowdhary . Robust Deep Reinforcement Learning with Adversarial Attacks . In AAMAS , pages 2040–2042 , 2018 . [ 49 ] D. Pomerleau . ALVINN : An Autonomous Land Vehicle in a Neural Network . In NeurIPS , pages 305–313 , 1988 . [ 50 ] R. F. Prudencio , M. R. O . A. M´aximo , and E. L. Colombini . A Survey on Offline Reinforcement Learning : Taxonomy , Review , and Open Problems . CoRR , abs/2203.01387 , 2022 . [ 51 ] H. Pu , L. He , P. Cheng , M. Sun , and J. Chen . Security of Industrial Robots : Vulnerabilities , Attacks , and Mitigations . IEEE Network , 2022 . [ 52 ] R. Qin , S. Gao , X. Zhang , Z. Xu , S. Huang , Z. Li , W. Zhang , and Y. Yu . NeoRL : A Near Real-World Benchmark for Offline Reinforcement Learning . CoRR , abs/2102.00714 , 2021 . [ 53 ] A. Raffin , A. Hill , A. Gleave , A. Kanervisto , M. Ernestus , and Stable-Baselines3 : Reliable Reinforcement Learning N. Dormann . Implementations . Journal of Machine Learning Research , 22 ( 268 ) :1–8 , 2021 . [ 54 ] Y. Rubner , C. Tomasi , and L. J. Guibas . A Metric for Distributions with Applications to Image Databases . In ICCV , pages 59–66 , 1998 . [ 55 ] T. Rupprecht and Y. Wang . A Survey for Deep Reinforcement 15 Learning in Markovian Cyber-physical Systems : Common Problems and Solutions . Neural Networks , 153:13–36 , 2022 . [ 56 ] T. Seno and M. Imai . d3rlpy : An Offline Deep Reinforcement Learning Library . Journal of Machine Learning Research , 23 ( 315 ) :1–20 , 2022 . [ 57 ] R. Shokri , M. Stronati , C. Song , and V. Shmatikov . Membership Inference Attacks Against Machine Learning Models . In IEEE S & P , pages 3–18 , 2017 . [ 58 ] D. Silver , G. Lever , N. Heess , T. Degris , D. Wierstra , and M. A. Riedmiller . Deterministic Policy Gradient Algorithms . In ICML , pages 387–395 , 2014 . [ 59 ] M. A. Stephens . EDF Statistics for Goodness of Fit and Some Compar- isons . Journal of the American statistical Association , 69 ( 347 ) :730–737 , 1974 . [ 60 ] X. Tang , S. Mahloujifar , L. Song , V. Shejwalkar , M. Nasr , A. Houmansadr , and P. Mittal . Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture . In USENIX Security , pages 1433–1450 , 2022 . [ 61 ] Tessian . How the Great Resignation is Creating More Security Chal- lenges . https : ting-more-security-challenges/ , 2021 . [ 62 ] L. Van der Maaten and G. Hinton . Visualizing Data Using t-SNE . Journal of machine learning research , 9 ( 11 ) , 2008 . [ 63 ] H. Wang , Z. Zhang , T. Wang , S. He , M. Backes , J. Chen , and Y. Zhang . PrivTrace : Differentially Private Trajectory Synthesis by Adaptive Markov Model . In USENIX Security , 2023 . [ 64 ] L. Wang , Z. Javed , X. Wu , W. Guo , X. Xing , and D. Song . BACK- DOORL : Backdoor Attack against Competitive Reinforcement Learn- ing . In IJCAI , pages 3699–3705 , 2021 . [ 65 ] T. Wang , J. Q. Chen , Z. Zhang , D. Su , Y. Cheng , Z. Li , N. Li , and S. Jha . Continuous Release of Data Streams under both Centralized and Local Differential Privacy . In ACM CCS , 2021 . [ 66 ] Y. Wang , E. Sarkar , W. Li , M. Maniatakos , and S. E. Jabari . Stop- and-Go : Exploring Backdoor Attacks on Deep Reinforcement Learning- Based Traffic Congestion Control Systems . IEEE TIFS , 16:4772–4787 , 2021 . [ 67 ] Z. Yang , L. He , H. Yu , C. Zhao , P. Cheng , and J. Chen . Detecting PLC Intrusions using Control Invariants . IEEE IoT J , 9 ( 12 ) :9934–9947 , 2022 . [ 68 ] T. Yu , A. Kumar , R. Rafailov , A. Rajeswaran , S. Levine , and C. Finn . COMBO : Conservative Offline Model-Based Policy Optimization . In NeurIPS , pages 28954–28967 , 2021 . [ 69 ] Q. Yuan , Z. Zhang , L. Du , M. Chen , P. Cheng , and M. Sun . PrivGraph : Differentially Private Graph Data Publication by Exploiting Community Information . In USENIX Security , 2023 . [ 70 ] L. Zeng , M. Sun , X. Wan , Z. Zhang , R. Deng , and Y. Xu . Physics- constrained Vulnerability Assessment of Deep Reinforcement Learning- based SCOPF . IEEE TPS , 2022 . [ 71 ] Z. Zhang , T. Wang , N. Li , S. He , and J. Chen . CALM : Consistent Adaptive Local Marginal for Marginal Release under Local Differential Privacy . In ACM CCS , 2018 . [ 72 ] Z. Zhang , T. Wang , N. Li , J. Honorio , M. Backes , S. He , J. Chen , and Y. Zhang . PrivSyn : Differentially Private Data Synthesis . In USENIX Security , 2021 . A . The Behavior Similarity of Models APPENDIX In Figure 10 , we provide the behavior similarity of the offline RL models trained on the datasets in Table XV . Taking the Bipedal Walker task as an example , the dataset “ 0841 ” is regarded as the target dataset , and the other four are the public datasets . We observe that the behavior similarity of the RL models waves heavily among the different public training data . If the auditor adopts the dataset “ 1203 ” as the public training data , the auditor likely misclassifies the RL models trained on the other three public datasets into the bootleg models . In addition , the behavior similarity is also affected by different offline RL frameworks , i.e. , BC [ 49 ] , BCQ [ 21 ] , [ 19 ] , IQL [ 35 ] , and TD3PlusBC [ 20 ] ( detailed in Section II-B ) . B . The Details of Tasks Lunar Lander ( continuous version ) . The LunarLander task is to smoothly land a spaceship between two flags on the target pad . The landing pad is always at coordinates ( 0,0 ) . The ship has three throttles ; one throttle points downward ( the main engine ) and the other two points in the left and right direction ( the left and right engines ) . The observation is an 8-dimensional vector : the coordinates of the lander in the x- axis and y-axis , its linear velocities in the x-axis and y-axis , its angle , its angular velocity , and two booleans that represent whether each leg is in contact with the ground or not . The action is two real values ranging in [ −1 , 1 ] . The first dimension controls the main engine , where the engine is off when the value is in [ −1 , 0 ) and increases from 50 % to 100 % throttle when the value rises from 0 to 1 . The other two points are controlled by the second value , where the spaceship fires the left engine if the value in [ −1.0 , −0.5 ) , fires the right engine if the value in [ 0.5 , 1 ) , and shuts down both engines if the value in [ −0.5 , 0.5 ] . The reward for moving from the top of the screen to the landing pad and zero speed is about 140 points . Landing outside the landing pad is possible . Thus , the player loses the terminal reward if the lander moves away from the landing pad . The player gets 10 additional points for each leg touching the ground . Firing the main engine is -0.3 points in each frame . The episode finishes if the lander crashes or lands smoothly , receiving -100 or 100 points . Bipedal Walker . The Bipedal Walker task is to operate a 4-joint walker robot to move forward as fast as possible . The robot is made of a hull and two legs . Each leg has 2 joints at both the hip and knee . The observation of the task includes eight continuous physical variables , i.e. , hull angle speed , angular velocity , horizontal speed , vertical speed , the position of joints and joints angular speed , legs contact with ground , and 10 lidar rangefinder measurements . Actions are motor speed values in the [ -1 , 1 ] range for each of the 4 joints at both hips and knees . The walker starts standing at the left end of the terrain with the hull horizontal , and both legs in the same position with a slight knee angle . The reward is given for moving forward , totaling 300+ points up to the far end . If the robot falls , it gets -100 . Applying motor torque costs a small amount of points . A more optimal model will get a better score . The episode will terminate if the hull gets in contact with the ground or the walker exceeds the right end of the terrain length . Ant . In this task , the player manipulates a 3D robot ( ant ) , which consists of one torso ( free rotational body ) with four legs attached to it , with each leg having two links , to move in the forward ( right ) direction . The observation contains positional values of different body parts of the ant , followed by the velocities of those individual parts ( their derivatives ) , with all the positions ordered before all the velocities . By default , an observation is a vector with shape ( 111 , ) where the elements correspond to the following : position ( 1-dim ) , angles ( 12- dim ) , velocities ( 14-dim ) , and the information about the contact forces ( 84-dim ) . The player can apply torques on the eight hinges connecting the two links of each leg and the torso 16 Fig . 10 : Models ’ behavior similarity measured by ℓ1 Norm , ℓ2 Norm , Cosine Distance , and Wasserstein Distance . From Table XV , we use the first dataset of each task as the private training data and the remaining four datasets are the public training data . For each plot , the x-axis displays the four public training data , and the y-axis shows the absolute fluctuating values of the behavior similarity between the models trained on the private dataset and the public datasets . BC , BCQ , IQL , and TD3PlusBC are abbreviations for different offline RL frameworks . ( nine parts and eight hinges ) . Thus , the action space is an 8-dim continuous vector representing the torques applied at the hinge joints . The reward of the “ Ant ” task consists of four parts : healthy reward , forward reward , control cost , and contact cost . The total reward returned is reward = healthy reward + forward reward - control cost - contact cost . The task ends when either the ant state is unhealthy , or the episode duration reaches 1000 timesteps . C. Impact of Shadow Models ’ Amount We investigate the relationship between the number of shadow models and the audit accuracy . Setup . We change the shadow models ’ amount to 9 and 21 with the other settings the same as Section V-B . Figure 6 shows the value change of TPR and TNR compared with that of 15 shadow models . Each figure ’ s title illustrates the settings of the model and the task , the x-axis indicates the four metrics , and the y-axis is the absolute value change . Also , we provide the detailed results in Table VIII ( 9 Shadow Models ) and Table IX ( 21 Shadow Models ) . Observations . From Figure 6 , we have the following obser- vations . 1 ) The audit accuracy increases with a larger amount of shadow models . Since the values of shadow models are the multi-sampling of the true value Q ( s , a ) of the dataset , the mean and standard deviation will be more precise with more shadow models . For example , ORL-AUDITOR suffers an obvious TPR decline ( more than 30 % ) with 9 shadow models . Since the insufficient knowledge about the diversity of models trained on the target dataset , the auditor easily misclassifies the positive models to the negative group . 2 ) There exists a saturation point for audit accuracy with the expansion of shadow models . When the shadow models ’ amount rises from 15 to 21 , the TPR usually increases since the auditor observes more possible cumulative rewards originating from the model trained on the target dataset . We should note that the value changes slightly in most plots , meaning that similar cumulative rewards appear in the shadow model set , and the diversity does not increase significantly compared to that of 15 shadow models . Therefore , excessive shadow models are unnecessary , and the auditor needs to burden more training overhead . D. Impact of Significance Level The significance level represents the auditor ’ s confidence in the audit results . In Section V-B , we adopt the significance level α = 0.01 , meaning that the auditor has 99 % confidence in the judgments made . Generally speaking , the significance level represents the maximum audit capacity of ORL-AUDITOR instead of a hyperparameter setting since it is an audit re- quirement by the dataset owner . Setup . We demand the auditor to output a more confident judgment , where the error possibility should be limited to 1‰ and 0.1‰ , i.e. , α = 0.001 and α = 0.0001 . Figure 7 shows the value change of TPR and TNR compared with that when significance level α = 0.01 . The used offline DRL model and task is shown in each figure ’ s title . The x-axis indicates the four metrics and the y-axis is the absolute value change . 17 l e u a V l e u a V 1400.0 1200.0 1000.0 800.0 600.0 400.0 200.0 0.0 4000.0 3500.0 3000.0 2500.0 2000.0 1500.0 1000.0 500.0 0.0 4000.0 3000.0 2000.0 l e u a V 1000.0 0.0 l e u a V 5000.0 4000.0 3000.0 2000.0 1000.0 0.0 Lunar Lander , L1 Norm Lunar Lander , L2 Norm Lunar Lander , Cosine Distance BC BCQ IQL TD3PlusBC 2094 4496 6518 9906 Bipedal Walker , L1 Norm BC BCQ IQL TD3PlusBC 1203 2110 3813 Ant , L1 Norm 6558 BC BCQ IQL TD3PlusBC 3569 4603 5766 7490 Half Cheetah , L1 Norm BC BCQ IQL TD3PlusBC medium random Dataset Name rluply 1400.0 1200.0 1000.0 800.0 600.0 400.0 200.0 0.0 5000.0 4000.0 3000.0 2000.0 1000.0 0.0 4000.0 3500.0 3000.0 2500.0 2000.0 1500.0 1000.0 500.0 0.0 8000.0 7000.0 6000.0 5000.0 4000.0 3000.0 2000.0 1000.0 0.0 BC BCQ IQL TD3PlusBC 2094 4496 6518 9906 Bipedal Walker , L2 Norm BC BCQ IQL TD3PlusBC 1203 2110 3813 Ant , L2 Norm 6558 BC BCQ IQL TD3PlusBC 3569 4603 5766 7490 Half Cheetah , L2 Norm BC BCQ IQL TD3PlusBC medium random Dataset Name rluply 1.2 1.0 0.8 0.6 0.4 0.2 0.0 1.2 1.0 0.8 0.6 0.4 0.2 0.0 0.8 0.6 0.4 0.2 0.0 1.2 1.0 0.8 0.6 0.4 0.2 0.0 BC BCQ IQL TD3PlusBC 2094 4496 6518 9906 Bipedal Walker , Cosine Distance BC BCQ IQL TD3PlusBC 1203 2110 3813 6558 Ant , Cosine Distance BC BCQ IQL TD3PlusBC 3569 4603 5766 7490 Half Cheetah , Cosine Distance BC BCQ IQL TD3PlusBC medium random Dataset Name rluply 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 0.0 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0.0 0.2 0.18 0.15 0.12 0.1 0.08 0.05 0.02 0.0 0.6 0.5 0.4 0.3 0.2 0.1 0.0 Lunar Lander , Wasserstein Distance BC BCQ IQL TD3PlusBC 2094 9906 Bipedal Walker , Wasserstein Distance 4496 6518 BC BCQ IQL TD3PlusBC 1203 2110 3813 6558 Ant , Wasserstein Distance BC BCQ IQL TD3PlusBC 3569 7490 Half Cheetah , Wasserstein Distance 4603 5766 BC BCQ IQL TD3PlusBC medium random Dataset Name rluply 2 ) It should be noticed that a small trajectory size achieves better results under some tasks . For the Ant task , ORL- AUDITOR auditing with 25 % of the full length obtains at most 7 % promotion on the TNR results . Based on the analysis of [ 46 ] , the front states of each trajectory are able to reflect more behavioral information of the model . Thus , in this case , a shorter trajectory truncates the rear state-action pairs , which might be unimportant or even weaken the significance of the hypothesis testing . Exploring effective data auditing with shorter trajectory sizes or even using only the first state of each trajectory would be an interesting future direction . F. Additional Results As a supplementary of [ 13 ] , we provide additional results about ORL-AUDITOR . For ease of reading , we summarize the main figures and tables in Table VI . The detailed results between every two datasets are in Table X ( α = 0.001 ) and Table XI ( α = 0.0001 ) . Observations . From Figure 7 , we have the following obser- vations . 1 ) For a complicated task , we recommend the auditor to select a large significance level for ORL-AUDITOR . The task ’ s complexity affects the minimum significance level of ORL-AUDITOR . For example , TPR and TNP change a little on the Lunar Lander task when the significance level reduces to 0.001 , while they highly shrink on the Ant task . From Table I , Ant ’ s state and action space are larger than that of Lunar Lander . When the auditor leverages the critic model to compress each model ’ s state and action pair into a scalar , the deviation between Qi j ( recalling Figure 4 ) on the Ant task is more imperceptible . j and Qs 2 ) For the suspect models with low performance , ORL- AUDITOR should adopt a large significance level to guarantee audit accuracy . For instance , in the figure titled with “ Bipedal Walker , TD3PlusBC ” , all TNR results from four distance metrics decrease when α reduces to 0.001 and 0.0001 . From Table XIX , most of the TD3PlusBC models ’ performance on the Bipedal Walker task is around -100 , meaning that the TD3PlusBC models do not fully master the knowledge of the dataset . Thus , the dataset features reflected in their behavior are ambiguous , which weakens the difference between positive and negative samples . Meanwhile , the confidence interval , i.e. , ∆ in Figure 1 , expands with a lower significance level . For the above two reasons , the TNR results of the TD3PlusBC models on the Bipedal Walker task drop more than 10 % compared with these when α = 0.01 . From the above analysis , α = 0.01 is a safe bound of ORL-AUDITOR , and a lower α may break through the capability boundary of ORL-AUDITOR , inducing the auditor to misclassify the negative model to the positive set . E. Impact of Trajectory Size We investigate the relationship between the trajectory size and audit accuracy . In Section V-B , we adopt the full-length trajectory , meaning that the auditor utilizes all states of each trajectory to query the suspect model and obtains the corre- sponding actions to conduct the dataset audit . Setup . We change the trajectory size to 25 % and 50 % of the full length with the other settings the same as Section V-B . Figure 8 shows the value change of TPR and TNR compared with that of the full-length trajectory . Each figure ’ s title illus- trates the settings of the model and the task , the x-axis indicates the four metrics , and the y-axis is the absolute value change . Also , we provide the detailed results in Table XII ( 25 % ) and Table XIII ( 50 % ) . Observation . From Figure 8 , we have the following observa- tions . 1 ) ORL-AUDITOR tends to achieve higher accuracy with a larger trajectory size . Since the predicted cumulative rewards of state-action pairs from the critic model are the audit basis , a longer trajectory collects more actions from the suspect model to enhance the significance of hypothesis testing . For example , the TNP results decrease at most 13 % when ORL-AUDITOR only leverages 25 % of the trajectory . 18 TABLE VI : The roadmap of the main figures and tables . Information Overview of tasks Online DRL models Involved Content Section V-A Section V-A Name Table I Table XIV Offline Datasets Section V-A Table XV Offline DRL models Section V Overall audit performance Section V-B Impact of shadow models ’ amount Appendix C Impact of significance level Appendix D Impact of trajectory size Appendix E Real-world application Section V-E Robustness : ensemble architecture Section VI-A Robustness : perturbing models output Section VI-B Table XVI Table XVII Table XVIII Table XIX Table IV Table VII Figure 11 Figure 12 Figure 13 Figure 6 Table VIII Table IX Figure 7 Table X Table XI Figure 8 Table XII Table XIII Table XXII Table XX Table XXI Table V Figure 14 Figure 16 Figure 17 Figure 9 Figure 18 Figure 19 Figure 20 Figure 21 Figure 22 Figure 23 Description The state shape and the action shape of each task . The performance of the used online models for collecting the offline datasets . The name , the number of trajectories , and the length of trajectory for each offline dataset . The offline models ’ performance with or without defense against ORL- AUDITOR : normal performance ( without defense ) , defended by model ensemble , and defended by perturbing models ’ output . The true positive rate ( TPR ) and true negative rate ( TNR ) results based on Grubbs ’ test and 3σ principle . The change values of TPR and TNR when the number of shadow models varies to 9 and 21 compared to the default 15 shadow models . The change value of TPR and TNR when the significance level ( σ ) varies to 0.001 and 0.0001 compared to the default 0.01 . The change value of TPR and TNR when the trajectory size varies to 25 % and 50 % compared to the default 100 % ( full length ) . The TPR and TNR results on the Half Cheetah datasets , which are published by DeepMind and Google separately . The TPR and TNR results of ORL-AUDITOR against model ensemble ( K = 5 ) . The TPR and TNR results of ORL-AUDITOR against models ’ action distortion . TABLE VII : As a supplementary of [ 13 ] , we provide the TPR and TNR results of ORL-AUDITOR based on 3σ principle . The mean and standard deviation of TPR and TNR in each row represent the audit results for one combination of task and model by four distance metrics . Bold indicates the highest sum of TPR and TNR , i.e. , accuracy , in a row . Task Name Offline Model Lunar Lander Bipedal Walker Ant BC BCQ IQL TD3PlusBC BC BCQ IQL TD3PlusBC BC BCQ IQL TD3PlusBC L1 Norm L2 Norm Cosine Distance Wasserstein Distance TPR 96.53±1.36 96.13±3.01 97.20±3.24 95.60±4.39 96.56±4.27 96.67±4.20 94.33±7.45 97.00±4.46 90.67±5.30 90.40±8.68 90.67±6.93 95.62±5.19 TNR 100.00±0.00 100.00±0.00 99.97±0.28 99.54±2.53 100.00±0.00 100.00±0.00 100.00±0.00 99.90±1.16 100.00±0.00 99.96±0.42 100.00±0.00 99.74±1.79 TPR 95.47±2.81 94.80±3.18 96.27±2.44 92.80±5.07 95.78±4.58 94.78±7.43 93.78±7.25 94.11±8.63 93.33±4.62 94.13±3.83 89.60±3.99 94.12±5.03 TNR 100.00±0.00 100.00±0.00 100.00±0.00 99.91±0.47 100.00±0.00 100.00±0.00 100.00±0.00 97.80±12.09 100.00±0.00 99.94±0.56 100.00±0.00 99.35±2.58 TPR 95.73±2.58 94.67±2.92 96.53±2.40 93.33±5.40 98.33±2.50 98.67±1.63 98.89±2.17 95.33±6.66 99.20±0.88 98.00±2.00 97.20±3.89 99.08±1.54 TNR 100.00±0.00 100.00±0.00 100.00±0.00 99.93±0.40 100.00±0.00 100.00±0.00 100.00±0.00 97.78±12.19 88.00±27.55 88.47±26.83 88.30±27.38 88.52±26.25 TPR 96.13±2.02 96.40±2.92 96.53±4.14 96.67±2.88 97.22±4.05 97.11±3.69 94.00±9.45 96.44±5.95 95.20±2.99 93.47±6.81 91.20±9.03 97.74±2.66 TNR 100.00±0.00 99.95±0.36 98.90±3.33 96.86±7.24 100.00±0.00 100.00±0.00 100.00±0.00 93.87±19.73 99.99±0.07 99.95±0.49 100.00±0.00 99.60±2.13 19 Fig . 11 : The audit accuracy between every two Lunar Lander datasets . The caption of each plot demonstrates the offline DRL model ’ s type , the task , and the distance metric . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . Fig . 12 : The audit accuracy between every two Bipedal Walker datasets . The caption of each plot demonstrates the offline DRL model ’ s type , the task , and the distance metric . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . 20 Lunar Lander , BC , L1 Norm Lunar Lander , BC , L2 Norm Lunar Lander , BC , Cosine Distance 98.5 98.8 99.9 2094 4496 Lunar Lander , BCQ , L1 Norm 6518 96.9 1171 95.6 98.8 9906 95.9 97.2 96.8 95.7 97.2 98.1 98.1 2094 4496 Lunar Lander , BCQ , L2 Norm 6518 1171 2094 4496 Lunar Lander , BCQ , Cosine Distance 6518 96.8 9906 95.5 99.8 Lunar Lander , BC , Wasserstein Distance 99.5 99.8 99.9 98.1 99.9 99.3 97.2 98.7 99.9 2094 98.5 9906 4496 1171 Lunar Lander , BCQ , Wasserstein Distance 99.9 99.7 97.7 6518 1171 99.1 2094 4496 6518 9906 1171 1171 98.5 1171 2094 4496 6518 9906 1171 2094 4496 6518 9906 96.4 99.6 94.3 96.9 97.7 95.7 2094 4496 Lunar Lander , IQL , L1 Norm 6518 99.2 9906 1171 2094 4496 Lunar Lander , IQL , L2 Norm 6518 99.5 99.7 99.1 99.9 96.1 99.6 94.4 96.7 9906 97.6 9906 99.5 98.5 2094 1171 4496 Lunar Lander , TD3PlusBC , L1 Norm 99.9 6518 97.6 9906 1171 2094 4496 Lunar Lander , TD3PlusBC , L2 Norm 6518 94.5 9906 1171 97.7 2094 4496 6518 9906 99.9 98.1 94.5 98.9 1171 98.5 2094 99.7 4496 98.1 99.5 98.0 6518 98.3 99.9 9906 92.8 99.9 98.9 99.9 92.5 99.1 1171 99.9 2094 99.7 4496 99.9 98.7 9906 98.8 99.5 6518 92.4 99.9 98.8 99.5 99.1 1171 2094 94.4 96.8 95.7 96.4 99.9 99.9 99.9 99.2 99.5 99.6 96.1 1171 2094 4496 Lunar Lander , IQL , Cosine Distance 6518 97.5 9906 99.1 99.6 99.6 99.4 99.4 99.9 94.0 94.8 1171 9906 4496 Lunar Lander , TD3PlusBC , Cosine Distance 6518 2094 99.8 2094 98.4 9906 4496 1171 Lunar Lander , IQL , Wasserstein Distance 89.4 74.8 6518 99.6 97.6 98.9 98.5 99.1 99.2 99.5 98.4 98.9 99.7 94.9 95.5 99.9 96.9 95.7 2094 98.9 1171 99.9 4496 Lunar Lander , TD3PlusBC , Wasserstein Distance 87.1 99.9 6518 98.3 9906 97.9 99.5 93.4 98.7 92.4 99.7 4496 98.7 6518 99.1 9906 98.9 94.7 93.9 1171 99.6 97.3 99.1 93.3 2094 98.9 96.4 98.6 94.5 4496 94.4 94.1 99.1 96.7 6518 85.6 96.5 96.7 99.7 9906 Bipedal Walker , BC , L1 Norm Bipedal Walker , BC , L2 Norm Bipedal Walker , BC , Cosine Distance Bipedal Walker , BC , Wasserstein Distance 96.3 98.9 99.9 99.7 96.7 1203 2110 Bipedal Walker , BCQ , L1 Norm 3813 99.7 6558 0841 1203 2110 Bipedal Walker , BCQ , L2 Norm 3813 93.1 6558 0841 1203 2110 Bipedal Walker , BCQ , Cosine Distance 3813 93.2 6558 99.9 6558 2110 0841 Bipedal Walker , BCQ , Wasserstein Distance 1203 3813 0841 1203 2110 3813 6558 0841 0841 99.9 1203 2110 3813 6558 0841 1203 2110 3813 6558 0841 1203 2110 98.0 92.5 99.9 99.7 99.7 98.3 99.9 99.7 0841 1203 2110 Bipedal Walker , IQL , L1 Norm 3813 6558 0841 1203 2110 Bipedal Walker , IQL , L2 Norm 3813 6558 0841 1203 2110 Bipedal Walker , IQL , Cosine Distance 3813 99.6 6558 1203 6558 2110 0841 Bipedal Walker , IQL , Wasserstein Distance 3813 99.5 80.7 93.7 85.2 95.5 96.4 99.2 95.5 82.0 97.6 0841 1203 2110 Bipedal Walker , TD3PlusBC , L1 Norm 3813 99.9 6558 10.4 0841 1203 2110 Bipedal Walker , TD3PlusBC , L2 Norm 89.1 3813 0.7 99.9 6558 0841 1203 2110 Bipedal Walker , TD3PlusBC , Cosine Distance 87.9 6558 3813 99.7 0.1 0841 2110 Bipedal Walker , TD3PlusBC , Wasserstein Distance 3813 1203 6558 1.9 48.7 3813 96.0 98.0 94.9 6558 0841 1203 2110 3813 96.0 96.8 6558 94.0 96.0 96.5 0841 1203 2110 3813 99.5 92.0 94.0 94.4 0841 1203 2110 3813 97.1 94.0 85.7 6558 79.6 92.0 85.3 6558 92.0 94.2 98.0 94.5 43.8 0841 1203 2110 3813 92.0 90.4 6558 Fig . 13 : The audit accuracy between every two Ant datasets . The caption of each plot demonstrates the offline DRL model ’ s type , the task , and the distance metric . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . TABLE VIII : The impact of shadow models ’ amount . The TPR and TNR results of ORL-AUDITOR with 9 shadow models . Task Name Lunar Lander Bipedal Walker Ant Offline Model BC BCQ IQL TPR 97.09±1.09 96.97±1.65 96.89±1.96 TD3PlusBC 97.24±2.17 95.14±3.54 93.90±5.98 88.55±10.61 TD3PlusBC 97.39±5.22 90.61±6.99 92.65±3.46 97.05±1.06 TD3PlusBC 93.57±7.04 BC BCQ IQL BC BCQ IQL L1 Norm L2 Norm Cosine Distance Wasserstein Distance TNR 100.00±0.00 100.00±0.00 99.90±0.37 99.32±0.84 100.00±0.00 100.00±0.00 100.00±0.00 94.30±20.23 99.93±0.16 99.78±0.50 99.58±0.92 99.35±1.27 TPR 94.97±1.31 94.53±1.20 95.22±2.85 93.77±3.64 89.68±10.06 95.47±3.37 87.79±8.56 96.57±6.86 92.25±4.98 90.00±5.47 94.44±2.40 93.15±4.39 TNR 100.00±0.00 100.00±0.00 99.98±0.07 99.82±0.45 100.00±0.00 100.00±0.00 100.00±0.00 90.88±22.63 99.95±0.17 99.88±0.27 99.63±0.72 99.59±1.05 TPR 95.09±1.41 94.48±1.09 95.03±3.13 93.81±3.71 97.70±3.59 98.69±0.93 98.80±1.27 97.30±4.95 98.91±0.99 98.02±1.01 99.12±0.43 99.35±0.75 TNR 100.00±0.00 99.98±0.10 99.91±0.22 99.78±0.49 100.00±0.00 100.00±0.00 100.00±0.00 88.39±24.21 85.17±28.30 85.88±28.10 85.16±28.62 87.99±26.18 TPR 96.55±1.98 97.03±1.51 96.82±2.14 97.54±1.16 94.80±3.69 95.35±4.04 90.68±8.87 96.08±7.85 96.23±3.90 98.11±1.42 98.50±1.30 97.86±1.32 TNR 99.93±0.26 99.78±0.38 96.85±6.45 95.45±3.71 100.00±0.00 100.00±0.00 100.00±0.00 84.40±30.65 99.92±0.16 99.76±0.52 99.57±0.93 99.30±1.36 21 Ant , BC , L1 Norm Ant , BC , L2 Norm 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 97.5 99.7 99.9 2232 96.4 98.9 2232 93.7 98.5 99.8 2232 99.9 98.0 99.6 99.1 99.9 99.8 94.3 3569 4603 Ant , BCQ , L1 Norm 5766 99.9 97.9 98.7 98.7 99.9 91.9 3569 4603 Ant , IQL , L1 Norm 5766 99.9 99.6 97.5 97.1 97.9 99.9 99.9 3569 4603 Ant , TD3PlusBC , L1 Norm 5766 99.9 98.3 7490 99.9 99.7 7490 99.6 99.9 95.7 7490 2232 3569 99.1 4603 99.8 96.4 5766 97.5 99.5 7490 98.3 96.2 92.5 98.0 98.8 95.9 99.9 2232 94.0 99.1 2232 91.9 98.9 99.9 2232 97.9 99.5 98.3 96.3 99.9 99.1 94.0 3569 4603 Ant , BCQ , L2 Norm 5766 98.3 94.9 99.5 98.4 92.3 3569 4603 Ant , IQL , L2 Norm 5766 99.9 97.2 7490 99.5 99.9 9.0 2232 99.9 99.5 98.8 7490 10.7 2232 Ant , BC , Cosine Distance 99.9 98.0 56.1 97.1 99.9 93.8 99.6 88.6 3569 99.9 4603 Ant , BCQ , Cosine Distance 56.1 5766 12.0 99.9 99.9 7490 Ant , BC , Wasserstein Distance 99.9 97.9 99.5 99.7 99.9 99.5 99.1 99.9 99.7 99.8 97.5 2232 3569 4603 Ant , BCQ , Wasserstein Distance 5766 96.1 7490 98.1 98.8 65.9 14.7 99.5 99.9 92.9 99.9 99.9 97.1 98.9 98.6 99.9 98.6 99.9 96.3 90.9 3569 99.9 4603 Ant , IQL , Cosine Distance 62.0 5766 99.9 7490 11.9 2232 99.6 98.5 99.8 3569 4603 Ant , IQL , Wasserstein Distance 5766 99.9 99.1 97.5 99.3 97.6 99.9 99.9 7490 99.6 99.8 98.7 97.3 98.1 96.7 98.5 99.9 98.3 99.8 99.3 98.7 98.0 99.1 74.7 99.7 92.4 99.9 3569 4603 Ant , TD3PlusBC , L2 Norm 5766 98.9 7490 8.8 2232 90.5 3569 99.6 4603 Ant , TD3PlusBC , Cosine Distance 50.3 5766 7490 2232 3569 4603 Ant , TD3PlusBC , Wasserstein Distance 5766 98.8 7490 96.1 99.0 94.6 92.0 98.2 99.7 99.0 99.5 99.9 99.6 99.9 98.9 98.2 7.1 2232 99.7 91.5 3569 97.2 7490 75.2 99.1 91.3 99.9 89.3 5766 99.2 99.9 92.2 100.0 4603 14.1 99.5 99.7 99.5 99.1 97.5 99.5 98.3 96.8 92.0 97.8 98.8 7490 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 2232 3569 4603 5766 TABLE IX : The impact of shadow models ’ amount . The TPR and TNR results of ORL-AUDITOR with 21 shadow models . Task Name Lunar Lander Bipedal Walker Ant Offline Model BC BCQ IQL TPR 99.25±0.97 99.56±0.32 97.95±2.45 TD3PlusBC 97.87±3.45 97.07±3.60 100.00±0.00 95.91±4.93 TD3PlusBC 99.91±0.18 98.13±1.55 97.16±2.73 95.91±3.87 TD3PlusBC 99.44±0.60 BC BCQ IQL BC BCQ IQL L1 Norm L2 Norm Cosine Distance Wasserstein Distance TNR 100.00±0.00 100.00±0.00 99.96±0.17 99.45±0.84 100.00±0.00 100.00±0.00 100.00±0.00 95.05±19.14 99.91±0.18 99.81±0.42 99.64±0.77 99.23±1.53 TPR 98.13±1.88 98.40±0.68 97.11±3.12 96.09±3.91 97.24±4.49 99.56±0.69 96.36±4.57 99.87±0.27 97.73±1.19 96.67±2.18 96.49±3.89 98.27±1.03 TNR 100.00±0.00 100.00±0.00 99.98±0.09 99.73±0.58 100.00±0.00 100.00±0.00 100.00±0.00 93.96±20.97 99.86±0.41 99.84±0.42 99.68±0.63 99.36±1.64 TPR 98.00±1.84 98.27±0.47 96.85±3.40 95.78±4.29 97.69±4.51 99.07±1.65 99.51±0.26 99.82±0.36 99.73±0.53 99.69±0.41 99.51±0.67 99.76±0.33 TNR 100.00±0.00 99.99±0.04 99.92±0.19 99.95±0.14 100.00±0.00 100.00±0.00 100.00±0.00 92.79±21.27 86.82±26.97 87.53±26.74 86.53±27.80 88.42±25.93 TPR 99.11±0.93 98.80±0.78 97.11±3.65 98.00±2.60 98.36±2.67 99.96±0.09 96.44±4.54 99.91±0.18 97.55±1.57 98.58±1.69 97.65±2.19 99.79±0.27 TNR 99.96±0.10 99.75±0.41 97.47±5.34 96.27±3.43 100.00±0.00 100.00±0.00 100.00±0.00 91.78±21.28 99.90±0.21 99.80±0.43 99.64±0.78 99.18±1.65 TABLE X : The impact of significance level . The TPR and TNR results of ORL-AUDITOR with σ = 0.001 . Task Name Lunar Lander Bipedal Walker Ant Offline Model BC BCQ IQL TPR 99.63±0.19 99.15±0.67 99.31±0.90 TD3PlusBC 99.20±1.10 99.97±0.05 99.95±0.06 97.04±5.47 TD3PlusBC 99.92±0.16 99.52±0.50 98.91±1.68 98.88±1.27 TD3PlusBC 99.62±0.46 BC BCQ IQL BC BCQ IQL L1 Norm L2 Norm Cosine Distance Wasserstein Distance TNR 100.00±0.00 100.00±0.00 99.83±0.40 99.22±0.89 100.00±0.00 100.00±0.00 100.00±0.00 89.69±22.99 99.86±0.25 99.71±0.60 99.53±0.97 98.92±2.08 TPR 98.21±0.55 97.60±1.13 98.56±1.51 97.47±2.33 98.67±2.67 99.73±0.34 95.81±5.06 97.17±5.65 98.48±0.80 97.97±1.43 98.42±1.80 98.73±0.97 TNR 100.00±0.00 100.00±0.00 99.96±0.16 99.61±0.55 100.00±0.00 100.00±0.00 100.00±0.00 85.59±27.05 99.88±0.40 99.81±0.47 99.60±0.73 99.24±1.91 TPR 98.21±0.63 97.63±1.04 98.51±1.59 97.55±2.22 98.64±2.66 99.95±0.06 99.87±0.27 97.20±5.60 99.55±0.66 99.87±0.15 99.71±0.52 99.79±0.36 TNR 100.00±0.00 99.97±0.13 99.79±0.51 99.75±0.51 100.00±0.00 100.00±0.00 100.00±0.00 82.52±30.48 80.58±33.24 81.88±31.60 80.90±32.60 84.36±28.07 TPR 99.31±0.38 98.59±0.95 99.04±1.21 99.49±0.56 100.00±0.00 99.97±0.05 97.68±4.51 99.68±0.64 99.36±0.49 99.52±0.64 99.92±0.06 99.71±0.58 TNR 99.84±0.38 99.61±0.53 94.88±8.21 92.45±5.32 100.00±0.00 100.00±0.00 100.00±0.00 80.18±35.21 99.85±0.25 99.69±0.63 99.49±1.05 98.78±2.15 TABLE XI : The impact of significance level . The TPR and TNR results of ORL-AUDITOR with σ = 0.0001 . Task Name Lunar Lander Bipedal Walker Ant Offline Model BC BCQ IQL TPR 99.87±0.12 99.49±0.46 99.71±0.52 TD3PlusBC 99.55±0.56 100.00±0.00 100.00±0.00 98.53±2.87 TD3PlusBC 100.00±0.00 99.95±0.11 99.33±1.21 99.73±0.29 TD3PlusBC 99.96±0.05 BC BCQ IQL BC BCQ IQL L1 Norm L2 Norm Cosine Distance Wasserstein Distance TNR 100.00±0.00 100.00±0.00 99.66±0.55 98.80±1.27 100.00±0.00 100.00±0.00 100.00±0.00 79.08±38.26 99.80±0.41 99.56±0.76 99.35±1.25 98.65±2.42 TPR 98.93±0.34 98.48±0.79 98.99±1.04 98.48±1.48 98.67±2.67 99.81±0.26 96.27±4.74 97.23±5.55 99.15±0.67 98.75±1.11 98.91±1.45 99.35±0.50 TNR 100.00±0.00 100.00±0.00 99.91±0.21 98.96±1.24 100.00±0.00 100.00±0.00 100.00±0.00 75.43±39.10 99.85±0.43 99.80±0.48 99.56±0.80 99.11±2.07 TPR 99.04±0.35 98.48±0.82 98.91±1.17 98.56±1.49 98.80±2.40 100.00±0.00 99.87±0.27 97.33±5.33 99.73±0.41 99.92±0.11 99.89±0.21 99.92±0.11 TNR 100.00±0.00 99.95±0.20 99.49±1.15 99.38±0.87 100.00±0.00 100.00±0.00 100.00±0.00 74.60±39.23 77.36±35.68 78.87±33.94 77.78±34.93 81.33±29.74 TPR 99.79±0.22 99.33±0.54 99.52±0.70 99.84±0.16 100.00±0.00 100.00±0.00 98.67±2.67 99.97±0.05 99.73±0.22 99.81±0.23 100.00±0.00 99.90±0.19 TNR 99.56±0.79 98.88±1.54 91.46±10.53 88.16±6.84 100.00±0.00 100.00±0.00 100.00±0.00 73.98±38.98 99.79±0.42 99.52±0.79 99.32±1.31 98.06±3.18 22 TABLE XII : The impact of trajectory size . The TPR and TNR results of ORL-AUDITOR with 25 % trajectory size . Task Name Lunar Lander Bipedal Walker Ant Offline Model BC BCQ IQL TPR 98.13±1.05 98.45±0.51 98.11±1.65 TD3PlusBC 98.00±2.42 99.20±0.97 98.59±2.63 96.80±5.37 TD3PlusBC 97.55±4.91 98.85±0.67 98.11±1.40 98.45±1.00 TD3PlusBC 98.80±1.33 BC BCQ IQL BC BCQ IQL L1 Norm L2 Norm Cosine Distance Wasserstein Distance TNR 99.53±1.30 99.28±1.19 95.42±5.71 95.44±4.57 100.00±0.00 100.00±0.00 100.00±0.00 94.08±21.64 99.90±0.35 99.85±0.34 99.90±0.30 99.76±0.43 TPR 96.27±2.00 97.33±0.76 96.72±2.57 96.43±3.13 97.47±3.12 97.68±2.95 95.73±5.42 97.20±5.60 97.04±1.24 97.36±1.61 96.45±1.47 96.92±1.60 TNR 99.64±1.09 99.59±0.71 97.10±3.96 96.86±3.24 100.00±0.00 100.00±0.00 100.00±0.00 89.72±24.95 99.84±0.47 99.78±0.46 99.85±0.40 99.70±0.67 TPR 96.29±1.97 96.91±1.06 96.80±2.25 95.95±2.56 98.61±2.71 99.68±0.27 99.41±0.45 96.93±5.74 99.49±0.88 99.49±0.76 99.68±0.51 99.22±1.18 TNR 99.13±2.41 99.01±1.33 92.42±5.78 92.95±3.92 100.00±0.00 100.00±0.00 100.00±0.00 90.65±23.69 92.58±19.10 92.64±19.34 92.56±20.01 93.58±17.31 TPR 98.10±0.92 98.56±1.10 98.19±1.55 98.45±1.43 99.36±0.90 98.61±2.45 97.01±5.45 97.41±5.17 98.96±0.81 99.12±0.59 99.04±0.55 99.28±1.07 TNR 97.74±2.30 94.02±4.44 84.64±9.09 81.51±9.13 100.00±0.00 100.00±0.00 100.00±0.00 84.06±33.72 99.90±0.35 99.84±0.34 99.80±0.49 99.74±0.45 TABLE XIII : The impact of trajectory size . The TPR and TNR results of ORL-AUDITOR with 50 % trajectory size . Task Name Lunar Lander Bipedal Walker Ant Offline Model BC BCQ IQL TPR 98.37±0.68 98.16±0.55 98.03±2.25 TD3PlusBC 98.03±2.33 99.44±0.75 98.75±2.38 95.68±6.60 TD3PlusBC 98.35±3.31 98.21±0.98 97.76±2.05 97.71±1.81 TD3PlusBC 98.52±1.81 BC BCQ IQL BC BCQ IQL L1 Norm L2 Norm Cosine Distance Wasserstein Distance TNR 100.00±0.00 99.96±0.19 98.93±1.35 98.28±2.03 100.00±0.00 100.00±0.00 100.00±0.00 94.29±21.47 99.92±0.24 99.85±0.36 99.73±0.61 99.61±0.77 TPR 97.07±0.90 96.11±0.83 96.80±2.84 96.37±3.41 97.81±2.83 97.92±2.81 95.47±5.34 97.20±5.60 97.04±1.33 96.72±1.50 96.53±1.65 96.99±1.57 TNR 100.00±0.00 99.95±0.20 99.29±1.06 99.27±0.97 100.00±0.00 100.00±0.00 100.00±0.00 91.75±22.51 99.85±0.43 99.81±0.44 99.82±0.40 99.74±0.64 TPR 97.25±0.72 96.40±0.84 97.25±2.18 96.51±2.98 98.67±2.67 99.89±0.10 99.81±0.31 96.96±6.02 99.49±0.83 99.60±0.60 99.79±0.30 99.82±0.25 TNR 100.00±0.02 99.58±0.80 96.38±2.48 95.94±4.14 100.00±0.00 100.00±0.00 100.00±0.00 90.88±23.07 88.52±25.25 89.27±24.10 88.67±25.63 90.62±24.30 TPR 98.58±0.50 97.57±1.64 98.27±2.29 98.24±1.79 99.41±0.86 99.55±0.72 96.40±6.11 97.41±5.17 98.59±0.81 98.88±1.30 98.99±0.65 99.13±1.29 TNR 98.50±1.91 96.28±3.72 86.89±10.96 84.30±8.08 100.00±0.00 100.00±0.00 100.00±0.00 89.04±27.90 99.92±0.24 99.84±0.36 99.70±0.66 99.58±0.79 TABLE XIV : The details of the online models for generating the offline datasets . The model performance shows the cumulative reward for 10 separate evaluations . Task Name Online Model Train Step Model Name Model Performance Lunar Lander SAC 1e6 Bipedal Walker PPO 1e6 Ant SAC 2e6 1171 2094 4496 6518 9906 0841 1203 2110 3813 6558 2232 3569 4603 5766 7490 275.47±14.38 50.79±65.95 195.02±143.15 246.40±33.91 209.33±91.73 285.55±60.84 286.94±53.46 283.58±47.35 235.88±103.83 285.16±65.92 5377.70±1653.17 1924.58±1180.96 5531.45±844.10 3025.89±547.36 5897.37±477.34 23 Fig . 14 : The audit accuracy against model ensemble for Lunar Lander . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the hyperparameter K of the model ensemble . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . TABLE XV : The details of the offline DRL datasets Task Name Number of Transitions Dataset Name Number of Trajectories Length of trajectory Lunar Lander 5e5 Bipedal Walker 1e6 Ant 2e6 2175 578 1252 1878 1566 1019 1027 877 887 1041 2093 3497 2096 2217 2103 229.83±83.51 864.19±231.88 399.30±240.88 266.13±99.65 319.21±231.06 981.03±190.79 973.07±118.42 1139.55±151.10 1126.63±379.05 959.77±146.13 955.46±177.72 571.66±375.40 954.01±175.82 901.84±236.93 951.02±187.93 1171 2094 4496 6518 9906 0841 1203 2110 3813 6558 2232 3569 4603 5766 7490 24 Lunar Lander , BC , L1 Norm , K = 5 Lunar Lander , BC , L2 Norm , K = 5 Lunar Lander , BC , Cosine , K = 5 Lunar Lander , BC , Wasserstein , K = 5 98.0 98.0 98.0 98.0 98.0 98.0 1171 2094 4496 6518 9906 1171 2094 4496 Lunar Lander , BCQ , L1 Norm , K = 5 6518 9906 1171 2094 4496 Lunar Lander , BCQ , L2 Norm , K = 5 6518 9906 1171 2094 4496 Lunar Lander , BCQ , Cosine , K = 5 6518 9906 1171 98.0 98.0 98.0 2094 4496 6518 9906 1171 2094 4496 6518 9906 1171 2094 4496 6518 9906 1171 2094 4496 Lunar Lander , IQL , L1 Norm , K = 5 6518 9906 1171 2094 4496 Lunar Lander , IQL , L2 Norm , K = 5 6518 94.0 9906 1171 2094 4496 Lunar Lander , IQL , Cosine , K = 5 6518 94.0 9906 98.0 98.0 98.0 98.0 98.0 98.0 94.0 98.0 98.0 2094 9906 4496 1171 Lunar Lander , TD3PlusBC , L1 Norm , K = 5 6518 98.0 9906 4496 1171 Lunar Lander , TD3PlusBC , L2 Norm , K = 5 2094 6518 2094 9906 4496 1171 Lunar Lander , TD3PlusBC , Cosine , K = 5 6518 96.0 1171 96.0 2094 4496 Lunar Lander , TD3PlusBC , Wasserstein , K = 5 92.0 6518 98.0 92.0 98.0 9906 98.0 98.0 98.0 98.0 98.0 1171 98.0 2094 98.0 4496 98.0 6518 9906 98.0 1171 2094 4496 6518 9906 98.0 1171 2094 98.0 98.0 4496 6518 9906 96.0 96.0 98.0 96.0 1171 92.0 2094 94.0 94.0 98.0 6518 86.0 98.0 96.0 9906 98.0 98.0 92.0 4496 2094 1171 9906 4496 Lunar Lander , BCQ , Wasserstein , K = 5 6518 1171 2094 4496 Lunar Lander , IQL , Wasserstein , K = 5 88.0 84.0 6518 98.0 98.0 9906 Fig . 15 : The audit accuracy against model ensemble for Bipedal Walker . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the hyperparameter K of the model ensemble . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . TABLE XVI : As a supplementary of [ 13 ] , we provide more details of the BC offline models . The model performance shows the cumulative reward for 10 separate evaluations . Offline Model Task Name Lunar Lander BC Bipedal Walker Ant Dataset Name 1171 2094 4496 6518 9906 0841 1203 2110 3813 6558 2232 3569 4603 5766 7490 Model Performance ( No Defense ) 272.06±5.14 39.04±34.07 173.62±58.93 211.85±43.52 225.45±32.91 264.92±29.11 288.85±15.39 276.80±26.03 164.56±46.14 281.02±48.65 5479.72±354.79 1493.77±413.96 5424.74±422.83 2806.80±286.57 5514.17±441.78 Model Performance ( Trajectory Splitting ) 269.17±11.28 46.65±37.73 183.34±47.00 215.13±57.35 213.70±40.65 277.42±18.00 287.12±16.88 277.15±24.63 156.62±47.94 277.24±54.87 5427.47±609.23 1523.73±473.18 5463.20±511.58 2863.00±291.50 5410.28±467.33 Model Performance ( Model Ensemble ) 266.20±13.81 45.74±116.66 189.41±102.32 199.44±118.66 234.34±67.54 241.77±117.88 298.62±1.29 265.78±98.38 66.65±97.36 308.01±0.87 5933.60±98.05 1695.64±1255.83 5269.72±1692.57 2951.89±728.14 5785.87±630.97 Model Performance ( Gauss . 0.01 ) 270.84±6.38 55.03±34.09 161.95±54.27 223.84±41.63 215.19±35.72 257.99±26.73 287.64±16.36 283.05±20.17 160.48±56.24 284.69±22.77 5324.99±441.27 1460.97±436.37 5470.37±473.25 2899.11±313.43 5451.01±430.96 Model Performance ( Gauss . 0.1 ) 269.01±11.12 53.99±30.89 177.23±35.35 219.14±44.10 215.76±33.81 268.83±25.55 285.91±15.71 286.19±14.48 182.20±55.79 268.39±39.12 4332.23±589.30 1412.06±391.99 4679.76±496.30 2458.92±272.67 4417.19±687.25 25 Bipedal Walker , BC , L1 Norm , K = 5 Bipedal Walker , BC , L2 Norm , K = 5 Bipedal Walker , BC , Cosine , K = 5 Bipedal Walker , BC , Wasserstein , K = 5 0841 1203 2110 3813 6558 0841 1203 2110 3813 6558 0841 1203 2110 3813 6558 0841 1203 2110 0841 1203 2110 Bipedal Walker , BCQ , L1 Norm , K = 5 3813 6558 0841 1203 2110 Bipedal Walker , BCQ , L2 Norm , K = 5 3813 6558 0841 1203 2110 Bipedal Walker , IQL , L1 Norm , K = 5 3813 6558 0841 1203 2110 Bipedal Walker , IQL , L2 Norm , K = 5 3813 6558 0841 1203 2110 Bipedal Walker , BCQ , Cosine , K = 5 3813 6558 0841 1203 2110 Bipedal Walker , IQL , Cosine , K = 5 3813 6558 0841 2110 Bipedal Walker , TD3PlusBC , L1 Norm , K = 5 6558 1203 3813 12.0 0841 1203 2110 Bipedal Walker , TD3PlusBC , L2 Norm , K = 5 94.0 3813 6558 0.0 1203 6558 2110 0841 Bipedal Walker , TD3PlusBC , Cosine , K = 5 94.0 3813 0.0 1203 0841 6558 2110 Bipedal Walker , BCQ , Wasserstein , K = 5 3813 1203 0841 6558 2110 Bipedal Walker , IQL , Wasserstein , K = 5 3813 0841 2110 Bipedal Walker , TD3PlusBC , Wasserstein , K = 5 3813 1203 6558 4.0 52.0 54.0 98.0 96.0 92.0 86.0 92.0 94.0 94.0 3813 96.0 98.0 96.0 96.0 94.0 96.0 98.0 94.0 92.0 94.0 96.0 6558 0841 1203 2110 3813 6558 0841 1203 2110 3813 6558 0841 1203 2110 3813 6558 0841 1203 2110 3813 6558 Fig . 16 : The audit accuracy against model ensemble for Ant . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the hyperparameter K of the model ensemble . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . TABLE XVII : As a supplementary of [ 13 ] , we provide more details of the BCQ offline models . The model performance shows the cumulative reward for 10 separate evaluations . Offline Model Task Name Lunar Lander BCQ Bipedal Walker Ant Dataset Name 1171 2094 4496 6518 9906 0841 1203 2110 3813 6558 2232 3569 4603 5766 7490 Model Performance ( No Defense ) 270.69±8.51 52.67±26.38 166.13±57.37 234.99±30.93 243.74±24.43 228.05±43.06 269.87±28.93 281.34±18.56 166.87±55.81 271.52±57.34 3844.45±875.84 1032.55±327.13 4554.06±676.32 2583.27±268.12 3653.48±1108.85 Model Performance ( Trajectory Splitting ) 270.45±12.51 64.70±22.08 195.16±37.67 227.41±36.30 236.93±23.49 235.75±39.17 276.35±23.98 282.23±20.88 181.39±45.03 271.09±75.34 3651.94±943.58 951.30±312.96 4562.26±828.88 2502.33±323.71 3755.22±1159.16 Model Performance ( Model Ensemble ) 278.43±9.57 30.79±81.96 88.06±182.38 233.08±45.90 236.40±41.93 229.03±117.30 243.15±112.91 264.16±97.68 131.04±165.52 306.09±4.03 4295.42±2225.70 435.72±420.34 3980.17±2203.92 2603.11±1075.03 4012.54±2267.61 Model Performance ( Gauss . 0.01 ) 268.41±13.91 57.80±30.64 188.89±38.33 236.13±33.25 237.51±31.45 247.17±37.65 276.78±21.02 270.97±24.22 177.90±52.03 275.55±30.70 3587.01±816.81 1013.29±283.76 4480.04±639.38 2640.93±323.35 3552.11±1115.43 Model Performance ( Gauss . 0.1 ) 270.25±13.45 55.73±28.36 191.19±46.30 235.19±25.16 233.42±34.97 249.94±28.21 281.59±17.69 270.78±26.49 185.86±45.97 262.56±43.95 2514.55±772.19 942.25±266.46 3412.76±804.53 2031.98±293.49 2432.82±892.02 26 Ant , BC , L1 Norm , K = 5 2232 98.0 Ant , BC , L2 Norm , K = 5 98.0 98.0 Ant , BC , Cosine , K = 5 98.0 28.0 98.0 10.0 96.0 Ant , BC , Wasserstein , K = 5 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 3569 4603 Ant , BCQ , L1 Norm , K = 5 5766 7490 2232 3569 4603 Ant , BCQ , L2 Norm , K = 5 5766 98.0 98.0 98.0 98.0 98.0 98.0 2232 3569 5766 4603 Ant , IQL , L1 Norm , K = 5 7490 2232 3569 5766 4603 Ant , IQL , L2 Norm , K = 5 7490 2232 3569 98.0 98.0 98.0 98.0 98.0 98.0 98.0 92.0 7490 10.0 2232 32.0 94.0 3569 5766 4603 Ant , BCQ , Cosine , K = 5 44.0 98.0 7490 2232 18.0 3569 4603 Ant , BCQ , Wasserstein , K = 5 5766 98.0 98.0 98.0 98.0 54.0 94.0 3569 5766 4603 Ant , IQL , Cosine , K = 5 82.0 98.0 7490 2232 14.0 3569 4603 Ant , IQL , Wasserstein , K = 5 5766 98.0 98.0 98.0 98.0 7490 98.0 7490 2232 3569 4603 Ant , TD3PlusBC , L1 Norm , K = 5 5766 7490 2232 3569 4603 Ant , TD3PlusBC , L2 Norm , K = 5 5766 7490 4603 Ant , TD3PlusBC , Cosine , K = 5 98.0 98.0 98.0 98.0 92.0 98.0 90.0 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 74.0 98.0 90.0 84.0 5766 8.0 2232 94.0 3569 90.0 4603 7490 18.0 2232 3569 4603 Ant , TD3PlusBC , Wasserstein , K = 5 5766 7490 98.0 98.0 98.0 84.0 92.0 98.0 7490 2232 3569 4603 5766 7490 94.0 3569 46.0 5766 4603 5766 7490 2232 3569 4603 5766 7490 10.0 2232 98.0 98.0 6.0 2232 Fig . 17 : The audit accuracy against model ensemble for Half Cheetah . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the hyperparameter K of the model ensemble . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . TABLE XVIII : As a supplementary of [ 13 ] , we provide more details of the IQL offline models . The model performance shows the cumulative reward for 10 separate evaluations . Offline Model Task Name Lunar Lander IQL Bipedal Walker Ant Dataset Name 1171 2094 4496 6518 9906 0841 1203 2110 3813 6558 2232 3569 4603 5766 7490 Model Performance ( No Defense ) 268.55±10.81 57.92±31.14 181.48±40.09 226.85±43.37 237.33±29.23 261.23±33.91 284.63±17.38 285.24±28.87 169.20±38.88 279.97±33.62 4577.36±865.63 1406.45±447.39 5248.48±477.42 2846.64±295.47 4814.81±556.16 Model Performance ( Trajectory Splitting ) 271.91±5.10 39.17±27.55 190.44±51.16 240.15±27.03 238.88±20.10 254.33±34.94 291.47±14.52 288.77±21.97 155.45±57.20 285.89±23.26 4437.55±766.02 1415.31±336.28 5148.72±476.71 2779.50±233.82 4715.59±628.54 Model Performance ( Model Ensemble ) 275.03±21.12 47.20±86.05 138.19±219.58 237.64±32.00 221.57±104.60 272.50±54.24 271.86±54.77 299.45±4.43 172.28±123.79 159.33±182.92 4968.65±1337.85 1563.86±1225.73 5822.61±164.84 2680.32±1019.01 3367.15±2159.49 Model Performance ( Gauss . 0.01 ) 266.55±13.58 49.96±28.60 194.79±43.22 218.41±45.31 245.07±20.08 254.18±35.26 285.79±17.42 287.20±19.29 172.41±43.21 284.75±21.41 4678.37±804.33 1421.81±459.03 5232.36±536.94 2879.16±262.72 4877.90±707.65 Model Performance ( Gauss . 0.1 ) 265.35±14.22 46.82±29.83 181.89±38.97 245.00±20.38 231.25±25.67 264.38±34.52 285.38±14.02 281.40±23.24 163.51±55.19 268.64±40.07 3420.01±912.08 1239.03±328.98 4135.40±708.39 2338.67±263.68 3461.92±694.92 27 Half Cheetah , BC , L1 Norm , K = 5 Half Cheetah , BC , L2 Norm , K = 5 Half Cheetah , BC , Cosine , K = 5 Half Cheetah , BC , Wasserstein , K = 5 expert medium random rluply expert medium random rluply 98.0 2.0 4.0 22.0 90.0 40.0 40.0 0.0 92.0 76.0 expert medium random Half Cheetah , BCQ , L1 Norm , K = 5 rluply expert medium random Half Cheetah , BCQ , L2 Norm , K = 5 rluply expert medium random Half Cheetah , BCQ , Cosine , K = 5 rluply 98.0 98.0 96.0 2.0 2.0 30.0 64.0 60.0 2.0 74.0 80.0 expert medium random Half Cheetah , IQL , L1 Norm , K = 5 rluply expert medium random Half Cheetah , IQL , L2 Norm , K = 5 rluply expert medium random Half Cheetah , IQL , Cosine , K = 5 rluply expert 96.0 96.0 medium random rluply 96.0 68.0 92.0 58.0 expert medium random Half Cheetah , TD3PlusBC , L1 Norm , K = 5 rluply expert medium random Half Cheetah , TD3PlusBC , L2 Norm , K = 5 rluply 8.0 0.0 50.0 92.0 2.0 78.0 rluply medium random expert Half Cheetah , TD3PlusBC , Cosine , K = 5 98.0 expert rluply medium random Half Cheetah , BCQ , Wasserstein , K = 5 50.0 expert rluply medium random Half Cheetah , IQL , Wasserstein , K = 5 72.0 96.0 70.0 expert medium random Half Cheetah , TD3PlusBC , Wasserstein , K = 5 rluply expert 74.0 84.0 38.0 88.0 86.0 80.0 94.0 medium random rluply expert medium random 46.0 rluply expert medium random 44.0 rluply expert medium random 2.0 2.0 34.0 2.0 68.0 80.0 rluply 54.0 4.0 98.0 expert medium random 52.0 rluply Fig . 18 : The audit accuracy with Gaussian noise ( µ = 0 , σ = 0.01 ) on the suspect models ’ action for Lunar Lander . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the noise strength . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . TABLE XIX : As a supplementary of [ 13 ] , we provide more details of the TD3PlusBC offline models . The model performance shows the cumulative reward for 10 separate evaluations . Offline Model Task Name Lunar Lander TD3PlusBC Bipedal Walker Ant Dataset Name 1171 2094 4496 6518 9906 0841 1203 2110 3813 6558 2232 3569 4603 5766 7490 Model Performance ( No Defense ) 263.65±21.47 99.72±47.21 201.58±42.49 242.58±21.54 235.98±25.48 -102.88±56.03 -86.65±22.94 -101.94±22.86 -114.96±14.97 154.70±148.81 259.94±116.75 549.14±192.30 374.17±199.78 396.13±130.69 314.48±222.06 Model Performance ( Trajectory Splitting ) 266.03±13.80 95.78±34.82 207.92±33.77 229.34±29.64 241.78±21.68 -100.63±59.89 -87.17±22.47 -100.43±26.01 -115.04±14.37 138.26±165.87 216.71±118.76 563.13±156.03 370.58±217.99 368.56±115.13 326.59±153.02 Model Performance ( Model Ensemble ) 263.34±16.97 71.96±111.26 159.76±135.46 248.09±30.91 206.93±113.68 -108.40±0.22 -95.59±17.13 -80.32±14.02 -126.18±2.36 303.03±2.30 258.28±297.07 566.88±655.52 151.13±112.93 369.73±275.57 689.21±637.77 Model Performance ( Gauss . 0.01 ) 267.15±12.96 100.67±34.95 207.07±28.13 238.51±21.01 230.41±34.05 -101.93±54.70 -87.64±22.35 -101.02±23.63 -113.97±12.93 165.64±136.38 243.30±121.39 579.86±213.98 372.37±194.00 334.74±172.22 365.24±212.09 Model Performance ( Gauss . 0.1 ) 265.12±10.36 90.74±37.66 194.69±42.59 243.96±16.41 229.55±36.81 -97.05±73.10 -86.95±25.50 -98.78±26.75 -119.21±10.67 168.47±68.50 222.48±139.45 495.19±160.81 367.64±279.00 361.40±117.68 275.81±130.30 TABLE XX : The details of the HalfCheetah dataset Task Name Half Cheetah Number of Transitions 1e6 1e6 1e6 3.003e5 Dataset Name D4RL Expert D4RL Medium D4RL Random RL Unplugged Number of Trajectories 1001 1001 1001 300 Length of trajectory 998.00 ±0.06 997.90 ±3.13 998.00±0.00 1001.00±0.00 28 Lunar Lander , BC , L1 Norm , 0.01 Lunar Lander , BC , L2 Norm , 0.01 Lunar Lander , BC , Cosine , 0.01 Lunar Lander , BC , Wasserstein , 0.01 1171 98.9 96.7 96.5 2094 4496 6518 9906 98.4 98.5 95.7 96.5 95.1 96.4 99.7 98.1 97.7 1171 2094 4496 Lunar Lander , BCQ , L1 Norm , 0.01 6518 98.1 9906 1171 2094 4496 Lunar Lander , BCQ , L2 Norm , 0.01 6518 96.1 9906 1171 2094 4496 Lunar Lander , BCQ , Cosine , 0.01 6518 96.3 9906 1171 98.4 95.6 95.3 99.8 99.5 99.8 99.9 98.0 97.1 99.2 99.9 99.9 98.8 99.9 2094 1171 4496 Lunar Lander , BCQ , Wasserstein , 0.01 99.6 6518 97.7 99.9 98.7 9906 2094 4496 6518 9906 1171 2094 4496 6518 9906 1171 2094 4496 6518 9906 95.3 99.5 93.2 96.8 93.9 96.7 97.5 95.6 95.7 99.9 99.9 96.3 99.9 99.2 99.6 99.6 95.7 1171 2094 4496 Lunar Lander , IQL , L1 Norm , 0.01 6518 98.9 9906 1171 2094 4496 Lunar Lander , IQL , L2 Norm , 0.01 6518 96.9 9906 1171 2094 4496 Lunar Lander , IQL , Cosine , 0.01 6518 96.8 9906 99.9 99.9 99.3 99.7 98.9 99.5 99.7 96.0 99.6 94.3 99.1 99.6 99.6 99.4 99.4 99.9 94.0 98.6 2094 97.6 1171 9906 4496 Lunar Lander , TD3PlusBC , L1 Norm , 0.01 97.6 99.9 6518 2094 94.3 1171 9906 4496 Lunar Lander , TD3PlusBC , L2 Norm , 0.01 92.4 6518 2094 94.3 1171 9906 4496 Lunar Lander , TD3PlusBC , Cosine , 0.01 92.1 6518 99.9 1171 99.7 2094 4496 Lunar Lander , IQL , Wasserstein , 0.01 74.7 6518 99.6 97.7 89.4 98.7 9906 98.9 98.5 99.1 99.2 99.5 98.4 98.9 99.7 95.1 95.5 99.9 96.9 98.7 1171 95.7 2094 99.9 4496 Lunar Lander , TD3PlusBC , Wasserstein , 0.01 87.1 99.9 6518 98.3 9906 98.0 99.5 98.8 93.4 99.9 98.1 94.3 98.9 1171 98.5 2094 99.7 4496 98.1 99.5 98.0 6518 98.3 99.9 9906 99.9 98.9 99.9 92.3 99.1 1171 99.9 2094 99.7 4496 99.9 98.5 9906 98.7 99.5 6518 99.9 98.8 99.5 99.1 1171 2094 92.4 99.7 4496 98.7 6518 98.9 9906 98.9 94.6 93.9 1171 99.6 97.4 99.1 93.3 2094 98.9 96.4 98.6 94.5 4496 94.5 94.1 99.1 96.7 6518 85.6 96.4 96.7 99.7 9906 Fig . 19 : The audit accuracy with Gaussian noise ( µ = 0 , σ = 0.1 ) on the suspect models ’ action for Lunar Lander . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the noise strength . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . TABLE XXI : As a supplementary of [ 13 ] , we provide more details of the models trained on the HalfCheetah dataset . The model performance shows the cumulative reward for 10 separate evaluations . Task Name Offline Model Dataset Name Half Cheetah BC BCQ IQL TD3PlusBC D4RL Expert D4RL Medium D4RL Random RL Unplugged D4RL Expert D4RL Medium D4RL Random RL Unplugged D4RL Expert D4RL Medium D4RL Random RL Unplugged D4RL Expert D4RL Medium D4RL Random RL Unplugged Model Performance ( No Defense ) 12620.94±307.84 4223.77±134.67 -0.33±0.24 -427.50±113.42 10974.19±842.10 4765.24±98.75 -1.13±0.43 -421.91±212.36 10163.20±1106.70 4808.11±46.99 1649.55±518.47 -378.74±151.65 12712.69±383.33 4969.74±56.31 1046.23±226.61 -181.50±205.29 Model Performance ( Trajectory Splitting ) 12624.61±333.32 4265.82±96.17 -0.33±0.22 -431.01±110.15 10735.35±1345.57 4746.03±108.99 -1.15±0.54 -419.59±219.29 9920.53±879.89 4800.87±59.75 1644.31±551.32 -367.87±156.81 12752.25±274.38 4964.48±57.44 1050.03±214.80 -175.49±225.09 Model Performance ( Model Ensemble ) 12868.22±180.39 4293.35±75.67 -0.37±0.62 -427.06±56.30 12334.59±539.99 4512.03±99.46 -0.54±0.78 -378.28±64.55 11268.02±2640.57 4671.25±99.09 1822.31±31.63 -311.62±16.31 11468.00±872.43 4871.85±82.15 1128.32±3.15 -385.80±54.32 TABLE XXII : The TPR and TNR results on the Half Cheetah task . The mean and standard deviation of TPR and TNR in each row represent the audit results for one combination of task and model by four distance metrics . Bold indicates the highest sum of TPR and TNR , i.e. , accuracy , in a row . Each pair of TPR and TNR is derived from the diagonal and non-diagonal values of the corresponding heatmap in Figure 24 . Task Name Half Cheetah Offline Model TPR 96.07±3.15 95.37±0.55 95.47±0.77 TD3PlusBC 95.00±2.87 BC BCQ IQL L1 Norm L2 Norm Cosine Distance Wasserstein Distance TNR 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 TPR 96.07±2.34 95.83±1.20 95.68±1.02 95.50±1.99 TNR 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 TPR 99.80±0.35 99.57±0.47 99.78±0.23 99.87±0.16 TNR 68.62±42.47 70.14±41.14 71.38±41.05 70.57±40.85 TPR 98.47±1.13 97.47±1.35 97.12±2.70 98.27±1.09 TNR 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 29 1171 2094 4496 6518 9906 1171 2094 4496 6518 9906 Lunar Lander , BC , L1 Norm , 0.1 Lunar Lander , BC , L2 Norm , 0.1 Lunar Lander , BC , Cosine , 0.1 2.0 3.2 2.0 4.4 0.0 4.0 0.1 4.0 0.1 0.5 3.7 2.0 Lunar Lander , BC , Wasserstein , 0.1 99.9 71.9 99.9 85.6 99.9 99.5 57.1 63.6 1171 2094 4496 Lunar Lander , BCQ , L1 Norm , 0.1 6518 2.0 9906 1171 2094 4496 Lunar Lander , BCQ , L2 Norm , 0.1 6518 2.0 9906 1171 2094 4496 Lunar Lander , BCQ , Cosine , 0.1 6518 2.0 9906 1171 2094 4496 Lunar Lander , BCQ , Wasserstein , 0.1 99.4 6518 99.9 87.2 64.4 9906 5.9 11.7 15.3 0.4 8.5 9.9 4.8 3.7 8.5 10.0 4.9 3.3 77.2 99.9 99.6 99.9 96.1 99.7 99.8 73.9 1171 2094 4496 Lunar Lander , IQL , L1 Norm , 0.1 6518 13.3 9906 1171 2094 4496 Lunar Lander , IQL , L2 Norm , 0.1 6518 13.1 9906 1171 56.7 42.1 2094 4496 6518 9906 1171 2094 4496 6518 9906 25.7 99.9 22.8 99.7 40.5 46.1 45.1 41.9 2094 19.7 1171 9906 4496 Lunar Lander , TD3PlusBC , L1 Norm , 0.1 46.7 6518 2094 12.0 1171 9906 4496 Lunar Lander , TD3PlusBC , L2 Norm , 0.1 32.5 6518 96.3 98.1 53.9 99.3 1171 98.6 2094 99.9 4496 98.1 31.7 98.0 6518 98.3 82.5 9906 87.7 47.7 99.7 1171 2094 4496 99.9 72.0 9906 40.8 99.6 6518 1171 43.7 2094 4496 Lunar Lander , IQL , Cosine , 0.1 6518 22.4 99.8 45.6 99.9 38.3 13.1 9906 99.9 99.6 1171 2094 4496 Lunar Lander , TD3PlusBC , Cosine , 0.1 6518 11.2 9906 99.9 1171 99.7 2094 4496 Lunar Lander , IQL , Wasserstein , 0.1 73.4 6518 99.7 98.7 90.4 85.2 9906 95.7 98.5 99.3 99.5 96.7 98.9 98.7 99.7 91.2 95.5 96.5 98.3 1171 96.7 2094 4496 Lunar Lander , TD3PlusBC , Wasserstein , 0.1 87.9 99.4 96.3 94.0 99.1 99.9 6518 95.7 9906 86.0 99.8 46.0 37.7 2094 4496 6518 72.3 9906 99.0 94.7 93.9 1171 99.6 97.6 99.1 93.5 2094 98.9 95.2 98.7 94.5 4496 95.1 94.3 96.4 97.0 6518 85.1 96.5 96.7 99.6 9906 33.1 99.9 99.7 1171 Fig . 20 : The audit accuracy with Gaussian noise ( µ = 0 , σ = 0.01 ) on the suspect models ’ action for Bipedal Walker . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the noise strength . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . TABLE XXIII : The TPR and TNR results of ORL-AUDITOR when splitting each trajectory into shorter ones ( S = 5 ) . The mean and standard deviation of TPR and TNR in each row represent the audit results for one combination of task and model by four distance metrics . Each pair of TPR and TNR is derived from the diagonal and non-diagonal values of the corresponding heatmap in Figure 25 ( Lunar Lander ) , Figure 26 ( Bipedal Walker ) , Figure 27 ( Ant ) , and Figure 28 ( Half Cheetah ) . Task Name Offline Model Lunar Lander Bipedal Walker Ant Half Cheetah BC BCQ IQL TD3PlusBC BC BCQ IQL TD3PlusBC BC BCQ IQL TD3PlusBC BC BCQ IQL TD3PlusBC L1 Norm L2 Norm Cosine Distance Wasserstein Distance TPR 99.01±0.46 98.29±1.10 98.59±1.55 98.29±2.04 99.65±0.57 99.55±0.71 95.17±7.39 99.39±1.23 98.03±1.38 97.47±2.93 97.68±2.08 98.71±1.63 98.50±1.50 96.83±1.54 97.00±2.00 97.53±1.30 TNR 100.00±0.00 100.00±0.00 99.91±0.31 99.48±0.79 100.00±0.00 100.00±0.00 100.00±0.00 94.77±19.42 99.93±0.12 99.80±0.44 99.65±0.73 99.18±1.71 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 TPR 96.96±0.73 95.87±1.12 97.52±2.51 96.35±3.01 98.45±2.71 98.19±2.84 95.01±5.49 97.15±5.71 96.77±1.49 95.89±2.32 96.77±2.50 97.20±1.79 96.87±2.14 96.27±1.36 96.25±1.13 96.53±1.20 TNR 100.00±0.00 100.00±0.00 99.97±0.12 99.89±0.22 100.00±0.00 100.00±0.00 100.00±0.00 93.37±21.46 99.90±0.36 99.84±0.41 99.69±0.59 99.35±1.72 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 TPR 96.96±0.73 95.87±1.06 97.49±2.56 96.27±3.16 98.64±2.66 99.68±0.45 99.81±0.31 96.93±6.00 99.39±0.91 99.65±0.63 99.63±0.62 99.81±0.31 99.74±0.27 99.93±0.12 99.56±0.20 99.56±0.61 TNR 100.00±0.00 99.99±0.03 99.92±0.19 99.91±0.23 100.00±0.00 100.00±0.00 100.00±0.00 91.98±21.75 86.07±27.76 86.86±27.33 85.74±28.43 88.35±25.99 69.56±41.70 68.58±41.88 72.63±40.22 71.21±40.66 TPR 98.43±0.73 97.60±1.14 98.32±1.79 98.53±1.25 99.79±0.43 99.89±0.10 95.33±7.01 98.13±3.73 98.05±1.43 98.83±1.55 99.31±0.49 99.22±1.31 98.60±0.92 97.43±1.38 97.06±2.73 98.37±1.09 TNR 99.94±0.18 99.91±0.15 97.10±5.66 95.59±3.77 100.00±0.00 100.00±0.00 100.00±0.00 88.23±25.40 99.91±0.15 99.79±0.47 99.63±0.78 99.14±1.81 100.00±0.00 100.00±0.00 100.00±0.00 100.00±0.00 30 0841 99.9 1203 2110 3813 6558 0841 99.9 0841 1203 2110 3813 6558 1203 2110 3813 6558 0841 1203 2110 Bipedal Walker , BC , L1 Norm , 0.01 Bipedal Walker , BC , L2 Norm , 0.01 Bipedal Walker , BC , Cosine , 0.01 Bipedal Walker , BC , Wasserstein , 0.01 7.5 3.9 99.2 78.9 45.1 68.7 99.9 99.9 39.2 4.1 66.1 0841 1203 2110 Bipedal Walker , BCQ , L1 Norm , 0.01 3813 93.9 6558 0841 1203 2110 Bipedal Walker , BCQ , L2 Norm , 0.01 3813 93.2 6558 0841 1203 2110 Bipedal Walker , BCQ , Cosine , 0.01 3813 93.1 6558 1203 96.9 0841 6558 2110 Bipedal Walker , BCQ , Wasserstein , 0.01 99.9 3813 96.8 92.1 98.5 95.3 99.9 99.7 99.6 99.2 0841 1203 2110 Bipedal Walker , IQL , L1 Norm , 0.01 3813 6558 0841 1203 2110 Bipedal Walker , IQL , L2 Norm , 0.01 3813 6558 0841 1203 2110 Bipedal Walker , IQL , Cosine , 0.01 3813 98.8 6558 0841 1203 2110 Bipedal Walker , IQL , Wasserstein , 0.01 3813 6558 86.8 43.2 91.5 99.3 89.6 77.1 89.7 99.9 98.8 85.1 68.4 94.5 97.7 0841 6558 2110 Bipedal Walker , TD3PlusBC , L1 Norm , 0.01 1203 3813 10.4 98.4 0841 6558 2110 Bipedal Walker , TD3PlusBC , L2 Norm , 0.01 88.8 1203 3813 0.7 1203 0841 6558 2110 Bipedal Walker , TD3PlusBC , Cosine , 0.01 87.9 3813 99.7 0.1 0841 2110 Bipedal Walker , TD3PlusBC , Wasserstein , 0.01 1203 3813 98.4 6558 1.9 48.9 3813 96.0 98.0 94.9 6558 0841 1203 2110 3813 96.0 95.2 6558 94.0 96.0 96.5 0841 1203 2110 3813 99.6 92.0 94.0 94.4 0841 1203 2110 3813 96.9 94.0 84.3 6558 79.5 92.0 86.0 6558 92.2 94.1 98.0 94.5 43.7 0841 1203 2110 3813 92.0 89.6 6558 Fig . 21 : The audit accuracy with Gaussian noise ( µ = 0 , σ = 0.1 ) on the suspect models ’ action for Bipedal Walker . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the noise strength . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . 31 0841 1203 2110 3813 6558 0841 1203 2110 3813 6558 0841 1203 2110 3813 6558 0841 1203 2110 Bipedal Walker , BC , L1 Norm , 0.1 Bipedal Walker , BC , L2 Norm , 0.1 Bipedal Walker , BC , Cosine , 0.1 Bipedal Walker , BC , Wasserstein , 0.1 0.0 0.0 0.0 0.0 5.6 93.2 0.0 0.0 0.0 0.0 0.0 0.0 24.9 30.7 0.0 0.0 0841 1203 2110 Bipedal Walker , BCQ , L1 Norm , 0.1 3813 0.0 6558 0841 1203 2110 Bipedal Walker , BCQ , L2 Norm , 0.1 3813 19.1 6558 0841 1203 2110 Bipedal Walker , BCQ , Cosine , 0.1 3813 35.5 6558 0.0 0.0 1.1 0.0 8.8 93.9 0.0 0.0 0.0 0.0 17.2 28.1 0841 1203 2110 Bipedal Walker , IQL , L1 Norm , 0.1 3813 0.0 6558 0841 1203 2110 Bipedal Walker , IQL , L2 Norm , 0.1 3813 39.6 6558 0841 1203 2110 Bipedal Walker , IQL , Cosine , 0.1 3813 38.0 6558 0.0 0.0 0.0 0.0 7.1 92.1 0.0 0.0 0.0 0.0 19.9 29.3 0.0 0841 6558 2110 Bipedal Walker , TD3PlusBC , L1 Norm , 0.1 1203 3813 11.6 1203 0.0 0841 6558 2110 Bipedal Walker , TD3PlusBC , L2 Norm , 0.1 99.9 91.1 3813 0.7 1203 19.3 0841 6558 2110 Bipedal Walker , TD3PlusBC , Cosine , 0.1 99.5 90.3 3813 99.9 0.1 0841 1203 2110 Bipedal Walker , BCQ , Wasserstein , 0.1 2.5 3813 0.0 6558 0.4 0.0 0.0 0841 1203 2110 Bipedal Walker , IQL , Wasserstein , 0.1 0.0 3813 0.3 6558 0.0 0.0 0.0 0841 2110 Bipedal Walker , TD3PlusBC , Wasserstein , 0.1 3813 1203 0.0 6558 2.3 50.9 3813 96.0 98.0 94.9 6558 0841 1203 2110 3813 96.0 0.0 6558 91.1 91.9 94.1 96.0 96.8 99.7 98.4 0841 1203 2110 3813 97.8 94.0 3.7 6558 92.0 94.0 95.0 99.8 97.6 0841 1203 2110 3813 83.7 92.0 13.5 6558 92.3 94.4 98.0 94.4 45.4 0841 1203 2110 3813 92.0 7.7 6558 Fig . 22 : The audit accuracy with Gaussian noise ( µ = 0 , σ = 0.01 ) on the suspect models ’ action for Ant . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the noise strength . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . 32 Ant , BC , L1 Norm , 0.01 99.9 97.5 99.6 96.9 99.8 84.4 5766 4603 3569 Ant , BCQ , L1 Norm , 0.01 99.9 97.2 98.7 99.9 98.7 99.9 87.1 3569 5766 4603 Ant , IQL , L1 Norm , 0.01 99.9 99.3 97.5 93.2 97.9 99.9 99.7 99.9 96.1 7490 99.9 99.6 7490 99.6 99.9 95.1 99.9 2232 93.5 99.1 2232 91.3 98.9 99.9 Ant , BC , L2 Norm , 0.01 98.3 95.2 99.9 98.8 89.7 5766 4603 3569 Ant , BCQ , L2 Norm , 0.01 98.3 94.0 99.5 97.9 88.7 3569 5766 4603 Ant , IQL , L2 Norm , 0.01 98.7 97.5 98.2 96.1 98.5 99.9 96.7 99.9 96.7 7490 99.9 99.5 99.9 8.8 2232 99.9 99.5 Ant , BC , Cosine , 0.01 97.9 57.0 97.1 99.9 11.7 99.9 94.3 99.9 57.3 99.7 88.2 5766 4603 3569 Ant , BCQ , Cosine , 0.01 98.2 62.9 98.3 99.7 99.9 94.3 99.7 Ant , BC , Wasserstein , 0.01 99.9 97.7 99.2 99.7 99.9 99.5 99.3 99.8 99.8 97.1 7490 2232 3569 4603 Ant , BCQ , Wasserstein , 0.01 5766 15.4 99.9 96.9 98.9 98.6 99.9 99.9 98.6 99.9 96.3 98.9 7490 10.1 2232 65.7 92.4 3569 5766 4603 Ant , IQL , Cosine , 0.01 73.5 98.7 99.9 7490 12.3 99.8 99.5 98.4 99.2 99.7 92.9 99.9 2232 99.7 98.5 99.8 3569 4603 Ant , IQL , Wasserstein , 0.01 5766 99.9 98.9 97.5 98.7 97.6 99.9 99.9 96.5 7490 99.9 7490 99.6 99.9 94.5 99.7 99.9 2232 95.5 98.9 2232 93.1 98.5 99.8 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 2232 3569 4603 Ant , TD3PlusBC , L1 Norm , 0.01 5766 94.9 7490 2232 3569 4603 Ant , TD3PlusBC , L2 Norm , 0.01 5766 98.7 7490 2232 3569 99.1 4603 99.8 95.2 5766 97.5 99.6 7490 98.3 93.6 92.5 98.0 98.8 98.0 99.5 95.9 98.2 99.7 99.0 92.9 92.1 99.0 99.5 2232 3569 4603 5766 99.5 7490 2232 3569 4603 5766 95.7 7490 8.1 2232 99.9 99.6 98.2 7.0 2232 90.9 3569 99.5 4603 Ant , TD3PlusBC , Cosine , 0.01 51.3 5766 99.5 99.7 92.1 3569 99.2 99.9 92.2 4603 75.4 99.1 91.9 87.3 5766 7490 14.7 99.5 2232 3569 4603 Ant , TD3PlusBC , Wasserstein , 0.01 5766 98.1 7490 99.8 99.1 99.1 97.5 99.5 98.3 96.6 92.0 97.8 98.8 7490 2232 3569 4603 5766 7490 Fig . 23 : The audit accuracy with Gaussian noise ( µ = 0 , σ = 0.1 ) on the suspect models ’ action for Ant . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the noise strength . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . 33 8.7 2232 3569 4603 99.9 5766 7490 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 2232 10.0 98.9 2232 9.7 98.9 99.9 2232 Ant , BC , L1 Norm , 0.1 99.9 13.6 99.9 2.0 2.3 5766 4603 3569 Ant , BCQ , L1 Norm , 0.1 99.9 24.4 99.0 2.0 99.3 99.9 9.5 3569 5766 4603 Ant , IQL , L1 Norm , 0.1 99.9 25.3 98.5 2.0 98.1 99.9 8.4 3569 4603 Ant , TD3PlusBC , L1 Norm , 0.1 5766 3.6 7490 99.9 99.9 3.9 7490 99.9 3.2 7490 Ant , BC , Cosine , 0.1 Ant , BC , Wasserstein , 0.1 59.7 13.3 12.9 Ant , BC , L2 Norm , 0.1 98.7 22.5 6.0 2.3 5766 4603 3569 Ant , BCQ , L2 Norm , 0.1 98.3 27.6 99.9 5.6 5.1 3569 5766 4603 Ant , IQL , L2 Norm , 0.1 98.7 40.0 99.3 5.6 98.9 4.5 3569 4603 Ant , TD3PlusBC , L2 Norm , 0.1 5766 4.4 7490 3.3 7490 8.8 99.9 2232 9.9 99.6 2232 9.2 99.9 2232 8.5 99.6 98.7 98.1 74.8 99.1 99.9 95.1 84.7 2.7 7490 10.8 2232 99.9 99.9 62.2 99.8 88.9 5766 4603 3569 Ant , BCQ , Cosine , 0.1 98.2 68.7 99.9 7490 16.7 77.5 99.9 96.5 84.4 10.8 2232 99.9 9.1 2232 99.6 98.8 7.7 2232 94.1 3569 69.3 5766 99.9 4603 Ant , IQL , Cosine , 0.1 78.1 98.9 81.6 99.9 95.7 84.8 91.8 3569 99.6 4603 Ant , TD3PlusBC , Cosine , 0.1 54.9 5766 99.9 80.8 93.5 3569 99.8 99.4 93.7 99.9 4603 78.5 99.4 94.3 99.1 91.3 5766 99.7 7490 13.1 99.7 7490 17.3 99.7 7490 99.9 29.9 99.9 5.6 3.7 3569 4603 Ant , BCQ , Wasserstein , 0.1 5766 99.9 42.5 98.9 7.3 99.3 99.9 14.1 3569 4603 Ant , IQL , Wasserstein , 0.1 5766 99.9 49.1 98.4 4.0 98.1 99.9 10.1 2.9 7490 99.9 99.9 43.1 7490 99.9 99.9 2232 62.3 98.9 2232 12.5 98.9 99.9 2232 3569 4603 Ant , TD3PlusBC , Wasserstein , 0.1 5766 25.7 7490 93.1 99.4 51.3 97.9 99.7 98.8 3.4 93.0 97.9 99.3 2232 3569 4603 5766 65.9 7490 2232 8.3 3569 99.4 27.9 4603 5766 98.1 99.7 7490 98.8 2.0 93.4 98.1 99.3 99.8 59.7 99.5 5.4 93.4 99.4 99.9 94.5 2232 3569 4603 5766 2.3 7490 2232 3569 4603 5766 2.0 7490 Fig . 24 : The audit accuracy between every two Half Cheetah datasets . The caption of each plot demonstrates the offline DRL model ’ s type , the task , and the distance metric . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . 34 Half Cheetah , BC , L1 Norm Half Cheetah , BC , L2 Norm Half Cheetah , BC , Cosine Distance Half Cheetah , BC , Wasserstein Distance expert 91.2 94.0 medium random rluply 96.7 94.7 90.0 96.4 95.6 5.4 3.1 26.9 1.6 96.3 99.2 expert medium random Half Cheetah , BCQ , L1 Norm rluply expert medium random Half Cheetah , BCQ , L2 Norm rluply expert 94.8 96.0 medium random rluply 95.1 96.3 97.7 94.9 expert medium random Half Cheetah , IQL , L1 Norm 95.3 rluply expert medium random Half Cheetah , IQL , L2 Norm 94.7 rluply expert 95.5 95.2 96.7 94.5 97.3 95.6 95.2 94.6 99.7 expert medium random Half Cheetah , BCQ , Cosine Distance rluply 11.1 5.3 30.2 99.9 98.8 95.2 99.9 3.9 96.1 99.6 expert medium random Half Cheetah , IQL , Cosine Distance rluply 5.9 99.9 92.1 2.9 55.5 99.9 1.4 99.0 99.4 99.1 97.6 medium random expert Half Cheetah , BCQ , Wasserstein Distance rluply 97.2 99.7 96.7 97.2 96.3 expert rluply medium random Half Cheetah , IQL , Wasserstein Distance 99.5 92.5 98.5 98.0 expert medium random Half Cheetah , TD3PlusBC , L1 Norm rluply expert medium random Half Cheetah , TD3PlusBC , L2 Norm rluply expert medium random Half Cheetah , TD3PlusBC , Cosine Distance rluply expert medium random Half Cheetah , TD3PlusBC , Wasserstein Distance rluply expert 90.3 92.8 95.6 96.1 94.8 96.1 6.9 99.9 4.8 45.1 89.5 expert medium random 98.0 rluply expert medium random 98.3 rluply expert medium random 2.2 98.3 99.6 rluply 98.9 96.4 99.1 expert medium random 98.7 rluply medium random rluply medium random rluply Fig . 25 : The audit accuracy of ORL-AUDITOR on Lunar Lander when splitting each trajectory into shorter ones ( S = 5 ) . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the hyperparameter S of trajectory splitting . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . 35 Lunar Lander , BC , L1 Norm , split 5 Lunar Lander , BC , L2 Norm , split 5 Lunar Lander , BC , Cosine , split 5 Lunar Lander , BC , Wasserstein , split 5 96.9 95.9 96.8 95.9 97.2 98.1 97.2 98.1 99.5 99.8 99.9 98.3 99.9 99.2 97.2 98.7 1171 99.1 2094 4496 6518 9906 98.5 98.8 99.9 1171 2094 4496 Lunar Lander , BCQ , L1 Norm , split 5 6518 98.8 9906 1171 2094 4496 Lunar Lander , BCQ , L2 Norm , split 5 6518 96.7 9906 1171 2094 4496 Lunar Lander , BCQ , Cosine , split 5 6518 96.8 9906 1171 98.5 96.4 99.5 97.9 95.5 94.1 95.2 94.4 99.9 96.8 95.6 96.9 95.6 1171 2094 4496 Lunar Lander , IQL , L1 Norm , split 5 6518 99.2 9906 1171 2094 4496 Lunar Lander , IQL , L2 Norm , split 5 6518 97.3 9906 1171 2094 4496 Lunar Lander , IQL , Cosine , split 5 6518 97.2 9906 99.5 99.7 99.1 99.5 99.9 96.0 99.6 94.4 99.1 99.6 99.6 99.4 99.4 99.9 94.0 98.6 2094 97.6 1171 9906 4496 Lunar Lander , TD3PlusBC , L1 Norm , split 5 97.7 99.9 6518 94.5 1171 9906 4496 Lunar Lander , TD3PlusBC , L2 Norm , split 5 92.8 2094 6518 2094 94.8 1171 9906 4496 Lunar Lander , TD3PlusBC , Cosine , split 5 92.4 6518 99.9 2094 98.5 9906 4496 1171 Lunar Lander , BCQ , Wasserstein , split 5 97.7 99.9 99.6 6518 96.5 99.9 99.9 99.9 99.2 99.5 99.6 96.1 99.8 2094 1171 4496 Lunar Lander , IQL , Wasserstein , split 5 74.8 6518 99.6 97.6 89.4 98.4 9906 98.9 98.5 99.1 99.2 99.5 98.4 98.9 99.7 94.9 95.5 99.9 96.9 98.9 1171 95.7 2094 99.9 4496 Lunar Lander , TD3PlusBC , Wasserstein , split 5 87.1 99.9 6518 98.3 9906 99.5 97.9 98.7 93.4 99.9 98.1 94.5 98.9 1171 98.5 2094 99.7 4496 98.1 99.5 98.0 6518 98.3 99.9 9906 99.9 98.9 99.9 92.5 99.1 1171 99.9 2094 99.7 4496 99.9 98.7 9906 98.8 99.5 6518 99.9 98.8 99.5 99.1 1171 2094 92.4 99.7 4496 98.7 6518 99.1 9906 98.9 94.7 93.9 1171 99.6 97.3 99.1 93.3 2094 98.9 96.4 98.6 94.5 4496 94.4 94.1 99.1 96.7 6518 85.6 96.5 96.7 99.7 9906 2094 4496 6518 9906 1171 2094 4496 6518 9906 1171 2094 4496 6518 9906 Fig . 26 : The audit accuracy of ORL-AUDITOR on Bipedal Walker when splitting each trajectory into shorter ones ( S = 5 ) . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the hyperparameter S of trajectory splitting . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . 36 0841 1203 2110 3813 6558 1203 2110 3813 6558 0841 1203 2110 3813 6558 0841 1203 2110 Bipedal Walker , BC , L1 Norm , split 5 Bipedal Walker , BC , L2 Norm , split 5 Bipedal Walker , BC , Cosine , split 5 Bipedal Walker , BC , Wasserstein , split 5 98.5 98.9 99.2 99.9 0841 1203 2110 Bipedal Walker , BCQ , L1 Norm , split 5 3813 99.7 6558 0841 1203 2110 Bipedal Walker , BCQ , L2 Norm , split 5 3813 93.1 6558 0841 1203 2110 Bipedal Walker , BCQ , Cosine , split 5 3813 93.3 6558 0841 99.9 1203 6558 2110 0841 Bipedal Walker , BCQ , Wasserstein , split 5 99.9 3813 98.1 92.7 99.7 98.3 99.7 99.9 99.7 99.9 0841 1203 2110 Bipedal Walker , IQL , L1 Norm , split 5 3813 6558 0841 1203 2110 Bipedal Walker , IQL , L2 Norm , split 5 3813 6558 0841 1203 2110 Bipedal Walker , IQL , Cosine , split 5 3813 98.8 6558 1203 0841 6558 2110 Bipedal Walker , IQL , Wasserstein , split 5 3813 99.7 80.8 93.7 85.1 99.9 97.6 95.5 96.4 99.2 81.5 97.6 0841 2110 Bipedal Walker , TD3PlusBC , L1 Norm , split 5 3813 1203 99.9 6558 10.4 1203 0841 2110 Bipedal Walker , TD3PlusBC , L2 Norm , split 5 89.3 3813 0.7 99.9 6558 1203 0841 6558 2110 Bipedal Walker , TD3PlusBC , Cosine , split 5 87.9 3813 99.7 0.1 0841 2110 Bipedal Walker , TD3PlusBC , Wasserstein , split 5 3813 6558 1203 1.9 48.0 3813 96.0 98.0 94.9 6558 0841 1203 2110 3813 96.0 96.9 6558 94.0 96.0 96.4 0841 1203 2110 3813 99.7 92.0 94.0 94.4 0841 1203 2110 3813 97.1 94.0 85.7 6558 79.6 92.0 84.9 6558 92.1 94.2 98.0 94.5 43.9 0841 1203 2110 3813 92.0 90.7 6558 Fig . 27 : The audit accuracy of ORL-AUDITOR on Ant when splitting each trajectory into shorter ones ( S = 5 ) . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the hyperparameter S of trajectory splitting . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . 37 Ant , BC , Cosine , split 5 98.0 57.6 97.6 99.9 12.0 99.9 Ant , BC , Wasserstein , split 5 99.9 98.1 99.5 99.7 99.9 99.5 99.5 99.7 99.8 97.6 Ant , BC , L1 Norm , split 5 99.9 98.0 99.6 99.9 99.9 99.8 95.6 3569 4603 Ant , BCQ , L1 Norm , split 5 5766 99.9 97.7 98.7 98.7 99.9 92.0 99.9 98.4 7490 96.8 99.9 2232 94.4 99.1 Ant , BC , L2 Norm , split 5 98.3 96.0 99.9 99.2 94.7 3569 4603 Ant , BCQ , L2 Norm , split 5 5766 98.3 95.2 99.5 98.0 99.9 92.8 3569 5766 4603 Ant , IQL , L1 Norm , split 5 7490 2232 3569 5766 4603 Ant , IQL , L2 Norm , split 5 99.9 99.6 97.5 98.1 97.9 99.9 99.6 99.9 98.7 97.3 92.0 98.9 99.9 98.1 96.9 98.5 99.9 98.7 98.3 99.7 99.9 2232 97.6 98.9 2232 94.5 98.5 99.8 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 2232 3569 4603 Ant , TD3PlusBC , L1 Norm , split 5 5766 96.1 7490 2232 3569 4603 Ant , TD3PlusBC , L2 Norm , split 5 5766 98.9 7490 2232 3569 99.1 99.8 96.1 4603 5766 97.5 99.6 7490 98.3 97.4 92.5 98.0 98.8 98.3 99.5 96.1 98.2 99.7 99.0 94.8 92.2 99.0 99.5 99.9 97.2 7490 99.9 99.6 99.9 11.0 2232 99.9 99.5 99.1 7490 8.9 2232 95.9 99.7 59.1 99.6 88.5 5766 4603 3569 Ant , BCQ , Cosine , split 5 98.1 64.9 98.4 99.5 95.2 65.1 93.0 3569 5766 4603 Ant , IQL , Cosine , split 5 67.0 99.9 98.7 11.6 99.9 7490 15.5 99.5 99.8 99.3 98.4 99.1 99.7 92.3 99.9 8.1 2232 99.9 99.6 98.2 7.9 2232 91.8 3569 99.7 4603 Ant , TD3PlusBC , Cosine , split 5 47.5 5766 99.2 99.2 99.7 92.7 3569 92.2 4603 82.6 99.1 89.2 91.7 5766 96.8 7490 99.9 95.6 7490 99.9 7490 99.6 99.9 7490 2232 3569 4603 Ant , BCQ , Wasserstein , split 5 5766 13.1 99.9 98.0 98.9 98.5 99.9 98.6 99.9 96.1 7490 2232 3569 4603 Ant , IQL , Wasserstein , split 5 5766 99.9 98.9 99.7 98.5 99.8 97.5 99.2 97.6 99.9 2232 3569 4603 Ant , TD3PlusBC , Wasserstein , split 5 5766 98.7 7490 99.8 99.5 99.1 97.5 99.5 98.3 96.6 92.0 97.8 98.7 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 2232 3569 4603 5766 7490 Fig . 28 : The audit accuracy of ORL-AUDITOR on Half Cheetah when splitting each trajectory into shorter ones ( S = 5 ) . The caption of each plot demonstrates the offline DRL model ’ s type , the task , the distance metric , and the hyperparameter S of trajectory splitting . The x labels are the names of datasets to be audited , i.e. , the target datasets . The y labels are the names of datasets the suspect models learned , i.e. , the actual datasets . Thus , the diagonal values show the audit accuracy when the actual dataset is the same as the target dataset , i.e. , TPR , and the non-diagonal values are the TNR results . The positions without value mean 100 % accuracy . 38 Half Cheetah , BC , L1 Norm , split 5 Half Cheetah , BC , L2 Norm , split 5 Half Cheetah , BC , Cosine , split 5 Half Cheetah , BC , Wasserstein , split 5 expert 99.7 medium random rluply 98.0 97.6 94.4 99.5 91.7 7.7 3.8 30.6 96.3 95.5 99.8 3.5 97.7 99.5 expert medium random Half Cheetah , BCQ , L1 Norm , split 5 rluply expert medium random Half Cheetah , BCQ , L2 Norm , split 5 rluply expert medium random Half Cheetah , BCQ , Cosine , split 5 rluply expert 99.2 97.3 medium random rluply 95.3 97.9 90.5 97.2 95.6 95.2 94.7 99.9 7.6 2.7 26.9 3.1 92.3 99.7 expert medium random Half Cheetah , IQL , L1 Norm , split 5 rluply expert medium random Half Cheetah , IQL , L2 Norm , split 5 rluply expert medium random Half Cheetah , IQL , Cosine , split 5 rluply expert 99.9 medium random rluply 97.9 96.9 97.6 99.3 94.2 7.9 99.9 94.9 95.3 95.9 94.6 5.3 61.9 99.6 2.7 99.6 99.5 98.7 98.3 rluply medium random expert Half Cheetah , BCQ , Wasserstein , split 5 97.5 99.7 96.7 97.2 96.1 expert rluply medium random Half Cheetah , IQL , Wasserstein , split 5 99.3 92.4 98.5 98.0 expert medium random Half Cheetah , TD3PlusBC , L1 Norm , split 5 rluply expert medium random Half Cheetah , TD3PlusBC , L2 Norm , split 5 rluply expert rluply medium random Half Cheetah , TD3PlusBC , Cosine , split 5 expert medium random Half Cheetah , TD3PlusBC , Wasserstein , split 5 rluply expert 99.1 96.9 95.6 97.2 94.8 96.3 medium random rluply expert medium random 98.3 rluply expert medium random 98.1 rluply expert medium random 99.7 90.9 6.9 4.7 52.3 1.6 98.1 98.5 rluply 98.9 96.5 99.3 expert medium random 98.7 rluply","['orlauditor', 'dataset', 'auditing', 'offline', 'deep', 'reinforcement', 'learn', 'p', 'e', 'r', 'c', 'c', 'r', 'shoule', 'jiming', 'sji', 'zjueducn', 'saodiseng', 'cjm', 'helmholtz', 'center', 'information', 'security', 'saarbr¨ucken', 'email', 'minchen', 'cispade', 'abstract', 'datum', 'critical', 'asset', 'ai', 'highquality', 'dataset', 'significantly', 'improve', 'performance', 'machine', 'learning', 'model', 'safetycritical', 'domain', 'autonomous', 'vehicle', 'offline', 'deep', 'reinforcement', 'learn', 'frequently', 'use', 'train', 'model', 'precollecte', 'dataset', 'oppose', 'train', 'ing', 'model', 'interact', 'realworld', 'environment', 'online', 'drl', 'support', 'development', 'model', 'many', 'institution', 'make', 'dataset', 'publicly', 'available', 'open', 'source', 'license', 'dataset', 'risk', 'potential', 'misuse', 'infringement', 'inject', 'watermark', 'dataset', 'protect', 'intellectual', 'property', 'datum', 'handle', 'dataset', 'already', 'publish', 'infeasible', 'alter', 'afterward', 'exist', 'solution', 'dataset', 'inference', 'membership', 'inference', 'work', 'well', 'offline', 'scenario', 'diverse', 'model', 'behavior', 'characteristic', 'offline', 'set', 'constraint', 'paper', 'advocate', 'new', 'paradigm', 'leverage', 'fact', 'cumulative', 'reward', 'act', 'unique', 'identifier', 'distinguish', 'drl', 'model', 'train', 'specific', 'dataset', 'end', 'propose', 'orlauditor', 'first', 'trajectory', 'level', 'dataset', 'auditing', 'mechanism', 'scenario', 'experiment', 'multiple', 'offline', 'drl', 'model', 'task', 'reveal', 'efficacy', 'orlauditor', 'auditing', 'accuracy', 'false', 'positive', 'rate', 'less', 'also', 'provide', 'valuable', 'insight', 'practical', 'implementation', 'auditor', 'study', 'various', 'parameter', 'setting', 'furthermore', 'demonstrate', 'auditing', 'capability', 'orlauditor', 'opensource', 'dataset', 'deepmind', 'highlight', 'effectiveness', 'audit', 'publish', 'dataset', 'orlauditor', 'opensource', 'https', 'githubcomlinkzjuorlauditor', 'introduction', 'deep', 'reinforcement', 'learn', 'successfully', 'apply', 'many', 'complex', 'decisionmake', 'task', 'autopilot', 'robot', 'control', 'power', 'system', 'intrusion', 'detection', 'however', 'safetycritical', 'domain', 'robot', 'control', 'directly', 'interact', 'environment', 'unsafe', 'partially', 'train', 'policy', 'first', 'author', 'make', 'equal', 'contribution', 'correspond', 'author', 'network', 'distribute', 'system', 'security', 'symposium', 'february', 'isbn', 'https', 'risk', 'damage', 'robot', 'hardware', 'surround', 'object', 'address', 'issue', 'researcher', 'propose', 'offline', 'deep', 'reinforcement', 'learn', 'offline', 'paradigm', 'also', 'know', 'full', 'batch', 'general', 'idea', 'learn', 'precollecte', 'datum', 'generate', 'expert', 'handcraft', 'controller', 'even', 'random', 'strategy', 'respect', 'system', 'constraint', 'artificial', 'facilitate', 'research', 'offline', 'drl', 'several', 'high', 'quality', 'dataset', 'publish', 'third', 'party', 'deep', 'mind', 'intelligence', 'research', 'bair', 'polixir', 'technology', 'tensorflow', 'dataset', 'publish', 'strict', 'opensource', 'license', 'general', 'public', 'license', 'apache', 'license', 'bsd', 'clause', 'license', 'protect', 'intellectual', 'property', 'ip', 'datum', 'owner', 'license', 'typically', 'encompas', 'essential', 'term', 'attribution', 'require', 'user', 'appropriately', 'acknowledge', 'source', 'provide', 'link', 'license', 'indicate', 'modification', 'make', 'sharealike', 'stipulate', 'remix', 'transform', 'build', 'material', 'distribute', 'contribution', 'license', 'original', 'furthermore', 'dataset', 'accompany', 'additional', 'patent', 'grant', 'aim', 'safeguard', 'right', 'datum', 'publisher', 'stardata', 'additionally', 'closedform', 'dataset', 'potential', 'face', 'misuse', 'insider', 'attack', 'intellectual', 'property', 'infringement', 'exemployee', 'steal', 'ing', 'datum', 'survey', 'find', 'respondent', 'admit', 'take', 'valuable', 'datum', 'leave', 'job', 'cite', 'lack', 'policy', 'technology', 'prevent', 'datum', 'theft', 'tessian', 'report', 'employee', 'take', 'generate', 'datum', 'train', 'model', 'leave', 'job', 'defense', 'threat', 'come', 'question', 'data', 'owner', 'prove', 'suspect', 'model', 'derive', 'dataset', 'exist', 'solution', 'recent', 'mainstream', 'solution', 'dataset', 'copyright', 'protection', 'classify', 'category', 'watermarke', 'dataset', 'inference', 'membership', 'inference', 'watermarking', 'approach', 'aim', 'inject', 'sample', 'specific', 'distribution', 'prior', 'publish', 'dataset', 'auditor', 'need', 'postevent', 'mechanism', 'however', 'opensource', 'datum', 'already', 'publish', 'real', 'world', 'contrast', 'watermarking', 'technique', 'dataset', 'inference', 'strategy', 'require', 'injection', 'explicit', 'watermark', 'dataset', 'train', 'model', 'implement', 'auditing', 'first', 'train', 'critic', 'model', 'predict', 'cumulative', 'reward', 'stateaction', 'pair', 'dataset', 'audit', 'target', 'dataset', 'straightfor', 'ward', 'strategy', 'derive', 'auditing', 'result', 'compare', 'cumulative', 'reward', 'stateaction', 'pair', 'suspect', 'model', 'target', 'dataset', 'preset', 'judgment', 'threshold', 'similarity', 'however', 'design', 'threshold', 'value', 'challenge', 'depend', 'distribution', 'pre', 'collect', 'dataset', 'vary', 'different', 'task', 'setting', 'collection', 'procedure', 'datum', 'postprocessing', 'method', 'address', 'issue', 'recognize', 'cumulative', 'reward', 'embed', 'stateaction', 'pair', 'model', 'esti', 'mate', 'cumulative', 'reward', 'target', 'dataset', 'offline', 'model', 'fit', 'cumulative', 'reward', 'dataset', 'training', 'thus', 'train', 'multiple', 'model', 'target', 'dataset', 'vary', 'initialization', 'optimization', 'shadow', 'model', 'collect', 'cumulative', 'reward', 'stateaction', 'pair', 'finally', 'compare', 'cumulative', 'reward', 'suspect', 'model', 'shadow', 'model', 'make', 'audit', 'decision', 'hypothesis', 'testing', 'evaluation', 'experimental', 'result', 'show', 'auditing', 'accuracy', 'orlauditor', 'exceed', 'false', 'positive', 'rate', 'less', 'multiple', 'drl', 'model', 'task', 'visualize', 'cumulative', 'reward', 'shadow', 'model', 'train', 'different', 'dataset', 'demonstrate', 'cumula', 'tive', 'reward', 'distinguishable', 'feature', 'dataset', 'audit', 'far', 'evaluate', 'influential', 'factor', 'practical', 'adop', 'tion', 'orlauditor', 'number', 'shadow', 'model', 'significance', 'level', 'hypothesis', 'testing', 'trajectory', 'size', 'first', 'shadow', 'model', 'improve', 'audit', 'accuracy', 'orlauditor', 'demonstrate', 'exceptional', 'performance', 'audit', 'accuracy', 'exceed', 'utilize', 'mere', 'shadow', 'model', 'illustrate', 'table', 'viii', 'second', 'minimum', 'sig', 'nificance', 'level', 'orlauditor', 'mean', 'auditor', 'output', 'single', 'result', 'confidence', 'third', 'orlauditor', 'tend', 'obtain', 'high', 'accuracy', 'large', 'trajectory', 'size', 'yet', 'also', 'notice', 'small', 'trajectory', 'size', 'achieve', 'well', 'result', 'task', 'far', 'implement', 'orlauditor', 'audit', 'opensource', 'dataset', 'deepmind', 'experimental', 'result', 'demonstrate', 'effectiveness', 'orlauditor', 'practice', 'robustness', 'evaluate', 'robustness', 'orlauditor', 'implement', 'defense', 'strategy', 'prevent', 'auditing', 'first', 'strategy', 'involve', 'use', 'stateoftheart', 'bership', 'inference', 'defense', 'technique', 'ensemble', 'architecture', 'propose', 'defense', 'mechanism', 'audit', 'accuracy', 'orlauditor', 'still', 'addition', 'ble', 'architecture', 'suspect', 'model', 'distort', 'action', 'hide', 'training', 'dataset', 'offline', 'drl', 'model', 'real', 'world', 'decisionmake', 'task', 'selfdrive', 'car', 'often', 'use', 'gaussian', 'noise', 'model', 'natural', 'distortion', 'thus', 'add', 'gaussian', 'noise', 'action', 'stealthy', 'avoid', 'auditor', 'detection', 'noise', 'convenient', 'mathematical', 'manipulation', 'simulate', 'strong', 'weak', 'action', 'distortion', 'normalize', 'dimension', 'action', 'space', '−1', 'use', 'gaussian', 'noise', 'µ', 'respectively', 'experiment', 'show', 'auditor', 'slightly', 'affect', 'gaussian', 'noise', 'fig', 'intuitive', 'explanation', 'orlauditor', 'middle', 'surface', 'cumulative', 'reward', 'stateaction', 'pair', 'dataset', 'auditor', 'output', 'positive', 'result', 'cumulative', 'reward', 'suspect', 'model', 'stateaction', 'pair', 'outer', 'surface', 'maini', 'separately', 'propose', 'dataset', 'inference', 'method', 'supervised', 'learning', 'selfsupervise', 'learning', 'model', 'enable', 'model', 'owner', 'provide', 'convincing', 'statistical', 'argument', 'particular', 'model', 'train', 'private', 'datum', 'however', 'dataset', 'inference', 'label', 'need', 'distance', 'datum', 'decision', 'boundary', 'possible', 'obtain', 'rl', 'continuous', 'output', 'dataset', 'inference', 'label', 'use', 'similarity', 'model', 'behavior', 'detect', 'unauthorized', 'dataset', 'usage', 'require', 'public', 'dataset', 'generate', 'surrogate', 'model', 'form', 'auditing', 'basis', 'compare', 'behavioral', 'difference', 'surrogate', 'model', 'model', 'train', 'private', 'datum', 'scene', 'distribution', 'collect', 'dataset', 'depend', 'environment', 'operator', 'difficult', 'determine', 'suitable', 'public', 'dataset', 'train', 'surrogate', 'model', 'make', 'audit', 'basis', 'hard', 'establish', 'third', 'category', 'adopt', 'notion', 'membership', 'inference', 'collect', 'rl', 'model', 'behavior', 'train', 'example', 'member', 'untrained', 'example', 'nonmember', 'classifier', 'construct', 'determine', 'data', 'sample', 'use', 'model', 'learn', 'process', 'however', 'online', 'scenario', 'auditor', 'collect', 'additional', 'datum', 'environment', 'nonmember', 'example', 'offline', 'case', 'auditor', 'access', 'environment', 'proposal', 'paper', 'propose', 'first', 'practical', 'dataset', 'auditing', 'paradigm', 'offline', 'auditor', 'concretely', 'inspire', 'fact', 'cumulative', 'reward', 'sum', 'reward', 'receive', 'period', 'time', 'start', 'give', 'stateaction', 'pair', 'guide', 'rl', 'model', 'learn', 'behavior', 'policy', 'thus', 'reward', 'intrinsic', 'feature', 'dataset', 'make', 'suitable', 'audit', 'basis', 'figure', 'provide', 'schematic', 'diagram', 'orlauditor', 'state', 'action', 'cumulative', 'reward', 'compose', 'threedimensional', 'space', 'surface', 'illustrate', 'exact', 'cumulative', 'reward', 'dataset', 'surface', 'show', 'possible', 'offset', 'exact', 'cumulative', 'reward', 'learn', 'offline', 'drl', 'model', 'randomness', 'initialization', 'learning', 'process', 'suspect', 'model', 'auditor', 'output', 'positive', 'result', 'datum', 'use', 'train', 'model', 'cumulative', 'reward', 'stateaction', 'pair', 'fall', 'surface', 'otherwise', 'negative', 'outcome', 'cumulative', 'reward', '𝑎𝑎', '𝑎𝑎', '𝑠𝑠', '𝑎𝑎', 'state', 'action', '𝑎𝑎', 'positive', 'negative', 'share', 'helpcontact', 'tpr', 'value', 'auditor', 'decline', 'yet', 'strong', 'distortion', 'also', 'impact', 'performance', 'suspect', 'model', 'especially', 'complex', 'task', 'contribution', 'contribution', 'threefold', 'knowledge', 'orlauditor', 'first', 'dataset', 'audit', 'ing', 'method', 'offline', 'drl', 'model', 'use', 'cumulative', 'reward', 'intrinsic', 'stable', 'fingerprint', 'dataset', '•', 'demonstrate', 'effectiveness', 'orlauditor', 'offline', 'drl', 'model', 'task', 'also', 'systematically', 'analyze', 'various', 'experimental', 'factor', 'hyperparam', 'eter', 'setting', 'robustness', 'orlauditor', 'summarize', 'important', 'guideline', 'adopt', 'orl', 'auditor', 'practice', 'implement', 'orlauditor', 'opensource', 'dataset', 'deepmind', 'show', 'orlauditor', 'serve', 'potent', 'audit', 'solution', 'scenario', 'background', 'offline', 'rl', 'problem', 'offline', 'reinforcement', 'learning', 'model', 'aim', 'learn', 'optimal', 'nearly', 'optimal', 'policy', 'pre', 'collect', 'dataset', 'interactive', 'environment', 'use', 'represent', 'rl', 'model', 'input', 'output', 'space', 'formally', 'call', 'state', 'action', 'scene', 'r', 'temporal', 'reward', 'time', 'step', 'r', 'real', 'number', 'set', 'unit', 'precollecte', 'dataset', 'call', 'transition', 'element', 'set', 'st1', 'successive', 'state', 'set', 'transition', 'chronological', 'order', 'form', 'trajectory', 'dataset', 'base', 'transition', 'offline', 'model', 'learn', 'markov', 'decision', 'process', 'dataset', 'form', 'policy', 'πθ', 'maximize', 'j', 'π', 'π', 'est∼dβ', 'h', 'use', 'dβ', 'denote', 'distribution', 'state', 'action', 'dataset', 'action', 'sample', 'accord', 'behavior', 'policy', 'πθ', 'discount', 'factor', 'apply', 'discount', 'future', 'reward', 'accumulate', 'reward', 'h', 'terminal', 'time', 'step', 'trajectory', 'example', 'figure', 'show', 'example', 'base', 'cartpole', 'task', 'datum', 'collection', 'process', 'dataset', 'generate', 'operation', 'log', 'operator', 'envi', 'ronment', 'contain', 'position', 'velocity', 'cart', 'pole', 'state', 'operator', 'force', 'direction', 'action', 'corresponding', 'reward', 'training', 'evaluation', 'process', 'offline', 'model', 'learn', 'play', 'cartpole', 'task', 'precollecte', 'dataset', 'generate', 'datum', 'collection', 'process', 'finally', 'deploy', 'model', 'environment', 'perform', 'task', 'controlcart', 'pole', 'fig', 'running', 'example', 'offline', 'model', 'offline', 'rl', 'model', 'section', 'first', 'introduce', 'offline', 'separately', 'represent', 'basic', 'idea', 'offline', 'model', 'policy', 'constraint', 'strategy', 'value', 'function', 'regularization', 'strategy', 'many', 'state', 'method', 'modify', 'approach', 'far', 'present', 'stateoftheart', 'minimalistic', 'light', 'computation', 'hyperparameter', 'set', 'overhead', 'addition', 'briefly', 'describe', 'behavior', 'clone', 'learn', 'stateaction', 'distribution', 'dataset', 'supervised', 'learning', 'approach', 'typical', 'reinforcement', 'learning', 'method', 'solve', 'offline', 'problem', 'usually', 'serve', 'baseline', 'method', 'offline', 'evaluation', 'behavior', 'clone', 'separately', 'take', 'pairwise', 'state', 'action', 'dataset', 'input', 'label', 'optimize', 'policy', 'follow', 'function', 'θ∗', 'arg', 'l', 'πθ', 'precollecte', 'dataset', 'l', 'loss', 'function', 'imitate', 'action', 'distribution', 'performance', 'close', 'mean', 'dataset', 'even', 'work', 'well', 'online', 'algorithm', 'case', 'batchconstraine', 'qlearne', 'first', 'practical', 'datadriven', 'key', 'idea', 'integrate', 'generative', 'model', 'achieve', 'notion', 'batchconstraine', 'minimize', 'deviation', 'candidate', 'action', 'action', 'record', 'dataset', 'maintain', 'diversity', 'action', 'build', 'perturbation', 'model', 'perturb', 'select', 'action', 'choose', 'highestvalue', 'action', 'qnetwork', 'learn', 'estimate', 'expect', 'cumulative', 'reward', 'give', 'state', 'action', 'pair', 'thus', 'objective', 'function', 'define', 'follow', 'π', 'argmax', 'ai', 'ai', 'φ', 'aiξϕ', 'ai', 'φ', 'ai', 'conditional', 'variational', 'autoencoder', 'vae', 'base', 'generative', 'model', 'use', 'generate', 'candidate', 'action', 'value', 'function', 'qθ', 'use', 'score', 'n', 'candidate', 'action', 'find', 'action', 'high', 'value', 'ai', 'φ', 'perturbation', 'model', 'output', 'dataset', '𝒓𝒓𝒕𝒕', '𝒔𝒔𝒕𝒕', 'state', 'reward', 'move', 'leave', 'r', 'move', 'right', 'r', 'move', 'leave', 'r', 'action', 'environment', 'operator', 'offline', 'model', 'state', 'datum', 'collection', 'training', 'evaluation', 'deployment', 'adjustment', 'action', 'range', '−φ', 'perturbation', 'model', 'optimize', 'deterministic', 'policy', 'gradient', 'follow', 'φ', 'represent', 'minibatch', 'stateaction', 'pair', 'dataset', 'penalize', 'rare', 'state', 'take', 'convex', 'combination', 'value', 'qnetwork', 'set', 'new', 'target', 'value', 'update', 'qnetwork', 'cid20', 'ai', 'ai', 'ai', 'correspond', 'perturb', 'action', 'sample', 'generative', 'model', 'implicit', 'qlearning', 'iql', 'compare', 'batch', 'constrain', 'idea', 'iql', 'strictly', 'avoid', 'query', 'ing', 'value', 'action', 'precollecte', 'dataset', 'iql', 'first', 'construct', 'model', 'evaluate', 'expect', 'return', 'stateaction', 'pair', 'objective', 'function', 'define', 'show', 'equation', 'l', 'θ', 'ed', 'cid2', 'cid0', 'r', 'γqˆθ', 'cid1', 'cid3', 'u', 'τ', 'u', 'represent', 'successor', 'state', 'action', 'qˆθ', 'use', 'assess', 'expect', 'return', 'state', 'action', 'pair', 'parameter', 'adjust', 'optimization', 'round', 'parameter', 'update', 'periodically', 'base', 'reduce', 'parameter', 'fluctuation', 'model', 'update', 'equation', 'involve', 'dynamic', 'environment', 'environment', 'state', 'transition', 'next', 'environment', 'state', 'potentially', 'introduce', 'interference', 'evaluation', 'expect', 'return', 'stateaction', 'pair', 'iql', 'address', 'issue', 'introduce', 'new', 'state', 'value', 'model', 'splitting', 'equation', 'objective', 'function', 'equation', 'show', 'objective', 'function', 'state', 'value', 'model', 'ed', 'cid2', 'cid0', 'cid3', 'iql', 'utilize', 'construct', 'equation', 'update', 'parameter', 'stateaction', 'value', 'model', 'lq', 'θ', 'cid104', 'r', 'γvψ', 'finally', 'iql', 'consider', 'use', 'stateaction', 'value', 'model', 'construct', 'behavior', 'policy', 'deployment', 'behavior', 'policy', 'also', 'need', 'avoid', 'action', 'dataset', 'distribution', 'thus', 'iql', 'employ', 'advantageweighted', 'regre', 'sion', 'update', 'policy', 'model', 'ed', 'exp', 'log', '∞', 'represent', 'inverse', 'temperature', 'small', 'value', 'iql', 'similar', 'behavior', 'clone', 'tend', 'mimic', 'datum', 'collection', 'policy', 'large', 'value', 'iql', 'inclined', 'select', 'action', 'correspond', 'high', 'expect', 'return', 'accord', 'stateaction', 'value', 'model', 'entire', 'training', 'process', 'iql', 'alternate', 'optimize', 'parameter', 'update', 'keep', 'fix', 'former', 'method', 'limit', 'regularize', 'action', 'selection', 'learn', 'policy', 'easy', 'evaluate', 'give', 'dataset', 'however', 'introduce', 'new', 'hyperparameter', 'often', 'leverage', 'secondary', 'component', 'generative', 'model', 'adjust', 'underlie', 'minimalist', 'highly', 'effective', 'offline', 'base', 'delay', 'deep', 'deterministic', 'policy', 'gradient', 'td3', 'regularization', 'term', 'push', 'policy', 'favor', 'action', 'contain', 'dataset', 'π', 'argmax', 'e', 'cid2', 'π', 'π', 'cid3', 'n', 'q', 'dataset', 'n', 'transition', 'facilitate', 'policy', 'training', 'normalize', 'state', 'give', 'dataset', 'si', 'si−µ', 'σϵ', 'σ', 'mean', 'standard', 'deviation', 'respectively', 'model', 'architecture', 'vary', 'significantly', 'regard', 'objec', 'tive', 'function', 'basic', 'model', 'structure', 'objective', 'function', 'use', 'policy', 'constraint', 'strategy', 'maintain', 'learn', 'policy', 'similar', 'one', 'use', 'collect', 'dataset', 'contrast', 'iql', 'adopt', 'regularization', 'strategy', 'improve', 'stochasticity', 'learn', 'policy', 'obtain', 'accurate', 'qvalue', 'estimation', 'basic', 'model', 'structure', 'iql', 'base', 'qlearning', 'model', 'build', 'td3', 'section', 'experiment', 'mainly', 'conduct', 'algorithm', 'however', 'orlauditor', 'also', 'apply', 'type', 'offline', 'drl', 'model', 'long', 'auditor', 'blackbox', 'access', 'suspect', 'model', 'problem', 'statement', 'exist', 'solution', 'system', 'threat', 'model', 'dataset', 'application', 'scenario', 'figure', 'illustrate', 'typical', 'plication', 'scenario', 'datum', 'provider', 'collect', 'publish', 'sell', 'customer', 'malicious', 'customer', 'adversary', 'access', 'dataset', 'make', 'piracy', 'distribution', 'illegally', 'build', 'modelasaservice', 'maas', 'platform', 'institution', 'suspect', 'model', 'generate', 'dataset', 'thus', 'hire', 'auditor', 'determine', 'model', 'trainer', 'pirate', 'trajectory', 'dataset', 'd1', 'auditor', 'background', 'knowledge', 'capability', 'auditor', 'full', 'knowledge', 'target', 'dataset', 'number', 'trajectory', 'space', 'state', 'action', 'offline', 'setting', 'auditor', 'prohibit', 'interact', 'online', 'environment', 'collect', 'datum', 'mean', 'entire', 'auditing', 'depend', 'target', 'dataset', 'consider', 'auditor', 'blackbox', 'access', 'model', 'note', 'general', 'challenging', 'scenario', 'auditor', 'typical', 'application', 'scenario', 'adver', 'sary', 'receive', 'model', 'setting', 'customer', 'select', 'offline', 'model', 'hyperparameter', 'desire', 'training', 'episode', 'adversary', 'train', 'offline', 'rl', 'model', 'provide', 'service', 'interface', 'customer', 'auditor', 'utilize', 'state', 'dataset', 'input', 'query', 'suspect', 'model', 'obtain', 'correspond', 'action', 'output', 'explicit', 'watermark', 'dataset', 'train', 'model', 'exist', 'method', 'divide', 'category', 'accord', 'explicit', 'classification', 'label', 'explicit', 'classification', 'label', 'rely', 'compute', 'distance', 'datum', 'point', 'decision', 'boundary', 'explicit', 'classification', 'label', 'utilize', 'similarity', 'model', 'behavior', 'detect', 'unauthorized', 'usage', 'dataset', 'require', 'assumption', 'additional', 'public', 'dataset', 'similar', 'distribution', 'form', 'auditing', 'basis', 'however', 'method', 'directly', 'apply', 'reinforcement', 'learning', 'case', 'reason', 'first', 'labelbase', 'dataset', 'inference', 'implement', 'rl', 'model', 'output', 'usually', 'continuous', 'guide', 'rough', 'reward', 'signal', 'instead', 'exact', 'label', 'second', 'distribution', 'offline', 'dataset', 'depend', 'environment', 'also', 'rely', 'strategy', 'interact', 'environment', 'thus', 'challenge', 'find', 'proper', 'public', 'dataset', 'scenario', 'delve', 'become', 'evident', 'behavior', 'similarity', 'drl', 'model', 'vary', 'different', 'public', 'training', 'datum', 'furthermore', 'behavior', 'similarity', 'also', 'influence', 'various', 'offline', 'drl', 'framework', 'membership', 'inference', 'attack', 'several', 'membership', 'inference', 'attack', 'exist', 'seem', 'address', 'problem', 'study', 'paper', 'target', 'scene', 'assume', 'attacker', 'environment', 'thus', 'utilize', 'environment', 'collect', 'datum', 'even', 'manipulate', 'adversarial', 'state', 'facilitate', 'inference', 'however', 'paper', 'aim', 'offline', 'case', 'challenging', 'thing', 'auditor', 'use', 'precollecte', 'dataset', 'scenario', 'exist', 'mia', 'rely', 'environment', 'generate', 'nonmember', 'datum', 'orlauditor', 'instantiate', 'q', 'figure', 'cumulative', 'reward', 'intrinsic', 'feature', 'dataset', 'suitable', 'auditing', 'determine', 'shadow', 'model', 'train', 'dataset', 'instead', 'preset', 'threshold', 'adapt', 'distribution', 'different', 'dataset', 'thus', 'welldesigne', 'q', 'guarantee', 'adaptiveness', 'effectiveness', 'orlauditor', 'workflow', 'ease', 'understanding', 'refer', 'target', 'dataset', 'dataset', 'audit', 'actual', 'dataset', 'dataset', 'use', 'suspect', 'model', 'suspect', 'model', 'train', 'target', 'dataset', 'actual', 'dataset', 'target', 'dataset', 'positive', 'audit', 'result', 'suspect', 'model', 'otherwise', 'suspect', 'model', 'use', 'target', 'dataset', 'negative', 'audit', 'result', 'suspect', 'model', 'figure', 'illustrate', 'workflow', 'orlauditor', 'fig', 'example', 'application', 'scenario', 'auditor', 'obtain', 'information', 'dataset', 'd1', 'knowledge', 'dataset', 'institution', 'discussion', 'compare', 'samplelevel', 'datasetlevel', 'datum', 'scene', 'trajectorylevel', 'datum', 'minimum', 'record', 'unit', 'sequential', 'interaction', 'operator', 'environment', 'single', 'trajectory', 'guide', 'model', 'initial', 'state', 'terminal', 'trajectorylevel', 'datum', 'regard', 'value', 'unit', 'dataset', 'thus', 'orlauditor', 'design', 'audit', 'dataset', 'trajectory', 'level', 'auditor', 'try', 'decide', 'suspect', 'model', 'use', 'specific', 'trajectory', 'dataset', 'addition', 'auditor', 'easily', 'extend', 'orlauditor', 'datasetlevel', 'datum', 'set', 'piracy', 'alarm', 'threshold', 'ratio', 'misappropriation', 'use', 'trajectory', 'exceed', 'preset', 'threshold', 'auditor', 'claim', 'datasetlevel', 'pirate', 'b', 'exist', 'solution', 'watermarking', 'watermarkingbase', 'dataset', 'copy', 'right', 'protection', 'method', 'inject', 'sample', 'specific', 'distribu', 'tion', 'publish', 'target', 'dataset', 'kind', 'implement', 'backdoor', 'attack', 'propose', 'modify', 'dataset', 'add', 'trigger', 'local', 'patch', 'innocent', 'sample', 'order', 'make', 'appear', 'predefine', 'target', 'class', 'verify', 'integrity', 'dataset', 'attack', 'use', 'hypothesis', 'test', 'approach', 'base', 'posterior', 'probability', 'generate', 'third', 'party', 'model', 'inspire', 'idea', 'auditor', 'employ', 'backdoor', 'attack', 'drl', 'model', 'generate', 'watermark', 'offline', 'dataset', 'however', 'opensource', 'dataset', 'already', 'pub', 'lishe', 'auditor', 'need', 'postevent', 'mechanism', 'require', 'inject', 'manipulate', 'sample', 'publish', 'dataset', 'watermarking', 'hand', 'preevent', 'mechanism', 'involve', 'inject', 'manipulate', 'sample', 'dataset', 'publish', 'additionally', 'difficult', 'auditor', 'guarantee', 'effective', 'watermarking', 'consistent', 'distribution', 'original', 'dataset', 'evitably', 'disturb', 'model', 'normal', 'behavior', 'dataset', 'inference', 'core', 'idea', 'dataset', 'inference', 'empower', 'model', 'owner', 'make', 'com', 'pelling', 'statistical', 'argument', 'particular', 'model', 'copy', 'version', 'model', 'demonstrate', 'base', 'private', 'training', 'datum', 'require', 'inject', 'step', 'model', 'preparation', 'mp', 'left', 'box', 'figure', 'auditor', 'prepare', 'critic', 'model', 'shadow', 'model', 'base', 'target', 'dataset', 'contain', 'length', 'critic', 'model', 'optimize', 'estimate', 'cumulative', 'reward', '𝒋𝒋', '𝒋𝒋', '𝒋𝒋', '𝒔𝒔𝒏𝒏𝟏𝟏', '𝒂𝒂𝒏𝒏𝟏𝟏', '𝒓𝒓𝒏𝒏𝟏𝟏', '𝒂𝒂𝒏𝒏𝒋𝒋', '𝒋𝒋', '𝒔𝒔𝒆𝒆𝒏𝒏𝒆𝒆', 'transition', 'trajectory', 'institution', 'dataset', 'institution', 'dataset', 'institution', 'dataset', 'v', 'e', 'r', 'r', 'model', 'model', '𝜋𝜋', 'model', 'auditor', 'institution', 'model', 'pirate', 'th', 'trajectory', 'dataset', '𝒋𝒋', 'fig', 'workflow', 'orlauditor', 'contain', 'step', 'ie', 'model', 'preparation', 'cumulative', 'reward', 'collection', 'audit', 'process', 'orlauditor', 'first', 'train', 'set', 'shadow', 'drl', 'model', 'critic', 'model', 'target', 'dataset', 'collect', 'cumulative', 'reward', 'stateaction', 'pair', 'shadow', 'model', 'suspect', 'model', 'finally', 'orlauditor', 'audits', 'trajectory', 'base', 'hypothesis', 'testing', 'stateaction', 'pair', 'trajectory', 'dataset', 'series', 'prediction', 'stateaction', 'pair', 'compose', 'exclusive', 'feature', 'auditing', 'way', 'optimize', 'critic', 'model', 'montecarlobase', 'mcbase', 'temporaldifferencebase', 'tdbase', 'strategy', 'adopt', 'tdbase', 'learning', 'method', 'explain', 'reason', 'section', 'ivb', 'addition', 'auditor', 'train', 'set', 'shadow', 'model', 'follow', 'model', 'objective', 'function', 'introduce', 'section', 'different', 'model', 'initialization', 'step', 'cumulative', 'reward', 'collection', 'crc', 'shadow', 'model', 'observe', 'state', 'dataset', 'take', 'action', 'trajectory', 'dataset', 'auditor', 'record', 'state', 'action', 'ai', 'shadow', 'model', 'represent', 'shadow', 'model', 'action', 'step', 'trajectory', 'ti', 'finish', 'action', 'collection', 'auditor', 'obtain', 'k', 'set', 'stateaction', 'pair', 'shadow', 'model', 'represent', 'learn', 'policy', 'different', 'initialization', 'training', 'process', 'target', 'dataset', 'use', 'critic', 'model', 'step', 'auditor', 'calculate', 'estimation', 'stateaction', 'record', 'estimate', 'cumulative', 'reward', 'sampling', 'exact', 'cumulative', 'reward', 'corresponding', 'stateaction', 'pair', 'dataset', 'similarly', 'auditor', 'query', 'suspect', 'model', 'stateaction', 'pair', 'put', 'critic', 'model', 'obtain', 'estimation', 'suspect', 'model', 'observe', 'action', 'ai', 'step', 'audit', 'process', 'step', 'auditor', 'obtain', 'estimate', 'cumulative', 'reward', 'shadow', 'model', 'suspect', 'model', 'con', 'duct', 'audit', 'process', 'jectory', 'dataset', 'auditor', 'collect', 'series', 'estimate', 'cumulative', 'reward', 'shadow', 'model', 'qi', 'k', 'suspect', 'model', 'qs', 'orlauditor', 'conduct', 'hypothesis', 'testing', 'base', '¯qj', 'auditor', 'distance', 'distribution', 'rule', 'suspicion', 'qs', 'j', 'k', 'otherwise', 'auditor', 'qi', 'conclude', 'positive', 'decision', 'suspect', 'model', 'train', 'use', 'trajectory', 'auditor', 'repeatedly', 'implement', 'process', 'trajectory', 'dataset', 'obtain', 'qs', 'final', 'audit', 'report', 'judgment', 'trajectory', 'discuss', 'detail', 'distance', 'metric', 'hypothesis', 'testing', 'section', 'selection', 'critic', 'model', 'auditor', 'use', 'base', 'temporaldifference', 'base', 'algorithm', 'train', 'critic', 'model', 'trajectory', 'dataset', 'main', 'distinction', 'method', 'lie', 'learning', 'target', 'lead', 'difference', 'objective', 'function', 'case', 'mcbase', 'method', 'learn', 'target', 'empirical', 'cumulative', 'reward', 'dataset', 'γh−1rh', 'represent', 'exact', 'cumulative', 'reward', 'terminal', 'time', 'step', 'h', 'trajectory', 'discount', 'factor', 'apply', 'discount', 'future', 'reward', 'critic', 'model', 'train', 'minimize', 'follow', 'objective', 'e', 'rt1', 'st1', 'cid104', 'cid105', 'tdbase', 'method', 'learn', 'target', 'change', 'expect', 'cumulative', 'reward', 'heuristic', 'form', 'γq', 'st1', 'at1', 'thus', 'critic', 'model', 'train', 'mini', 'mize', 'follow', 'loss', 'function', 'e', 'rt1', 'st1', 'cid2', 'rt1', 'st1', 'at1', 'cid3', 'critic', 'model', 'start', 'arbitrary', 'initialization', 'θ', 'repeatedly', 'evaluate', 'obtain', 'reward', 'rt1', 'update', 'weight', 'θ′', 'snapshot', 'θ', 'copy', 'θ', 'update', 'θ', 'mcbase', 'method', 'utilize', 'exact', 'cumulative', 'reward', 'dataset', 'train', 'critic', 'model', 'result', 'unbiased', 'prediction', 'also', 'strong', 'convergence', 'property', 'stationary', 'however', 'apply', 'situation', 'collect', 'datum', 'truncate', 'trajectory', 'dataset', 'complete', 'practice', 'many', 'sequential', 'decisionmake', 'task', 'usually', 'long', 'infinite', 'time', 'step', 'thus', 'dataset', 'provider', 'segment', 'interaction', 'record', 'trajectory', 'preset', 'maximum', 'length', 'tdbase', 'method', 'tackle', 'limitation', 'mcbase', 'learn', 'incomplete', 'sequence', 'nevertheless', 'heuristic', 'learn', 'process', 'step', 'model', 'preparation', 'step', 'cumulative', 'reward', 'collection', 'dataset', '𝑟𝑡', '𝑠𝑡1', '𝑟𝑡', '𝑠𝑡1', '𝑛2', '𝑛𝑚', 'train', 'shadow', 'model', 'critic', 'model', '𝑎', 'shadow', 'model', '𝑛2', '𝑛𝑚', 'state', 'model', '𝑛2', '𝑛𝑚', 'model', '𝑛1', 'model', '𝑎𝑡', '𝑡', '𝑛2', '𝑡', '𝑛2', '𝑛𝑚', '𝑛𝑚', 'state', 'action', 'critic', 'model', '𝑠', 'cumulative', 'reward', '𝑎𝑡', '𝑛1', '𝑛2', '𝑛𝑚', '𝑎𝑡', '𝑡', '𝑛1', '𝑡', '𝑛2', '𝑛𝑚', 'suspect', 'model', 'state', 'action', 'critic', 'model', '𝑠', 'cumulative', 'reward', 'audit', 'metric', 'step3', 'audit', 'process', '𝒋th', 'trajectory', 'dataset', '𝑚', '⋯', 'length', 'trajectory', '𝑑', '𝑑', 'elementwise', 'mean', '𝑑', '⋯', '𝑑', 'positive', 'negative', 'hypothesis', 'testing', 'negative', 'workflow', 'orlauditor', 'input', 'suspect', 'model', 'number', 'shadow', 'model', 'significance', 'level', 'output', 'trajectorylevel', 'audit', 'report', 'step', 'model', 'preparation', 'train', 'shadow', 'model', 'k', 'critic', 'model', 'step', 'datum', 'preparation', 'model', 'πi', 'k', '∪', 'query', 'state', 'obtain', 'action', 'evaluate', 'pair', 'base', 'critic', 'model', 'record', 'cumulative', 'reward', 'sequential', 'form', 'qj', 'j', 'end', 'step', 'audit', 'process', 'audit', 'report', 'trajectory', 'j', 'calculate', 'elementwise', 'mean', '¯qj', 'k', 'measure', 'qj', 'qi', 'hypothesis', 'testing', 'k', 'decide', 'j', '¯qj', 'j', 'qs', 'suspect', 'model', 'pirate', 'significance', 'level', 'audit', 'reportappend', 'audit', 'result', 'end', 'return', 'audit', 'report', 'tdbase', 'method', 'bias', 'sensitive', 'model', 'initialization', 'therefore', 'choose', 'elementwise', 'mean', 'shadow', 'model', 'cumulative', 'reward', '¯q', 'auditing', 'directrix', 'section', 'iva', 'instead', 'rely', 'solely', 'critic', 'model', 'prediction', 'compensate', 'shortage', 'tdbase', 'method', 'detail', 'audit', 'process', 'audit', 'process', 'choice', 'distance', 'metric', 'hypothesis', 'testing', 'method', 'play', 'critical', 'role', 'auditor', 'performance', 'proper', 'metric', 'sensitive', 'deviation', 'estimate', 'cumulative', 'reward', 'facilitate', 'hypothesis', 'test', 'suitable', 'hypothesis', 'test', 'ing', 'method', 'provide', 'precise', 'result', 'high', 'confidence', 'distance', 'metric', 'consider', 'type', 'distance', 'metric', 'norm', 'cosine', 'distance', 'distance', 'ℓp', 'norm', 'popular', 'method', 'measure', 'distance', 'vector', 'sum', 'absolute', 'difference', 'compo', 'nent', 'vector', 'rl', 'scene', 'state', 'action', 'sequential', 'datum', 'mean', 'distance', 'metric', 'measure', 'value', 'position', 'deviation', 'cumulative', 'reward', 'however', 'ℓp', 'norm', 'fail', 'reflect', 'difference', 'sequence', 'aspect', 'set', 'value', 'cosine', 'distance', 'derivative', 'cosine', 'similarity', 'define', 'cosine', 'angle', 'vector', 'cosine', 'distance', 'embody', 'difference', 'value', 'position', 'aspect', 'vector', 'however', 'cosine', 'distance', 'normalize', 'inner', 'product', 'use', 'vector', 'norm', 'weaken', 'numerical', 'difference', 'cumulative', 'reward', 'wasserstein', 'distance', 'aka', 'earth', 'mover', 'distance', 'metric', 'difference', 'probability', 'distribution', 'region', 'define', 'follow', 'inf', 'u', 'v', 'set', 'distribution', 'r', 'r', 'marginal', 'u', 'v', 'first', 'second', 'factor', 'tively', 'wasserstein', 'distance', 'fit', 'well', 'audit', 'requirement', 'reflect', 'positional', 'deviation', 'cumula', 'tive', 'reward', 'thus', 'set', 'wasserstein', 'distance', 'default', 'compare', 'different', 'distance', 'metric', 'section', 'hypothesis', 'testing', 'selection', 'distance', 'metric', 'auditor', 'proceed', 'hypothesis', 'testing', 'distance', 'qs', 'j', '¯qj', 'h0', 'qs', 'j', 'outlier', 'j', 'outlier', 'intuitive', 'method', 'leverage', 'principle', 'normal', 'sample', 'distribute', 'range', 'time', 'standard', 'deviation', 'mean', 'principle', 'efficient', 'hypothesis', 'testing', 'method', 'yet', 'mean', 'easily', 'mislead', 'outlier', 'compare', 'principle', 'grubb', 'test', 'robust', 'sis', 'testing', 'method', 'detect', 'single', 'outlier', 'univariate', '¯qj', 'exceed', 'dataset', 'grubb', 'test', 'statistic', 'qs', 'threshold', 'derive', 'significance', 'level', 'auditor', 'deviate', 'mean', 'value', 'reject', 'claim', 'h0', 'output', 'negative', 'audit', 'result', 'set', 'sample', 'grubb', 'test', 'locate', 'outlier', 'procedure', 'calculate', 'mean', 'µd', 'standard', 'deviation', 'calculate', 'grubb', 'test', 'statistic', 'qs', 'n', 'n−2t2', 'invalid', 'suspect', 'model', 'train', 'trajectory', 'inequation', 'represent', 'upper', 'critical', 'value', 'tdistribution', 'degree', 'freedom', 'significance', 'level', 'n', 'hypothesis', 'testing', 'method', 'base', 'assump', 'tion', 'distance', 'value', 'follow', 'gaussian', 'distribution', 'thus', 'orlauditor', 'need', 'precheck', 'distance', 'value', 'shadow', 'model', 'satisfy', 'gaussian', 'distribution', 'adopt', 'andersondarle', 'test', 'fit', 'scenario', 'auditor', 'small', 'number', 'sampling', 'actual', 'distribution', 'unknown', 'evaluation', 'distance', 'value', 'shadow', 'model', 'pass', 'andersondarle', 'test', 'randomness', 'model', 'initialization', 'training', 'orlauditor', 'conduct', 'hypothesis', 'test', 'evaluation', 'first', 'introduce', 'task', 'experimental', 'setup', 'section', 'validate', 'effectiveness', 'auditor', 'behavior', 'clone', 'offline', 'drl', 'model', 'batchconstraine', 'qlearne', 'implicit', 'learning', 'iql', 'section', 'visualize', 'cumulative', 'reward', 'tsne', 'demonstrate', 'cumulative', 'reward', 'intrinsic', 'stable', 'table', 'overview', 'task', 'continuous', 'discrete', 'illustrate', 'data', 'type', 'state', 'action', 'correspond', 'number', 'dimension', 'parenthesis', 'task', 'lunar', 'lander', 'continuous', 'state', 'shape', 'action', 'shape', 'continuous', '6dim', 'discrete', 'continuous', 'walker', 'continuous', 'continuous', 'ant', 'continuous', 'continuous', 'feature', 'dataset', 'auditing', 'section', 'far', 'evaluate', 'impact', 'factor', 'orlauditor', 'number', 'shadow', 'model', 'significance', 'level', 'hypothesis', 'testing', 'trajectory', 'size', 'section', 'finally', 'utilize', 'orlauditor', 'audit', 'opensource', 'dataset', 'deepmind', 'section', 'experimental', 'setup', 'task', 'adopt', 'lunar', 'lander', 'bipedal', 'walker', 'ant', 'task', 'gym', 'widely', 'use', 'prior', 'work', 'task', 'stem', 'distinct', 'realworld', 'problem', 'numerical', 'vector', 'contain', 'different', 'physical', 'formation', 'position', 'velocity', 'acceleration', 'task', 'involve', 'discrete', 'continuous', 'variable', 'observation', 'action', 'space', 'dimension', 'range', 'low', 'dim', 'high', 'give', 'overview', 'table', 'put', 'detail', 'b', 'dataset', 'generation', 'offline', 'model', 'preparation', 'obtain', 'dataset', 'task', 'table', 'adopt', 'idea', 'exist', 'dataset', 'publisher', 'train', 'model', 'interactive', 'envi', 'ronment', 'record', 'interaction', 'dataset', 'dataset', 'consist', 'numerical', 'vector', 'lunar', 'lander', 'transition', 'include', 'state', 'next', 'state', '6dimensional', 'continuous', '2dimensional', 'discrete', 'variable', 'action', 'continuous', 'variable', 'reward', 'scalar', 'therefore', 'transition', 'vector', 'similarly', 'datum', 'type', 'bipedal', 'walker', 'ant', '53dimensional', 'numerical', 'vector', 'respectively', 'number', 'transition', 'task', 'lunar', 'lander', 'bipedal', 'walker', '×', 'ant', 'offline', 'rl', 'model', 'learn', 'dataset', 'table', 'summarize', 'whole', 'process', 'task', 'use', 'global', 'random', 'seed', 'train', 'online', 'model', 'separately', 'collect', 'dataset', 'online', 'model', 'random', 'seed', 'online', 'model', 'generate', 'dataset', 'ease', 'read', 'dataset', 'share', 'name', 'online', 'model', 'train', 'offline', 'drl', 'model', 'dataset', 'distinct', 'global', 'random', 'seed', 'initialization', 'optimization', 'process', 'online', 'offline', 'model', 'implement', 'librarie', 'default', 'hyperparameter', 'setting', 'critic', 'model', 'adopt', 'fully', 'connect', 'neural', 'network', 'critic', 'model', 'hidden', 'layer', 'neuron', 'layer', 'optimize', 'critic', 'model', 'follow', 'tdbase', 'method', 'section', 'ivb', 'adam', 'optimizer', 'learning', 'rate', 'minibatch', 'size', 'table', 'main', 'step', 'dataset', 'generation', 'offline', 'model', 'preparation', 'detail', 'input', 'output', 'combination', 'task', 'offline', 'model', 'experiment', '↓', 'train', 'random', 'seed', '↓', 'online', 'rl', 'model', 'detail', 'table', '↓', 'collect', 'random', 'seed', '↓', 'offline', 'dataset', 'detail', 'table', '↓', 'train', 'random', 'seed', '↓', 'offline', 'rl', 'model', 'detail', 'table', 'xvi', 'table', 'xvii', 'table', 'table', 'entire', 'training', 'take', 'epoch', 'learning', 'rate', 'decay', 'epoch', 'evaluation', 'metric', 'recall', 'orlauditor', 'application', 'scenario', 'figure', 'single', 'suspect', 'model', 'audit', 'accuracy', 'well', 'characterize', 'performance', 'auditor', 'ratio', 'number', 'correctly', 'audit', 'trajectory', 'total', 'auditing', 'trajectory', 'experiment', 'positive', 'model', 'train', 'target', 'dataset', 'negative', 'model', 'train', 'dataset', 'randomly', 'mixed', 'majority', 'dominate', 'accuracy', 'thus', 'provide', 'true', 'positive', 'rate', 'tpr', 'true', 'negative', 'rate', 'tnr', 'method', 'provide', 'audit', 'performance', 'principle', 'grubbs', 'test', 'distance', 'metric', 'ℓ1', 'norm', 'norm', 'cosine', 'distance', 'distance', 'competitor', 'recall', 'section', 'iiib', 'exist', 'method', 'design', 'online', 'reinforcement', 'learning', 'scene', 'assume', 'auditor', 'continuously', 'interact', 'environment', 'obtain', 'new', 'datum', 'nonmember', 'example', 'base', 'behavioral', 'difference', 'model', 'member', 'example', 'nonmember', 'example', 'build', 'member', 'inference', 'method', 'detect', 'example', 'use', 'train', 'suspect', 'model', 'offline', 'scenario', 'access', 'environment', 'auditor', 'precollecte', 'target', 'dataset', 'thus', 'randomly', 'divide', 'target', 'dataset', 'part', 'train', 'offline', 'model', 'subset', 'separately', 'subset', 'regard', 'set', 'nonmember', 'example', 'offline', 'rl', 'model', 'train', 'subset', 'adopt', 'data', 'augmentation', 'attack', 'classifier', 'architecture', 'hyperparameter', 'setting', 'implementation', 'use', 'stablebaseline', 'd3rlpy', 'implement', 'online', 'offline', 'drl', 'model', 'separately', 'audit', 'method', 'realize', 'server', 'geforce', 'gb', 'memory', 'b', 'overall', 'audit', 'performance', 'assess', 'effectiveness', 'orlauditor', 'combination', 'task', 'model', 'fur', 'present', 'evaluation', 'efficacy', 'competitor', 'offline', 'drl', 'model', 'setup', 'table', 'train', 'offline', 'rl', 'model', 'dataset', 'obtain', 'offline', 'drl', 'model', 'table', 'performance', 'exist', 'membership', 'inference', 'attack', 'offline', 'model', 'task', 'lunar', 'train', '5009±068', '4984±139', '4988±076', 'test', '4719±190', '4548±146', '4674±237', '4538±216', '4503±155', 'experimental', 'setting', 'audit', 'dataset', 'separately', 'auditor', 'randomly', 'select', 'model', 'target', 'dataset', 'shadow', 'model', 'remain', 'model', 'model', 'dataset', 'positive', 'negative', 'suspect', 'model', 'target', 'dataset', 'randomly', 'select', 'auditing', 'trajectory', 'audit', 'unbalanced', 'amount', 'positive', 'negative', 'model', 'report', 'aggregated', 'mean', 'standard', 'deviation', 'tpr', 'tnr', 'setting', 'table', 'provide', 'audit', 'result', 'dataset', 'figure', 'lunar', 'lander', 'figure', 'bipedal', 'walker', 'figure', 'ant', 'pair', 'tpr', 'tnr', 'table', 'derive', 'diagonal', 'nondiagonal', 'value', 'corresponding', 'heatmap', 'supplementary', 'also', 'show', 'audit', 'result', 'principle', 'table', 'competitor', 'performance', 'show', 'table', 'value', 'mean', 'standard', 'variation', 'calculate', 'repeat', 'experiment', 'time', 'observation', 'follow', 'observation', 'table', 'iv', 'table', 'table', 'tpr', 'tnr', 'value', 'high', 'mean', 'orlauditor', 'valid', 'solution', 'audit', 'learned', 'dataset', 'offline', 'drl', 'model', 'instance', 'result', 'orlauditor', 'ℓ1', 'norm', 'experiment', 'setting', 'orlauditor', 'obtain', 'different', 'audit', 'accuracy', 'distance', 'metric', 'audit', 'effectiveness', 'ℓ1', 'norm', 'wasserstein', 'distance', 'well', 'ℓ2', 'norm', 'cosine', 'distance', 'table', 'table', 'vii', 'orlauditor', 'wasserstein', 'distance', 'always', 'perform', 'good', 'second', 'place', 'result', 'ℓ2', 'norm', 'usually', 'distance', 'metric', 'recall', 'section', 'distance', 'characterize', 'positional', 'deviation', 'cumulative', 'reward', 'sensitive', 'numerical', 'difference', 'cumulative', 'reward', 'slight', 'eg', 'experiment', 'norm', 'undercut', 'small', 'potential', 'difference', 'accuracy', 'audit', 'determine', 'grubb', 'test', 'outperform', 'principle', 'principle', 'empirical', 'method', 'easily', 'mislead', 'outlier', 'cumu', 'lative', 'reward', 'shadow', 'model', 'recall', 'section', 'ivc', 'grubb', 'test', 'first', 'calculate', 'statistic', 'g', 'compare', 'g', 'adaptive', 'threshold', 'number', 'sample', 'also', 'consider', 'hypothesis', 'testing', 'new', 'datum', 'environment', 'fectiveness', 'exist', 'membership', 'inference', 'method', 'attenuate', 'perspective', 'similarity', 'sub', 'dataset', 'split', 'dataset', 'result', 'train', 'rl', 'model', 'exhibit', 'undifferentiated', 'behavior', 'make', 'difficult', 'effectively', 'distinguish', 'member', 'member', 'hand', 'consider', 'result', 'present', 'figure', 'conclude', 'action', 'rl', 'model', 'directly', 'utilize', 'foundation', 'membership', 'inference', 'c', 'visualization', 'cumulative', 'reward', 'far', 'explain', 'audit', 'result', 'section', 'analyze', 'cumulative', 'reward', 'shadow', 'model', 'j', 'qs', 'suspect', 'model', 'j', 'use', 'tsne', 'j', 'positive', 'qs', 'setup', 'caption', 'plot', 'figure', 'indicate', 'used', 'task', 'offline', 'drl', 'model', 'point', 'plot', 'show', 'visualization', 'single', 'qi', 'negative', 'single', 'plot', 'demonstrate', 'result', 'trajectory', 'task', 'first', 'dataset', 'instance', 'target', 'dataset', 'plot', 'title', 'lunar', 'lander', 'dataset', 'table', 'positive', 'point', 'trajectory', 'collect', 'shadow', 'model', 'train', 'dataset', 'negative', 'point', 'randomly', 'sample', 'shadow', 'model', 'dataset', 'observation', 'figure', 'follow', 'obser', 'vation', 'trajectory', 'target', 'dataset', 'cumulative', 'reward', 'shadow', 'model', 'suspect', 'model', 'clearly', 'divide', 'different', 'group', 'mean', 'critic', 'model', 'well', 'reflect', 'difference', 'model', 'action', 'thus', 'cumulative', 'reward', 'generate', 'critic', 'model', 'qualified', 'postevent', 'fingerprint', 'trajectorylevel', 'auditing', 'distribution', 'point', 'vary', 'different', 'trajec', 'tory', 'example', 'trajectory', 'lunar', 'lander', 'dataset', 'hard', 'cluster', 'trajectory', 'speculate', 'trajectory', 'represent', 'basic', 'policy', 'eg', 'local', 'optimum', 'policy', 'fire', 'lander', 'thruster', 'way', 'similar', 'trajectory', 'exist', 'dataset', 'nonuniqueness', 'optimal', 'strategy', 'rl', 'problem', 'impact', 'randomness', 'model', 'training', 'process', 'collect', 'trajectory', 'unique', 'characteristic', 'thus', 'trajectory', 'cumulative', 'reward', 'clearly', 'divide', 'hyperparameter', 'study', 'impact', 'extend', 'assessment', 'scrutinize', 'pivotal', 'de', 'terminant', 'pragmatic', 'integration', 'auditor', 'specifically', 'consider', 'amount', 'shadow', 'model', 'level', 'significance', 'hypothesis', 'testing', 'magnitude', 'trajectory', 'size', 'space', 'limitation', 'give', 'brief', 'conclusion', 'section', 'refer', 'specific', 'analysis', 'c', 'e', 'impact', 'shadow', 'model', 'amount', 'change', 'shadow', 'model', 'amount', 'setting', 'section', 'figure', 'show', 'value', 'change', 'tpr', 'tnr', 'compare', 'shadow', 'model', 'figure', 'title', 'illustrate', 'setting', 'model', 'task', 'indicate', 'metric', 'yaxis', 'absolute', 'value', 'change', 'supplementary', 'provide', 'detailed', 'result', 'table', 'viii', 'shadow', 'model', 'table', 'shadow', 'model', 'table', 'tpr', 'tnr', 'result', 'base', 'grubb', 'test', 'mean', 'standard', 'deviation', 'tpr', 'tnr', 'row', 'represent', 'audit', 'result', 'combination', 'task', 'model', 'distance', 'metric', 'indicate', 'high', 'sum', 'tpr', 'tnr', 'accuracy', 'row', 'pair', 'tpr', 'tnr', 'derive', 'diagonal', 'nondiagonal', 'value', 'corresponding', 'heatmap', 'figure', 'figure', 'figure', 'supplementary', 'task', 'offline', 'model', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', 'tpr', '9901±046', '9829±114', '9861±151', '9829±204', '9936±128', '9717±296', '9980±043', 'tpr', '9648±166', '9661±250', '9717±179', '9990±036', '9984±043', 'tpr', '9984±032', '9696±582', '9920±108', '9966±043', '9972±040', 'tpr', '9840±074', '9757±117', '9832±179', '9853±125', '9931±132', '9501±672', '9936±042', '9925±124', 'tnr', '9992±014', '9963±078', 'figure', 'follow', 'observation', 'audit', 'accuracy', 'increase', 'large', 'amount', 'shadow', 'model', 'exist', 'saturation', 'point', 'audit', 'accuracy', 'expansion', 'shadow', 'model', 'impact', 'significance', 'level', 'significance', 'level', 'rep', 'resent', 'auditor', 'confidence', 'auditing', 'result', 'significance', 'level', 'section', 'adopt', 'mean', 'auditor', 'confidence', 'judg', 'ment', 'generally', 'speak', 'significance', 'level', 'represent', 'maximum', 'audit', 'capacity', 'orlauditor', 'instead', 'hyperparameter', 'setting', 'audit', 'requirement', 'dataset', 'owner', 'demand', 'auditor', 'output', 'confident', 'judgment', 'error', 'possibility', 'limit', 'figure', 'show', 'value', 'change', 'tpr', 'tnr', 'compare', 'supplementary', 'detailed', 'result', 'dataset', 'table', 'table', 'figure', 'follow', 'observation', 'complicated', 'task', 'recommend', 'auditor', 'select', 'large', 'significance', 'level', 'orlauditor', 'suspect', 'model', 'low', 'performance', 'orlauditor', 'adopt', 'large', 'significance', 'level', 'guarantee', 'audit', 'accuracy', 'general', 'safe', 'bind', 'orlauditor', 'low', 'break', 'capability', 'boundary', 'auditor', 'induce', 'auditor', 'misclassify', 'negative', 'model', 'positive', 'set', 'impact', 'trajectory', 'size', 'investigate', 'relationship', 'trajectory', 'size', 'audit', 'accuracy', 'section', 'adopt', 'fulllength', 'trajectory', 'mean', 'auditor', 'utilize', 'state', 'trajectory', 'query', 'suspect', 'model', 'obtain', 'correspond', 'action', 'conduct', 'dataset', 'auditing', 'change', 'trajectory', 'size', 'full', 'length', 'setting', 'section', 'figure', 'show', 'value', 'change', 'tpr', 'tnr', 'compare', 'fulllength', 'trajectory', 'supplementary', 'also', 'provide', 'detailed', 'result', 'table', 'table', 'xiii', 'figure', 'follow', 'observation', 'orlauditor', 'tend', 'achieve', 'high', 'accuracy', 'large', 'trajectory', 'size', 'small', 'trajectory', 'size', 'achieve', 'well', 'result', 'task', 'front', 'state', 'trajectory', 'able', 'reflect', 'behavioral', 'information', 'model', 'e', 'realworld', 'application', 'section', 'apply', 'orlauditor', 'audit', 'open', 'source', 'dataset', 'deepmind', 'choose', 'task', 'publish', 'operator', 'control', 'cheetah', 'robot', 'consist', 'link', 'joint', 'connect', 'include', 'paw', 'make', 'run', 'forward', 'right', 'fast', 'possible', 'detail', 'offline', 'drl', 'model', 'table', 'xx', 'table', 'experimental', 'setting', 'consistent', 'section', 'vb', 'observation', 'table', 'follow', 'observation', 'orlauditor', 'effective', 'realworld', 'application', 'tpr', 'orlauditor', 'exceed', 'ℓ1', 'norm', 'wasserstein', 'distance', 'mean', 'orlauditor', 'remain', 'valid', 'exist', 'opensource', 'dataset', 'wasserstein', 'distance', 'stable', 'performance', 'experimental', 'realworld', 'dataset', 'overall', 'accuracy', 'orlauditor', 'wasserstein', 'distance', 'high', 'metric', 'vi', 'robustness', 'ensemble', 'architecture', 'hinder', 'audit', 'dataset', 'adversary', 'lize', 'stateoftheart', 'membership', 'inference', 'defense', 'strategy', 'propose', 'recent', 'research', 'work', 'defense', 'strategy', 'aim', 'mitigate', 'influence', 'member', 'example', 'behavior', 'machine', 'learning', 'model', 'base', 'idea', 'model', 'ensemble', 'particular', 'propose', 'split', 'training', 'set', 'several', 'subset', 'train', 'sub', 'model', 'subset', 'auditor', 'use', 'example', 'target', 'dataset', 'query', 'suspect', 'model', 'fig', 'visualization', 'cumulative', 'reward', 'tsne', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'single', 'plot', 'randomly', 'select', 'trajectory', 'first', 'dataset', 'task', 'ie', 'lunar', 'lander', 'dataset', 'bipedal', 'ant', 'dataset', 'table', 'show', 'cumulative', 'reward', 'positive', 'model', 'negative', 'model', 'trajectory', 'fig', 'impact', 'shadow', 'model', 'amount', 'change', 'value', 'tpr', 'tnr', 'number', 'shadow', 'model', 'vary', 'compare', 'default', 'shadow', 'model', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'label', 'display', 'distance', 'metric', 'label', 'show', 'absolute', 'fluctuating', 'value', 'tpr', 'tnr', 'adversary', 'aggregate', 'output', 'submodel', 'train', 'example', 'setup', 'number', 'divide', 'subset', 'denote', 'repre', 'sent', 'crucial', 'hyperparameter', 'ensemblebase', 'method', 'discuss', 'consider', 'analysis', 'conduct', 'study', 'well', 'size', 'offline', 'dataset', 'establish', 'present', 'investigation', 'experimental', 'setting', 'remain', 'unchanged', 'describe', 'section', 'correspond', 'audit', 'outcome', 'present', 'table', 'v', 'supplementary', 'result', 'dataset', 'figure', 'lunar', 'lander', 'figure', 'bipedal', 'walker', 'figure', 'ant', 'figure', 'half', 'cheetah', 'observation', 'conclude', 'follow', 'observation', 'base', 'result', 'even', 'face', 'ensemble', 'architecture', 'orlauditor', 'maintain', 'high', 'level', 'audit', 'accuracy', 'show', 'table', 'tpr', 'sistently', 'exceed', 'describe', 'section', 'iva', 'auditor', 'use', 'predict', 'cumulative', 'reward', 'critic', 'model', 'basis', 'auditing', 'train', 'critic', 'model', 'capture', 'overall', 'feature', 'dataset', 'distribution', 'instead', 'memorize', 'feature', 'individual', 'sample', 'ensemble', 'model', 'train', 'target', 'dataset', 'behavior', 'embed', 'distribution', 'characteristic', 'dataset', 'lunar', 'lander', 'lunar', 'lander', 'lunar', 'lander', 'iql', 'lunar', 'lander', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'ant', 'iql', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'trajectory', 'audit', 'result', 'positive', 'negative', 'lunar', 'lander', 'l', 'e', 'u', 'v', 'l', 'e', 'u', 'v', 'l', 'e', 'u', 'v', 'lunar', 'lander', 'lunar', 'lander', 'iql', 'lunar', 'lander', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'c', 'distance', 'metric', 'distance', 'metric', 'distance', 'metric', 'distance', 'metric', 'shadow', 'model', 'shadow', 'model', 'fig', 'impact', 'significance', 'level', 'change', 'value', 'tpr', 'tnr', 'significance', 'level', 'vary', 'compare', 'default', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'label', 'display', 'distance', 'metric', 'label', 'show', 'absolute', 'fluctuating', 'value', 'tpr', 'tnr', 'fig', 'impact', 'trajectory', 'size', 'change', 'value', 'tpr', 'tnr', 'trajectory', 'size', 'vary', 'compare', 'entire', 'trajectory', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'label', 'display', 'distance', 'metric', 'label', 'show', 'absolute', 'fluctuating', 'value', 'tpr', 'tnr', 'fig', 'robustness', 'action', 'distortion', 'change', 'value', 'tpr', 'tnr', 'suspect', 'model', 'add', 'µ', 'σ', 'output', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'label', 'display', 'distance', 'metric', 'label', 'show', 'absolute', 'fluctuating', 'value', 'orlauditor', 'detect', 'use', 'ensemble', 'architecture', 'result', 'crease', 'model', 'performance', 'certain', 'task', 'experiman', 'tal', 'result', 'show', 'column', 'model', 'performance', 'model', 'ensemble', 'table', 'table', 'xvi', 'table', 'xvii', 'table', 'table', 'demonstrate', 'decline', 'performance', 'offline', 'rl', 'model', 'utilize', 'ensemble', 'architecture', 'instance', 'model', 'learn', 'ant', 'dataset', 'mean', 'value', 'cumulative', 'reward', 'decrease', 'significantly', 'furthermore', 'submodel', 'train', 'subset', 'datum', 'fit', 'partial', 'dataset', 'distribution', 'consequently', 'apply', 'model', 'ensemble', 'practical', 'scenario', 'standard', 'deviation', 'model', 'performance', 'large', 'lunar', 'lander', 'v', 'u', 'v', 'u', 'v', 'lunar', 'lander', 'lunar', 'lander', 'iql', 'lunar', 'lander', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'c', 'distance', 'metric', 'distance', 'metric', 'distance', 'metric', 'distance', 'lunar', 'lander', 'lunar', 'lander', 'lunar', 'lander', 'iql', 'lunar', 'lander', 'v', 'l', 'e', 'u', 'v', 'l', 'e', 'u', 'v', 'bipedal', 'bipedal', 'walker', 'bipedal', 'walker', 'iql', 'bipedal', 'walker', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'c', 'distance', 'metric', 'distance', 'metric', 'distance', 'metric', 'distance', 'metric', 'full', 'trajectory', 'full', 'trajectory', 'lunar', 'lander', 'lunar', 'lander', 'lunar', 'lander', 'iql', 'lunar', 'lander', 'v', 'l', 'e', 'u', 'v', 'l', 'e', 'u', 'v', 'bipedal', 'walker', 'bipedal', 'walker', 'bipedal', 'walker', 'iql', 'bipedal', 'walker', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'l', 'l', 'l', 'l', 'p', 'r', 'r', 'r', 'r', 'p', 'r', 'r', 'p', 'r', 'r', 'c', 'distance', 'metric', 'distance', 'metric', 'distance', 'metric', 'distance', 'metric', 'sigma01', 'table', 'tpr', 'tnr', 'result', 'orlauditor', 'model', 'ensemble', 'k', 'mean', 'standard', 'deviation', 'tpr', 'tnr', 'row', 'represent', 'audit', 'result', 'combination', 'task', 'model', 'distance', 'metric', 'pair', 'tpr', 'tnr', 'derive', 'diagonal', 'nondiagonal', 'value', 'corresponding', 'heatmap', 'figure', 'lunar', 'lander', 'figure', 'bipedal', 'walker', 'figure', 'ant', 'figure', 'half', 'supplementary', 'task', 'name', 'lunar', 'half', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', '8900±1676', '9990±044', '9980±060', '8680±2832', 'tpr', 'tnr', '9990±044', '9980±060', 'action', 'distortion', 'suspect', 'model', 'perturb', 'action', 'change', 'original', 'model', 'output', 'conceal', 'training', 'dataset', 'practice', 'action', 'distortion', 'mechanism', 'stealthy', 'detect', 'auditor', 'easily', 'consider', 'drl', 'model', 'usually', 'apply', 'realworld', 'decision', 'make', 'task', 'selfdrive', 'car', 'industry', 'automa', 'natural', 'distortion', 'often', 'model', 'tion', 'gaussian', 'noise', 'example', 'thermal', 'noise', 'cause', 'random', 'motion', 'electron', 'conductor', 'model', 'gaussian', 'noise', 'constant', 'power', 'spec', 'trum', 'addition', 'noise', 'easy', 'manipulate', 'mathematically', 'ease', 'evaluate', 'effect', 'different', 'distortion', 'intensity', 'dimension', 'model', 'action', 'space', 'normalize', '−1', 'utilize', 'gaussian', 'noise', 'µ', 'standard', 'deviation', 'represent', 'level', 'distortion', 'setup', 'figure', 'depict', 'impact', 'action', 'distortion', 'information', 'used', 'offline', 'drl', 'model', 'task', 'show', 'figure', 'title', 'indicate', 'metric', 'yaxis', 'absolute', 'value', 'change', 'supplementary', 'detailed', 'result', 'dataset', 'figure', 'figure', 'lunar', 'lander', 'figure', 'figure', 'bipedal', 'walker', 'figure', 'figure', 'ant', 'observation', 'conclude', 'follow', 'observation', 'base', 'result', 'orlauditor', 'able', 'resist', 'potential', 'action', 'distortion', 'suspect', 'model', 'especially', 'cosine', 'metric', 'figure', 'tpr', 'tnr', 'vary', 'slightly', 'setting', 'weak', 'noise', 'maximum', 'accuracy', 'attenuation', 'cosine', 'distance', 'speculate', 'cosine', 'distance', 'noise', 'suppression', 'ability', 'calculate', 'inner', 'product', 'series', 'cumulative', 'reward', 'also', 'weak', 'noise', 'facilitate', 'dataset', 'auditing', 'move', 'negative', 'sample', 'far', 'away', 'positive', 'set', 'orlauditor', 'single', 'distance', 'metric', 'face', 'limitation', 'heavy', 'distortion', 'tpr', 'orlauditor', 'suffer', 'obvious', 'decline', 'strong', 'noise', 'strong', 'distortion', 'thoroughly', 'change', 'distribution', 'model', 'action', 'cumulative', 'reward', 'suspect', 'model', 'train', 'target', 'dataset', 'different', 'auditor', 'shadow', 'model', 'case', 'auditor', 'identify', 'positive', 'model', 'negative', 'single', 'kind', 'distance', 'metric', 'figure', 'cosine', 'distance', 'good', 'discriminate', 'positive', 'model', 'result', 'diagonal', 'distance', 'proper', 'negative', 'model', 'result', 'nondiagonal', 'thus', 'strong', 'distortion', 'combination', 'multiple', 'distance', 'metric', 'enhance', 'auditing', 'robustness', 'orlauditor', 'addition', 'note', 'model', 'normal', 'behavior', 'also', 'destroy', 'strong', 'distortion', 'example', 'table', 'noise', 'induce', 'model', 'performance', 'iql', 'decrease', 'well', 'model', 'quality', 'pronounced', 'performance', 'drop', 'vii', 'relate', 'work', 'membership', 'dataset', 'inference', 'infer', 'individual', 'data', 'record', 'use', 'train', 'target', 'model', 'shokri', 'propose', 'first', 'practical', 'membership', 'inference', 'strategy', 'train', 'number', 'shadow', 'classifier', 'distinguish', 'target', 'model', 'output', 'member', 'non', 'member', 'training', 'dataset', 'researcher', 'investigate', 'membership', 'inference', 'various', 'system', 'machine', 'unlearn', 'facial', 'recognition', 'system', 'neural', 'architecture', 'search', 'present', 'firstofitskind', 'holistic', 'risk', 'assessment', 'different', 'inference', 'attack', 'machine', 'learning', 'model', 'maini', 'introduce', 'definition', 'dataset', 'inference', 'design', 'first', 'mechanism', 'identify', 'suspect', 'model', 'copy', 'private', 'knowledge', 'dataset', 'compare', 'exist', 'work', 'orlauditor', 'welldesigne', 'solution', 'build', 'offline', 'drl', 'scene', 'overcome', 'several', 'new', 'challenge', 'first', 'orlauditor', 'postevent', 'mechanism', 'directly', 'apply', 'exist', 'opensource', 'dataset', 'second', 'orlauditor', 'use', 'auxiliary', 'dataset', 'knowledge', 'extraction', 'drl', 'drl', 'model', 'learn', 'interaction', 'environment', 'valuable', 'information', 'case', 'eg', 'indoor', 'robot', 'demonstrate', 'knowledge', 'extraction', 'vulnerability', 'drl', 'various', 'setting', 'propose', 'algorithm', 'infer', 'floor', 'plan', 'train', 'grid', 'world', 'navigation', 'model', 'lidar', 'perception', 'exact', 'model', 'propose', 'first', 'method', 'acquire', 'approximation', 'model', 'victim', 'build', 'classifier', 'reveal', 'targeted', 'black', 'box', 'model', 'train', 'base', 'predict', 'action', 'leverage', 'stateoftheart', 'imitation', 'learn', 'technique', 'replicate', 'model', 'identi', 'integrate', 'differential', 'privacy', 'distribute', 'defend', 'extraction', 'local', 'model', 'report', 'noisy', 'gradient', 'design', 'satisfy', 'local', 'differential', 'privacy', 'keep', 'local', 'information', 'exploit', 'adversarial', 'reverse', 'engineering', 'propose', 'novel', 'testing', 'framework', 'deep', 'learn', 'copyright', 'protection', 'adjust', 'detect', 'knowledge', 'extraction', 'drl', 'viii', 'disscusion', 'highlight', 'orlauditor', 'orlauditor', 'first', 'approach', 'conduct', 'trajectorylevel', 'dataset', 'auditing', 'offline', 'drl', 'model', 'conduct', 'comprehensive', 'analysis', 'orlauditor', 'different', 'experimental', 'setting', 'shadow', 'model', 'amount', 'significance', 'level', 'pothesis', 'test', 'trajectory', 'size', 'robustness', 'ensemble', 'architecture', 'action', 'distortion', 'conclude', 'useful', 'observation', 'adopt', 'orlauditor', 'apply', 'orlauditor', 'audit', 'model', 'train', 'opensource', 'dataset', 'deepmind', 'tpr', 'tnr', 'result', 'superior', 'demonstrating', 'orlauditor', 'effective', 'efficient', 'strategy', 'publish', 'dataset', 'limitation', 'future', 'work', 'discuss', 'limitation', 'orlauditor', 'promise', 'direction', 'improvement', 'accuracy', 'orlauditor', 'decrease', 'significance', 'level', 'thus', 'interesting', 'enhance', 'orlauditor', 'satisfy', 'strict', 'auditing', 'demand', 'future', 'auditor', 'base', 'single', 'distance', 'metric', 'suffi', 'ciently', 'robust', 'strong', 'distortion', 'base', 'observation', 'section', 'integrate', 'distance', 'metric', 'audit', 'process', 'far', 'promising', 'direction', 'conclusion', 'work', 'propose', 'novel', 'trajectorylevel', 'dataset', 'auditing', 'method', 'offline', 'drl', 'model', 'rely', 'insight', 'cumulative', 'reward', 'serve', 'dataset', 'intrinsic', 'fingerprint', 'exist', 'model', 'train', 'target', 'dataset', 'true', 'positive', 'rate', 'true', 'negative', 'rate', 'orlauditor', 'exceed', 'offline', 'drl', 'model', 'task', 'combination', 'show', 'orlauditor', 'effective', 'efficient', 'solution', 'protect', 'ip', 'dataset', 'owner', 'multiple', 'experiment', 'study', 'parameter', 'setting', 'number', 'shadow', 'model', 'significance', 'level', 'hypothesis', 'testing', 'trajectory', 'size', 'conclude', 'several', 'important', 'observation', 'adopt', 'orlauditor', 'practice', 'robustness', 'evaluation', 'demonstrate', 'auditor', 'resist', 'defense', 'model', 'ensemble', 'action', 'distortion', 'suspect', 'model', 'integrate', 'multiple', 'distance', 'metric', 'improve', 'robustness', 'auditor', 'action', 'distortion', 'promising', 'direction', 'future', 'work', 'finally', 'utilize', 'opensource', 'dataset', 'deepmind', 'examine', 'practicality', 'orlauditor', 'show', 'orlauditor', 'behave', 'excellently', 'exist', 'publish', 'dataset', 'acknowledgment', 'like', 'thank', 'anonymous', 'reviewer', 'constructive', 'comment', 'also', 'thank', 'share', 'expertise', 'reinforcement', 'learning', 'work', 'partly', 'support', 'national', 'key', 'research', 'develop', 'ment', 'program', 'nsfc', 'grant', 'fundamental', 'research', 'fund', 'central', 'univer', 'sitie', 'partly', 'sponsor', 'project', 'trustworthy', 'federate', 'data', 'analytic', 'zti', 'oo1', 'support', 'center', 'cybersecurity', 'reference', 'agarwal', 'brevdo', 'ghemawat', 'goodfellow', 'harp', 'jozefowicz', 'man´e', 'r', 'moore', 'shlen', 'sutskever', 'tucker', 'vanhoucke', 'vinyal', 'tensorflow', 'largescale', 'learning', 'heterogeneous', 'system', 'https', 'wwwtensorfloworg', 'alhinai', 'introduction', 'biomedical', 'signal', 'processing', 'artificial', 'intelligence', 'biomedical', 'signal', 'processing', 'artificial', 'intelligence', 'healthcare', 'development', 'biomedical', 'engineering', 'bioelec', 'tronic', 'page', '1–28', 'elsevi', 'deep', 'reinforcement', 'learning', 'robotic', 'manipulation', 'state', 'art', 'c', 'leibo', 'teplyashin', 'ward', 'k¨uttler', 'lefrancq', 'green', 'sadik', 'cain', 'bolton', 'h', 'king', 'legg', 'petersen', 'deepmind', 'lab', 'employee', 'departure', 'create', 'gape', 'security', 'hole', 'https', 'holesaysnewdata', 'systematic', 'review', 'model', 'watermarking', 'neural', 'network', 'frontier', 'big', 'datum', 'pettersson', 'schneider', 'schulman', 'song', 'copy', 'right', 'testing', 'framework', 'copyright', 'protection', 'deep', 'learning', 'model', 'ieee', 'p', 'page', 'steal', 'deep', 'reinforcement', 'learning', 'model', 'fun', 'profit', 'conference', 'computer', 'communication', 'security', 'asiaccs', 'page', 'ilahi', 'niyato', 'challenge', 'countermeasure', 'adversarial', 'attack', 'deep', 'reinforcement', 'learning', 'eshete', 'miashield', 'defend', 'membership', 'inference', 'attack', 'preemptive', 'exclusion', 'member', 'privacy', 'enhance', 'technology', 'symposium', 'page', 'r', 'kidambi', 'rajeswaran', 'morel', 'modelbase', 'offline', 'reinforcement', 'learning', 'neurip', 'p', 'well', 'autoencode', 'variational', 'baye', 'backe', 'iclr', 'machine', 'unlearn', 'jeopardize', 'privacy', 'backe', 'graph', 'unlearn', 'backe', 'face', 'auditor', 'datum', 'auditing', 'facial', 'recognition', 'system', 'usenix', 'security', 'l', 'auditor', 'dataset', 'auditing', 'offline', 'deep', 'reinforcement', 'learning', 'network', 'distribute', 'system', 'security', 'symposium', 'internet', 'society', 'l', 'du', 'bai', 'ahead', 'adaptive', 'hierarchical', 'decomposition', 'range', 'query', 'local', 'differential', 'privacy', 'ldptrace', 'locally', 'differentially', 'private', 'trajectory', 'synthesis', 'vldb', 'dziedzic', 'kaleem', 'papernot', 'dataset', 'inference', 'selfsupervise', 'model', 'corr', 'abs220909024', 'r', 'fayjie', 'hossain', 'oualid', 'driverless', 'car', 'autonomous', 'driving', 'use', 'deep', 'reinforcement', 'learning', 'urban', 'environment', 'international', 'conference', 'ubiquitous', 'robot', 'page', 'nachum', 'tucker', 'levine', 'dataset', 'deep', 'datadriven', 'reinforcement', 'learning', 'abs200407219', 'fujimoto', 'ghavamzadeh', 'bench', 'mark', 'batch', 'deep', 'reinforcement', 'learning', 'algorithm', 'fujimoto', 'gu', 'minimalist', 'approach', 'offline', 'rein', 'forcement', 'learning', 'neurip', 'page', '20132–20145', 'fujimoto', 'meger', 'precup', 'offpolicy', 'deep', 'reinforcement', 'learning', 'exploration', 'icml', 'page', 'fujimoto', 'h', 'hoof', 'address', 'function', 'approximation', 'error', 'actorcritic', 'method', 'icml', 'page', 'amin', 'h', 'aboutalebi', 'wong', 'precup', 'learn', 'surprising', 'effectiveness', 'bership', 'inference', 'attack', 'temporally', 'correlate', 'datum', 'deep', 'reinforcement', 'learning', 'main', 'amin', 'precup', 'privattack', 'membership', 'inference', 'attack', 'framework', 'deep', 'reinforcement', 'learn', 'agent', 'e', 'sample', 'criterion', 'test', 'outlying', 'observation', 'annal', 'mathematical', 'statistic', 'page', 'g¨ulc¸ehre', 'z', 'novikov', 'paine', 'g', 'r', 'agarwal', 'merel', 'c', 'paduraru', 'dulacarnold', 'freitas', 'unplug', 'collection', 'benchmark', 'offline', 'reinforcement', 'learning', 'neurip', 'g¨urtler', 'blaes', 'kolev', 'widmai', 'martius', 'benchmarking', 'offline', 'reinforcement', 'learning', 'realrobot', 'hardware', 'iclr', 'collaborative', 'sensing', 'internet', 'thing', 'comprehensive', 'survey', 'ieee', 'communication', 'survey', 'tutorial', 'h', 'back', 'privacy', 'risk', 'cellbase', 'architecture', 'j', 'susmit', 'trojdrl', 'evaluation', 'backdoor', 'attack', 'deep', 'reinforcement', 'learning', 'kostrikov', 'nair', 'levine', 'offline', 'reinforcement', 'learning', 'implicit', 'qlearning', 'iclr', 'lange', 'riedmiller', 'batch', 'reinforcement', 'reinforcement', 'learning', 'volume', 'adaptation', 'learn', 'learning', 'optimization', 'page', 'springer', 'levine', 'tucker', 'offline', 'reinforcement', 'learning', 'tutorial', 'review', 'perspective', 'open', 'problem', 'bai', 'untargete', 'backdoor', 'watermark', 'harmless', 'stealthy', 'dataset', 'copyright', 'protec', 'tion', 'opensource', 'dataset', 'protection', 'backdoor', 'watermarking', 'corr', 'abs201005821', 'gehre', 'khalidov', 'synnaeve', 'stardata', 'starcraft', 'ai', 'research', 'corr', 'salem', 'backe', 'e', 'cristofaro', 'fritz', 'mldoctor', 'holistic', 'risk', 'assessment', 'usenix', 'inference', 'attack', 'machine', 'learning', 'model', 'security', 'b', 'sanchezesguevillas', 'application', 'deep', 'reinforcement', 'learning', 'intrusion', 'detection', 'supervised', 'problem', 'expert', 'system', 'application', 'p', 'maini', 'yaghini', 'papernot', 'dataset', 'inference', 'ownership', 'resolution', 'machine', 'learn', 'iclr', 'mwiti', 'reallife', 'application', 'reinforcement', 'learning', 'https', 'locally', 'private', 'distribute', 'reinforcement', 'learning', 'l', 'paine', 'c', 'paduraru', 'novikov', 'z', 'freitas', 'hyperparameter', 'selection', 'offline', 'reinforcement', 'learning', 'abs200709055', 'song', 'act', 'tell', 'lot', 'privacyleake', 'attack', 'deep', 'reinforcement', 'learning', 'page', 'pattanaik', 'bommannan', 'chowdhary', 'robust', 'deep', 'reinforcement', 'learning', 'adversarial', 'attack', 'page', 'pomerleau', 'autonomous', 'land', 'vehicle', 'neural', 'network', 'neurip', 'page', 'r', 'r', 'm´aximo', 'l', 'colombini', 'survey', 'offline', 'reinforcement', 'learning', 'taxonomy', 'review', 'open', 'problem', 'abs220301387', 'h', 'l', 'security', 'industrial', 'robot', 'vulnerability', 'attack', 'mitigation', 'ieee', 'network', 'r', 'qin', 'gao', 'near', 'realworld', 'benchmark', 'offline', 'reinforcement', 'learning', 'abs210200714', 'raffin', 'hill', 'gleave', 'kanervisto', 'ernestus', 'reliable', 'reinforcement', 'learning', 'implementation', 'journal', 'machine', 'learn', 'research', 'rubner', 'tomasi', 'metric', 'distribution', 'application', 'image', 'database', 'iccv', 'page', 'rupprecht', 'survey', 'deep', 'reinforcement', 'learning', 'markovian', 'cyberphysical', 'system', 'common', 'problem', 'solution', 'neural', 'network', 'seno', 'imai', 'd3rlpy', 'offline', 'deep', 'reinforcement', 'learning', 'library', 'journal', 'machine', 'learn', 'research', 'r', 'shokri', 'song', 'shmatikov', 'membership', 'inference', 'attack', 'machine', 'learning', 'model', 'ieee', 'p', 'page', 'silver', 'lever', 'wierstra', 'riedmiller', 'deterministic', 'policy', 'gradient', 'algorithm', 'icml', 'page', 'stephen', 'statistic', 'goodness', 'fit', 'compar', 'ison', 'journal', 'american', 'statistical', 'association', 'l', 'song', 'p', 'mittal', 'mitigate', 'membership', 'inference', 'attack', 'selfdistillation', 'novel', 'ensemble', 'architecture', 'usenix', 'security', 'page', 'tessian', 'great', 'resignation', 'create', 'security', 'chal', 'lenge', 'https', 'tingmoresecuritychallenge', 'der', 'maaten', 'visualize', 'datum', 'use', 'tsne', 'journal', 'machine', 'learn', 'research', 'h', 'back', 'privtrace', 'differentially', 'private', 'trajectory', 'synthesis', 'adaptive', 'markov', 'model', 'usenix', 'security', 'l', 'song', 'doorl', 'attack', 'competitive', 'reinforcement', 'learn', 'ijcai', 'page', 'jha', 'continuous', 'release', 'datum', 'stream', 'centralized', 'local', 'differential', 'privacy', 'maniatakos', 'stop', 'andgo', 'explore', 'backdoor', 'attack', 'deep', 'reinforcement', 'learning', 'base', 'traffic', 'congestion', 'control', 'system', 'ieee', 'tif', 'l', 'detect', 'plc', 'intrusion', 'use', 'control', 'invariant', 'ieee', 'r', 'rafailov', 'levine', 'combo', 'conservative', 'offline', 'modelbase', 'policy', 'optimization', 'neurip', 'page', 'yuan', 'privgraph', 'differentially', 'private', 'graph', 'datum', 'publication', 'exploit', 'community', 'information', 'usenix', 'security', 'wan', 'r', 'deng', 'constrain', 'vulnerability', 'assessment', 'deep', 'reinforcement', 'learning', 'base', 'scopf', 'ieee', 'tps', 'calm', 'consistent', 'adaptive', 'local', 'marginal', 'marginal', 'release', 'local', 'differential', 'privacy', 'backe', 'differentially', 'private', 'datum', 'synthesis', 'usenix', 'security', 'behavior', 'similarity', 'model', 'figure', 'provide', 'behavior', 'similarity', 'offline', 'rl', 'model', 'train', 'dataset', 'table', 'take', 'bipedal', 'walker', 'task', 'example', 'dataset', 'regard', 'target', 'dataset', 'public', 'dataset', 'observe', 'behavior', 'similarity', 'rl', 'model', 'wave', 'heavily', 'different', 'public', 'training', 'datum', 'auditor', 'adopt', 'dataset', 'public', 'training', 'datum', 'auditor', 'likely', 'misclassifie', 'rl', 'model', 'train', 'public', 'dataset', 'bootleg', 'model', 'addition', 'behavior', 'similarity', 'also', 'affect', 'different', 'offline', 'rl', 'framework', 'iql', 'detailed', 'section', 'detail', 'task', 'lunar', 'lander', 'continuous', 'version', 'lunarlander', 'task', 'smoothly', 'land', 'spaceship', 'flag', 'target', 'pad', 'landing', 'pad', 'always', 'coordinate', 'ship', 'throttle', 'throttle', 'point', 'downward', 'main', 'engine', 'point', 'left', 'right', 'direction', 'left', 'right', 'engine', 'observation', '8dimensional', 'vector', 'coordinate', 'lander', 'x', 'axis', 'yaxis', 'linear', 'velocity', 'yaxis', 'angle', 'angular', 'velocity', 'boolean', 'represent', 'leg', 'contact', 'ground', 'action', 'real', 'value', 'range', '−1', 'first', 'dimension', 'control', 'main', 'engine', 'engine', 'value', '−1', 'increase', 'throttle', 'value', 'rise', 'point', 'control', 'second', 'value', 'spaceship', 'fire', 'left', 'engine', 'value', '−10', 'fire', 'right', 'engine', 'value', 'shut', 'engine', 'value', 'reward', 'move', 'top', 'screen', 'landing', 'pad', 'speed', 'point', 'landing', 'landing', 'pad', 'possible', 'thus', 'player', 'lose', 'terminal', 'reward', 'lander', 'move', 'away', 'landing', 'pad', 'player', 'get', 'additional', 'point', 'leg', 'touch', 'ground', 'fire', 'main', 'engine', 'point', 'frame', 'episode', 'finish', 'lander', 'crash', 'land', 'smoothly', 'receive', 'point', 'bipedal', 'walker', 'bipedal', 'walker', 'task', 'operate', 'walker', 'robot', 'move', 'forward', 'fast', 'possible', 'robot', 'make', 'hull', 'leg', 'leg', 'joint', 'hip', 'knee', 'observation', 'task', 'include', 'continuous', 'physical', 'variable', 'angle', 'speed', 'angular', 'velocity', 'horizontal', 'speed', 'vertical', 'speed', 'position', 'joint', 'joint', 'angular', 'speed', 'leg', 'contact', 'ground', 'lidar', 'rangefinder', 'measurement', 'action', 'motor', 'speed', 'value', 'range', 'joint', 'hip', 'knee', 'walker', 'start', 'stand', 'left', 'end', 'terrain', 'hull', 'horizontal', 'leg', 'position', 'slight', 'knee', 'angle', 'reward', 'give', 'move', 'forward', 'total', 'point', 'far', 'end', 'robot', 'fall', 'get', 'apply', 'motor', 'torque', 'cost', 'small', 'amount', 'point', 'optimal', 'model', 'get', 'well', 'score', 'episode', 'terminate', 'hull', 'get', 'contact', 'ground', 'walker', 'exceed', 'right', 'end', 'terrain', 'length', 'ant', 'task', 'player', 'manipulate', '3d', 'robot', 'ant', 'consist', 'torso', 'free', 'rotational', 'body', 'leg', 'attach', 'leg', 'link', 'move', 'forward', 'right', 'direction', 'observation', 'contain', 'positional', 'value', 'different', 'body', 'part', 'ant', 'follow', 'velocity', 'individual', 'part', 'derivative', 'position', 'order', 'velocity', 'default', 'observation', 'vector', 'shape', 'element', 'correspond', 'follow', 'position', 'angle', 'dim', 'velocity', '14dim', 'information', 'contact', 'force', '84dim', 'player', 'apply', 'torque', 'hinge', 'connect', 'link', 'leg', 'fig', 'model', 'behavior', 'similarity', 'measure', 'ℓ1', 'norm', 'norm', 'cosine', 'distance', 'distance', 'table', 'use', 'first', 'dataset', 'task', 'private', 'training', 'datum', 'remain', 'dataset', 'public', 'training', 'datum', 'plot', 'xaxis', 'display', 'public', 'training', 'datum', 'yaxis', 'show', 'absolute', 'fluctuating', 'value', 'behavior', 'similarity', 'model', 'train', 'private', 'dataset', 'public', 'dataset', 'iql', 'abbreviation', 'different', 'offline', 'rl', 'framework', 'part', 'hinge', 'thus', 'action', 'space', 'continuous', 'vector', 'represent', 'torque', 'apply', 'hinge', 'joint', 'reward', 'ant', 'task', 'consist', 'part', 'healthy', 'reward', 'forward', 'reward', 'control', 'cost', 'contact', 'cost', 'total', 'reward', 'return', 'reward', 'healthy', 'reward', 'forward', 'reward', 'control', 'cost', 'contact', 'cost', 'task', 'end', 'ant', 'state', 'unhealthy', 'episode', 'duration', 'reach', 'timestep', 'c', 'impact', 'shadow', 'model', 'amount', 'investigate', 'relationship', 'number', 'shadow', 'model', 'audit', 'accuracy', 'setup', 'change', 'shadow', 'model', 'amount', 'setting', 'section', 'figure', 'show', 'value', 'change', 'tpr', 'tnr', 'compare', 'shadow', 'model', 'figure', 'title', 'illustrate', 'setting', 'model', 'task', 'indicate', 'metric', 'yaxis', 'absolute', 'value', 'change', 'also', 'provide', 'detailed', 'result', 'table', 'viii', 'shadow', 'model', 'table', 'shadow', 'model', 'observation', 'figure', 'follow', 'obser', 'vation', 'audit', 'accuracy', 'increase', 'large', 'amount', 'shadow', 'model', 'value', 'shadow', 'model', 'multisampling', 'true', 'value', 'q', 'dataset', 'mean', 'standard', 'deviation', 'precise', 'shadow', 'model', 'example', 'orlauditor', 'suffer', 'obvious', 'tpr', 'decline', 'shadow', 'model', 'insufficient', 'knowledge', 'diversity', 'model', 'train', 'target', 'dataset', 'auditor', 'easily', 'misclassifie', 'positive', 'model', 'negative', 'group', 'exist', 'saturation', 'point', 'audit', 'accuracy', 'expansion', 'shadow', 'model', 'shadow', 'model', 'amount', 'rise', 'tpr', 'usually', 'increase', 'auditor', 'observe', 'possible', 'cumulative', 'reward', 'originate', 'model', 'train', 'target', 'dataset', 'note', 'value', 'change', 'slightly', 'plot', 'mean', 'similar', 'cumulative', 'reward', 'appear', 'shadow', 'model', 'set', 'diversity', 'increase', 'significantly', 'compare', 'shadow', 'model', 'therefore', 'excessive', 'shadow', 'model', 'unnecessary', 'auditor', 'need', 'burden', 'training', 'overhead', 'impact', 'significance', 'level', 'significance', 'level', 'represent', 'auditor', 'confidence', 'audit', 'result', 'section', 'adopt', 'significance', 'level', 'meaning', 'auditor', 'confidence', 'judgment', 'generally', 'speak', 'significance', 'level', 'represent', 'maximum', 'audit', 'capacity', 'orlauditor', 'instead', 'hyperparameter', 'setting', 'audit', 'quirement', 'dataset', 'owner', 'setup', 'demand', 'auditor', 'output', 'confident', 'judgment', 'error', 'possibility', 'limit', 'figure', 'show', 'value', 'change', 'tpr', 'tnr', 'compare', 'significance', 'level', 'used', 'offline', 'drl', 'model', 'task', 'show', 'figure', 'title', 'indicate', 'metric', 'yaxis', 'absolute', 'value', 'change', 'l', 'u', 'l', 'e', 'u', 'v', 'l', 'e', 'u', 'v', 'u', 'v', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'cosine', 'distance', 'bipedal', 'walker', 'norm', 'ant', 'norm', 'half', 'medium', 'random', 'dataset', 'name', 'rluply', 'bipedal', 'walker', 'norm', 'ant', 'norm', 'half', 'norm', 'medium', 'random', 'dataset', 'name', 'bipedal', 'walker', 'cosine', 'distance', 'ant', 'cosine', 'distance', 'half', 'cosine', 'distance', 'medium', 'random', 'dataset', 'name', 'rluply', 'lunar', 'lander', 'distance', 'bipedal', 'wasserstein', 'distance', 'ant', 'distance', 'half', 'distance', 'medium', 'random', 'dataset', 'name', 'rluply', 'notice', 'small', 'trajectory', 'size', 'achieve', 'well', 'result', 'task', 'ant', 'task', 'auditor', 'auditing', 'full', 'length', 'obtain', 'promotion', 'tnr', 'result', 'base', 'analysis', 'front', 'state', 'trajectory', 'able', 'reflect', 'behavioral', 'information', 'model', 'thus', 'case', 'short', 'trajectory', 'truncate', 'rear', 'stateaction', 'pair', 'unimportant', 'even', 'weaken', 'significance', 'hypothesis', 'testing', 'explore', 'effective', 'datum', 'auditing', 'short', 'trajectory', 'size', 'even', 'use', 'first', 'state', 'trajectory', 'interesting', 'future', 'direction', 'additional', 'result', 'supplementary', 'provide', 'additional', 'result', 'orlauditor', 'ease', 'read', 'summarize', 'main', 'figure', 'table', 'table', 'detailed', 'result', 'dataset', 'table', 'table', 'observation', 'figure', 'follow', 'obser', 'vation', 'complicated', 'task', 'recommend', 'auditor', 'select', 'large', 'significance', 'level', 'orlauditor', 'task', 'complexity', 'affect', 'minimum', 'significance', 'level', 'orlauditor', 'example', 'tpr', 'tnp', 'change', 'little', 'lunar', 'lander', 'task', 'significance', 'level', 'reduce', 'highly', 'shrink', 'ant', 'task', 'table', 'ant', 'state', 'action', 'space', 'large', 'lunar', 'lander', 'auditor', 'leverage', 'critic', 'model', 'compress', 'model', 'state', 'action', 'pair', 'scalar', 'deviation', 'recall', 'figure', 'ant', 'task', 'imperceptible', 'j', 'qs', 'suspect', 'model', 'low', 'performance', 'auditor', 'adopt', 'large', 'significance', 'level', 'guarantee', 'audit', 'accuracy', 'instance', 'figure', 'title', 'bipedal', 'walker', 'tnr', 'result', 'distance', 'metric', 'decrease', 'reduce', 'table', 'model', 'performance', 'bipedal', 'walker', 'task', 'around', 'mean', 'td3plusbc', 'model', 'fully', 'master', 'knowledge', 'dataset', 'thus', 'dataset', 'feature', 'reflect', 'behavior', 'ambiguous', 'weaken', 'difference', 'positive', 'negative', 'sample', 'meanwhile', 'confidence', 'interval', 'figure', 'expand', 'low', 'significance', 'level', 'reason', 'tnr', 'result', 'td3plusbc', 'model', 'bipedal', 'walker', 'task', 'drop', 'compare', 'analysis', 'safe', 'bind', 'orlauditor', 'low', 'break', 'capability', 'boundary', 'orlauditor', 'induce', 'auditor', 'misclassify', 'negative', 'model', 'positive', 'set', 'e', 'impact', 'trajectory', 'size', 'investigate', 'relationship', 'trajectory', 'size', 'audit', 'accuracy', 'section', 'adopt', 'fulllength', 'trajectory', 'mean', 'auditor', 'utilize', 'state', 'trajectory', 'query', 'suspect', 'model', 'obtain', 'corre', 'sponde', 'action', 'conduct', 'dataset', 'audit', 'setup', 'change', 'trajectory', 'size', 'full', 'length', 'setting', 'section', 'figure', 'show', 'value', 'change', 'tpr', 'tnr', 'compare', 'fulllength', 'trajectory', 'figure', 'title', 'illus', 'trate', 'setting', 'model', 'task', 'indicate', 'metric', 'yaxis', 'absolute', 'value', 'change', 'also', 'provide', 'detailed', 'result', 'table', 'table', 'xiii', 'observation', 'figure', 'follow', 'observa', 'tion', 'orlauditor', 'tend', 'achieve', 'high', 'accuracy', 'large', 'trajectory', 'size', 'predict', 'cumulative', 'reward', 'stateaction', 'pair', 'critic', 'model', 'audit', 'basis', 'long', 'trajectory', 'collect', 'action', 'suspect', 'model', 'enhance', 'significance', 'hypothesis', 'testing', 'example', 'tnp', 'result', 'decrease', 'orlauditor', 'leverage', 'trajectory', 'table', 'vi', 'roadmap', 'main', 'figure', 'table', 'information', 'overview', 'task', 'online', 'drl', 'model', 'involve', 'content', 'section', 'name', 'table', 'table', 'table', 'model', 'section', 'overall', 'audit', 'performance', 'section', 'vb', 'impact', 'shadow', 'model', 'amount', 'c', 'impact', 'significance', 'level', 'impact', 'trajectory', 'size', 'realworld', 'application', 'section', 'robustness', 'ensemble', 'architecture', 'section', 'robustness', 'perturb', 'model', 'output', 'section', 'table', 'table', 'table', 'table', 'table', 'table', 'figure', 'figure', 'figure', 'figure', 'table', 'viii', 'table', 'figure', 'table', 'table', 'figure', 'table', 'table', 'table', 'table', 'table', 'figure', 'figure', 'figure', 'figure', 'figure', 'figure', 'figure', 'figure', 'figure', 'figure', 'description', 'state', 'shape', 'action', 'shape', 'task', 'performance', 'used', 'online', 'model', 'collect', 'offline', 'dataset', 'name', 'number', 'trajectory', 'length', 'trajectory', 'offline', 'dataset', 'offline', 'model', 'performance', 'defense', 'auditor', 'normal', 'performance', 'defense', 'defend', 'model', 'ensemble', 'defend', 'perturb', 'model', 'output', 'true', 'positive', 'rate', 'tpr', 'true', 'negative', 'rate', 'tnr', 'result', 'base', 'grubb', 'test', 'principle', 'change', 'value', 'tpr', 'tnr', 'number', 'shadow', 'model', 'vary', 'compare', 'default', 'shadow', 'model', 'change', 'value', 'tpr', 'tnr', 'significance', 'level', 'vary', 'compare', 'default', 'change', 'value', 'tpr', 'tnr', 'trajectory', 'size', 'vary', 'compare', 'default', 'full', 'length', 'tpr', 'tnr', 'result', 'half', 'cheetah', 'dataset', 'publish', 'deepmind', 'separately', 'tpr', 'tnr', 'result', 'orlauditor', 'model', 'ensemble', 'k', 'tpr', 'tnr', 'result', 'orlauditor', 'model', 'action', 'distortion', 'table', 'supplementary', 'provide', 'tpr', 'tnr', 'result', 'orlauditor', 'base', 'principle', 'mean', 'standard', 'deviation', 'tpr', 'tnr', 'row', 'represent', 'audit', 'result', 'combination', 'task', 'model', 'distance', 'metric', 'indicate', 'high', 'sum', 'tpr', 'tnr', 'accuracy', 'row', 'task', 'offline', 'model', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', 'tpr', '9653±136', '9613±301', '9720±324', '9560±439', '9656±427', '9667±420', '9433±745', '9700±446', '9067±530', '9067±693', '9562±519', 'tnr', 'tpr', '9547±281', '9480±318', '9627±244', '9280±507', '9578±458', '9478±743', '9411±863', '9333±462', '9413±383', '8960±399', '9412±503', 'tpr', '9573±258', '9653±240', '9889±217', '9720±389', '9908±154', 'tpr', '9653±414', '9667±288', '9995±049', 'fig', 'audit', 'accuracy', 'lunar', 'lander', 'dataset', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'fig', 'audit', 'accuracy', 'bipedal', 'walker', 'dataset', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'cosine', 'distance', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'cosine', 'distance', 'lunar', 'lander', 'distance', 'lunar', 'lander', 'distance', 'lunar', 'lander', 'iql', 'norm', 'lunar', 'lander', 'iql', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'iql', 'cosine', 'distance', 'lunar', 'lander', 'cosine', 'distance', 'lunar', 'lander', 'iql', 'wasserstein', 'distance', 'lunar', 'lander', 'distance', 'bipedal', 'norm', 'norm', 'cosine', 'distance', 'distance', 'bipedal', 'walker', 'norm', 'walker', 'norm', 'walker', 'cosine', 'distance', 'distance', 'iql', 'norm', 'iql', 'norm', 'iql', 'cosine', 'distance', 'iql', 'distance', 'bipedal', 'walker', 'norm', 'bipedal', 'walker', 'norm', 'bipedal', 'walker', 'cosine', 'distance', 'distance', 'fig', 'audit', 'accuracy', 'ant', 'dataset', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'table', 'viii', 'impact', 'shadow', 'model', 'amount', 'tpr', 'tnr', 'result', 'orlauditor', 'shadow', 'model', 'task', 'lunar', '9265±346', '9705±106', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', '9978±050', 'tpr', '9377±364', '9547±337', '9000±547', '10000±000', '9995±017', '9770±359', '9730±495', '9891±099', '9802±101', '9912±043', '9935±075', '8588±2810', 'tpr', '9655±198', '9703±151', '9754±116', '9811±142', '9850±130', '9685±645', '9992±016', '9976±052', '9957±093', '9930±136', 'ant', 'norm', 'norm', 'ant', 'norm', 'ant', 'iql', 'norm', 'ant', 'norm', 'ant', 'norm', 'ant', 'iql', 'norm', 'cosine', 'distance', 'ant', 'cosine', 'distance', 'distance', 'ant', 'distance', 'ant', 'iql', 'cosine', 'distance', 'ant', 'iql', 'distance', 'ant', 'norm', 'ant', 'cosine', 'distance', 'ant', 'distance', 'table', 'impact', 'shadow', 'model', 'amount', 'tpr', 'tnr', 'result', 'orlauditor', 'shadow', 'model', 'task', 'lunar', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', '9996±017', 'tpr', '9813±188', '9840±068', '9636±457', '9987±027', '9827±103', '9986±041', '9968±063', 'tpr', '9800±184', '9685±340', '9578±429', '9769±451', '9907±165', '9951±026', '9982±036', '8682±2697', 'tpr', '9800±260', 'table', 'impact', 'significance', 'level', 'tpr', 'tnr', 'result', 'orlauditor', 'task', 'lunar', '9891±168', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', '9983±040', 'tpr', '9821±055', '9760±113', '9856±151', '9747±233', '9973±034', '9581±506', '9988±040', '9981±047', '9960±073', 'tpr', '9821±063', '9755±222', '9987±027', 'tpr', '9859±095', '9768±451', '9971±058', 'tnr', '9985±025', '9969±063', '9949±105', '9878±215', 'table', 'impact', 'significance', 'level', 'tpr', 'tnr', 'result', 'orlauditor', 'task', 'lunar', '9933±121', '9973±029', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', '9980±041', '9956±076', 'tpr', '9981±026', '9723±555', '9915±067', '9980±048', '9911±207', '9856±149', '9880±240', '9992±011', '9989±021', '9992±011', '10000±000', 'tpr', '9979±022', '9933±054', '9973±022', '9956±079', '9888±154', '9806±318', 'table', 'impact', 'trajectory', 'size', 'tpr', 'tnr', 'result', 'orlauditor', 'trajectory', 'size', 'task', 'lunar', '9800±242', '9680±537', '9811±140', '9845±100', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', '9953±130', '9985±034', '9976±043', 'tpr', '9627±200', '9672±257', '9643±313', '9704±124', '9692±160', '9964±109', '9978±046', '9985±040', 'tpr', '9861±271', '9922±118', 'tnr', 'tpr', '9810±092', '9856±110', '9936±090', '9861±245', '9701±545', '9896±081', '9928±107', 'table', 'impact', 'trajectory', 'size', 'tpr', 'tnr', 'result', 'orlauditor', 'trajectory', 'size', 'task', 'lunar', '9776±205', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', '9985±036', '9680±284', '9781±283', '9792±281', '9547±534', '9704±133', '9672±150', '9929±106', '9725±072', '9640±084', '9725±218', '9651±298', '9989±010', '9981±031', '9949±083', '9960±060', '9979±030', '9982±025', 'tpr', '9824±179', '9941±086', '9955±072', '8430±808', '9984±036', '9970±066', 'table', 'detail', 'online', 'model', 'generate', 'offline', 'dataset', 'model', 'performance', 'show', 'cumulative', 'reward', 'separate', 'evaluation', 'task', 'name', 'model', 'train', 'step', 'model', 'name', 'model', 'performance', 'lunar', 'lander', 'sac', 'bipedal', 'walker', 'ppo', 'sac', 'fig', 'audit', 'accuracy', 'model', 'ensemble', 'lunar', 'lander', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'hyperparameter', 'model', 'ensemble', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'table', 'detail', 'offline', 'dataset', 'task', 'name', 'number', 'transition', 'dataset', 'name', 'number', 'trajectory', 'length', 'trajectory', 'lunar', 'lander', 'bipedal', 'walker', 'ant', '22983±8351', '26613±9965', '98103±19079', '97307±11842', '112663±37905', '95546±17772', '90184±23693', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'k', 'lunar', 'lander', 'cosine', 'lunar', 'lander', 'k', 'lunar', 'lander', 'norm', 'k', 'lunar', 'lander', 'norm', 'k', 'lunar', 'lander', 'cosine', 'lunar', 'lander', 'iql', 'norm', 'k', 'lunar', 'lander', 'iql', 'norm', 'k', 'lunar', 'lander', 'iql', 'cosine', 'k', 'lunar', 'lander', 'norm', 'k', 'lunar', 'lander', 'norm', 'k', 'lunar', 'lander', 'cosine', 'lunar', 'lander', 'wasserstein', 'k', 'lunar', 'lander', 'wasserstein', 'k', 'lunar', 'lander', 'iql', 'wasserstein', 'k', 'fig', 'audit', 'accuracy', 'model', 'ensemble', 'bipedal', 'walker', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'hyperparameter', 'model', 'ensemble', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'table', 'xvi', 'supplementary', 'provide', 'detail', 'model', 'model', 'performance', 'show', 'cumulative', 'reward', 'separate', 'evaluation', 'offline', 'model', 'lunar', 'dataset', 'name', 'model', 'performance', 'defense', '28885±1539', 'model', 'performance', 'trajectory', 'splitting', '18334±4700', '152373±47318', 'model', 'performance', 'model', 'ensemble', '30801±087', 'model', 'performance', 'gauss', '27084±638', '28764±1636', '532499±44127', 'model', 'performance', 'gauss', '26883±2555', 'bipedal', 'walker', 'norm', 'bipedal', 'walker', 'norm', 'k', 'bipedal', 'walker', 'cosine', 'bipedal', 'walker', 'walker', 'norm', 'k', 'walker', 'norm', 'k', 'iql', 'norm', 'k', 'iql', 'norm', 'k', 'walker', 'cosine', 'k', 'iql', 'cosine', 'k', 'norm', 'k', 'bipedal', 'walker', 'norm', 'k', 'bipedal', 'cosine', 'bipedal', 'walker', 'wasserstein', 'k', 'bipedal', 'walker', 'iql', 'wasserstein', 'k', 'wasserstein', 'k', 'fig', 'audit', 'accuracy', 'model', 'ensemble', 'ant', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'hyperparameter', 'model', 'ensemble', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'table', 'xvii', 'supplementary', 'provide', 'detail', 'offline', 'model', 'model', 'performance', 'show', 'cumulative', 'reward', 'separate', 'evaluation', 'offline', 'model', 'lunar', 'dataset', 'name', 'model', 'performance', 'defense', 'model', 'performance', 'trajectory', 'splitting', 'model', 'performance', 'model', 'ensemble', '27843±957', '26416±9768', '30609±403', 'model', 'performance', 'gauss', 'model', 'performance', 'gauss', '341276±80453', 'ant', 'norm', 'k', 'ant', 'norm', 'k', 'ant', 'cosine', 'k', 'ant', 'k', 'ant', 'norm', 'k', 'ant', 'norm', 'k', 'ant', 'iql', 'norm', 'ant', 'iql', 'norm', 'k', 'ant', 'cosine', 'k', 'ant', 'wasserstein', 'k', 'ant', 'iql', 'cosine', 'ant', 'iql', 'wasserstein', 'k', 'ant', 'norm', 'k', 'ant', 'norm', 'k', 'ant', 'cosine', 'ant', 'wasserstein', 'k', 'fig', 'audit', 'accuracy', 'model', 'ensemble', 'half', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'hyperparameter', 'model', 'ensemble', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'table', 'supplementary', 'provide', 'detail', 'iql', 'offline', 'model', 'model', 'performance', 'show', 'cumulative', 'reward', 'separate', 'evaluation', 'offline', 'model', 'lunar', 'dataset', 'name', 'model', 'performance', 'defense', '5792±3114', '28463±1738', 'model', 'performance', 'trajectory', 'splitting', '27191±510', 'model', 'performance', 'model', 'ensemble', '496865±133785', '156386±122573', 'model', 'performance', 'gauss', '4996±2860', '28720±1929', '287916±26272', 'model', 'performance', 'gauss', '26438±3452', '123903±32898', 'half', 'norm', 'half', 'norm', 'k', 'half', 'cosine', 'half', 'k', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'half', 'norm', 'rluply', 'expert', 'medium', 'random', 'half', 'norm', 'k', 'rluply', 'expert', 'medium', 'random', 'half', 'cosine', 'k', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'iql', 'norm', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'iql', 'norm', 'k', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'iql', 'cosine', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'norm', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'norm', 'k', 'rluply', 'rluply', 'medium', 'random', 'expert', 'half', 'cosine', 'expert', 'rluply', 'medium', 'random', 'half', 'wasserstein', 'k', 'expert', 'rluply', 'medium', 'random', 'half', 'cheetah', 'iql', 'wasserstein', 'k', 'expert', 'medium', 'random', 'half', 'cheetah', 'wasserstein', 'k', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'fig', 'audit', 'accuracy', 'suspect', 'model', 'action', 'lunar', 'lander', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'noise', 'strength', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'table', 'supplementary', 'provide', 'detail', 'model', 'model', 'performance', 'show', 'cumulative', 'reward', 'separate', 'evaluation', 'offline', 'model', 'lunar', 'dataset', 'name', 'model', 'performance', 'defense', 'model', 'performance', 'trajectory', 'splitting', '24178±2168', '21671±11876', 'model', 'performance', 'model', 'ensemble', '7196±11126', '10840±022', '12618±236', 'model', 'performance', 'gauss', '20707±2813', 'model', 'performance', 'gauss', '19469±4259', 'table', 'detail', 'dataset', 'name', 'half', 'cheetah', 'number', 'transition', 'dataset', 'name', 'expert', 'medium', 'random', 'rl', 'unplugged', 'number', 'trajectory', 'length', 'trajectory', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'cosine', 'lunar', 'lander', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'cosine', 'lunar', 'lander', 'wasserstein', 'lunar', 'lander', 'iql', 'norm', 'lunar', 'lander', 'iql', 'norm', 'lunar', 'lander', 'iql', 'cosine', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'cosine', 'lunar', 'lander', 'iql', 'wasserstein', 'lunar', 'lander', 'fig', 'audit', 'accuracy', 'suspect', 'model', 'action', 'lunar', 'lander', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'noise', 'strength', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'table', 'supplementary', 'provide', 'detail', 'model', 'train', 'dataset', 'model', 'performance', 'show', 'cumulative', 'reward', 'separate', 'evaluation', 'task', 'offline', 'model', 'half', 'expert', 'medium', 'random', 'rl', 'unplugged', 'expert', 'medium', 'random', 'rl', 'unplugged', 'expert', 'medium', 'random', 'rl', 'unplugged', 'expert', 'medium', 'random', 'unplugged', 'model', 'performance', 'defense', '033±024', '1097419±84210', '1271269±38333', 'model', 'performance', 'trajectory', 'splitting', '033±022', '41959±21929', '1275225±27438', 'model', 'performance', 'model', 'ensemble', '1286822±18039', '429335±7567', '1233459±53999', '054±078', '1126802±264057', 'table', 'tpr', 'tnr', 'result', 'half', 'cheetah', 'task', 'mean', 'standard', 'deviation', 'tpr', 'tnr', 'row', 'represent', 'audit', 'result', 'combination', 'task', 'model', 'distance', 'metric', 'indicate', 'high', 'sum', 'tpr', 'tnr', 'accuracy', 'row', 'pair', 'tpr', 'tnr', 'derive', 'diagonal', 'nondiagonal', 'value', 'corresponding', 'heatmap', 'figure', 'task', 'name', 'half', 'model', 'tpr', 'iql', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', '9607±234', '9583±120', 'tpr', '9847±113', '9747±135', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'cosine', 'lunar', 'lander', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'cosine', 'lunar', 'lander', 'wasserstein', 'lunar', 'lander', 'iql', 'norm', 'lunar', 'lander', 'iql', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'norm', 'lunar', 'lander', 'iql', 'cosine', 'lunar', 'lander', 'cosine', 'lunar', 'lander', 'iql', 'wasserstein', 'lunar', 'lander', 'wasserstein', 'fig', 'audit', 'accuracy', 'suspect', 'model', 'action', 'bipedal', 'walker', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'noise', 'strength', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'table', 'tpr', 'tnr', 'result', 'orlauditor', 'split', 'trajectory', 'short', 'one', 'mean', 'standard', 'deviation', 'tpr', 'tnr', 'row', 'represent', 'audit', 'result', 'combination', 'task', 'model', 'distance', 'metric', 'pair', 'tpr', 'tnr', 'derive', 'diagonal', 'nondiagonal', 'value', 'corresponding', 'heatmap', 'figure', 'lunar', 'lander', 'figure', 'bipedal', 'walker', 'figure', 'ant', 'figure', 'half', 'cheetah', 'task', 'offline', 'model', 'half', 'norm', 'norm', 'cosine', 'distance', 'wasserstein', 'distance', '9955±071', '9871±163', '9850±150', '9683±154', '9700±200', '9753±130', 'tnr', '9993±012', '9845±271', '9819±284', '9589±232', '9677±250', '9720±179', '9687±214', '9627±136', '9625±113', '9653±120', '9990±036', '9984±041', '9587±106', '9749±256', '9627±316', '9864±266', '9968±045', '9981±031', '9965±063', '9963±062', '9981±031', '9974±027', '9993±012', '9956±020', '9956±061', '7263±4022', 'tpr', '9843±073', '9760±114', '9832±179', '9853±125', '9883±155', '9837±109', 'tnr', '9979±047', 'norm', 'norm', 'cosine', 'walker', 'norm', 'walker', 'norm', 'walker', 'cosine', 'bipedal', 'walker', 'wasserstein', 'iql', 'norm', 'iql', 'norm', 'iql', 'cosine', 'iql', 'bipedal', 'walker', 'norm', 'bipedal', 'walker', 'norm', 'bipedal', 'walker', 'cosine', 'fig', 'audit', 'accuracy', 'suspect', 'model', 'action', 'bipedal', 'walker', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'noise', 'strength', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'norm', 'bipedal', 'walker', 'norm', 'bipedal', 'walker', 'cosine', 'bipedal', 'walker', 'norm', 'walker', 'norm', 'walker', 'cosine', 'iql', 'norm', 'iql', 'norm', 'iql', 'cosine', 'bipedal', 'walker', 'norm', 'bipedal', 'walker', 'norm', 'bipedal', 'walker', 'cosine', 'walker', 'wasserstein', 'iql', 'wasserstein', 'wasserstein', 'fig', 'audit', 'accuracy', 'suspect', 'model', 'action', 'ant', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'noise', 'strength', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'ant', 'norm', 'ant', 'norm', 'ant', 'iql', 'norm', 'ant', 'norm', 'ant', 'norm', 'ant', 'iql', 'norm', 'ant', 'cosine', 'ant', 'cosine', 'ant', 'ant', 'wasserstein', 'ant', 'iql', 'cosine', 'ant', 'iql', 'wasserstein', 'ant', 'norm', 'ant', 'norm', 'ant', 'cosine', 'ant', 'fig', 'audit', 'accuracy', 'suspect', 'model', 'action', 'ant', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'noise', 'strength', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'norm', 'ant', 'norm', 'ant', 'iql', 'norm', 'ant', 'norm', 'ant', 'cosine', 'ant', 'ant', 'norm', 'ant', 'norm', 'ant', 'iql', 'norm', 'ant', 'norm', 'ant', 'cosine', 'ant', 'iql', 'cosine', 'ant', 'cosine', 'ant', 'wasserstein', 'ant', 'iql', 'wasserstein', 'ant', 'wasserstein', 'fig', 'audit', 'accuracy', 'half', 'cheetah', 'dataset', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'half', 'norm', 'half', 'norm', 'half', 'cosine', 'distance', 'half', 'wasserstein', 'distance', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'half', 'norm', 'rluply', 'expert', 'medium', 'random', 'half', 'norm', 'rluply', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'iql', 'norm', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'iql', 'norm', 'rluply', 'expert', 'expert', 'medium', 'random', 'half', 'cosine', 'distance', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'iql', 'cosine', 'distance', 'rluply', 'medium', 'random', 'expert', 'half', 'distance', 'expert', 'rluply', 'medium', 'random', 'half', 'cheetah', 'iql', 'distance', 'expert', 'medium', 'random', 'half', 'cheetah', 'norm', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'norm', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'cosine', 'distance', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'distance', 'expert', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'medium', 'random', 'rluply', 'medium', 'random', 'fig', 'audit', 'accuracy', 'orlauditor', 'lunar', 'lander', 'split', 'trajectory', 'short', 'one', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'hyperparameter', 'trajectory', 'splitting', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'lunar', 'lander', 'norm', 'split', 'lunar', 'lander', 'norm', 'split', 'lunar', 'lander', 'cosine', 'split', 'lunar', 'lander', 'wasserstein', 'split', 'lunar', 'lander', 'norm', 'split', 'lunar', 'lander', 'norm', 'split', 'lunar', 'lander', 'cosine', 'split', 'lunar', 'lander', 'iql', 'norm', 'split', 'lunar', 'lander', 'iql', 'norm', 'split', 'lunar', 'lander', 'iql', 'cosine', 'split', 'lunar', 'lander', 'norm', 'split', 'lunar', 'lander', 'norm', 'split', 'lunar', 'lander', 'cosine', 'split', 'lunar', 'lander', 'wasserstein', 'split', 'lunar', 'lander', 'iql', 'wasserstein', 'split', 'lunar', 'lander', 'split', 'fig', 'audit', 'accuracy', 'orlauditor', 'bipedal', 'walker', 'split', 'trajectory', 'short', 'one', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'hyperparameter', 'trajectory', 'splitting', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'norm', 'split', 'bipedal', 'walker', 'norm', 'split', 'bipedal', 'walker', 'cosine', 'split', 'bipedal', 'walker', 'wasserstein', 'split', 'walker', 'norm', 'split', 'walker', 'norm', 'split', 'walker', 'cosine', 'split', 'wasserstein', 'split', 'norm', 'split', 'iql', 'norm', 'split', 'iql', 'cosine', 'split', 'bipedal', 'walker', 'iql', 'wasserstein', 'split', 'norm', 'split', 'norm', 'split', 'bipedal', 'walker', 'cosine', 'split', 'split', 'fig', 'audit', 'accuracy', 'orlauditor', 'ant', 'split', 'trajectory', 'short', 'one', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'hyperparameter', 'trajectory', 'splitting', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'ant', 'cosine', 'split', 'ant', 'wasserstein', 'split', 'ant', 'norm', 'split', 'ant', 'norm', 'split', 'ant', 'norm', 'split', 'ant', 'norm', 'split', 'ant', 'iql', 'norm', 'split', 'ant', 'iql', 'norm', 'split', 'ant', 'norm', 'split', 'ant', 'norm', 'split', 'ant', 'cosine', 'split', 'ant', 'iql', 'cosine', 'split', 'ant', 'cosine', 'split', 'ant', 'wasserstein', 'split', 'ant', 'iql', 'wasserstein', 'split', 'ant', 'split', 'fig', 'audit', 'accuracy', 'orlauditor', 'half', 'cheetah', 'split', 'trajectory', 'short', 'one', 'caption', 'plot', 'demonstrate', 'offline', 'model', 'type', 'task', 'distance', 'metric', 'hyperparameter', 'trajectory', 'splitting', 'label', 'name', 'dataset', 'audit', 'target', 'dataset', 'label', 'name', 'dataset', 'suspect', 'model', 'learn', 'actual', 'dataset', 'thus', 'diagonal', 'value', 'show', 'audit', 'accuracy', 'actual', 'dataset', 'target', 'dataset', 'tpr', 'nondiagonal', 'value', 'tnr', 'result', 'position', 'value', 'accuracy', 'half', 'norm', 'split', 'half', 'norm', 'split', 'half', 'cosine', 'split', 'half', 'wasserstein', 'split', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'half', 'norm', 'split', 'rluply', 'expert', 'medium', 'random', 'half', 'norm', 'split', 'rluply', 'expert', 'medium', 'random', 'half', 'cosine', 'split', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'iql', 'norm', 'split', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'iql', 'norm', 'split', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'iql', 'cosine', 'split', 'rluply', 'expert', 'medium', 'random', 'rluply', 'rluply', 'medium', 'random', 'expert', 'half', 'wasserstein', 'split', 'expert', 'rluply', 'medium', 'random', 'half', 'cheetah', 'iql', 'wasserstein', 'split', 'expert', 'medium', 'random', 'half', 'cheetah', 'norm', 'split', 'rluply', 'expert', 'medium', 'random', 'half', 'cheetah', 'norm', 'split', 'rluply', 'expert', 'rluply', 'medium', 'random', 'half', 'cheetah', 'cosine', 'split', 'expert', 'medium', 'random', 'half', 'cheetah', 'split', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply', 'expert', 'medium', 'random', 'rluply']"
Why We Don't Have AGI Yet,"[{'href': 'http://arxiv.org/abs/2308.03598v4', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2308.03598v4', 'rel': 'related', 'type': 'application/pdf'}]",2023-08-07 13:59:31,"ElasticNotebook: Enabling Live Migration for
Computational Notebooks (Technical Report)

Zhaoheng Li∗, Pranav Gor∗, Rahul Prabhu∗, Hui Yu∗, Yuzhou Mao+, Yongjoo Park∗
University of Illinois at Urbana-Champaign∗ University of Michigan+
{zl20,gor2,rprabhu5,huiy3,yongjoo}@illinois.edu,yuzhom@umich.edu

3
2
0
2

p
e
S
0
2

]

B
D
.
s
c
[

1
v
3
8
0
1
1
.
9
0
3
2
:
v
i
X
r
a

ABSTRACT
Computational notebooks (e.g., Jupyter, Google Colab) are widely
used for interactive data science and machine learning. In those
frameworks, users can start a session, then execute cells (i.e., a set of
statements) to create variables, train models, visualize results, etc.
Unfortunately, existing notebook systems do not offer live migra-
tion: when a notebook launches on a new machine, it loses its state,
preventing users from continuing their tasks from where they had
left off. This is because, unlike DBMS, the sessions directly rely on
underlying kernels (e.g., Python/R interpreters) without an addi-
tional data management layer. Existing techniques for preserving
states, such as copying all variables or OS-level checkpointing, are
unreliable (often fail), inefficient, and platform-dependent. Also,
re-running code from scratch can be highly time-consuming.

In this paper, we introduce a new notebook system, Elastic-
Notebook, that offers live migration via checkpointing/restoration
using a novel mechanism that is reliable, efficient, and platform-
independent. Specifically, by observing all cell executions via trans-
parent, lightweight monitoring, ElasticNotebook can find a reliable
and efficient way (i.e., replication plan) for reconstructing the origi-
nal session state, considering variable-cell dependencies, observed
runtime, variable sizes, etc. To this end, our new graph-based opti-
mization problem finds how to reconstruct all variables (efficiently)
from a subset of variables that can be transferred across machines.
We show that ElasticNotebook reduces end-to-end migration and
restoration times by 85%-98% and 94%-99%, respectively, on a vari-
ety (i.e., Kaggle, JWST, and Tutorial) of notebooks with negligible
runtime and memory overheads of <2.5% and <10%.

PVLDB Reference Format:
Zhaoheng Li∗, Pranav Gor∗, Rahul Prabhu∗, Hui Yu∗, Yuzhou Mao+,
Yongjoo Park∗. ElasticNotebook: Enabling Live Migration for
Computational Notebooks. PVLDB, 14(1): XXX-XXX, 2020.
doi:XX.XX/XXX.XX

1 INTRODUCTION
Computational notebooks1 (e.g., Jupyter [63, 101], Rstudio [86]) are
widely used in data science and machine learning for interactive tu-
torials [62], data exploration [19, 26, 121], visualization [28], model

This work is licensed under the Creative Commons BY-NC-ND 4.0 International
License. Visit https://creativecommons.org/licenses/by-nc-nd/4.0/ to view a copy of
this license. For any use beyond those covered by this license, obtain permission by
emailing info@vldb.org. Copyright is held by the owner/author(s). Publication rights
licensed to the VLDB Endowment.
Proceedings of the VLDB Endowment, Vol. 14, No. 1 ISSN 2150-8097.
doi:XX.XX/XXX.XX

1In this work, we use the term a “notebook” to mean either a system serving the
notebook or the contents of the notebook, depending on the context.

User Interface

Our Data Layer

Kernel

cell 1
...code...

cell 2
...code...

Technique 1: dynamic exe-
cution history in graph (§4)

Technique 2: optimization
for fast migration (§5)

Python
R
LLVM

Figure 1: Our transparent data layer (in the middle) enables
robust, efficient, and platform-independent live migration.

tuning and selection [9, 114], etc. Cloud providers offer Software-
as-a-Services (e.g., AWS hub [91], Azure ML studio [4], Google
Colab [47], IBM Watson studio [56]) with commonly used libraries
(e.g., Pandas, PyTorch). A notebook workflow begins with a user
starting a computing session. Then, the user can execute a cell (i.e.,
a set of statements), one by one, to load datasets, create variables,
train models, visualize results, etc. The session can be terminated
manually or automatically to save resources and costs.

Limitation: No Live Replication. Unfortunately, existing note-
books do not offer transparent infrastructure scaling (independent
of applications), which are becoming increasingly popular in the
cloud for instant scalability and cost reduction (e.g., auto-scaling
DBMS [85, 112], micro-service orchestration [25, 68]). That is, if
we copy a notebook file to a new VM (e.g., for larger memory) or
suspend a session to save costs, the resumed notebook loses its state
(i.e., a set of variables), having only code and outputs. In other words,
the user cannot resume their task from where they had previously
left off. This is because the notebooks directly rely on underlying
kernels (e.g., Python/R interpreters, C++ REPL) without an addi-
tional data management layer. Accordingly, the variables residing
in processes are erased as they terminate with sessions. To address
this, we can potentially save those variables and restore them on a
new environment. However, existing techniques such as serializing
all variables [37–39] and checkpointing OS processes [3, 18, 43, 61]
may fail, are inefficient, and platform-dependent (discussed shortly).
Finally, re-running code from scratch can be time-consuming.

Our Goal. We propose ElasticNotebook, a notebook system that
offers live state migration via checkpointing/restoration using a
reliable, efficient, and platform-independent state replication mech-
anism. Reliability: It enables correct/successful replication for
(almost) all notebooks. Efficiency: It is significantly more efficient
than others. Platform-independence: It does not rely on platform-
/architecture-specific features. That is, ElasticNotebook enables
live notebook replication for potentially all notebook workloads by
introducing a novel data management layer. For example, if a user
specifies a new machine to run a currently active notebook, the
system transparently replicates the notebook, including all of its
variables, as if the notebook has been running on the new machine.

 
 
 
 
 
 
Zhaoheng Li, Pranav Gor, Rahul Prabhu, Hui Yu, Yuzhou Mao, Yongjoo Park

Table 1: Comparison between our ElasticNotebook and other possible approaches to saving/restoring session states

Approach

Mechanism

Serialization-based tools [35, 38–40, 104]
System-level checkpointing [3, 18, 43, 61, 64]
Notebook Versioning and Replay [11, 76, 98]
Execution environment migration [1, 115]
Ours (ElasticNotebook)

Serializes and stores variables during computing session (fails with unserializable variables)
Saves memory dump of computing session (high network cost and low portability)
Enable re-execution of versioned notebook snapshots for result verification
Migrates installed modules; useful in conjunction with (but orthogonal to) session state replication
Optimally combines copy/recompute for reliability, efficiency, and platform independence

If we can provide this capability with little to no modifications
to existing systems (e.g., Jupyter), we can offer benefits to a large
number of data scientists and educators who use notebooks. To
achieve this, we must overcome the following technical challenges.

Challenge. Creating a reliable, efficient, and platform-independent
replication mechanism is challenging. First, the mechanism must
offer high coverage. That is, for almost all notebooks people create,
we should be able to successfully replicate them across machines.
Second, the mechanism should be significantly faster than straight-
forward approaches—rerunning all the cells exactly as they were
run in the past, or copying, if possible, all the variables with serial-
ization/deserialization. Third, the mechanism should integrate with
existing notebook systems with clean separation for sustainable
development and easier adoption.

Our Approach. Our core idea is that by observing the evolution
of session states via lightweight monitoring, we can address the
three important challenges—reliability, efficiency, and platform-
independence—by combining program language techniques (i.e., on-
the-fly code analyses) and novel algorithmic solutions (i.e., graph-
based mathematical optimization). Specifically, to represent session
state changes, we introduce the application history, a special form of
bipartite graph expressing the dependencies among variables and
cell executions. Using this graph, we take the following approach.
First, we achieve reliability and platform independence by choos-
ing a computational plan (or replication plan) that can safely re-
construct platform-dependent variables (e.g., Python generators,
incompletely defined custom classes) based on the other platform-
independent variables. That is, in the presence of variables that
cannot be serialized for platform-independent replication, Elas-
ticNotebook uses the application history to recompute them dy-
namically on a target machine. In this process, ElasticNotebook
optimizes for the collective cost of recomputing all such variables
while still maintaining their correctness (§4).

Second, for efficiency, ElasticNotebook optimizes its replication
plan to determine (1) the variables that will be copied, and (2) the
variables that will be recomputed based on the copied variables,
to minimize the end-to-end migration (or restoration) time in con-
sideration of serialization costs, recomputation costs, data transfer
costs, etc. For example, even if a variable can be reliably transferred
across machines, the variable may still be dynamically constructed
if doing so results in a lower total cost. To make this decision in a
principled way, we devise a new graph-based optimization problem,
which reduces to a well-established min-cut problem (§5).

Implementation: While our contributions can apply to many dy-
namically analyzable languages (e.g., Python/R, LLVM-based ones),
we implement our prototype (in C and Python) for the Python user
interface, which is widely used for data science, machine learning,

statistical analysis, etc. Specifically, ElasticNotebook provides a
data management layer to Jupyter as a hidden cell magic [103] to
transparently monitor cell executions and offer efficient replication.
Difference from Existing Work. Compared to existing work, we
pursue a significantly different direction. For example, there are
tools that make data serialization more convenient [40, 104]; how-
ever, they fail if a session contains non-serializable variables, and
are inefficient because they do not consider opportunities for dy-
namic recomputation. Alternatively, system-level checkpointing [3,
18, 43, 61] is platform-dependent, limited to checkpointing memory
(e.g., not GPU), less efficient than ours since dynamic recompu-
tation is impossible. Building on top of result reuse [42, 116] and
lineage tracing [54, 83, 93], we introduce deeper (reference-aware)
analyses (§4.2) and novel optimization techniques to incorporate
unique constraints such as inter-variable dependencies (§5) and
also empirically confirm their effectiveness (§7.2). Completely or-
thogonal work includes library migration [1, 115] and scalable data
science [79, 81, 117]. Table 1 summarizes differences.
Contributions. Our contributions are as follows:
• Motivation. We discuss alternative approaches and explain

the advantage of our approach. (§2)

• Architecture. We describe our system architecture for achiev-

ing efficient and robust session replication. (§3)

• Data Model. We introduce a novel data model (Application
History Graph) for expression session history, which enables
efficient and accurate state replication. (§4)

• Optimization Problem and Solution. We formally define
the optimization problem of minimizing state replication cost
through balancing variable copying and recomputation. We
propose an efficient and effective solution. (§5)

• Evaluation. We show ElasticNotebook reduces upscaling, down-
scaling, and restore times by 85%-98%, 84%-99%, and 94%-99%,
respectively. Overheads are negligible (<2.5% runtime). (§7)

2 MOTIVATION
This section describes use cases (§2.1) and requirements (§2.2) for
session replication, and our intuition for higher efficiency (§2.3).

2.1 Why is Live Migration Useful?
A seamless state replication for computational notebooks can al-
low easier infrastructure scaling and frequent session suspension,
without interrupting user workflow, as described below.
Fast Replication for Elastic Computing. The ability to move
a state across machines is useful for scaling resources [21, 64],
allowing us to migrate a live session to the machines with the right
equipment/resources (e.g., GPU [22], specific architectures [119]).
For interruption-free scaling, we can copy data D from a source

ElasticNotebook: Enabling Live Migration for Computational Notebooks

User Interface
...
%%intercept
code
...

def intercept(code):
preprocess(code)
# regular kernel execution
out = execute(code)
postprocess(out, code)

Application History

df_train

Cell 1
3mins

df

Cell 2
1min

Cell 3
20mins

model

Cell 4
10mins

plot

df_test

Figure 2: For every cell run, we can inject custom pre-/post-
processing logic. “%%intercept” is hidden to users.

Variable
Store cost (mins)
Reload cost (mins)
Total cost (mins)

df
8
2
10

df_train df_test
6.4
1.6
8

1.6
0.4
2

model
0.2
0.2
0.4

plot
0.1
0.1
0.2

machine to a target machine in a way that the original session state
can be restored from D. In this process, we want to minimize the
end-to-end time for creating D, transferring D to a target machine,
reconstructing the state from D on the target machine. This is the
first use case we empirically study (§7.3).

Fast Restart for On-demand Computing. Leveraging pay-as-
you-go pricing model offered by many cloud vendors [5, 48], sus-
pending sessions (and VMs) when not in use is an effective way
for reducing charges (e.g., up to 6× [115]). With the ability to cre-
ate data D sufficient for reconstructing the current session state,
we can persist D prior to either manual or automated suspen-
sion [20, 47, 59], to quickly resume, when needed, the session in
the same state. This achieves on-demand, granular computing with
fast session restart times without impacting user experience due to
frequent session suspensions [58, 97]. In this process, we want to
restore the session as quickly as possible by minimizing the time it
takes for downloading D and reconstructing a state from it. This is
the second use case we empirically study (§7.4).

2.2 How to Enable Data Management Layer?
We discuss the pros and cons of several different approaches to
enabling a data management layer.

OS-level Checkpointing. To save the current session state, we can
checkpoint the entire memory space associated with the underlying
Python/R kernels. To make the process more efficient, existing tools
like CRIU patch the Linux kernel to trace dirty pages. However,
as described in §1, this approach is platform-independent, incurs
higher space cost, and is limited to storing the state of primary
memory (not GPU or other devices). We empirically compare our
approach to CRIU to understand reliability and efficiency (§7).

Object wrappers. Watchpoint object wrappers [41, 44] are com-
monly used for debugging purposes [83] and program slicing [54,
93]: they maintain deep copies for objects in the session state, which
are compared to check for changes after each frame execution; how-
ever, they are unsuitable for use during data science workflows due
to the unacceptable ~20× runtime overhead in our preliminary tests.

Monitoring Cell Executions (Ours). In order to trace cell exe-
cutions and their effects on variables, we can add a lightweight
wrapper (i.e., our data management layer) that functions before
and after each cell execution to monitor the cell code, runtime,
and variable changes. This idea is depicted conceptually in Fig 2.
Specifically, our implementation uses cell magics, a Jupyter-native
mechanism that allows arbitrary modification to cell statements
when the cell is executed. With this, we add pre-/post-processing
steps to capture cell code and resulting session state modifications.

Store Vars
N/A
All

Method
Rerun all
Store all
Fast-migrate model,plot
Fast-restore df,model,plot 2

Rerun cells Migration Cost Restore Cost
All
3+1+20+10=33
N/A
1, 2

3+1+20+10=33
10+8+2+.4+.2=20.6 2+1.6+.4+.2+.1=4.3
3+1+.4+.2=4.6
10+1+.4+.2=11.6

3+1+.2+.1=4.3
2+1+.2+.1=3.3

Figure 3: Example app history (top) and different replica-
tion plan costs (bottom). Combining recompute/copy allows
faster migration (Fast-migrate). Alternatively, the optimal
plan changes if the restoration is prioritized (Fast-restore).

2.3 Fast Replication with Application History
This section describes our core idea for devising an efficient repli-
cation strategy by leveraging the ability to monitor cell executions.

Application History. An application history graph (AHG) is a bipar-
tite graph for expressing session states changes with respect to cell
runs. There are two types of nodes: variables and transformations.
A transformation node connects input variables to output variables
(see an example in Fig 3). AHG aims to achieve two properties:
• Completeness: No false negatives. All input/output variable

for each transformation must be captured.

• Minimal: Minimal false positives. The number of variables that
are incorrectly identified as accessed/modified, while variables
are not actually accessed/modified, must be minimized.

These properties are required for correct state reconstruction (§4).

Core Optimization Idea. AHG allows for efficient state replica-
tion with a combination of (1) recompute and (2) copy. Motivating
Example. Suppose a data analyst fitting a regression model (Fig 3).
The notebook contains 4 cell runs: data load (Cell 1), train-test split
(Cell 2), fitting (Cell 3), and evaluation (Cell 4). After fitting, the ana-
lyst decides to move the session to a new machine for GPU. Simply
rerunning the entire notebook incurs 33 minutes. Alternatively,
serializing/copying variables takes 20.6 minutes.

However, there is a more efficient approach. By copying only
model and plot and recomputing others on a new machine (Fast-
migrate), we can complete end-to-end migration in 4.6 minutes.
Or, if we prioritize restoration time (to reduce user-perceived restart
time for on-demand computing), our optimized plan (Fast-restore)
takes 3.3 minutes. This example illustrates significant optimization
opportunities in session replication. Our goal is to have the ability
to find the best replication plan for arbitrarily complex AHGs.

3 SYSTEM OVERVIEW
This section presents ElasticNotebook at a high level by describing
its components (§3.1) and operations (§3.2).

Data Layer (core part of ElasticNotebook)

Table 2: Notations and their meaning

Zhaoheng Li, Pranav Gor, Rahul Prabhu, Hui Yu, Yuzhou Mao, Yongjoo Park

Notebook
User
Interface

x=""hello""

y=""world""

.
.
.

Cell Execution
Interceptor (§4.2)

Optimizer (§5)

ID Graphs &
object hashes

Optimization
algorithm

Application
History
Graph (§4.1)

Cost Model
(§5.2)

Session
Replicator (§4.3)

Writer

Notebook
Replayer

Jupyter
Kernel
Namespace
(user_ns)

KEY VAL
x
y

hello
world
...

Figure 4: ElasticNotebook architecture. Its data layer acts as
a gateway between the user interface and the kernel: cell
executions are intercepted to observe session state changes.

3.1 ElasticNotebook Components
ElasticNotebook introduces a unique data layer that acts as a gate-
way between the user and the kernel (See Fig 4): it monitors every
cell execution, observing code and resulting session state changes.

Cell Execution Interceptor. The Cell Execution Interceptor inter-
cepts cell execution requests and adds pre-/post-processing scripts
before rerouting it into the underlying kernel for regular execu-
tion. The added scripts perform (1) cell code analyses and the AHG
updates, and (2) cell runtime recordings.

Application History Graph (AHG). The AHG is incrementally
built by the Cell Execution Interceptor to record how variables have
been accessed/modified by each cell execution (§4). The AHG is
used by the Optimizer to compute replication plans (§5).

Cost Model. The cost model stores profiled metrics (i.e., cell run-
times, variable sizes, network bandwidth), serving as the hyperpa-
rameters for the Optimizer (§5.2).

Optimizer. The Optimizer uses the AHG and the Cost Model to
determine the most efficient replication plan consisting of (1) vari-
ables to store and (2) cells to re-run. We discuss ElasticNotebook’s
cost model and optimization in detail in §5.

Session Replicator. The Session Replicator replicates a notebook
session according to the Optimizer’s plan. Specifically, the Writer
creates and writes a checkpoint file to storage (e.g., SSD, cloud
storage), while the Notebook Replayer reads the file and restores
the session, both following the replication plan. We discuss Elastic-
Notebook’s session replication in detail in §3.2.

3.2 ElasticNotebook Workflow
This section describes ElasticNotebook’s operations. ElasticNote-
book monitors every cell execution during a session lifecycle, then
performs on-request replication of the session in two steps: check-
pointing (writing to the checkpoint file) and restoration.
Monitoring Cell Executions. Upon each cell execution by the user,
ElasticNotebook performs the following steps:
1. Accessed variables of the cell execution are identified via AST

analysis (described in §4.2).

2. The cell code is executed by the Jupyter kernel.

Definition
Set of Variables
Set of Variable Snapshots (VSs)
Set of Active Variable Snapshots
Set of Cell Executions (CEs)
Set of write dependencies
Set of read dependencies

Symbols
X
V
V𝑎
C (= 𝑐𝑡1, 𝑐𝑡2, . . .)
E𝑤
E𝑟
G := { V ∪ C, E𝑤 ∪ E𝑟 } Application History Graph (AHG)
𝑟𝑒𝑞 : X → 2C
Reconstruction mapping function
𝑤𝑠𝑡𝑜𝑟𝑒 : X → R+
Variable storage cost
𝑤𝑟𝑒𝑟𝑢𝑛 : C → R+
Cell Rerun cost
𝑤M : 2X → R+
Migration cost function
𝑤R : 2X → R+
Recomputation cost function
Pairs of linked variables
L ⊆ X × X
Flow graph
H := { V𝐻 , E𝐻 }
𝑐 : E𝐻 → R+
Flow graph edge capacity function

3. Variable changes (i.e., creation/deletion/modification) are iden-

tified within the global namespace (§4.2).

4. The AHG is updated using (1) the cell code and (2) modified

variables by the cell execution.

5. The Cost Model is updated to record cell runtime.
Initiating Replication. When replication is requested, Elastic-
Notebook creates and writes a checkpoint file to storage, which can
be restored later to exactly and efficiently reconstruct the current
session. ElasticNotebook first completes the Cost Model by pro-
filing variable sizes and network bandwidth to storage; then, the
Optimizer utilizes the AHG and Cost model to compute a replica-
tion plan, according to which the Writer creates the checkpoint file:
it consists of (1) a subset of stored variables from the session state,
(2) cells to rerun, (3) the AHG, and (4) the Cost Model.
Restoring a Session. When requested, ElasticNotebook restores
the notebook session from the checkpoint file according to the
replication plan. The Notebook Replayer reconstructs variables
in the order they appeared in the original session by combining
(1) cell reruns and (2) data deserialization followed by variable re-
declaration (into the kernel). Finally, ElasticNotebook loads the
AHG and Cost Model for future replications.

Accuracy Guarantee: ElasticNotebook’s state reconstructing is
effectively the same as re-running all the cells from scratch exactly
in the order they were run in the past. That is, ElasticNotebook
shortens the end-to-end reconstruction time by loading saved vari-
ables (into the kernel namespace) if doing so achieves time savings.
§4.3 presents formal correctness analysis. §6.1 discusses how we
address external resources, side effects, and deserialization failures.

4 APPLICATION HISTORY GRAPH
This section formally defines the Application History Graph (§4.1),
and describes how we achieve exact state replication (§4.3).

4.1 AHG Formal Definition
The AHG is a directed acyclic graph expressing how a session state
has changed with respect to cell executions. Fig 5 is an example.

Definition 1. A variable is a named entity (e.g., df) referencing
an object (which can be uniquely identified by its object ID).

ElasticNotebook: Enabling Live Migration for Computational Notebooks

A variable can be primitive (e.g., int, string) or complex (e.g., list,
dataframe). Multiple variables may point to the same object. The
set of all variables (i.e., X) defined in the global namespace forms a
session state. Cell executions may modify the values of variables
(or referenced objects) without changes to their names, which we
recognize in AHG using variable snapshot, as follows.

Definition 2. A variable snapshot (VS) is a name-timestamp
pair, (𝑥, 𝑡), representing the variable 𝑥 created/modified at 𝑡. We
denote the set of VSes as V.

Definition 3. A cell execution (CE) 𝑐𝑡 represents a cell execution
that finishes at timestamp 𝑡.

All cell executions are linear; that is, for each session, there is at most
one cell running at a time, and their executions are totally ordered.
We denote the list of CEs by C. Each CE also stores executed cell
code, which can be used for re-runs (§3.2).

Definition 4. A write dependency (𝑐𝑡 → (x, 𝑡)) indicates CE 𝑐𝑡
may have modified/created at time 𝑡 the object(s) reachable from
the variable 𝑥. We denote the set of write dependencies as E𝑤.

In Fig 5, 𝑐𝑡3 modifies x with “x += 1”; hence, (𝑐𝑡3 → (x, 𝑐𝑡3 )).
Definition 5. A read dependency ((x, 𝑠) → 𝑐𝑡 ) indicates CE 𝑐𝑡
may have accessed object(s) reachable from x last created/modified
at time 𝑠. We denote the set of read dependencies by E𝑟 .

In Fig 5, “gen=(i for i in l1)” in 𝐶𝑡4 accesses elements in the
list l1 after its creation in 𝑐𝑡3 ; hence there is ((x → 𝑐𝑡3 ), 𝑐𝑡4 ). Note
that write/read dependencies are allowed to contain false positives;
nevertheless, our replication ensures correctness (§4.3).

Definition 6. The AHG 𝐺 := {V∪C, E𝑤 ∪E𝑟 } is a bipartite graph,
where V is VSes, C is CEs; E𝑤 and E𝑟 are write/read dependencies,
respectively. It models the lineage of the notebook session.

In sum, AHG formalizes variable accesses/modifications with re-
spect to cell executions. at the variable level (not object level), theo-
retically bounding the size of AHG to scale linearly with the number
of defined variables, not the number of underlying objects (which
can be very large for lists, dataframes, and so on). We empirically
verify AHG’s low memory overhead in §7.5.

4.2 Dynamic AHG Construction
We describe how ElasticNotebook constructs the AHG accurately.
Constructing the AHG. The AHG is incrementally built with
accessed/created/modified variables by each cell execution:
• A new CE 𝑐𝑡 is created; 𝑡 is an execution completion time.
• Read dependencies are created from VSes (𝑥1, 𝑡𝑥1 ), ..., (𝑥𝑘 , 𝑡𝑥𝑘 )
to 𝑐𝑡 , where 𝑥1, ..., 𝑥𝑘 are variables possibly accessed by 𝑐𝑡 .
• VSes (𝑦1, 𝑡), ..., (𝑦𝑘 , 𝑡) are created, where 𝑦1, ..., 𝑦𝑘 are variables
possibly modified and created by 𝑐𝑡 . Write dependencies are
added from 𝑐𝑡 to each of the newly created VSes.

Fig 5 (right) shows an example AHG. Identifying access/modified
variables is crucial for its construction, which we describe below.

ID Graph. The ID Graph aims to to detect changes at the reference
level (in addition to values). For instance, conventional equality
checks (e.g., based on serialization) will return True for “[a] ==

Notebook
Cell 1 (𝑐𝑡1 )
x, y = 1
Cell 2 (𝑐𝑡2 )
z = y
if False:
print(x)
Cell 3 (𝑐𝑡3 )
x += 1
l1 = [z, 2, 3]
Cell 4 (𝑐𝑡4 )
gen=(i for i in l1)
2dlist = [l1]
Cell 5 (𝑐𝑡5 )
print(gen)

(x, 𝒕1)

(y, 𝑡1)

𝒄𝒕1

𝑐𝑡2

(z, 𝑡2)

𝒄𝒕3

(x, 𝒕3)

(l1,𝑡3)

𝑐𝑡4

(gen, 𝑡4)

(2dlist, 𝑡4)

𝑐𝑡5

(gen, 𝑡5)

(x, 𝑡1)

(Overwritten/deleted)
Variable Snapshot

𝑐𝑡1

Cell
Execution

(x, 𝑡1)

Active
Variable Snapshot

Figure 5: An example notebook and its corresponding Appli-
cation History Graph. The AHG tells ElasticNotebook how
to recompute variables; for example, rerunning 𝑐𝑡1 and 𝑐𝑡3 is
necessary for recomputing x (red).

[b]” if a and b have the same value (e.g., a = [1] and b = [1]),
whereas we ensure it returns True only if a and b refer to the
same object, i.e., id(a)==id(b), where id is the object’s unique ID.
This is because for correct state replication, shared references (e.g.
aliases) and inter-variable relationships must be captured precisely.

Identifying Accessed Variables. ElasticNotebook identifies both
directly accessed variables (via AST [31] parsing) and indirectly
accessed variables (with ID Graphs), as follows.

Direct Accesses: Cell code is analyzed with AST, stepping also into
user-defined functions (potentially nested) to check for accesses to
variables not explicitly passed in as parameters (e.g., global x).

Indirect Accesses: The object(s) reachable from a variable X may
be accessed indirectly via another variable Y if X and Y reference
common object(s) (e.g., when aliases exist, Fig 6a), which cannot
be identified via parsing only. To recognize indirect accesses, we
check the existence of overlaps between the ID Graphs of X and Y.
Our approach is conservative; that is, it may over-identify vari-
ables by including, for example, ones reachable from control flow
branches that were not taken during cell executions. However, these
false positives do not affect accuracy of state replication (§4.3).

Identifying Modified Variables. Variable modifications are iden-
tified using a combination of (1) object hashes and (2) ID Graphs.
Value Changes: ElasticNotebook identifies value modifications
by comparing hashes (by xxHash [118]) before and after each cell
execution while using deep copy as a fallback. If the deep copy fails
(e.g., unserializable or uncomparable variables), we consider them
to be modified-on-access using results from AST and ID Graph
(§6.1). This may result in false positives; however, as previously
mentioned, these false positives do not affect the accuracy.

Structural Changes: The ID Graph enables detecting structural
changes (Fig 6b). After each cell execution, the current variables’ ID
Graphs are compared to the ones created before to identify reference
swaps. In Fig 6b, while the value of 2dlist1 remains unchanged

Cell 1
func = lambda x:...
obj1.foo = func
obj2.foo = func
Cell 2
obj2.foo(""str"")

&obj1

&obj2

ID Graph

&func

(a) Detecting indirect variable accesses from aliases

Cell 1
list1 = [1, 2, 3]
2dlist1 = [list1]
2dlist2 = [list1]
Cell 2
list2 = [1, 2, 3]
2dlist1[0] = list2

Before Cell 2

After Cell 2

ID Graph

&2dlist1

&2dlist1

≠

&list1

&list2

Value

[[1,2,3]]

=

[[1,2,3]]

(b) Detecting structural variable modifications

Figure 6: Two uses of the ID Graph during AHG construction.

after execution after executing Cell 2, the memory address of its
nested list has been changed, no longer referencing list1.

4.3 State Reconstruction with AHG
This section describes how we reconstruct variable(s). We focus
on reconstructing the latest version of each variable, as defined in
active variable snapshot (VS) in an AHG.

Definition 7. VS (𝑥, 𝑡𝑖 ) is active if 𝑥 is in the system (i.e., not
deleted), and there is no VS (𝑥, 𝑡 𝑗 ) such that 𝑡𝑖 < 𝑡 𝑗 .

An active VS, (𝑥, 𝑡𝑖 ), represents the current version of 𝑥. For example,
even if we checkpoint after 𝑐𝑡5 (in Fig 5), “(x, 𝑡3)” is active since x
was last modified by 𝑐𝑡3 . We denote the set of active VSes as V𝑎.
Reconstruction Algorithm. Our goal is to identify the most effi-
cient computation strategy for reconstructing one or more active
variables. Note that we do not reconstruct non-active variables
since they are not part of the current session state. In achieving
this goal, the AHG allows us to avoid unnecessary cell executions
(e.g., because their outcomes have been overwritten) and to learn
proper execution orders. Moreover, this process can be extended
to reconstruct a set of variables more efficiently than computing
them one by one. while still ensuring correctness.

Specifically, to recompute VS (𝑥, 𝑡), we traverse back to its an-
cestors in the AHG (e.g., using the breadth-first search), collecting
all CEs into a list 𝑟𝑒𝑞(𝑥, 𝑡), until we find a ground variable for every
path, where the ground variable is a variable whose value is avail-
able in the system, i.e., either another active VS or copied variable.
By rerunning all the CEs in 𝑟𝑒𝑞(𝑥, 𝑡) in the order of their completion
times, we can obtain the target VS (𝑥, 𝑡). To extend this algorithm
to multiple VSes, say (𝑥1, 𝑡𝑥1), (𝑥2, 𝑡𝑥2), and (𝑥3, 𝑡𝑥3), we obtain 𝑟𝑒𝑞
for each VS and union them into a merged set (that is, identical CEs
collapse into one). By rerunning all the CEs in the merged set, we
obtain all target VSes. Fig 5 shows an example. To recompute (𝑥, 𝑡3),
we rerun 𝑐𝑡3 which requires the previous version (x, 𝑡1) as input,
which in turn requires 𝑐𝑡1 to be rerun. Notably, it is not necessary
to rerun 𝑐𝑡2 as its output z is available in the namespace. Finally,
§6.1 discusses how this approach can recover even if some ground
variables are unexpectedly unobtainable.

Zhaoheng Li, Pranav Gor, Rahul Prabhu, Hui Yu, Yuzhou Mao, Yongjoo Park

Notebook
Cell 3 (𝑐𝑡3 )
l1 = [z, 2, 3]
Cell 4 (𝑐𝑡4 )
2dlist = [l1]

Replication Plan

l1
Migrate

2dlist
Migrate

Recompute Recompute
Recompute

Migrate

&l1==&2dlist1[0]

True
True
False

Figure 7: Two variables sharing references (in Fig 5). They
must be migrated/recomputed together for the correct repli-
cation, serving as constraints to our opt problem (see §5.3).

Why Only Use Active VSes? Theoretically, it is possible to use
non-active variables as ground variables. That is, by preserving
deleted/overwritten variables (e.g., in a cache), we may be able to
speed up the recomputation of active variables [42, 116]. However,
we don’t consider this approach as many data science workloads
are memory-hungry with large training data and model sizes. Still,
there might be cases where we can speed up recomputation by
storing small overwritten variables, which we leave as future work.

Correctness of Reconstruction. As stated in §2.3, the AHG is
allowed to have false positives, meaning it may indicate a cell ac-
cessed/modified variables that were not actually accessed/modified.
While the false positives have a performance impact, they do not
affect the correctness of identification.

Theorem 4.1. Given the approximate AHG G of ElasticNotebook
with false positives, and the true AHG G∗, there is 𝑟𝑒𝑞∗ (𝑥, 𝑡 ∗) ⊆
𝑟𝑒𝑞(𝑥, 𝑡) for any variable 𝑥 ∈ X, where (𝑥, 𝑡) and (𝑥, 𝑡 ∗), 𝑟𝑒𝑞 and
𝑟𝑒𝑞∗ are the active VSs of 𝑥 and reconstruction mapping functions
defined on G and G∗ respectively.

That is, for any arbitrary variable 𝑥, while 𝑟𝑒𝑞(𝑥, 𝑡) may contain
cell executions unnecessary for recomputing 𝑥, it will never miss
any necessary cell executions (i.e., those in 𝑟𝑒𝑞(𝑥, 𝑡 ∗)). The proof is
presented in Appendix A.2.

5 CORRECT & EFFICIENT REPLICATION
This section covers how ElasticNotebook computes an efficient and
correct plan for state replication with the AHG and profiled metrics.
We describe correctness requirements in §5.1, the cost model in
§5.2, the optimization problem in §5.3, and our solution in §5.4.

5.1 Correctness Requirements
ElasticNotebook aims to correctly replicate session states. which
we define the notion of in this section:

Definition 8. A replication of state X is value-equivalent if
∀𝑥 ∈ X,𝑥 =𝑛𝑒𝑤 (𝑥), where 𝑛𝑒𝑤 (𝑥) is the value of 𝑥 post-replication.

A value-equivalent replication preserves the value of each indi-
vidual variable and is guaranteed by the correct identification of
𝑟𝑒𝑞(𝑥, 𝑡) for each variable 𝑥 (§4.3). However, it is additionally im-
portant that shared references are preserved, as defined below.

Definition 9. A value-equivalent replication of a session state X
is additionally isomorphic if ∀𝑎, 𝑏, 𝑖𝑑 (𝑎) = 𝑖𝑑 (𝑏) → 𝑖𝑑_𝑛𝑒𝑤 (𝑎) =
𝑖𝑑_𝑛𝑒𝑤 (𝑏), where 𝑎, 𝑏 are arbitrary references (e.g., x[0][1], y.foo),
and 𝑖𝑑 (𝑎), 𝑖𝑑_𝑛𝑒𝑤 (𝑎) are the unique IDs (i.e., memory addresses)
of the objects pointed to by 𝑎 before and after replication.

ElasticNotebook: Enabling Live Migration for Computational Notebooks

migration cost

=

capacity

Source

y

z

x

l1

Active VSes

Cell Executions

capacity=∞ ca

p

acity

=

reru

n

cost

Sink

𝑐𝑡1

𝑐𝑡2

𝑐𝑡3

𝑐𝑡4

𝑐𝑡5

capacity=∞

2dlist1

gen

Figure 8: Running min-cut on the flow graph constructed
from the AHG in Fig 5. The partition (red) defined by the
minimum cut (dashed edges) determines the replication plan.

ElasticNotebook defines replication as ’correct’ only if it is isomor-
phic, requiring all shared references to be preserved: two references
pointing to the same object pre-replication will still do so post-
replication. That is, inter-object relations are identical (analogous
to graph isomorphism). We describe how ElasticNotebook ensures
isomorphic replication via its linked variable constraint in §5.3.

5.2 Cost Model
Our model captures the costs associated with (1) serializing vari-
ables, (2) writing byte data into storage (e.g., local SSD, cloud stor-
age) and (3) rerunning cell executions. These costs are computed
using the AHG and profiled system metrics.

Variable Migration Cost. Migrating a variable (from one session
to another) includes serializing it to the checkpoint file, then loading
it into a new session. Given a subset of variables to migrate S ⊆ X,
the migration cost 𝑤𝑀 can be expressed as follows:
∑︁
𝛼 × 𝑤𝑠𝑡𝑜𝑟𝑒 (𝑥) + 𝑤𝑙𝑜𝑎𝑑 (𝑥)

𝑤𝑀 (S) =

(1)

𝑥 ∈ S

Where 𝑤𝑠𝑡𝑜𝑟𝑒 (𝑥) and 𝑤𝑙𝑜𝑎𝑑 (𝑥) are the time costs for serializing
the value of 𝑥 at checkpointing time into a file and unpacking into
the new session, respectively. These times are estimated using the
size of 𝑥 and storage latency/bandwidth from ElasticNotebook’s
Profiler (§3.1). The time costs for unserializable variables are set to
infinity. 𝛼 is a coefficient for adjusting the time cost of storage; for
example, if ElasticNotebook is to be invoked upon auto-suspension,
𝛼 can be set to a low value to discount the user-perceived time of
storing variables prior to completely suspending a session (as the
user is likely away).

Variable Recomputation Cost. The Interceptor records cell run-
times during a session lifecycle (§3.1). Combined with the recon-
struction mapping 𝑟𝑒𝑞() for the AHG (§4.3), the cost 𝑤𝑅 for recom-
puting a subset of variables S ⊆ X can be defined as follows:
𝑟𝑒𝑞(𝑥, 𝑡)

𝑤𝑟𝑒𝑟𝑢𝑛 (𝑐), where 𝑟𝑒𝑞(S) =

𝑤𝑅 (S) =

∑︁

(cid:216)

(2)

𝑐 ∈𝑟𝑒𝑞 ( S)

𝑥 ∈ S

where (𝑥, 𝑡) is the active VS of 𝑥 and 𝑤𝑟𝑒𝑟𝑢𝑛 (𝑐) : C → R+ is the
estimated time to rerun the CE 𝑐 in the new session.

Replication Plan Cost. Using migration and recomputation costs
(i.e., Eqs. (1) and (2)), the total cost 𝑤—with variables to migrate S

and variables to recompute X − S—is expressed as:

𝑤 (S) = 𝑤𝑀 (S) + 𝑤𝑅 (X − S)

(3)

5.3 Optimization Problem for State Replication
The goal is to find the variables to migrate S ⊆ X that minimizes
the cost Eq. (3). To ensure isomoprhic replication in consideration
of variable inter-dependencies, additional constraints are added.

Constraint for Linked Variables. Two variables containing refer-
ences to the same object (which we refer to as linked variables, e.g.,
l1 and 2dlist1 in Fig 7) must be either both migrated or recom-
puted, as migrating one and recomputing the other may result in
their contained shared reference/alias being broken, as illustrated
in Fig 7. Let the set of linked variable pairs be denoted as L, then
the constraint can be formally expressed as follows:

(𝑥1 ∈ S ∧ 𝑥2 ∈ S) ∨ (𝑥1 ∉ S ∧ 𝑥2 ∉ S) ∀(𝑥1, 𝑥2) ∈ L
Problem definition. Using the cost model in Eq. (3) and the con-
straint in Eq. (4), we formally define the state replication problem:

(4)

Problem 1. Optimal State Replication
Input:

1. AHG G = {V ∪ C, E}
2. Migration cost function 𝑤𝑀 : 2X → R+
3. Recompute cost function 𝑤𝑅 : 2X → R+
4. Linked variables L ⊆ X × X
A replication plan of subset of variables S ⊆ X for
which we migrate (and another subset X − S which
we recompute)

Output:

Objective: Minimize replication cost 𝑤𝑀 (S) + 𝑤𝑅 (X − S)
Constraint: Linked variables are either both migrated or recom-

puted: (𝑥1, 𝑥2 ∈ S) ∨ (𝑥1, 𝑥2 ∉ S) ∀(𝑥1, 𝑥2) ∈ L

The next section (§5.4) presents our solution to Prob 1.

5.4 Solving State Replication Opt. Problem
We solve Prob 1 by reducing it to a min-cut problem, with a 𝑠𝑟𝑐-𝑠𝑖𝑛𝑘
flow graph constructed from the AHG such that each 𝑠𝑟𝑐-𝑠𝑖𝑛𝑘 cut
(a subset of edges, which, when removed from the flow graph,
disconnects source 𝑠 and sink 𝑡) corresponds to a replication plan
S, while the cost of the cut is equal to the replication cost 𝑤𝑀 (S) +
𝑤𝑅 (X − S). Therefore, finding the minimum cost 𝑠𝑟𝑐-𝑠𝑖𝑛𝑘 cut is
equivalent to finding the optimal replication plan.

Flow Graph Construction. A flow graph 𝐻 := {V𝐻 , E𝐻 } and its
edge capacity 𝜙 : E𝐻 → R+ are defined as follows:
• V𝐻 = V𝑎 ∪ C ∪ {𝑠𝑟𝑐, 𝑠𝑖𝑛𝑘 }: V𝑎 is active VSes, C is cell execu-
tions, and 𝑠𝑟𝑐 and 𝑠𝑖𝑛𝑘 are dummy source and sink nodes.
• ∀𝑥 ∈ V𝑎, (𝑠𝑟𝑐, (𝑥, 𝑡)) ∈ E𝐻 and 𝜙 (𝑠𝑟𝑐, (𝑥, 𝑡)) = 𝑤𝑀 (𝑥): We add
an edge from the source to each active VS with a capacity equal
to the migration cost of the variable.

• ∀𝑐 ∈ C, (𝑐, 𝑠𝑖𝑛𝑘) ∈ E𝐻 and 𝜙 (𝑐, 𝑠𝑖𝑛𝑘) = 𝑤𝑟𝑒𝑟𝑢𝑛 (𝑐): We add an
edge with capacity from each CE to the sink with a capacity
equal to the rerun cost of the CE.

• ∀𝑐 ∈ C, 𝑐 ∈ 𝑟𝑒𝑞(𝑥, 𝑡) → ((𝑥, 𝑡), 𝑐) ∈ E𝐻 and 𝜙 ((𝑥, 𝑡), 𝑐) = ∞
and (𝑥, 𝑡) ∈ V𝑎: We add an edge with infinite capacity from an
active VS (𝑥, 𝑡) to a CE 𝑐 if (𝑥, 𝑡) must be recomputed.

• ∀(𝑥1, 𝑥2) ∈ L,

((𝑥1, 𝑡1) ↔ (𝑥2, 𝑡2)) ∈ E𝐻 and 𝜙 ((𝑥1, 𝑡1) ↔
(𝑥2, 𝑡2)) = ∞: We add a bi-directional edge with an infinite

capacity between each pair of active VSes corresponding to
linked variables 𝑥1 and 𝑥2, e.g., l1 and 2dlist1.

The flow graph H for the AHG in Fig 5 is depicted in Fig 8.
Solution. We can now solve Prob 1 by running a 𝑠𝑟𝑐—𝑠𝑖𝑛𝑘 min-cut
solving algorithm (i.e., Ford-Fulkerson [30]) on 𝐻 . The set of edges
that form the 𝑠𝑟𝑐—𝑠𝑖𝑛𝑘 min-cut (dashed edges), when removed,
disconnects 𝑠𝑟𝑐 from 𝑠𝑖𝑛𝑘; therefore, it defines a partition (in red)
of the nodes into nodes reachable from 𝑠𝑟𝑐, V𝐻𝑠𝑟𝑐
and nodes un-
. The replication plan can be obtained
reachable from 𝑠𝑟𝑐, V𝐻𝑠𝑖𝑛𝑘
from the partition:
• S = {𝑥 | (𝑥, 𝑡) ∈ V𝐻𝑠𝑖𝑛𝑘 ∩ V𝑎 } are the active variable snapshots
(and thus variables) that we want to migrate; in the example,
these variables are l1, 2dlist1, and gen.

• V𝐻𝑠𝑟𝑐 ∩ C are the CEs which we will rerun post-migration to
recompute X − S. In the example, these CEs are 𝑡1, 𝑡2, and 𝑡3;
when rerun, they recompute y, z, and x.2

By construction of H , the sum of migration and recomputation
costs of this configuration 𝑤𝑀 ({𝑥 | (𝑥, 𝑡) ∈ V𝐻𝑠𝑖𝑛𝑘 ) + 𝑤𝑅 (C𝑎 −
(V𝐻𝑠𝑟𝑐 ∩ C)) is precisely the cost of the found 𝑠𝑟𝑐—𝑠𝑖𝑛𝑘 min-cut.

6 IMPLEMENTATION AND DISCUSSION
This section describes ElasticNotebook’s implementation details
(§6.1) and design considerations (§6.2).

6.1 Implementation
Integrating with Jupyter. For seamless integration, ElasticNote-
book’s data layer is implemented using a magic extension [103],
which is loaded into the kernel upon session initialization. The cell
magic is automatically added to each cell (§2.2) to transparently
intercept user cell executions, perform code analyses, create ID
Graphs and object hashes, and so on.

Serialization Protocol. The Pickle protocol (e.g., __reduce__) is
employed for (1) object serialization and (2) definition of reachable
objects, i.e., an object y is reachable from a variable x if pickle(x)
includes y. As Pickle is the de-facto standard (in Python) observed
by almost all data science libraries (e.g., NumPy, PyTorch [29]),
ElasticNotebook can be used for almost all use cases.
Handling Undeserializable variables. Certain variables can be
serialized but contain errors in its deserialization instructions (which
we refer to as undeserializable variables), and are typically caused
by oversights in incompletely implemented libraries [15, 69]. While
undetectable via serializability checks prior to checkpointing, Elas-
ticNotebook handles them via fallback recomputation: if Elastic-
Notebook encounters an error while deserializing a stored variable
during session restoration, it will trace the AHG to determine and
rerun (only) necessary cell executions to recompute said variable,
which is still faster than recomputing the session from scratch.

6.2 Design Considerations
Definition of Session State. In ElasticNotebook, the session state
is formally defined as the contents of the user namespace dictionary
(user_ns), which contains key-value pairs of variable names to their

2Rerunning 𝑡3 also recomputes l1; however, it will be overwritten with the stored
l1 in the checkpoint file following the procedure in §3.2. This is to preserve the link
between l1 and 2dlist1.

Zhaoheng Li, Pranav Gor, Rahul Prabhu, Hui Yu, Yuzhou Mao, Yongjoo Park

values (i.e., reachable objects). The session state does not include
local/module/hidden variables, which we do not aim to capture.
Unobservable State / External Functions. Although the Pickle
protocol is followed by almost all libraries, there could be lesser-
known ones with incorrect serialization (e.g., ignoring data defined
in a C stack). To address this, ElasticNotebook can be easily ex-
tended to allow users to annotate cells/variables to inform our
system that they must be recomputed for proper reconstruction.
Mathematically, this has the same effect as setting their recomputa-
tion costs to infinity in Eq. (2).
Cell Executions with Side Effects. Certain cell executions may
cause external changes outside a notebook session (e.g., filesystem)
and may not be desirable to rerun (e.g., uploading items to a reposi-
tory). Our prototype currently does not identify these side effects
as our focus is read-oriented data science and analytics workloads.
Nevertheless, our system can be extended at least in two ways to
prevent them. (1: Annotation) We can allow users to add manual
annotations to the cells that may cause side effects; then, our system
will never re-run them during replications3
(2: Sandbook) We can
block external changes by replicating a notebook into a sandbox
with altered file system access (e.g., chroot [73]) and blocked out-
going network (e.g., ufw [27]). The sandbox can then be associated
with regular file/network accesses upon successful restoration.
Non-deterministic Operations. The replication has the same ef-
fect as rerunning the cells in the exact same order as they occurred
in the past; thus, under the existence of nondeterministic operations
(e.g., randint()), the reconstructed variables may have different
values than the original ones. Users can avoid this by using annota-
tions to inform ElasticNotebook to always copy them.
Library Version Compatibility. Accurate replication is ensured
when external resources (e.g., installed modules, database tables)
remain the same before and after the replication. While there are
existing tools (i.e., pip freeze [84]) for reproducing computational
environments on existing data science platforms (i.e., Jupyter Note-
book, Colab) [1, 115], this work does not incorporate such tools.

7 EXPERIMENTAL EVALUATION
In this section, we empirically study the effectiveness of Elastic-
Notebook’s session replication. We make the following claims:
1. Robust Replication: Unlike existing mechanisms, ElasticNote-
book is capable of replicating almost all notebooks. (§7.2)
2. Faster Migration: ElasticNotebook reduces session migration
time to upscaled/downscaled machines by 85%–98%/84%-99%
compared to rerunning all cells and is up to 2.07×/2.00× faster
than the next best alternative, respectively. (§7.3)

3. Faster Resumption: ElasticNotebook reduces session restora-
tion time by 94%–99% compared to rerunning all cells and is up
to 3.92× faster than the next best alternative. (§7.4)

4. Low Runtime Overhead: ElasticNotebook incurs negligible
overhead—amortized runtime and memory overhead of <2.5%
and <10%, respectively. (§7.5)

3Replication may be unfeasible due to annotations, e.g., an unserializable variable
requiring an cell execution annotated ’never-rerun’ to recompute. ElasticNotebook can
detect these cases as they have infinite min-cut cost (§5.4), upon which the user can be
warned to delete the problematic variable to proceed with replicating the remaining
(majority of) variables in the state.

ElasticNotebook: Enabling Live Migration for Computational Notebooks

Table 3: Summary of datasets for evaluation.

Dataset
Notebooks Runtime (s) Input data (MB) Cell count
Kaggle [57]
35
JWST [60]
5
5
Tutorial [107]
HW [13, 46, 66] 15

107–12,560
2–109
1–139
16–439

178-31831
25–323
10–96
9–1203

15–103
21–44
10–48
11–160

5. Low Storage Overhead: ElasticNotebook’s checkpoint sizes

are up to 66% smaller compared to existing tools. (§7.6)

6. Adaptability to System Environments: ElasticNotebook
achieves consistent savings across various environments with
different network speeds and available compute resources. (§7.7)
7. Scalability for Complex Notebooks: ElasticNotebook’s run-
time and memory overheads remain negligible (<150ms, <4MB)
even for complex notebooks with 2000 cells. (§7.8)

7.1 Experiment Setup
Datasets. We select a total of 60 notebooks from 4 datasets:
• Kaggle [57]: We select 35 popular notebooks on the topic of EDA
(exploratory data analysis) + machine learning from Kaggle
created by Grandmaster/Master-level users.

• JWST [60]: We select 5 notebooks on the topic of data pipelining
from the example notebooks provided on investigating data
from the James Webb Space Telescope (JWST).

• Tutorial [107]: We select 5 notebooks from the Cornell Vir-
tual Workshop Tutorial. These notebooks are lightweight and
introduce tools (i.e., clustering, graph analysis) to the user.
• Homework [13, 46, 66]: 15 in-progress notebooks are chosen
from data science exercises. They contain out-of-order cell exe-
cutions, runtime errors, and mistakes (e.g., df_backup=df4).
Table 3 reports our selected notebooks’ dataset sizes and runtimes.

Methods. We evaluate ElasticNotebook against existing tools ca-
pable of performing session replication:
• RerunAll [102]: Save (only) cell code and outputs as an ipynb

file. All cells are rerun to restore the session state.

• CRIU [18]: Performs a system-level memory dump of the pro-
cess hosting the notebook session. The session state is restored
by loading the memory dump and reviving the process.

• %Store [104]: A checkpointing tool that serializes variables one
by one into storage. We use a modified version using Dill [39]
instead of Pickle [38] for robustness.5

• DumpSession [40]: Unlike %Store, DumpSession packs the en-

tire session state into one single file.

Ablation Study. We additionally compare against the following
ablated implementations of ElasticNotebook:
• ElasticNotebook + Helix [116]: We replace our min-cut solution
with Helix, which does not consider linked variables (§5.3).
• EN (No ID graph): This method omits ID Graphs, relying only on
AST analysis and object hashes for detecting variable accesses
and modifications, respectively.

4This creates a shallow copy of df, which does not serve the purpose of backup.
5The original implementation of %store uses Python Pickle [38], and fails on too many
notebooks to give meaningful results.

RerunAll

%Store

EN (No ID graph)
100%
80%
60%
40%
20%
0%

)

%

(

e
t
a
r

s
s
e
c
c
u
S

CRIU (same architecture)
DumpSession

ElasticNotebook (Ours)

CRIU (cross-architecture)
ElasticNotebook + Helix

e
r
u
l
i
a
f
%
0
0
1

Figure 9: Ratio of correct replications. ElasticNotebook
achieves 100% correctness, on par with full rerun (RerunAll).

Table 4: Existing work fails for these cases. Ours works.

Notebook(s)
NFL [88]

All 5 JWST
notebooks [60]

Arxiv [70]
Plant [94]

Type
hashlib [33]

mmap [36]

Description and purpose
Dropdown list in plot

Helps avoid reading large file
into memory

generator [32]

Speedup iterable comprehension
via lazy element generation

We consider these methods regarding replication correctness (§7.2)
to gauge the impact of ignoring (1) the linked constraint and (2)
implicit accesses and structural modifications, respectively.

Environment. We use an Azure Standard D32as v5 VM instance
with 32 vCPUs and 128 GB RAM. For the migration experiment
(§7.3), we migrate sessions from D32as to D64as/D16as with 64/16
vCPUs and 256/64 GB RAM for upscaling/downscaling, respectively.
Input data and checkpoints are read/stored from/to an Azure stor-
age with block blobs configuration (NFS). Its network bandwidth is
274 MB/s with a read latency of 175 𝜇𝑠.

Time measurement. We measure (1) migration time as the time
from starting the checkpointing process to having the state restored
(i.e., all variables declared into the namespace) in the destination
session and (2) restoration time as the time to restore the state from
a checkpoint file. We clear our cache between (1) checkpointing
and restoring a notebook and (2) between subsequent runs.

Reproducibility. Our implementation of ElasticNotebook, experi-
ment notebooks, and scripts can be found in our Github repository.6

7.2 Robust Session Replication
This section compares the robustness of ElasticNotebook’s session
replication to existing methods. We count the number of isomorphic
(thus, correct) replications (§5.1) achieved with each method on the
60 notebooks and report the results in Fig 9.

ElasticNotebook correctly replicates all sessions, on par with
full rerun from checkpoint file (which almost always works). No-
tably, it replicates 19, 25, and 2 notebooks containing unserializable
variables, variable aliases, and undeserializable variables (§6.1), re-
spectively. DumpSession and %Store fail on 19/60 notebooks con-
taining unserializable variables, many of which are used to enhance
data science workflow efficiency (examples in Table 4); ElasticNote-
book successfully replicates them as it can bypass the serialization
of these variables through recomputation. %Store additionally fails
on 21/60 notebooks (total 40/60) without unserializable variables
but contain variable aliases (i.e., Timeseries [89] notebook, Cell 15,

6https://github.com/illinoisdata/ElasticNotebook

RerunAll

CRIU

100%

100%

100%

100%

%Store
49%

DumpSession

ElasticNotebook (Ours)

100%

100%

100%

100%

100%

51%

100%

100%

84%

100%

60%86%

Zhaoheng Li, Pranav Gor, Rahul Prabhu, Hui Yu, Yuzhou Mao, Yongjoo Park

Sklearn [109]

NLP [2]

StoreSales [7] TPS-Mar [113]

Glove [92]

Trading [95] Timeseries [80] Stacking [24] Agriculture [109] LANL [87]

HW-LM [45] HW-ex3 [67]

l
l

A
n
u
r
e
R
f
o
%
e
m
T

i

40%
30%
20%
10%
0%

Figure 10: ElasticNotebook’s session upscaling time (D32as v5 VM→D64as v5 VM) vs. existing tools. Times normalized w.r.t.
RerunAll. ElasticNotebook speeds up migration by 85%-98% and is up to 2.07× faster than the next best alternative.

l
l

A
n
u
r
e
R
f
o
%
e
m
T

i

20%
15%
10%
5%
0%

RerunAll

100%

100%

CRIU

100%

%Store

DumpSession

ElasticNotebook (Ours)

100%

100%

100%

100%

100%

100%

31%

100%

29%

100%

24%

100%

25%

Sklearn [109]

NLP [2]

StoreSales [7] TPS-Mar [113]

Glove [92]

Trading [95] Timeseries [80] Stacking [24] Agriculture [109] LANL [87]

HW-LM [45] HW-ex3 [67]

Figure 11: ElasticNotebook’s session restoration time vs. existing tools. Times normalized w.r.t. RerunAll. ElasticNotebook
speeds up session restore by 94%-99%, and is up to 3.92× faster compared to the next best alternative.

Table 5: Runtime and memory overhead of ElasticNotebook’s workflow monitoring on selected notebooks.

Notebook runtime (s)
Total cell monitoring time (s)
Runtime overhead (%)
User Namespace memory usage (MB) 1021.45
ElasticNotebook memory usage (MB) 19.16
1.88
Memory overhead (%)

Sklearn
58.48
1.26
2.14

NLP
1016.77
4.30
0.42
325.82
4.73
1.45

StoreSales TPS-Mar Glove
696.64
178.42
283.06
6.43
1.34
0.81
0.92
0.78
0.28
347.16
1558.52
6732.17
33.25
1.69
0.14
9.58
0.11
0.002

Trading
687.54
0.46
0.07
1363.32
4.09
0.30

Timeser.
204.10
0.60
0.29
130.27
0.28
0.21

Stacking Agricult. LANL
269.40
788.54
3.08
2.13
1.14
0.27
5026.48
20211.51
0.06
0.33
0.001
0.002

1437.87
0.19
0.01
7641.19
0.14
0.001

HW-LM HW-ex3
22.54
0.50
2.21
31.28
0.99
3.16

27.29
0.09
0.32
19.06
0.47
2.45

linked components of a Matplotlib [105] plot—f,fig,ax) ; it serial-
izes variables into individual files, which breaks object references
and isomorphism. ElasticNotebook’s linked variables constraint
(§5.3) ensures that it does not do so. ElasticNotebook + Helix fails
to correctly replicate 5/60 notebooks containing variable aliases due
to its lacking of the linked variable constraint. EN (No ID graph)
fails to correctly replicate 11/60 sessions due to it missing indirect
accesses and structural modifications causing incorrect construc-
tion of the AHG, which in turn leads it to recompute some variables
value-incorrectly. CRIU fails on one notebook [90] which contains
an invisible file; however, unlike ElasticNotebook’s failures, this
failure is currently a fundamental limitation in CRIU [17].
Robust Migration across System Architectures. We additionally
performed session replication from our D32as VM (x64 architecture)
to a D32pds V5 VM instance (arm64 architecture). The CRIU images
cannot be replicated across machines with different architectures.
In contrast, ElasticNotebook does not have such a limitation.

7.3 Faster Session Migration
This section compares the efficiency of ElasticNotebook’s session
migration to existing methods. We choose 10 notebooks with no
unserializable variables (otherwise, existing methods fail) to com-
pare the end-to-end session migration time achieved by different
methods. We report upscaling and downscaling results in Fig 10
and Fig 16, respectively.

The design goal of ElasticNotebook is to reduce session replica-
tion time through balancing variable storage and recomputation,
which is successfully reflected as follows. ElasticNotebook is able
to reduce session migration time to the upscaled/downscaled VMs
by 85%–98%/84%-99% compared RerunAll. Compared to DumpSes-
sion, %Store, and CRIU, which store all variables in the checkpoint

file, ElasticNotebook upscales/downscales up to 2.07×/2.00× faster
than the best of the three. DumpSession, while being the next best
alternative for upscaling/downscaling on 8/9 notebooks, falls short
in robustness as demonstrated in §7.2. %Store’s individual reading
and writing of each variable results in high overhead from multiple
calls to the NFS for each migration. CRIU is the slowest non-rerun
method for upscaling/downscaling on 6/7 notebooks, due to the
size of its memory dump (higher I/O during migration) being up to
10× larger compared to checkpoint files from native tools (§7.6).

7.4 Faster Session Restoration
In this section, we compare the efficiency of ElasticNotebook’s
session restoration to existing methods. We generate checkpoint
files using each method, then compare the time taken to restore
the session from the checkpoint files on the 10 notebooks from
§7.3. For ElasticNotebook, we set the coefficient 𝛼 to 0.05 (§5.2) to
emphasize session restoration time heavily.

We report the results in Fig 10. ElasticNotebook’s restoration
time is 94%–99% faster compared to full rerun. Compared to the
baselines, ElasticNotebook is 3.92× faster than the next best alter-
native. These fast restoration can be attributed to ElasticNotebook
capable of adapting to the new optimization objective, unlike the
baselines: for example, on the Sklearn [109] notebook, instead of re-
running cell 3 (df = pd.read_csv(...)) to re-read the dataframe
df into the session as in the migration-centric plan, the restoration-
centric plan opts to store df instead. The reasoning is that despite
the sum of serialization and deserialization times of df being greater
than the re-reading time with pd.read_csv (6.19s + 1.17s > 5.5s),
the deserialization time by itself is less than the re-reading time
(1.17s < 5.5s); hence, storing df is the optimal choice.

ElasticNotebook: Enabling Live Migration for Computational Notebooks

RerunAll
DumpSession
1048%

CRIU
ElasticNotebook (Ours)
283%

388%

467%

%Store

1137%

200%
150%
100%
50%

S
D

f
o
%
e
z
i
S

0.5%

0.4%

5.6%

2.6%

0.1%

0.5%

NLP[2]

TPS[113] Trading[95] Timeseries[80]Agriculture[109] HW-LM [45]

Figure 12: ElasticNotebook’s checkpoint file size vs. exist-
ing tools. Times normalized w.r.t. output from DumpSession.
ElasticNotebook’s checkpoint file size is up to 67% smaller
compared to those from existing tools (excluding RerunAll).

7.5 Low Runtime Overhead
This section investigates the overhead of ElasticNotebook’s note-
book workflow monitoring. We measure ElasticNotebook’s total
time spent in pre/post-processing steps before/after each cell execu-
tion for updating the AHG and cell runtimes (Total cell monitoring
time), and total storage space taken to store the AHG, ID Graphs,
and hashes at checkpoint time (ElasticNotebook memory usage).

We report the results in Table 5. ElasticNotebook’s cell monitor-
ing incurs a maximum and median runtime overhead of (only) 2.21%
and 0.6%; thus, ElasticNotebook can be seamlessly integrated into
existing workflow. ElasticNotebook is similarly memory-efficient
as its stored items (AHG, ID Graphs, and hashes) are all metadata
largely independent of the size of items in the session: the median
memory overhead is 0.25%, with the worst case being 9.58%.
Fine-grained Analysis. To study the per-cell time and memory
overheads during experimental notebook usage, we examined three
notebooks from Homework category to confirm the maximum time
and memory overheads were 92ms and 4.9MB, respectively. We
report details in Appendix A.1.

7.6 Lower Storage Overhead
This section measures the storage cost of ElasticNotebook’s check-
point files: we compare the migration-centric checkpoint file sizes
from ElasticNotebook and those from other baseline methods.

We report select results in Fig 12. ElasticNotebook’s AHG al-
lows it to choose between storing and recomputing each variable,
reflected in ElasticNotebook’s checkpoint files being up to 67%
smaller compared to DumpSession’s. For example, on the Agri-
culture [89] notebook, ElasticNotebook recomputes the train-test
splits of the input dataframes X and Y (Cell 5, x_train, x_test,...
= train_test_split(X, Y)) instead of storing them in the check-
point file: this saves considerable storage space (2.5GB) in addition
to speeding up migration. Conversely, CRIU’s checkpoint file sizes
can be 10× larger than ElasticNotebook’s as it additionally dumps
memory occupied by the Python process itself and imported mod-
ules, no matter necessary or not, into the checkpoint file. Output
sizes from RerunAll (i.e., notebook metadata size consisting of cell
code and outputs) are provided for comparison. While metadata
are significantly smaller than checkpoint files, the storage benefit
is offset by significantly slower session recovery times (§7.4).

7.7 Performance Gains Across Environments
This section demonstrates ElasticNotebook’s operation in environ-
ments with varying specifications. We perform a parameter sweep

ElasticNotebook Migrate Time
DumpSession

ElasticNotebook Recompute Time
RerunAll

)
s
(
e
m
T

i

)
s
(
e
m
T

i

1,250
1,000
750
500
250
0

2,000
1,500
1,000
500
0

1600 800 400 200 100 50
Network bandwidth (Mbps)
(a) AI4CODE [53]

1600 800 400 200 100 50
Network bandwidth (Mbps)

)
s
(
e
m
T

i

2,500
2,000
1,500
1,000
500
0

)
s
(
e
m
T

i

500
400
300
200
100
0

1600 800 400 200 100 50
Network bandwidth (Mbps)
(b) Stacking [24]

1600 800 400 200 100 50
Network bandwidth (Mbps)

(c) Agriculture [89]

(d) Asset [95]

Figure 13: ElasticNotebook adapts to different environments
for its replication plan. The lower the network bandwidth,
the more variables are recomputed.
Twitter [110]

Interactive [108]

Sklearn [109]

)
B
M

(
d
a
e
h
r
e
v
O

4
3
2
1
0

)
s

m

(

e
m
T

i

0

500
1500
1000
No. cell executions

2000

(a) AHG size

150

100

50

0

0

500
1500
1000
No. cell executions
(b) Optimization Time

2000

Figure 14: Scalability of ElasticNotebook with cell execution
count. The size of AHG increases linearly. Replication plan
optimization time increases sub-linearly.

on the NFS network bandwidth via rate limiting [10] and compare
the migration time of ElasticNotebook, DumpSession (migrating
all variables), and RerunAll.

We report the results in Fig 13. ElasticNotebook’s balancing of
variables storage and recomputation ensures that it is always at least
as fast as the faster of DumpSession and RerunAll. Notably, Elastic-
Notebook can adapt to the relative availability between network
bandwidth and compute power: as the bandwidth decreases, the
replication plan is changed accordingly to migrate more variables
through recomputation rather than storage. For example, on the
Stacking [24] notebook, at regular bandwidth (>400Mbps), Elastic-
Notebook’s replication plan includes migrating most of the session
state, opting only to recompute certain train/test splits (i.e., Cell 37,
Y_train, Y_validation). At <400 Mbps, ElasticNotebook modifies
its plan to recompute instead of store a computationally expensive
processed dataframe (Cell 39, latest_record). At <100 Mbps, Elas-
ticNotebook modifies its plan again to only store the imported class
and function definitions (i.e., XGBRegressor, mean_squared_error
in Cell 1) while recomputing the rest of the notebook.

7.8 Scaling to Complex Workloads
In this section, we test the scalability of ElasticNotebook’s session
replication on complex notebook sessions with a large number of
cell executions and re-executions. Specifically, we choose 3 tutorial
notebooks, on which we randomly re-execute cells and measure
the (1) size of ElasticNotebook’s AHG and (2) optimization time for
computing the replication plan at up to 2000 cell re-executions7.

7This is twice the length of the longest observed notebook on Kaggle [50].

We report the results in Fig 14. The memory consumption of Elas-
ticNotebook’s AHG exhibits linear scaling vs. the number of cell
executions reaching only <4MB at 2000 cell re-executions, which
is negligible compared to the memory consumption of the note-
book session (>1GB) itself. ElasticNotebook’s optimization time
for computing the replication plan similarly exhibits linear scaling,
reaching a negligible <150ms at 2000 cell re-executions: ElasticNote-
book’s chosen algorithm for solving min-cut, Ford-Fulkerson [30],
has time complexity 𝑂 (𝐸 𝑓 ), where 𝐸 is the number of edges in the
AHG and 𝑓 is the cost of the optimal replication plan: The former
scales linearly while the latter is largely constant.

8 RELATED WORK
Intermediate Result Reuse in Data Science. The storage of in-
termediate results has been explored in various contexts in Data
Science due to the incremental and feed-forward nature of tasks,
which allows outputs from prior operations to be useful for speed-
ing up future operations [42, 55, 65, 111, 116, 117, 122]. Examples
include caching to speed up model training replay for ML model di-
agnosis [42, 111], caching to speed up anticipated future dataframe
operations in notebook workflows [117], and storage of cell out-
puts to facilitate graphical exploration of the notebook’s execu-
tion history for convenient cell re-runs [55, 65]. There are related
works [116, 122] which algorithmically explore the most efficient
way to (re)compute a state given currently stored items; compared
to our work, while Helix [116] similarly features balancing loading
and recomputation, its model lacks the linked variable constraint
which may result in silently incorrect replication if directly applied
to the computational notebook problem setting.

Data-level Session Replication. Session replication on Jupyter-
based platforms can be performed with serialization libraries [34, 35,
38, 39, 78]. There exists a variety of checkpoint tools built on these
serialization libraries: IPython’s %Store [104] is a Pickle-based [38]
interface for saving variables to a key-value store; however, it breaks
object references as linked variables are serialized into separate
files. The Dill-based [39] DumpSession [40] correctly resolves ob-
ject references, yet it still fails if the session contains unserializable
objects. Tensorflow [49] and Pytorch [29] offer periodical check-
pointing during ML model training limited to objects within the
same library. Jupyter’s native checkpointing mechanism [102] only
saves cell metadata and often fails to exactly restore a session due to
the common presence of hidden states. Compared to existing data-
level tools, session replication with ElasticNotebook is both more
efficient and robust: the Application History Graph enables balanc-
ing state storage and recomputation, which achieves considerable
speedup while avoiding failure on unserializable objects.

System-Level Session Replication. Session replication can sim-
ilarly be performed using system-level checkpoint/restart (C/R)
tools, on which there is much existing work [6, 6, 8, 12, 23, 52, 72,
77, 96]. Applicable tools include DMTCP [3] and CRIU [18]; recently,
CRUM [43] and CRAC [61] have explored extending C/R to CUDA
applications. Elsa [64] integrates CRIU with JupyterHub to enable
C/R of JupyterHub servers. Compared to ElasticNotebook, system-
level tools are less efficient and robust due to their large memory
dump sizes and limited cross-platform portability, respectively.

Zhaoheng Li, Pranav Gor, Rahul Prabhu, Hui Yu, Yuzhou Mao, Yongjoo Park

Lineage Tracing. Lineage tracing has seen extensive use in state
management to enable recomputation of data for more efficient
storage of state or fault tolerance [16, 51, 71, 82, 106, 111, 120]
Recently, the usage of data lineage in computational notebooks
has enabled multi-version notebook replay [76], recommending
notebook interactions [75], and creating reproducible notebook
containers [1], and program slicing, i.e., finding the minimal set of
code to run to compute certain variable(s) [51, 54, 65, 83, 93]. This
work adopts lineage tracing techniques to capturing inter-variable
dependencies (the Application History Graph) for optimization; to
the best of our knowledge, existing works on Python programs
focus on capturing value modifications (via equality comparisons);
however, our techniques additionally identifies and captures strucal
changes via the ID graph, which is crucial for preserving variable
aliases and avoiding silent errors during state replication.
Replicating Execution Environment. An identical execution en-
vironment may be necessary for session replication on a different
machine. There is some recent work exploring environment repli-
cation for Jupyter Notebook via containerizing input files and mod-
ules [1, 115]. While useful in conjunction with ElasticNotebook,
we consider these works to be largely orthogonal.
Notebook Parameterization and Scripts. There exists works on
executing notebooks in parameterized form for systematic experi-
mentation (e.g., in the form of a script via [99] or papermill [100]).
While ElasticNotebook is designed for use within interactive note-
book interfaces, it is similarly applicable for the migration of pa-
rameterized notebook execution results.

9 CONCLUSION
In this work, we have proposed ElasticNotebook, a new computa-
tional notebook system that newly offers elastic scaling and check-
pointing/restoration. To achieve this, ElasticNotebook introduces
a transparent data management layer between the user interface
and the underlying kernel, enabling robust, efficient, and platform-
independent state replication for notebook sessions. Its core con-
tributions include (1) low-overhead, on-the-fly application history
construction and (2) a new optimization for combining copying and
re-computation of variables that comprise session states. We have
demonstrated that ElasticNotebook can reduce upscaling, down-
scaling, and restoration times by 85%-98%, 84%-99%, and 94%-99%,
respectively, on real-world data science notebooks with negligible
runtime and memory overheads of <2.5% and <10%, respectively.
In the future, we plan to achieve higher efficiency and usability by
tracing state changes at a finer level. Specifically, we will introduce
micro-cells to capture code blocks inside a cell that repeatedly runs
(e.g., for-loop for machine learning training). Then, the system will
automatically store intermediate models (along with other meta-
data) that will enable live migration and checkpointing/restoration
for long-running cell executions.

ACKNOWLEDGMENTS
The authors are grateful to Chandra Chekuri and Kent Quanrud for
assistance with the derivation of the reduction to min-cut employed
in ElasticNotebook. This work is supported in part by the National
Center for Supercomputing Applications and Microsoft Azure.

ElasticNotebook: Enabling Live Migration for Computational Notebooks

REFERENCES

[1] Raza Ahmad, Naga Nithin Manne, and Tanu Malik. 2022. Reproducible Notebook
Containers using Application Virtualization. In 2022 IEEE 18th International
Conference on e-Science (e-Science). IEEE, 1–10.

[2] AndresHG. 2021. NLP, GloVe, BERT, TF-IDF, LSTM... Explained. https://www.
kaggle.com/code/andreshg/nlp-glove-bert-tf-idf-lstm-explained/notebook.
Jason Ansel, Kapil Arya, and Gene Cooperman. 2009. DMTCP: Transparent
checkpointing for cluster computations and the desktop. In 2009 IEEE Interna-
tional Symposium on Parallel & Distributed Processing. IEEE, 1–12.

[4] Microsoft Azure. 2023. Azure ML Studio. https://learn.microsoft.com/en-

[3]

us/azure/machine-learning/how-to-run-jupyter-notebooks.

[5] Microsoft Azure. 2023. Microsoft Azure pay-as-you-go. https://azure.microsoft.

com/en-us/pricing/purchase-options/pay-as-you-go/.

[6] Anju Bala and Inderveer Chana. 2012. Fault tolerance-challenges, techniques
and implementation in cloud computing. International Journal of Computer
Science Issues (IJCSI) 9, 1 (2012), 288.

[7] Ekrem Bayar. 2022.

Store Sales TS Forecasting - A Comprehensive
Guide. https://www.kaggle.com/code/ekrembayar/store-sales-ts-forecasting-a-
comprehensive-guide/notebook.

[8] Mohammad Riyaz Belgaum, Safeeullah Soomro, Zainab Alansari, and Muham-
mad Alam. 2018. Cloud service ranking using checkpoint-based load balancing
in real-time scheduling of cloud computing. In Progress in advanced computing
and intelligent engineering. Springer, 667–676.
James Bergstra and Yoshua Bengio. 2012. Random search for hyper-parameter
optimization. Journal of machine learning research 13, 2 (2012).

[9]

[10] Simon Séhier Bert Hubert, Jacco Geul. 2020. WonderShaper. https://github.

com/magnific0/wondershaper.

[11] Michael Brachmann and William Spoth. 2020. Your notebook is not crumby
enough, REPLace it. In Conference on Innovative Data Systems Research (CIDR).
[12] Gang Chen, Hai Jin, Deqing Zou, Bing Bing Zhou, Weizhong Qiang, and Gang
Hu. 2010. Shelp: Automatic self-healing for multiple application instances in a
virtual machine environment. In 2010 IEEE International Conference on Cluster
Computing. IEEE, 97–106.

[13] Chhaya Choudhary. 2023. Machine Learning and Deep learning Notebooks.

https://github.com/chhayac/Machine-Learning-Notebooks.

[14] Chhaya Choudhary. 2023. This project is about customer churn predic-
tion. https://github.com/chhayac/Machine-Learning-Notebooks/blob/master/
customer_churn_prediction.ipynb.

[15] Bokeh Contributors. 2023. Bokeh - Interaction. https://docs.bokeh.org/en/

[16]

latest/docs/user_guide/interaction.html.
Iván Cores, Gabriel Rodríguez, Mará J Martín, Patricia González, and Roberto R
Osorio. 2013. Improving scalability of application-level checkpoint-recovery by
reducing checkpoint sizes. New Generation Computing 31 (2013), 163–185.

[17] CRIU. 2023. CRIU - Invisible file. https://criu.org/Invisible_files.
[18] CRIU. 2023. Linux CRIU. https://criu.org/Main_Page.
[19] Andrew Crotty, Alex Galakatos, Emanuel Zgraggen, Carsten Binnig, and Tim
Kraska. 2015. Vizdom: interactive analytics through pen and touch. Proceedings
of the VLDB Endowment 8, 12 (2015), 2024–2027.
JupyterHub Idle Culler. 2023.
jupyterhub/jupyterhub-idle-culler.

JupyterHub Idle Culler. https://github.com/

[20]

[21] Renato LF Cunha, Lucas C Villa Real, Renan Souza, Bruno Silva, and Marco AS
Netto. 2021. Context-aware Execution Migration Tool for Data Science Jupyter
Notebooks on Hybrid Clouds. In 2021 IEEE 17th International Conference on
eScience (eScience). IEEE, 30–39.

[22] Nvidia Developer. 2023. Nvidia - CUDA. https://developer.nvidia.com/cuda-

toolkit.

[23] Sheng Di, Yves Robert, Frédéric Vivien, Derrick Kondo, Cho-Li Wang, and
Franck Cappello. 2013. Optimization of cloud task processing with checkpoint-
restart mechanism. In Proceedings of the International Conference on High Per-
formance Computing, Networking, Storage and Analysis. 1–12.

[24] DimitreOliveira. 2019. Model stacking, feature engineering and EDA.
https://www.kaggle.com/code/dimitreoliveira/model-stacking-feature-
engineering-and-eda/notebook.

[25] Docker. [n.d.]. Docker documentation - Swarm mode overview. https://docs.

docker.com/engine/swarm/.

[26] Cody Dunne, Nathalie Henry Riche, Bongshin Lee, Ronald Metoyer, and George
Robertson. 2012. GraphTrail: Analyzing large multivariate, heterogeneous
networks while supporting exploration history. In Proceedings of the SIGCHI
conference on human factors in computing systems. 1663–1672.

[27] dwd daniel. 2022.

UncomplicatedFirewall.

https://wiki.ubuntu.com/

UncomplicatedFirewall.

[28] Philipp Eichmann, Emanuel Zgraggen, Carsten Binnig, and Tim Kraska. 2020.
Idebench: A benchmark for interactive data exploration. In Proceedings of the
2020 ACM SIGMOD International Conference on Management of Data. 1555–1569.
https://pytorch-

[29] Lightning AI et al. 2018.

PyTorch ModelCheckpoint.

lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.
ModelCheckpoint.html.

[30] LRDR FORD-FULKERSON. 1962. Flows in Networks.
[31] Python Software Foundation. 2023. Python - AST. https://docs.python.org/3/

library/ast.html.

[32] Python Software Foundation. 2023. Python - Generators. https://wiki.python.

org/moin/Generators.

[33] Python Software Foundation. 2023. Python Hashlib. https://docs.python.org/3/

library/hashlib.html.

[34] Python Software Foundation. 2023. Python JSON. https://docs.python.org/3/

library/json.html.

[35] Python Software Foundation. 2023. Python Marshal. https://docs.python.org/3/

library/marshal.html.

[36] Python Software Foundation. 2023. Python Mmap. https://docs.python.org/3/

library/mmap.html.

[37] Python Software Foundation. 2023. Python Object Reduction. https://docs.

python.org/3/library/pickle.html#object.__reduce__.

[38] Python Software Foundation. 2023. Python Pickle Documentation. https:

//docs.python.org/3/library/pickle.html.

[39] The Uncertainty Quantification Foundation. 2023. Dill - PyPi. https://pypi.org/

project/dill/.

[40] The Uncertainty Quantification Foundation. 2023. Dill dump session. https:

//dill.readthedocs.io/en/latest/dill.html.

[41] Tian Gao. 2020. Python Watchpoints. https://pypi.org/project/watchpoints/.
[42] Rolando Garcia, Eric Liu, Vikram Sreekanti, Bobby Yan, Anusha Dandamudi,
Joseph E Gonzalez, Joseph M Hellerstein, and Koushik Sen. 2020. Hindsight
logging for model training. arXiv preprint arXiv:2006.07357 (2020).

[43] Rohan Garg, Apoorve Mohan, Michael Sullivan, and Gene Cooperman. 2018.
CRUM: Checkpoint-restart support for CUDA’s unified memory. In 2018 IEEE
International Conference on Cluster Computing (CLUSTER). IEEE, 302–313.

[44] GDB. 2022. GDB Watchpoints.

https://sourceware.org/gdb/download/

onlinedocs/gdb/Set-Watchpoints.html.

[45] Aurélien Geron. 2023. Chapter 4 – Training Models. https://github.com/ageron/

handson-ml3/blob/main/04_training_linear_models.ipynb.

[46] Aurélien Geron. 2023. Machine Learning Notebooks, 3rd edition. https://github.

com/ageron/handson-ml3.

[47] Google. 2023. Google Colab. https://colab.research.google.com/.
[48] Google. 2023. Google Colab pay-as-you-go. https://colab.research.google.com/

signup.

[49] Google. 2023. Tensorflow Checkpoint. https://www.tensorflow.org/guide/

checkpoint.

[50] Google and X. 2022. Google AI4Code – Understand Code in Python Notebooks.

https://www.kaggle.com/competitions/AI4Code.

[51] Philip J Guo and Margo I Seltzer. 2012. Burrito: Wrapping your lab notebook in

computational infrastructure. (2012).

[52] HAProxy. 2023. HAProxy. http://www.haproxy.org/.
[53] Sanskar Hasija. 2022. AI4Code Detailed EDA. https://www.kaggle.com/code/

odins0n/ai4code-detailed-eda.

[55]

[54] Andrew Head, Fred Hohman, Titus Barik, Steven M Drucker, and Robert DeLine.
2019. Managing messes in computational notebooks. In Proceedings of the 2019
CHI Conference on Human Factors in Computing Systems. 1–12.
Inc. Hex Technologies. 2023. Hex 2.0: Reactivity, Graphs, and a little bit of
Magic. https://hex.tech/blog/hex-two-point-oh/.
IBM. 2022.
knowledge-accelerators/1.0.0?topic=catalog-jupyter-notebook.

IBM Watson Studio Service. https://www.ibm.com/docs/en/

[56]

[57] Kaggle Inc. 2023. Kaggle. https://www.kaggle.com/.
[58] Kaggle Inc. 2023. Kaggle Forums - Product Feedback. https://www.kaggle.com/

discussions/product-feedback.

[59] Kaggle Inc. 2023. Kaggle Notebook Specifications. https://www.kaggle.com/

docs/notebooks#technical-specifications.

[60] Space Telescope Science Institute. 2023.

JWST Data Analysis Exam-
ple. https://jwst-docs.stsci.edu/jwst-post-pipeline-data-analysis/data-analysis-
example-jupyter-notebooks.

[62]

[61] Twinkle Jain and Gene Cooperman. 2020. Crac: Checkpoint-restart architecture
for cuda with streams and uvm. In SC20: International Conference for High
Performance Computing, Networking, Storage and Analysis. IEEE, 1–15.
Jeremiah W Johnson. 2020. Benefits and pitfalls of jupyter notebooks in the
classroom. In Proceedings of the 21st Annual Conference on Information Technol-
ogy Education. 32–37.

[63] Project Jupyter. 2023. Jupyter Notebook. https://jupyter.org/.
[64] Mario Juric, Steven Stetzler, and Colin T Slater. 2021. Checkpoint, Restore, and
Live Migration for Science Platforms. arXiv preprint arXiv:2101.05782 (2021).
[65] David Koop and Jay Patel. 2017. Dataflow notebooks: encoding and tracking
dependencies of cells. In 9th USENIX Workshop on the Theory and Practice of
Provenance (TaPP 2017).

[66] Martin Krasser. 2023. Machine learning notebooks. https://github.com/

krasserm/machine-learning-notebook.

[67] Martin Krasser. 2023. Multi-class Classification. https://github.com/krasserm/

machine-learning-notebooks/blob/master/ml-ex3.ipynb.

[68] Kubernetes. [n.d.]. Kubernetes. https://kubernetes.io/.

[69] SFU Database System Lab. 2022. Dataprep - Low-Code Data Preparation. https:

[100] Nteract Team. 2023. Welcome to papermill. https://papermill.readthedocs.io/

//dataprep.ai/.

en/latest/.

[70] Colin Lagator. 2020. Arxiv Data Processing. https://www.kaggle.com/code/

[101] The IPython Development Team. 2023. IPython Interactive Computing. https:

colinlagator/arxiv-data-processing.

//ipython.org/.

Zhaoheng Li, Pranav Gor, Rahul Prabhu, Hui Yu, Yuzhou Mao, Yongjoo Park

[71] Haoyuan Li, Ali Ghodsi, Matei Zaharia, Scott Shenker, and Ion Stoica. 2014.
Tachyon: Reliable, memory speed storage for cluster computing frameworks.
In Proceedings of the ACM Symposium on Cloud Computing. 1–15.

[72] Yawei Li and Zhiling Lan. 2010. FREM: A fast restart mechanism for general

checkpoint/restart. IEEE Trans. Comput. 60, 5 (2010), 639–652.
[73] Arch Linux. 2023. chroot. https://wiki.archlinux.org/title/chroot.
[74] Zhicheng Liu and Jeffrey Heer. 2014. The effects of interactive latency on
exploratory visual analysis. IEEE transactions on visualization and computer
graphics 20, 12 (2014), 2122–2131.

[75] Stephen Macke, Hongpu Gong, Doris Jung-Lin Lee, Andrew Head, Doris Xin,
and Aditya Parameswaran. 2020. Fine-grained lineage for safer notebook
interactions. arXiv preprint arXiv:2012.06981 (2020).

[76] Naga Nithin Manne, Shilvi Satpati, Tanu Malik, Amitabha Bagchi, Ashish
Gehani, and Amitabh Chaudhary. 2022. CHEX: Multiversion Replay with
Ordered Checkpoints. arXiv preprint arXiv:2202.08429 (2022).

[77] Anjali D Meshram, AS Sambare, and SD Zade. 2013. Fault tolerance model for
reliable cloud computing. International Journal on Recent and Innovation Trends
in Computing and Communication 1, 7 (2013), 600–603.
Inc. MongoDB. 2023. BSON. https://pymongo.readthedocs.io/en/stable/api/
bson/index.html.

[78]

[79] Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov, Richard
Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I Jordan,
et al. 2018. Ray: A distributed framework for emerging {AI} applications. In
13th {USENIX} Symposium on Operating Systems Design and Implementation
({OSDI} 18). 561–577.

[80] Rob Mulla. 2020. Time Series forecasting with Prophet. https://www.kaggle.

com/code/robikscube/time-series-forecasting-with-prophet.

[81] Devin Petersohn, Stephen Macke, Doris Xin, William Ma, Doris Lee, Xiangxi
Mo, Joseph E Gonzalez, Joseph M Hellerstein, Anthony D Joseph, and Aditya
Parameswaran. 2020. Towards scalable dataframe systems. arXiv preprint
arXiv:2001.00888 (2020).

[82] Arnab Phani, Benjamin Rath, and Matthias Boehm. 2021. LIMA: Fine-grained
Lineage Tracing and Reuse in Machine Learning Systems. In Proceedings of the
2021 International Conference on Management of Data. 1426–1439.
Joao Felipe Pimentel, Leonardo Murta, Vanessa Braganholo, and Juliana Freire.
2017. noWorkflow: a tool for collecting, analyzing, and managing provenance
from python scripts. Proceedings of the VLDB Endowment 10, 12 (2017).
[84] The pip developers. 2023. Pip Freeze. https://pip.pypa.io/en/stable/cli/pip_

[83]

freeze/.

[85] Olga Poppe, Qun Guo, Willis Lang, Pankaj Arora, Morgan Oslake, Shize Xu,
and Ajay Kalhan. 2022. Moneyball: proactive auto-scaling in Microsoft Azure
SQL database serverless. Proceedings of the VLDB Endowment 15, 6 (2022),
1279–1287.

[86] PBC Posit Software, PBC formerly RStudio. 2023. Posit RStudio. https://posit.

[102] The IPython Development Team. 2023. Jupyter checkpoint. https://jupyter-

server.readthedocs.io/en/latest/developers/contents.html.

[103] The IPython Development Team. 2023. Jupyter Magics Class. https://ipython.

readthedocs.io/en/stable/config/custommagics.html.

[104] The IPython Development Team. 2023. Jupyter store magic. https://ipython.

readthedocs.io/en/stable/config/extensions/storemagic.html.

[105] The Matplotlib Development Team. 2023. Matplotlib. https://matplotlib.org/.
[106] Quoc-Cuong To, Juan Soto, and Volker Markl. 2018. A survey of state manage-
ment in big data processing systems. The VLDB Journal 27, 6 (2018), 847–872.
[107] Cornell University. 2021. Cornell Virtual Workshop Tutorial Notebooks. https:

//github.com/CornellCAC/CVW_PyDataSci2.

[108] Cornell University. 2021. Investigating Tweet Timelines Using Interactive Bokeh
Scatterplots. https://github.com/CornellCAC/CVW_PyDataSci2/blob/master/
code/interactive_visualization_with_bokeh.ipynb.

[109] Cornell University. 2021.

SKLearn Tweet Classification.

https:

//github.com/CornellCAC/CVW_PyDataSci2/blob/master/code/sklearn_
tweet_classification.ipynb.

[110] Cornell University. 2021. Twitter Networks. https://github.com/CornellCAC/

CVW_PyDataSci2/blob/master/code/twitter_networks.ipynb.

[111] Manasi Vartak, Joana M F. da Trindade, Samuel Madden, and Matei Zaharia.
2018. Mistique: A system to store and query model intermediates for model
diagnosis. In Proceedings of the 2018 International Conference on Management of
Data. 1285–1300.

[112] Alexandre Verbitski, Anurag Gupta, Debanjan Saha, Murali Brahmadesam,
Kamal Gupta, Raman Mittal, Sailesh Krishnamurthy, Sandor Maurice, Tengiz
Kharatishvili, and Xiaofeng Bao. 2017. Amazon aurora: Design considerations
for high throughput cloud-native relational databases. In Proceedings of the 2017
ACM International Conference on Management of Data. 1041–1052.

[113] Devlikamov Vlad. 2022.

[TPS-Mar] Fast workflow using scikit-learn-
https://www.kaggle.com/code/lordozvlad/tps-mar-fast-workflow-

intelex.
using-scikit-learn-intelex/notebook.

[114] Eric-Jan Wagenmakers and Simon Farrell. 2004. AIC model selection using
Akaike weights. Psychonomic bulletin & review 11, 1 (2004), 192–196.
[115] Dimuthu Wannipurage, Suresh Marru, and Marlon Pierce. 2022. A Framework
to capture and reproduce the Absolute State of Jupyter Notebooks. arXiv
preprint arXiv:2204.07452 (2022).

[116] Doris Xin, Stephen Macke, Litian Ma, Jialin Liu, Shuchen Song, and Aditya
Parameswaran. 2018. Helix: Holistic optimization for accelerating iterative
machine learning. arXiv preprint arXiv:1812.05762 (2018).

[117] Doris Xin, Devin Petersohn, Dixin Tang, Yifan Wu, Joseph E Gonzalez, Joseph M
Hellerstein, Anthony D Joseph, and Aditya G Parameswaran. 2021. Enhancing
the interactivity of dataframe queries by leveraging think time. arXiv preprint
arXiv:2103.02145 (2021).

[118] xxHash. 2023. xxHash - Extremely fast non-cryptographic hash algorithm.

co/.

https://github.com/Cyan4973/xxHash.

[87] Gabriel Preda. 2019. LANL Earthquake EDA and Prediction. https://www.

[119] Yandex. 2023. CatBoost - open-source gradient boosting library. https://catboost.

kaggle.com/code/gpreda/lanl-earthquake-eda-and-prediction.

ai/.

[88] Kalilur Rahman. 2022.

NFL Data Bowl 2023 - Offensive Plays EDA.
https://www.kaggle.com/code/kalilurrahman/nfl-data-bowl-2023-offensive-
plays-eda/notebook.

[89] DS Rahul. 2020. Agricultural Drought Prediction. https://www.kaggle.com/

code/dsrhul/agricultural-drought-prediction.

[90] Mani Raj. 2022. Amex Dataset. https://www.kaggle.com/code/manirajheerakar/

amex-dataset.

[91] Amazon Web Services. 2023. AWS JupyterHub. https://docs.aws.amazon.com/

emr/latest/ReleaseGuide/emr-jupyterhub.html.

[92] Shahules. 2022. Basic EDA,Cleaning and GloVe. https://www.kaggle.com/code/

shahules/basic-eda-cleaning-and-glove/notebook.

[93] Shreya Shankar, Stephen Macke, Sarah Chasins, Andrew Head, and Aditya
Parameswaran. 2022. Bolt-on, compact, and rapid program slicing for notebooks.
Proceedings of the VLDB Endowment 15, 13 (2022), 4038–4047.

[94] shreyas thorat30. 2023. Plant disease classification SDP. https://www.kaggle.

com/code/shreyasthorat30/plant-disease-classification-sdp.

[95] Andrey Shtrauss. 2022. Building an Asset Trading Strategy. https://www.kaggle.
com/code/shtrausslearning/building-an-asset-trading-strategy/notebook.
[96] Stelios Sidiroglou, Oren Laadan, Carlos Perez, Nicolas Viennot, Jason Nieh,
and Angelos D Keromytis. 2009. Assure: automatic software self-healing using
rescue points. ACM SIGARCH Computer Architecture News 37, 1 (2009), 37–48.
[97] StackOverflow. 2019. Colab Session Timeout. https://stackoverflow.com/

questions/57113226/how-can-i-prevent-google-colab-from-disconnecting.

[98] Stitchfix. 2017. Nodebooks. https://github.com/stitchfix/nodebook.
[99]

Jupyter Development Team. 2023. nbconvert - Jupyter Notebook Conversion.
https://github.com/jupyter/nbconvert.

[120] Matei Zaharia, Mosharaf Chowdhury, Michael J Franklin, Scott Shenker, and
Ion Stoica. 2010. Spark: Cluster computing with working sets. In 2nd USENIX
Workshop on Hot Topics in Cloud Computing (HotCloud 10).

[121] Emanuel Zgraggen, Robert Zeleznik, and Steven M Drucker. 2014. Panoram-
icData: Data analysis through pen & touch. IEEE transactions on visualization
and computer graphics 20, 12 (2014), 2112–2121.

[122] Ce Zhang, Arun Kumar, and Christopher Ré. 2016. Materialization optimizations
for feature selection workloads. ACM Transactions on Database Systems (TODS)
41, 1 (2016), 1–32.

A APPENDIX
A.1 Low Per-cell overhead
We report the results for per-cell time and memory overheads on
3 Homework notebooks in Fig 15. ElasticNotebook’s memory and
per-cell monitoring overhead are consistently under 10% and 1ms,
respectively. There are occasionally ’spikes’ when certain cells
declaring/modifying complex variables are executed; for example,
the 60% and 91ms memory and time overheads of cell 28 in [46]
is attributed to constructing the ID Graph for a complex nested
list. However, even in this worst case, the time overhead is still

ElasticNotebook: Enabling Live Migration for Computational Notebooks

)
B
M

(
d
a
e
h
r
e
v
O

30

20

10

0

0

User namespace memory usage

20
60
40
No. cell executions

80

)
B
M

(
d
a
e
h
r
e
v
O

ElasticNotebook memory usage
40

30

20

10

0

0

5

10

15

No. cell executions

)
B
M

(
d
a
e
h
r
e
v
O

20

15

10

5

0

0

[45]

[67]

[14]

)
s

m

(

e
m
T

i

100

75

50

25

0

25

0

25%
50%
No. cell executions

75% 100%

10

5
20
No. cell executions

15

(a) Mem. overhead, [45]

(b) Mem. overhead, [67]

(c) Mem. overhead, [14]

(d) Per-cell time overhead

Figure 15: Runtime and memory overhead of ElasticNotebook during notebook use on selected homework notebooks. Memory
overhead is consistently low, and per-cell runtime overhead is negligible for most cell executions.

RerunAll

CRIU

%Store

DumpSession

ElasticNotebook (Ours)

100%
40%

50%

100%

100%

100%

100%

100%

100%

100%

100%

51%

100%

100%

84%

100%

55%

93%

30%

20%

10%

0%

Sklearn [109]

NLP [2]

StoreSales [7] TPS-Mar [113]

Glove [92]

Trading [95] Timeseries [80] Stacking [24] Agriculture [109] LANL [87]

HW-LM [45] HW-ex3 [67]

Notebook

l
l

A
n
u
r
e
R
f
o
%
e
m
T

i

Figure 16: ElasticNotebook’s session downscaling time (D32as v5 VM→D16as v5 VM) vs. existing tools. Times normalized w.r.t.
RerunAll. ElasticNotebook speeds up migration by 84%-99% and is up to 2.00× faster than the next best alternative.

be a an arbitrary variable, and (𝑥, 𝑡 G), (𝑥, 𝑡 G∗ ) be its active VSs in G
and G∗ respectively. There is 𝑡 G ≥ 𝑡 G∗ : if 𝑡 G > 𝑡 G∗ (due to falsely
implied non-overwrite modifications, i.e., gen in Fig 17) then there
must be a path from (𝑥, 𝑡 G) to (𝑥, 𝑡 G∗ ): (𝑥, 𝑡 G), 𝑐𝑡G
, (𝑥, 𝑡𝑘1 ), 𝑐𝑡𝑘1
,..., (𝑥, 𝑡𝑘𝑙 ), 𝑐𝑡𝑘𝑙
< 𝑡 G∗ and
, (𝑥, 𝑡 G∗ ), where 𝑡 G < 𝑡𝑘1
< ... < 𝑡𝑘𝑙
all contain false non-overwrite modifications to 𝑥. There-
𝑐𝑡𝑘1
, ..., 𝑐𝑡𝑘𝑙
fore, the subtree rooted at (𝑥, 𝑡 G) in G must be contained the subtree
rooted at (𝑥, 𝑡 G∗ ) in G∗, hence 𝑟𝑒𝑞∗ (𝑥, 𝑡 G∗ ) ⊆ 𝑟𝑒𝑞(𝑥, 𝑡 G).
□

A.3 Handling Large Pandas Dataframes
To avoid hashing large Pandas dataframes after each cell execution,
ElasticNotebook uses the dataframes’ underlying writeable flag as
a dirty bit to detect in-place changes: before each cell execution, the
writeable flag is set to False, and the dataframe is identified as
modified if the flag has been flipped to True after the cell execution.

G

(x, 𝒕1)

𝒄𝒕1

𝒄𝒕2

(z, 𝒕2)
𝑐𝑡3

G∗

(x, 𝑡1)

(y, 𝑡1)

(y, 𝑡1)

𝑐𝑡1

𝒄𝒕2

(z, 𝒕2)
𝑐𝑡3

(x, 𝑡3)

(l1, 𝑡3)

(x, 𝑡3)

(l1, 𝑡3)

(gen, 𝒕4)

𝒄𝒕4

𝒄𝒕5

(2dlist, 𝑡4)

(gen, 𝒕4)

𝒄𝒕4

𝑐𝑡5

(2dlist, 𝑡4)

(gen, 𝒕5)

𝑟𝑒𝑞∗ (𝑥 ) = {𝑐𝑡2 } ⊆ 𝑟𝑒𝑞 (𝑥 ) = {𝑐𝑡1, 𝑐𝑡2 }
𝑟𝑒𝑞∗ (𝑔𝑒𝑛) = {𝑐𝑡4 } ⊆ 𝑟𝑒𝑞 (𝑔𝑒𝑛) = {𝑐𝑡4, 𝑐𝑡5 }

(x, 𝑡1)

(Overwritten/deleted)
Variable Snapshot

𝑐𝑡1

Cell
Execution

(x, 𝑡1)

Active
Variable Snapshot

Figure 17: AHG G may contain false positives compared to
the true AHG G∗. The correctness is still ensured, while the
efficiency may be affected due to extra cells re-running, for
example, when recomputing z (green) and gen (red).

well under the 500ms threshold suggested for interactive data en-
gines [74], while the memory overhead is of a low absolute value
(4MB) compared to the size of the (not yet loaded) datasets, thus
having negligible user impact.

A.2 Proof of Theorem 4.1
An illustration of our proof is provided in Fig 17.

Proof. As there are no false negatives, the true AHG G∗ is con-
tained within the approximate AHG G, i.e., G∗ ⊆ G (Fig 17). Let 𝑥

","ElasticNotebook : Enabling Live Migration for Computational Notebooks ( Technical Report ) Zhaoheng Li∗ , Pranav Gor∗ , Rahul Prabhu∗ , Hui Yu∗ , Yuzhou Mao+ , Yongjoo Park∗ University of Illinois at Urbana-Champaign∗ University of Michigan+ { zl20 , gor2 , rprabhu5 , huiy3 , yongjoo } @ illinois.edu , yuzhom @ umich.edu 3 2 0 2 p e S 0 2 ] B D . s c [ 1 v 3 8 0 1 1 . 9 0 3 2 : v i X r a ABSTRACT Computational notebooks ( e.g. , Jupyter , Google Colab ) are widely used for interactive data science and machine learning . In those frameworks , users can start a session , then execute cells ( i.e. , a set of statements ) to create variables , train models , visualize results , etc . Unfortunately , existing notebook systems do not offer live migra- tion : when a notebook launches on a new machine , it loses its state , preventing users from continuing their tasks from where they had left off . This is because , unlike DBMS , the sessions directly rely on underlying kernels ( e.g. , Python/R interpreters ) without an addi- tional data management layer . Existing techniques for preserving states , such as copying all variables or OS-level checkpointing , are unreliable ( often fail ) , inefficient , and platform-dependent . Also , re-running code from scratch can be highly time-consuming . In this paper , we introduce a new notebook system , Elastic- Notebook , that offers live migration via checkpointing/restoration using a novel mechanism that is reliable , efficient , and platform- independent . Specifically , by observing all cell executions via trans- parent , lightweight monitoring , ElasticNotebook can find a reliable and efficient way ( i.e. , replication plan ) for reconstructing the origi- nal session state , considering variable-cell dependencies , observed runtime , variable sizes , etc . To this end , our new graph-based opti- mization problem finds how to reconstruct all variables ( efficiently ) from a subset of variables that can be transferred across machines . We show that ElasticNotebook reduces end-to-end migration and restoration times by 85 % -98 % and 94 % -99 % , respectively , on a vari- ety ( i.e. , Kaggle , JWST , and Tutorial ) of notebooks with negligible runtime and memory overheads of < 2.5 % and < 10 % . PVLDB Reference Format : Zhaoheng Li∗ , Pranav Gor∗ , Rahul Prabhu∗ , Hui Yu∗ , Yuzhou Mao+ , Yongjoo Park∗ . ElasticNotebook : Enabling Live Migration for Computational Notebooks . PVLDB , 14 ( 1 ) : XXX-XXX , 2020. doi : XX.XX/XXX.XX 1 INTRODUCTION Computational notebooks1 ( e.g. , Jupyter [ 63 , 101 ] , Rstudio [ 86 ] ) are widely used in data science and machine learning for interactive tu- torials [ 62 ] , data exploration [ 19 , 26 , 121 ] , visualization [ 28 ] , model This work is licensed under the Creative Commons BY-NC-ND 4.0 International License . Visit https : to view a copy of this license . For any use beyond those covered by this license , obtain permission by emailing info @ vldb.org . Copyright is held by the owner/author ( s ) . Publication rights licensed to the VLDB Endowment . Proceedings of the VLDB Endowment , Vol . 14 , No . 1 ISSN 2150-8097. doi : XX.XX/XXX.XX 1In this work , we use the term a “ notebook ” to mean either a system serving the notebook or the contents of the notebook , depending on the context . User Interface Our Data Layer Kernel cell 1 ... code ... cell 2 ... code ... Technique 1 : dynamic exe- cution history in graph ( §4 ) Technique 2 : optimization for fast migration ( §5 ) Python R LLVM Figure 1 : Our transparent data layer ( in the middle ) enables robust , efficient , and platform-independent live migration . tuning and selection [ 9 , 114 ] , etc . Cloud providers offer Software- as-a-Services ( e.g. , AWS hub [ 91 ] , Azure ML studio [ 4 ] , Google Colab [ 47 ] , IBM Watson studio [ 56 ] ) with commonly used libraries ( e.g. , Pandas , PyTorch ) . A notebook workflow begins with a user starting a computing session . Then , the user can execute a cell ( i.e. , a set of statements ) , one by one , to load datasets , create variables , train models , visualize results , etc . The session can be terminated manually or automatically to save resources and costs . Limitation : No Live Replication . Unfortunately , existing note- books do not offer transparent infrastructure scaling ( independent of applications ) , which are becoming increasingly popular in the cloud for instant scalability and cost reduction ( e.g. , auto-scaling DBMS [ 85 , 112 ] , micro-service orchestration [ 25 , 68 ] ) . That is , if we copy a notebook file to a new VM ( e.g. , for larger memory ) or suspend a session to save costs , the resumed notebook loses its state ( i.e. , a set of variables ) , having only code and outputs . In other words , the user can not resume their task from where they had previously left off . This is because the notebooks directly rely on underlying kernels ( e.g. , Python/R interpreters , C++ REPL ) without an addi- tional data management layer . Accordingly , the variables residing in processes are erased as they terminate with sessions . To address this , we can potentially save those variables and restore them on a new environment . However , existing techniques such as serializing all variables [ 37–39 ] and checkpointing OS processes [ 3 , 18 , 43 , 61 ] may fail , are inefficient , and platform-dependent ( discussed shortly ) . Finally , re-running code from scratch can be time-consuming . Our Goal . We propose ElasticNotebook , a notebook system that offers live state migration via checkpointing/restoration using a reliable , efficient , and platform-independent state replication mech- anism . Reliability : It enables correct/successful replication for ( almost ) all notebooks . Efficiency : It is significantly more efficient than others . Platform-independence : It does not rely on platform- /architecture-specific features . That is , ElasticNotebook enables live notebook replication for potentially all notebook workloads by introducing a novel data management layer . For example , if a user specifies a new machine to run a currently active notebook , the system transparently replicates the notebook , including all of its variables , as if the notebook has been running on the new machine . Zhaoheng Li , Pranav Gor , Rahul Prabhu , Hui Yu , Yuzhou Mao , Yongjoo Park Table 1 : Comparison between our ElasticNotebook and other possible approaches to saving/restoring session states Approach Mechanism Serialization-based tools [ 35 , 38–40 , 104 ] System-level checkpointing [ 3 , 18 , 43 , 61 , 64 ] Notebook Versioning and Replay [ 11 , 76 , 98 ] Execution environment migration [ 1 , 115 ] Ours ( ElasticNotebook ) Serializes and stores variables during computing session ( fails with unserializable variables ) Saves memory dump of computing session ( high network cost and low portability ) Enable re-execution of versioned notebook snapshots for result verification Migrates installed modules ; useful in conjunction with ( but orthogonal to ) session state replication Optimally combines copy/recompute for reliability , efficiency , and platform independence If we can provide this capability with little to no modifications to existing systems ( e.g. , Jupyter ) , we can offer benefits to a large number of data scientists and educators who use notebooks . To achieve this , we must overcome the following technical challenges . Challenge . Creating a reliable , efficient , and platform-independent replication mechanism is challenging . First , the mechanism must offer high coverage . That is , for almost all notebooks people create , we should be able to successfully replicate them across machines . Second , the mechanism should be significantly faster than straight- forward approaches—rerunning all the cells exactly as they were run in the past , or copying , if possible , all the variables with serial- ization/deserialization . Third , the mechanism should integrate with existing notebook systems with clean separation for sustainable development and easier adoption . Our Approach . Our core idea is that by observing the evolution of session states via lightweight monitoring , we can address the three important challenges—reliability , efficiency , and platform- independence—by combining program language techniques ( i.e. , on- the-fly code analyses ) and novel algorithmic solutions ( i.e. , graph- based mathematical optimization ) . Specifically , to represent session state changes , we introduce the application history , a special form of bipartite graph expressing the dependencies among variables and cell executions . Using this graph , we take the following approach . First , we achieve reliability and platform independence by choos- ing a computational plan ( or replication plan ) that can safely re- construct platform-dependent variables ( e.g. , Python generators , incompletely defined custom classes ) based on the other platform- independent variables . That is , in the presence of variables that can not be serialized for platform-independent replication , Elas- ticNotebook uses the application history to recompute them dy- namically on a target machine . In this process , ElasticNotebook optimizes for the collective cost of recomputing all such variables while still maintaining their correctness ( §4 ) . Second , for efficiency , ElasticNotebook optimizes its replication plan to determine ( 1 ) the variables that will be copied , and ( 2 ) the variables that will be recomputed based on the copied variables , to minimize the end-to-end migration ( or restoration ) time in con- sideration of serialization costs , recomputation costs , data transfer costs , etc . For example , even if a variable can be reliably transferred across machines , the variable may still be dynamically constructed if doing so results in a lower total cost . To make this decision in a principled way , we devise a new graph-based optimization problem , which reduces to a well-established min-cut problem ( §5 ) . Implementation : While our contributions can apply to many dy- namically analyzable languages ( e.g. , Python/R , LLVM-based ones ) , we implement our prototype ( in C and Python ) for the Python user interface , which is widely used for data science , machine learning , statistical analysis , etc . Specifically , ElasticNotebook provides a data management layer to Jupyter as a hidden cell magic [ 103 ] to transparently monitor cell executions and offer efficient replication . Difference from Existing Work . Compared to existing work , we pursue a significantly different direction . For example , there are tools that make data serialization more convenient [ 40 , 104 ] ; how- ever , they fail if a session contains non-serializable variables , and are inefficient because they do not consider opportunities for dy- namic recomputation . Alternatively , system-level checkpointing [ 3 , 18 , 43 , 61 ] is platform-dependent , limited to checkpointing memory ( e.g. , not GPU ) , less efficient than ours since dynamic recompu- tation is impossible . Building on top of result reuse [ 42 , 116 ] and lineage tracing [ 54 , 83 , 93 ] , we introduce deeper ( reference-aware ) analyses ( §4.2 ) and novel optimization techniques to incorporate unique constraints such as inter-variable dependencies ( §5 ) and also empirically confirm their effectiveness ( §7.2 ) . Completely or- thogonal work includes library migration [ 1 , 115 ] and scalable data science [ 79 , 81 , 117 ] . Table 1 summarizes differences . Contributions . Our contributions are as follows : • Motivation . We discuss alternative approaches and explain the advantage of our approach . ( §2 ) • Architecture . We describe our system architecture for achiev- ing efficient and robust session replication . ( §3 ) • Data Model . We introduce a novel data model ( Application History Graph ) for expression session history , which enables efficient and accurate state replication . ( §4 ) • Optimization Problem and Solution . We formally define the optimization problem of minimizing state replication cost through balancing variable copying and recomputation . We propose an efficient and effective solution . ( §5 ) • Evaluation . We show ElasticNotebook reduces upscaling , down- scaling , and restore times by 85 % -98 % , 84 % -99 % , and 94 % -99 % , respectively . Overheads are negligible ( < 2.5 % runtime ) . ( §7 ) 2 MOTIVATION This section describes use cases ( §2.1 ) and requirements ( §2.2 ) for session replication , and our intuition for higher efficiency ( §2.3 ) . 2.1 Why is Live Migration Useful ? A seamless state replication for computational notebooks can al- low easier infrastructure scaling and frequent session suspension , without interrupting user workflow , as described below . Fast Replication for Elastic Computing . The ability to move a state across machines is useful for scaling resources [ 21 , 64 ] , allowing us to migrate a live session to the machines with the right equipment/resources ( e.g. , GPU [ 22 ] , specific architectures [ 119 ] ) . For interruption-free scaling , we can copy data D from a source ElasticNotebook : Enabling Live Migration for Computational Notebooks User Interface ... % % intercept code ... def intercept ( code ) : preprocess ( code ) # regular kernel execution out = execute ( code ) postprocess ( out , code ) Application History df_train Cell 1 3mins df Cell 2 1min Cell 3 20mins model Cell 4 10mins plot df_test Figure 2 : For every cell run , we can inject custom pre-/post- processing logic . “ % % intercept ” is hidden to users . Variable Store cost ( mins ) Reload cost ( mins ) Total cost ( mins ) df 8 2 10 df_train df_test 6.4 1.6 8 1.6 0.4 2 model 0.2 0.2 0.4 plot 0.1 0.1 0.2 machine to a target machine in a way that the original session state can be restored from D. In this process , we want to minimize the end-to-end time for creating D , transferring D to a target machine , reconstructing the state from D on the target machine . This is the first use case we empirically study ( §7.3 ) . Fast Restart for On-demand Computing . Leveraging pay-as- you-go pricing model offered by many cloud vendors [ 5 , 48 ] , sus- pending sessions ( and VMs ) when not in use is an effective way for reducing charges ( e.g. , up to 6× [ 115 ] ) . With the ability to cre- ate data D sufficient for reconstructing the current session state , we can persist D prior to either manual or automated suspen- sion [ 20 , 47 , 59 ] , to quickly resume , when needed , the session in the same state . This achieves on-demand , granular computing with fast session restart times without impacting user experience due to frequent session suspensions [ 58 , 97 ] . In this process , we want to restore the session as quickly as possible by minimizing the time it takes for downloading D and reconstructing a state from it . This is the second use case we empirically study ( §7.4 ) . 2.2 How to Enable Data Management Layer ? We discuss the pros and cons of several different approaches to enabling a data management layer . OS-level Checkpointing . To save the current session state , we can checkpoint the entire memory space associated with the underlying Python/R kernels . To make the process more efficient , existing tools like CRIU patch the Linux kernel to trace dirty pages . However , as described in §1 , this approach is platform-independent , incurs higher space cost , and is limited to storing the state of primary memory ( not GPU or other devices ) . We empirically compare our approach to CRIU to understand reliability and efficiency ( §7 ) . Object wrappers . Watchpoint object wrappers [ 41 , 44 ] are com- monly used for debugging purposes [ 83 ] and program slicing [ 54 , 93 ] : they maintain deep copies for objects in the session state , which are compared to check for changes after each frame execution ; how- ever , they are unsuitable for use during data science workflows due to the unacceptable ~20× runtime overhead in our preliminary tests . Monitoring Cell Executions ( Ours ) . In order to trace cell exe- cutions and their effects on variables , we can add a lightweight wrapper ( i.e. , our data management layer ) that functions before and after each cell execution to monitor the cell code , runtime , and variable changes . This idea is depicted conceptually in Fig 2 . Specifically , our implementation uses cell magics , a Jupyter-native mechanism that allows arbitrary modification to cell statements when the cell is executed . With this , we add pre-/post-processing steps to capture cell code and resulting session state modifications . Store Vars N/A All Method Rerun all Store all Fast-migrate model , plot Fast-restore df , model , plot 2 Rerun cells Migration Cost Restore Cost All 3+1+20+10=33 N/A 1 , 2 3+1+20+10=33 10+8+2+.4+.2=20.6 2+1.6+.4+.2+.1=4.3 3+1+.4+.2=4.6 10+1+.4+.2=11.6 3+1+.2+.1=4.3 2+1+.2+.1=3.3 Figure 3 : Example app history ( top ) and different replica- tion plan costs ( bottom ) . Combining recompute/copy allows faster migration ( Fast-migrate ) . Alternatively , the optimal plan changes if the restoration is prioritized ( Fast-restore ) . 2.3 Fast Replication with Application History This section describes our core idea for devising an efficient repli- cation strategy by leveraging the ability to monitor cell executions . Application History . An application history graph ( AHG ) is a bipar- tite graph for expressing session states changes with respect to cell runs . There are two types of nodes : variables and transformations . A transformation node connects input variables to output variables ( see an example in Fig 3 ) . AHG aims to achieve two properties : • Completeness : No false negatives . All input/output variable for each transformation must be captured . • Minimal : Minimal false positives . The number of variables that are incorrectly identified as accessed/modified , while variables are not actually accessed/modified , must be minimized . These properties are required for correct state reconstruction ( §4 ) . Core Optimization Idea . AHG allows for efficient state replica- tion with a combination of ( 1 ) recompute and ( 2 ) copy . Motivating Example . Suppose a data analyst fitting a regression model ( Fig 3 ) . The notebook contains 4 cell runs : data load ( Cell 1 ) , train-test split ( Cell 2 ) , fitting ( Cell 3 ) , and evaluation ( Cell 4 ) . After fitting , the ana- lyst decides to move the session to a new machine for GPU . Simply rerunning the entire notebook incurs 33 minutes . Alternatively , serializing/copying variables takes 20.6 minutes . However , there is a more efficient approach . By copying only model and plot and recomputing others on a new machine ( Fast- migrate ) , we can complete end-to-end migration in 4.6 minutes . Or , if we prioritize restoration time ( to reduce user-perceived restart time for on-demand computing ) , our optimized plan ( Fast-restore ) takes 3.3 minutes . This example illustrates significant optimization opportunities in session replication . Our goal is to have the ability to find the best replication plan for arbitrarily complex AHGs . 3 SYSTEM OVERVIEW This section presents ElasticNotebook at a high level by describing its components ( §3.1 ) and operations ( §3.2 ) . Data Layer ( core part of ElasticNotebook ) Table 2 : Notations and their meaning Zhaoheng Li , Pranav Gor , Rahul Prabhu , Hui Yu , Yuzhou Mao , Yongjoo Park Notebook User Interface x= '' hello '' y= '' world '' . . . Cell Execution Interceptor ( §4.2 ) Optimizer ( §5 ) ID Graphs & object hashes Optimization algorithm Application History Graph ( §4.1 ) Cost Model ( §5.2 ) Session Replicator ( §4.3 ) Writer Notebook Replayer Jupyter Kernel Namespace ( user_ns ) KEY VAL x y hello world ... Figure 4 : ElasticNotebook architecture . Its data layer acts as a gateway between the user interface and the kernel : cell executions are intercepted to observe session state changes . 3.1 ElasticNotebook Components ElasticNotebook introduces a unique data layer that acts as a gate- way between the user and the kernel ( See Fig 4 ) : it monitors every cell execution , observing code and resulting session state changes . Cell Execution Interceptor . The Cell Execution Interceptor inter- cepts cell execution requests and adds pre-/post-processing scripts before rerouting it into the underlying kernel for regular execu- tion . The added scripts perform ( 1 ) cell code analyses and the AHG updates , and ( 2 ) cell runtime recordings . Application History Graph ( AHG ) . The AHG is incrementally built by the Cell Execution Interceptor to record how variables have been accessed/modified by each cell execution ( §4 ) . The AHG is used by the Optimizer to compute replication plans ( §5 ) . Cost Model . The cost model stores profiled metrics ( i.e. , cell run- times , variable sizes , network bandwidth ) , serving as the hyperpa- rameters for the Optimizer ( §5.2 ) . Optimizer . The Optimizer uses the AHG and the Cost Model to determine the most efficient replication plan consisting of ( 1 ) vari- ables to store and ( 2 ) cells to re-run . We discuss ElasticNotebook ’ s cost model and optimization in detail in §5 . Session Replicator . The Session Replicator replicates a notebook session according to the Optimizer ’ s plan . Specifically , the Writer creates and writes a checkpoint file to storage ( e.g. , SSD , cloud storage ) , while the Notebook Replayer reads the file and restores the session , both following the replication plan . We discuss Elastic- Notebook ’ s session replication in detail in §3.2 . 3.2 ElasticNotebook Workflow This section describes ElasticNotebook ’ s operations . ElasticNote- book monitors every cell execution during a session lifecycle , then performs on-request replication of the session in two steps : check- pointing ( writing to the checkpoint file ) and restoration . Monitoring Cell Executions . Upon each cell execution by the user , ElasticNotebook performs the following steps : 1 . Accessed variables of the cell execution are identified via AST analysis ( described in §4.2 ) . 2 . The cell code is executed by the Jupyter kernel . Definition Set of Variables Set of Variable Snapshots ( VSs ) Set of Active Variable Snapshots Set of Cell Executions ( CEs ) Set of write dependencies Set of read dependencies Symbols X V V𝑎 C ( = 𝑐𝑡1 , 𝑐𝑡2 , . . . ) E𝑤 E𝑟 G : = { V ∪ C , E𝑤 ∪ E𝑟 } Application History Graph ( AHG ) 𝑟𝑒𝑞 : X → 2C Reconstruction mapping function 𝑤𝑠𝑡𝑜𝑟𝑒 : X → R+ Variable storage cost 𝑤𝑟𝑒𝑟𝑢𝑛 : C → R+ Cell Rerun cost 𝑤M : 2X → R+ Migration cost function 𝑤R : 2X → R+ Recomputation cost function Pairs of linked variables L ⊆ X × X Flow graph H : = { V𝐻 , E𝐻 } 𝑐 : E𝐻 → R+ Flow graph edge capacity function 3 . Variable changes ( i.e. , creation/deletion/modification ) are iden- tified within the global namespace ( §4.2 ) . 4 . The AHG is updated using ( 1 ) the cell code and ( 2 ) modified variables by the cell execution . 5 . The Cost Model is updated to record cell runtime . Initiating Replication . When replication is requested , Elastic- Notebook creates and writes a checkpoint file to storage , which can be restored later to exactly and efficiently reconstruct the current session . ElasticNotebook first completes the Cost Model by pro- filing variable sizes and network bandwidth to storage ; then , the Optimizer utilizes the AHG and Cost model to compute a replica- tion plan , according to which the Writer creates the checkpoint file : it consists of ( 1 ) a subset of stored variables from the session state , ( 2 ) cells to rerun , ( 3 ) the AHG , and ( 4 ) the Cost Model . Restoring a Session . When requested , ElasticNotebook restores the notebook session from the checkpoint file according to the replication plan . The Notebook Replayer reconstructs variables in the order they appeared in the original session by combining ( 1 ) cell reruns and ( 2 ) data deserialization followed by variable re- declaration ( into the kernel ) . Finally , ElasticNotebook loads the AHG and Cost Model for future replications . Accuracy Guarantee : ElasticNotebook ’ s state reconstructing is effectively the same as re-running all the cells from scratch exactly in the order they were run in the past . That is , ElasticNotebook shortens the end-to-end reconstruction time by loading saved vari- ables ( into the kernel namespace ) if doing so achieves time savings . §4.3 presents formal correctness analysis . §6.1 discusses how we address external resources , side effects , and deserialization failures . 4 APPLICATION HISTORY GRAPH This section formally defines the Application History Graph ( §4.1 ) , and describes how we achieve exact state replication ( §4.3 ) . 4.1 AHG Formal Definition The AHG is a directed acyclic graph expressing how a session state has changed with respect to cell executions . Fig 5 is an example . Definition 1 . A variable is a named entity ( e.g. , df ) referencing an object ( which can be uniquely identified by its object ID ) . ElasticNotebook : Enabling Live Migration for Computational Notebooks A variable can be primitive ( e.g. , int , string ) or complex ( e.g. , list , dataframe ) . Multiple variables may point to the same object . The set of all variables ( i.e. , X ) defined in the global namespace forms a session state . Cell executions may modify the values of variables ( or referenced objects ) without changes to their names , which we recognize in AHG using variable snapshot , as follows . Definition 2 . A variable snapshot ( VS ) is a name-timestamp pair , ( 𝑥 , 𝑡 ) , representing the variable 𝑥 created/modified at 𝑡 . We denote the set of VSes as V. Definition 3 . A cell execution ( CE ) 𝑐𝑡 represents a cell execution that finishes at timestamp 𝑡 . All cell executions are linear ; that is , for each session , there is at most one cell running at a time , and their executions are totally ordered . We denote the list of CEs by C. Each CE also stores executed cell code , which can be used for re-runs ( §3.2 ) . Definition 4 . A write dependency ( 𝑐𝑡 → ( x , 𝑡 ) ) indicates CE 𝑐𝑡 may have modified/created at time 𝑡 the object ( s ) reachable from the variable 𝑥 . We denote the set of write dependencies as E𝑤 . In Fig 5 , 𝑐𝑡3 modifies x with “ x += 1 ” ; hence , ( 𝑐𝑡3 → ( x , 𝑐𝑡3 ) ) . Definition 5 . A read dependency ( ( x , 𝑠 ) → 𝑐𝑡 ) indicates CE 𝑐𝑡 may have accessed object ( s ) reachable from x last created/modified at time 𝑠 . We denote the set of read dependencies by E𝑟 . In Fig 5 , “ gen= ( i for i in l1 ) ” in 𝐶𝑡4 accesses elements in the list l1 after its creation in 𝑐𝑡3 ; hence there is ( ( x → 𝑐𝑡3 ) , 𝑐𝑡4 ) . Note that write/read dependencies are allowed to contain false positives ; nevertheless , our replication ensures correctness ( §4.3 ) . Definition 6 . The AHG 𝐺 : = { V∪C , E𝑤 ∪E𝑟 } is a bipartite graph , where V is VSes , C is CEs ; E𝑤 and E𝑟 are write/read dependencies , respectively . It models the lineage of the notebook session . In sum , AHG formalizes variable accesses/modifications with re- spect to cell executions . at the variable level ( not object level ) , theo- retically bounding the size of AHG to scale linearly with the number of defined variables , not the number of underlying objects ( which can be very large for lists , dataframes , and so on ) . We empirically verify AHG ’ s low memory overhead in §7.5 . 4.2 Dynamic AHG Construction We describe how ElasticNotebook constructs the AHG accurately . Constructing the AHG . The AHG is incrementally built with accessed/created/modified variables by each cell execution : • A new CE 𝑐𝑡 is created ; 𝑡 is an execution completion time . • Read dependencies are created from VSes ( 𝑥1 , 𝑡𝑥1 ) , ... , ( 𝑥𝑘 , 𝑡𝑥𝑘 ) to 𝑐𝑡 , where 𝑥1 , ... , 𝑥𝑘 are variables possibly accessed by 𝑐𝑡 . • VSes ( 𝑦1 , 𝑡 ) , ... , ( 𝑦𝑘 , 𝑡 ) are created , where 𝑦1 , ... , 𝑦𝑘 are variables possibly modified and created by 𝑐𝑡 . Write dependencies are added from 𝑐𝑡 to each of the newly created VSes . Fig 5 ( right ) shows an example AHG . Identifying access/modified variables is crucial for its construction , which we describe below . ID Graph . The ID Graph aims to to detect changes at the reference level ( in addition to values ) . For instance , conventional equality checks ( e.g. , based on serialization ) will return True for “ [ a ] == Notebook Cell 1 ( 𝑐𝑡1 ) x , y = 1 Cell 2 ( 𝑐𝑡2 ) z = y if False : print ( x ) Cell 3 ( 𝑐𝑡3 ) x += 1 l1 = [ z , 2 , 3 ] Cell 4 ( 𝑐𝑡4 ) gen= ( i for i in l1 ) 2dlist = [ l1 ] Cell 5 ( 𝑐𝑡5 ) print ( gen ) ( x , 𝒕1 ) ( y , 𝑡1 ) 𝒄𝒕1 𝑐𝑡2 ( z , 𝑡2 ) 𝒄𝒕3 ( x , 𝒕3 ) ( l1 , 𝑡3 ) 𝑐𝑡4 ( gen , 𝑡4 ) ( 2dlist , 𝑡4 ) 𝑐𝑡5 ( gen , 𝑡5 ) ( x , 𝑡1 ) ( Overwritten/deleted ) Variable Snapshot 𝑐𝑡1 Cell Execution ( x , 𝑡1 ) Active Variable Snapshot Figure 5 : An example notebook and its corresponding Appli- cation History Graph . The AHG tells ElasticNotebook how to recompute variables ; for example , rerunning 𝑐𝑡1 and 𝑐𝑡3 is necessary for recomputing x ( red ) . [ b ] ” if a and b have the same value ( e.g. , a = [ 1 ] and b = [ 1 ] ) , whereas we ensure it returns True only if a and b refer to the same object , i.e. , id ( a ) ==id ( b ) , where id is the object ’ s unique ID . This is because for correct state replication , shared references ( e.g . aliases ) and inter-variable relationships must be captured precisely . Identifying Accessed Variables . ElasticNotebook identifies both directly accessed variables ( via AST [ 31 ] parsing ) and indirectly accessed variables ( with ID Graphs ) , as follows . Direct Accesses : Cell code is analyzed with AST , stepping also into user-defined functions ( potentially nested ) to check for accesses to variables not explicitly passed in as parameters ( e.g. , global x ) . Indirect Accesses : The object ( s ) reachable from a variable X may be accessed indirectly via another variable Y if X and Y reference common object ( s ) ( e.g. , when aliases exist , Fig 6a ) , which can not be identified via parsing only . To recognize indirect accesses , we check the existence of overlaps between the ID Graphs of X and Y . Our approach is conservative ; that is , it may over-identify vari- ables by including , for example , ones reachable from control flow branches that were not taken during cell executions . However , these false positives do not affect accuracy of state replication ( §4.3 ) . Identifying Modified Variables . Variable modifications are iden- tified using a combination of ( 1 ) object hashes and ( 2 ) ID Graphs . Value Changes : ElasticNotebook identifies value modifications by comparing hashes ( by xxHash [ 118 ] ) before and after each cell execution while using deep copy as a fallback . If the deep copy fails ( e.g. , unserializable or uncomparable variables ) , we consider them to be modified-on-access using results from AST and ID Graph ( §6.1 ) . This may result in false positives ; however , as previously mentioned , these false positives do not affect the accuracy . Structural Changes : The ID Graph enables detecting structural changes ( Fig 6b ) . After each cell execution , the current variables ’ ID Graphs are compared to the ones created before to identify reference swaps . In Fig 6b , while the value of 2dlist1 remains unchanged Cell 1 func = lambda x : ... obj1.foo = func obj2.foo = func Cell 2 obj2.foo ( `` str '' ) & obj1 & obj2 ID Graph & func ( a ) Detecting indirect variable accesses from aliases Cell 1 list1 = [ 1 , 2 , 3 ] 2dlist1 = [ list1 ] 2dlist2 = [ list1 ] Cell 2 list2 = [ 1 , 2 , 3 ] 2dlist1 [ 0 ] = list2 Before Cell 2 After Cell 2 ID Graph & 2dlist1 & 2dlist1 ≠ & list1 & list2 Value [ [ 1,2,3 ] ] = [ [ 1,2,3 ] ] ( b ) Detecting structural variable modifications Figure 6 : Two uses of the ID Graph during AHG construction . after execution after executing Cell 2 , the memory address of its nested list has been changed , no longer referencing list1 . 4.3 State Reconstruction with AHG This section describes how we reconstruct variable ( s ) . We focus on reconstructing the latest version of each variable , as defined in active variable snapshot ( VS ) in an AHG . Definition 7 . VS ( 𝑥 , 𝑡𝑖 ) is active if 𝑥 is in the system ( i.e. , not deleted ) , and there is no VS ( 𝑥 , 𝑡 𝑗 ) such that 𝑡𝑖 < 𝑡 𝑗 . An active VS , ( 𝑥 , 𝑡𝑖 ) , represents the current version of 𝑥 . For example , even if we checkpoint after 𝑐𝑡5 ( in Fig 5 ) , “ ( x , 𝑡3 ) ” is active since x was last modified by 𝑐𝑡3 . We denote the set of active VSes as V𝑎 . Reconstruction Algorithm . Our goal is to identify the most effi- cient computation strategy for reconstructing one or more active variables . Note that we do not reconstruct non-active variables since they are not part of the current session state . In achieving this goal , the AHG allows us to avoid unnecessary cell executions ( e.g. , because their outcomes have been overwritten ) and to learn proper execution orders . Moreover , this process can be extended to reconstruct a set of variables more efficiently than computing them one by one . while still ensuring correctness . Specifically , to recompute VS ( 𝑥 , 𝑡 ) , we traverse back to its an- cestors in the AHG ( e.g. , using the breadth-first search ) , collecting all CEs into a list 𝑟𝑒𝑞 ( 𝑥 , 𝑡 ) , until we find a ground variable for every path , where the ground variable is a variable whose value is avail- able in the system , i.e. , either another active VS or copied variable . By rerunning all the CEs in 𝑟𝑒𝑞 ( 𝑥 , 𝑡 ) in the order of their completion times , we can obtain the target VS ( 𝑥 , 𝑡 ) . To extend this algorithm to multiple VSes , say ( 𝑥1 , 𝑡𝑥1 ) , ( 𝑥2 , 𝑡𝑥2 ) , and ( 𝑥3 , 𝑡𝑥3 ) , we obtain 𝑟𝑒𝑞 for each VS and union them into a merged set ( that is , identical CEs collapse into one ) . By rerunning all the CEs in the merged set , we obtain all target VSes . Fig 5 shows an example . To recompute ( 𝑥 , 𝑡3 ) , we rerun 𝑐𝑡3 which requires the previous version ( x , 𝑡1 ) as input , which in turn requires 𝑐𝑡1 to be rerun . Notably , it is not necessary to rerun 𝑐𝑡2 as its output z is available in the namespace . Finally , §6.1 discusses how this approach can recover even if some ground variables are unexpectedly unobtainable . Zhaoheng Li , Pranav Gor , Rahul Prabhu , Hui Yu , Yuzhou Mao , Yongjoo Park Notebook Cell 3 ( 𝑐𝑡3 ) l1 = [ z , 2 , 3 ] Cell 4 ( 𝑐𝑡4 ) 2dlist = [ l1 ] Replication Plan l1 Migrate 2dlist Migrate Recompute Recompute Recompute Migrate & l1== & 2dlist1 [ 0 ] True True False Figure 7 : Two variables sharing references ( in Fig 5 ) . They must be migrated/recomputed together for the correct repli- cation , serving as constraints to our opt problem ( see §5.3 ) . Why Only Use Active VSes ? Theoretically , it is possible to use non-active variables as ground variables . That is , by preserving deleted/overwritten variables ( e.g. , in a cache ) , we may be able to speed up the recomputation of active variables [ 42 , 116 ] . However , we don ’ t consider this approach as many data science workloads are memory-hungry with large training data and model sizes . Still , there might be cases where we can speed up recomputation by storing small overwritten variables , which we leave as future work . Correctness of Reconstruction . As stated in §2.3 , the AHG is allowed to have false positives , meaning it may indicate a cell ac- cessed/modified variables that were not actually accessed/modified . While the false positives have a performance impact , they do not affect the correctness of identification . Theorem 4.1 . Given the approximate AHG G of ElasticNotebook with false positives , and the true AHG G∗ , there is 𝑟𝑒𝑞∗ ( 𝑥 , 𝑡 ∗ ) ⊆ 𝑟𝑒𝑞 ( 𝑥 , 𝑡 ) for any variable 𝑥 ∈ X , where ( 𝑥 , 𝑡 ) and ( 𝑥 , 𝑡 ∗ ) , 𝑟𝑒𝑞 and 𝑟𝑒𝑞∗ are the active VSs of 𝑥 and reconstruction mapping functions defined on G and G∗ respectively . That is , for any arbitrary variable 𝑥 , while 𝑟𝑒𝑞 ( 𝑥 , 𝑡 ) may contain cell executions unnecessary for recomputing 𝑥 , it will never miss any necessary cell executions ( i.e. , those in 𝑟𝑒𝑞 ( 𝑥 , 𝑡 ∗ ) ) . The proof is presented in Appendix A.2 . 5 CORRECT & EFFICIENT REPLICATION This section covers how ElasticNotebook computes an efficient and correct plan for state replication with the AHG and profiled metrics . We describe correctness requirements in §5.1 , the cost model in §5.2 , the optimization problem in §5.3 , and our solution in §5.4 . 5.1 Correctness Requirements ElasticNotebook aims to correctly replicate session states . which we define the notion of in this section : Definition 8 . A replication of state X is value-equivalent if ∀𝑥 ∈ X , 𝑥 =𝑛𝑒𝑤 ( 𝑥 ) , where 𝑛𝑒𝑤 ( 𝑥 ) is the value of 𝑥 post-replication . A value-equivalent replication preserves the value of each indi- vidual variable and is guaranteed by the correct identification of 𝑟𝑒𝑞 ( 𝑥 , 𝑡 ) for each variable 𝑥 ( §4.3 ) . However , it is additionally im- portant that shared references are preserved , as defined below . Definition 9 . A value-equivalent replication of a session state X is additionally isomorphic if ∀𝑎 , 𝑏 , 𝑖𝑑 ( 𝑎 ) = 𝑖𝑑 ( 𝑏 ) → 𝑖𝑑_𝑛𝑒𝑤 ( 𝑎 ) = 𝑖𝑑_𝑛𝑒𝑤 ( 𝑏 ) , where 𝑎 , 𝑏 are arbitrary references ( e.g. , x [ 0 ] [ 1 ] , y.foo ) , and 𝑖𝑑 ( 𝑎 ) , 𝑖𝑑_𝑛𝑒𝑤 ( 𝑎 ) are the unique IDs ( i.e. , memory addresses ) of the objects pointed to by 𝑎 before and after replication . ElasticNotebook : Enabling Live Migration for Computational Notebooks migration cost = capacity Source y z x l1 Active VSes Cell Executions capacity=∞ ca p acity = reru n cost Sink 𝑐𝑡1 𝑐𝑡2 𝑐𝑡3 𝑐𝑡4 𝑐𝑡5 capacity=∞ 2dlist1 gen Figure 8 : Running min-cut on the flow graph constructed from the AHG in Fig 5 . The partition ( red ) defined by the minimum cut ( dashed edges ) determines the replication plan . ElasticNotebook defines replication as ’ correct ’ only if it is isomor- phic , requiring all shared references to be preserved : two references pointing to the same object pre-replication will still do so post- replication . That is , inter-object relations are identical ( analogous to graph isomorphism ) . We describe how ElasticNotebook ensures isomorphic replication via its linked variable constraint in §5.3 . 5.2 Cost Model Our model captures the costs associated with ( 1 ) serializing vari- ables , ( 2 ) writing byte data into storage ( e.g. , local SSD , cloud stor- age ) and ( 3 ) rerunning cell executions . These costs are computed using the AHG and profiled system metrics . Variable Migration Cost . Migrating a variable ( from one session to another ) includes serializing it to the checkpoint file , then loading it into a new session . Given a subset of variables to migrate S ⊆ X , the migration cost 𝑤𝑀 can be expressed as follows : ∑︁ 𝛼 × 𝑤𝑠𝑡𝑜𝑟𝑒 ( 𝑥 ) + 𝑤𝑙𝑜𝑎𝑑 ( 𝑥 ) 𝑤𝑀 ( S ) = ( 1 ) 𝑥 ∈ S Where 𝑤𝑠𝑡𝑜𝑟𝑒 ( 𝑥 ) and 𝑤𝑙𝑜𝑎𝑑 ( 𝑥 ) are the time costs for serializing the value of 𝑥 at checkpointing time into a file and unpacking into the new session , respectively . These times are estimated using the size of 𝑥 and storage latency/bandwidth from ElasticNotebook ’ s Profiler ( §3.1 ) . The time costs for unserializable variables are set to infinity . 𝛼 is a coefficient for adjusting the time cost of storage ; for example , if ElasticNotebook is to be invoked upon auto-suspension , 𝛼 can be set to a low value to discount the user-perceived time of storing variables prior to completely suspending a session ( as the user is likely away ) . Variable Recomputation Cost . The Interceptor records cell run- times during a session lifecycle ( §3.1 ) . Combined with the recon- struction mapping 𝑟𝑒𝑞 ( ) for the AHG ( §4.3 ) , the cost 𝑤𝑅 for recom- puting a subset of variables S ⊆ X can be defined as follows : 𝑟𝑒𝑞 ( 𝑥 , 𝑡 ) 𝑤𝑟𝑒𝑟𝑢𝑛 ( 𝑐 ) , where 𝑟𝑒𝑞 ( S ) = 𝑤𝑅 ( S ) = ∑︁ ( cid:216 ) ( 2 ) 𝑐 ∈𝑟𝑒𝑞 ( S ) 𝑥 ∈ S where ( 𝑥 , 𝑡 ) is the active VS of 𝑥 and 𝑤𝑟𝑒𝑟𝑢𝑛 ( 𝑐 ) : C → R+ is the estimated time to rerun the CE 𝑐 in the new session . Replication Plan Cost . Using migration and recomputation costs ( i.e. , Eqs . ( 1 ) and ( 2 ) ) , the total cost 𝑤—with variables to migrate S and variables to recompute X − S—is expressed as : 𝑤 ( S ) = 𝑤𝑀 ( S ) + 𝑤𝑅 ( X − S ) ( 3 ) 5.3 Optimization Problem for State Replication The goal is to find the variables to migrate S ⊆ X that minimizes the cost Eq . ( 3 ) . To ensure isomoprhic replication in consideration of variable inter-dependencies , additional constraints are added . Constraint for Linked Variables . Two variables containing refer- ences to the same object ( which we refer to as linked variables , e.g. , l1 and 2dlist1 in Fig 7 ) must be either both migrated or recom- puted , as migrating one and recomputing the other may result in their contained shared reference/alias being broken , as illustrated in Fig 7 . Let the set of linked variable pairs be denoted as L , then the constraint can be formally expressed as follows : ( 𝑥1 ∈ S ∧ 𝑥2 ∈ S ) ∨ ( 𝑥1 ∉ S ∧ 𝑥2 ∉ S ) ∀ ( 𝑥1 , 𝑥2 ) ∈ L Problem definition . Using the cost model in Eq . ( 3 ) and the con- straint in Eq . ( 4 ) , we formally define the state replication problem : ( 4 ) Problem 1 . Optimal State Replication Input : 1 . AHG G = { V ∪ C , E } 2 . Migration cost function 𝑤𝑀 : 2X → R+ 3 . Recompute cost function 𝑤𝑅 : 2X → R+ 4 . Linked variables L ⊆ X × X A replication plan of subset of variables S ⊆ X for which we migrate ( and another subset X − S which we recompute ) Output : Objective : Minimize replication cost 𝑤𝑀 ( S ) + 𝑤𝑅 ( X − S ) Constraint : Linked variables are either both migrated or recom- puted : ( 𝑥1 , 𝑥2 ∈ S ) ∨ ( 𝑥1 , 𝑥2 ∉ S ) ∀ ( 𝑥1 , 𝑥2 ) ∈ L The next section ( §5.4 ) presents our solution to Prob 1 . 5.4 Solving State Replication Opt . Problem We solve Prob 1 by reducing it to a min-cut problem , with a 𝑠𝑟𝑐-𝑠𝑖𝑛𝑘 flow graph constructed from the AHG such that each 𝑠𝑟𝑐-𝑠𝑖𝑛𝑘 cut ( a subset of edges , which , when removed from the flow graph , disconnects source 𝑠 and sink 𝑡 ) corresponds to a replication plan S , while the cost of the cut is equal to the replication cost 𝑤𝑀 ( S ) + 𝑤𝑅 ( X − S ) . Therefore , finding the minimum cost 𝑠𝑟𝑐-𝑠𝑖𝑛𝑘 cut is equivalent to finding the optimal replication plan . Flow Graph Construction . A flow graph 𝐻 : = { V𝐻 , E𝐻 } and its edge capacity 𝜙 : E𝐻 → R+ are defined as follows : • V𝐻 = V𝑎 ∪ C ∪ { 𝑠𝑟𝑐 , 𝑠𝑖𝑛𝑘 } : V𝑎 is active VSes , C is cell execu- tions , and 𝑠𝑟𝑐 and 𝑠𝑖𝑛𝑘 are dummy source and sink nodes . • ∀𝑥 ∈ V𝑎 , ( 𝑠𝑟𝑐 , ( 𝑥 , 𝑡 ) ) ∈ E𝐻 and 𝜙 ( 𝑠𝑟𝑐 , ( 𝑥 , 𝑡 ) ) = 𝑤𝑀 ( 𝑥 ) : We add an edge from the source to each active VS with a capacity equal to the migration cost of the variable . • ∀𝑐 ∈ C , ( 𝑐 , 𝑠𝑖𝑛𝑘 ) ∈ E𝐻 and 𝜙 ( 𝑐 , 𝑠𝑖𝑛𝑘 ) = 𝑤𝑟𝑒𝑟𝑢𝑛 ( 𝑐 ) : We add an edge with capacity from each CE to the sink with a capacity equal to the rerun cost of the CE . • ∀𝑐 ∈ C , 𝑐 ∈ 𝑟𝑒𝑞 ( 𝑥 , 𝑡 ) → ( ( 𝑥 , 𝑡 ) , 𝑐 ) ∈ E𝐻 and 𝜙 ( ( 𝑥 , 𝑡 ) , 𝑐 ) = ∞ and ( 𝑥 , 𝑡 ) ∈ V𝑎 : We add an edge with infinite capacity from an active VS ( 𝑥 , 𝑡 ) to a CE 𝑐 if ( 𝑥 , 𝑡 ) must be recomputed . • ∀ ( 𝑥1 , 𝑥2 ) ∈ L , ( ( 𝑥1 , 𝑡1 ) ↔ ( 𝑥2 , 𝑡2 ) ) ∈ E𝐻 and 𝜙 ( ( 𝑥1 , 𝑡1 ) ↔ ( 𝑥2 , 𝑡2 ) ) = ∞ : We add a bi-directional edge with an infinite capacity between each pair of active VSes corresponding to linked variables 𝑥1 and 𝑥2 , e.g. , l1 and 2dlist1 . The flow graph H for the AHG in Fig 5 is depicted in Fig 8 . Solution . We can now solve Prob 1 by running a 𝑠𝑟𝑐—𝑠𝑖𝑛𝑘 min-cut solving algorithm ( i.e. , Ford-Fulkerson [ 30 ] ) on 𝐻 . The set of edges that form the 𝑠𝑟𝑐—𝑠𝑖𝑛𝑘 min-cut ( dashed edges ) , when removed , disconnects 𝑠𝑟𝑐 from 𝑠𝑖𝑛𝑘 ; therefore , it defines a partition ( in red ) of the nodes into nodes reachable from 𝑠𝑟𝑐 , V𝐻𝑠𝑟𝑐 and nodes un- . The replication plan can be obtained reachable from 𝑠𝑟𝑐 , V𝐻𝑠𝑖𝑛𝑘 from the partition : • S = { 𝑥 | ( 𝑥 , 𝑡 ) ∈ V𝐻𝑠𝑖𝑛𝑘 ∩ V𝑎 } are the active variable snapshots ( and thus variables ) that we want to migrate ; in the example , these variables are l1 , 2dlist1 , and gen. • V𝐻𝑠𝑟𝑐 ∩ C are the CEs which we will rerun post-migration to recompute X − S. In the example , these CEs are 𝑡1 , 𝑡2 , and 𝑡3 ; when rerun , they recompute y , z , and x.2 By construction of H , the sum of migration and recomputation costs of this configuration 𝑤𝑀 ( { 𝑥 | ( 𝑥 , 𝑡 ) ∈ V𝐻𝑠𝑖𝑛𝑘 ) + 𝑤𝑅 ( C𝑎 − ( V𝐻𝑠𝑟𝑐 ∩ C ) ) is precisely the cost of the found 𝑠𝑟𝑐—𝑠𝑖𝑛𝑘 min-cut . 6 IMPLEMENTATION AND DISCUSSION This section describes ElasticNotebook ’ s implementation details ( §6.1 ) and design considerations ( §6.2 ) . 6.1 Implementation Integrating with Jupyter . For seamless integration , ElasticNote- book ’ s data layer is implemented using a magic extension [ 103 ] , which is loaded into the kernel upon session initialization . The cell magic is automatically added to each cell ( §2.2 ) to transparently intercept user cell executions , perform code analyses , create ID Graphs and object hashes , and so on . Serialization Protocol . The Pickle protocol ( e.g. , __reduce__ ) is employed for ( 1 ) object serialization and ( 2 ) definition of reachable objects , i.e. , an object y is reachable from a variable x if pickle ( x ) includes y . As Pickle is the de-facto standard ( in Python ) observed by almost all data science libraries ( e.g. , NumPy , PyTorch [ 29 ] ) , ElasticNotebook can be used for almost all use cases . Handling Undeserializable variables . Certain variables can be serialized but contain errors in its deserialization instructions ( which we refer to as undeserializable variables ) , and are typically caused by oversights in incompletely implemented libraries [ 15 , 69 ] . While undetectable via serializability checks prior to checkpointing , Elas- ticNotebook handles them via fallback recomputation : if Elastic- Notebook encounters an error while deserializing a stored variable during session restoration , it will trace the AHG to determine and rerun ( only ) necessary cell executions to recompute said variable , which is still faster than recomputing the session from scratch . 6.2 Design Considerations Definition of Session State . In ElasticNotebook , the session state is formally defined as the contents of the user namespace dictionary ( user_ns ) , which contains key-value pairs of variable names to their 2Rerunning 𝑡3 also recomputes l1 ; however , it will be overwritten with the stored l1 in the checkpoint file following the procedure in §3.2 . This is to preserve the link between l1 and 2dlist1 . Zhaoheng Li , Pranav Gor , Rahul Prabhu , Hui Yu , Yuzhou Mao , Yongjoo Park values ( i.e. , reachable objects ) . The session state does not include local/module/hidden variables , which we do not aim to capture . Unobservable State / External Functions . Although the Pickle protocol is followed by almost all libraries , there could be lesser- known ones with incorrect serialization ( e.g. , ignoring data defined in a C stack ) . To address this , ElasticNotebook can be easily ex- tended to allow users to annotate cells/variables to inform our system that they must be recomputed for proper reconstruction . Mathematically , this has the same effect as setting their recomputa- tion costs to infinity in Eq . ( 2 ) . Cell Executions with Side Effects . Certain cell executions may cause external changes outside a notebook session ( e.g. , filesystem ) and may not be desirable to rerun ( e.g. , uploading items to a reposi- tory ) . Our prototype currently does not identify these side effects as our focus is read-oriented data science and analytics workloads . Nevertheless , our system can be extended at least in two ways to prevent them . ( 1 : Annotation ) We can allow users to add manual annotations to the cells that may cause side effects ; then , our system will never re-run them during replications3 ( 2 : Sandbook ) We can block external changes by replicating a notebook into a sandbox with altered file system access ( e.g. , chroot [ 73 ] ) and blocked out- going network ( e.g. , ufw [ 27 ] ) . The sandbox can then be associated with regular file/network accesses upon successful restoration . Non-deterministic Operations . The replication has the same ef- fect as rerunning the cells in the exact same order as they occurred in the past ; thus , under the existence of nondeterministic operations ( e.g. , randint ( ) ) , the reconstructed variables may have different values than the original ones . Users can avoid this by using annota- tions to inform ElasticNotebook to always copy them . Library Version Compatibility . Accurate replication is ensured when external resources ( e.g. , installed modules , database tables ) remain the same before and after the replication . While there are existing tools ( i.e. , pip freeze [ 84 ] ) for reproducing computational environments on existing data science platforms ( i.e. , Jupyter Note- book , Colab ) [ 1 , 115 ] , this work does not incorporate such tools . 7 EXPERIMENTAL EVALUATION In this section , we empirically study the effectiveness of Elastic- Notebook ’ s session replication . We make the following claims : 1 . Robust Replication : Unlike existing mechanisms , ElasticNote- book is capable of replicating almost all notebooks . ( §7.2 ) 2 . Faster Migration : ElasticNotebook reduces session migration time to upscaled/downscaled machines by 85 % –98 % /84 % -99 % compared to rerunning all cells and is up to 2.07×/2.00× faster than the next best alternative , respectively . ( §7.3 ) 3 . Faster Resumption : ElasticNotebook reduces session restora- tion time by 94 % –99 % compared to rerunning all cells and is up to 3.92× faster than the next best alternative . ( §7.4 ) 4 . Low Runtime Overhead : ElasticNotebook incurs negligible overhead—amortized runtime and memory overhead of < 2.5 % and < 10 % , respectively . ( §7.5 ) 3Replication may be unfeasible due to annotations , e.g. , an unserializable variable requiring an cell execution annotated ’ never-rerun ’ to recompute . ElasticNotebook can detect these cases as they have infinite min-cut cost ( §5.4 ) , upon which the user can be warned to delete the problematic variable to proceed with replicating the remaining ( majority of ) variables in the state . ElasticNotebook : Enabling Live Migration for Computational Notebooks Table 3 : Summary of datasets for evaluation . Dataset Notebooks Runtime ( s ) Input data ( MB ) Cell count Kaggle [ 57 ] 35 JWST [ 60 ] 5 5 Tutorial [ 107 ] HW [ 13 , 46 , 66 ] 15 107–12,560 2–109 1–139 16–439 178-31831 25–323 10–96 9–1203 15–103 21–44 10–48 11–160 5 . Low Storage Overhead : ElasticNotebook ’ s checkpoint sizes are up to 66 % smaller compared to existing tools . ( §7.6 ) 6 . Adaptability to System Environments : ElasticNotebook achieves consistent savings across various environments with different network speeds and available compute resources . ( §7.7 ) 7 . Scalability for Complex Notebooks : ElasticNotebook ’ s run- time and memory overheads remain negligible ( < 150ms , < 4MB ) even for complex notebooks with 2000 cells . ( §7.8 ) 7.1 Experiment Setup Datasets . We select a total of 60 notebooks from 4 datasets : • Kaggle [ 57 ] : We select 35 popular notebooks on the topic of EDA ( exploratory data analysis ) + machine learning from Kaggle created by Grandmaster/Master-level users . • JWST [ 60 ] : We select 5 notebooks on the topic of data pipelining from the example notebooks provided on investigating data from the James Webb Space Telescope ( JWST ) . • Tutorial [ 107 ] : We select 5 notebooks from the Cornell Vir- tual Workshop Tutorial . These notebooks are lightweight and introduce tools ( i.e. , clustering , graph analysis ) to the user . • Homework [ 13 , 46 , 66 ] : 15 in-progress notebooks are chosen from data science exercises . They contain out-of-order cell exe- cutions , runtime errors , and mistakes ( e.g. , df_backup=df4 ) . Table 3 reports our selected notebooks ’ dataset sizes and runtimes . Methods . We evaluate ElasticNotebook against existing tools ca- pable of performing session replication : • RerunAll [ 102 ] : Save ( only ) cell code and outputs as an ipynb file . All cells are rerun to restore the session state . • CRIU [ 18 ] : Performs a system-level memory dump of the pro- cess hosting the notebook session . The session state is restored by loading the memory dump and reviving the process . • % Store [ 104 ] : A checkpointing tool that serializes variables one by one into storage . We use a modified version using Dill [ 39 ] instead of Pickle [ 38 ] for robustness.5 • DumpSession [ 40 ] : Unlike % Store , DumpSession packs the en- tire session state into one single file . Ablation Study . We additionally compare against the following ablated implementations of ElasticNotebook : • ElasticNotebook + Helix [ 116 ] : We replace our min-cut solution with Helix , which does not consider linked variables ( §5.3 ) . • EN ( No ID graph ) : This method omits ID Graphs , relying only on AST analysis and object hashes for detecting variable accesses and modifications , respectively . 4This creates a shallow copy of df , which does not serve the purpose of backup . 5The original implementation of % store uses Python Pickle [ 38 ] , and fails on too many notebooks to give meaningful results . RerunAll % Store EN ( No ID graph ) 100 % 80 % 60 % 40 % 20 % 0 % ) % ( e t a r s s e c c u S CRIU ( same architecture ) DumpSession ElasticNotebook ( Ours ) CRIU ( cross-architecture ) ElasticNotebook + Helix e r u l i a f % 0 0 1 Figure 9 : Ratio of correct replications . ElasticNotebook achieves 100 % correctness , on par with full rerun ( RerunAll ) . Table 4 : Existing work fails for these cases . Ours works . Notebook ( s ) NFL [ 88 ] All 5 JWST notebooks [ 60 ] Arxiv [ 70 ] Plant [ 94 ] Type hashlib [ 33 ] mmap [ 36 ] Description and purpose Dropdown list in plot Helps avoid reading large file into memory generator [ 32 ] Speedup iterable comprehension via lazy element generation We consider these methods regarding replication correctness ( §7.2 ) to gauge the impact of ignoring ( 1 ) the linked constraint and ( 2 ) implicit accesses and structural modifications , respectively . Environment . We use an Azure Standard D32as v5 VM instance with 32 vCPUs and 128 GB RAM . For the migration experiment ( §7.3 ) , we migrate sessions from D32as to D64as/D16as with 64/16 vCPUs and 256/64 GB RAM for upscaling/downscaling , respectively . Input data and checkpoints are read/stored from/to an Azure stor- age with block blobs configuration ( NFS ) . Its network bandwidth is 274 MB/s with a read latency of 175 𝜇𝑠 . Time measurement . We measure ( 1 ) migration time as the time from starting the checkpointing process to having the state restored ( i.e. , all variables declared into the namespace ) in the destination session and ( 2 ) restoration time as the time to restore the state from a checkpoint file . We clear our cache between ( 1 ) checkpointing and restoring a notebook and ( 2 ) between subsequent runs . Reproducibility . Our implementation of ElasticNotebook , experi- ment notebooks , and scripts can be found in our Github repository.6 7.2 Robust Session Replication This section compares the robustness of ElasticNotebook ’ s session replication to existing methods . We count the number of isomorphic ( thus , correct ) replications ( §5.1 ) achieved with each method on the 60 notebooks and report the results in Fig 9 . ElasticNotebook correctly replicates all sessions , on par with full rerun from checkpoint file ( which almost always works ) . No- tably , it replicates 19 , 25 , and 2 notebooks containing unserializable variables , variable aliases , and undeserializable variables ( §6.1 ) , re- spectively . DumpSession and % Store fail on 19/60 notebooks con- taining unserializable variables , many of which are used to enhance data science workflow efficiency ( examples in Table 4 ) ; ElasticNote- book successfully replicates them as it can bypass the serialization of these variables through recomputation . % Store additionally fails on 21/60 notebooks ( total 40/60 ) without unserializable variables but contain variable aliases ( i.e. , Timeseries [ 89 ] notebook , Cell 15 , 6https : RerunAll CRIU 100 % 100 % 100 % 100 % % Store 49 % DumpSession ElasticNotebook ( Ours ) 100 % 100 % 100 % 100 % 100 % 51 % 100 % 100 % 84 % 100 % 60 % 86 % Zhaoheng Li , Pranav Gor , Rahul Prabhu , Hui Yu , Yuzhou Mao , Yongjoo Park Sklearn [ 109 ] NLP [ 2 ] StoreSales [ 7 ] TPS-Mar [ 113 ] Glove [ 92 ] Trading [ 95 ] Timeseries [ 80 ] Stacking [ 24 ] Agriculture [ 109 ] LANL [ 87 ] HW-LM [ 45 ] HW-ex3 [ 67 ] l l A n u r e R f o % e m T i 40 % 30 % 20 % 10 % 0 % Figure 10 : ElasticNotebook ’ s session upscaling time ( D32as v5 VM→D64as v5 VM ) vs. existing tools . Times normalized w.r.t . RerunAll . ElasticNotebook speeds up migration by 85 % -98 % and is up to 2.07× faster than the next best alternative . l l A n u r e R f o % e m T i 20 % 15 % 10 % 5 % 0 % RerunAll 100 % 100 % CRIU 100 % % Store DumpSession ElasticNotebook ( Ours ) 100 % 100 % 100 % 100 % 100 % 100 % 31 % 100 % 29 % 100 % 24 % 100 % 25 % Sklearn [ 109 ] NLP [ 2 ] StoreSales [ 7 ] TPS-Mar [ 113 ] Glove [ 92 ] Trading [ 95 ] Timeseries [ 80 ] Stacking [ 24 ] Agriculture [ 109 ] LANL [ 87 ] HW-LM [ 45 ] HW-ex3 [ 67 ] Figure 11 : ElasticNotebook ’ s session restoration time vs. existing tools . Times normalized w.r.t . RerunAll . ElasticNotebook speeds up session restore by 94 % -99 % , and is up to 3.92× faster compared to the next best alternative . Table 5 : Runtime and memory overhead of ElasticNotebook ’ s workflow monitoring on selected notebooks . Notebook runtime ( s ) Total cell monitoring time ( s ) Runtime overhead ( % ) User Namespace memory usage ( MB ) 1021.45 ElasticNotebook memory usage ( MB ) 19.16 1.88 Memory overhead ( % ) Sklearn 58.48 1.26 2.14 NLP 1016.77 4.30 0.42 325.82 4.73 1.45 StoreSales TPS-Mar Glove 696.64 178.42 283.06 6.43 1.34 0.81 0.92 0.78 0.28 347.16 1558.52 6732.17 33.25 1.69 0.14 9.58 0.11 0.002 Trading 687.54 0.46 0.07 1363.32 4.09 0.30 Timeser . 204.10 0.60 0.29 130.27 0.28 0.21 Stacking Agricult . LANL 269.40 788.54 3.08 2.13 1.14 0.27 5026.48 20211.51 0.06 0.33 0.001 0.002 1437.87 0.19 0.01 7641.19 0.14 0.001 HW-LM HW-ex3 22.54 0.50 2.21 31.28 0.99 3.16 27.29 0.09 0.32 19.06 0.47 2.45 linked components of a Matplotlib [ 105 ] plot—f , fig , ax ) ; it serial- izes variables into individual files , which breaks object references and isomorphism . ElasticNotebook ’ s linked variables constraint ( §5.3 ) ensures that it does not do so . ElasticNotebook + Helix fails to correctly replicate 5/60 notebooks containing variable aliases due to its lacking of the linked variable constraint . EN ( No ID graph ) fails to correctly replicate 11/60 sessions due to it missing indirect accesses and structural modifications causing incorrect construc- tion of the AHG , which in turn leads it to recompute some variables value-incorrectly . CRIU fails on one notebook [ 90 ] which contains an invisible file ; however , unlike ElasticNotebook ’ s failures , this failure is currently a fundamental limitation in CRIU [ 17 ] . Robust Migration across System Architectures . We additionally performed session replication from our D32as VM ( x64 architecture ) to a D32pds V5 VM instance ( arm64 architecture ) . The CRIU images can not be replicated across machines with different architectures . In contrast , ElasticNotebook does not have such a limitation . 7.3 Faster Session Migration This section compares the efficiency of ElasticNotebook ’ s session migration to existing methods . We choose 10 notebooks with no unserializable variables ( otherwise , existing methods fail ) to com- pare the end-to-end session migration time achieved by different methods . We report upscaling and downscaling results in Fig 10 and Fig 16 , respectively . The design goal of ElasticNotebook is to reduce session replica- tion time through balancing variable storage and recomputation , which is successfully reflected as follows . ElasticNotebook is able to reduce session migration time to the upscaled/downscaled VMs by 85 % –98 % /84 % -99 % compared RerunAll . Compared to DumpSes- sion , % Store , and CRIU , which store all variables in the checkpoint file , ElasticNotebook upscales/downscales up to 2.07×/2.00× faster than the best of the three . DumpSession , while being the next best alternative for upscaling/downscaling on 8/9 notebooks , falls short in robustness as demonstrated in §7.2 . % Store ’ s individual reading and writing of each variable results in high overhead from multiple calls to the NFS for each migration . CRIU is the slowest non-rerun method for upscaling/downscaling on 6/7 notebooks , due to the size of its memory dump ( higher I/O during migration ) being up to 10× larger compared to checkpoint files from native tools ( §7.6 ) . 7.4 Faster Session Restoration In this section , we compare the efficiency of ElasticNotebook ’ s session restoration to existing methods . We generate checkpoint files using each method , then compare the time taken to restore the session from the checkpoint files on the 10 notebooks from §7.3 . For ElasticNotebook , we set the coefficient 𝛼 to 0.05 ( §5.2 ) to emphasize session restoration time heavily . We report the results in Fig 10 . ElasticNotebook ’ s restoration time is 94 % –99 % faster compared to full rerun . Compared to the baselines , ElasticNotebook is 3.92× faster than the next best alter- native . These fast restoration can be attributed to ElasticNotebook capable of adapting to the new optimization objective , unlike the baselines : for example , on the Sklearn [ 109 ] notebook , instead of re- running cell 3 ( df = pd.read_csv ( ... ) ) to re-read the dataframe df into the session as in the migration-centric plan , the restoration- centric plan opts to store df instead . The reasoning is that despite the sum of serialization and deserialization times of df being greater than the re-reading time with pd.read_csv ( 6.19s + 1.17s > 5.5s ) , the deserialization time by itself is less than the re-reading time ( 1.17s < 5.5s ) ; hence , storing df is the optimal choice . ElasticNotebook : Enabling Live Migration for Computational Notebooks RerunAll DumpSession 1048 % CRIU ElasticNotebook ( Ours ) 283 % 388 % 467 % % Store 1137 % 200 % 150 % 100 % 50 % S D f o % e z i S 0.5 % 0.4 % 5.6 % 2.6 % 0.1 % 0.5 % NLP [ 2 ] TPS [ 113 ] Trading [ 95 ] Timeseries [ 80 ] Agriculture [ 109 ] HW-LM [ 45 ] Figure 12 : ElasticNotebook ’ s checkpoint file size vs. exist- ing tools . Times normalized w.r.t . output from DumpSession . ElasticNotebook ’ s checkpoint file size is up to 67 % smaller compared to those from existing tools ( excluding RerunAll ) . 7.5 Low Runtime Overhead This section investigates the overhead of ElasticNotebook ’ s note- book workflow monitoring . We measure ElasticNotebook ’ s total time spent in pre/post-processing steps before/after each cell execu- tion for updating the AHG and cell runtimes ( Total cell monitoring time ) , and total storage space taken to store the AHG , ID Graphs , and hashes at checkpoint time ( ElasticNotebook memory usage ) . We report the results in Table 5 . ElasticNotebook ’ s cell monitor- ing incurs a maximum and median runtime overhead of ( only ) 2.21 % and 0.6 % ; thus , ElasticNotebook can be seamlessly integrated into existing workflow . ElasticNotebook is similarly memory-efficient as its stored items ( AHG , ID Graphs , and hashes ) are all metadata largely independent of the size of items in the session : the median memory overhead is 0.25 % , with the worst case being 9.58 % . Fine-grained Analysis . To study the per-cell time and memory overheads during experimental notebook usage , we examined three notebooks from Homework category to confirm the maximum time and memory overheads were 92ms and 4.9MB , respectively . We report details in Appendix A.1 . 7.6 Lower Storage Overhead This section measures the storage cost of ElasticNotebook ’ s check- point files : we compare the migration-centric checkpoint file sizes from ElasticNotebook and those from other baseline methods . We report select results in Fig 12 . ElasticNotebook ’ s AHG al- lows it to choose between storing and recomputing each variable , reflected in ElasticNotebook ’ s checkpoint files being up to 67 % smaller compared to DumpSession ’ s . For example , on the Agri- culture [ 89 ] notebook , ElasticNotebook recomputes the train-test splits of the input dataframes X and Y ( Cell 5 , x_train , x_test , ... = train_test_split ( X , Y ) ) instead of storing them in the check- point file : this saves considerable storage space ( 2.5GB ) in addition to speeding up migration . Conversely , CRIU ’ s checkpoint file sizes can be 10× larger than ElasticNotebook ’ s as it additionally dumps memory occupied by the Python process itself and imported mod- ules , no matter necessary or not , into the checkpoint file . Output sizes from RerunAll ( i.e. , notebook metadata size consisting of cell code and outputs ) are provided for comparison . While metadata are significantly smaller than checkpoint files , the storage benefit is offset by significantly slower session recovery times ( §7.4 ) . 7.7 Performance Gains Across Environments This section demonstrates ElasticNotebook ’ s operation in environ- ments with varying specifications . We perform a parameter sweep ElasticNotebook Migrate Time DumpSession ElasticNotebook Recompute Time RerunAll ) s ( e m T i ) s ( e m T i 1,250 1,000 750 500 250 0 2,000 1,500 1,000 500 0 1600 800 400 200 100 50 Network bandwidth ( Mbps ) ( a ) AI4CODE [ 53 ] 1600 800 400 200 100 50 Network bandwidth ( Mbps ) ) s ( e m T i 2,500 2,000 1,500 1,000 500 0 ) s ( e m T i 500 400 300 200 100 0 1600 800 400 200 100 50 Network bandwidth ( Mbps ) ( b ) Stacking [ 24 ] 1600 800 400 200 100 50 Network bandwidth ( Mbps ) ( c ) Agriculture [ 89 ] ( d ) Asset [ 95 ] Figure 13 : ElasticNotebook adapts to different environments for its replication plan . The lower the network bandwidth , the more variables are recomputed . Twitter [ 110 ] Interactive [ 108 ] Sklearn [ 109 ] ) B M ( d a e h r e v O 4 3 2 1 0 ) s m ( e m T i 0 500 1500 1000 No . cell executions 2000 ( a ) AHG size 150 100 50 0 0 500 1500 1000 No . cell executions ( b ) Optimization Time 2000 Figure 14 : Scalability of ElasticNotebook with cell execution count . The size of AHG increases linearly . Replication plan optimization time increases sub-linearly . on the NFS network bandwidth via rate limiting [ 10 ] and compare the migration time of ElasticNotebook , DumpSession ( migrating all variables ) , and RerunAll . We report the results in Fig 13 . ElasticNotebook ’ s balancing of variables storage and recomputation ensures that it is always at least as fast as the faster of DumpSession and RerunAll . Notably , Elastic- Notebook can adapt to the relative availability between network bandwidth and compute power : as the bandwidth decreases , the replication plan is changed accordingly to migrate more variables through recomputation rather than storage . For example , on the Stacking [ 24 ] notebook , at regular bandwidth ( > 400Mbps ) , Elastic- Notebook ’ s replication plan includes migrating most of the session state , opting only to recompute certain train/test splits ( i.e. , Cell 37 , Y_train , Y_validation ) . At < 400 Mbps , ElasticNotebook modifies its plan to recompute instead of store a computationally expensive processed dataframe ( Cell 39 , latest_record ) . At < 100 Mbps , Elas- ticNotebook modifies its plan again to only store the imported class and function definitions ( i.e. , XGBRegressor , mean_squared_error in Cell 1 ) while recomputing the rest of the notebook . 7.8 Scaling to Complex Workloads In this section , we test the scalability of ElasticNotebook ’ s session replication on complex notebook sessions with a large number of cell executions and re-executions . Specifically , we choose 3 tutorial notebooks , on which we randomly re-execute cells and measure the ( 1 ) size of ElasticNotebook ’ s AHG and ( 2 ) optimization time for computing the replication plan at up to 2000 cell re-executions7 . 7This is twice the length of the longest observed notebook on Kaggle [ 50 ] . We report the results in Fig 14 . The memory consumption of Elas- ticNotebook ’ s AHG exhibits linear scaling vs. the number of cell executions reaching only < 4MB at 2000 cell re-executions , which is negligible compared to the memory consumption of the note- book session ( > 1GB ) itself . ElasticNotebook ’ s optimization time for computing the replication plan similarly exhibits linear scaling , reaching a negligible < 150ms at 2000 cell re-executions : ElasticNote- book ’ s chosen algorithm for solving min-cut , Ford-Fulkerson [ 30 ] , has time complexity 𝑂 ( 𝐸 𝑓 ) , where 𝐸 is the number of edges in the AHG and 𝑓 is the cost of the optimal replication plan : The former scales linearly while the latter is largely constant . 8 RELATED WORK Intermediate Result Reuse in Data Science . The storage of in- termediate results has been explored in various contexts in Data Science due to the incremental and feed-forward nature of tasks , which allows outputs from prior operations to be useful for speed- ing up future operations [ 42 , 55 , 65 , 111 , 116 , 117 , 122 ] . Examples include caching to speed up model training replay for ML model di- agnosis [ 42 , 111 ] , caching to speed up anticipated future dataframe operations in notebook workflows [ 117 ] , and storage of cell out- puts to facilitate graphical exploration of the notebook ’ s execu- tion history for convenient cell re-runs [ 55 , 65 ] . There are related works [ 116 , 122 ] which algorithmically explore the most efficient way to ( re ) compute a state given currently stored items ; compared to our work , while Helix [ 116 ] similarly features balancing loading and recomputation , its model lacks the linked variable constraint which may result in silently incorrect replication if directly applied to the computational notebook problem setting . Data-level Session Replication . Session replication on Jupyter- based platforms can be performed with serialization libraries [ 34 , 35 , 38 , 39 , 78 ] . There exists a variety of checkpoint tools built on these serialization libraries : IPython ’ s % Store [ 104 ] is a Pickle-based [ 38 ] interface for saving variables to a key-value store ; however , it breaks object references as linked variables are serialized into separate files . The Dill-based [ 39 ] DumpSession [ 40 ] correctly resolves ob- ject references , yet it still fails if the session contains unserializable objects . Tensorflow [ 49 ] and Pytorch [ 29 ] offer periodical check- pointing during ML model training limited to objects within the same library . Jupyter ’ s native checkpointing mechanism [ 102 ] only saves cell metadata and often fails to exactly restore a session due to the common presence of hidden states . Compared to existing data- level tools , session replication with ElasticNotebook is both more efficient and robust : the Application History Graph enables balanc- ing state storage and recomputation , which achieves considerable speedup while avoiding failure on unserializable objects . System-Level Session Replication . Session replication can sim- ilarly be performed using system-level checkpoint/restart ( C/R ) tools , on which there is much existing work [ 6 , 6 , 8 , 12 , 23 , 52 , 72 , 77 , 96 ] . Applicable tools include DMTCP [ 3 ] and CRIU [ 18 ] ; recently , CRUM [ 43 ] and CRAC [ 61 ] have explored extending C/R to CUDA applications . Elsa [ 64 ] integrates CRIU with JupyterHub to enable C/R of JupyterHub servers . Compared to ElasticNotebook , system- level tools are less efficient and robust due to their large memory dump sizes and limited cross-platform portability , respectively . Zhaoheng Li , Pranav Gor , Rahul Prabhu , Hui Yu , Yuzhou Mao , Yongjoo Park Lineage Tracing . Lineage tracing has seen extensive use in state management to enable recomputation of data for more efficient storage of state or fault tolerance [ 16 , 51 , 71 , 82 , 106 , 111 , 120 ] Recently , the usage of data lineage in computational notebooks has enabled multi-version notebook replay [ 76 ] , recommending notebook interactions [ 75 ] , and creating reproducible notebook containers [ 1 ] , and program slicing , i.e. , finding the minimal set of code to run to compute certain variable ( s ) [ 51 , 54 , 65 , 83 , 93 ] . This work adopts lineage tracing techniques to capturing inter-variable dependencies ( the Application History Graph ) for optimization ; to the best of our knowledge , existing works on Python programs focus on capturing value modifications ( via equality comparisons ) ; however , our techniques additionally identifies and captures strucal changes via the ID graph , which is crucial for preserving variable aliases and avoiding silent errors during state replication . Replicating Execution Environment . An identical execution en- vironment may be necessary for session replication on a different machine . There is some recent work exploring environment repli- cation for Jupyter Notebook via containerizing input files and mod- ules [ 1 , 115 ] . While useful in conjunction with ElasticNotebook , we consider these works to be largely orthogonal . Notebook Parameterization and Scripts . There exists works on executing notebooks in parameterized form for systematic experi- mentation ( e.g. , in the form of a script via [ 99 ] or papermill [ 100 ] ) . While ElasticNotebook is designed for use within interactive note- book interfaces , it is similarly applicable for the migration of pa- rameterized notebook execution results . 9 CONCLUSION In this work , we have proposed ElasticNotebook , a new computa- tional notebook system that newly offers elastic scaling and check- pointing/restoration . To achieve this , ElasticNotebook introduces a transparent data management layer between the user interface and the underlying kernel , enabling robust , efficient , and platform- independent state replication for notebook sessions . Its core con- tributions include ( 1 ) low-overhead , on-the-fly application history construction and ( 2 ) a new optimization for combining copying and re-computation of variables that comprise session states . We have demonstrated that ElasticNotebook can reduce upscaling , down- scaling , and restoration times by 85 % -98 % , 84 % -99 % , and 94 % -99 % , respectively , on real-world data science notebooks with negligible runtime and memory overheads of < 2.5 % and < 10 % , respectively . In the future , we plan to achieve higher efficiency and usability by tracing state changes at a finer level . Specifically , we will introduce micro-cells to capture code blocks inside a cell that repeatedly runs ( e.g. , for-loop for machine learning training ) . Then , the system will automatically store intermediate models ( along with other meta- data ) that will enable live migration and checkpointing/restoration for long-running cell executions . ACKNOWLEDGMENTS The authors are grateful to Chandra Chekuri and Kent Quanrud for assistance with the derivation of the reduction to min-cut employed in ElasticNotebook . This work is supported in part by the National Center for Supercomputing Applications and Microsoft Azure . ElasticNotebook : Enabling Live Migration for Computational Notebooks REFERENCES [ 1 ] Raza Ahmad , Naga Nithin Manne , and Tanu Malik . 2022 . Reproducible Notebook Containers using Application Virtualization . In 2022 IEEE 18th International Conference on e-Science ( e-Science ) . IEEE , 1–10 . [ 2 ] AndresHG . 2021 . NLP , GloVe , BERT , TF-IDF , LSTM ... Explained . https : //www . . Jason Ansel , Kapil Arya , and Gene Cooperman . 2009 . DMTCP : Transparent checkpointing for cluster computations and the desktop . In 2009 IEEE Interna- tional Symposium on Parallel & Distributed Processing . IEEE , 1–12 . [ 4 ] Microsoft Azure . 2023 . Azure ML Studio . https : //learn.microsoft.com/en- [ 3 ] . [ 5 ] Microsoft Azure . 2023 . Microsoft Azure pay-as-you-go . https : //azure.microsoft . . [ 6 ] Anju Bala and Inderveer Chana . 2012 . Fault tolerance-challenges , techniques and implementation in cloud computing . International Journal of Computer Science Issues ( IJCSI ) 9 , 1 ( 2012 ) , 288 . [ 7 ] Ekrem Bayar . 2022 . Store Sales TS Forecasting - A Comprehensive Guide . https : comprehensive-guide/notebook . [ 8 ] Mohammad Riyaz Belgaum , Safeeullah Soomro , Zainab Alansari , and Muham- mad Alam . 2018 . Cloud service ranking using checkpoint-based load balancing in real-time scheduling of cloud computing . In Progress in advanced computing and intelligent engineering . Springer , 667–676 . James Bergstra and Yoshua Bengio . 2012 . Random search for hyper-parameter optimization . Journal of machine learning research 13 , 2 ( 2012 ) . [ 9 ] [ 10 ] Simon Séhier Bert Hubert , Jacco Geul . 2020 . WonderShaper . https : //github . com/magnific0/wondershaper . [ 11 ] Michael Brachmann and William Spoth . 2020 . Your notebook is not crumby enough , REPLace it . In Conference on Innovative Data Systems Research ( CIDR ) . [ 12 ] Gang Chen , Hai Jin , Deqing Zou , Bing Bing Zhou , Weizhong Qiang , and Gang Hu . 2010 . Shelp : Automatic self-healing for multiple application instances in a virtual machine environment . In 2010 IEEE International Conference on Cluster Computing . IEEE , 97–106 . [ 13 ] Chhaya Choudhary . 2023 . Machine Learning and Deep learning Notebooks . https : . [ 14 ] Chhaya Choudhary . 2023 . This project is about customer churn predic- tion . https : customer_churn_prediction.ipynb . [ 15 ] Bokeh Contributors . 2023 . Bokeh - Interaction . https : //docs.bokeh.org/en/ [ 16 ] . Iván Cores , Gabriel Rodríguez , Mará J Martín , Patricia González , and Roberto R Osorio . 2013 . Improving scalability of application-level checkpoint-recovery by reducing checkpoint sizes . New Generation Computing 31 ( 2013 ) , 163–185 . [ 17 ] CRIU . 2023 . CRIU - Invisible file . https : //criu.org/Invisible_files . [ 18 ] CRIU . 2023 . Linux CRIU . https : //criu.org/Main_Page . [ 19 ] Andrew Crotty , Alex Galakatos , Emanuel Zgraggen , Carsten Binnig , and Tim Kraska . 2015 . Vizdom : interactive analytics through pen and touch . Proceedings of the VLDB Endowment 8 , 12 ( 2015 ) , 2024–2027 . JupyterHub Idle Culler . 2023. jupyterhub/jupyterhub-idle-culler . JupyterHub Idle Culler . https : //github.com/ [ 20 ] [ 21 ] Renato LF Cunha , Lucas C Villa Real , Renan Souza , Bruno Silva , and Marco AS Netto . 2021 . Context-aware Execution Migration Tool for Data Science Jupyter Notebooks on Hybrid Clouds . In 2021 IEEE 17th International Conference on eScience ( eScience ) . IEEE , 30–39 . [ 22 ] Nvidia Developer . 2023 . Nvidia - CUDA . https : //developer.nvidia.com/cuda- toolkit . [ 23 ] Sheng Di , Yves Robert , Frédéric Vivien , Derrick Kondo , Cho-Li Wang , and Franck Cappello . 2013 . Optimization of cloud task processing with checkpoint- restart mechanism . In Proceedings of the International Conference on High Per- formance Computing , Networking , Storage and Analysis . 1–12 . [ 24 ] DimitreOliveira . 2019 . Model stacking , feature engineering and EDA . https : engineering-and-eda/notebook . [ 25 ] Docker . [ n.d. ] . Docker documentation - Swarm mode overview . https : //docs . docker.com/engine/swarm/ . [ 26 ] Cody Dunne , Nathalie Henry Riche , Bongshin Lee , Ronald Metoyer , and George Robertson . 2012 . GraphTrail : Analyzing large multivariate , heterogeneous networks while supporting exploration history . In Proceedings of the SIGCHI conference on human factors in computing systems . 1663–1672 . [ 27 ] dwd daniel . 2022 . UncomplicatedFirewall . https : //wiki.ubuntu.com/ UncomplicatedFirewall . [ 28 ] Philipp Eichmann , Emanuel Zgraggen , Carsten Binnig , and Tim Kraska . 2020 . Idebench : A benchmark for interactive data exploration . In Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data . 1555–1569 . https : //pytorch- [ 29 ] Lightning AI et al . 2018 . PyTorch ModelCheckpoint . . ModelCheckpoint.html . [ 30 ] LRDR FORD-FULKERSON . 1962 . Flows in Networks . [ 31 ] Python Software Foundation . 2023 . Python - AST . https : //docs.python.org/3/ library/ast.html . [ 32 ] Python Software Foundation . 2023 . Python - Generators . https : //wiki.python . org/moin/Generators . [ 33 ] Python Software Foundation . 2023 . Python Hashlib . https : //docs.python.org/3/ library/hashlib.html . [ 34 ] Python Software Foundation . 2023 . Python JSON . https : //docs.python.org/3/ library/json.html . [ 35 ] Python Software Foundation . 2023 . Python Marshal . https : //docs.python.org/3/ library/marshal.html . [ 36 ] Python Software Foundation . 2023 . Python Mmap . https : //docs.python.org/3/ library/mmap.html . [ 37 ] Python Software Foundation . 2023 . Python Object Reduction . https : //docs . python.org/3/library/pickle.html # object.__reduce__ . [ 38 ] Python Software Foundation . 2023 . Python Pickle Documentation . https : . [ 39 ] The Uncertainty Quantification Foundation . 2023 . Dill - PyPi . https : //pypi.org/ project/dill/ . [ 40 ] The Uncertainty Quantification Foundation . 2023 . Dill dump session . https : . [ 41 ] Tian Gao . 2020 . Python Watchpoints . https : //pypi.org/project/watchpoints/ . [ 42 ] Rolando Garcia , Eric Liu , Vikram Sreekanti , Bobby Yan , Anusha Dandamudi , Joseph E Gonzalez , Joseph M Hellerstein , and Koushik Sen. 2020 . Hindsight logging for model training . arXiv preprint arXiv:2006.07357 ( 2020 ) . [ 43 ] Rohan Garg , Apoorve Mohan , Michael Sullivan , and Gene Cooperman . 2018 . CRUM : Checkpoint-restart support for CUDA ’ s unified memory . In 2018 IEEE International Conference on Cluster Computing ( CLUSTER ) . IEEE , 302–313 . [ 44 ] GDB . 2022 . GDB Watchpoints . https : //sourceware.org/gdb/download/ . [ 45 ] Aurélien Geron . 2023 . Chapter 4 – Training Models . https : //github.com/ageron/ . [ 46 ] Aurélien Geron . 2023 . Machine Learning Notebooks , 3rd edition . https : //github . com/ageron/handson-ml3 . [ 47 ] Google . 2023 . Google Colab . https : //colab.research.google.com/ . [ 48 ] Google . 2023 . Google Colab pay-as-you-go . https : //colab.research.google.com/ signup . [ 49 ] Google . 2023 . Tensorflow Checkpoint . https : //www.tensorflow.org/guide/ checkpoint . [ 50 ] Google and X . 2022 . Google AI4Code – Understand Code in Python Notebooks . https : . [ 51 ] Philip J Guo and Margo I Seltzer . 2012 . Burrito : Wrapping your lab notebook in computational infrastructure . ( 2012 ) . [ 52 ] HAProxy . 2023 . HAProxy . http : //www.haproxy.org/ . [ 53 ] Sanskar Hasija . 2022 . AI4Code Detailed EDA . https : //www.kaggle.com/code/ odins0n/ai4code-detailed-eda . [ 55 ] [ 54 ] Andrew Head , Fred Hohman , Titus Barik , Steven M Drucker , and Robert DeLine . 2019 . Managing messes in computational notebooks . In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems . 1–12 . Inc. Hex Technologies . 2023 . Hex 2.0 : Reactivity , Graphs , and a little bit of Magic . https : //hex.tech/blog/hex-two-point-oh/ . IBM . 2022. knowledge-accelerators/1.0.0 ? topic=catalog-jupyter-notebook . IBM Watson Studio Service . https : //www.ibm.com/docs/en/ [ 56 ] [ 57 ] Kaggle Inc. 2023 . Kaggle . https : //www.kaggle.com/ . [ 58 ] Kaggle Inc. 2023 . Kaggle Forums - Product Feedback . https : //www.kaggle.com/ discussions/product-feedback . [ 59 ] Kaggle Inc. 2023 . Kaggle Notebook Specifications . https : //www.kaggle.com/ docs/notebooks # technical-specifications . [ 60 ] Space Telescope Science Institute . 2023 . JWST Data Analysis Exam- ple . https : example-jupyter-notebooks . [ 62 ] [ 61 ] Twinkle Jain and Gene Cooperman . 2020 . Crac : Checkpoint-restart architecture for cuda with streams and uvm . In SC20 : International Conference for High Performance Computing , Networking , Storage and Analysis . IEEE , 1–15 . Jeremiah W Johnson . 2020 . Benefits and pitfalls of jupyter notebooks in the classroom . In Proceedings of the 21st Annual Conference on Information Technol- ogy Education . 32–37 . [ 63 ] Project Jupyter . 2023 . Jupyter Notebook . https : //jupyter.org/ . [ 64 ] Mario Juric , Steven Stetzler , and Colin T Slater . 2021 . Checkpoint , Restore , and Live Migration for Science Platforms . arXiv preprint arXiv:2101.05782 ( 2021 ) . [ 65 ] David Koop and Jay Patel . 2017 . Dataflow notebooks : encoding and tracking dependencies of cells . In 9th USENIX Workshop on the Theory and Practice of Provenance ( TaPP 2017 ) . [ 66 ] Martin Krasser . 2023 . Machine learning notebooks . https : //github.com/ krasserm/machine-learning-notebook . [ 67 ] Martin Krasser . 2023 . Multi-class Classification . https : //github.com/krasserm/ . [ 68 ] Kubernetes . [ n.d. ] . Kubernetes . https : //kubernetes.io/ . [ 69 ] SFU Database System Lab . 2022 . Dataprep - Low-Code Data Preparation . https : [ 100 ] Nteract Team . 2023 . Welcome to papermill . https : //papermill.readthedocs.io/ //dataprep.ai/ . en/latest/ . [ 70 ] Colin Lagator . 2020 . Arxiv Data Processing . https : //www.kaggle.com/code/ [ 101 ] The IPython Development Team . 2023 . IPython Interactive Computing . https : colinlagator/arxiv-data-processing . //ipython.org/ . Zhaoheng Li , Pranav Gor , Rahul Prabhu , Hui Yu , Yuzhou Mao , Yongjoo Park [ 71 ] Haoyuan Li , Ali Ghodsi , Matei Zaharia , Scott Shenker , and Ion Stoica . 2014 . Tachyon : Reliable , memory speed storage for cluster computing frameworks . In Proceedings of the ACM Symposium on Cloud Computing . 1–15 . [ 72 ] Yawei Li and Zhiling Lan . 2010 . FREM : A fast restart mechanism for general checkpoint/restart . IEEE Trans . Comput . 60 , 5 ( 2010 ) , 639–652 . [ 73 ] Arch Linux . 2023. chroot . https : //wiki.archlinux.org/title/chroot . [ 74 ] Zhicheng Liu and Jeffrey Heer . 2014 . The effects of interactive latency on exploratory visual analysis . IEEE transactions on visualization and computer graphics 20 , 12 ( 2014 ) , 2122–2131 . [ 75 ] Stephen Macke , Hongpu Gong , Doris Jung-Lin Lee , Andrew Head , Doris Xin , and Aditya Parameswaran . 2020 . Fine-grained lineage for safer notebook interactions . arXiv preprint arXiv:2012.06981 ( 2020 ) . [ 76 ] Naga Nithin Manne , Shilvi Satpati , Tanu Malik , Amitabha Bagchi , Ashish Gehani , and Amitabh Chaudhary . 2022 . CHEX : Multiversion Replay with Ordered Checkpoints . arXiv preprint arXiv:2202.08429 ( 2022 ) . [ 77 ] Anjali D Meshram , AS Sambare , and SD Zade . 2013 . Fault tolerance model for reliable cloud computing . International Journal on Recent and Innovation Trends in Computing and Communication 1 , 7 ( 2013 ) , 600–603 . Inc. MongoDB . 2023 . BSON . https : bson/index.html . [ 78 ] [ 79 ] Philipp Moritz , Robert Nishihara , Stephanie Wang , Alexey Tumanov , Richard Liaw , Eric Liang , Melih Elibol , Zongheng Yang , William Paul , Michael I Jordan , et al . 2018 . Ray : A distributed framework for emerging { AI } applications . In 13th { USENIX } Symposium on Operating Systems Design and Implementation ( { OSDI } 18 ) . 561–577 . [ 80 ] Rob Mulla . 2020 . Time Series forecasting with Prophet . https : //www.kaggle . . [ 81 ] Devin Petersohn , Stephen Macke , Doris Xin , William Ma , Doris Lee , Xiangxi Mo , Joseph E Gonzalez , Joseph M Hellerstein , Anthony D Joseph , and Aditya Parameswaran . 2020 . Towards scalable dataframe systems . arXiv preprint arXiv:2001.00888 ( 2020 ) . [ 82 ] Arnab Phani , Benjamin Rath , and Matthias Boehm . 2021 . LIMA : Fine-grained Lineage Tracing and Reuse in Machine Learning Systems . In Proceedings of the 2021 International Conference on Management of Data . 1426–1439 . Joao Felipe Pimentel , Leonardo Murta , Vanessa Braganholo , and Juliana Freire . 2017. noWorkflow : a tool for collecting , analyzing , and managing provenance from python scripts . Proceedings of the VLDB Endowment 10 , 12 ( 2017 ) . [ 84 ] The pip developers . 2023 . Pip Freeze . https : //pip.pypa.io/en/stable/cli/pip_ [ 83 ] freeze/ . [ 85 ] Olga Poppe , Qun Guo , Willis Lang , Pankaj Arora , Morgan Oslake , Shize Xu , and Ajay Kalhan . 2022 . Moneyball : proactive auto-scaling in Microsoft Azure SQL database serverless . Proceedings of the VLDB Endowment 15 , 6 ( 2022 ) , 1279–1287 . [ 86 ] PBC Posit Software , PBC formerly RStudio . 2023 . Posit RStudio . https : //posit . [ 102 ] The IPython Development Team . 2023 . Jupyter checkpoint . https : //jupyter- . [ 103 ] The IPython Development Team . 2023 . Jupyter Magics Class . https : //ipython . . [ 104 ] The IPython Development Team . 2023 . Jupyter store magic . https : //ipython . . [ 105 ] The Matplotlib Development Team . 2023 . Matplotlib . https : //matplotlib.org/ . [ 106 ] Quoc-Cuong To , Juan Soto , and Volker Markl . 2018 . A survey of state manage- ment in big data processing systems . The VLDB Journal 27 , 6 ( 2018 ) , 847–872 . [ 107 ] Cornell University . 2021 . Cornell Virtual Workshop Tutorial Notebooks . https : . [ 108 ] Cornell University . 2021 . Investigating Tweet Timelines Using Interactive Bokeh Scatterplots . https : . [ 109 ] Cornell University . 2021 . SKLearn Tweet Classification . https : tweet_classification.ipynb . [ 110 ] Cornell University . 2021 . Twitter Networks . https : //github.com/CornellCAC/ . [ 111 ] Manasi Vartak , Joana M F. da Trindade , Samuel Madden , and Matei Zaharia . 2018 . Mistique : A system to store and query model intermediates for model diagnosis . In Proceedings of the 2018 International Conference on Management of Data . 1285–1300 . [ 112 ] Alexandre Verbitski , Anurag Gupta , Debanjan Saha , Murali Brahmadesam , Kamal Gupta , Raman Mittal , Sailesh Krishnamurthy , Sandor Maurice , Tengiz Kharatishvili , and Xiaofeng Bao . 2017 . Amazon aurora : Design considerations for high throughput cloud-native relational databases . In Proceedings of the 2017 ACM International Conference on Management of Data . 1041–1052 . [ 113 ] Devlikamov Vlad . 2022 . [ TPS-Mar ] Fast workflow using scikit-learn- https : intelex . . [ 114 ] Eric-Jan Wagenmakers and Simon Farrell . 2004 . AIC model selection using Akaike weights . Psychonomic bulletin & review 11 , 1 ( 2004 ) , 192–196 . [ 115 ] Dimuthu Wannipurage , Suresh Marru , and Marlon Pierce . 2022 . A Framework to capture and reproduce the Absolute State of Jupyter Notebooks . arXiv preprint arXiv:2204.07452 ( 2022 ) . [ 116 ] Doris Xin , Stephen Macke , Litian Ma , Jialin Liu , Shuchen Song , and Aditya Parameswaran . 2018 . Helix : Holistic optimization for accelerating iterative machine learning . arXiv preprint arXiv:1812.05762 ( 2018 ) . [ 117 ] Doris Xin , Devin Petersohn , Dixin Tang , Yifan Wu , Joseph E Gonzalez , Joseph M Hellerstein , Anthony D Joseph , and Aditya G Parameswaran . 2021 . Enhancing the interactivity of dataframe queries by leveraging think time . arXiv preprint arXiv:2103.02145 ( 2021 ) . [ 118 ] xxHash . 2023. xxHash - Extremely fast non-cryptographic hash algorithm . co/ . https : //github.com/Cyan4973/xxHash . [ 87 ] Gabriel Preda . 2019 . LANL Earthquake EDA and Prediction . https : //www . [ 119 ] Yandex . 2023 . CatBoost - open-source gradient boosting library . https : //catboost . . ai/ . [ 88 ] Kalilur Rahman . 2022 . NFL Data Bowl 2023 - Offensive Plays EDA . https : plays-eda/notebook . [ 89 ] DS Rahul . 2020 . Agricultural Drought Prediction . https : //www.kaggle.com/ . [ 90 ] Mani Raj . 2022 . Amex Dataset . https : amex-dataset . [ 91 ] Amazon Web Services . 2023 . AWS JupyterHub . https : //docs.aws.amazon.com/ . [ 92 ] Shahules . 2022 . Basic EDA , Cleaning and GloVe . https : //www.kaggle.com/code/ . [ 93 ] Shreya Shankar , Stephen Macke , Sarah Chasins , Andrew Head , and Aditya Parameswaran . 2022 . Bolt-on , compact , and rapid program slicing for notebooks . Proceedings of the VLDB Endowment 15 , 13 ( 2022 ) , 4038–4047 . [ 94 ] shreyas thorat30 . 2023 . Plant disease classification SDP . https : //www.kaggle . . [ 95 ] Andrey Shtrauss . 2022 . Building an Asset Trading Strategy . https : //www.kaggle . . [ 96 ] Stelios Sidiroglou , Oren Laadan , Carlos Perez , Nicolas Viennot , Jason Nieh , and Angelos D Keromytis . 2009 . Assure : automatic software self-healing using rescue points . ACM SIGARCH Computer Architecture News 37 , 1 ( 2009 ) , 37–48 . [ 97 ] StackOverflow . 2019 . Colab Session Timeout . https : //stackoverflow.com/ . [ 98 ] Stitchfix . 2017 . Nodebooks . https : //github.com/stitchfix/nodebook . [ 99 ] Jupyter Development Team . 2023. nbconvert - Jupyter Notebook Conversion . https : //github.com/jupyter/nbconvert . [ 120 ] Matei Zaharia , Mosharaf Chowdhury , Michael J Franklin , Scott Shenker , and Ion Stoica . 2010 . Spark : Cluster computing with working sets . In 2nd USENIX Workshop on Hot Topics in Cloud Computing ( HotCloud 10 ) . [ 121 ] Emanuel Zgraggen , Robert Zeleznik , and Steven M Drucker . 2014 . Panoram- icData : Data analysis through pen & touch . IEEE transactions on visualization and computer graphics 20 , 12 ( 2014 ) , 2112–2121 . [ 122 ] Ce Zhang , Arun Kumar , and Christopher Ré . 2016 . Materialization optimizations for feature selection workloads . ACM Transactions on Database Systems ( TODS ) 41 , 1 ( 2016 ) , 1–32 . A APPENDIX A.1 Low Per-cell overhead We report the results for per-cell time and memory overheads on 3 Homework notebooks in Fig 15 . ElasticNotebook ’ s memory and per-cell monitoring overhead are consistently under 10 % and 1ms , respectively . There are occasionally ’ spikes ’ when certain cells declaring/modifying complex variables are executed ; for example , the 60 % and 91ms memory and time overheads of cell 28 in [ 46 ] is attributed to constructing the ID Graph for a complex nested list . However , even in this worst case , the time overhead is still ElasticNotebook : Enabling Live Migration for Computational Notebooks ) B M ( d a e h r e v O 30 20 10 0 0 User namespace memory usage 20 60 40 No . cell executions 80 ) B M ( d a e h r e v O ElasticNotebook memory usage 40 30 20 10 0 0 5 10 15 No . cell executions ) B M ( d a e h r e v O 20 15 10 5 0 0 [ 45 ] [ 67 ] [ 14 ] ) s m ( e m T i 100 75 50 25 0 25 0 25 % 50 % No . cell executions 75 % 100 % 10 5 20 No . cell executions 15 ( a ) Mem . overhead , [ 45 ] ( b ) Mem . overhead , [ 67 ] ( c ) Mem . overhead , [ 14 ] ( d ) Per-cell time overhead Figure 15 : Runtime and memory overhead of ElasticNotebook during notebook use on selected homework notebooks . Memory overhead is consistently low , and per-cell runtime overhead is negligible for most cell executions . RerunAll CRIU % Store DumpSession ElasticNotebook ( Ours ) 100 % 40 % 50 % 100 % 100 % 100 % 100 % 100 % 100 % 100 % 100 % 51 % 100 % 100 % 84 % 100 % 55 % 93 % 30 % 20 % 10 % 0 % Sklearn [ 109 ] NLP [ 2 ] StoreSales [ 7 ] TPS-Mar [ 113 ] Glove [ 92 ] Trading [ 95 ] Timeseries [ 80 ] Stacking [ 24 ] Agriculture [ 109 ] LANL [ 87 ] HW-LM [ 45 ] HW-ex3 [ 67 ] Notebook l l A n u r e R f o % e m T i Figure 16 : ElasticNotebook ’ s session downscaling time ( D32as v5 VM→D16as v5 VM ) vs. existing tools . Times normalized w.r.t . RerunAll . ElasticNotebook speeds up migration by 84 % -99 % and is up to 2.00× faster than the next best alternative . be a an arbitrary variable , and ( 𝑥 , 𝑡 G ) , ( 𝑥 , 𝑡 G∗ ) be its active VSs in G and G∗ respectively . There is 𝑡 G ≥ 𝑡 G∗ : if 𝑡 G > 𝑡 G∗ ( due to falsely implied non-overwrite modifications , i.e. , gen in Fig 17 ) then there must be a path from ( 𝑥 , 𝑡 G ) to ( 𝑥 , 𝑡 G∗ ) : ( 𝑥 , 𝑡 G ) , 𝑐𝑡G , ( 𝑥 , 𝑡𝑘1 ) , 𝑐𝑡𝑘1 , ... , ( 𝑥 , 𝑡𝑘𝑙 ) , 𝑐𝑡𝑘𝑙 < 𝑡 G∗ and , ( 𝑥 , 𝑡 G∗ ) , where 𝑡 G < 𝑡𝑘1 < ... < 𝑡𝑘𝑙 all contain false non-overwrite modifications to 𝑥. There- 𝑐𝑡𝑘1 , ... , 𝑐𝑡𝑘𝑙 fore , the subtree rooted at ( 𝑥 , 𝑡 G ) in G must be contained the subtree rooted at ( 𝑥 , 𝑡 G∗ ) in G∗ , hence 𝑟𝑒𝑞∗ ( 𝑥 , 𝑡 G∗ ) ⊆ 𝑟𝑒𝑞 ( 𝑥 , 𝑡 G ) . □ A.3 Handling Large Pandas Dataframes To avoid hashing large Pandas dataframes after each cell execution , ElasticNotebook uses the dataframes ’ underlying writeable flag as a dirty bit to detect in-place changes : before each cell execution , the writeable flag is set to False , and the dataframe is identified as modified if the flag has been flipped to True after the cell execution . G ( x , 𝒕1 ) 𝒄𝒕1 𝒄𝒕2 ( z , 𝒕2 ) 𝑐𝑡3 G∗ ( x , 𝑡1 ) ( y , 𝑡1 ) ( y , 𝑡1 ) 𝑐𝑡1 𝒄𝒕2 ( z , 𝒕2 ) 𝑐𝑡3 ( x , 𝑡3 ) ( l1 , 𝑡3 ) ( x , 𝑡3 ) ( l1 , 𝑡3 ) ( gen , 𝒕4 ) 𝒄𝒕4 𝒄𝒕5 ( 2dlist , 𝑡4 ) ( gen , 𝒕4 ) 𝒄𝒕4 𝑐𝑡5 ( 2dlist , 𝑡4 ) ( gen , 𝒕5 ) 𝑟𝑒𝑞∗ ( 𝑥 ) = { 𝑐𝑡2 } ⊆ 𝑟𝑒𝑞 ( 𝑥 ) = { 𝑐𝑡1 , 𝑐𝑡2 } 𝑟𝑒𝑞∗ ( 𝑔𝑒𝑛 ) = { 𝑐𝑡4 } ⊆ 𝑟𝑒𝑞 ( 𝑔𝑒𝑛 ) = { 𝑐𝑡4 , 𝑐𝑡5 } ( x , 𝑡1 ) ( Overwritten/deleted ) Variable Snapshot 𝑐𝑡1 Cell Execution ( x , 𝑡1 ) Active Variable Snapshot Figure 17 : AHG G may contain false positives compared to the true AHG G∗ . The correctness is still ensured , while the efficiency may be affected due to extra cells re-running , for example , when recomputing z ( green ) and gen ( red ) . well under the 500ms threshold suggested for interactive data en- gines [ 74 ] , while the memory overhead is of a low absolute value ( 4MB ) compared to the size of the ( not yet loaded ) datasets , thus having negligible user impact . A.2 Proof of Theorem 4.1 An illustration of our proof is provided in Fig 17 . Proof . As there are no false negatives , the true AHG G∗ is con- tained within the approximate AHG G , i.e. , G∗ ⊆ G ( Fig 17 ) . Let 𝑥","['elasticnotebook', 'enable', 'live', 'migration', 'computational', 'technical', 'report', 'pranav', 'gor∗', 'prabhu∗', 'rprabhu5', 'huiy3', 'umichedu', 'p', 'e', 'b', 'c', 'v', 'r', 'abstract', 'computational', 'notebook', 'widely', 'use', 'interactive', 'datum', 'science', 'machine', 'learning', 'framework', 'user', 'start', 'session', 'execute', 'cell', 'set', 'statement', 'create', 'variable', 'train', 'model', 'visualize', 'result', 'unfortunately', 'exist', 'notebook', 'system', 'offer', 'live', 'tion', 'notebook', 'launch', 'new', 'machine', 'lose', 'state', 'prevent', 'user', 'continue', 'task', 'leave', 'dbms', 'session', 'directly', 'rely', 'underlying', 'kernel', 'interpreter', 'addi', 'tional', 'data', 'management', 'layer', 'exist', 'technique', 'preserve', 'state', 'copy', 'variable', 'oslevel', 'checkpointing', 'unreliable', 'often', 'fail', 'inefficient', 'platformdependent', 'also', 'rerun', 'code', 'scratch', 'highly', 'timeconsuming', 'paper', 'introduce', 'new', 'notebook', 'system', 'elastic', 'notebook', 'offer', 'live', 'migration', 'checkpointingrestoration', 'use', 'novel', 'mechanism', 'reliable', 'efficient', 'platform', 'independent', 'specifically', 'observe', 'cell', 'execution', 'parent', 'lightweight', 'monitoring', 'elasticnotebook', 'find', 'reliable', 'efficient', 'way', 'ie', 'replication', 'plan', 'reconstruct', 'origi', 'nal', 'session', 'state', 'consider', 'variablecell', 'dependency', 'observe', 'runtime', 'variable', 'size', 'end', 'new', 'graphbased', 'mization', 'problem', 'find', 'reconstruct', 'variable', 'efficiently', 'subset', 'variable', 'transfer', 'machine', 'show', 'elasticnotebook', 'reduce', 'endtoend', 'migration', 'restoration', 'time', 'respectively', 'ety', 'jwst', 'tutorial', 'notebook', 'negligible', 'runtime', 'memory', 'overhead', 'pvldb', 'reference', 'format', 'pranav', 'gor∗', 'prabhu∗', 'elasticnotebook', 'enable', 'live', 'migration', 'computational', 'notebook', 'xxxxxx', 'doi', 'xxxxxxxxx', 'introduction', 'computational', 'rstudio', 'widely', 'use', 'datum', 'science', 'machine', 'learning', 'interactive', 'torial', 'datum', 'exploration', 'visualization', 'model', 'work', 'license', 'creative', 'common', 'international', 'license', 'visit', 'https', 'view', 'copy', 'license', 'use', 'cover', 'license', 'obtain', 'permission', 'email', 'info', 'vldborg', 'copyright', 'hold', 'ownerauthor', 'publication', 'right', 'license', 'vldb', 'endowment', 'proceeding', 'vldb', 'endowment', 'vol', 'issn', 'doi', 'xxxxxxxxx', 'work', 'use', 'term', 'notebook', 'mean', 'system', 'serve', 'notebook', 'content', 'notebook', 'depend', 'context', 'user', 'interface', 'datum', 'code', 'cell', 'code', 'technique', 'dynamic', 'exe', 'cution', 'history', 'graph', 'technique', 'optimization', 'fast', 'migration', 'python', 'r', 'llvm', 'figure', 'transparent', 'datum', 'layer', 'middle', 'enable', 'robust', 'efficient', 'platformindependent', 'live', 'migration', 'tuning', 'selection', 'cloud', 'provider', 'offer', 'software', 'asaservice', 'hub', 'azure', 'studio', 'studio', 'commonly', 'use', 'library', 'panda', 'pytorch', 'notebook', 'workflow', 'begin', 'user', 'start', 'computing', 'session', 'user', 'execute', 'cell', 'set', 'statement', 'load', 'dataset', 'create', 'variable', 'train', 'model', 'visualize', 'result', 'session', 'terminate', 'manually', 'automatically', 'save', 'resource', 'cost', 'limitation', 'live', 'replication', 'unfortunately', 'exist', 'note', 'book', 'offer', 'transparent', 'infrastructure', 'scale', 'independent', 'application', 'become', 'increasingly', 'popular', 'cloud', 'instant', 'scalability', 'cost', 'reduction', 'eg', 'autoscale', 'dbms', 'microservice', 'orchestration', 'copy', 'notebook', 'file', 'new', 'large', 'memory', 'suspend', 'session', 'save', 'cost', 'resume', 'notebook', 'lose', 'state', 'set', 'variable', 'code', 'output', 'word', 'user', 'resume', 'task', 'previously', 'leave', 'notebook', 'directly', 'rely', 'underlying', 'kernel', 'interpreter', 'c', 'repl', 'addi', 'tional', 'data', 'management', 'layer', 'accordingly', 'variable', 'reside', 'process', 'erase', 'terminate', 'session', 'address', 'potentially', 'save', 'variable', 'restore', 'new', 'environment', 'however', 'exist', 'technique', 'serialize', 'variable', 'checkpointe', 'process', 'fail', 'inefficient', 'platformdependent', 'discuss', 'shortly', 'finally', 'rerun', 'code', 'scratch', 'timeconsume', 'goal', 'propose', 'elasticnotebook', 'notebook', 'system', 'offer', 'live', 'state', 'migration', 'checkpointingrestoration', 'use', 'reliable', 'efficient', 'platformindependent', 'state', 'replication', 'mech', 'anism', 'reliability', 'enable', 'correctsuccessful', 'replication', 'almost', 'notebook', 'efficiency', 'significantly', 'efficient', 'platformindependence', 'rely', 'platform', 'architecturespecific', 'feature', 'elasticnotebook', 'enable', 'live', 'notebook', 'replication', 'potentially', 'notebook', 'workload', 'introduce', 'novel', 'data', 'management', 'layer', 'example', 'user', 'specify', 'new', 'machine', 'run', 'currently', 'active', 'notebook', 'system', 'transparently', 'replicate', 'notebook', 'include', 'variable', 'notebook', 'run', 'new', 'machine', 'pranav', 'rahul', 'park', 'table', 'comparison', 'elasticnotebook', 'possible', 'approach', 'savingrestore', 'session', 'state', 'approach', 'mechanism', 'serializationbase', 'tool', 'systemlevel', 'checkpointe', 'notebook', 'versione', 'replay', 'execution', 'environment', 'elasticnotebook', 'serialize', 'store', 'variable', 'computing', 'session', 'fail', 'unserializable', 'variable', 'save', 'memory', 'dump', 'computing', 'session', 'high', 'network', 'cost', 'low', 'portability', 'enable', 'reexecution', 'versione', 'notebook', 'snapshot', 'result', 'verification', 'migrate', 'instal', 'module', 'useful', 'conjunction', 'orthogonal', 'session', 'state', 'replication', 'optimally', 'combine', 'copyrecompute', 'reliability', 'efficiency', 'platform', 'independence', 'provide', 'capability', 'little', 'modification', 'exist', 'system', 'offer', 'benefit', 'large', 'number', 'datum', 'scientist', 'educator', 'use', 'notebook', 'achieve', 'overcome', 'follow', 'technical', 'challenge', 'challenge', 'create', 'reliable', 'efficient', 'platformindependent', 'replication', 'mechanism', 'challenge', 'first', 'mechanism', 'offer', 'high', 'coverage', 'almost', 'notebook', 'people', 'create', 'able', 'successfully', 'replicate', 'machine', 'second', 'mechanism', 'significantly', 'fast', 'straight', 'forward', 'approach', 'rerun', 'cell', 'exactly', 'run', 'past', 'copy', 'possible', 'variable', 'serial', 'izationdeserialization', 'third', 'mechanism', 'integrate', 'exist', 'notebook', 'system', 'clean', 'separation', 'sustainable', 'development', 'easy', 'adoption', 'approach', 'core', 'idea', 'observe', 'evolution', 'session', 'state', 'lightweight', 'monitoring', 'address', 'important', 'challenge', 'reliability', 'efficiency', 'platform', 'independence', 'combine', 'program', 'language', 'technique', 'thefly', 'code', 'analysis', 'novel', 'algorithmic', 'solution', 'graph', 'base', 'mathematical', 'optimization', 'specifically', 'represent', 'session', 'state', 'change', 'introduce', 'application', 'history', 'special', 'form', 'bipartite', 'graph', 'express', 'dependency', 'variable', 'cell', 'execution', 'use', 'graph', 'take', 'follow', 'approach', 'first', 'achieve', 'reliability', 'platform', 'independence', 'choo', 'e', 'computational', 'plan', 'replication', 'plan', 'safely', 'construct', 'variable', 'generator', 'incompletely', 'define', 'custom', 'class', 'base', 'platform', 'independent', 'variable', 'presence', 'variable', 'serialize', 'platformindependent', 'replication', 'use', 'application', 'history', 'recompute', 'dy', 'namically', 'target', 'machine', 'process', 'elasticnotebook', 'optimize', 'collective', 'cost', 'recompute', 'variable', 'still', 'maintain', 'correctness', 'second', 'efficiency', 'elasticnotebook', 'optimize', 'replication', 'plan', 'determine', 'variable', 'copy', 'variable', 'recompute', 'base', 'copy', 'variable', 'minimize', 'endtoend', 'migration', 'restoration', 'time', 'sideration', 'serialization', 'cost', 'recomputation', 'cost', 'data', 'transfer', 'cost', 'example', 'even', 'variable', 'reliably', 'transfer', 'machine', 'variable', 'still', 'dynamically', 'construct', 'result', 'low', 'total', 'cost', 'make', 'decision', 'principled', 'way', 'devise', 'new', 'graphbased', 'optimization', 'problem', 'reduce', 'wellestablished', 'mincut', 'problem', 'implementation', 'contribution', 'apply', 'many', 'namically', 'analyzable', 'language', 'llvmbase', 'one', 'implement', 'prototype', 'c', 'python', 'user', 'interface', 'widely', 'use', 'datum', 'science', 'machine', 'learn', 'statistical', 'analysis', 'specifically', 'elasticnotebook', 'provide', 'data', 'management', 'layer', 'jupyter', 'hide', 'cell', 'magic', 'transparently', 'monitor', 'cell', 'execution', 'offer', 'efficient', 'replication', 'difference', 'exist', 'work', 'compare', 'exist', 'work', 'pursue', 'significantly', 'different', 'direction', 'example', 'tool', 'make', 'data', 'serialization', 'convenient', 'ever', 'fail', 'session', 'contain', 'nonserializable', 'variable', 'inefficient', 'consider', 'opportunity', 'dy', 'namic', 'recomputation', 'alternatively', 'systemlevel', 'checkpointe', 'platformdependent', 'limited', 'checkpointe', 'memory', 'less', 'efficient', 'dynamic', 'recompu', 'tation', 'impossible', 'building', 'top', 'result', 'reuse', 'lineage', 'trace', 'introduce', 'deep', 'referenceaware', 'analysis', 'novel', 'optimization', 'technique', 'incorporate', 'unique', 'constraint', 'intervariable', 'dependency', 'also', 'empirically', 'confirm', 'effectiveness', 'completely', 'thogonal', 'work', 'include', 'library', 'migration', 'scalable', 'datum', 'science', 'table', 'summarize', 'difference', 'contribution', 'contribution', 'follow', 'motivation', 'discuss', 'alternative', 'approach', 'explain', 'advantage', 'approach', 'architecture', 'describe', 'system', 'architecture', 'efficient', 'robust', 'session', 'replication', 'datum', 'model', 'introduce', 'novel', 'data', 'model', 'application', 'history', 'graph', 'expression', 'session', 'history', 'enable', 'efficient', 'accurate', 'state', 'replication', 'optimization', 'problem', 'solution', 'formally', 'define', 'optimization', 'problem', 'minimize', 'state', 'replication', 'cost', 'balance', 'variable', 'copying', 'recomputation', 'propose', 'efficient', 'effective', 'solution', 'evaluation', 'show', 'elasticnotebook', 'reduce', 'upscale', 'scaling', 'restore', 'time', 'respectively', 'overhead', 'negligible', 'runtime', 'motivation', 'section', 'describe', 'use', 'case', 'requirement', 'session', 'replication', 'intuition', 'high', 'efficiency', 'live', 'migration', 'useful', 'seamless', 'state', 'replication', 'computational', 'notebook', 'low', 'easy', 'infrastructure', 'scaling', 'frequent', 'session', 'suspension', 'interrupt', 'user', 'workflow', 'describe', 'fast', 'replication', 'elastic', 'computing', 'ability', 'move', 'state', 'machine', 'useful', 'scale', 'resource', 'allow', 'migrate', 'live', 'session', 'machine', 'right', 'equipmentresource', 'specific', 'architecture', 'interruptionfree', 'scaling', 'copy', 'datum', 'source', 'elasticnotebook', 'enable', 'live', 'migration', 'computational', 'intercept', 'code', 'def', 'intercept', 'code', 'preprocess', 'code', 'regular', 'kernel', 'execution', 'execute', 'code', 'postprocess', 'code', 'application', 'history', 'cell', 'df', 'cell', '1min', 'cell', 'model', 'cell', 'plot', 'dftest', 'figure', 'cell', 'run', 'inject', 'custom', 'prepost', 'processing', 'logic', 'intercept', 'hide', 'user', 'variable', 'store', 'cost', 'min', 'reload', 'cost', 'min', 'total', 'cost', 'min', 'df', 'dftrain', 'dftest', 'model', 'plot', 'machine', 'target', 'machine', 'way', 'original', 'session', 'state', 'restore', 'process', 'want', 'minimize', 'endtoend', 'time', 'create', 'transfer', 'target', 'machine', 'reconstruct', 'state', 'target', 'machine', 'first', 'use', 'case', 'empirically', 'study', 'fast', 'restart', 'ondemand', 'computing', 'leverage', 'pricing', 'model', 'offer', 'many', 'cloud', 'vendor', 'sus', 'pende', 'session', 'use', 'effective', 'way', 'reduce', 'charge', 'eg', '6×', 'ability', 'cre', 'eat', 'datum', 'sufficient', 'reconstruct', 'current', 'session', 'state', 'persist', 'prior', 'manual', 'automate', 'suspen', 'sion', 'quickly', 'resume', 'need', 'session', 'state', 'achieve', 'ondemand', 'granular', 'computing', 'fast', 'session', 'restart', 'time', 'impact', 'user', 'experience', 'frequent', 'session', 'suspension', 'process', 'want', 'restore', 'session', 'quickly', 'possible', 'minimize', 'time', 'take', 'download', 'reconstruct', 'state', 'second', 'use', 'case', 'empirically', 'study', 'enable', 'data', 'management', 'layer', 'discuss', 'pro', 'con', 'several', 'different', 'approach', 'enable', 'data', 'management', 'layer', 'oslevel', 'checkpointing', 'save', 'current', 'session', 'state', 'checkpoint', 'entire', 'memory', 'space', 'associate', 'underlie', 'kernel', 'make', 'process', 'efficient', 'exist', 'tool', 'patch', 'trace', 'dirty', 'page', 'however', 'describe', 'approach', 'platformindependent', 'incur', 'high', 'space', 'cost', 'limit', 'store', 'state', 'primary', 'memory', 'device', 'empirically', 'compare', 'approach', 'criu', 'understand', 'reliability', 'efficiency', 'object', 'wrapper', 'watchpoint', 'object', 'wrapper', 'com', 'monly', 'use', 'debug', 'purpose', 'program', 'slice', 'maintain', 'deep', 'copy', 'object', 'session', 'state', 'compare', 'check', 'change', 'frame', 'execution', 'ever', 'unsuitable', 'use', 'datum', 'science', 'workflow', 'unacceptable', 'runtime', 'overhead', 'preliminary', 'test', 'monitor', 'cell', 'execution', 'order', 'trace', 'cell', 'exe', 'cution', 'effect', 'variable', 'add', 'lightweight', 'wrapper', 'data', 'management', 'layer', 'function', 'cell', 'execution', 'monitor', 'cell', 'code', 'runtime', 'variable', 'change', 'idea', 'depict', 'conceptually', 'fig', 'specifically', 'implementation', 'use', 'cell', 'magic', 'jupyternative', 'mechanism', 'allow', 'arbitrary', 'modification', 'cell', 'statement', 'cell', 'execute', 'add', 'prepostprocesse', 'step', 'capture', 'cell', 'code', 'result', 'session', 'state', 'modification', 'store', 'var', 'method', 'rerun', 'store', 'fastmigrate', 'model', 'plot', 'fastrestore', 'df', 'model', 'plot', 'rerun', 'cell', 'migration', 'cost', 'restore', 'cost', 'figure', 'example', 'app', 'history', 'top', 'different', 'tion', 'plan', 'cost', 'bottom', 'combine', 'recomputecopy', 'allow', 'fast', 'migration', 'fastmigrate', 'alternatively', 'optimal', 'plan', 'change', 'restoration', 'prioritize', 'fastrestore', 'fast', 'replication', 'application', 'history', 'section', 'describe', 'core', 'idea', 'devise', 'efficient', 'repli', 'cation', 'strategy', 'leverage', 'ability', 'monitor', 'cell', 'execution', 'application', 'history', 'application', 'history', 'graph', 'ahg', 'bipar', 'tite', 'graph', 'express', 'session', 'state', 'change', 'respect', 'cell', 'run', 'type', 'variable', 'transformation', 'transformation', 'node', 'connect', 'input', 'variable', 'output', 'variable', 'see', 'example', 'fig', 'aim', 'achieve', 'property', 'completeness', 'false', 'negative', 'inputoutput', 'variable', 'transformation', 'capture', 'minimal', 'minimal', 'false', 'positive', 'number', 'variable', 'incorrectly', 'identify', 'accessedmodified', 'variable', 'actually', 'accessedmodifie', 'minimize', 'property', 'require', 'correct', 'state', 'reconstruction', 'core', 'optimization', 'idea', 'ahg', 'allow', 'efficient', 'state', 'replica', 'tion', 'combination', 'recompute', 'copy', 'motivate', 'example', 'suppose', 'data', 'analyst', 'fit', 'regression', 'model', 'fig', 'notebook', 'contain', 'cell', 'run', 'datum', 'load', 'cell', 'traint', 'split', 'cell', 'fitting', 'cell', 'evaluation', 'cell', 'fit', 'decide', 'move', 'session', 'new', 'machine', 'simply', 'rerun', 'entire', 'notebook', 'incur', 'minute', 'alternatively', 'serializingcopye', 'variable', 'take', 'minute', 'however', 'efficient', 'approach', 'copy', 'model', 'plot', 'recompute', 'new', 'machine', 'fast', 'migrate', 'complete', 'endtoend', 'migration', 'minute', 'prioritize', 'restoration', 'time', 'reduce', 'userperceived', 'restart', 'time', 'ondemand', 'compute', 'optimize', 'plan', 'fastrestore', 'take', 'minute', 'example', 'illustrate', 'significant', 'optimization', 'opportunity', 'session', 'replication', 'goal', 'ability', 'find', 'good', 'replication', 'plan', 'arbitrarily', 'complex', 'ahgs', 'system', 'overview', 'section', 'present', 'elasticnotebook', 'high', 'level', 'describe', 'component', 'operation', 'datum', 'layer', 'core', 'part', 'elasticnotebook', 'table', 'notation', 'meaning', 'pranav', 'rahul', 'notebook', 'user', 'world', 'cell', 'execution', 'interceptor', 'optimizer', 'graph', 'object', 'hash', 'optimization', 'application', 'history', 'graph', 'cost', 'model', 'session', 'replicator', 'writer', 'notebook', 'usern', 'key', 'val', 'world', 'figure', 'elasticnotebook', 'architecture', 'datum', 'layer', 'act', 'gateway', 'user', 'interface', 'kernel', 'cell', 'execution', 'intercept', 'observe', 'session', 'state', 'change', 'elasticnotebook', 'component', 'elasticnotebook', 'introduce', 'unique', 'data', 'layer', 'act', 'gate', 'way', 'user', 'kernel', 'see', 'fig', 'monitor', 'cell', 'execution', 'observe', 'code', 'result', 'session', 'state', 'change', 'cell', 'execution', 'interceptor', 'cell', 'execution', 'interceptor', 'cept', 'cell', 'execution', 'request', 'add', 'prepostprocesse', 'script', 'reroute', 'underlie', 'kernel', 'regular', 'tion', 'add', 'script', 'perform', 'cell', 'code', 'analysis', 'ahg', 'update', 'cell', 'runtime', 'recording', 'application', 'history', 'graph', 'ahg', 'incrementally', 'build', 'cell', 'execution', 'interceptor', 'record', 'variable', 'accessedmodifie', 'cell', 'execution', 'ahg', 'use', 'optimizer', 'compute', 'replication', 'plan', 'cost', 'model', 'cost', 'model', 'store', 'profile', 'metric', 'cell', 'run', 'time', 'variable', 'size', 'network', 'bandwidth', 'serve', 'hyperpa', 'rameter', 'optimizer', 'optimizer', 'optimizer', 'use', 'ahg', 'cost', 'model', 'determine', 'efficient', 'replication', 'plan', 'consist', 'able', 'store', 'cell', 'rerun', 'discuss', 'elasticnotebook', 'cost', 'model', 'optimization', 'detail', 'session', 'replicator', 'session', 'replicator', 'replicate', 'notebook', 'session', 'accord', 'optimizer', 'plan', 'specifically', 'writer', 'create', 'write', 'checkpoint', 'file', 'storage', 'ssd', 'cloud', 'storage', 'notebook', 'read', 'file', 'restore', 'session', 'follow', 'replication', 'plan', 'discuss', 'elastic', 'notebook', 'session', 'replication', 'detail', 'elasticnotebook', 'workflow', 'section', 'describe', 'operation', 'elasticnote', 'book', 'monitor', 'cell', 'execution', 'session', 'lifecycle', 'perform', 'onrequest', 'replication', 'session', 'step', 'check', 'point', 'writing', 'checkpoint', 'file', 'restoration', 'monitor', 'cell', 'execution', 'cell', 'execution', 'user', 'elasticnotebook', 'perform', 'follow', 'step', 'access', 'variable', 'cell', 'execution', 'identify', 'analysis', 'describe', 'cell', 'code', 'execute', 'definition', 'set', 'variable', 'set', 'variable', 'snapshot', 'vss', 'set', 'active', 'variable', 'snapshot', 'set', 'cell', 'execution', 'ce', 'set', 'write', 'dependency', 'set', 'read', 'dependency', 'symbol', 'v𝑎', 'c', '∪', '∪', 'application', 'history', 'graph', '𝑟𝑒𝑞', 'reconstruction', 'mapping', 'function', '𝑤𝑠𝑡𝑜𝑟𝑒', 'variable', 'storage', 'cost', '𝑤𝑟𝑒𝑟𝑢𝑛', 'c', 'r', 'cell', 'rerun', 'cost', '𝑤m', 'r', 'migration', 'cost', 'function', 'r', 'recomputation', 'cost', 'function', 'pair', 'link', 'variable', 'flow', 'graph', 'h', 'r', 'flow', 'graph', 'edge', 'capacity', 'function', 'variable', 'change', 'ie', 'creationdeletionmodification', 'iden', 'tifie', 'global', 'namespace', 'ahg', 'update', 'use', 'cell', 'code', 'modify', 'variable', 'cell', 'execution', 'cost', 'model', 'update', 'record', 'cell', 'runtime', 'initiate', 'replication', 'replication', 'request', 'elastic', 'notebook', 'create', 'write', 'checkpoint', 'file', 'storage', 'restore', 'later', 'exactly', 'efficiently', 'reconstruct', 'current', 'session', 'elasticnotebook', 'first', 'complete', 'cost', 'model', 'pro', 'filing', 'variable', 'size', 'network', 'bandwidth', 'storage', 'optimizer', 'utilize', 'ahg', 'cost', 'model', 'compute', 'replica', 'tion', 'plan', 'accord', 'writer', 'create', 'checkpoint', 'file', 'consist', 'subset', 'store', 'variable', 'session', 'state', 'cell', 'rerun', 'ahg', 'cost', 'model', 'restore', 'session', 'request', 'elasticnotebook', 'restore', 'notebook', 'session', 'checkpoint', 'file', 'accord', 'replication', 'plan', 'notebook', 'reconstruct', 'variable', 'order', 'appear', 'original', 'session', 'combine', 'cell', 'rerun', 'datum', 'deserialization', 'follow', 'variable', 'declaration', 'kernel', 'finally', 'elasticnotebook', 'load', 'ahg', 'cost', 'model', 'future', 'replication', 'accuracy', 'elasticnotebook', 'state', 'reconstructing', 'effectively', 'rerun', 'cell', 'scratch', 'exactly', 'order', 'run', 'past', 'elasticnotebook', 'shorten', 'endtoend', 'reconstruction', 'time', 'loading', 'save', 'able', 'kernel', 'namespace', 'achieve', 'time', 'saving', 'present', 'formal', 'correctness', 'analysis', 'discuss', 'address', 'external', 'resource', 'side', 'effect', 'deserialization', 'failure', 'application', 'history', 'graph', 'section', 'formally', 'define', 'application', 'history', 'graph', 'describe', 'achieve', 'exact', 'state', 'replication', 'ahg', 'formal', 'definition', 'ahg', 'direct', 'acyclic', 'graph', 'express', 'session', 'state', 'change', 'respect', 'cell', 'execution', 'fig', 'example', 'definition', 'variable', 'name', 'entity', 'df', 'reference', 'object', 'uniquely', 'identify', 'object', 'elasticnotebook', 'enable', 'live', 'migration', 'computational', 'notebook', 'variable', 'primitive', 'eg', 'int', 'string', 'complex', 'list', 'dataframe', 'multiple', 'variable', 'point', 'object', 'set', 'variable', 'define', 'global', 'namespace', 'form', 'session', 'state', 'cell', 'execution', 'modify', 'value', 'variable', 'reference', 'object', 'change', 'name', 'recognize', 'ahg', 'use', 'variable', 'snapshot', 'follow', 'definition', 'variable', 'snapshot', 'nametimestamp', 'pair', 'represent', 'variable', '𝑥', 'createdmodifie', 'denote', 'set', 'vse', 'definition', 'cell', 'execution', 'represent', 'cell', 'execution', 'finish', 'cell', 'execution', 'linear', 'session', 'cell', 'run', 'time', 'execution', 'totally', 'order', 'denote', 'list', 'ce', 'also', 'store', 'execute', 'cell', 'code', 'use', 'rerun', 'definition', 'write', 'dependency', 'indicate', 'modifiedcreate', 'time', 'object', 'reachable', 'variable', '𝑥', 'denote', 'set', 'write', 'dependency', 'fig', '𝑐𝑡3', 'modifie', 'hence', '𝑐𝑡3', '𝑐𝑡3', 'definition', 'read', 'dependency', '𝑠', 'indicate', 'access', 'object', 'reachable', 'createdmodifie', 'time', 'denote', 'set', 'read', 'dependency', 'fig', '𝐶𝑡4', 'access', 'element', 'list', 'creation', '𝑐𝑡3', 'hence', 'x', '𝑐𝑡3', '𝑐𝑡4', 'note', 'writeread', 'dependency', 'allow', 'contain', 'false', 'positive', 'nevertheless', 'replication', 'ensure', 'correctness', 'definition', 'ahg', '𝐺', 'v∪c', 'bipartite', 'graph', 'v', 'vse', 'c', 'writeread', 'dependency', 'respectively', 'model', 'lineage', 'notebook', 'session', 'sum', 'formalize', 'variable', 'accessesmodification', 'spect', 'cell', 'execution', 'variable', 'level', 'object', 'level', 'theo', 'retically', 'bound', 'size', 'ahg', 'scale', 'linearly', 'number', 'define', 'variable', 'number', 'underlying', 'object', 'large', 'list', 'dataframe', 'empirically', 'verify', 'ahg', 'low', 'memory', 'overhead', 'dynamic', 'ahg', 'construction', 'describe', 'elasticnotebook', 'construct', 'ahg', 'accurately', 'construct', 'ahg', 'incrementally', 'build', 'accessedcreatedmodified', 'variable', 'cell', 'execution', '•', 'new', 'create', 'execution', 'completion', 'time', 'read', 'dependency', 'create', 'vse', '𝑥1', '𝑡𝑥1', '𝑥𝑘', '𝑡𝑥𝑘', '𝑥1', '𝑥𝑘', 'variable', 'possibly', 'access', 'vse', 'create', 'variable', 'possibly', 'modify', 'create', 'write', 'dependency', 'add', 'newly', 'create', 'vse', 'fig', 'right', 'show', 'example', 'identify', 'accessmodified', 'variable', 'crucial', 'construction', 'describe', 'graph', 'graph', 'aim', 'detect', 'change', 'reference', 'level', 'addition', 'value', 'instance', 'conventional', 'equality', 'check', 'eg', 'base', 'serialization', 'return', 'true', 'notebook', 'cell', 'cell', '𝑐𝑡2', 'z', 'false', 'print', 'cell', '𝑐𝑡3', 'z', 'cell', '𝑐𝑡4', 'cell', '𝑐𝑡5', 'print', '𝒕1', '𝒄𝒕1', '𝑐𝑡2', 'z', '𝒄𝒕3', '𝑐𝑡4', '𝑐𝑡5', 'overwrittendelete', 'variable', 'snapshot', '𝑐𝑡1', 'cell', 'execution', '𝑡1', 'active', 'variable', 'snapshot', 'figure', 'example', 'notebook', 'correspond', 'appli', 'cation', 'history', 'graph', 'ahg', 'tell', 'elasticnotebook', 'recompute', 'variable', 'example', 'rerun', '𝑐𝑡1', '𝑐𝑡3', 'necessary', 'recompute', 'x', 'b', 'b', 'value', 'ensure', 'return', 'true', 'b', 'refer', 'object', 'object', 'unique', 'correct', 'state', 'replication', 'share', 'reference', 'alias', 'intervariable', 'relationship', 'capture', 'precisely', 'identify', 'access', 'variable', 'elasticnotebook', 'identifie', 'directly', 'access', 'variable', 'parse', 'indirectly', 'access', 'variable', 'graph', 'follow', 'direct', 'access', 'cell', 'code', 'analyze', 'stepping', 'also', 'userdefined', 'function', 'potentially', 'nest', 'check', 'access', 'variable', 'explicitly', 'pass', 'parameter', 'global', 'indirect', 'access', 'object', 'reachable', 'variable', 'access', 'indirectly', 'variable', 'reference', 'common', 'object', 'eg', 'alias', 'exist', 'fig', '6a', 'identify', 'parse', 'recognize', 'indirect', 'access', 'check', 'existence', 'overlap', 'graph', 'approach', 'conservative', 'overidentify', 'vari', 'able', 'include', 'example', 'one', 'reachable', 'control', 'flow', 'branch', 'take', 'cell', 'execution', 'however', 'false', 'positive', 'affect', 'accuracy', 'state', 'replication', 'identify', 'modify', 'variable', 'variable', 'modification', 'iden', 'tifie', 'use', 'combination', 'object', 'hash', 'graphs', 'value', 'change', 'elasticnotebook', 'identifie', 'value', 'modification', 'compare', 'hash', 'cell', 'execution', 'use', 'deep', 'copy', 'fallback', 'deep', 'copy', 'fail', 'eg', 'unserializable', 'uncomparable', 'variable', 'consider', 'modifiedonaccess', 'use', 'result', 'ast', 'graph', 'result', 'false', 'positive', 'however', 'previously', 'mention', 'false', 'positive', 'affect', 'accuracy', 'structural', 'change', 'graph', 'enable', 'detect', 'structural', 'change', 'fig', 'cell', 'execution', 'current', 'variable', 'graph', 'compare', 'one', 'create', 'identify', 'reference', 'swap', 'fig', 'value', 'remain', 'unchanged', 'cell', 'lambda', 'func', 'func', 'cell', 'graph', 'func', 'detect', 'indirect', 'variable', 'access', 'alias', 'cell', 'list1', 'list1', 'list1', 'cell', 'list2', 'list2', 'cell', 'cell', 'graph', 'list1', 'list2', 'value', 'b', 'detect', 'structural', 'variable', 'modification', 'figure', 'use', 'graph', 'ahg', 'construction', 'execution', 'execute', 'cell', 'memory', 'address', 'nest', 'list', 'change', 'long', 'reference', 'list1', 'state', 'reconstruction', 'ahg', 'section', 'describe', 'reconstruct', 'variable', 'focus', 'reconstruct', 'late', 'version', 'variable', 'define', 'active', 'variable', 'snapshot', 'ahg', 'definition', '𝑥', 'active', '𝑥', 'system', 'delete', 'vs', '𝑗', '𝑗', 'active', '𝑥', 'represent', 'current', 'version', '𝑥', 'example', 'even', 'checkpoint', '𝑐𝑡5', 'fig', 'active', 'last', 'modify', '𝑐𝑡3', 'denote', 'set', 'active', 'vse', 'v𝑎', 'reconstruction', 'goal', 'identify', 'cient', 'computation', 'strategy', 'reconstruct', 'active', 'variable', 'note', 'reconstruct', 'nonactive', 'variable', 'part', 'current', 'session', 'state', 'achieve', 'goal', 'ahg', 'allow', 'avoid', 'unnecessary', 'cell', 'execution', 'eg', 'outcome', 'overwrite', 'learn', 'proper', 'execution', 'order', 'moreover', 'process', 'extend', 'reconstruct', 'set', 'variable', 'efficiently', 'compute', 'still', 'ensure', 'correctness', 'specifically', 'recompute', 'traverse', 'back', 'cestor', 'eg', 'use', 'breadthfirst', 'search', 'collect', 'ce', 'list', '𝑟𝑒𝑞', '𝑡', 'find', 'ground', 'variable', 'path', 'ground', 'variable', 'variable', 'value', 'avail', 'able', 'system', 'ie', 'active', 'copy', 'variable', 'rerun', 'ce', 'order', 'completion', 'time', 'obtain', 'target', '𝑡', 'extend', 'multiple', 'vse', 'say', '𝑥1', '𝑡𝑥1', '𝑥2', '𝑡𝑥2', '𝑥3', '𝑡𝑥3', 'obtain', 'vs', 'union', 'merge', 'set', 'identical', 'ce', 'collapse', 'rerun', 'ce', 'merge', 'set', 'obtain', 'target', 'vse', 'fig', 'show', 'example', 'recompute', 'rerun', '𝑐𝑡3', 'require', 'previous', 'version', '𝑡1', 'input', 'turn', 'require', '𝑐𝑡1', 'rerun', 'notably', 'necessary', 'rerun', '𝑐𝑡2', 'output', 'z', 'available', 'namespace', 'finally', 'discuss', 'approach', 'recover', 'even', 'ground', 'variable', 'unexpectedly', 'unobtainable', 'pranav', 'rahul', 'notebook', 'cell', '𝑐𝑡3', 'z', 'cell', '𝑐𝑡4', 'replication', 'plan', 'migrate', 'migrate', 'recompute', 'recompute', 'recompute', 'migrate', 'true', 'true', 'false', 'figure', 'variable', 'share', 'reference', 'fig', 'migratedrecompute', 'together', 'correct', 'repli', 'cation', 'serve', 'constraint', 'opt', 'problem', 'see', 'use', 'active', 'vse', 'theoretically', 'possible', 'use', 'nonactive', 'variable', 'ground', 'variable', 'preserve', 'deletedoverwritten', 'variable', 'cache', 'able', 'speed', 'recomputation', 'active', 'variable', 'however', 'consider', 'approach', 'many', 'datum', 'science', 'workload', 'memoryhungry', 'large', 'training', 'datum', 'model', 'size', 'still', 'case', 'speed', 'recomputation', 'store', 'small', 'overwritten', 'variable', 'leave', 'future', 'work', 'correctness', 'reconstruction', 'state', 'ahg', 'allow', 'false', 'positive', 'mean', 'indicate', 'cell', 'cessedmodifie', 'variable', 'actually', 'accessedmodifie', 'false', 'positive', 'performance', 'impact', 'affect', 'correctness', 'identification', 'theorem', 'give', 'approximate', 'g', 'elasticnotebook', 'false', 'positive', 'true', 'ahg', 'g∗', '∗', '𝑟𝑒𝑞', 'variable', '𝑥', '𝑡', '∗', '𝑟𝑒𝑞', 'active', 'vss', 'reconstruction', 'mapping', 'function', 'define', 'g', 'g∗', 'respectively', 'arbitrary', 'variable', 'contain', 'cell', 'execution', 'unnecessary', 'recompute', '𝑥', 'never', 'miss', 'necessary', 'cell', 'execution', '∗', 'proof', 'present', 'correct', 'efficient', 'replication', 'section', 'cover', 'elasticnotebook', 'compute', 'efficient', 'correct', 'plan', 'state', 'replication', 'ahg', 'profiled', 'metric', 'describe', 'correctness', 'requirement', 'cost', 'model', 'optimization', 'problem', 'solution', 'correctness', 'requirement', 'elasticnotebook', 'aim', 'correctly', 'replicate', 'session', 'state', 'define', 'notion', 'section', 'definition', 'replication', 'state', 'valueequivalent', 'value', 'postreplication', 'valueequivalent', 'replication', 'preserve', 'value', 'vidual', 'variable', 'guarantee', 'correct', 'identification', '𝑟𝑒𝑞', 'variable', 'however', 'additionally', 'portant', 'share', 'reference', 'preserve', 'define', 'definition', 'valueequivalent', 'replication', 'session', 'state', 'additionally', 'isomorphic', '𝑖𝑑', '𝑏', '𝑖𝑑𝑛𝑒𝑤', '𝑖𝑑𝑛𝑒𝑤', '𝑏', 'arbitrary', 'reference', '𝑖𝑑', '𝑖𝑑𝑛𝑒𝑤', 'unique', 'id', 'memory', 'address', 'object', 'point', '𝑎', 'replication', 'elasticnotebook', 'enable', 'live', 'migration', 'computational', 'notebook', 'migration', 'cost', 'capacity', 'source', 'active', 'vse', 'cell', 'execution', 'capacity∞', 'p', 'acity', 'n', 'cost', 'sink', '𝑐𝑡3', '𝑐𝑡4', '𝑐𝑡5', 'figure', 'run', 'mincut', 'flow', 'graph', 'construct', 'ahg', 'fig', 'partition', 'red', 'define', 'minimum', 'cut', 'dash', 'edge', 'determine', 'replication', 'plan', 'elasticnotebook', 'define', 'replication', 'correct', 'isomor', 'phic', 'require', 'share', 'reference', 'preserve', 'reference', 'point', 'object', 'prereplication', 'still', 'post', 'replication', 'interobject', 'relation', 'identical', 'analogous', 'graph', 'isomorphism', 'describe', 'elasticnotebook', 'ensure', 'isomorphic', 'replication', 'link', 'variable', 'constraint', 'cost', 'model', 'model', 'capture', 'cost', 'associate', 'serialize', 'able', 'write', 'byte', 'datum', 'storage', 'local', 'ssd', 'cloud', 'stor', 'age', 'rerun', 'cell', 'execution', 'cost', 'compute', 'use', 'ahg', 'profiled', 'system', 'metric', 'variable', 'migration', 'cost', 'migrate', 'variable', 'session', 'include', 'serialize', 'checkpoint', 'file', 'load', 'new', 'session', 'give', 'subset', 'variable', 'migrate', 'migration', 'cost', '𝑤𝑀', 'express', 'follow', '𝛼', '×', '𝑤𝑠𝑡𝑜𝑟𝑒', '𝑤𝑙𝑜𝑎𝑑', '𝑤𝑀', '𝑤𝑠𝑡𝑜𝑟𝑒', 'time', 'cost', 'serialize', 'value', '𝑥', 'checkpointe', 'time', 'file', 'unpack', 'new', 'session', 'respectively', 'time', 'estimate', 'use', 'size', '𝑥', 'storage', 'latencybandwidth', 'elasticnotebook', 'time', 'cost', 'unserializable', 'variable', 'set', 'infinity', 'coefficient', 'adjust', 'time', 'cost', 'storage', 'example', 'elasticnotebook', 'invoke', 'autosuspension', '𝛼', 'set', 'low', 'value', 'discount', 'userperceived', 'time', 'store', 'variable', 'prior', 'completely', 'suspend', 'session', 'user', 'likely', 'away', 'variable', 'recomputation', 'cost', 'interceptor', 'record', 'cell', 'run', 'time', 'session', 'lifecycle', 'combine', 'recon', 'struction', 'mapping', '𝑟𝑒𝑞', 'ahg', 'cost', 'recom', 'put', 'subset', 'variable', 'define', 'follow', '𝑤𝑟𝑒𝑟𝑢𝑛', '𝑐', '∑︁', 'cid216', '𝑐', '∈𝑟𝑒𝑞', '𝑥', 'active', 'vs', '𝑥', '𝑤𝑟𝑒𝑟𝑢𝑛', 'c', 'r', 'estimate', 'time', 'rerun', 'new', 'session', 'replication', 'plan', 'cost', 'use', 'migration', 'recomputation', 'cost', 'eq', 'total', 'cost', 'variable', 'migrate', 'variable', 'recompute', 'express', '𝑤', '𝑤𝑀', 'optimization', 'problem', 'state', 'replication', 'goal', 'find', 'variable', 'migrate', 'minimize', 'cost', 'ensure', 'isomoprhic', 'replication', 'consideration', 'variable', 'interdependency', 'additional', 'constraint', 'add', 'constraint', 'link', 'variable', 'variable', 'contain', 'refer', 'ence', 'object', 'refer', 'link', 'variable', 'fig', 'migrate', 'recom', 'put', 'migrate', 'recompute', 'result', 'contain', 'share', 'referencealia', 'break', 'illustrate', 'fig', 'let', 'set', 'link', 'variable', 'pair', 'denote', 'l', 'constraint', 'formally', 'express', 'follow', '𝑥1', '∧', '𝑥2', '𝑥1', '∧', '∉', '𝑥1', '𝑥2', 'l', 'problem', 'definition', 'use', 'cost', 'model', 'con', 'straint', 'formally', 'define', 'state', 'replication', 'problem', 'problem', 'optimal', 'state', 'replication', 'input', 'ahg', '∪', 'e', 'migration', 'cost', 'function', '𝑤𝑀', 'r', 'recompute', 'cost', 'function', 'link', 'variable', 'l', 'replication', 'plan', 'subset', 'variable', 'migrate', 'subset', 'recompute', 'output', 'objective', 'minimize', 'replication', 'cost', 'constraint', 'link', 'variable', 'migrate', 'recom', 'put', '𝑥1', '𝑥2', '𝑥1', '∉', '𝑥1', '𝑥2', '∈', 'l', 'next', 'section', 'present', 'solution', 'solve', 'state', 'replication', 'opt', 'problem', 'solve', 'reduce', 'mincut', 'problem', '𝑠𝑟𝑐𝑠𝑖𝑛𝑘', 'flow', 'graph', 'construct', '𝑠𝑟𝑐𝑠𝑖𝑛𝑘', 'cut', 'subset', 'edge', 'remove', 'flow', 'graph', 'disconnect', 'source', 'sink', 'correspond', 'replication', 'plan', 'cost', 'cut', 'equal', 'replication', 'cost', 'therefore', 'find', 'minimum', 'cost', '𝑠𝑟𝑐𝑠𝑖𝑛𝑘', 'cut', 'equivalent', 'find', 'optimal', 'replication', 'plan', 'flow', 'graph', 'construction', 'flow', 'graph', 'edge', 'capacity', 'r', 'define', 'follow', 'v𝑎', '∪', '𝑠𝑟𝑐', 'v𝑎', 'active', 'vse', 'c', 'cell', 'tion', '𝑠𝑟𝑐', '𝑠𝑖𝑛𝑘', 'dummy', 'source', 'sink', 'v𝑎', '𝑠𝑟𝑐', '𝑠𝑟𝑐', '𝑡', 'add', 'edge', 'source', 'active', 'capacity', 'equal', 'migration', 'cost', 'variable', '𝑤𝑟𝑒𝑟𝑢𝑛', 'add', 'edge', 'capacity', 'sink', 'capacity', 'equal', 'rerun', 'cost', '𝑡', '𝑐', '∞', 'v𝑎', 'add', 'edge', 'infinite', 'capacity', 'active', '𝑥', '𝑡', 'ce', 'recompute', '𝑥1', '𝑥2', 'l', '𝑥1', '𝑥2', '𝑥1', '𝑥2', '∞', 'add', 'bidirectional', 'edge', 'infinite', 'capacity', 'pair', 'active', 'vse', 'correspond', 'link', 'variable', '𝑥1', '𝑥2', 'flow', 'graph', 'h', 'fig', 'depict', 'fig', 'solution', 'solve', 'prob', 'run', '𝑠𝑟𝑐—𝑠𝑖𝑛𝑘', 'mincut', 'solve', 'ie', 'fordfulkerson', 'set', 'edge', 'form', 'mincut', 'dash', 'edge', 'remove', 'disconnect', '𝑠𝑟𝑐', '𝑠𝑖𝑛𝑘', 'therefore', 'define', 'partition', 'red', 'node', 'node', 'reachable', '𝑠𝑟𝑐', 'replication', 'plan', 'obtain', 'reachable', '𝑠𝑟𝑐', 'partition', '𝑥', '∩', 'v𝑎', 'active', 'variable', 'snapshot', 'thus', 'variable', 'want', 'migrate', 'example', 'variable', '∩', 'c', 'ce', 'rerun', 'postmigration', 'recompute', 'example', 'ce', '𝑡1', 'rerun', 'recompute', 'z', 'construction', 'h', 'sum', 'migration', 'recomputation', 'cost', 'configuration', '∩', 'c', 'precisely', 'cost', 'find', 'mincut', 'implementation', 'discussion', 'section', 'describe', 'implementation', 'detail', 'design', 'consideration', 'implementation', 'integrate', 'jupyter', 'seamless', 'integration', 'elasticnote', 'book', 'datum', 'layer', 'implement', 'use', 'magic', 'extension', 'load', 'kernel', 'session', 'initialization', 'cell', 'magic', 'automatically', 'add', 'cell', 'transparently', 'intercept', 'user', 'cell', 'execution', 'perform', 'code', 'analysis', 'create', 'graph', 'object', 'hash', 'serialization', 'protocol', 'pickle', 'protocol', 'eg', 'reduce', 'employ', 'object', 'serialization', 'definition', 'reachable', 'object', 'object', 'reachable', 'variable', 'pickle', 'include', 'pickle', 'standard', 'observe', 'almost', 'datum', 'science', 'librarie', 'numpy', 'pytorch', 'elasticnotebook', 'use', 'almost', 'use', 'case', 'handle', 'undeserializable', 'variable', 'certain', 'variable', 'serialize', 'contain', 'error', 'deserialization', 'instruction', 'refer', 'undeserializable', 'variable', 'typically', 'cause', 'oversight', 'incompletely', 'implement', 'library', 'undetectable', 'serializability', 'check', 'prior', 'checkpointe', 'handle', 'fallback', 'recomputation', 'elastic', 'notebook', 'encounter', 'error', 'deserialize', 'store', 'variable', 'session', 'restoration', 'trace', 'ahg', 'determine', 'rerun', 'necessary', 'cell', 'execution', 'recompute', 'say', 'variable', 'still', 'fast', 'recompute', 'session', 'scratch', 'design', 'consideration', 'definition', 'session', 'state', 'elasticnotebook', 'session', 'state', 'formally', 'define', 'content', 'user', 'namespace', 'usern', 'contain', 'keyvalue', 'pair', 'variable', 'name', '𝑡3', 'also', 'recompute', 'however', 'overwrite', 'store', 'checkpoint', 'file', 'follow', 'procedure', 'preserve', 'link', 'pranav', 'rahul', 'park', 'value', 'reachable', 'object', 'session', 'state', 'include', 'localmodulehidden', 'variable', 'aim', 'capture', 'unobservable', 'state', 'external', 'function', 'pickle', 'protocol', 'follow', 'almost', 'library', 'lesser', 'know', 'one', 'incorrect', 'serialization', 'ignore', 'datum', 'define', 'c', 'stack', 'address', 'elasticnotebook', 'easily', 'tend', 'allow', 'user', 'annotate', 'cellsvariable', 'inform', 'system', 'recompute', 'proper', 'reconstruction', 'mathematically', 'effect', 'set', 'recomputa', 'tion', 'cost', 'infinity', 'cell', 'execution', 'side', 'effect', 'certain', 'cell', 'execution', 'cause', 'external', 'change', 'notebook', 'session', 'filesystem', 'desirable', 'rerun', 'eg', 'upload', 'item', 'reposi', 'tory', 'prototype', 'currently', 'identify', 'side', 'effect', 'focus', 'readoriente', 'data', 'science', 'analytic', 'workload', 'nevertheless', 'system', 'extend', 'least', 'way', 'prevent', 'annotation', 'allow', 'user', 'add', 'manual', 'annotation', 'cell', 'cause', 'side', 'effect', 'system', 'never', 'rerun', 'replications3', 'sandbook', 'block', 'external', 'change', 'replicate', 'notebook', 'sandbox', 'altered', 'file', 'system', 'access', 'chroot', 'block', 'go', 'network', 'ufw', 'sandbox', 'associate', 'regular', 'filenetwork', 'access', 'successful', 'restoration', 'nondeterministic', 'operation', 'replication', 'ef', 'fect', 'rerun', 'cell', 'exact', 'order', 'occur', 'past', 'thus', 'existence', 'nondeterministic', 'operation', 'randint', 'reconstructed', 'variable', 'different', 'value', 'original', 'one', 'user', 'avoid', 'use', 'annota', 'tion', 'inform', 'elasticnotebook', 'always', 'copy', 'library', 'version', 'compatibility', 'accurate', 'replication', 'ensure', 'external', 'resource', 'eg', 'instal', 'module', 'database', 'table', 'remain', 'replication', 'exist', 'tool', 'freeze', 'reproduce', 'computational', 'environment', 'exist', 'datum', 'science', 'platform', 'book', 'colab', 'work', 'incorporate', 'tool', 'experimental', 'evaluation', 'section', 'empirically', 'study', 'effectiveness', 'elastic', 'notebook', 'session', 'replication', 'make', 'follow', 'claim', 'robust', 'replication', 'exist', 'mechanism', 'elasticnote', 'book', 'capable', 'replicate', 'almost', 'notebook', 'fast', 'migration', 'reduce', 'session', 'migration', 'time', 'upscaleddownscaled', 'machine', 'compare', 'rerun', 'cell', 'fast', 'next', 'good', 'alternative', 'respectively', 'fast', 'resumption', 'reduce', 'session', 'restora', 'tion', 'time', 'compare', 'rerun', 'cell', 'fast', 'next', 'good', 'alternative', 'low', 'runtime', 'overhead', 'elasticnotebook', 'incur', 'negligible', 'overhead', 'amortize', 'runtime', 'memory', 'overhead', 'respectively', 'unfeasible', 'annotation', 'eg', 'unserializable', 'variable', 'require', 'cell', 'execution', 'annotate', 'neverrerun', 'recompute', 'elasticnotebook', 'detect', 'case', 'infinite', 'mincut', 'cost', 'user', 'warn', 'delete', 'problematic', 'variable', 'proceed', 'replicate', 'remain', 'majority', 'variable', 'state', 'elasticnotebook', 'enable', 'live', 'migration', 'computational', 'notebook', 'table', 'summary', 'dataset', 'evaluation', 'dataset', 'notebook', 'runtime', 'input', 'datum', 'cell', 'jwst', 'tutorial', '16–439', '25–323', 'low', 'storage', 'overhead', 'checkpoint', 'size', 'small', 'compare', 'exist', 'tool', 'adaptability', 'system', 'environment', 'elasticnotebook', 'achieve', 'consistent', 'saving', 'various', 'environment', 'different', 'network', 'speed', 'available', 'compute', 'resource', 'scalability', 'complex', 'notebook', 'run', 'time', 'memory', 'overhead', 'remain', 'negligible', '150ms', 'even', 'complex', 'notebook', 'cell', 'experiment', 'setup', 'dataset', 'select', 'total', 'notebook', 'dataset', 'kaggle', 'select', 'popular', 'notebook', 'topic', 'exploratory', 'datum', 'analysis', 'machine', 'learn', 'kaggle', 'create', 'grandmastermasterlevel', 'user', 'jwst', 'select', 'notebook', 'topic', 'datum', 'pipeline', 'example', 'notebook', 'provide', 'investigate', 'datum', 'telescope', 'jwst', 'tutorial', 'select', 'notebook', 'cornell', 'vir', 'tual', 'workshop', 'tutorial', 'notebook', 'lightweight', 'introduce', 'tool', 'cluster', 'graph', 'analysis', 'user', 'homework', 'inprogress', 'notebook', 'choose', 'data', 'science', 'exercise', 'contain', 'outoforder', 'cell', 'exe', 'cution', 'runtime', 'error', 'mistake', 'dfbackupdf4', 'table', 'report', 'select', 'notebook', 'dataset', 'size', 'runtime', 'method', 'evaluate', 'elasticnotebook', 'exist', 'tool', 'pable', 'perform', 'session', 'replication', 'rerunall', 'save', 'cell', 'code', 'output', 'ipynb', 'file', 'cell', 'rerun', 'restore', 'session', 'state', 'criu', 'perform', 'systemlevel', 'memory', 'dump', 'pro', 'cess', 'host', 'notebook', 'session', 'session', 'state', 'restore', 'load', 'memory', 'dump', 'revive', 'process', 'store', 'checkpointing', 'tool', 'serialize', 'variable', 'storage', 'use', 'modify', 'version', 'use', 'dill', 'instead', 'pickle', 'dumpsession', 'store', 'dumpsession', 'pack', 'tire', 'session', 'state', 'single', 'file', 'ablation', 'study', 'additionally', 'compare', 'follow', 'ablate', 'implementation', 'elasticnotebook', 'elasticnotebook', 'helix', 'replace', 'mincut', 'solution', 'helix', 'consider', 'link', 'variable', '•', 'graph', 'method', 'omit', 'graph', 'rely', 'ast', 'analysis', 'object', 'hash', 'detect', 'variable', 'access', 'modification', 'respectively', 'create', 'shallow', 'copy', 'df', 'serve', 'purpose', 'backup', 'original', 'implementation', 'store', 'use', 'python', 'fail', 'many', 'notebook', 'give', 'meaningful', 'result', 'rerunall', 'store', 'graph', 'e', 'r', 'e', 'criu', 'architecture', 'dumpsession', 'elasticnotebook', 'criu', 'crossarchitecture', 'elasticnotebook', 'helix', 'e', 'figure', 'ratio', 'correct', 'replication', 'elasticnotebook', 'achieve', 'correctness', 'par', 'full', 'rerun', 'rerunall', 'table', 'exist', 'work', 'fail', 'case', 'work', 'notebook', 'nfl', 'jwst', 'notebook', 'arxiv', 'plant', 'type', 'hashlib', 'mmap', 'description', 'purpose', 'dropdown', 'list', 'plot', 'help', 'avoid', 'read', 'large', 'file', 'memory', 'generator', 'speedup', 'iterable', 'comprehension', 'lazy', 'element', 'generation', 'consider', 'method', 'regard', 'replication', 'correctness', 'gauge', 'impact', 'ignore', 'link', 'constraint', 'implicit', 'access', 'structural', 'modification', 'respectively', 'environment', 'use', 'azure', 'standard', 'instance', 'vcpus', 'gb', 'ram', 'migration', 'experiment', 'migrate', 'session', 'd64asd16as', 'vcpus', 'gb', 'ram', 'upscalingdownscale', 'respectively', 'input', 'datum', 'checkpoint', 'readstore', 'fromto', 'azure', 'stor', 'age', 'block', 'configuration', 'nfs', 'network', 'bandwidth', 'mb', 'read', 'latency', 'time', 'measurement', 'measure', 'migration', 'time', 'time', 'start', 'checkpointe', 'process', 'state', 'restore', 'variable', 'declare', 'namespace', 'destination', 'session', 'restoration', 'time', 'time', 'restore', 'state', 'checkpoint', 'file', 'clear', 'cache', 'checkpointing', 'restore', 'notebook', 'subsequent', 'run', 'reproducibility', 'implementation', 'elasticnotebook', 'experi', 'ment', 'notebook', 'script', 'find', 'repository6', 'robust', 'session', 'replication', 'section', 'compare', 'robustness', 'elasticnotebook', 'session', 'replication', 'exist', 'method', 'count', 'number', 'isomorphic', 'thus', 'correct', 'replication', 'achieve', 'method', 'notebook', 'report', 'result', 'fig', 'elasticnotebook', 'correctly', 'replicate', 'session', 'par', 'full', 'rerun', 'checkpoint', 'file', 'almost', 'always', 'work', 'tably', 'replicate', 'notebook', 'contain', 'unserializable', 'variable', 'variable', 'alias', 'undeserializable', 'variable', 'spectively', 'dumpsession', 'store', 'fail', 'notebook', 'con', 'taine', 'unserializable', 'variable', 'many', 'use', 'enhance', 'datum', 'science', 'workflow', 'efficiency', 'example', 'table', 'elasticnote', 'book', 'successfully', 'replicate', 'bypass', 'serialization', 'variable', 'recomputation', 'store', 'additionally', 'fail', 'notebook', 'total', 'unserializable', 'variable', 'contain', 'variable', 'alias', 'timeserie', 'notebook', 'cell', 'rerunall', 'criu', 'store', 'dumpsession', 'elasticnotebook', 'pranav', 'rahul', 'park', 'sklearn', 'nlp', 'storesale', 'glove', 'trading', 'timeserie', 'stack', 'agriculture', 'lanl', 'hwlm', 'hwex3', 'l', 'n', 'r', 'e', 'r', 'e', 'figure', 'elasticnotebook', 'session', 'upscale', 'time', 'd32as', 'exist', 'tool', 'time', 'normalize', 'wrt', 'rerunall', 'elasticnotebook', 'speed', 'migration', 'fast', 'next', 'good', 'alternative', 'l', 'n', 'r', 'e', 'r', 'e', 'rerunall', 'criu', 'store', 'dumpsession', 'elasticnotebook', 'sklearn', 'nlp', 'storesale', 'glove', 'trading', 'timeserie', 'stack', 'agriculture', 'lanl', 'hwlm', 'hwex3', 'figure', 'elasticnotebook', 'session', 'restoration', 'time', 'exist', 'tool', 'time', 'normalize', 'wrt', 'rerunall', 'elasticnotebook', 'speed', 'session', 'restore', 'fast', 'compare', 'next', 'good', 'alternative', 'table', 'runtime', 'memory', 'overhead', 'elasticnotebook', 'workflow', 'monitoring', 'select', 'notebook', 'notebook', 'runtime', 'total', 'cell', 'monitoring', 'time', 'runtime', 'overhead', 'user', 'namespace', 'memory', 'usage', 'elasticnotebook', 'memory', 'usage', 'memory', 'overhead', 'sklearn', 'nlp', 'storesale', 'trading', 'timeser', 'stack', 'agricult', 'lanl', 'hwlm', 'hwex3', 'link', 'component', 'matplotlib', 'plot', 'fig', 'ax', 'serial', 'ize', 'variable', 'individual', 'file', 'break', 'object', 'reference', 'isomorphism', 'elasticnotebook', 'link', 'variable', 'constraint', 'ensure', 'elasticnotebook', 'helix', 'fail', 'correctly', 'replicate', 'notebook', 'contain', 'variable', 'alias', 'lacking', 'link', 'variable', 'constraint', 'graph', 'fail', 'correctly', 'replicate', 'session', 'miss', 'indirect', 'access', 'structural', 'modification', 'cause', 'incorrect', 'construc', 'tion', 'ahg', 'turn', 'lead', 'recompute', 'variable', 'valueincorrectly', 'criu', 'fail', 'notebook', 'contain', 'invisible', 'file', 'however', 'elasticnotebook', 'failure', 'failure', 'currently', 'fundamental', 'limitation', 'criu', 'robust', 'migration', 'system', 'architecture', 'additionally', 'perform', 'session', 'replication', 'x64', 'architecture', 'instance', 'architecture', 'criu', 'image', 'replicate', 'machine', 'different', 'architecture', 'contrast', 'elasticnotebook', 'limitation', 'fast', 'session', 'migration', 'section', 'compare', 'efficiency', 'elasticnotebook', 'session', 'migration', 'exist', 'method', 'choose', 'notebook', 'unserializable', 'variable', 'otherwise', 'exist', 'method', 'fail', 'com', 'pare', 'endtoend', 'session', 'migration', 'time', 'achieve', 'different', 'method', 'report', 'upscale', 'downscale', 'result', 'fig', 'fig', 'respectively', 'design', 'goal', 'elasticnotebook', 'reduce', 'session', 'replica', 'tion', 'time', 'balance', 'variable', 'storage', 'recomputation', 'successfully', 'reflect', 'follow', 'elasticnotebook', 'able', 'reduce', 'session', 'migration', 'time', 'upscaleddownscaled', 'vms', 'compare', 'rerunall', 'compare', 'dumpse', 'sion', 'store', 'criu', 'store', 'variable', 'checkpoint', 'file', 'elasticnotebook', 'upscalesdownscale', 'fast', 'good', 'dumpsession', 'next', 'good', 'alternative', 'upscalingdownscale', 'notebook', 'fall', 'short', 'robustness', 'demonstrate', 'store', 'individual', 'reading', 'writing', 'variable', 'result', 'high', 'overhead', 'multiple', 'call', 'nfs', 'migration', 'criu', 'slow', 'nonrerun', 'method', 'upscalingdownscale', 'notebook', 'size', 'memory', 'dump', 'high', 'io', 'migration', 'large', 'compare', 'checkpoint', 'file', 'native', 'tool', 'fast', 'session', 'restoration', 'section', 'compare', 'efficiency', 'elasticnotebook', 'session', 'restoration', 'exist', 'method', 'generate', 'checkpoint', 'file', 'use', 'method', 'compare', 'time', 'take', 'restore', 'session', 'checkpoint', 'file', 'notebook', 'elasticnotebook', 'set', 'coefficient', 'emphasize', 'session', 'restoration', 'time', 'heavily', 'report', 'result', 'restoration', 'time', 'fast', 'compare', 'full', 'rerun', 'compare', 'baseline', 'elasticnotebook', '392×', 'fast', 'next', 'good', 'alter', 'native', 'fast', 'restoration', 'attribute', 'elasticnotebook', 'capable', 'adapt', 'new', 'optimization', 'objective', 'baseline', 'example', 'notebook', 'instead', 'run', 'cell', 'df', 'reread', 'dataframe', 'df', 'session', 'migrationcentric', 'plan', 'restoration', 'centric', 'plan', 'opt', 'store', 'df', 'instead', 'reasoning', 'sum', 'serialization', 'deserialization', 'time', 'df', 'great', 'reread', 'time', 'pdreadcsv', '117', '55', 'deserialization', 'time', 'less', 'reread', 'time', '117', '55', 'hence', 'store', 'df', 'optimal', 'choice', 'elasticnotebook', 'enable', 'live', 'migration', 'computational', 'notebook', 'rerunall', 'store', 'e', 'z', 'nlp', 'tps', 'trading', 'timeserie', 'agriculture', 'hwlm', 'figure', 'elasticnotebook', 'checkpoint', 'file', 'size', 'exist', 'ing', 'tool', 'time', 'normalize', 'output', 'dumpsession', 'checkpoint', 'file', 'size', 'small', 'compare', 'exist', 'tool', 'exclude', 'rerunall', 'low', 'runtime', 'overhead', 'section', 'investigate', 'overhead', 'elasticnotebook', 'note', 'book', 'workflow', 'monitor', 'measure', 'elasticnotebook', 'total', 'time', 'spend', 'prepostprocesse', 'step', 'beforeafter', 'cell', 'execu', 'tion', 'update', 'ahg', 'cell', 'runtime', 'total', 'cell', 'monitoring', 'time', 'total', 'storage', 'space', 'take', 'store', 'graph', 'hash', 'checkpoint', 'time', 'elasticnotebook', 'memory', 'usage', 'report', 'result', 'table', 'elasticnotebook', 'cell', 'monitor', 'incur', 'maximum', 'median', 'runtime', 'overhead', 'thus', 'elasticnotebook', 'seamlessly', 'integrate', 'exist', 'workflow', 'elasticnotebook', 'similarly', 'memoryefficient', 'store', 'item', 'graph', 'hash', 'largely', 'independent', 'size', 'item', 'session', 'median', 'memory', 'overhead', 'bad', 'case', 'finegraine', 'analysis', 'study', 'percell', 'time', 'memory', 'overhead', 'experimental', 'notebook', 'usage', 'examine', 'notebook', 'homework', 'category', 'confirm', 'maximum', 'time', 'memory', 'overhead', '92ms', 'respectively', 'report', 'detail', 'low', 'storage', 'overhead', 'section', 'measure', 'storage', 'cost', 'elasticnotebook', 'check', 'point', 'file', 'compare', 'migrationcentric', 'checkpoint', 'file', 'size', 'elasticnotebook', 'baseline', 'method', 'report', 'select', 'result', 'fig', 'low', 'choose', 'store', 'recompute', 'variable', 'reflect', 'elasticnotebook', 'checkpoint', 'file', 'small', 'compare', 'dumpsession', 'example', 'agri', 'culture', 'notebook', 'elasticnotebook', 'recompute', 'traintest', 'split', 'input', 'dataframe', 'cell', 'xtrain', 'traintestsplit', 'instead', 'store', 'check', 'point', 'file', 'save', 'considerable', 'storage', 'space', 'gb', 'addition', 'speed', 'migration', 'conversely', 'criu', 'checkpoint', 'file', 'size', 'large', 'elasticnotebook', 'additionally', 'dump', 'memory', 'occupy', 'process', 'import', 'mod', 'ule', 'matter', 'necessary', 'checkpoint', 'file', 'output', 'size', 'rerunall', 'ie', 'notebook', 'metadata', 'size', 'consist', 'cell', 'code', 'output', 'provide', 'comparison', 'significantly', 'small', 'checkpoint', 'file', 'storage', 'benefit', 'offset', 'significantly', 'slow', 'session', 'recovery', 'performance', 'gain', 'environment', 'section', 'demonstrate', 'operation', 'environ', 'ment', 'vary', 'specification', 'perform', 'parameter', 'sweep', 'elasticnotebook', 'migrate', 'time', 'elasticnotebook', 'recompute', 'time', 'rerunall', 'e', 'e', 'network', 'bandwidth', 'network', 'bandwidth', 'e', 'e', 'network', 'bandwidth', 'stack', 'network', 'bandwidth', 'c', 'agriculture', 'asset', 'figure', 'elasticnotebook', 'adapt', 'different', 'environment', 'replication', 'plan', 'low', 'network', 'bandwidth', 'variable', 'recompute', 'twitter', 'interactive', 'sklearn', 'e', 'h', 'e', 'e', 'cell', 'execution', 'ahg', 'size', 'cell', 'execution', 'b', 'optimization', 'time', 'figure', 'scalability', 'elasticnotebook', 'cell', 'execution', 'count', 'size', 'ahg', 'increase', 'linearly', 'replication', 'plan', 'optimization', 'time', 'increase', 'sublinearly', 'network', 'bandwidth', 'rate', 'limit', 'compare', 'migration', 'time', 'elasticnotebook', 'dumpsession', 'migrate', 'variable', 'rerunall', 'report', 'result', 'elasticnotebook', 'balance', 'variable', 'storage', 'recomputation', 'ensure', 'always', 'least', 'fast', 'fast', 'dumpsession', 'rerunall', 'notably', 'elastic', 'notebook', 'adapt', 'relative', 'availability', 'network', 'bandwidth', 'compute', 'power', 'bandwidth', 'decrease', 'replication', 'plan', 'change', 'accordingly', 'migrate', 'variable', 'recomputation', 'rather', 'storage', 'example', 'stacking', 'notebook', 'regular', 'bandwidth', 'elastic', 'notebook', 'replication', 'plan', 'include', 'migrate', 'session', 'state', 'opt', 'recompute', 'certain', 'traintest', 'split', 'ie', 'cell', 'ytrain', 'yvalidation', 'modify', 'plan', 'recompute', 'instead', 'store', 'computationally', 'expensive', 'process', 'dataframe', 'cell', 'latestrecord', 'modify', 'plan', 'store', 'import', 'class', 'function', 'definition', 'xgbregressor', 'cell', 'recompute', 'rest', 'notebook', 'scale', 'complex', 'workload', 'section', 'test', 'scalability', 'session', 'replication', 'complex', 'notebook', 'session', 'large', 'number', 'cell', 'execution', 'reexecution', 'specifically', 'choose', 'tutorial', 'notebook', 'randomly', 'reexecute', 'cell', 'measure', 'size', 'elasticnotebook', 'ahg', 'optimization', 'time', 'compute', 'replication', 'plan', 'cell', 'twice', 'length', 'long', 'observe', 'notebook', 'report', 'result', 'fig', 'memory', 'consumption', 'ahg', 'exhibit', 'linear', 'scaling', 'number', 'cell', 'execution', 'reach', 'mb', 'cell', 'reexecution', 'negligible', 'compare', 'memory', 'consumption', 'note', 'book', 'session', 'gb', 'optimization', 'time', 'compute', 'replication', 'plan', 'similarly', 'exhibit', 'linear', 'scaling', 'reach', 'negligible', '150ms', 'cell', 'reexecution', 'elasticnote', 'book', 'choose', 'solve', 'mincut', 'fordfulkerson', 'time', 'complexity', '𝑂', 'number', 'edge', 'ahg', '𝑓', 'cost', 'optimal', 'replication', 'plan', 'former', 'scale', 'linearly', 'latter', 'largely', 'constant', 'relate', 'work', 'intermediate', 'result', 'reuse', 'datum', 'science', 'storage', 'termediate', 'result', 'explore', 'various', 'context', 'datum', 'science', 'incremental', 'feedforward', 'nature', 'task', 'allow', 'output', 'prior', 'operation', 'useful', 'speed', 'future', 'operation', 'example', 'include', 'cache', 'speed', 'model', 'training', 'replay', 'agnosis', 'cache', 'speed', 'anticipate', 'future', 'dataframe', 'operation', 'notebook', 'workflow', 'storage', 'cell', 'put', 'facilitate', 'graphical', 'exploration', 'notebook', 'tion', 'history', 'convenient', 'cell', 'rerun', 'relate', 'work', 'algorithmically', 'explore', 'efficient', 'way', 'compute', 'state', 'give', 'currently', 'store', 'item', 'compare', 'work', 'helix', 'similarly', 'feature', 'balance', 'loading', 'recomputation', 'model', 'lack', 'link', 'variable', 'constraint', 'result', 'silently', 'incorrect', 'replication', 'directly', 'apply', 'computational', 'notebook', 'problem', 'set', 'datalevel', 'session', 'replication', 'session', 'replication', 'base', 'platform', 'perform', 'serialization', 'librarie', 'exist', 'variety', 'checkpoint', 'tool', 'build', 'serialization', 'librarie', 'store', 'picklebased', 'interface', 'save', 'variable', 'keyvalue', 'store', 'however', 'break', 'object', 'reference', 'link', 'variable', 'serialize', 'separate', 'file', 'dillbase', 'dumpsession', 'correctly', 'resolve', 'reference', 'yet', 'still', 'fail', 'session', 'contain', 'unserializable', 'object', 'tensorflow', 'pytorch', 'offer', 'periodical', 'check', 'point', 'model', 'training', 'limit', 'object', 'library', 'native', 'checkpointing', 'mechanism', 'save', 'cell', 'metadata', 'often', 'fail', 'exactly', 'restore', 'session', 'common', 'presence', 'hide', 'state', 'compare', 'exist', 'datum', 'level', 'tool', 'session', 'replication', 'elasticnotebook', 'efficient', 'robust', 'application', 'history', 'graph', 'enable', 'balanc', 'ing', 'state', 'storage', 'recomputation', 'achieve', 'considerable', 'speedup', 'avoid', 'failure', 'unserializable', 'object', 'systemlevel', 'session', 'replication', 'session', 'replication', 'sim', 'ilarly', 'perform', 'use', 'systemlevel', 'tool', 'much', 'exist', 'work', 'applicable', 'tool', 'include', 'criu', 'recently', 'crum', 'crac', 'explore', 'extend', 'cuda', 'application', 'elsa', 'integrate', 'criu', 'enable', 'server', 'compare', 'elasticnotebook', 'system', 'level', 'tool', 'less', 'efficient', 'robust', 'large', 'memory', 'dump', 'size', 'limited', 'crossplatform', 'portability', 'respectively', 'pranav', 'rahul', 'park', 'lineage', 'trace', 'lineage', 'tracing', 'see', 'extensive', 'use', 'state', 'management', 'enable', 'recomputation', 'datum', 'efficient', 'storage', 'state', 'fault', 'tolerance', 'recently', 'usage', 'datum', 'lineage', 'computational', 'notebook', 'enable', 'multiversion', 'notebook', 'replay', 'recommend', 'notebook', 'interaction', 'create', 'reproducible', 'notebook', 'container', 'program', 'slicing', 'find', 'minimal', 'set', 'code', 'run', 'compute', 'certain', 'variable', 'work', 'adopt', 'lineage', 'trace', 'technique', 'capture', 'intervariable', 'dependency', 'application', 'history', 'graph', 'optimization', 'good', 'knowledge', 'exist', 'work', 'program', 'focus', 'capture', 'value', 'modification', 'equality', 'comparison', 'however', 'technique', 'additionally', 'identify', 'capture', 'strucal', 'change', 'graph', 'crucial', 'preserve', 'variable', 'alias', 'avoid', 'silent', 'error', 'state', 'replication', 'replicate', 'execution', 'environment', 'identical', 'execution', 'vironment', 'necessary', 'session', 'replication', 'different', 'machine', 'recent', 'work', 'explore', 'environment', 'repli', 'cation', 'notebook', 'containerize', 'input', 'file', 'mod', 'ule', 'useful', 'conjunction', 'elasticnotebook', 'consider', 'work', 'largely', 'orthogonal', 'notebook', 'parameterization', 'script', 'exist', 'work', 'execute', 'notebook', 'parameterized', 'form', 'systematic', 'experi', 'mentation', 'form', 'script', 'papermill', 'elasticnotebook', 'design', 'use', 'interactive', 'note', 'book', 'interface', 'similarly', 'applicable', 'migration', 'rameterize', 'notebook', 'execution', 'result', 'conclusion', 'work', 'propose', 'elasticnotebook', 'new', 'computa', 'tional', 'notebook', 'system', 'newly', 'offer', 'elastic', 'scaling', 'check', 'pointingrestoration', 'achieve', 'elasticnotebook', 'introduce', 'transparent', 'data', 'management', 'layer', 'user', 'interface', 'underlie', 'kernel', 'enable', 'robust', 'efficient', 'platform', 'independent', 'state', 'replication', 'notebook', 'session', 'core', 'con', 'tribution', 'include', 'lowoverhead', 'onthefly', 'application', 'history', 'construction', 'new', 'optimization', 'combine', 'copying', 'recomputation', 'variable', 'comprise', 'session', 'state', 'demonstrate', 'elasticnotebook', 'reduce', 'upscale', 'scaling', 'restoration', 'time', 'respectively', 'realworld', 'science', 'notebook', 'negligible', 'runtime', 'memory', 'overhead', 'respectively', 'future', 'plan', 'achieve', 'high', 'efficiency', 'usability', 'trace', 'state', 'change', 'fine', 'level', 'specifically', 'introduce', 'microcell', 'capture', 'code', 'block', 'cell', 'repeatedly', 'run', 'forloop', 'machine', 'learn', 'training', 'system', 'automatically', 'store', 'intermediate', 'model', 'meta', 'datum', 'enable', 'live', 'migration', 'checkpointingrestoration', 'longrunne', 'cell', 'execution', 'acknowledgment', 'author', 'grateful', 'kent', 'quanrud', 'assistance', 'derivation', 'reduction', 'employ', 'elasticnotebook', 'work', 'support', 'part', 'national', 'center', 'supercomputing', 'application', 'azure', 'elasticnotebook', 'enable', 'live', 'migration', 'computational', 'notebook', 'reference', 'naga', 'tanu', 'malik', 'reproducible', 'notebook', 'container', 'use', 'application', 'virtualization', 'ieee', '18th', 'international', 'conference', 'escience', 'escience', 'ieee', 'andreshg', 'nlp', 'glove', 'tfidf', 'lstm', 'explain', 'https', 'gene', 'cooperman', 'dmtcp', 'transparent', 'checkpointing', 'cluster', 'computation', 'desktop', 'ieee', 'tional', 'symposium', 'parallel', 'distribute', 'processing', 'ieee', 'azure', 'azure', 'studio', 'https', 'learnmicrosoftcoman', 'azure', 'azure', 'azuremicrosoft', 'anju', 'fault', 'tolerancechallenge', 'technique', 'implementation', 'international', 'journal', 'computer', 'science', 'issue', 'ijcsi', 'ekrem', 'store', 'sale', 'forecast', 'comprehensive', 'guide', 'https', 'mohammad', 'riyaz', 'belgaum', 'mad', 'cloud', 'service', 'rank', 'use', 'checkpointbase', 'load', 'balance', 'realtime', 'scheduling', 'cloud', 'computing', 'progress', 'advanced', 'computing', 'intelligent', 'engineering', 'springer', 'random', 'search', 'hyperparameter', 'optimization', 'journal', 'machine', 'learn', 'research', 'wondershaper', 'notebook', 'crumby', 'enough', 'replace', 'conference', 'innovative', 'datum', 'system', 'research', 'gang', 'deqe', 'zou', 'bing', 'bing', 'shelp', 'automatic', 'selfheale', 'multiple', 'application', 'instance', 'virtual', 'machine', 'environment', 'ieee', 'international', 'conference', 'cluster', 'computing', 'ieee', 'chhaya', 'choudhary', 'machine', 'learning', 'deep', 'learning', 'notebook', 'https', 'chhaya', 'choudhary', 'project', 'customer', 'churn', 'predic', 'tion', 'bokeh', 'contributor', 'bokeh', 'interaction', 'https', 'docsbokehorgen', 'iván', 'core', 'roberto', 'r', 'osorio', 'improve', 'scalability', 'applicationlevel', 'checkpointrecovery', 'reduce', 'checkpoint', 'size', 'new', 'generation', 'compute', 'criu', 'criu', 'invisible', 'file', 'https', 'criuorginvisiblefile', 'criu', 'https', 'criuorgmainpage', 'emanuel', 'carsten', 'binnig', 'interactive', 'analytic', 'pen', 'touch', 'proceeding', 'vldb', 'endowment', 'jupyterhubjupyterhubidleculler', 'https', 'cunha', 'real', 'silva', 'marco', 'netto', 'contextaware', 'execution', 'migration', 'tool', 'datum', 'notebook', 'hybrid', 'cloud', 'ieee', '17th', 'international', 'conference', 'escience', 'escience', 'ieee', 'developer', 'cuda', 'https', 'developernvidiacomcuda', 'toolkit', 'yve', 'frédéric', 'choli', 'optimization', 'cloud', 'task', 'process', 'checkpoint', 'restart', 'mechanism', 'proceeding', 'international', 'conference', 'high', 'formance', 'compute', 'network', 'storage', 'analysis', 'dimitreoliveira', 'model', 'stack', 'feature', 'engineering', 'https', 'engineeringandedanotebook', 'docker', 'nd', 'docker', 'documentation', 'swarm', 'mode', 'overview', 'https', 'doc', 'dockercomengineswarm', 'cody', 'dunne', 'graphtrail', 'analyze', 'large', 'multivariate', 'heterogeneous', 'network', 'support', 'exploration', 'history', 'proceeding', 'human', 'factor', 'computing', 'system', 'dwd', 'uncomplicatedfirewall', 'https', 'wikiubuntucom', 'uncomplicatedfirewall', 'philipp', 'eichmann', 'emanuel', 'carsten', 'binnig', 'idebench', 'benchmark', 'interactive', 'datum', 'exploration', 'proceeding', 'conference', 'management', 'datum', 'https', 'pytorch', 'lightning', 'ai', 'pytorch', 'modelcheckpoint', 'lrdr', 'fordfulkerson', 'flow', 'network', 'software', 'python', 'https', 'docspythonorg3', 'libraryasthtml', 'software', 'python', 'generator', 'https', 'wikipython', 'orgmoingenerator', 'software', 'https', 'docspythonorg3', 'libraryhashlibhtml', 'software', 'https', 'docspythonorg3', 'libraryjsonhtml', 'software', 'https', 'docspythonorg3', 'librarymarshalhtml', 'software', 'https', 'software', 'foundation', 'python', 'object', 'reduction', 'https', 'doc', 'pythonorg3librarypicklehtml', 'objectreduce', 'software', 'foundation', 'python', 'pickle', 'documentation', 'https', 'uncertainty', 'quantification', 'foundation', 'dill', 'pypi', 'https', 'pypiorg', 'projectdill', 'uncertainty', 'quantification', 'foundation', 'dill', 'dump', 'session', 'https', 'tian', 'watchpoint', 'https', 'pypiorgprojectwatchpoint', 'rolando', 'sreekanti', 'log', 'model', 'training', 'arxiv', 'preprint', 'garg', 'gene', 'crum', 'support', 'cuda', 'unified', 'memory', 'ieee', 'international', 'conference', 'cluster', 'computing', 'cluster', 'ieee', 'aurélien', 'geron', 'chapter', 'training', 'model', 'githubcomageron', 'aurélien', 'geron', 'machine', 'learn', 'notebook', 'edition', 'signup', 'tensorflow', 'checkpoint', 'https', 'wwwtensorfloworgguide', 'checkpoint', 'google', 'x', 'understand', 'code', 'https', 'burrito', 'wrap', 'lab', 'notebook', 'computational', 'infrastructure', 'haproxy', 'http', 'wwwhaproxyorg', 'detailed', 'https', 'wwwkagglecomcode', 'fred', 'hohman', 'druck', 'manage', 'mess', 'computational', 'notebook', 'proceeding', 'conference', 'human', 'factor', 'compute', 'system', 'technology', 'reactivity', 'graph', 'little', 'bit', 'magic', 'https', 'hextechbloghextwopointoh', 'topiccatalogjupyternotebook', 'studio', 'service', 'https', 'wwwibmcomdocsen', 'wwwkagglecom', 'kaggle', 'forum', 'product', 'feedback', 'https', 'wwwkagglecom', 'discussionsproductfeedback', 'notebook', 'specification', 'https', 'wwwkagglecom', 'docsnotebook', 'technicalspecification', 'space', 'telescope', 'jwst', 'datum', 'analysis', 'exam', 'ple', 'https', 'examplejupyternotebook', 'twinkle', 'jain', 'gene', 'cooperman', 'crac', 'architecture', 'cuda', 'stream', 'uvm', 'international', 'conference', 'high', 'performance', 'compute', 'network', 'storage', 'analysis', 'ieee', 'benefit', 'pitfall', 'notebook', 'classroom', 'proceeding', '21st', 'annual', 'conference', 'information', 'technol', 'ogy', 'education', 'project', 'notebook', 'stetzler', 'slater', 'checkpoint', 'restore', 'live', 'migration', 'science', 'platform', 'arxiv', 'preprint', 'dataflow', 'notebook', 'encoding', 'tracking', 'dependency', 'cell', '9th', 'usenix', 'workshop', 'theory', 'practice', 'provenance', 'tapp', 'machine', 'learn', 'notebook', 'multiclass', 'classification', 'https', 'githubcomkrasserm', 'kubernete', 'nd', 'kubernete', 'sfu', 'database', 'system', 'lab', 'dataprep', 'preparation', 'https', 'nteract', 'team', 'welcome', 'papermill', 'https', 'papermillreadthedocsio', 'dataprepai', 'enlat', 'lagator', 'arxiv', 'datum', 'processing', 'https', 'wwwkagglecomcode', 'development', 'team', 'ipython', 'interactive', 'computing', 'https', 'colinlagatorarxivdataprocesse', 'pranav', 'rahul', 'park', 'matei', 'shenker', 'tachyon', 'reliable', 'memory', 'speed', 'storage', 'cluster', 'computing', 'framework', 'proceeding', 'acm', 'symposium', 'zhile', 'frem', 'fast', 'restart', 'mechanism', 'general', 'checkpointrestart', 'ieee', 'comput', 'chroot', 'https', 'wikiarchlinuxorgtitlechroot', 'heer', 'effect', 'interactive', 'latency', 'exploratory', 'visual', 'analysis', 'ieee', 'transaction', 'visualization', 'computer', 'graphic', 'stephen', 'finegraine', 'lineage', 'safe', 'notebook', 'interaction', 'arxiv', 'preprint', 'naga', 'shilvi', 'tanu', 'malik', 'chaudhary', 'chex', 'multiversion', 'replay', 'order', 'checkpoint', 'arxiv', 'preprint', 'arxiv220208429', 'anjali', 'meshram', 'sambare', 'zade', 'fault', 'tolerance', 'model', 'reliable', 'cloud', 'international', 'journal', 'recent', 'innovation', 'trend', 'computing', 'communication', 'mongodb', 'bson', 'alexey', 'elibol', 'ray', 'distribute', 'framework', 'emerge', 'ai', 'application', '13th', 'usenix', 'symposium', 'operating', 'system', 'design', 'implementation', 'osdi', 'time', 'series', 'forecasting', 'prophet', 'https', 'wwwkaggle', 'stephen', 'scalable', 'dataframe', 'system', 'arxiv', 'preprint', 'arnab', 'benjamin', 'rath', 'matthias', 'boehm', 'finegraine', 'lineage', 'tracing', 'reuse', 'machine', 'learning', 'system', 'proceeding', 'international', 'conference', 'management', 'datum', 'braganholo', 'noworkflow', 'tool', 'collect', 'analyze', 'manage', 'provenance', 'script', 'proceeding', 'vldb', 'endowment', 'developer', 'freeze', 'https', 'pippypaioenstableclipip', 'freeze', 'shize', 'moneyball', 'proactive', 'autoscaling', 'sql', 'database', 'serverless', 'proceeding', 'vldb', 'endowment', 'pbc', 'posit', 'software', 'formerly', 'rstudio', 'posit', 'rstudio', 'https', 'posit', 'development', 'team', 'https', 'development', 'team', 'class', 'https', 'ipython', 'development', 'team', 'store', 'magic', 'https', 'ipython', 'development', 'team', 'matplotlib', 'https', 'matplotliborg', 'quoccuong', 'volker', 'survey', 'state', 'manage', 'ment', 'big', 'datum', 'processing', 'system', 'vldb', 'journal', 'university', 'cornell', 'virtual', 'workshop', 'tutorial', 'notebook', 'https', 'university', 'investigate', 'timeline', 'use', 'interactive', 'bokeh', 'scatterplot', 'https', 'university', 'sklearn', 'tweet', 'classification', 'https', 'university', 'twitter', 'network', 'https', 'githubcomcornellcac', 'trindade', 'matei', 'mistique', 'system', 'store', 'query', 'model', 'intermediate', 'model', 'diagnosis', 'proceeding', 'international', 'conference', 'management', 'datum', 'alexandre', 'verbitski', 'anurag', 'gupta', 'murali', 'brahmadesam', 'kamal', 'gupta', 'raman', 'mittal', 'sailesh', 'krishnamurthy', 'maurice', 'design', 'consideration', 'high', 'throughput', 'cloudnative', 'relational', 'database', 'proceeding', 'international', 'conference', 'management', 'datum', 'devlikamov', 'vlad', 'fast', 'workflow', 'use', 'scikitlearn', 'https', 'ericjan', 'wagenmaker', 'model', 'selection', 'use', 'akaike', 'weight', 'psychonomic', 'bulletin', 'review', 'wannipurage', 'suresh', 'marru', 'marlon', 'pierce', 'framework', 'capture', 'reproduce', 'absolute', 'state', 'arxiv', 'preprint', 'arxiv220407452', 'stephen', 'litian', 'song', 'helix', 'holistic', 'optimization', 'accelerate', 'iterative', 'machine', 'learn', 'arxiv', 'preprint', 'enhance', 'interactivity', 'dataframe', 'query', 'leverage', 'think', 'time', 'arxiv', 'preprint', 'arxiv210302145', 'xxhash', 'extremely', 'fast', 'noncryptographic', 'hash', 'co', 'prediction', 'https', 'www', 'yandex', 'opensource', 'gradient', 'boost', 'library', 'ai', 'bowl', 'offensive', 'play', 'rahul', 'agricultural', 'drought', 'prediction', 'https', 'wwwkagglecom', 'raj', 'https', 'amexdataset', 'web', 'service', 'aw', 'docsawsamazoncom', 'shahule', 'basic', 'cleaning', 'glove', 'wwwkagglecomcode', 'stephen', 'macke', 'chasin', 'compact', 'rapid', 'program', 'slicing', 'notebook', 'proceeding', 'vldb', 'endowment', 'shreyas', 'thorat30', 'plant', 'disease', 'classification', 'sdp', 'https', 'wwwkaggle', 'shtrauss', 'build', 'asset', 'trading', 'strategy', 'https', 'wwwkaggle', 'stelio', 'assure', 'automatic', 'software', 'selfheale', 'use', 'rescue', 'point', 'acm', 'sigarch', 'computer', 'architecture', 'news', 'stackoverflow', 'colab', 'session', 'timeout', 'https', 'stitchfix', 'nodebook', 'https', 'githubcomstitchfixnodebook', 'team', 'nbconvert', 'conversion', 'https', 'githubcomjupyternbconvert', 'matei', 'chowdhury', 'shenker', 'spark', 'cluster', 'computing', 'working', 'set', '2nd', 'usenix', 'workshop', 'hot', 'topic', 'hotcloud', 'emanuel', 'druck', 'icdata', 'datum', 'analysis', 'pen', 'touch', 'ieee', 'transaction', 'visualization', 'computer', 'graphic', 'materialization', 'optimization', 'feature', 'selection', 'workload', 'acm', 'transaction', 'database', 'system', 'tod', '1–32', 'a1', 'low', 'percell', 'overhead', 'report', 'result', 'percell', 'time', 'memory', 'overhead', 'homework', 'notebook', 'elasticnotebook', 'memory', 'percell', 'monitoring', 'overhead', 'consistently', '1ms', 'respectively', 'occasionally', 'spike', 'certain', 'cell', 'declaringmodifye', 'complex', 'variable', 'execute', 'example', '91ms', 'memory', 'time', 'overhead', 'cell', 'attribute', 'construct', 'graph', 'complex', 'nest', 'list', 'however', 'even', 'bad', 'case', 'time', 'overhead', 'still', 'elasticnotebook', 'enable', 'live', 'migration', 'computational', 'notebook', 'e', 'h', 'e', 'user', 'namespace', 'memory', 'usage', 'cell', 'execution', 'b', 'e', 'h', 'elasticnotebook', 'memory', 'usage', 'cell', 'execution', 'e', 'h', 'r', 'e', 'e', 'cell', 'execution', 'cell', 'execution', 'mem', 'overhead', 'overhead', 'c', 'overhead', 'percell', 'time', 'overhead', 'figure', 'runtime', 'memory', 'overhead', 'elasticnotebook', 'notebook', 'use', 'select', 'homework', 'notebook', 'memory', 'overhead', 'consistently', 'low', 'percell', 'runtime', 'overhead', 'negligible', 'cell', 'execution', 'rerunall', 'criu', 'store', 'dumpsession', 'elasticnotebook', 'sklearn', 'nlp', 'storesale', 'glove', 'trading', 'timeserie', 'stack', 'agriculture', 'lanl', 'hwlm', 'hwex3', 'notebook', 'n', 'r', 'e', 'r', 'e', 'figure', 'elasticnotebook', 'session', 'downscale', 'time', 'vm→d16a', 'exist', 'tool', 'time', 'normalize', 'wrt', 'rerunall', 'elasticnotebook', 'speed', 'migration', '200×', 'fast', 'next', 'good', 'alternative', 'arbitrary', 'variable', 'g', 'g∗', 'active', 'vss', 'g∗', 'respectively', '≥', 'g∗', 'due', 'falsely', 'imply', 'nonoverwrite', 'modification', 'fig', 'path', 'g', 'g∗', '𝑥', 'g', '𝑐𝑡g', '𝑡𝑘1', '𝑐𝑡𝑘1', '𝑡𝑘𝑙', '𝑐𝑡𝑘𝑙', 'g∗', 'g∗', 'g', '𝑡𝑘1', '𝑡𝑘𝑙', 'contain', 'false', 'nonoverwrite', 'modification', '𝑐𝑡𝑘1', '𝑐𝑡𝑘𝑙', 'fore', 'subtree', 'root', 'g', 'contain', 'subtree', 'root', 'g∗', 'g∗', 'hence', '𝑟𝑒𝑞∗', 'g∗', '𝑟𝑒𝑞', 'g', 'handle', 'large', 'panda', 'dataframe', 'avoid', 'hash', 'large', 'panda', 'dataframe', 'cell', 'execution', 'elasticnotebook', 'use', 'dataframe', 'underlie', 'writeable', 'flag', 'dirty', 'bit', 'detect', 'inplace', 'change', 'cell', 'execution', 'writeable', 'flag', 'set', 'false', 'dataframe', 'identify', 'modified', 'flag', 'flip', 'true', 'cell', 'execution', 'g', '𝒕1', '𝒄𝒕1', '𝒄𝒕2', '𝑐𝑡3', 'g∗', '𝑡1', '𝑐𝑡3', '𝒄𝒕4', '𝒄𝒕5', '𝒄𝒕4', '𝑐𝑡5', '𝑐𝑡2', '𝑟𝑒𝑞', '𝑐𝑡4', '𝑟𝑒𝑞', '𝑐𝑡4', '𝑐𝑡5', 'overwrittendelete', 'variable', 'snapshot', '𝑐𝑡1', 'cell', 'execution', '𝑡1', 'active', 'variable', 'snapshot', 'figure', 'ahg', 'contain', 'false', 'positive', 'compare', 'true', 'ahg', 'g∗', 'correctness', 'still', 'ensure', 'efficiency', 'affect', 'extra', 'cell', 'rerun', 'example', 'recompute', 'z', 'green', 'well', '500ms', 'threshold', 'suggest', 'interactive', 'datum', 'gine', 'memory', 'overhead', 'low', 'absolute', 'value', 'compare', 'size', 'yet', 'load', 'dataset', 'thus', 'negligible', 'user', 'impact', 'a2', 'proof', 'theorem', 'illustration', 'proof', 'provide', 'fig', 'proof', 'false', 'negative', 'true', 'ahg', 'g∗', 'taine', 'approximate', 'g∗', 'g', 'fig', 'let']"
ElasticNotebook: Enabling Live Migration for Computational Notebooks,"[{'href': 'http://arxiv.org/abs/2309.11083v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2309.11083v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-09-20 06:18:07,"Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Yao Fu 1 Run Peng 1 Honglak Lee 1 2

3
2
0
2

g
u
A
5
2

]

G
L
.
s
c
[

1
v
1
6
6
3
1
.
8
0
3
2
:
v
i
X
r
a

Abstract
Efficient exploration is a challenging topic in rein-
forcement learning, especially for sparse reward
tasks. To deal with the reward sparsity, people
commonly apply intrinsic rewards to motivate
agents to explore the state space efficiently. In
this paper, we introduce a new intrinsic reward
design called GoBI - Go Beyond Imagination,
which combines the traditional lifelong novelty
motivation with an episodic intrinsic reward that
is designed to maximize the stepwise reachability
expansion. More specifically, we apply learned
world models to generate predicted future states
with random actions. States with more unique
predictions that are not in episodic memory are as-
signed high intrinsic rewards. Our method greatly
outperforms previous state-of-the-art methods on
12 of the most challenging Minigrid navigation
tasks and improves the sample efficiency on loco-
motion tasks from DeepMind Control Suite.

1. Introduction

Efficient exploration in state space is a fundamental chal-
lenge in reinforcement learning (RL) (Hazan et al., 2019;
Lee et al., 2019), especially when the environment rewards
are sparse (Mnih et al., 2013; 2016; Schulman et al., 2017)
or absent (Liu & Abbeel, 2021; Parisi et al., 2021). Such
reward sparsity makes RL algorithms easy to fail due to the
lack of useful signals for policy update (Riedmiller et al.,
2018; Florensa et al., 2018; Sekar et al., 2020). A com-
mon approach for exploration is to introduce self-motivated
intrinsic rewards such as state visitation counts (Strehl
& Littman, 2008; Kolter & Ng, 2009) and prediction er-
rors (Stadie et al., 2015; Pathak et al., 2017; Burda et al.,
2018). Most of these intrinsic reward designs measure life-
long state novelty and prioritize visiting states that are less

1University

of Michigan

2LG AI. Correspon-
Yao Fu <violetfy@umich.edu>, Run Peng
dence to:
<roihn@umich.edu>, Honglak Lee <honglak@eecs.umich.edu
& honglak@lgresearch.ai>.

Proceedings of the 40 th International Conference on Machine
Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright
2023 by the author(s).

1

visited starting from the beginning of training.

While the above methods achieves great improvement on
hard-exploration tasks like Montezumas Revenge (Burda
et al., 2018), they generally only work well on “single-
ton” environments, where training and evaluation environ-
ments are the same. However, due to the poor generalization
performance of reinforcement learning in unseen environ-
ments (Kirk et al., 2021), nowadays researchers have been
paying more attention on procedurally-generated environ-
ments (Cobbe et al., 2019; 2020; Flet-Berliac et al., 2021),
where the nature of task remains the same but the environ-
ment is randomly constructed for each new episode. For
example, a maze-like environment will have different maze
structures, making it rare for the agent to encounter the
same observations across different episodes. Therefore,
lifelong novelty intrinsic motivations usually fail in hard
procedurally-generated environments of this kind (Raileanu
& Rockt¨aschel, 2020; Zha et al., 2021) because an agent
will be trapped around newly-generated states.

Inspired by human’s frequent use of short-term memory (An-
dersen et al., 2006; Eichenbaum, 2017) to avoid repeatedly
visiting the same space, recent work propose to derive intrin-
sic rewards on episodic level (Savinov et al., 2018; Badia
et al., 2020; Raileanu & Rockt¨aschel, 2020; Zha et al., 2021;
Zhang et al., 2021). The episodic intrinsic rewards gener-
ally give bonus to large episodic-level state space visitation
coverage, therefore encourage visiting as many states as
possible in the same episode. However, does visiting more
states necessarily mean efficient episodic-level exploration?
We notice that some state visitations are unnecessary and
can be avoided if they are predictable from episodic mem-
ory. For example, when navigating through a house to find
a fridge, if you open a door and find an empty room, you
do not need to go into it anymore because you can easily
predict what the states are like in the room (i.e., intuitively
speaking, you would be moving around in an empty room).
With this inspiration, we propose to design the episodic in-
trinsic reward to not only maximize the number of visited
states in an episode, but also consider those states that are
not visited but can be predicted from episodic memory.

More precisely, we maintain an episodic buffer to store all
the visited states as well as states reachable from the visited
states within a few time steps. To get the reachable states,

 
 
 
 
 
 
Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Figure 1. Illustration of how GoBI works on Minigrid. For the environment in the upper-left corner, the red triangle indicates the position
and orientation of the agent. It has a 7 × 7 partially-observable view (highlighted). During pre-training (Stage 1), we collect data using
a random policy to train a forward dynamics model ˆfϕ(panot, at) = ot+1, where panot denotes the panoramic view as is defined in
Section 3.1. For policy training (Stage 2), we apply ˆf to predict observations in the future k time steps with n random actions for each
step. We add the new ones to an episodic buffer M and take the change of size of M as the episodic intrinsic reward repi. The lifelong
intrinsic reward is COUNT-based. Our intrinsic reward GoBI is rlifelong ∗ repi.

we train a world model with forward dynamics function and
apply random actions to the learned dynamics model to pre-
dict future states. The predictions are added to the episodic
buffer if they are not there already. We use the change of
size of this episodic buffer as the episodic intrinsic reward.
Following many previous work, we weight the episodic in-
trinsic reward by a lifelong intrinsic reward (Badia et al.,
2020; Zhang et al., 2021) like the COUNT-based rewards.
With this newly proposed intrinsic reward design GoBI - Go
Beyond Imagination, the agent is expected to both explore
the most of the state space throughout training to discover
extrinsic rewards, and learn to act in an efficient manner
within a single episode to avoid being trapped by seemingly
novel states.

The contributions of this work can be highlighted as fol-
lows: (i) We propose a novel way to combine world models
with episodic memory to formulate an effective episodic
intrinsic reward design. (ii) In sparse-reward procedurally-
generated Minigrid environments (Chevalier-Boisvert et al.,
2023), GoBI greatly improves the training sample efficiency
in comparison with prior state-of-the-art intrinsic reward
functions. (iii) GoBI extends well to DeepMind Control
Suite (Tunyasuvunakool et al., 2020) with high-dimensional
visual inputs and shows promising results on sparse-reward
continuous control tasks. (iv) We analyze the design of
GoBI and present extensive ablations to show the contribu-
tion of each component.

2. Method

We consider reinforcement learning problems framed as
Markov Decision Process (MDP) M = (S, A, T, R, γ),
where S and A denote the state space and action space.
T : S × A × S → [0, 1] is the state transition function.
R : S × A × S → R is the reward function. γ is the
reward discount factor. At each step t, the state of the
environment is denoted as st ∈ S. The agent generates
an action at ∈ A to interact with the environment. The
environment then transits to the next underlying state st+1 ∈
S. Apart from the new state st+1, the environment also
returns an extrinsic reward rext that describes how well the
agent reacts to st. In sparse-reward tasks, rext is usually
0. In this work, we follow the previous work to train RL
algorithms with rext +λ∗rint
is a self-motivated
intrinsic reward and λ is a hyper-parameter that controls the
relative importance between intrinsic and extrinsic rewards.

, where rint

t

t

2.1. Go Beyond Imagination

Reachable States and Episodic Buffer Our intrinsic re-
ward design aims to exploit the information hidden inside
the neighbourhood of states. We define a state A to be k-
step reachable from state B if the agent can reach A from
B within k time steps. During the training process, for each
new episode, we initialize an empty episodic memory buffer
M. At time step t, we hash st as well as all the states
reachable from st. We denote the set containing all the hash

2

Environment

e.g. 🚶

Action Space

1. Left
2. Right
3. Forward
4. Pickup
5. Drop
6. Toggle
7. Done

⬅
➡
🚶
🤏
✋
🛠
✅

Encoder

Decoder

Policy Net

Conv2d

U
L
E
R
+
r
a
e
n
L

i

U
L
E
R
+
r
a
e
n
L

i

Episodic Memory Expansion

= 🚶

next obs             =  

Random 
Actions

k

n

Already in 

New state

Pre-train forward 
dynamics model

Stage 1

X

Count(             )

Episodic Reachability 
Maximization

Stage 2

 
 
 
 
Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Figure 2. An illustration of how our episodic buffer updates. We consider reachable states that are k = 2 time steps away from st. After
the agent moves from s1 to s2, the episodic buffer M (shaded in green) expands by 3 new reachable states (shaded in yellow). More
formally, M ← M ∪ MR(s2), where MR(s2) indicates a set of all the states 2-step reachable from s2. Notice that all the states in the
trajectory, i.e., s0, s1, s2 are also added to the buffer.

codes of st and its reachable states as MR(st). Then we
update M by M ← M ∪ MR(st). Storing the hash codes
instead of directly storing the states may alleviate the poten-
tial memory issue of the buffer. We illustrate this process in
Figure 2. When the agent reaches state s2, we add 3 more
states that are reachable from s2 but not in M.

Forward Dynamics
In real environments, it is common
that we do not have access to the neighbourhood relationship
between states. However, we can learn a world model by
training a forward dynamics model ˆfϕ(st, at) = st+1 to
predict the states reachable from st. This forward dynamics
can be pre-trained using data collected by a random policy or
trained online together with policy training. When training
the policy, for each time step t, we generate k · n random
actions and use the learned dynamics ˆfϕ to predict states in
the future k steps. We hash the current state st as well as the
t+1, ..., ˆsn
predicted future states ˆs1
t+k and
add the hash codes to the episodic buffer M if they are not
in the buffer. Apart from alleviating potential memory issue
as is mentioned in the last paragraph, using a hash function
may also mitigate the noise introduced by ˆf . With a learned
dynamics model, the predictions of reachable states are
usually not perfect. However, in the experiment section we
show that even with imperfect predictions, our method can
improve the training sample efficiency a lot.

t+k, ..., ˆsn

t+1, ..., ˆs1

Episodic Novelty We aim to design an episodic-level nov-
elty reward that guides the agent to extend the frontier of its
predicted reachable space efficiently to discover states not
visited and not predictable within the same episode. More
specifically, we denote the size of the episodic buffer M
as mt at time step t and design a reachability-based bonus
repi = mt+1 − mt that encourages the agent to find unex-
plored regions. For each time step, the agent is expected to
reach the state that is reachable to more new states in the
current episode.

3

Intrinsic Reward Formulation We further weight our
episodic intrinsic reward by a lifelong intrinsic reward to
encourage the agent to explore the regions that are not well
explored in the past. More formally, the proposed intrinsic
reward GoBI is defined as:

t = (mt+1 − mt) ∗ rlifelong
rint

t

(1)

Here, rlifelong
denotes lifelong intrinsic reward. We note
t
that our framework is compatible with any choice of lifelong
intrinsic reward. Specifically, we use the simple COUNT-
based reward 1/(cid:112)N (st+1) for the navigation experiments
on Minigrid environments (Chevalier-Boisvert et al., 2023),
where N denotes the count of st+1 from the start of train-
ing.1 For the experiments on DeepMind Control Suite (Tun-
yasuvunakool et al., 2020) we use the state-of-the-art in-
trinsic reward RE3 (Seo et al., 2021), which estimates state
entropy by a random encoder.

Intrinsic Decay Intrinsic rewards are expected to be
asymptotically consistent so that it will not influence the
policy learning at later stage of training and result in a
sub-optimal policy. To guarantee that the policy learning
focuses more on extrinsic rewards as training proceeds, in
RE3 (Seo et al., 2021), the authors apply exponential decay
schedule for the intrinsic rewards to decrease over time. Al-
though COUNT-based reward theoretically converges to
0 with enough exploration, it decreases quite slowly in
procedurally-generated environments. Therefore, we also
apply intrinsic reward decay when calculating GoBI by de-
creasing the intrinsic reward coefficient λ during training.
We summarize our method in Algorithm 1 and illustrate the
training process on Minigrid navigation tasks in Figure 1.

1For environments that are partially observable (e.g., in Mini-
grid, the agent observes a 7×7 pixel local view of the environment),
we substitute state st with observation ot when calculating the in-
trinsic rewards.

t = 1

t = 2

Action: Move(S1, S2)

Episodic Buffer

Non-reachable Space

New Reachable Space

Reachable States from

Visited State

Reachable State

Non-reachable State

Trajectory

Observed Transition Path

Unreachable Transition Path

Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Algorithm 1 Go Beyond Imagination

Input: Intrinsic Reward Coefficient λ0, Forward Pre-
diction Step k, Number of Random Actions n, Intrinsic
Reward Decay Parameter ρ
Initialize policy πθ, dynamics model ˆfϕ, replay buffer B.
(Optional) Collect episodes with πθ and train ˆfϕ with
prediction loss
for episode e = 1, 2, ... until convergence do

Initialize episodic buffer M.
λ ← λ0 ∗ (1 − ρ)(e−1)∗T
for t = 1 to T do

Execute πθ in the environment to get a transition
pair (st, at, st+1, rext
mt ← size(M)
M ← M ∪ {hash(st)})
for t′ = 1 to k do

).

t

gets a high intrinsic reward if the corresponding similarity
scores are low. Only with low enough similarity scores do
they add st to the buffer. Although their method and ours
are similar at high level, they are different by design. For ex-
ample, for an agent standing in front of an empty blind alley
with dead end, agent trained with GoBI does not benefit in
going deep into the blind alley because everything there can
be predicted as reachable and added to the episodic buffer
already. However, EC encourages going to the very end of
the blind alley to reach the state with low similarity score
and high intrinsic reward, even though going into an empty
blind alley is not beneficial for exploration and wastes time
that can be used to explore other parts of the environment.
In Appendix C, we present the visitation heatmaps of poli-
cies learned by EC and find that it prefers going to the room
corners, which well matches our explanation above.

t′, ..., an
t′

generate n random actions a1
M ← M ∪ {hash( ˆfϕ((cid:98)si

t+t′, ai

end for
t = (size(M) − mt) ∗ rlifelong
rint
B ← B ∪ {(st, at, st+1, rext

t + λ ∗ rint

t )}

t′)|i = 1, ..., n})

end for
update πθ with RL objective
update ˆfϕ with prediction loss

end for

2.2. Conceptual Advantage of GoBI over Prior Works

Previous works including RIDE (Raileanu & Rockt¨aschel,
2020) and NovelD (Zhang et al., 2021) also combine
episodic intrinsic reward with lifelong novelty as we do.
However, most of them focus on episodic-level state vis-
itation. For example, NovelD only assigns non-zero re-
wards to a state when it is visited for the first time in the
episode. However, we notice that not all state visitations
are necessary. The agent’s goal for exploration is to gather
information about the states. Therefore for states that are
easily predictable from episodic memory, visiting them may
not really help to acquire more information about the en-
vironment. In Figure 4, we plot the visitation heatmap of
GoBI and NovelD to demonstrate the different exploration
behaviours of the two methods.

Our method is closely related to another work that mea-
sures episodic curiosity (EC) (Savinov et al., 2018). In EC,
the authors train a reachability network that takes in two
arbitrary states and outputs a similarity score between 0
and 1, where 1 indicates the two states are the same and 0
indicates they are totally different. The network is trained
using collected episodes by marking temporally close states
as positive examples and temporally far ones as negative
samples. Meanwhile, they also maintain an episodic buffer.
A state st is compared with all the states in the buffer and

(a) MiniGrid

(b) Deepmind Control

Figure 3. Rendering of the environments used in this work. Left:
2D grid world navigation tasks that require object interactions.
Right: DeepMind Control tasks with visual observations.

3. Experiments

In this section, we evaluate GoBI in two domains: 2D
procedurally-generated Minigrid environments (Chevalier-
Boisvert et al., 2018) with hard-exploration tasks and lo-
comotion tasks from DeepMind Control Suite (Tunyasu-
vunakool et al., 2020). The experiments are designed to
answer the following research questions: (1) How does
GoBI perform against previous state-of-the-art intrinsic re-
ward designs in terms of training-time sample efficiency on
challenging procedurally-generated environments? (2) Can
GoBI successfully extend to complex continuous domains
with high-dimensional observations, for example control
tasks with visual observations? (3) How does each compo-
nent of our intrinsic reward contribute to the performance?
(4) What is the influence of the accuracy of the learned
world models to our method?

3.1. Minigrid Navigation Tasks

Minigrid Environments MiniGrid (Chevalier-Boisvert
et al., 2018) is a set of partially-observable procedurally-

4

Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Figure 4. Visitation heatmaps on KeyCorridorS5R3 at different training stages. This figure compares the policy behaviour of GoBI and
NovelD. A dark red color means plentiful visitations, white means the agent has seen the space but did not step on it, and black means
space that are not discovered. It is worth noticing that early in the training (3.5M and 7M time steps), our policy already learns not to go
into an empty room, likely because states in an empty room are easily predictable. On the contrary, even after 11M steps, an agent trained
with NovelD still goes into an empty room (bottom-right corner) for more state visitations.

generated grid world navigation tasks. The agent is expected
to interact with objects such as keys, balls, doors, and boxes
to navigate through rooms and find the goal that is randomly
placed in one of the rooms. The tasks only provide one
sparse reward at the end of each episode, which indicates if
the agent successfully finds the goal or not and how many
steps it takes to reach the goal. In this work, we consider
3 types of tasks including MultiRoom, KeyCorridor, and
ObstructedMaze. Some environments that we experiment
on in this paper are shown in Figure 3a. The upper-right is
a KeyCorridor-S4R3 environment, where the agent should
learn to open the doors to find a key, use it to open the locked
blue door, and pick up the green ball. The bottom-left fig-
ure shows an ObstructedMaze-Full environment, which is
similar to KeyCorridor but more challenging. The rooms
are larger, the doors are blocked by balls, and the keys are
hidden in boxes. The upper-left and bottom-right environ-
ments are MultiRoom environments, in which the agent has
to navigate through connected rooms to reach the goal in
the last room.

Baselines We compare with state-of-the-art intrinsic re-
ward designs that work well on Minigrid including Nov-
elD (Zhang et al., 2021), RIDE (Raileanu & Rockt¨aschel,
2020), and RND (Burda et al., 2018). For a fair compari-
son, we follow the same basic RL algorithm and network
architectures used in the official codebase of NovelD and
only change the intrinsic rewards rint for all the methods.
We also compare our method with EC (Savinov et al., 2018)
because of the similarity of the high-level idea between
the two methods. However, the original paper of EC does
not include experiments on Minigrid. Therefore, we im-
plement our own version to adapt to Minigrid. We follow
their implementation suggestions in the paper and tune the
hyper-parameters such as novelty threshold by grid search.

Dynamics Model Training For each experiment on Min-
igrid, we first run a random policy for 1e5 steps to collect
data and use them to train a forward dynamics model as the
world model. Among the pairs collected, there are about
5e4 different transition pairs. During our experiments, we
observe that fine-tuning the pre-trained dynamics model
during policy training has no significant influence on the
performance. Similar to (Parisi et al., 2021), we use the
360◦ panoramic views as the input to predict the future
observations. This is a rotation-invariant representation of
the observed state. We consider this still a fair compari-
son with the previous state-of-the-arts because both NovelD
and RIDE rely on using the state information instead of
observations for the episodic count calculation.

Due to the limited field of view of the agent, we only forward
the learned dynamics by k = 1 step when predicting. We
predict the next observations produced by all 7 discrete
actions in the Minigrid tasks including turn left, turn right,
forward, toggle, pick up, drop, and done. We directly apply
the default Python hashing function to hash the observations
and predicted future observations. We do not expect the
hashing function to mitigate the prediction error on Minigrid,
but only use it to reduce the dimension of observations and
predictions.

Training Performance on Minigrid Figure 5 shows
the learning curves of GoBI and state-of-the-art explo-
ration baselines NovelD, RIDE, RND, and EC on 12 most
challenging Minigrid navigation tasks, including Multi-
Room, KeyCorridor, and ObstructedMaze. Our curves
are shifted towards right by the number of random explo-
ration environment steps used to train the world model.
In all 12 environments, GoBI significantly outperforms
previous methods in terms of sample efficiency. For in-

5

GoBI(Ours)

One episode of Training Environment

same

s
t
n
u
o
C
d
e
t
i
s
V

i

Unlock

3.5M

3.5M

7M

7M

11M

11M

Training Steps

21M

21M

Pick

Minigrid-KeyCorridor-S5R3-v0

NovelD

Unseen

Seen

 
Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Figure 5. Training performance of GoBI and the baselines on 12 MiniGrid environments. The x-axis shows the number of environment
steps. We shift the training curves towards right by the number of environment steps we use to pre-train the dynamics model, i.e. 1e5 time
steps. Results are averaged across 4 seeds.

stance, on ObstructedMaze-2Dlhb, GoBI is about three
times more sample efficient than NovelD. On the hard-
est ObstructedMaze-Full environment, GoBI achieves near-
optimal performance within 70M steps. Lastly, although we
try to tune the hyper-parameters of EC, our implementation
of EC still does not learn well on the Minigrid environments.

Qualitative Results To clearly present the exploration be-
havior learned by GoBI, we show the visitation heatmaps
of GoBI and NovelD on a KeyCorridorS5R3 environment
in Figure 4. Not only does our method converge to an opti-
mal policy faster, the exploration behaviour is very different
from NovelD. GoBI quickly learns not to visit easily pre-
dictable states like an empty room, making it more efficient
to explore interesting parts of the environment, for example,
the room with a key in it.

Dynamics Model Training We follow the world model
structure in Dreamer (Hafner et al., 2019) and directly apply
their encoder, transition model, and observation model to
predict future observations. However, compared to Mini-
grid, it requires way more data to train a decent dynamics
model on DeepMind Control to generate visually-reasonable
predictions. Therefore, different from the experiments on
Minigrid, we do not pre-train the dynamics models. Instead
we train the dynamics model together with the policy as is
shown in Algorithm 1. We find that the number of sampled
random actions n = 5 works well across all 4 environments.
For the number of forward prediction steps k, we set it to be
3 for Pendulum Swingup and 1 for the other 3 environments.

For the hashing function, we find that a simple SimHash as is
suggested in (Tang et al., 2017) works well in capturing the
similarities between similar observations. We use SimHash
to hash the image observations to 50 bits.

3.2. Experiments on Control Tasks

We further test GoBI on DeepMind Control Suite, which
are a set of image-based continuous control tasks. These
tasks are more challenging than Minigrid because of its high-
dimensional observations and stochastic transitions. Notice
that these environments are not procedurally-generated. The
experiments in this section are to show the generality of
our method by experimentally showing that GoBI extends
well to sparse-reward tasks with continuous action space
and high-dimensional observation space.

Training Performance on DeepMind Control We com-
pare with the state-of-the-art intrinsic motivation on Deepm-
Mind Control tasks - RE3 (Seo et al., 2021), which applies a
k-nearest neighbor entropy estimator in the low-dimensional
representation space of a randomly initialized encoder to
maximize state entropy. RE3 is also what we use for the life-
long intrinsic reward part rlifelong of GoBI in Eq 1. Another
two intrinsic reward baselines we consider are ICM (Pathak
et al., 2017) and RND (Burda et al., 2018). For a fair com-
parison, all the experiments use the same basic RL algorithm

6

MultiRoom-N6

MultiRoom-N7-S8

MultiRoom-N12-S10

KeyCorridorS3R3

0.6

0.4

0.2

0.0

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0

0.0

0.2

0.3

0.5

0.6

0.8

0.0

0.1

0.3

0.5

0.6

0.8

0.0

0.2

0.4

0.6

0.8

0.9

0.0

0.2

0.5

0.7

1.0

1.2

KeyCorridorS4R3

KeyCorridorS5R3

KeyCorridorS6R3

ObstructedMaze-2Dlh

1e7

0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0

1.0

0.8

0.6

0.4

0.2

0.0

0.0

0.2

0.5

0.7

1.0

1.2

0.0

0.3

0.6

0.9

1.2

1.5

0.0

0.4

0.8

1.2

1.6

2.0

0.0

0.4

0.8

1.3

1.7

2.1

ObstructedMaze-2Dlhb

ObstructedMaze-1Q

ObstructedMaze-2Q

ObstructedMaze-Full

1e7

0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0

1.0

0.8

0.6

0.4

0.2

0.0

n
r
u

t

e
R
e
g
a
r
e
v
A

0.6

0.4

0.2

0.0

n
r
u

t

e
R
e
g
a
r
e
v
A

0.8

0.6

0.4

0.2

0.0

n
r
u

t

e
R
e
g
a
r
e
v
A

0.8

0.6

0.4

0.2

0.0

0.0

0.8

1.6

2.4

3.2

4.0

0.0

0.6

1.3

1.9

2.6

3.2

0.0

0.9

1.7

2.6

3.4

4.3

0.0

2.0

4.0

6.0

8.0

10.0

NovelD

RIDE

EC

RND

Ours (GoBI)

1e7

 
 
 
Go Beyond Imagination: Maximizing Episodic Reachability with World Models

episodes than MultiRoom (all generated rooms are squares
with fixed sizes), therefore the COUNT-based rewards con-
tribute more in such environments than in MultiRoom. At
the same time, R2 performs way worse than GoBI. Agents
trained with R2 prefer actions that only increase the size of
the episodic buffer a bit therefore getting positive score more
often. We provide an illustrative example in Appendix F
to explain why R2 does not work well compared to GoBI.
Using only lifelong intrinsic reward R3 performs the worst
and struggles to learn efficiently on large Multiroom, Key
Corridor, and Obstructed Maze environments.

Real Dynamics vs Learned Dynamics A learned dynam-
ics model is generally not perfect, especially for partially-
observable environments like Minigrid. In many cases the
predictions can never be accurate. For example, when the
agent first opens the door of a new room, usually it will
not accurately predict everything behind the door. Figure 8
shows the training curves between using the real dynamics
model vs a learned dynamics model. Not surprisingly, with
the same intrinsic reward function, using the real dynamics
converges faster to a near-optimal policy. However, even
with imperfect dynamics model, our method still greatly
surpasses previous state-of-the-arts.

Figure 8. Comparison between using the real dynamics model of
the environments vs using a learned one on Minigrid environments.
In both MultiRoom and KeyCorridor, using a real dynamics model
to derive intrinsic reward makes the policy converge faster, espe-
cially on KeyCorridor.

Multi-Step Predictions Figure 9 shows the learning per-
formance of GoBI on Minigrid with a varying choices of
the number of future steps to do predictions k = 1, 2, 3. For
k > 1, our dynamics model outputs panot+1 instead of ot+1
and we hash and store the observations from panoramas in
each future time step. With a real forward dynamics model,
a larger k generally accelerates exploration more, because it
prioritizes actions that lead to the states that are reachable
to more states in the long run. However, due to the limited
field of view of the agent and the model inaccuracy, this is
not the case if we use a learned model. Forwarding 2 steps
is still faster than only 1 step, but more steps than that does
not really make exploration faster.

Figure 6. Training curves of GoBI and the baselines on DeepMind
Control Suite. The curves are averaged across 5 seeds.

RAD (Laskin et al., 2020). The results are shown in Figure
6. The additional episodic-level intrinsic reward term im-
proves the sample efficiency a lot compared to only using
lifelong intrinsic reward, especially on Hopper Hop and
Walker Run Sparse.

3.3. Ablation Study

GoBI Variations
In this section, we analyze how each
component of our intrinsic reward contributes to the final
performance. We ablate each component of GoBI and run
experiments on Minigrid environments with the following:

• R1: only episodic intrinsic reward mt+1 − mt
• R2: indicator of whether new states are added to the
episodic buffer (1{mt+1 − mt > 0})/(cid:112)N (ot+1)

• R3: only lifelong intrinsic reward 1/(cid:112)N (ot+1)

Figure 7. Training performance comparison among GoBI, R1, R2,
and R3 on 3 Minigrid environments.

Training performance of GoBI as well as R1, R2, and R3 are
shown in Figure 7. Although R1 works on MultiRoom, it
suffers on Obstructed Maze and large KeyCorridor environ-
ments. The underlying reason may be that in Key Corridor
and Obstructed Maze the room structures change less across

7

n
r
u
t
e
R
e
d
o
s
p
E

i

800

600

400

200

0

n
r
u
t
e
R
e
d
o
s
p
E

i

250

200

150

100

50

0

Pendulum Swingup

Cartpole Swingup Sparse

800

600

400

200

0

0.0

0.2

0.4

0.7

0.9

1.1

0.0

0.5

1.0

1.6

2.1

2.6

Hopper Hop

Walker Run Sparse

1e5

1e5

400

300

200

100

0

0.0

1.0

2.0

3.0

4.0

5.0

0.0

1.0

2.0

3.0

4.0

5.0

RAD+ICM

RAD+RND

RAD+RE3

RAD

1e5

1e5

Ours

 
 
MultiRoom-N12-S10

KeyCorridorS6R3

ObstructedMaze-2Dlh

n
r
u
t
e
R
e
g
a
r
e
v
A

0.6

0.5

0.4

0.3

0.2

0.1

0.0

0.8

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0

0.0

0.2

0.3

0.5

0.6

0.8

0.0

0.4

0.7

1.1

1.4

1.8

0.0

0.2

0.4

0.6

0.8

1.0

R1

R2

R3

Ours

1e7

 
MultiRoom-N7-S8

KeyCorridorS3R3

t

n
r
u
e
R
e
g
a
r
e
v
A

0.6

0.4

0.2

0.0

0.8

0.6

0.4

0.2

0.0

0.0

0.1

0.2

0.4

0.5

0.6

0.0

0.1

0.2

0.3

0.4

0.5

real dynamics

learned dynamics

1e7

 
Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Rockt¨aschel, 2020) and NovelD (Zhang et al., 2021) both
count the episodic state visitations, while we claim that apart
from visited states, we should also consider states that can
be predicted from short-term episodic memory.

4.3. Learning World Models with Forward Dynamics
Learning dynamics function from a set of observed data is a
widely-studied topic in reinforcement learning, especially
due to the rapid growth of model-based reinforcement learn-
ing (Wang et al., 2019). Existing work show that an agent’s
world model is implicitly a forward model that predict future
states (Ha & Schmidhuber, 2018a; Freeman et al., 2019).
Recently, people have proposed latent dynamics models
that work well on high-dimensional inputs (Okada et al.,
2020). These latent dynamics models encode image obser-
vations and predict future states in the latent space (Ha &
Schmidhuber, 2018b; Hafner et al., 2019; 2023), outputting
realistic future observations on visually complex domains
including DeepMind Control Suite (Tunyasuvunakool et al.,
2020), VizDoom (Kempka et al., 2016), Atari Games, and
DeepMind Lab (Beattie et al., 2016). The learned dynamics
models can be used to guide exploration by prediction error
(Stadie et al., 2015; Pathak et al., 2017; Burda et al., 2018),
surprise (Achiam & Sastry, 2017), or information gain by
variance of model ensemble means (Sekar et al., 2020). Our
method differ from the previous methods by directly gener-
ating and hashing the predicted states and add them to an
episodic reachable state buffer. With the advanced world
model structures, our method can be extended to diverse
domains with complex observations.

5. Discussions and Future Work

This paper shows an effective way to combine learned world
models with episodic memory to intrinsically guide efficient
exploration. Our method achieves state-of-the-art perfor-
mance on procedurally-generated hard exploration tasks
and also works well on singleton continuous control do-
mains. However, it still has certain limitations. First of all,
the dynamics model we use for the Minigrid experiments
is deterministic, making it possible to generate less accu-
rate predictions and making the performance of our method
worse than using the real dynamics. A possible way to make
improvement on this is to make the prediction model gen-
erative and sample possible future states. Secondly, for the
control tasks with complex visual inputs, we hash the im-
ages with static hashing to make them discrete hash codes.
However, to better capture the semantic similarities between
the image observations, it would be beneficial to learn hash
functions, for example, by using an autoencoder (AE) to
learn meaningful hash codes (Tang et al., 2017). We leave
these investigations as future work.

Figure 9. We make forward predictions for different number of
future steps k using both the real dynamics and the learned dy-
namics model. The plots above show the training performance on
Minigrid MultiRoom-N7-S8.

4. Related Work

4.1. Exploration in Reinforcement Learning
Efficient exploration in reinforcement learning, especially
for sparse-reward reinforcement learning problems is chal-
lenging. A natural and popular solution is to design some
metric to evaluate state novelty and assign high intrinsic re-
ward to novel states. For example, COUNT-based intrinsic
reward (Strehl & Littman, 2008; Kolter & Ng, 2009; Tang
et al., 2017) and curiosity-based intrinsic motivation (Stadie
et al., 2015; Pathak et al., 2017; Burda et al., 2018). An-
other popular way is to do state space entropy maximization
(Hazan et al., 2019; Lee et al., 2019). Recently, nearest
neighbor entropy estimation methods (Yarats et al., 2021a;
Liu & Abbeel, 2021) have shown great performance im-
provements in challenging visual domains. Our method is
compatible with all these successful exploration intrinsic re-
ward designs by using them as rlifelong, but we additionally
encourage the episodic-level reachable space expansion to
achieve large state space coverage within a single episode.

4.2. Episodic Memory
Deriving useful information from episodic buffer have
shown great success in improving the training sample ef-
ficiency in RL on navigation, control, and Atari games.
Episodic memory buffers are applied to mimic hippocampal
episodic control and rapidly assimilate recent experience
(Blundell et al., 2016; Pritzel et al., 2017). As is men-
tioned in the previous sections, (Savinov et al., 2018) keeps
an episodic buffer to store observations and introduce an
episodic curiosity module to determine if a new observation
is reachable from previous observations or not. RAPID (Zha
et al., 2021) proposes a novel way to do behaviour cloning
on episodes with high episodic coverage. NGU (Badia et al.,
2020) combines an episodic novelty module and a lifelong
novelty module to generate intrinsic rewards. However,
in NGU, the episodic novelty is a measurement of differ-
ence between the current observations from the previous
observations, while ours focus on how much the reachable
space is expanded from the new state. RIDE (Raileanu &

8

real dynamics

learned dynamics

n
r
u
t
e
R
e
g
a
r
e
v
A

0.6

0.4

0.2

0.0

0.6

0.4

0.2

0.0

0.0

0.2

0.3

0.5

0.6

0.8

0.0

0.2

0.3

0.5

0.6

0.8

1e7

k=1

k=2

k=3

1e7

 
Go Beyond Imagination: Maximizing Episodic Reachability with World Models

6. Conclusion
In this work, we introduce Go Beyond Imagination- GoBI,
a novel episodic intrinsic reward design that encourages
efficient episodic-level exploration by expanding reachable
space. While most previous episodic intrinsic rewards use a
naive episodic state count or state visitation coverage, our
method exploits learned world models to predict reachable
states and motivates the agent to seek for the states with
more unexplored neighbors. Combined with lifelong intrin-
sic rewards, our method shows great training time sample
efficiency improvement on hard procedurally-generated en-
vironments. At the same time, it can be extended to guide
exploration on continuous control tasks with visual inputs,
both indicating a promising future in this direction.

7. Acknowledgments

This work was supported in part by grants from LG AI Re-
search, NSF IIS 1453651, and NSF FW-HTF-R 2128623.

References

Achiam, J. and Sastry, S. Surprise-based intrinsic moti-
vation for deep reinforcement learning. arXiv preprint
arXiv:1703.01732, 2017.

Andersen, P., Morris, R., Amaral, D., Bliss, T., and O’Keefe,
J. The hippocampus book. Oxford university press, 2006.

Badia, A. P., Sprechmann, P., Vitvitskyi, A., Guo, D., Piot,
B., Kapturowski, S., Tieleman, O., Arjovsky, M., Pritzel,
A., Bolt, A., et al. Never give up: Learning directed
exploration strategies. arXiv preprint arXiv:2002.06038,
2020.

Beattie, C., Leibo, J. Z., Teplyashin, D., Ward, T., Wain-
wright, M., K¨uttler, H., Lefrancq, A., Green, S., Vald´es,
V., Sadik, A., et al. Deepmind lab. arXiv preprint
arXiv:1612.03801, 2016.

Blundell, C., Uria, B., Pritzel, A., Li, Y., Ruderman,
A., Leibo, J. Z., Rae, J., Wierstra, D., and Hass-
abis, D. Model-free episodic control. arXiv preprint
arXiv:1606.04460, 2016.

Burda, Y., Edwards, H., Storkey, A., and Klimov, O. Ex-
ploration by random network distillation. arXiv preprint
arXiv:1810.12894, 2018.

Chevalier-Boisvert, M., Willems, L., and Pal, S. Minimalis-
tic gridworld environment for openai gym. https://
github.com/maximecb/gym-minigrid, 2018.

Chevalier-Boisvert, M., Dai, B., Towers, M., de Lazcano,
R., Willems, L., Lahlou, S., Pal, S., Castro, P. S., and
Terry, J. Minigrid & miniworld: Modular & customizable

reinforcement learning environments for goal-oriented
tasks. CoRR, abs/2306.13831, 2023.

Cobbe, K., Klimov, O., Hesse, C., Kim, T., and Schulman,
J. Quantifying generalization in reinforcement learning.
In International Conference on Machine Learning, pp.
1282–1289. PMLR, 2019.

Cobbe, K., Hesse, C., Hilton, J., and Schulman, J. Lever-
aging procedural generation to benchmark reinforcement
learning. In International conference on machine learn-
ing, pp. 2048–2056. PMLR, 2020.

Eichenbaum, H. The role of the hippocampus in navigation
is memory. Journal of neurophysiology, 117(4):1785–
1796, 2017.

Espeholt, L., Soyer, H., Munos, R., Simonyan, K., Mnih,
V., Ward, T., Doron, Y., Firoiu, V., Harley, T., Dunning,
I., et al. Impala: Scalable distributed deep-rl with im-
portance weighted actor-learner architectures. In Interna-
tional conference on machine learning, pp. 1407–1416.
PMLR, 2018.

Flet-Berliac, Y., Ferret, J., Pietquin, O., Preux, P., and Geist,
M. Adversarially guided actor-critic. arXiv preprint
arXiv:2102.04376, 2021.

Florensa, C., Held, D., Geng, X., and Abbeel, P. Automatic
goal generation for reinforcement learning agents.
In
International conference on machine learning, pp. 1515–
1528. PMLR, 2018.

Freeman, D., Ha, D., and Metz, L. Learning to predict
without looking ahead: World models without forward
prediction. Advances in Neural Information Processing
Systems, 32, 2019.

Ha, D. and Schmidhuber, J. Recurrent world models facil-
itate policy evolution. Advances in neural information
processing systems, 31, 2018a.

Ha, D. and Schmidhuber, J. World models. arXiv preprint

arXiv:1803.10122, 2018b.

Hafner, D., Lillicrap, T., Ba, J., and Norouzi, M. Dream to
control: Learning behaviors by latent imagination. arXiv
preprint arXiv:1912.01603, 2019.

Hafner, D., Pasukonis, J., Ba, J., and Lillicrap, T. Mastering
diverse domains through world models. arXiv preprint
arXiv:2301.04104, 2023.

Hazan, E., Kakade, S., Singh, K., and Van Soest, A. Prov-
ably efficient maximum entropy exploration. In Interna-
tional Conference on Machine Learning, pp. 2681–2691.
PMLR, 2019.

9

Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Kempka, M., Wydmuch, M., Runc, G., Toczek, J., and
Ja´skowski, W. Vizdoom: A doom-based ai research plat-
form for visual reinforcement learning. In 2016 IEEE con-
ference on computational intelligence and games (CIG),
pp. 1–8. IEEE, 2016.

Kirk, R., Zhang, A., Grefenstette, E., and Rockt¨aschel, T. A
survey of generalisation in deep reinforcement learning.
arXiv preprint arXiv:2111.09794, 2021.

Kolter, J. Z. and Ng, A. Y. Near-bayesian exploration in
In Proceedings of the 26th annual
polynomial time.
international conference on machine learning, pp. 513–
520, 2009.

Laskin, M., Lee, K., Stooke, A., Pinto, L., Abbeel, P., and
Srinivas, A. Reinforcement learning with augmented data.
Advances in neural information processing systems, 33:
19884–19895, 2020.

Lee, L., Eysenbach, B., Parisotto, E., Xing, E., Levine,
S., and Salakhutdinov, R. Efficient exploration via state
marginal matching. arXiv preprint arXiv:1906.05274,
2019.

Liu, H. and Abbeel, P. Behavior from the void: Unsuper-
vised active pre-training. Advances in Neural Information
Processing Systems, 34:18459–18473, 2021.

Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A.,
Antonoglou, I., Wierstra, D., and Riedmiller, M. Playing
atari with deep reinforcement learning. arXiv preprint
arXiv:1312.5602, 2013.

Mnih, V., Badia, A. P., Mirza, M., Graves, A., Lillicrap,
T., Harley, T., Silver, D., and Kavukcuoglu, K. Asyn-
chronous methods for deep reinforcement learning. In
International conference on machine learning, pp. 1928–
1937. PMLR, 2016.

Okada, M., Kosaka, N., and Taniguchi, T. Planet of the
bayesians: Reconsidering and improving deep planning
network by incorporating bayesian inference. In 2020
IEEE/RSJ International Conference on Intelligent Robots
and Systems (IROS), pp. 5611–5618. IEEE, 2020.

Parisi, S., Dean, V., Pathak, D., and Gupta, A. Interesting
object, curious agent: Learning task-agnostic exploration.
Advances in Neural Information Processing Systems, 34,
2021.

Pathak, D., Agrawal, P., Efros, A. A., and Darrell, T.
Curiosity-driven exploration by self-supervised predic-
tion. In International conference on machine learning,
pp. 2778–2787. PMLR, 2017.

Pritzel, A., Uria, B., Srinivasan, S., Badia, A. P., Vinyals,
O., Hassabis, D., Wierstra, D., and Blundell, C. Neural

episodic control. In International Conference on Machine
Learning, pp. 2827–2836. PMLR, 2017.

Raileanu, R. and Rockt¨aschel, T. Ride: Rewarding impact-
driven exploration for procedurally-generated environ-
ments. arXiv preprint arXiv:2002.12292, 2020.

Riedmiller, M., Hafner, R., Lampe, T., Neunert, M., De-
grave, J., Wiele, T., Mnih, V., Heess, N., and Springen-
berg, J. T. Learning by playing solving sparse reward
tasks from scratch. In International conference on ma-
chine learning, pp. 4344–4353. PMLR, 2018.

Savinov, N., Raichuk, A., Marinier, R., Vincent, D., Polle-
feys, M., Lillicrap, T., and Gelly, S. Episodic curiosity
through reachability. arXiv preprint arXiv:1810.02274,
2018.

Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and
Klimov, O. Proximal policy optimization algorithms.
arXiv preprint arXiv:1707.06347, 2017.

Sekar, R., Rybkin, O., Daniilidis, K., Abbeel, P., Hafner, D.,
and Pathak, D. Planning to explore via self-supervised
world models. In International Conference on Machine
Learning, pp. 8583–8592. PMLR, 2020.

Seo, Y., Chen, L., Shin, J., Lee, H., Abbeel, P., and Lee,
K. State entropy maximization with random encoders
for efficient exploration.
In Meila, M. and Zhang, T.
(eds.), Proceedings of the 38th International Conference
on Machine Learning, volume 139 of Proceedings of
Machine Learning Research, pp. 9443–9454. PMLR, 18–
24 Jul 2021. URL https://proceedings.mlr.
press/v139/seo21a.html.

Stadie, B. C., Levine, S., and Abbeel, P. Incentivizing ex-
ploration in reinforcement learning with deep predictive
models. arXiv preprint arXiv:1507.00814, 2015.

Strehl, A. L. and Littman, M. L. An analysis of model-
based interval estimation for markov decision processes.
Journal of Computer and System Sciences, 74(8):1309–
1331, 2008.

Tang, H., Houthooft, R., Foote, D., Stooke, A., Xi Chen, O.,
Duan, Y., Schulman, J., DeTurck, F., and Abbeel, P. #
exploration: A study of count-based exploration for deep
reinforcement learning. Advances in neural information
processing systems, 30, 2017.

Tunyasuvunakool, S., Muldal, A., Doron, Y., Liu, S., Bohez,
S., Merel, J., Erez, T., Lillicrap, T., Heess, N., and Tassa,
Y. dm control: Software and tasks for continuous control.
Software Impacts, 6:100022, 2020.
ISSN 2665-9638.
https://doi.org/10.1016/j.simpa.2020.100022.
doi:
https://www.sciencedirect.com/
URL
science/article/pii/S2665963820300099.

10

Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Wang, T., Bao, X., Clavera, I., Hoang, J., Wen, Y., Lan-
glois, E., Zhang, S., Zhang, G., Abbeel, P., and Ba,
J. Benchmarking model-based reinforcement learning.
arXiv preprint arXiv:1907.02057, 2019.

Yarats, D., Fergus, R., Lazaric, A., and Pinto, L. Reinforce-
ment learning with prototypical representations. In Inter-
national Conference on Machine Learning, pp. 11920–
11931. PMLR, 2021a.

Yarats, D., Zhang, A., Kostrikov, I., Amos, B., Pineau, J.,
and Fergus, R. Improving sample efficiency in model-
free reinforcement learning from images. In Proceedings
of the AAAI Conference on Artificial Intelligence, vol-
ume 35, pp. 10674–10681, 2021b.

Zha, D., Ma, W., Yuan, L., Hu, X., and Liu, J. Rank
the episodes: A simple approach for exploration in
procedurally-generated environments. arXiv preprint
arXiv:2101.08152, 2021.

Zhang, T., Xu, H., Wang, X., Wu, Y., Keutzer, K., Gonza-
lez, J. E., and Tian, Y. Noveld: A simple yet effective
exploration criterion. Advances in Neural Information
Processing Systems, 34, 2021.

11

Go Beyond Imagination: Maximizing Episodic Reachability with World Models

A. Implementation Details

A.1. Experiments on Minigrid

Baselines
Implementations of GoBI, NovelD (Zhang
et al., 2021), RIDE (Raileanu & Rockt¨aschel, 2020),
RND (Burda et al., 2018), and EC (Savinov et al., 2018) are
built on the official codebase of NovelD. For fair compar-
isons, only the intrinsic reward rint differs among the meth-
ods and they all use the same base algorithm IMPALA (Es-
peholt et al., 2018). At the same time, all the experiments
are run with the same compute resource with Nvidia TI-
TAN X GPU and 40 CPUs. For NovelD, we rerun their
official code to get the results of Minigrid MultiRoom and
KeyCorridor. For the experiments on ObstructedMaze, we
did not find the proper hyper-parameters to fully reproduce
their results. Therefore, we directly take the results reported
in their paper. For RIDE and RND, we run the code in
the official codebase of NovelD. For EC (Savinov et al.,
2018), their original paper does not include experiments
on Minigrid environments. Therefore, we implement our
own version and tune the hyper-parameters with grid search.
The intrinsic reward functions of GoBI and the baselines
are listed below:

• GoBI: (mt+1 − mt)/(cid:112)N (ot+1), where mt is the size
of the episodic buffer M and N (ot+1) is the lifelong
count of the observation ot+1 starting from the begin-
ning of training.

• RND: ∥ϕ(ot+1) − ˆϕ(ot+1)∥2, which is the difference
between a fixed random network ˆϕ and a trained state
embedding network ϕ. Here, ϕ is trained to minimize
the same error.

• NovelD: max[novelty(ot+1) − α · novelty(ot), 0] ∗
1{N epi(st+1 = 1)}. They apply RND to measure the
novelty of ot, i.e., novelty(ot) = ∥ϕ(ot) − ˆϕ(ot)∥2.
N epi(st+1 = 1) checks if the agent visits state st+1
for the first time in an episode. Notice that they use
the full environment information, i.e. everything in the
grid world instead of only the 7×7 partially-observable
view. Therefore N epi counts st+1 instead of ot+1.
• RIDE: ∥ϕ(ot) − ϕ(ot+1)∥2/(cid:112)N epi(st+1), where ϕ is
the state embedding network trained to minimize the
prediction error of an inverse and a forward dynamics.
N epi indicates the episodic counts. Same as NovelD,
in RIDE, they also use the state information st+1 for
episodic count.

Policy and Value Function Training For fair compar-
isons, the policy network and value function network are
the same for all approaches. The input observations of di-
mension 7 × 7 × 3 are put into a shared feature extraction
network, which includes three convolutional layers of ker-
nel size= 3 × 3, padding= 1, channel=32, 128, 512, and
stride= 1, 2, 2 respectively with ELU activation. The fea-
tures are then flattened and put through 2 linear layers with
1024 units and ReLU activation, and an LSTM layer with
1024 units. This shared feature is passed separately to 2
fully-connected layers with 1024 units to output action dis-
tribution and value estimation.

Dynamics model For our implementation of the dynamics
model, our input is the panorama of the current step. To get
the panorama, we let the agent rotate for 3 times and con-
catenate the 4 observations to get inputs of size 28 × 7 × 3.
It is then passed to a feature extraction module that has the
same structure as our policy and value function networks,
except that the input to the first linear layer is 4 × 1024.
We then concatenate it with actions and put it through a de-
coder with 2 linear layers of sizes 256 and 512, and reshape
back to 7 × 7 × 3 to get a predicted observation. We pre-
train the dynamics model using 1e5 (panot, at, ot+1) pairs
collected by a random policy. RIDE also requires training
dynamics models for the state embedding network ϕ. The
input of their dynamics model is the state embedding and
action. The forward model contains two fully-connected
layers with 256 and 128 units activated by ReLU. The in-
verse dynamics model contains two fully-connected layers
with 256 units and a ReLU activation function. Its input is
the state embeddings of two consecutive steps.

Hash Functions We directly apply the default Python
hashing function to hash the 7 × 7 × 3 observations and
predicted future observations before adding them to the
episodic buffer.

State embedding NovelD, RIDE, and RND all require
training a state embedding network ϕ. The input is the
observation in MiniGrid with dimension 7×7×3. It contains
three convolutional layers with kernel size= 3 × 3, padding
= 1, stride = 1, 2, 2, number of channels = 32, 128, 512
respectively. The activation function is ELU. Following the
convolutional layers are two linear layers of 2048 and 1024
units with ReLU activation.

• EC: β − C(M, ot+1), where C(M, ot+1) is the 90-th
percentile similarity scores between ot+1 and all the
observations in the episodic buffer M. The similar-
ity scores are calculated using a pre-trained episodic
curiosity module. β is a hyper-parameter.

Visitation Count For GoBI, N (o) stores the flattened 7 ×
7 × 3 observations of each step. And for NovelD and RIDE,
they count the full states at episodic level, whose shape
varies from environment to environment. For example, the
shape is 25 × 25 × 3 for MultiRoom environments.

12

Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Hyper-parameters Table 1 shows the values of hyper-
parameters shared across different methods.

Parameter name

Batch Size
Optimizer
Learning Rate
LSTM Steps
Discount Factor γ
Weight of Policy Entropy Loss
Weight of Value Function Loss

Value

32
RMSProp
0.0001
100
0.99
0.0005
0.5

Table 1. Hyper-parameters for experiments on Minigrid. These
hyper-parameters are shared across all the methods

For all of our experiments using GoBI on Minigrid, we set
the intrinsic reward coefficient λ = 0.01 and k = 1, which
means only forwarding the dynamics model by 1 step. At
the same time, as the action space is small and discrete,
instead of randomly sampling some actions, we directly
predict the future observations using all 7 possible actions.
We list the hyper-parameter choices of intrinsic decay factor
ρ in Table 2. The value of ρ is chosen to make the intrinsic
reward large at the beginning of training and near-zero at
the end of the training.

Parameters

Forward Step k
Intrinsic Decay ρ

ˆfϕ Optimizer
ˆfϕ Learning Rate

Value

1
6e−7 for MR-N7S8;
8e−7 for MR-N12S10, MR-N6;
1.5e−6 for KC-S3R3;
5e−7 for KC-S4R3, KC-S5R3
3e−7 for KC-S6R3, OM-2Dlh
2e−7 for OM-1Q, OM-2Dlhb, OM-2Q
5e−8 for OM-Full
Adam
5e−4

Table 2. The hyper-parameters of GoBI for experiments on Mini-
grid.

For NovelD, we set λ = 0.05 for all the environments
as is suggested in their official codebase. For RIDE, we
use λ = 0.1 on KeyCorridor-S3R3 and λ = 0.5 on all
other environments. For RND, we set λ = 0.1 on all the
environments. For EC, we make λ = 0.01 so that the initial
average intrinsic reward of EC is similar to ours.

experiments apply the same base reinforcement learning
algorithm RAD (Laskin et al., 2020). For RE3, we rerun
their official code to get the results on all four environments.
For ICM and RND, we follow the implementation details
listed in RE3 to implement them to be compatible with
DeepMind Control tasks. For a fair comparison, only the
intrinsic reward design differs among the methods. The in-
trinsic reward functions of GoBI and the baselines are listed
below:

• GoBI: (mt+1 −mt)×log(||yi −yk−N N

||2 +1), where
mt is the size of the episodic buffer M. The latter part
is the RE3 intrinsic reward which we introduce below.

i

i

• RE3: log(||yi − yk−N N

||2 + 1), where yi = fθ(si) is
a fixed representation outputs from a randomly initial-
ized encoder and yk−N N
is a set of k-nearest neighbors
of yi among all the collected y’s from the beginning of
training.

i

• ICM: η

2 || ˆϕ(ot+1) − ϕ(ot+1)||2

2, where η is a scaling
factor. ϕ(o) is a feature vector that is jointly optimized
with a forward prediction model and an inverse dynam-
ics model and ˆϕ(o) predicts the feature encoding at
time step t + 1.

• RND: ∥ϕ(ot+1) − ˆϕ(ot+1)∥2, which is the difference
between a fixed random network ˆϕ and a trained state
embedding network ϕ. Here, ϕ is trained to minimize
∥ϕ(ot+1) − ˆϕ(ot+1)∥2.

Architecture The observation size of all the environments
is 84×84×3. The encoder architecture follows the same one
as in (Yarats et al., 2021b), which contains 4 convolutional
layers of 3 × 3 kernels, channel=32, and stride=2, 1, 1, 1
with ReLU activations. The output is then passed to a fully-
connected layer and normalized by LayerNorm.

Dynamics Model For the forward dynamics model that
we use to generate future predictions, we apply the same
world model structure as in Dreamer (Hafner et al., 2019).
The input size of Dreamer is 64 × 64 × 3. We down-sample
the input observations to 64 × 64 instead of tuning the world
model layers. We train the dynamics model together with
the RL policy in an online manner instead of pre-train it
because it takes many episodes for the predictions to be
visually reasonable. Therefore it does not add extra effort to
determine how many data should we collect to pre-train the
dynamics model.

A.2. Experiments on Deepmind Control Suites

Baselines
Implementations of GoBI, RE3 (Seo et al.,
2021), ICM (Pathak et al., 2017), and RND (Burda et al.,
2018) are built on the official codebase of RE3. All the

Image hashing As the observations are images in high-
dimensional space and the predictions are usually not accu-
rate, we hash the images to lower dimension to avoid taking
too much space and to collapse similar observations and

13

Go Beyond Imagination: Maximizing Episodic Reachability with World Models

predictions. Following (Tang et al., 2017), we use the sim-
ple SimHash function to map the images to 50 bits. More
specifically, we project the flattened images to a random
initialized vector and use the signs of output vector values
as the hash code.

Hyper-parameters Table 3 shows the values of hyper-
parameters shared across different methods.

decreases to very small. Therefore sometimes it is hard for
the agent to learn anything useful, resulting in unsatisfac-
tory performance. Meanwhile, if ρ is too small, for example
when ρ = 5e − 7, the intrinsic reward will be too large at
later stage of training and make the agent focus less on the
extrinsic reward. Therefore the policy may converge slower.

Parameter name

Augmentation
Observation Size
Action Repeat
Replay Buffer Size
Initial Random Exploration Steps
Frame Stack
Actor Learning Rate
Critic Learning Rate
Batch Size
# Nearest Neighbors
Critic Target Update Freq

Value

Crop
(84, 84)
2
100000
1000
3
0.0002
0.0002
512
3
2

Table 3. Hyper-parameters for experiments on DeepMind Control
Suites. These hyper-parameters are shared across all the methods

For the intrinsic reward coefficients, we follow the best
choices reported in RE3. For GoBI, we apply the same
intrinsic reward coefficient λ and intrinsic reward decay ρ
as the ones in RE3 for fair comparison. The intrinsic rewards
that are specific to our method is shown in Table 4. For the
number of random actions n, we perform hyper-parameter
search over {3, 5, 10, 20} and find that n = 5 perform well
across all the tasks. For the number of forward steps k, we
perform hyper-parameter search over {1, 2, 3, 5} and report
the ones with the best results.

Parameter name

# Forward Step k

# Random Actions n

Value

3 for pendulum-swingup;
1 for others
5

Table 4. Hyper-parameters for experiments on DeepMind Control
Suites. These hyper-parameters are specific to our method.

B. Hyper-Parameters

B.1. Intrinsic reward decay

Figure 10. Training performance of GoBI on Minigrid Multiroom-
N12-S10 with different intrinsic reward decay ρ.

Figure 11. Training performance of GoBI on Minigrid Multiroom-
N7-S8 with different n randomly sampled actions per step.

B.2. Number of randomly sampled actions

In the Minigrid experiments reported in Section 3, we do
not randomly sample actions because Minigrid has a small
discrete action space with only 7 actions. Therefore we
directly predict future observations of all 7 actions. How-
ever, we also report the results with n = 3, 5, 10, 15 random
actions in Figure 11. To summarize, n = 5, 10, 15 all have
similar performance on Minigrid, while a larger n makes
the wallclock training time longer. n = 3 is slightly slower
at the early stage, but still outperforms the previous state-
of-the-arts. Overall, n = 5 would be a good choice for the
Minigrid environments.

In Figure 10, we show the training performance with differ-
ent intrinsic reward decay ρ. The choice of ρ is to balance
between the relative importance of the extrinsic and intrinsic
reward. If ρ is too large, for example when ρ = 1e − 6,
before the agent finds any goal, the intrinsic reward already

C. Exploration Behaviour Comparison

between GoBI and EC

In Figure 12, we visualize the policy visitation heatmaps
of GoBI and EC (Savinov et al., 2018) on a MultiRoom

14

n
r
u
t
e
R
e
g
a
r
e
v
A

0.6

0.4

0.2

0.0

0.0

MultiRoom-N12-S10

0.3

0.2
0.6
environment steps (1e7)

0.5

 = 1e-6
 = 9e-7

 = 8e-7
 = 7e-7

0.8

 = 6e-7
 = 5e-7

 
MultiRoom-N7-S8

n
r
u
t
e
R
e
g
a
r
e
v
A

0.6

0.4

0.2

0.0

0.0

0.2

0.3

0.5

0.6

0.8

1e7

n=3

n=5

n=10

n=15

 
Go Beyond Imagination: Maximizing Episodic Reachability with World Models

Figure 12. Heatmaps of example trajectories at different training steps in Minigrid-Multiroom-N7-S8 environment.

Algorithm Wallclock Time (hours)

NovelD
GoBI(ours)

5.46(±0.058)
10.65(±0.082)

Table 5. Wallclock training time comparison in hours between
NovelD and GoBI.

environment from Minigrid. Although EC fails to learn an
optimal policy, we can still capture its preference from the
heatmaps. An agent trained with EC prefers going to the
corners of the room, which generally have lower similarity
scores than the states in the middle of the room. However,
if the similarity scores are not low enough for the states
to be added to the episodic buffer, it will continue staying
at the states to maximize its intrinsic reward. We tried to
tune the similarity score threshold using grid search but still
have not find a good hyper-parameter choice for it because
the similarity score at different corners does not share a
consistent value. Unlike EC, we can see from the figure
that GoBI chooses not to visit the border of the room early
on in training, as the information on the border are easily
predictable from the information in the middle of the room.

Figure 14. An illustrative example of why R2 does not work well
to encourage efficient exploration. In this example, our goal is
to include all the states into the episodic buffer quickly. GoBI
can move directly to the center in one step for maximum intrinsic
reward, while R2 may choose to take extra steps for exploration
since it mainly focuses on whether the episodic buffer expands or
not.

Figure 13. Training performance comparison on MultiRoom-N7-
S8 environment among 1) use a fixed pre-trained dynamics model,
2) use a pre-trained dynamics model, and fine-tune it online, 3)
no pre-training, directly train the dynamics model together with
policy training.

D. Wallclock Training Time

Table 5 shows the wallclock time needed to train NovelD
and our method for 10M Minigrid environment steps. GoBI
requires about 2x the wallclock time needed to train NovelD
for the same number of environment steps.

E. Dynamics Training

In the experiment section 3, we report the results of apply-
ing a pre-trained forward dynamics for GoBI on Minigrid.
However, the forward dynamics model can also be trained
together with policy training. In Figure 13, we report the
results of an ablation study on a Minigrid environment of
3 settings: 1) use a pre-trained dynamics model, and keep
it fixed when training the policy, 2) pre-train a dynamics
model, and fine-tune it when training the policy, 3) no pre-
training, directly train the dynamics model in an online
manner. In summary, all 3 versions work similarly, but due
to the fact that training the dynamics model online will add

15

GoBI(Ours)

Training Environment when Episode = 2

Goal

Agent

Minigrid-MultiRoom-N7S8-v0

Episodic 
Curiosity (EC)

s
t
n
u
o
C
d
e
t
i
s
V

i

2.3M

2.1M

4.5M

4.0M

8.9M

Training Steps

5.9M

8.0M

Unseen

Seen

 
MultiRoom-N7-S8

n
r
u
t
e
R
e
g
a
r
e
v
A

0.6

0.4

0.2

0.0

0.0

0.2

0.3

0.5

0.6

0.8

1e7

pre_train+fine_tune

no_pre_train

no_fine_tune

 
Model

t = 0

t = 1

t = 2

t = 3

R2

GoBI
(Ours)

s0

s0

s2

s3 s2

s0

s1

s0

s1

s0

s1

s1

s0

st

Visited State

Reachable State

Non-reachable State

Trajectory (Directed via Temporal Order)

Observed Transition Path (Bidirectional)

Unreachable Transition Path (Bidirectional)

Go Beyond Imagination: Maximizing Episodic Reachability with World Models

extra wall clock training time, we use option 1 in our main
experiments.

F. Ablation Study Illustration

In this section, we provide an illustrative example of why
only considering whether new states are added to the
episodic buffer or not, i.e., R2 in Section 3.3, works way
worse than our method. The example is shown in Figure 14.
If these 9 states are only a small part of the environment, we
want a policy that explore this part as quickly as possible -
mark all the states as reachable as quickly as possible. How-
ever, in order to maximize its step-wise intrinsic reward, an
agent trained with R2 will go along the border to only add a
few new states to the episodic buffer at a time, which wastes
many unnecessary steps so is not beneficial for exploration.

16

","Go Beyond Imagination : Maximizing Episodic Reachability with World Models Yao Fu 1 Run Peng 1 Honglak Lee 1 2 3 2 0 2 g u A 5 2 ] G L . s c [ 1 v 1 6 6 3 1 . 8 0 3 2 : v i X r a Abstract Efficient exploration is a challenging topic in rein- forcement learning , especially for sparse reward tasks . To deal with the reward sparsity , people commonly apply intrinsic rewards to motivate agents to explore the state space efficiently . In this paper , we introduce a new intrinsic reward design called GoBI - Go Beyond Imagination , which combines the traditional lifelong novelty motivation with an episodic intrinsic reward that is designed to maximize the stepwise reachability expansion . More specifically , we apply learned world models to generate predicted future states with random actions . States with more unique predictions that are not in episodic memory are as- signed high intrinsic rewards . Our method greatly outperforms previous state-of-the-art methods on 12 of the most challenging Minigrid navigation tasks and improves the sample efficiency on loco- motion tasks from DeepMind Control Suite . 1 . Introduction Efficient exploration in state space is a fundamental chal- lenge in reinforcement learning ( RL ) ( Hazan et al. , 2019 ; Lee et al. , 2019 ) , especially when the environment rewards are sparse ( Mnih et al. , 2013 ; 2016 ; Schulman et al. , 2017 ) or absent ( Liu & Abbeel , 2021 ; Parisi et al. , 2021 ) . Such reward sparsity makes RL algorithms easy to fail due to the lack of useful signals for policy update ( Riedmiller et al. , 2018 ; Florensa et al. , 2018 ; Sekar et al. , 2020 ) . A com- mon approach for exploration is to introduce self-motivated intrinsic rewards such as state visitation counts ( Strehl & Littman , 2008 ; Kolter & Ng , 2009 ) and prediction er- rors ( Stadie et al. , 2015 ; Pathak et al. , 2017 ; Burda et al. , 2018 ) . Most of these intrinsic reward designs measure life- long state novelty and prioritize visiting states that are less 1University of Michigan 2LG AI . Correspon- Yao Fu < violetfy @ umich.edu > , Run Peng dence to : < roihn @ umich.edu > , Honglak Lee < honglak @ eecs.umich.edu & honglak @ lgresearch.ai > . Proceedings of the 40 th International Conference on Machine Learning , Honolulu , Hawaii , USA . PMLR 202 , 2023 . Copyright 2023 by the author ( s ) . 1 visited starting from the beginning of training . While the above methods achieves great improvement on hard-exploration tasks like Montezumas Revenge ( Burda et al. , 2018 ) , they generally only work well on “ single- ton ” environments , where training and evaluation environ- ments are the same . However , due to the poor generalization performance of reinforcement learning in unseen environ- ments ( Kirk et al. , 2021 ) , nowadays researchers have been paying more attention on procedurally-generated environ- ments ( Cobbe et al. , 2019 ; 2020 ; Flet-Berliac et al. , 2021 ) , where the nature of task remains the same but the environ- ment is randomly constructed for each new episode . For example , a maze-like environment will have different maze structures , making it rare for the agent to encounter the same observations across different episodes . Therefore , lifelong novelty intrinsic motivations usually fail in hard procedurally-generated environments of this kind ( Raileanu & Rockt¨aschel , 2020 ; Zha et al. , 2021 ) because an agent will be trapped around newly-generated states . Inspired by human ’ s frequent use of short-term memory ( An- dersen et al. , 2006 ; Eichenbaum , 2017 ) to avoid repeatedly visiting the same space , recent work propose to derive intrin- sic rewards on episodic level ( Savinov et al. , 2018 ; Badia et al. , 2020 ; Raileanu & Rockt¨aschel , 2020 ; Zha et al. , 2021 ; Zhang et al. , 2021 ) . The episodic intrinsic rewards gener- ally give bonus to large episodic-level state space visitation coverage , therefore encourage visiting as many states as possible in the same episode . However , does visiting more states necessarily mean efficient episodic-level exploration ? We notice that some state visitations are unnecessary and can be avoided if they are predictable from episodic mem- ory . For example , when navigating through a house to find a fridge , if you open a door and find an empty room , you do not need to go into it anymore because you can easily predict what the states are like in the room ( i.e. , intuitively speaking , you would be moving around in an empty room ) . With this inspiration , we propose to design the episodic in- trinsic reward to not only maximize the number of visited states in an episode , but also consider those states that are not visited but can be predicted from episodic memory . More precisely , we maintain an episodic buffer to store all the visited states as well as states reachable from the visited states within a few time steps . To get the reachable states , Go Beyond Imagination : Maximizing Episodic Reachability with World Models Figure 1 . Illustration of how GoBI works on Minigrid . For the environment in the upper-left corner , the red triangle indicates the position and orientation of the agent . It has a 7 × 7 partially-observable view ( highlighted ) . During pre-training ( Stage 1 ) , we collect data using a random policy to train a forward dynamics model ˆfϕ ( panot , at ) = ot+1 , where panot denotes the panoramic view as is defined in Section 3.1 . For policy training ( Stage 2 ) , we apply ˆf to predict observations in the future k time steps with n random actions for each step . We add the new ones to an episodic buffer M and take the change of size of M as the episodic intrinsic reward repi . The lifelong intrinsic reward is COUNT-based . Our intrinsic reward GoBI is rlifelong ∗ repi . we train a world model with forward dynamics function and apply random actions to the learned dynamics model to pre- dict future states . The predictions are added to the episodic buffer if they are not there already . We use the change of size of this episodic buffer as the episodic intrinsic reward . Following many previous work , we weight the episodic in- trinsic reward by a lifelong intrinsic reward ( Badia et al. , 2020 ; Zhang et al. , 2021 ) like the COUNT-based rewards . With this newly proposed intrinsic reward design GoBI - Go Beyond Imagination , the agent is expected to both explore the most of the state space throughout training to discover extrinsic rewards , and learn to act in an efficient manner within a single episode to avoid being trapped by seemingly novel states . The contributions of this work can be highlighted as fol- lows : ( i ) We propose a novel way to combine world models with episodic memory to formulate an effective episodic intrinsic reward design . ( ii ) In sparse-reward procedurally- generated Minigrid environments ( Chevalier-Boisvert et al. , 2023 ) , GoBI greatly improves the training sample efficiency in comparison with prior state-of-the-art intrinsic reward functions . ( iii ) GoBI extends well to DeepMind Control Suite ( Tunyasuvunakool et al. , 2020 ) with high-dimensional visual inputs and shows promising results on sparse-reward continuous control tasks . ( iv ) We analyze the design of GoBI and present extensive ablations to show the contribu- tion of each component . 2 . Method We consider reinforcement learning problems framed as Markov Decision Process ( MDP ) M = ( S , A , T , R , γ ) , where S and A denote the state space and action space . T : S × A × S → [ 0 , 1 ] is the state transition function . R : S × A × S → R is the reward function . γ is the reward discount factor . At each step t , the state of the environment is denoted as st ∈ S. The agent generates an action at ∈ A to interact with the environment . The environment then transits to the next underlying state st+1 ∈ S. Apart from the new state st+1 , the environment also returns an extrinsic reward rext that describes how well the agent reacts to st . In sparse-reward tasks , rext is usually 0 . In this work , we follow the previous work to train RL algorithms with rext +λ∗rint is a self-motivated intrinsic reward and λ is a hyper-parameter that controls the relative importance between intrinsic and extrinsic rewards . , where rint t t 2.1 . Go Beyond Imagination Reachable States and Episodic Buffer Our intrinsic re- ward design aims to exploit the information hidden inside the neighbourhood of states . We define a state A to be k- step reachable from state B if the agent can reach A from B within k time steps . During the training process , for each new episode , we initialize an empty episodic memory buffer M. At time step t , we hash st as well as all the states reachable from st. We denote the set containing all the hash 2 Environment e.g . 🚶 Action Space 1 . Left 2 . Right 3 . Forward 4 . Pickup 5 . Drop 6 . Toggle 7 . Done ⬅ ➡ 🚶 🤏 ✋ 🛠 ✅ Encoder Decoder Policy Net Conv2d U L E R + r a e n L i U L E R + r a e n L i Episodic Memory Expansion = 🚶 next obs = Random Actions k n Already in New state Pre-train forward dynamics model Stage 1 X Count ( ) Episodic Reachability Maximization Stage 2 Go Beyond Imagination : Maximizing Episodic Reachability with World Models Figure 2 . An illustration of how our episodic buffer updates . We consider reachable states that are k = 2 time steps away from st. After the agent moves from s1 to s2 , the episodic buffer M ( shaded in green ) expands by 3 new reachable states ( shaded in yellow ) . More formally , M ← M ∪ MR ( s2 ) , where MR ( s2 ) indicates a set of all the states 2-step reachable from s2 . Notice that all the states in the trajectory , i.e. , s0 , s1 , s2 are also added to the buffer . codes of st and its reachable states as MR ( st ) . Then we update M by M ← M ∪ MR ( st ) . Storing the hash codes instead of directly storing the states may alleviate the poten- tial memory issue of the buffer . We illustrate this process in Figure 2 . When the agent reaches state s2 , we add 3 more states that are reachable from s2 but not in M. Forward Dynamics In real environments , it is common that we do not have access to the neighbourhood relationship between states . However , we can learn a world model by training a forward dynamics model ˆfϕ ( st , at ) = st+1 to predict the states reachable from st . This forward dynamics can be pre-trained using data collected by a random policy or trained online together with policy training . When training the policy , for each time step t , we generate k · n random actions and use the learned dynamics ˆfϕ to predict states in the future k steps . We hash the current state st as well as the t+1 , ... , ˆsn predicted future states ˆs1 t+k and add the hash codes to the episodic buffer M if they are not in the buffer . Apart from alleviating potential memory issue as is mentioned in the last paragraph , using a hash function may also mitigate the noise introduced by ˆf . With a learned dynamics model , the predictions of reachable states are usually not perfect . However , in the experiment section we show that even with imperfect predictions , our method can improve the training sample efficiency a lot . t+k , ... , ˆsn t+1 , ... , ˆs1 Episodic Novelty We aim to design an episodic-level nov- elty reward that guides the agent to extend the frontier of its predicted reachable space efficiently to discover states not visited and not predictable within the same episode . More specifically , we denote the size of the episodic buffer M as mt at time step t and design a reachability-based bonus repi = mt+1 − mt that encourages the agent to find unex- plored regions . For each time step , the agent is expected to reach the state that is reachable to more new states in the current episode . 3 Intrinsic Reward Formulation We further weight our episodic intrinsic reward by a lifelong intrinsic reward to encourage the agent to explore the regions that are not well explored in the past . More formally , the proposed intrinsic reward GoBI is defined as : t = ( mt+1 − mt ) ∗ rlifelong rint t ( 1 ) Here , rlifelong denotes lifelong intrinsic reward . We note t that our framework is compatible with any choice of lifelong intrinsic reward . Specifically , we use the simple COUNT- based reward 1/ ( cid:112 ) N ( st+1 ) for the navigation experiments on Minigrid environments ( Chevalier-Boisvert et al. , 2023 ) , where N denotes the count of st+1 from the start of train- ing.1 For the experiments on DeepMind Control Suite ( Tun- yasuvunakool et al. , 2020 ) we use the state-of-the-art in- trinsic reward RE3 ( Seo et al. , 2021 ) , which estimates state entropy by a random encoder . Intrinsic Decay Intrinsic rewards are expected to be asymptotically consistent so that it will not influence the policy learning at later stage of training and result in a sub-optimal policy . To guarantee that the policy learning focuses more on extrinsic rewards as training proceeds , in RE3 ( Seo et al. , 2021 ) , the authors apply exponential decay schedule for the intrinsic rewards to decrease over time . Al- though COUNT-based reward theoretically converges to 0 with enough exploration , it decreases quite slowly in procedurally-generated environments . Therefore , we also apply intrinsic reward decay when calculating GoBI by de- creasing the intrinsic reward coefficient λ during training . We summarize our method in Algorithm 1 and illustrate the training process on Minigrid navigation tasks in Figure 1 . 1For environments that are partially observable ( e.g. , in Mini- grid , the agent observes a 7×7 pixel local view of the environment ) , we substitute state st with observation ot when calculating the in- trinsic rewards . t = 1 t = 2 Action : Move ( S1 , S2 ) Episodic Buffer Non-reachable Space New Reachable Space Reachable States from Visited State Reachable State Non-reachable State Trajectory Observed Transition Path Unreachable Transition Path Go Beyond Imagination : Maximizing Episodic Reachability with World Models Algorithm 1 Go Beyond Imagination Input : Intrinsic Reward Coefficient λ0 , Forward Pre- diction Step k , Number of Random Actions n , Intrinsic Reward Decay Parameter ρ Initialize policy πθ , dynamics model ˆfϕ , replay buffer B . ( Optional ) Collect episodes with πθ and train ˆfϕ with prediction loss for episode e = 1 , 2 , ... until convergence do Initialize episodic buffer M. λ ← λ0 ∗ ( 1 − ρ ) ( e−1 ) ∗T for t = 1 to T do Execute πθ in the environment to get a transition pair ( st , at , st+1 , rext mt ← size ( M ) M ← M ∪ { hash ( st ) } ) for t′ = 1 to k do ) . t gets a high intrinsic reward if the corresponding similarity scores are low . Only with low enough similarity scores do they add st to the buffer . Although their method and ours are similar at high level , they are different by design . For ex- ample , for an agent standing in front of an empty blind alley with dead end , agent trained with GoBI does not benefit in going deep into the blind alley because everything there can be predicted as reachable and added to the episodic buffer already . However , EC encourages going to the very end of the blind alley to reach the state with low similarity score and high intrinsic reward , even though going into an empty blind alley is not beneficial for exploration and wastes time that can be used to explore other parts of the environment . In Appendix C , we present the visitation heatmaps of poli- cies learned by EC and find that it prefers going to the room corners , which well matches our explanation above . t′ , ... , an t′ generate n random actions a1 M ← M ∪ { hash ( ˆfϕ ( ( cid:98 ) si t+t′ , ai end for t = ( size ( M ) − mt ) ∗ rlifelong rint B ← B ∪ { ( st , at , st+1 , rext t + λ ∗ rint t ) } t′ ) |i = 1 , ... , n } ) end for update πθ with RL objective update ˆfϕ with prediction loss end for 2.2 . Conceptual Advantage of GoBI over Prior Works Previous works including RIDE ( Raileanu & Rockt¨aschel , 2020 ) and NovelD ( Zhang et al. , 2021 ) also combine episodic intrinsic reward with lifelong novelty as we do . However , most of them focus on episodic-level state vis- itation . For example , NovelD only assigns non-zero re- wards to a state when it is visited for the first time in the episode . However , we notice that not all state visitations are necessary . The agent ’ s goal for exploration is to gather information about the states . Therefore for states that are easily predictable from episodic memory , visiting them may not really help to acquire more information about the en- vironment . In Figure 4 , we plot the visitation heatmap of GoBI and NovelD to demonstrate the different exploration behaviours of the two methods . Our method is closely related to another work that mea- sures episodic curiosity ( EC ) ( Savinov et al. , 2018 ) . In EC , the authors train a reachability network that takes in two arbitrary states and outputs a similarity score between 0 and 1 , where 1 indicates the two states are the same and 0 indicates they are totally different . The network is trained using collected episodes by marking temporally close states as positive examples and temporally far ones as negative samples . Meanwhile , they also maintain an episodic buffer . A state st is compared with all the states in the buffer and ( a ) MiniGrid ( b ) Deepmind Control Figure 3 . Rendering of the environments used in this work . Left : 2D grid world navigation tasks that require object interactions . Right : DeepMind Control tasks with visual observations . 3 . Experiments In this section , we evaluate GoBI in two domains : 2D procedurally-generated Minigrid environments ( Chevalier- Boisvert et al. , 2018 ) with hard-exploration tasks and lo- comotion tasks from DeepMind Control Suite ( Tunyasu- vunakool et al. , 2020 ) . The experiments are designed to answer the following research questions : ( 1 ) How does GoBI perform against previous state-of-the-art intrinsic re- ward designs in terms of training-time sample efficiency on challenging procedurally-generated environments ? ( 2 ) Can GoBI successfully extend to complex continuous domains with high-dimensional observations , for example control tasks with visual observations ? ( 3 ) How does each compo- nent of our intrinsic reward contribute to the performance ? ( 4 ) What is the influence of the accuracy of the learned world models to our method ? 3.1 . Minigrid Navigation Tasks Minigrid Environments MiniGrid ( Chevalier-Boisvert et al. , 2018 ) is a set of partially-observable procedurally- 4 Go Beyond Imagination : Maximizing Episodic Reachability with World Models Figure 4 . Visitation heatmaps on KeyCorridorS5R3 at different training stages . This figure compares the policy behaviour of GoBI and NovelD . A dark red color means plentiful visitations , white means the agent has seen the space but did not step on it , and black means space that are not discovered . It is worth noticing that early in the training ( 3.5M and 7M time steps ) , our policy already learns not to go into an empty room , likely because states in an empty room are easily predictable . On the contrary , even after 11M steps , an agent trained with NovelD still goes into an empty room ( bottom-right corner ) for more state visitations . generated grid world navigation tasks . The agent is expected to interact with objects such as keys , balls , doors , and boxes to navigate through rooms and find the goal that is randomly placed in one of the rooms . The tasks only provide one sparse reward at the end of each episode , which indicates if the agent successfully finds the goal or not and how many steps it takes to reach the goal . In this work , we consider 3 types of tasks including MultiRoom , KeyCorridor , and ObstructedMaze . Some environments that we experiment on in this paper are shown in Figure 3a . The upper-right is a KeyCorridor-S4R3 environment , where the agent should learn to open the doors to find a key , use it to open the locked blue door , and pick up the green ball . The bottom-left fig- ure shows an ObstructedMaze-Full environment , which is similar to KeyCorridor but more challenging . The rooms are larger , the doors are blocked by balls , and the keys are hidden in boxes . The upper-left and bottom-right environ- ments are MultiRoom environments , in which the agent has to navigate through connected rooms to reach the goal in the last room . Baselines We compare with state-of-the-art intrinsic re- ward designs that work well on Minigrid including Nov- elD ( Zhang et al. , 2021 ) , RIDE ( Raileanu & Rockt¨aschel , 2020 ) , and RND ( Burda et al. , 2018 ) . For a fair compari- son , we follow the same basic RL algorithm and network architectures used in the official codebase of NovelD and only change the intrinsic rewards rint for all the methods . We also compare our method with EC ( Savinov et al. , 2018 ) because of the similarity of the high-level idea between the two methods . However , the original paper of EC does not include experiments on Minigrid . Therefore , we im- plement our own version to adapt to Minigrid . We follow their implementation suggestions in the paper and tune the hyper-parameters such as novelty threshold by grid search . Dynamics Model Training For each experiment on Min- igrid , we first run a random policy for 1e5 steps to collect data and use them to train a forward dynamics model as the world model . Among the pairs collected , there are about 5e4 different transition pairs . During our experiments , we observe that fine-tuning the pre-trained dynamics model during policy training has no significant influence on the performance . Similar to ( Parisi et al. , 2021 ) , we use the 360◦ panoramic views as the input to predict the future observations . This is a rotation-invariant representation of the observed state . We consider this still a fair compari- son with the previous state-of-the-arts because both NovelD and RIDE rely on using the state information instead of observations for the episodic count calculation . Due to the limited field of view of the agent , we only forward the learned dynamics by k = 1 step when predicting . We predict the next observations produced by all 7 discrete actions in the Minigrid tasks including turn left , turn right , forward , toggle , pick up , drop , and done . We directly apply the default Python hashing function to hash the observations and predicted future observations . We do not expect the hashing function to mitigate the prediction error on Minigrid , but only use it to reduce the dimension of observations and predictions . Training Performance on Minigrid Figure 5 shows the learning curves of GoBI and state-of-the-art explo- ration baselines NovelD , RIDE , RND , and EC on 12 most challenging Minigrid navigation tasks , including Multi- Room , KeyCorridor , and ObstructedMaze . Our curves are shifted towards right by the number of random explo- ration environment steps used to train the world model . In all 12 environments , GoBI significantly outperforms previous methods in terms of sample efficiency . For in- 5 GoBI ( Ours ) One episode of Training Environment same s t n u o C d e t i s V i Unlock 3.5M 3.5M 7M 7M 11M 11M Training Steps 21M 21M Pick Minigrid-KeyCorridor-S5R3-v0 NovelD Unseen Seen Go Beyond Imagination : Maximizing Episodic Reachability with World Models Figure 5 . Training performance of GoBI and the baselines on 12 MiniGrid environments . The x-axis shows the number of environment steps . We shift the training curves towards right by the number of environment steps we use to pre-train the dynamics model , i.e . 1e5 time steps . Results are averaged across 4 seeds . stance , on ObstructedMaze-2Dlhb , GoBI is about three times more sample efficient than NovelD . On the hard- est ObstructedMaze-Full environment , GoBI achieves near- optimal performance within 70M steps . Lastly , although we try to tune the hyper-parameters of EC , our implementation of EC still does not learn well on the Minigrid environments . Qualitative Results To clearly present the exploration be- havior learned by GoBI , we show the visitation heatmaps of GoBI and NovelD on a KeyCorridorS5R3 environment in Figure 4 . Not only does our method converge to an opti- mal policy faster , the exploration behaviour is very different from NovelD . GoBI quickly learns not to visit easily pre- dictable states like an empty room , making it more efficient to explore interesting parts of the environment , for example , the room with a key in it . Dynamics Model Training We follow the world model structure in Dreamer ( Hafner et al. , 2019 ) and directly apply their encoder , transition model , and observation model to predict future observations . However , compared to Mini- grid , it requires way more data to train a decent dynamics model on DeepMind Control to generate visually-reasonable predictions . Therefore , different from the experiments on Minigrid , we do not pre-train the dynamics models . Instead we train the dynamics model together with the policy as is shown in Algorithm 1 . We find that the number of sampled random actions n = 5 works well across all 4 environments . For the number of forward prediction steps k , we set it to be 3 for Pendulum Swingup and 1 for the other 3 environments . For the hashing function , we find that a simple SimHash as is suggested in ( Tang et al. , 2017 ) works well in capturing the similarities between similar observations . We use SimHash to hash the image observations to 50 bits . 3.2 . Experiments on Control Tasks We further test GoBI on DeepMind Control Suite , which are a set of image-based continuous control tasks . These tasks are more challenging than Minigrid because of its high- dimensional observations and stochastic transitions . Notice that these environments are not procedurally-generated . The experiments in this section are to show the generality of our method by experimentally showing that GoBI extends well to sparse-reward tasks with continuous action space and high-dimensional observation space . Training Performance on DeepMind Control We com- pare with the state-of-the-art intrinsic motivation on Deepm- Mind Control tasks - RE3 ( Seo et al. , 2021 ) , which applies a k-nearest neighbor entropy estimator in the low-dimensional representation space of a randomly initialized encoder to maximize state entropy . RE3 is also what we use for the life- long intrinsic reward part rlifelong of GoBI in Eq 1 . Another two intrinsic reward baselines we consider are ICM ( Pathak et al. , 2017 ) and RND ( Burda et al. , 2018 ) . For a fair com- parison , all the experiments use the same basic RL algorithm 6 MultiRoom-N6 MultiRoom-N7-S8 MultiRoom-N12-S10 KeyCorridorS3R3 0.6 0.4 0.2 0.0 0.6 0.4 0.2 0.0 0.8 0.6 0.4 0.2 0.0 0.0 0.2 0.3 0.5 0.6 0.8 0.0 0.1 0.3 0.5 0.6 0.8 0.0 0.2 0.4 0.6 0.8 0.9 0.0 0.2 0.5 0.7 1.0 1.2 KeyCorridorS4R3 KeyCorridorS5R3 KeyCorridorS6R3 ObstructedMaze-2Dlh 1e7 0.8 0.6 0.4 0.2 0.0 0.8 0.6 0.4 0.2 0.0 1.0 0.8 0.6 0.4 0.2 0.0 0.0 0.2 0.5 0.7 1.0 1.2 0.0 0.3 0.6 0.9 1.2 1.5 0.0 0.4 0.8 1.2 1.6 2.0 0.0 0.4 0.8 1.3 1.7 2.1 ObstructedMaze-2Dlhb ObstructedMaze-1Q ObstructedMaze-2Q ObstructedMaze-Full 1e7 0.8 0.6 0.4 0.2 0.0 0.8 0.6 0.4 0.2 0.0 1.0 0.8 0.6 0.4 0.2 0.0 n r u t e R e g a r e v A 0.6 0.4 0.2 0.0 n r u t e R e g a r e v A 0.8 0.6 0.4 0.2 0.0 n r u t e R e g a r e v A 0.8 0.6 0.4 0.2 0.0 0.0 0.8 1.6 2.4 3.2 4.0 0.0 0.6 1.3 1.9 2.6 3.2 0.0 0.9 1.7 2.6 3.4 4.3 0.0 2.0 4.0 6.0 8.0 10.0 NovelD RIDE EC RND Ours ( GoBI ) 1e7 Go Beyond Imagination : Maximizing Episodic Reachability with World Models episodes than MultiRoom ( all generated rooms are squares with fixed sizes ) , therefore the COUNT-based rewards con- tribute more in such environments than in MultiRoom . At the same time , R2 performs way worse than GoBI . Agents trained with R2 prefer actions that only increase the size of the episodic buffer a bit therefore getting positive score more often . We provide an illustrative example in Appendix F to explain why R2 does not work well compared to GoBI . Using only lifelong intrinsic reward R3 performs the worst and struggles to learn efficiently on large Multiroom , Key Corridor , and Obstructed Maze environments . Real Dynamics vs Learned Dynamics A learned dynam- ics model is generally not perfect , especially for partially- observable environments like Minigrid . In many cases the predictions can never be accurate . For example , when the agent first opens the door of a new room , usually it will not accurately predict everything behind the door . Figure 8 shows the training curves between using the real dynamics model vs a learned dynamics model . Not surprisingly , with the same intrinsic reward function , using the real dynamics converges faster to a near-optimal policy . However , even with imperfect dynamics model , our method still greatly surpasses previous state-of-the-arts . Figure 8 . Comparison between using the real dynamics model of the environments vs using a learned one on Minigrid environments . In both MultiRoom and KeyCorridor , using a real dynamics model to derive intrinsic reward makes the policy converge faster , espe- cially on KeyCorridor . Multi-Step Predictions Figure 9 shows the learning per- formance of GoBI on Minigrid with a varying choices of the number of future steps to do predictions k = 1 , 2 , 3 . For k > 1 , our dynamics model outputs panot+1 instead of ot+1 and we hash and store the observations from panoramas in each future time step . With a real forward dynamics model , a larger k generally accelerates exploration more , because it prioritizes actions that lead to the states that are reachable to more states in the long run . However , due to the limited field of view of the agent and the model inaccuracy , this is not the case if we use a learned model . Forwarding 2 steps is still faster than only 1 step , but more steps than that does not really make exploration faster . Figure 6 . Training curves of GoBI and the baselines on DeepMind Control Suite . The curves are averaged across 5 seeds . RAD ( Laskin et al. , 2020 ) . The results are shown in Figure 6 . The additional episodic-level intrinsic reward term im- proves the sample efficiency a lot compared to only using lifelong intrinsic reward , especially on Hopper Hop and Walker Run Sparse . 3.3 . Ablation Study GoBI Variations In this section , we analyze how each component of our intrinsic reward contributes to the final performance . We ablate each component of GoBI and run experiments on Minigrid environments with the following : • R1 : only episodic intrinsic reward mt+1 − mt • R2 : indicator of whether new states are added to the episodic buffer ( 1 { mt+1 − mt > 0 } ) / ( cid:112 ) N ( ot+1 ) • R3 : only lifelong intrinsic reward 1/ ( cid:112 ) N ( ot+1 ) Figure 7 . Training performance comparison among GoBI , R1 , R2 , and R3 on 3 Minigrid environments . Training performance of GoBI as well as R1 , R2 , and R3 are shown in Figure 7 . Although R1 works on MultiRoom , it suffers on Obstructed Maze and large KeyCorridor environ- ments . The underlying reason may be that in Key Corridor and Obstructed Maze the room structures change less across 7 n r u t e R e d o s p E i 800 600 400 200 0 n r u t e R e d o s p E i 250 200 150 100 50 0 Pendulum Swingup Cartpole Swingup Sparse 800 600 400 200 0 0.0 0.2 0.4 0.7 0.9 1.1 0.0 0.5 1.0 1.6 2.1 2.6 Hopper Hop Walker Run Sparse 1e5 1e5 400 300 200 100 0 0.0 1.0 2.0 3.0 4.0 5.0 0.0 1.0 2.0 3.0 4.0 5.0 RAD+ICM RAD+RND RAD+RE3 RAD 1e5 1e5 Ours MultiRoom-N12-S10 KeyCorridorS6R3 ObstructedMaze-2Dlh n r u t e R e g a r e v A 0.6 0.5 0.4 0.3 0.2 0.1 0.0 0.8 0.6 0.4 0.2 0.0 0.8 0.6 0.4 0.2 0.0 0.0 0.2 0.3 0.5 0.6 0.8 0.0 0.4 0.7 1.1 1.4 1.8 0.0 0.2 0.4 0.6 0.8 1.0 R1 R2 R3 Ours 1e7 MultiRoom-N7-S8 KeyCorridorS3R3 t n r u e R e g a r e v A 0.6 0.4 0.2 0.0 0.8 0.6 0.4 0.2 0.0 0.0 0.1 0.2 0.4 0.5 0.6 0.0 0.1 0.2 0.3 0.4 0.5 real dynamics learned dynamics 1e7 Go Beyond Imagination : Maximizing Episodic Reachability with World Models Rockt¨aschel , 2020 ) and NovelD ( Zhang et al. , 2021 ) both count the episodic state visitations , while we claim that apart from visited states , we should also consider states that can be predicted from short-term episodic memory . 4.3 . Learning World Models with Forward Dynamics Learning dynamics function from a set of observed data is a widely-studied topic in reinforcement learning , especially due to the rapid growth of model-based reinforcement learn- ing ( Wang et al. , 2019 ) . Existing work show that an agent ’ s world model is implicitly a forward model that predict future states ( Ha & Schmidhuber , 2018a ; Freeman et al. , 2019 ) . Recently , people have proposed latent dynamics models that work well on high-dimensional inputs ( Okada et al. , 2020 ) . These latent dynamics models encode image obser- vations and predict future states in the latent space ( Ha & Schmidhuber , 2018b ; Hafner et al. , 2019 ; 2023 ) , outputting realistic future observations on visually complex domains including DeepMind Control Suite ( Tunyasuvunakool et al. , 2020 ) , VizDoom ( Kempka et al. , 2016 ) , Atari Games , and DeepMind Lab ( Beattie et al. , 2016 ) . The learned dynamics models can be used to guide exploration by prediction error ( Stadie et al. , 2015 ; Pathak et al. , 2017 ; Burda et al. , 2018 ) , surprise ( Achiam & Sastry , 2017 ) , or information gain by variance of model ensemble means ( Sekar et al. , 2020 ) . Our method differ from the previous methods by directly gener- ating and hashing the predicted states and add them to an episodic reachable state buffer . With the advanced world model structures , our method can be extended to diverse domains with complex observations . 5 . Discussions and Future Work This paper shows an effective way to combine learned world models with episodic memory to intrinsically guide efficient exploration . Our method achieves state-of-the-art perfor- mance on procedurally-generated hard exploration tasks and also works well on singleton continuous control do- mains . However , it still has certain limitations . First of all , the dynamics model we use for the Minigrid experiments is deterministic , making it possible to generate less accu- rate predictions and making the performance of our method worse than using the real dynamics . A possible way to make improvement on this is to make the prediction model gen- erative and sample possible future states . Secondly , for the control tasks with complex visual inputs , we hash the im- ages with static hashing to make them discrete hash codes . However , to better capture the semantic similarities between the image observations , it would be beneficial to learn hash functions , for example , by using an autoencoder ( AE ) to learn meaningful hash codes ( Tang et al. , 2017 ) . We leave these investigations as future work . Figure 9 . We make forward predictions for different number of future steps k using both the real dynamics and the learned dy- namics model . The plots above show the training performance on Minigrid MultiRoom-N7-S8 . 4 . Related Work 4.1 . Exploration in Reinforcement Learning Efficient exploration in reinforcement learning , especially for sparse-reward reinforcement learning problems is chal- lenging . A natural and popular solution is to design some metric to evaluate state novelty and assign high intrinsic re- ward to novel states . For example , COUNT-based intrinsic reward ( Strehl & Littman , 2008 ; Kolter & Ng , 2009 ; Tang et al. , 2017 ) and curiosity-based intrinsic motivation ( Stadie et al. , 2015 ; Pathak et al. , 2017 ; Burda et al. , 2018 ) . An- other popular way is to do state space entropy maximization ( Hazan et al. , 2019 ; Lee et al. , 2019 ) . Recently , nearest neighbor entropy estimation methods ( Yarats et al. , 2021a ; Liu & Abbeel , 2021 ) have shown great performance im- provements in challenging visual domains . Our method is compatible with all these successful exploration intrinsic re- ward designs by using them as rlifelong , but we additionally encourage the episodic-level reachable space expansion to achieve large state space coverage within a single episode . 4.2 . Episodic Memory Deriving useful information from episodic buffer have shown great success in improving the training sample ef- ficiency in RL on navigation , control , and Atari games . Episodic memory buffers are applied to mimic hippocampal episodic control and rapidly assimilate recent experience ( Blundell et al. , 2016 ; Pritzel et al. , 2017 ) . As is men- tioned in the previous sections , ( Savinov et al. , 2018 ) keeps an episodic buffer to store observations and introduce an episodic curiosity module to determine if a new observation is reachable from previous observations or not . RAPID ( Zha et al. , 2021 ) proposes a novel way to do behaviour cloning on episodes with high episodic coverage . NGU ( Badia et al. , 2020 ) combines an episodic novelty module and a lifelong novelty module to generate intrinsic rewards . However , in NGU , the episodic novelty is a measurement of differ- ence between the current observations from the previous observations , while ours focus on how much the reachable space is expanded from the new state . RIDE ( Raileanu & 8 real dynamics learned dynamics n r u t e R e g a r e v A 0.6 0.4 0.2 0.0 0.6 0.4 0.2 0.0 0.0 0.2 0.3 0.5 0.6 0.8 0.0 0.2 0.3 0.5 0.6 0.8 1e7 k=1 k=2 k=3 1e7 Go Beyond Imagination : Maximizing Episodic Reachability with World Models 6 . Conclusion In this work , we introduce Go Beyond Imagination- GoBI , a novel episodic intrinsic reward design that encourages efficient episodic-level exploration by expanding reachable space . While most previous episodic intrinsic rewards use a naive episodic state count or state visitation coverage , our method exploits learned world models to predict reachable states and motivates the agent to seek for the states with more unexplored neighbors . Combined with lifelong intrin- sic rewards , our method shows great training time sample efficiency improvement on hard procedurally-generated en- vironments . At the same time , it can be extended to guide exploration on continuous control tasks with visual inputs , both indicating a promising future in this direction . 7 . Acknowledgments This work was supported in part by grants from LG AI Re- search , NSF IIS 1453651 , and NSF FW-HTF-R 2128623 . References Achiam , J. and Sastry , S. Surprise-based intrinsic moti- vation for deep reinforcement learning . arXiv preprint arXiv:1703.01732 , 2017 . Andersen , P. , Morris , R. , Amaral , D. , Bliss , T. , and O ’ Keefe , J . The hippocampus book . Oxford university press , 2006 . Badia , A. P. , Sprechmann , P. , Vitvitskyi , A. , Guo , D. , Piot , B. , Kapturowski , S. , Tieleman , O. , Arjovsky , M. , Pritzel , A. , Bolt , A. , et al . Never give up : Learning directed exploration strategies . arXiv preprint arXiv:2002.06038 , 2020 . Beattie , C. , Leibo , J . Z. , Teplyashin , D. , Ward , T. , Wain- wright , M. , K¨uttler , H. , Lefrancq , A. , Green , S. , Vald´es , V. , Sadik , A. , et al . Deepmind lab . arXiv preprint arXiv:1612.03801 , 2016 . Blundell , C. , Uria , B. , Pritzel , A. , Li , Y. , Ruderman , A. , Leibo , J . Z. , Rae , J. , Wierstra , D. , and Hass- abis , D. Model-free episodic control . arXiv preprint arXiv:1606.04460 , 2016 . Burda , Y. , Edwards , H. , Storkey , A. , and Klimov , O. Ex- ploration by random network distillation . arXiv preprint arXiv:1810.12894 , 2018 . Chevalier-Boisvert , M. , Willems , L. , and Pal , S. Minimalis- tic gridworld environment for openai gym . https : // github.com/maximecb/gym-minigrid , 2018 . Chevalier-Boisvert , M. , Dai , B. , Towers , M. , de Lazcano , R. , Willems , L. , Lahlou , S. , Pal , S. , Castro , P. S. , and Terry , J. Minigrid & miniworld : Modular & customizable reinforcement learning environments for goal-oriented tasks . CoRR , abs/2306.13831 , 2023 . Cobbe , K. , Klimov , O. , Hesse , C. , Kim , T. , and Schulman , J. Quantifying generalization in reinforcement learning . In International Conference on Machine Learning , pp . 1282–1289 . PMLR , 2019 . Cobbe , K. , Hesse , C. , Hilton , J. , and Schulman , J. Lever- aging procedural generation to benchmark reinforcement learning . In International conference on machine learn- ing , pp . 2048–2056 . PMLR , 2020 . Eichenbaum , H. The role of the hippocampus in navigation is memory . Journal of neurophysiology , 117 ( 4 ) :1785– 1796 , 2017 . Espeholt , L. , Soyer , H. , Munos , R. , Simonyan , K. , Mnih , V. , Ward , T. , Doron , Y. , Firoiu , V. , Harley , T. , Dunning , I. , et al . Impala : Scalable distributed deep-rl with im- portance weighted actor-learner architectures . In Interna- tional conference on machine learning , pp . 1407–1416 . PMLR , 2018 . Flet-Berliac , Y. , Ferret , J. , Pietquin , O. , Preux , P. , and Geist , M. Adversarially guided actor-critic . arXiv preprint arXiv:2102.04376 , 2021 . Florensa , C. , Held , D. , Geng , X. , and Abbeel , P. Automatic goal generation for reinforcement learning agents . In International conference on machine learning , pp . 1515– 1528 . PMLR , 2018 . Freeman , D. , Ha , D. , and Metz , L. Learning to predict without looking ahead : World models without forward prediction . Advances in Neural Information Processing Systems , 32 , 2019 . Ha , D. and Schmidhuber , J. Recurrent world models facil- itate policy evolution . Advances in neural information processing systems , 31 , 2018a . Ha , D. and Schmidhuber , J . World models . arXiv preprint arXiv:1803.10122 , 2018b . Hafner , D. , Lillicrap , T. , Ba , J. , and Norouzi , M. Dream to control : Learning behaviors by latent imagination . arXiv preprint arXiv:1912.01603 , 2019 . Hafner , D. , Pasukonis , J. , Ba , J. , and Lillicrap , T. Mastering diverse domains through world models . arXiv preprint arXiv:2301.04104 , 2023 . Hazan , E. , Kakade , S. , Singh , K. , and Van Soest , A. Prov- ably efficient maximum entropy exploration . In Interna- tional Conference on Machine Learning , pp . 2681–2691 . PMLR , 2019 . 9 Go Beyond Imagination : Maximizing Episodic Reachability with World Models Kempka , M. , Wydmuch , M. , Runc , G. , Toczek , J. , and Ja´skowski , W. Vizdoom : A doom-based ai research plat- form for visual reinforcement learning . In 2016 IEEE con- ference on computational intelligence and games ( CIG ) , pp . 1–8 . IEEE , 2016 . Kirk , R. , Zhang , A. , Grefenstette , E. , and Rockt¨aschel , T. A survey of generalisation in deep reinforcement learning . arXiv preprint arXiv:2111.09794 , 2021 . Kolter , J . Z. and Ng , A. Y. Near-bayesian exploration in In Proceedings of the 26th annual polynomial time . international conference on machine learning , pp . 513– 520 , 2009 . Laskin , M. , Lee , K. , Stooke , A. , Pinto , L. , Abbeel , P. , and Srinivas , A. Reinforcement learning with augmented data . Advances in neural information processing systems , 33 : 19884–19895 , 2020 . Lee , L. , Eysenbach , B. , Parisotto , E. , Xing , E. , Levine , S. , and Salakhutdinov , R. Efficient exploration via state marginal matching . arXiv preprint arXiv:1906.05274 , 2019 . Liu , H. and Abbeel , P. Behavior from the void : Unsuper- vised active pre-training . Advances in Neural Information Processing Systems , 34:18459–18473 , 2021 . Mnih , V. , Kavukcuoglu , K. , Silver , D. , Graves , A. , Antonoglou , I. , Wierstra , D. , and Riedmiller , M. Playing atari with deep reinforcement learning . arXiv preprint arXiv:1312.5602 , 2013 . Mnih , V. , Badia , A. P. , Mirza , M. , Graves , A. , Lillicrap , T. , Harley , T. , Silver , D. , and Kavukcuoglu , K. Asyn- chronous methods for deep reinforcement learning . In International conference on machine learning , pp . 1928– 1937 . PMLR , 2016 . Okada , M. , Kosaka , N. , and Taniguchi , T. Planet of the bayesians : Reconsidering and improving deep planning network by incorporating bayesian inference . In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems ( IROS ) , pp . 5611–5618 . IEEE , 2020 . Parisi , S. , Dean , V. , Pathak , D. , and Gupta , A . Interesting object , curious agent : Learning task-agnostic exploration . Advances in Neural Information Processing Systems , 34 , 2021 . Pathak , D. , Agrawal , P. , Efros , A . A. , and Darrell , T. Curiosity-driven exploration by self-supervised predic- tion . In International conference on machine learning , pp . 2778–2787 . PMLR , 2017 . Pritzel , A. , Uria , B. , Srinivasan , S. , Badia , A. P. , Vinyals , O. , Hassabis , D. , Wierstra , D. , and Blundell , C. Neural episodic control . In International Conference on Machine Learning , pp . 2827–2836 . PMLR , 2017 . Raileanu , R. and Rockt¨aschel , T. Ride : Rewarding impact- driven exploration for procedurally-generated environ- ments . arXiv preprint arXiv:2002.12292 , 2020 . Riedmiller , M. , Hafner , R. , Lampe , T. , Neunert , M. , De- grave , J. , Wiele , T. , Mnih , V. , Heess , N. , and Springen- berg , J. T. Learning by playing solving sparse reward tasks from scratch . In International conference on ma- chine learning , pp . 4344–4353 . PMLR , 2018 . Savinov , N. , Raichuk , A. , Marinier , R. , Vincent , D. , Polle- feys , M. , Lillicrap , T. , and Gelly , S. Episodic curiosity through reachability . arXiv preprint arXiv:1810.02274 , 2018 . Schulman , J. , Wolski , F. , Dhariwal , P. , Radford , A. , and Klimov , O. Proximal policy optimization algorithms . arXiv preprint arXiv:1707.06347 , 2017 . Sekar , R. , Rybkin , O. , Daniilidis , K. , Abbeel , P. , Hafner , D. , and Pathak , D. Planning to explore via self-supervised world models . In International Conference on Machine Learning , pp . 8583–8592 . PMLR , 2020 . Seo , Y. , Chen , L. , Shin , J. , Lee , H. , Abbeel , P. , and Lee , K. State entropy maximization with random encoders for efficient exploration . In Meila , M. and Zhang , T . ( eds . ) , Proceedings of the 38th International Conference on Machine Learning , volume 139 of Proceedings of Machine Learning Research , pp . 9443–9454 . PMLR , 18– 24 Jul 2021 . URL https : //proceedings.mlr . press/v139/seo21a.html . Stadie , B. C. , Levine , S. , and Abbeel , P. Incentivizing ex- ploration in reinforcement learning with deep predictive models . arXiv preprint arXiv:1507.00814 , 2015 . Strehl , A. L. and Littman , M. L. An analysis of model- based interval estimation for markov decision processes . Journal of Computer and System Sciences , 74 ( 8 ) :1309– 1331 , 2008 . Tang , H. , Houthooft , R. , Foote , D. , Stooke , A. , Xi Chen , O. , Duan , Y. , Schulman , J. , DeTurck , F. , and Abbeel , P. # exploration : A study of count-based exploration for deep reinforcement learning . Advances in neural information processing systems , 30 , 2017 . Tunyasuvunakool , S. , Muldal , A. , Doron , Y. , Liu , S. , Bohez , S. , Merel , J. , Erez , T. , Lillicrap , T. , Heess , N. , and Tassa , Y. dm control : Software and tasks for continuous control . Software Impacts , 6:100022 , 2020 . ISSN 2665-9638. https : . doi : https : //www.sciencedirect.com/ URL . 10 Go Beyond Imagination : Maximizing Episodic Reachability with World Models Wang , T. , Bao , X. , Clavera , I. , Hoang , J. , Wen , Y. , Lan- glois , E. , Zhang , S. , Zhang , G. , Abbeel , P. , and Ba , J. Benchmarking model-based reinforcement learning . arXiv preprint arXiv:1907.02057 , 2019 . Yarats , D. , Fergus , R. , Lazaric , A. , and Pinto , L. Reinforce- ment learning with prototypical representations . In Inter- national Conference on Machine Learning , pp . 11920– 11931 . PMLR , 2021a . Yarats , D. , Zhang , A. , Kostrikov , I. , Amos , B. , Pineau , J. , and Fergus , R. Improving sample efficiency in model- free reinforcement learning from images . In Proceedings of the AAAI Conference on Artificial Intelligence , vol- ume 35 , pp . 10674–10681 , 2021b . Zha , D. , Ma , W. , Yuan , L. , Hu , X. , and Liu , J . Rank the episodes : A simple approach for exploration in procedurally-generated environments . arXiv preprint arXiv:2101.08152 , 2021 . Zhang , T. , Xu , H. , Wang , X. , Wu , Y. , Keutzer , K. , Gonza- lez , J. E. , and Tian , Y. Noveld : A simple yet effective exploration criterion . Advances in Neural Information Processing Systems , 34 , 2021 . 11 Go Beyond Imagination : Maximizing Episodic Reachability with World Models A . Implementation Details A.1 . Experiments on Minigrid Baselines Implementations of GoBI , NovelD ( Zhang et al. , 2021 ) , RIDE ( Raileanu & Rockt¨aschel , 2020 ) , RND ( Burda et al. , 2018 ) , and EC ( Savinov et al. , 2018 ) are built on the official codebase of NovelD . For fair compar- isons , only the intrinsic reward rint differs among the meth- ods and they all use the same base algorithm IMPALA ( Es- peholt et al. , 2018 ) . At the same time , all the experiments are run with the same compute resource with Nvidia TI- TAN X GPU and 40 CPUs . For NovelD , we rerun their official code to get the results of Minigrid MultiRoom and KeyCorridor . For the experiments on ObstructedMaze , we did not find the proper hyper-parameters to fully reproduce their results . Therefore , we directly take the results reported in their paper . For RIDE and RND , we run the code in the official codebase of NovelD . For EC ( Savinov et al. , 2018 ) , their original paper does not include experiments on Minigrid environments . Therefore , we implement our own version and tune the hyper-parameters with grid search . The intrinsic reward functions of GoBI and the baselines are listed below : • GoBI : ( mt+1 − mt ) / ( cid:112 ) N ( ot+1 ) , where mt is the size of the episodic buffer M and N ( ot+1 ) is the lifelong count of the observation ot+1 starting from the begin- ning of training . • RND : ∥ϕ ( ot+1 ) − ˆϕ ( ot+1 ) ∥2 , which is the difference between a fixed random network ˆϕ and a trained state embedding network ϕ . Here , ϕ is trained to minimize the same error . • NovelD : max [ novelty ( ot+1 ) − α · novelty ( ot ) , 0 ] ∗ 1 { N epi ( st+1 = 1 ) } . They apply RND to measure the novelty of ot , i.e. , novelty ( ot ) = ∥ϕ ( ot ) − ˆϕ ( ot ) ∥2 . N epi ( st+1 = 1 ) checks if the agent visits state st+1 for the first time in an episode . Notice that they use the full environment information , i.e . everything in the grid world instead of only the 7×7 partially-observable view . Therefore N epi counts st+1 instead of ot+1 . • RIDE : ∥ϕ ( ot ) − ϕ ( ot+1 ) ∥2/ ( cid:112 ) N epi ( st+1 ) , where ϕ is the state embedding network trained to minimize the prediction error of an inverse and a forward dynamics . N epi indicates the episodic counts . Same as NovelD , in RIDE , they also use the state information st+1 for episodic count . Policy and Value Function Training For fair compar- isons , the policy network and value function network are the same for all approaches . The input observations of di- mension 7 × 7 × 3 are put into a shared feature extraction network , which includes three convolutional layers of ker- nel size= 3 × 3 , padding= 1 , channel=32 , 128 , 512 , and stride= 1 , 2 , 2 respectively with ELU activation . The fea- tures are then flattened and put through 2 linear layers with 1024 units and ReLU activation , and an LSTM layer with 1024 units . This shared feature is passed separately to 2 fully-connected layers with 1024 units to output action dis- tribution and value estimation . Dynamics model For our implementation of the dynamics model , our input is the panorama of the current step . To get the panorama , we let the agent rotate for 3 times and con- catenate the 4 observations to get inputs of size 28 × 7 × 3 . It is then passed to a feature extraction module that has the same structure as our policy and value function networks , except that the input to the first linear layer is 4 × 1024 . We then concatenate it with actions and put it through a de- coder with 2 linear layers of sizes 256 and 512 , and reshape back to 7 × 7 × 3 to get a predicted observation . We pre- train the dynamics model using 1e5 ( panot , at , ot+1 ) pairs collected by a random policy . RIDE also requires training dynamics models for the state embedding network ϕ . The input of their dynamics model is the state embedding and action . The forward model contains two fully-connected layers with 256 and 128 units activated by ReLU . The in- verse dynamics model contains two fully-connected layers with 256 units and a ReLU activation function . Its input is the state embeddings of two consecutive steps . Hash Functions We directly apply the default Python hashing function to hash the 7 × 7 × 3 observations and predicted future observations before adding them to the episodic buffer . State embedding NovelD , RIDE , and RND all require training a state embedding network ϕ . The input is the observation in MiniGrid with dimension 7×7×3 . It contains three convolutional layers with kernel size= 3 × 3 , padding = 1 , stride = 1 , 2 , 2 , number of channels = 32 , 128 , 512 respectively . The activation function is ELU . Following the convolutional layers are two linear layers of 2048 and 1024 units with ReLU activation . • EC : β − C ( M , ot+1 ) , where C ( M , ot+1 ) is the 90-th percentile similarity scores between ot+1 and all the observations in the episodic buffer M. The similar- ity scores are calculated using a pre-trained episodic curiosity module . β is a hyper-parameter . Visitation Count For GoBI , N ( o ) stores the flattened 7 × 7 × 3 observations of each step . And for NovelD and RIDE , they count the full states at episodic level , whose shape varies from environment to environment . For example , the shape is 25 × 25 × 3 for MultiRoom environments . 12 Go Beyond Imagination : Maximizing Episodic Reachability with World Models Hyper-parameters Table 1 shows the values of hyper- parameters shared across different methods . Parameter name Batch Size Optimizer Learning Rate LSTM Steps Discount Factor γ Weight of Policy Entropy Loss Weight of Value Function Loss Value 32 RMSProp 0.0001 100 0.99 0.0005 0.5 Table 1 . Hyper-parameters for experiments on Minigrid . These hyper-parameters are shared across all the methods For all of our experiments using GoBI on Minigrid , we set the intrinsic reward coefficient λ = 0.01 and k = 1 , which means only forwarding the dynamics model by 1 step . At the same time , as the action space is small and discrete , instead of randomly sampling some actions , we directly predict the future observations using all 7 possible actions . We list the hyper-parameter choices of intrinsic decay factor ρ in Table 2 . The value of ρ is chosen to make the intrinsic reward large at the beginning of training and near-zero at the end of the training . Parameters Forward Step k Intrinsic Decay ρ ˆfϕ Optimizer ˆfϕ Learning Rate Value 1 6e−7 for MR-N7S8 ; 8e−7 for MR-N12S10 , MR-N6 ; 1.5e−6 for KC-S3R3 ; 5e−7 for KC-S4R3 , KC-S5R3 3e−7 for KC-S6R3 , OM-2Dlh 2e−7 for OM-1Q , OM-2Dlhb , OM-2Q 5e−8 for OM-Full Adam 5e−4 Table 2 . The hyper-parameters of GoBI for experiments on Mini- grid . For NovelD , we set λ = 0.05 for all the environments as is suggested in their official codebase . For RIDE , we use λ = 0.1 on KeyCorridor-S3R3 and λ = 0.5 on all other environments . For RND , we set λ = 0.1 on all the environments . For EC , we make λ = 0.01 so that the initial average intrinsic reward of EC is similar to ours . experiments apply the same base reinforcement learning algorithm RAD ( Laskin et al. , 2020 ) . For RE3 , we rerun their official code to get the results on all four environments . For ICM and RND , we follow the implementation details listed in RE3 to implement them to be compatible with DeepMind Control tasks . For a fair comparison , only the intrinsic reward design differs among the methods . The in- trinsic reward functions of GoBI and the baselines are listed below : • GoBI : ( mt+1 −mt ) ×log ( ||yi −yk−N N ||2 +1 ) , where mt is the size of the episodic buffer M. The latter part is the RE3 intrinsic reward which we introduce below . i i • RE3 : log ( ||yi − yk−N N ||2 + 1 ) , where yi = fθ ( si ) is a fixed representation outputs from a randomly initial- ized encoder and yk−N N is a set of k-nearest neighbors of yi among all the collected y ’ s from the beginning of training . i • ICM : η 2 || ˆϕ ( ot+1 ) − ϕ ( ot+1 ) ||2 2 , where η is a scaling factor . ϕ ( o ) is a feature vector that is jointly optimized with a forward prediction model and an inverse dynam- ics model and ˆϕ ( o ) predicts the feature encoding at time step t + 1 . • RND : ∥ϕ ( ot+1 ) − ˆϕ ( ot+1 ) ∥2 , which is the difference between a fixed random network ˆϕ and a trained state embedding network ϕ . Here , ϕ is trained to minimize ∥ϕ ( ot+1 ) − ˆϕ ( ot+1 ) ∥2 . Architecture The observation size of all the environments is 84×84×3 . The encoder architecture follows the same one as in ( Yarats et al. , 2021b ) , which contains 4 convolutional layers of 3 × 3 kernels , channel=32 , and stride=2 , 1 , 1 , 1 with ReLU activations . The output is then passed to a fully- connected layer and normalized by LayerNorm . Dynamics Model For the forward dynamics model that we use to generate future predictions , we apply the same world model structure as in Dreamer ( Hafner et al. , 2019 ) . The input size of Dreamer is 64 × 64 × 3 . We down-sample the input observations to 64 × 64 instead of tuning the world model layers . We train the dynamics model together with the RL policy in an online manner instead of pre-train it because it takes many episodes for the predictions to be visually reasonable . Therefore it does not add extra effort to determine how many data should we collect to pre-train the dynamics model . A.2 . Experiments on Deepmind Control Suites Baselines Implementations of GoBI , RE3 ( Seo et al. , 2021 ) , ICM ( Pathak et al. , 2017 ) , and RND ( Burda et al. , 2018 ) are built on the official codebase of RE3 . All the Image hashing As the observations are images in high- dimensional space and the predictions are usually not accu- rate , we hash the images to lower dimension to avoid taking too much space and to collapse similar observations and 13 Go Beyond Imagination : Maximizing Episodic Reachability with World Models predictions . Following ( Tang et al. , 2017 ) , we use the sim- ple SimHash function to map the images to 50 bits . More specifically , we project the flattened images to a random initialized vector and use the signs of output vector values as the hash code . Hyper-parameters Table 3 shows the values of hyper- parameters shared across different methods . decreases to very small . Therefore sometimes it is hard for the agent to learn anything useful , resulting in unsatisfac- tory performance . Meanwhile , if ρ is too small , for example when ρ = 5e − 7 , the intrinsic reward will be too large at later stage of training and make the agent focus less on the extrinsic reward . Therefore the policy may converge slower . Parameter name Augmentation Observation Size Action Repeat Replay Buffer Size Initial Random Exploration Steps Frame Stack Actor Learning Rate Critic Learning Rate Batch Size # Nearest Neighbors Critic Target Update Freq Value Crop ( 84 , 84 ) 2 100000 1000 3 0.0002 0.0002 512 3 2 Table 3 . Hyper-parameters for experiments on DeepMind Control Suites . These hyper-parameters are shared across all the methods For the intrinsic reward coefficients , we follow the best choices reported in RE3 . For GoBI , we apply the same intrinsic reward coefficient λ and intrinsic reward decay ρ as the ones in RE3 for fair comparison . The intrinsic rewards that are specific to our method is shown in Table 4 . For the number of random actions n , we perform hyper-parameter search over { 3 , 5 , 10 , 20 } and find that n = 5 perform well across all the tasks . For the number of forward steps k , we perform hyper-parameter search over { 1 , 2 , 3 , 5 } and report the ones with the best results . Parameter name # Forward Step k # Random Actions n Value 3 for pendulum-swingup ; 1 for others 5 Table 4 . Hyper-parameters for experiments on DeepMind Control Suites . These hyper-parameters are specific to our method . B. Hyper-Parameters B.1 . Intrinsic reward decay Figure 10 . Training performance of GoBI on Minigrid Multiroom- N12-S10 with different intrinsic reward decay ρ . Figure 11 . Training performance of GoBI on Minigrid Multiroom- N7-S8 with different n randomly sampled actions per step . B.2 . Number of randomly sampled actions In the Minigrid experiments reported in Section 3 , we do not randomly sample actions because Minigrid has a small discrete action space with only 7 actions . Therefore we directly predict future observations of all 7 actions . How- ever , we also report the results with n = 3 , 5 , 10 , 15 random actions in Figure 11 . To summarize , n = 5 , 10 , 15 all have similar performance on Minigrid , while a larger n makes the wallclock training time longer . n = 3 is slightly slower at the early stage , but still outperforms the previous state- of-the-arts . Overall , n = 5 would be a good choice for the Minigrid environments . In Figure 10 , we show the training performance with differ- ent intrinsic reward decay ρ . The choice of ρ is to balance between the relative importance of the extrinsic and intrinsic reward . If ρ is too large , for example when ρ = 1e − 6 , before the agent finds any goal , the intrinsic reward already C. Exploration Behaviour Comparison between GoBI and EC In Figure 12 , we visualize the policy visitation heatmaps of GoBI and EC ( Savinov et al. , 2018 ) on a MultiRoom 14 n r u t e R e g a r e v A 0.6 0.4 0.2 0.0 0.0 MultiRoom-N12-S10 0.3 0.2 0.6 environment steps ( 1e7 ) 0.5 = 1e-6 = 9e-7 = 8e-7 = 7e-7 0.8 = 6e-7 = 5e-7 MultiRoom-N7-S8 n r u t e R e g a r e v A 0.6 0.4 0.2 0.0 0.0 0.2 0.3 0.5 0.6 0.8 1e7 n=3 n=5 n=10 n=15 Go Beyond Imagination : Maximizing Episodic Reachability with World Models Figure 12 . Heatmaps of example trajectories at different training steps in Minigrid-Multiroom-N7-S8 environment . Algorithm Wallclock Time ( hours ) NovelD GoBI ( ours ) 5.46 ( ±0.058 ) 10.65 ( ±0.082 ) Table 5 . Wallclock training time comparison in hours between NovelD and GoBI . environment from Minigrid . Although EC fails to learn an optimal policy , we can still capture its preference from the heatmaps . An agent trained with EC prefers going to the corners of the room , which generally have lower similarity scores than the states in the middle of the room . However , if the similarity scores are not low enough for the states to be added to the episodic buffer , it will continue staying at the states to maximize its intrinsic reward . We tried to tune the similarity score threshold using grid search but still have not find a good hyper-parameter choice for it because the similarity score at different corners does not share a consistent value . Unlike EC , we can see from the figure that GoBI chooses not to visit the border of the room early on in training , as the information on the border are easily predictable from the information in the middle of the room . Figure 14 . An illustrative example of why R2 does not work well to encourage efficient exploration . In this example , our goal is to include all the states into the episodic buffer quickly . GoBI can move directly to the center in one step for maximum intrinsic reward , while R2 may choose to take extra steps for exploration since it mainly focuses on whether the episodic buffer expands or not . Figure 13 . Training performance comparison on MultiRoom-N7- S8 environment among 1 ) use a fixed pre-trained dynamics model , 2 ) use a pre-trained dynamics model , and fine-tune it online , 3 ) no pre-training , directly train the dynamics model together with policy training . D. Wallclock Training Time Table 5 shows the wallclock time needed to train NovelD and our method for 10M Minigrid environment steps . GoBI requires about 2x the wallclock time needed to train NovelD for the same number of environment steps . E. Dynamics Training In the experiment section 3 , we report the results of apply- ing a pre-trained forward dynamics for GoBI on Minigrid . However , the forward dynamics model can also be trained together with policy training . In Figure 13 , we report the results of an ablation study on a Minigrid environment of 3 settings : 1 ) use a pre-trained dynamics model , and keep it fixed when training the policy , 2 ) pre-train a dynamics model , and fine-tune it when training the policy , 3 ) no pre- training , directly train the dynamics model in an online manner . In summary , all 3 versions work similarly , but due to the fact that training the dynamics model online will add 15 GoBI ( Ours ) Training Environment when Episode = 2 Goal Agent Minigrid-MultiRoom-N7S8-v0 Episodic Curiosity ( EC ) s t n u o C d e t i s V i 2.3M 2.1M 4.5M 4.0M 8.9M Training Steps 5.9M 8.0M Unseen Seen MultiRoom-N7-S8 n r u t e R e g a r e v A 0.6 0.4 0.2 0.0 0.0 0.2 0.3 0.5 0.6 0.8 1e7 pre_train+fine_tune no_pre_train no_fine_tune Model t = 0 t = 1 t = 2 t = 3 R2 GoBI ( Ours ) s0 s0 s2 s3 s2 s0 s1 s0 s1 s0 s1 s1 s0 st Visited State Reachable State Non-reachable State Trajectory ( Directed via Temporal Order ) Observed Transition Path ( Bidirectional ) Unreachable Transition Path ( Bidirectional ) Go Beyond Imagination : Maximizing Episodic Reachability with World Models extra wall clock training time , we use option 1 in our main experiments . F. Ablation Study Illustration In this section , we provide an illustrative example of why only considering whether new states are added to the episodic buffer or not , i.e. , R2 in Section 3.3 , works way worse than our method . The example is shown in Figure 14 . If these 9 states are only a small part of the environment , we want a policy that explore this part as quickly as possible - mark all the states as reachable as quickly as possible . How- ever , in order to maximize its step-wise intrinsic reward , an agent trained with R2 will go along the border to only add a few new states to the episodic buffer at a time , which wastes many unnecessary steps so is not beneficial for exploration . 16","['go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'run', 'honglak', 'g', 'u', 'l', 'c', 'r', 'abstract', 'efficient', 'exploration', 'challenging', 'topic', 'rein', 'forcement', 'learning', 'especially', 'sparse', 'reward', 'task', 'deal', 'reward', 'sparsity', 'people', 'commonly', 'apply', 'intrinsic', 'reward', 'motivate', 'agent', 'explore', 'state', 'space', 'efficiently', 'paper', 'introduce', 'new', 'intrinsic', 'reward', 'design', 'call', 'gobi', 'go', 'imagination', 'combine', 'traditional', 'lifelong', 'novelty', 'motivation', 'episodic', 'intrinsic', 'reward', 'design', 'maximize', 'stepwise', 'reachability', 'expansion', 'specifically', 'apply', 'learn', 'world', 'model', 'generate', 'predict', 'future', 'state', 'random', 'action', 'state', 'unique', 'prediction', 'episodic', 'memory', 'sign', 'high', 'intrinsic', 'reward', 'method', 'greatly', 'outperform', 'previous', 'stateoftheart', 'method', 'challenging', 'minigrid', 'navigation', 'task', 'improve', 'sample', 'efficiency', 'loco', 'motion', 'task', 'deepmind', 'control', 'introduction', 'efficient', 'exploration', 'state', 'space', 'fundamental', 'chal', 'lenge', 'reinforcement', 'learning', 'especially', 'environment', 'reward', 'sparse', 'schulman', 'absent', 'abbeel', 'parisi', 'reward', 'sparsity', 'make', 'algorithm', 'easy', 'fail', 'lack', 'useful', 'signal', 'policy', 'update', 'riedmiller', 'florensa', 'com', 'mon', 'approach', 'exploration', 'introduce', 'selfmotivate', 'intrinsic', 'reward', 'state', 'visitation', 'count', 'strehl', 'littman', 'kolter', 'prediction', 'ror', 'stadie', 'pathak', 'intrinsic', 'reward', 'design', 'measure', 'life', 'long', 'state', 'novelty', 'prioritize', 'visit', 'state', 'less', 'ai', 'correspon', 'yao', 'violetfy', 'run', 'peng', 'dence', 'eecsumichedu', 'honglak', 'proceeding', 'th', 'international', 'conference', 'machine', 'learn', 'pmlr', 'copyright', 'author', 'visit', 'start', 'beginning', 'training', 'method', 'achieve', 'great', 'improvement', 'hardexploration', 'task', 'generally', 'work', 'well', 'single', 'ton', 'environment', 'training', 'evaluation', 'environ', 'ment', 'however', 'poor', 'generalization', 'performance', 'reinforcement', 'learning', 'unseen', 'environ', 'ment', 'nowadays', 'researcher', 'pay', 'attention', 'procedurallygenerate', 'environ', 'ment', 'cobbe', 'fletberliac', 'nature', 'task', 'remain', 'environ', 'ment', 'randomly', 'construct', 'new', 'episode', 'example', 'mazelike', 'environment', 'different', 'maze', 'structure', 'make', 'rare', 'agent', 'encounter', 'observation', 'different', 'episode', 'therefore', 'lifelong', 'novelty', 'intrinsic', 'motivation', 'usually', 'fail', 'hard', 'procedurallygenerate', 'environment', 'kind', 'raileanu', 'zha', 'et', 'agent', 'trap', 'newlygenerate', 'state', 'inspire', 'human', 'frequent', 'use', 'shortterm', 'memory', 'dersen', 'eichenbaum', 'avoid', 'repeatedly', 'visit', 'space', 'recent', 'work', 'propose', 'derive', 'intrin', 'sic', 'reward', 'episodic', 'level', 'badia', 'raileanu', 'zha', 'et', 'episodic', 'intrinsic', 'reward', 'give', 'bonus', 'large', 'episodiclevel', 'state', 'space', 'visitation', 'coverage', 'therefore', 'encourage', 'visit', 'many', 'state', 'possible', 'episode', 'however', 'visit', 'state', 'necessarily', 'mean', 'efficient', 'episodiclevel', 'exploration', 'notice', 'state', 'visitation', 'unnecessary', 'avoid', 'predictable', 'episodic', 'ory', 'example', 'navigate', 'house', 'find', 'fridge', 'open', 'door', 'find', 'empty', 'room', 'need', 'go', 'anymore', 'easily', 'predict', 'state', 'room', 'intuitively', 'speak', 'move', 'around', 'empty', 'room', 'inspiration', 'propose', 'design', 'episodic', 'trinsic', 'reward', 'maximize', 'number', 'visit', 'state', 'episode', 'also', 'consider', 'state', 'visit', 'predict', 'episodic', 'memory', 'precisely', 'maintain', 'episodic', 'buffer', 'store', 'visit', 'state', 'well', 'state', 'reachable', 'visit', 'state', 'time', 'step', 'get', 'reachable', 'state', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'figure', 'illustration', 'gobi', 'work', 'minigrid', 'environment', 'upperleft', 'corner', 'red', 'triangle', 'indicate', 'position', 'orientation', 'agent', '×', 'partiallyobservable', 'view', 'highlight', 'pretraine', 'stage', 'collect', 'datum', 'use', 'random', 'policy', 'train', 'forward', 'dynamic', 'model', 'panot', 'ot1', 'panot', 'denote', 'panoramic', 'view', 'define', 'section', 'policy', 'training', 'stage', 'apply', 'ˆf', 'predict', 'observation', 'future', 'time', 'step', 'random', 'action', 'step', 'add', 'new', 'one', 'episodic', 'buffer', 'take', 'change', 'size', 'episodic', 'intrinsic', 'reward', 'repi', 'lifelong', 'intrinsic', 'reward', 'countbase', 'intrinsic', 'reward', 'gobi', '∗', 'repi', 'train', 'world', 'model', 'forward', 'dynamic', 'function', 'apply', 'random', 'action', 'learn', 'dynamic', 'model', 'pre', 'dict', 'future', 'state', 'prediction', 'add', 'episodic', 'buffer', 'already', 'use', 'change', 'size', 'episodic', 'buffer', 'episodic', 'intrinsic', 'reward', 'follow', 'many', 'previous', 'work', 'weight', 'episodic', 'trinsic', 'reward', 'lifelong', 'intrinsic', 'reward', 'badia', 'countbase', 'reward', 'newly', 'propose', 'intrinsic', 'reward', 'design', 'gobi', 'go', 'imagination', 'agent', 'expect', 'explore', 'state', 'space', 'training', 'discover', 'extrinsic', 'reward', 'learn', 'act', 'efficient', 'manner', 'single', 'episode', 'avoid', 'trap', 'seemingly', 'novel', 'state', 'contribution', 'work', 'highlight', 'low', 'propose', 'novel', 'way', 'combine', 'world', 'model', 'episodic', 'memory', 'formulate', 'effective', 'episodic', 'intrinsic', 'reward', 'design', 'procedurally', 'generate', 'minigrid', 'environment', 'gobi', 'greatly', 'improve', 'training', 'sample', 'efficiency', 'comparison', 'prior', 'stateoftheart', 'intrinsic', 'reward', 'function', 'gobi', 'extend', 'well', 'deepmind', 'control', 'suite', 'tunyasuvunakool', 'highdimensional', 'visual', 'input', 'show', 'promise', 'result', 'sparsereward', 'continuous', 'control', 'task', 'analyze', 'design', 'gobi', 'present', 'extensive', 'ablation', 'show', 'contribu', 'tion', 'component', 'method', 'consider', 'reinforcement', 'learning', 'problem', 'frame', 'markov', 'decision', 'process', 'r', 'denote', 'state', 'space', 'action', 'space', '×', 'state', 'transition', 'function', 'r', '×', '×', 'r', 'reward', 'function', 'reward', 'discount', 'factor', 'step', 'state', 'environment', 'denote', 'agent', 'generate', 'action', 'interact', 'environment', 'environment', 'transit', 'next', 'underlying', 'state', 'st1', 'apart', 'new', 'state', 'st1', 'environment', 'also', 'return', 'extrinsic', 'reward', 'rext', 'describe', 'well', 'agent', 'react', 'sparsereward', 'task', 'rext', 'usually', 'work', 'follow', 'previous', 'work', 'train', 'algorithm', 'rext', 'λ∗rint', 'selfmotivated', 'intrinsic', 'reward', 'hyperparameter', 'control', 'relative', 'importance', 'intrinsic', 'extrinsic', 'reward', 'go', 'imagination', 'reachable', 'state', 'episodic', 'buffer', 'intrinsic', 'ward', 'design', 'aim', 'exploit', 'information', 'hide', 'neighbourhood', 'state', 'define', 'state', 'k', 'step', 'reachable', 'agent', 'reach', 'b', 'k', 'time', 'step', 'training', 'process', 'new', 'episode', 'initialize', 'empty', 'episodic', 'memory', 'buffer', 'time', 'step', 'hash', 'well', 'state', 'reachable', 'denote', 'set', 'contain', 'hash', 'environment', '🚶', 'action', 'space', 'leave', 'right', 'forward', 'pickup', 'drop', 'toggle', '⬅', '➡', '🚶', '🤏', '✋', '🛠', '✅', 'encoder', 'decoder', 'policy', 'net', 'r', 'r', 'e', 'r', 'r', 'e', 'episodic', 'memory', 'expansion', '🚶', 'next', 'obs', 'random', 'action', 'n', 'already', 'new', 'state', 'pretrain', 'forward', 'dynamic', 'model', 'stage', 'count', 'episodic', 'reachability', 'maximization', 'stage', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'figure', 'illustration', 'episodic', 'buffer', 'update', 'consider', 'reachable', 'state', 'k', 'time', 'step', 'away', 'agent', 'move', 'episodic', 'buffer', 'shaded', 'green', 'expand', 'new', 'reachable', 'state', 'shade', 'yellow', 'formally', 'indicate', 'set', 'state', 'reachable', 'notice', 'state', 'trajectory', 'also', 'add', 'buffer', 'code', 'reachable', 'state', 'update', 'store', 'hash', 'code', 'instead', 'directly', 'store', 'state', 'alleviate', 'poten', 'tial', 'memory', 'issue', 'buffer', 'illustrate', 'process', 'figure', 'agent', 'reach', 'state', 'add', 'state', 'reachable', 'forward', 'dynamic', 'real', 'environment', 'common', 'access', 'neighbourhood', 'relationship', 'state', 'however', 'learn', 'world', 'model', 'train', 'forward', 'dynamic', 'model', 'st1', 'predict', 'state', 'reachable', 'forward', 'dynamic', 'pretraine', 'use', 'datum', 'collect', 'random', 'policy', 'train', 'online', 'together', 'policy', 'training', 'train', 'policy', 'time', 'step', 'generate', 'k', 'random', 'action', 'use', 'learn', 'dynamic', 'ˆfϕ', 'predict', 'state', 'future', 'step', 'hash', 'current', 'state', 'well', 'ˆsn', 'predict', 'future', 'state', 'add', 'hash', 'code', 'episodic', 'buffer', 'buffer', 'apart', 'alleviate', 'potential', 'memory', 'issue', 'mention', 'last', 'paragraph', 'use', 'hash', 'function', 'also', 'mitigate', 'noise', 'introduce', 'ˆf', 'learn', 'dynamic', 'model', 'prediction', 'reachable', 'state', 'usually', 'perfect', 'however', 'experiment', 'section', 'show', 'even', 'imperfect', 'prediction', 'method', 'improve', 'training', 'sample', 'efficiency', 'lot', 'tk', 'ˆsn', 't1', 'ˆs1', 'episodic', 'novelty', 'aim', 'design', 'episodiclevel', 'elty', 'reward', 'guide', 'agent', 'extend', 'frontier', 'predict', 'reachable', 'space', 'efficiently', 'discover', 'state', 'visit', 'predictable', 'episode', 'specifically', 'denote', 'size', 'episodic', 'buffer', 'time', 'step', 'design', 'reachabilitybased', 'bonus', 'repi', 'encourage', 'agent', 'find', 'unex', 'plored', 'region', 'time', 'step', 'agent', 'expect', 'reach', 'state', 'reachable', 'new', 'state', 'current', 'episode', 'intrinsic', 'reward', 'formulation', 'far', 'weight', 'episodic', 'intrinsic', 'reward', 'lifelong', 'intrinsic', 'reward', 'encourage', 'agent', 'explore', 'region', 'well', 'explore', 'past', 'formally', 'propose', 'intrinsic', 'reward', 'gobi', 'define', '∗', 'denote', 'lifelong', 'intrinsic', 'reward', 'note', 'framework', 'compatible', 'choice', 'lifelong', 'intrinsic', 'reward', 'specifically', 'use', 'simple', 'count', 'base', 'reward', 'cid112', 'st1', 'navigation', 'experiment', 'minigrid', 'environment', 'denote', 'count', 'st1', 'start', 'train', 'ing1', 'experiment', 'deepmind', 'control', 'suite', 'tun', 'yasuvunakool', 'use', 'stateoftheart', 'seo', 'estimate', 'state', 'random', 'encoder', 'intrinsic', 'decay', 'intrinsic', 'reward', 'expect', 'asymptotically', 'consistent', 'influence', 'policy', 'learning', 'later', 'stage', 'training', 'result', 'suboptimal', 'policy', 'guarantee', 'policy', 'learning', 'focus', 'extrinsic', 'reward', 'training', 'proceed', 're3', 'seo', 'author', 'apply', 'exponential', 'decay', 'schedule', 'intrinsic', 'reward', 'decrease', 'time', 'countbase', 'reward', 'theoretically', 'converge', 'enough', 'exploration', 'decrease', 'quite', 'slowly', 'procedurallygenerate', 'environment', 'therefore', 'also', 'apply', 'intrinsic', 'reward', 'decay', 'calculate', 'gobi', 'crease', 'intrinsic', 'reward', 'coefficient', 'training', 'summarize', 'method', 'illustrate', 'training', 'process', 'minigrid', 'navigation', 'task', 'figure', 'environment', 'partially', 'observable', 'eg', 'mini', 'grid', 'agent', 'observe', 'pixel', 'local', 'view', 'environment', 'substitute', 'state', 'observation', 'ot', 'calculate', 'trinsic', 'reward', 'action', 'move', 'episodic', 'buffer', 'nonreachable', 'space', 'new', 'reachable', 'space', 'reachable', 'state', 'visited', 'state', 'reachable', 'state', 'nonreachable', 'state', 'trajectory', 'observe', 'transition', 'path', 'unreachable', 'transition', 'path', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'go', 'imagination', 'input', 'intrinsic', 'reward', 'coefficient', 'λ0', 'forward', 'pre', 'diction', 'step', 'k', 'number', 'random', 'action', 'intrinsic', 'reward', 'decay', 'parameter', 'initialize', 'policy', 'πθ', 'dynamic', 'model', 'replay', 'optional', 'collect', 'episode', 'πθ', 'train', 'ˆfϕ', 'prediction', 'loss', 'episode', 'convergence', 'initialize', 'episodic', 'buffer', 'λ0', '∗', 'execute', 'πθ', 'environment', 'get', 'transition', 'pair', 'st1', 'rext', 'size', '∪', 'hash', 'get', 'high', 'intrinsic', 'reward', 'corresponding', 'similarity', 'score', 'low', 'low', 'enough', 'similarity', 'score', 'add', 'buffer', 'method', 'similar', 'high', 'level', 'different', 'design', 'ex', 'ample', 'agent', 'stand', 'front', 'empty', 'blind', 'alley', 'dead', 'end', 'agent', 'train', 'gobi', 'benefit', 'go', 'deep', 'blind', 'alley', 'predict', 'reachable', 'add', 'episodic', 'buffer', 'already', 'however', 'encourage', 'go', 'end', 'blind', 'alley', 'reach', 'state', 'low', 'similarity', 'score', 'high', 'intrinsic', 'reward', 'even', 'go', 'empty', 'blind', 'alley', 'beneficial', 'exploration', 'waste', 'time', 'use', 'explore', 'part', 'environment', 'c', 'present', 'visitation', 'heatmap', 'poli', 'cie', 'learn', 'find', 'prefer', 'go', 'room', 'corner', 'well', 'match', 'explanation', 'generate', 'random', 'action', '∪', 'hash', 'ˆfϕ', 'tt′', 'ai', 'end', 'size', '∗', '∪', 'st1', 'rext', 'λ', 'rint', 'end', 'update', 'πθ', 'objective', 'update', 'ˆfϕ', 'prediction', 'loss', 'end', 'conceptual', 'advantage', 'gobi', 'prior', 'work', 'previous', 'work', 'include', 'ride', 'raileanu', 'also', 'combine', 'episodic', 'intrinsic', 'reward', 'lifelong', 'novelty', 'however', 'focus', 'episodiclevel', 'state', 'itation', 'example', 'noveld', 'assign', 'nonzero', 'ward', 'state', 'visit', 'first', 'time', 'episode', 'however', 'notice', 'state', 'visitation', 'necessary', 'agent', 'goal', 'exploration', 'gather', 'information', 'state', 'therefore', 'state', 'easily', 'predictable', 'episodic', 'memory', 'visit', 'really', 'help', 'acquire', 'information', 'en', 'vironment', 'figure', 'plot', 'visitation', 'heatmap', 'gobi', 'noveld', 'demonstrate', 'different', 'exploration', 'behaviour', 'method', 'method', 'closely', 'relate', 'work', 'sure', 'episodic', 'curiosity', 'author', 'train', 'reachability', 'network', 'take', 'arbitrary', 'state', 'output', 'similarity', 'score', 'indicate', 'state', 'indicate', 'totally', 'different', 'network', 'train', 'use', 'collect', 'episode', 'mark', 'temporally', 'close', 'state', 'positive', 'example', 'temporally', 'far', 'one', 'negative', 'sample', 'meanwhile', 'also', 'maintain', 'episodic', 'buffer', 'state', 'compare', 'state', 'buffer', 'minigrid', 'deepmind', 'control', 'figure', 'rendering', 'environment', 'use', 'work', 'leave', 'grid', 'world', 'navigation', 'task', 'require', 'object', 'interaction', 'right', 'deepmind', 'control', 'task', 'visual', 'observation', 'experiment', 'section', 'evaluate', 'gobi', 'domain', 'procedurallygenerate', 'minigrid', 'environment', 'chevalier', 'hardexploration', 'task', 'comotion', 'task', 'deepmind', 'control', 'suite', 'vunakool', 'experiment', 'design', 'answer', 'follow', 'research', 'question', 'gobi', 'perform', 'previous', 'stateoftheart', 'intrinsic', 'ward', 'design', 'term', 'trainingtime', 'sample', 'efficiency', 'challenge', 'procedurallygenerate', 'environment', 'gobi', 'successfully', 'extend', 'complex', 'continuous', 'domain', 'highdimensional', 'observation', 'example', 'control', 'task', 'visual', 'observation', 'compo', 'nent', 'intrinsic', 'reward', 'contribute', 'performance', 'influence', 'accuracy', 'learned', 'world', 'model', 'method', 'minigrid', 'navigation', 'task', 'set', 'partiallyobservable', 'procedurally', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'figure', 'visitation', 'heatmap', 'different', 'training', 'stage', 'figure', 'compare', 'policy', 'behaviour', 'gobi', 'noveld', 'dark', 'red', 'color', 'mean', 'plentiful', 'visitation', 'mean', 'agent', 'see', 'space', 'step', 'black', 'mean', 'space', 'discover', 'worth', 'notice', 'early', 'training', 'time', 'step', 'policy', 'already', 'learn', 'go', 'empty', 'room', 'likely', 'state', 'empty', 'room', 'easily', 'predictable', 'contrary', 'even', 'step', 'agent', 'train', 'still', 'go', 'empty', 'room', 'bottomright', 'corner', 'state', 'visitation', 'generate', 'grid', 'world', 'navigation', 'task', 'agent', 'expect', 'interact', 'object', 'key', 'ball', 'door', 'box', 'navigate', 'room', 'find', 'goal', 'randomly', 'place', 'room', 'task', 'provide', 'sparse', 'reward', 'end', 'episode', 'indicate', 'agent', 'successfully', 'find', 'goal', 'many', 'step', 'take', 'reach', 'goal', 'work', 'consider', 'type', 'task', 'include', 'multiroom', 'keycorridor', 'obstructedmaze', 'environment', 'experiment', 'paper', 'show', 'figure', 'upperright', 'environment', 'agent', 'learn', 'open', 'door', 'find', 'key', 'use', 'open', 'locked', 'blue', 'door', 'pick', 'bottomleft', 'fig', 'ure', 'show', 'obstructedmazefull', 'environment', 'similar', 'keycorridor', 'challenging', 'room', 'large', 'door', 'block', 'ball', 'key', 'hide', 'box', 'upperleft', 'bottomright', 'environ', 'ment', 'multiroom', 'environment', 'agent', 'navigate', 'connect', 'room', 'reach', 'goal', 'last', 'room', 'baseline', 'compare', 'stateoftheart', 'intrinsic', 'ward', 'design', 'work', 'well', 'minigrid', 'include', 'ride', 'raileanu', 'fair', 'compari', 'son', 'follow', 'basic', 'network', 'architecture', 'use', 'official', 'codebase', 'change', 'intrinsic', 'reward', 'rint', 'method', 'also', 'compare', 'method', 'similarity', 'highlevel', 'idea', 'method', 'however', 'original', 'paper', 'include', 'experiment', 'minigrid', 'therefore', 'plement', 'version', 'adapt', 'minigrid', 'follow', 'implementation', 'suggestion', 'paper', 'tune', 'hyperparameter', 'novelty', 'threshold', 'grid', 'search', 'dynamic', 'model', 'training', 'experiment', 'min', 'igrid', 'first', 'run', 'random', 'policy', 'step', 'collect', 'datum', 'use', 'train', 'forward', 'dynamic', 'model', 'world', 'model', 'pair', 'collect', '5e4', 'different', 'transition', 'pair', 'experiment', 'observe', 'finetune', 'pretraine', 'dynamic', 'model', 'policy', 'training', 'significant', 'influence', 'performance', 'similar', 'parisi', 'use', '◦', 'panoramic', 'view', 'input', 'predict', 'future', 'observation', 'rotationinvariant', 'representation', 'observed', 'state', 'consider', 'still', 'fair', 'compari', 'son', 'previous', 'stateoftheart', 'noveld', 'ride', 'rely', 'use', 'state', 'information', 'instead', 'observation', 'episodic', 'count', 'calculation', 'limited', 'field', 'view', 'agent', 'forward', 'learned', 'dynamic', 'step', 'predict', 'predict', 'next', 'observation', 'produce', 'discrete', 'action', 'minigrid', 'task', 'include', 'turn', 'leave', 'turn', 'right', 'forward', 'toggle', 'pick', 'drop', 'directly', 'apply', 'default', 'python', 'hash', 'function', 'hash', 'observation', 'predict', 'future', 'observation', 'expect', 'hash', 'function', 'mitigate', 'prediction', 'error', 'minigrid', 'use', 'reduce', 'dimension', 'observation', 'prediction', 'training', 'performance', 'minigrid', 'figure', 'show', 'learn', 'curve', 'gobi', 'stateoftheart', 'explo', 'ration', 'baseline', 'ride', 'challenging', 'minigrid', 'navigation', 'task', 'include', 'multi', 'room', 'keycorridor', 'obstructedmaze', 'curve', 'shift', 'right', 'number', 'random', 'explo', 'ration', 'environment', 'step', 'use', 'train', 'world', 'model', 'environment', 'gobi', 'significantly', 'outperform', 'previous', 'method', 'term', 'sample', 'efficiency', 'gobi', 'episode', 'training', 'environment', 'c', 'e', 'v', 'unlock', 'train', 'step', 'pick', 'unseen', 'see', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'figure', 'training', 'performance', 'gobi', 'baseline', 'minigrid', 'environment', 'show', 'number', 'environment', 'step', 'shift', 'training', 'curve', 'right', 'number', 'environment', 'step', 'use', 'pretrain', 'dynamic', 'model', '1e5', 'time', 'step', 'result', 'average', 'seed', 'stance', 'obstructedmaze2dlhb', 'gobi', 'time', 'sample', 'efficient', 'hard', 'obstructedmazefull', 'environment', 'gobi', 'achieve', 'optimal', 'performance', 'step', 'lastly', 'try', 'tune', 'hyperparameter', 'implementation', 'still', 'learn', 'well', 'minigrid', 'environment', 'qualitative', 'result', 'clearly', 'present', 'exploration', 'havior', 'learn', 'show', 'visitation', 'heatmap', 'gobi', 'noveld', 'keycorridors5r3', 'environment', 'figure', 'method', 'converge', 'mal', 'policy', 'fast', 'exploration', 'behaviour', 'different', 'gobi', 'quickly', 'learn', 'visit', 'easily', 'pre', 'dictable', 'state', 'empty', 'room', 'make', 'efficient', 'explore', 'interesting', 'part', 'environment', 'example', 'room', 'key', 'dynamic', 'model', 'training', 'follow', 'world', 'model', 'structure', 'directly', 'apply', 'encoder', 'transition', 'model', 'observation', 'model', 'predict', 'future', 'observation', 'however', 'compare', 'mini', 'grid', 'require', 'way', 'datum', 'train', 'decent', 'dynamic', 'model', 'deepmind', 'control', 'generate', 'visuallyreasonable', 'prediction', 'therefore', 'different', 'experiment', 'minigrid', 'pretrain', 'dynamic', 'model', 'instead', 'train', 'dynamic', 'model', 'together', 'policy', 'show', 'find', 'number', 'sample', 'random', 'action', 'work', 'well', 'environment', 'number', 'forward', 'prediction', 'step', 'k', 'set', 'pendulum', 'swingup', 'environment', 'hash', 'function', 'find', 'simple', 'simhash', 'suggest', 'work', 'well', 'capture', 'similarity', 'similar', 'observation', 'use', 'simhash', 'hash', 'image', 'observation', 'bit', 'experiment', 'control', 'task', 'far', 'test', 'gobi', 'deepmind', 'control', 'suite', 'set', 'imagebase', 'continuous', 'control', 'task', 'task', 'challenging', 'high', 'dimensional', 'observation', 'stochastic', 'transition', 'notice', 'environment', 'procedurallygenerate', 'experiment', 'section', 'show', 'generality', 'method', 'experimentally', 'show', 'gobi', 'extend', 'well', 'sparsereward', 'task', 'continuous', 'action', 'space', 'highdimensional', 'observation', 'space', 'training', 'performance', 'deepmind', 'control', 'com', 'pare', 'stateoftheart', 'intrinsic', 'motivation', 'mind', 'control', 'task', 'seo', 'apply', 'knear', 'estimator', 'lowdimensional', 'representation', 'space', 'randomly', 'initialize', 'encoder', 'maximize', 'state', 're3', 'also', 'use', 'life', 'long', 'intrinsic', 'reward', 'part', 'rlifelong', 'gobi', 'intrinsic', 'reward', 'baseline', 'consider', 'icm', 'pathak', 'fair', 'com', 'parison', 'experiment', 'use', 'basic', 'multiroomn6', 'multiroomn12s10', 'keycorridors3r3', 'obstructedmaze2q', 'obstructedmazefull', 'r', 'e', 'r', 'e', 'g', 'r', 'e', 'r', 'e', 'r', 'e', 'g', 'r', 'e', 'r', 'e', 'r', 'e', 'g', 'r', 'e', 'ride', 'gobi', '1e7', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'episode', 'multiroom', 'generate', 'room', 'square', 'fix', 'size', 'therefore', 'countbase', 'reward', 'tribute', 'environment', 'multiroom', 'time', 'perform', 'way', 'bad', 'gobi', 'agent', 'train', 'prefer', 'action', 'increase', 'size', 'episodic', 'buffer', 'bit', 'therefore', 'get', 'positive', 'score', 'often', 'provide', 'illustrative', 'example', 'explain', 'work', 'well', 'compare', 'gobi', 'use', 'lifelong', 'intrinsic', 'reward', 'perform', 'bad', 'struggle', 'learn', 'efficiently', 'large', 'multiroom', 'key', 'corridor', 'obstruct', 'maze', 'environment', 'real', 'dynamic', 'learn', 'dynamic', 'learn', 'ic', 'model', 'generally', 'perfect', 'especially', 'partially', 'observable', 'environment', 'minigrid', 'many', 'case', 'prediction', 'never', 'accurate', 'example', 'agent', 'first', 'open', 'door', 'new', 'room', 'usually', 'accurately', 'predict', 'door', 'figure', 'show', 'training', 'curve', 'use', 'real', 'dynamic', 'model', 'learn', 'dynamic', 'model', 'surprisingly', 'intrinsic', 'reward', 'function', 'use', 'real', 'dynamic', 'converge', 'fast', 'nearoptimal', 'policy', 'however', 'even', 'imperfect', 'dynamic', 'model', 'method', 'still', 'greatly', 'surpass', 'previous', 'stateoftheart', 'figure', 'comparison', 'use', 'real', 'dynamic', 'model', 'environment', 'use', 'learn', 'minigrid', 'environment', 'multiroom', 'use', 'real', 'dynamic', 'model', 'derive', 'intrinsic', 'reward', 'make', 'policy', 'converge', 'fast', 'espe', 'cially', 'multistep', 'prediction', 'figure', 'show', 'learning', 'formance', 'gobi', 'minigrid', 'vary', 'choice', 'number', 'future', 'step', 'prediction', 'dynamic', 'model', 'panot1', 'instead', 'hash', 'store', 'observation', 'future', 'time', 'step', 'real', 'forward', 'dynamic', 'model', 'large', 'generally', 'accelerate', 'exploration', 'prioritize', 'action', 'lead', 'state', 'reachable', 'state', 'long', 'run', 'however', 'limited', 'field', 'view', 'agent', 'model', 'inaccuracy', 'case', 'use', 'learned', 'model', 'forward', 'step', 'still', 'fast', 'step', 'step', 'really', 'make', 'exploration', 'fast', 'figure', 'training', 'curve', 'gobi', 'baseline', 'deepmind', 'control', 'suite', 'curve', 'average', 'seed', 'result', 'show', 'figure', 'additional', 'episodiclevel', 'intrinsic', 'reward', 'term', 'prove', 'sample', 'efficiency', 'lot', 'compare', 'use', 'lifelong', 'intrinsic', 'reward', 'especially', 'hopper', 'walker', 'run', 'sparse', 'ablation', 'study', 'gobi', 'variation', 'section', 'analyze', 'component', 'intrinsic', 'reward', 'contribute', 'final', 'performance', 'ablate', 'component', 'gobi', 'run', 'experiment', 'minigrid', 'environment', 'follow', 'r1', 'episodic', 'intrinsic', 'reward', 'indicator', 'new', 'state', 'add', 'episodic', 'buffer', 'ot1', 'lifelong', 'intrinsic', 'reward', 'cid112', 'ot1', 'figure', 'training', 'performance', 'comparison', 'gobi', 'minigrid', 'environment', 'training', 'performance', 'gobi', 'well', 'r1', 'show', 'figure', 'r1', 'work', 'multiroom', 'suffer', 'obstruct', 'maze', 'large', 'keycorridor', 'environ', 'ment', 'underlie', 'reason', 'key', 'corridor', 'obstruct', 'maze', 'room', 'structure', 'change', 'less', 'r', 'u', 'e', 'e', 'p', 'e', 'r', 'e', 'e', 'p', 'e', 'pendulum', 'swingup', 'cartpole', 'sparse', 'hopper', 'run', 'sparse', 'radicm', 'multiroomn12s10', 'e', 'r', 'e', 'g', 'r', 'e', 'r1', '1e7', 'keycorridors3r3', 'e', 'r', 'e', 'real', 'dynamic', 'learn', 'dynamic', '1e7', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'count', 'episodic', 'state', 'visitation', 'claim', 'apart', 'visit', 'state', 'also', 'consider', 'state', 'predict', 'episodic', 'memory', 'learn', 'world', 'model', 'forward', 'dynamic', 'learn', 'dynamic', 'function', 'set', 'observe', 'datum', 'widelystudied', 'topic', 'reinforcement', 'learning', 'especially', 'rapid', 'growth', 'modelbase', 'reinforcement', 'learn', 'exist', 'work', 'show', 'agent', 'world', 'model', 'implicitly', 'forward', 'model', 'predict', 'future', 'state', 'schmidhuber', 'freeman', 'recently', 'people', 'propose', 'latent', 'dynamic', 'model', 'work', 'well', 'highdimensional', 'input', 'latent', 'dynamic', 'model', 'encode', 'image', 'vation', 'predict', 'future', 'state', 'latent', 'space', 'schmidhuber', 'hafner', 'output', 'realistic', 'future', 'observation', 'visually', 'complex', 'domain', 'include', 'deepmind', 'control', 'suite', 'tunyasuvunakool', 'vizdoom', 'atari', 'game', 'deepmind', 'lab', 'beattie', 'learn', 'dynamic', 'model', 'use', 'guide', 'exploration', 'prediction', 'error', 'stadie', 'pathak', 'surprise', 'sastry', 'information', 'gain', 'variance', 'model', 'ensemble', 'mean', 'method', 'differ', 'previous', 'method', 'directly', 'ate', 'hash', 'predict', 'state', 'add', 'episodic', 'reachable', 'state', 'buffer', 'advanced', 'world', 'model', 'structure', 'method', 'extend', 'diverse', 'domain', 'complex', 'observation', 'discussion', 'future', 'work', 'paper', 'show', 'effective', 'way', 'combine', 'learn', 'world', 'model', 'episodic', 'memory', 'intrinsically', 'guide', 'efficient', 'exploration', 'method', 'achieve', 'stateoftheart', 'mance', 'procedurallygenerate', 'hard', 'exploration', 'task', 'also', 'work', 'well', 'singleton', 'continuous', 'control', 'main', 'however', 'still', 'certain', 'limitation', 'first', 'dynamic', 'model', 'use', 'minigrid', 'experiment', 'deterministic', 'make', 'possible', 'generate', 'less', 'accu', 'rate', 'prediction', 'make', 'performance', 'method', 'bad', 'use', 'real', 'dynamic', 'possible', 'way', 'make', 'improvement', 'make', 'prediction', 'model', 'erative', 'sample', 'possible', 'future', 'state', 'secondly', 'control', 'task', 'complex', 'visual', 'input', 'hash', 'age', 'static', 'hash', 'make', 'discrete', 'hash', 'code', 'however', 'well', 'capture', 'semantic', 'similarity', 'image', 'observation', 'beneficial', 'learn', 'hash', 'function', 'example', 'use', 'autoencoder', 'learn', 'meaningful', 'hash', 'code', 'leave', 'investigation', 'future', 'work', 'figure', 'make', 'forward', 'prediction', 'different', 'number', 'future', 'step', 'use', 'real', 'dynamic', 'learn', 'dy', 'namic', 'model', 'plot', 'show', 'training', 'performance', 'relate', 'work', 'exploration', 'reinforcement', 'learning', 'efficient', 'exploration', 'reinforcement', 'learning', 'especially', 'sparsereward', 'reinforcement', 'learning', 'problem', 'chal', 'lenge', 'natural', 'popular', 'solution', 'design', 'metric', 'evaluate', 'state', 'novelty', 'assign', 'high', 'intrinsic', 'ward', 'novel', 'state', 'example', 'countbase', 'intrinsic', 'reward', 'strehl', 'littman', 'kolter', 'curiositybase', 'intrinsic', 'motivation', 'stadie', 'pathak', 'popular', 'way', 'state', 'space', 'recently', 'near', 'estimation', 'method', 'yarat', 'abbeel', 'show', 'great', 'performance', 'provement', 'challenge', 'visual', 'domain', 'method', 'compatible', 'successful', 'exploration', 'intrinsic', 'ward', 'design', 'use', 'additionally', 'encourage', 'episodiclevel', 'reachable', 'space', 'expansion', 'achieve', 'large', 'state', 'space', 'coverage', 'single', 'episode', 'episodic', 'memory', 'derive', 'useful', 'information', 'episodic', 'buffer', 'show', 'great', 'success', 'improve', 'training', 'sample', 'ef', 'ficiency', 'rl', 'navigation', 'control', 'game', 'episodic', 'memory', 'buffer', 'apply', 'mimic', 'hippocampal', 'episodic', 'control', 'rapidly', 'assimilate', 'recent', 'experience', 'blundell', 'pritzel', 'man', 'tione', 'previous', 'section', 'keep', 'episodic', 'buffer', 'store', 'observation', 'introduce', 'episodic', 'curiosity', 'module', 'determine', 'new', 'observation', 'reachable', 'previous', 'observation', 'rapid', 'zha', 'et', 'propose', 'novel', 'way', 'behaviour', 'cloning', 'episode', 'high', 'episodic', 'coverage', 'badia', 'combine', 'episodic', 'novelty', 'module', 'lifelong', 'novelty', 'module', 'generate', 'intrinsic', 'reward', 'however', 'episodic', 'novelty', 'measurement', 'differ', 'ence', 'current', 'observation', 'previous', 'observation', 'focus', 'much', 'reachable', 'space', 'expand', 'new', 'state', 'ride', 'raileanu', 'real', 'dynamic', 'learn', 'dynamic', 'e', 'r', 'e', 'g', 'r', 'e', 'k3', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'conclusion', 'work', 'introduce', 'go', 'imagination', 'gobi', 'novel', 'episodic', 'intrinsic', 'reward', 'design', 'encourage', 'efficient', 'episodiclevel', 'exploration', 'expand', 'reachable', 'space', 'previous', 'episodic', 'intrinsic', 'reward', 'use', 'naive', 'episodic', 'state', 'count', 'state', 'visitation', 'coverage', 'method', 'exploit', 'learn', 'world', 'model', 'predict', 'reachable', 'state', 'motivate', 'agent', 'seek', 'state', 'unexplored', 'neighbor', 'combine', 'lifelong', 'intrin', 'sic', 'reward', 'method', 'show', 'great', 'training', 'time', 'sample', 'efficiency', 'improvement', 'hard', 'procedurallygenerate', 'vironment', 'time', 'extend', 'guide', 'exploration', 'continuous', 'control', 'task', 'visual', 'input', 'indicate', 'promising', 'future', 'direction', 'acknowledgment', 'work', 'support', 'part', 'grant', 'ai', 'search', 'iis', 'fwhtfr', 'reference', 'surprisebase', 'intrinsic', 'moti', 'vation', 'deep', 'reinforcement', 'learning', 'arxiv', 'preprint', 'p', 'r', 'amaral', 'bliss', 'keefe', 'book', 'press', 'badia', 'p', 'vitvitskyi', 'guo', 'piot', 'tieleman', 'arjovsky', 'pritzel', 'bolt', 'et', 'never', 'give', 'learn', 'direct', 'exploration', 'strategy', 'arxiv', 'preprint', 'beattie', 'c', 'leibo', 'z', 'teplyashin', 'ward', 'wain', 'wright', 'h', 'lefrancq', 'green', 'sadik', 'et', 'deepmind', 'lab', 'arxiv', 'preprint', 'arxiv161203801', 'blundell', 'c', 'uria', 'b', 'pritzel', 'li', 'ruderman', 'leibo', 'z', 'wierstra', 'abis', 'modelfree', 'episodic', 'control', 'arxiv', 'preprint', 'h', 'storkey', 'klimov', 'ex', 'ploration', 'random', 'network', 'distillation', 'arxiv', 'preprint', 'willem', 'l', 'pal', 'tic', 'gridworld', 'environment', 'gym', 'https', 'githubcommaximecbgymminigrid', 'tower', 'r', 'willem', 'l', 'pal', 'minigrid', 'miniworld', 'modular', 'customizable', 'reinforcement', 'learning', 'environment', 'goaloriente', 'task', 'hesse', 'schulman', 'j', 'quantify', 'generalization', 'reinforcement', 'learning', 'international', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'schulman', 'lever', 'age', 'procedural', 'generation', 'benchmark', 'reinforcement', 'learning', 'international', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'eichenbaum', 'h', 'role', 'hippocampus', 'navigation', 'memory', 'journal', 'neurophysiology', 'espeholt', 'l', 'soyer', 'h', 'muno', 'r', 'ward', 'doron', 'firoiu', 'harley', 'dun', 'et', 'impala', 'scalable', 'distribute', 'deeprl', 'weight', 'actorlearner', 'architecture', 'tional', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'fletberliac', 'ferret', 'pietquin', 'preux', 'p', 'adversarially', 'guide', 'actorcritic', 'arxiv', 'preprint', 'florensa', 'c', 'hold', 'geng', 'abbeel', 'p', 'automatic', 'goal', 'generation', 'reinforcement', 'learning', 'agent', 'international', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'freeman', 'metz', 'l', 'learning', 'predict', 'look', 'ahead', 'world', 'model', 'forward', 'prediction', 'advance', 'neural', 'information', 'processing', 'system', 'schmidhuber', 'recurrent', 'world', 'model', 'facil', 'itate', 'policy', 'evolution', 'advance', 'neural', 'information', 'processing', 'system', 'schmidhuber', 'world', 'model', 'arxiv', 'preprint', 'hafner', 'lillicrap', 'j', 'dream', 'control', 'learn', 'behavior', 'latent', 'imagination', 'arxiv', 'preprint', 'hafner', 'j', 'master', 'diverse', 'domain', 'world', 'model', 'arxiv', 'preprint', 'hazan', 'e', 'kakade', 'k', 'prov', 'ably', 'efficient', 'maximum', 'entropy', 'exploration', 'tional', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'wydmuch', 'runc', 'g', 'toczek', 'j', 'w', 'vizdoom', 'doombase', 'ai', 'research', 'plat', 'form', 'visual', 'reinforcement', 'learning', 'ieee', 'con', 'ference', 'computational', 'intelligence', 'game', 'pp', 'ieee', 'r', 'grefenstette', 'e', 'survey', 'generalisation', 'deep', 'reinforcement', 'learning', 'arxiv', 'preprint', 'kolter', 'z', 'nearbayesian', 'exploration', 'proceeding', '26th', 'annual', 'polynomial', 'time', 'international', 'conference', 'machine', 'learn', 'pp', 'laskin', 'stooke', 'pinto', 'l', 'abbeel', 'p', 'srinivas', 'reinforcement', 'learning', 'augmented', 'datum', 'advance', 'neural', 'information', 'processing', 'system', 'l', 'eysenbach', 'b', 'e', 'e', 'salakhutdinov', 'r', 'efficient', 'exploration', 'state', 'marginal', 'matching', 'arxiv', 'preprint', 'arxiv190605274', 'h', 'abbeel', 'p', 'behavior', 'void', 'unsuper', 'vise', 'active', 'pretraine', 'advance', 'neural', 'information', 'processing', 'system', 'silver', 'grave', 'antonoglou', 'riedmiller', 'play', 'atari', 'deep', 'reinforcement', 'learning', 'arxiv', 'preprint', 'badia', 'p', 'mirza', 'grave', 'lillicrap', 'harley', 'silver', 'asyn', 'chronous', 'method', 'deep', 'reinforcement', 'learning', 'international', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'taniguchi', 'planet', 'bayesian', 'reconsider', 'improve', 'deep', 'planning', 'network', 'incorporate', 'bayesian', 'inference', 'ieeersj', 'international', 'conference', 'intelligent', 'robot', 'system', 'iro', 'pp', 'ieee', 'dean', 'pathak', 'gupta', 'interesting', 'object', 'curious', 'agent', 'learn', 'taskagnostic', 'exploration', 'advance', 'neural', 'information', 'processing', 'system', 'pathak', 'agrawal', 'efro', 'darrell', 'exploration', 'selfsupervise', 'predic', 'tion', 'international', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'pritzel', 'uria', 'b', 'srinivasan', 'badia', 'p', 'vinyal', 'wierstra', 'blundell', 'c', 'neural', 'episodic', 'control', 'international', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'raileanu', 'r', 'ride', 'rewarding', 'impact', 'drive', 'exploration', 'procedurallygenerate', 'environ', 'ment', 'arxiv', 'preprint', 'riedmiller', 'hafner', 'r', 'lampe', 'neunert', 'heess', 'springen', 'learn', 'play', 'solve', 'sparse', 'reward', 'task', 'scratch', 'international', 'conference', 'pp', 'pmlr', 'raichuk', 'marini', 'r', 'vincent', 'polle', 'fey', 'lillicrap', 'gelly', 'episodic', 'curiosity', 'reachability', 'arxiv', 'preprint', 'arxiv181002274', 'schulman', 'dhariwal', 'p', 'radford', 'klimov', 'proximal', 'policy', 'optimization', 'algorithm', 'arxiv', 'preprint', 'r', 'rybkin', 'abbeel', 'p', 'hafner', 'pathak', 'planning', 'explore', 'selfsupervise', 'world', 'model', 'international', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'seo', 'h', 'abbeel', 'p', 'maximization', 'random', 'encoder', 'efficient', 'exploration', 'ed', 'proceeding', '38th', 'international', 'conference', 'machine', 'learn', 'volume', 'proceeding', 'machine', 'learn', 'research', 'pp', 'pmlr', 'jul', 'proceedingsmlr', 'pressv139seo21ahtml', 'stadie', 'c', 'abbeel', 'p', 'incentivize', 'ex', 'ploration', 'reinforcement', 'learning', 'deep', 'predictive', 'model', 'arxiv', 'preprint', 'strehl', 'l', 'littman', 'l', 'analysis', 'model', 'base', 'interval', 'estimation', 'markov', 'decision', 'process', 'journal', 'computer', 'system', 'science', 'h', 'r', 'foote', 'stooke', 'schulman', 'abbeel', 'p', 'exploration', 'study', 'countbase', 'exploration', 'deep', 'reinforcement', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'tunyasuvunakool', 'muldal', 'doron', 'merel', 'erez', 'lillicrap', 'tassa', 'control', 'software', 'task', 'continuous', 'control', 'software', 'impact', 'issn', 'https', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'bao', 'clavera', 'abbeel', 'p', 'ba', 'j', 'benchmarke', 'modelbase', 'reinforcement', 'learning', 'arxiv', 'preprint', 'yarat', 'fergus', 'r', 'lazaric', 'l', 'reinforce', 'ment', 'learn', 'prototypical', 'representation', 'national', 'conference', 'machine', 'learn', 'pp', 'pmlr', 'yarat', 'kostrikov', 'amos', 'b', 'fergus', 'r', 'improve', 'sample', 'efficiency', 'model', 'free', 'reinforcement', 'learning', 'image', 'proceeding', 'conference', 'artificial', 'intelligence', 'vol', 'ume', 'pp', 'zha', 'l', 'rank', 'episode', 'simple', 'approach', 'exploration', 'procedurallygenerate', 'environment', 'arxiv', 'preprint', 'h', 'simple', 'yet', 'effective', 'exploration', 'criterion', 'advance', 'neural', 'information', 'processing', 'system', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'implementation', 'detail', 'experiment', 'minigrid', 'baseline', 'implementation', 'ride', 'raileanu', 'build', 'official', 'codebase', 'fair', 'compar', 'ison', 'intrinsic', 'reward', 'rint', 'differ', 'use', 'base', 'time', 'experiment', 'run', 'compute', 'resource', 'cpu', 'rerun', 'official', 'code', 'get', 'result', 'minigrid', 'multiroom', 'keycorridor', 'experiment', 'obstructedmaze', 'find', 'proper', 'hyperparameter', 'fully', 'reproduce', 'result', 'therefore', 'directly', 'take', 'result', 'report', 'paper', 'ride', 'rnd', 'run', 'code', 'official', 'codebase', 'original', 'paper', 'include', 'experiment', 'minigrid', 'environment', 'therefore', 'implement', 'version', 'tune', 'hyperparameter', 'grid', 'search', 'intrinsic', 'reward', 'function', 'gobi', 'baseline', 'list', 'gobi', 'ot1', 'size', 'episodic', 'buffer', 'ot1', 'lifelong', 'count', 'observation', 'ot1', 'start', 'begin', 'ning', 'training', 'rnd', 'ot1', '∥2', 'difference', 'fix', 'random', 'network', 'train', 'state', 'embed', 'network', 'train', 'minimize', 'error', 'noveld', 'novelty', 'novelty', '∗', 'epi', 'st1', 'apply', 'measure', 'novelty', 'ie', 'novelty', '∥ϕ', '∥2', 'epi', 'st1', 'check', 'agent', 'visit', 'state', 'st1', 'first', 'time', 'episode', 'notice', 'use', 'full', 'environment', 'information', 'grid', 'world', 'instead', 'partiallyobservable', 'view', 'therefore', 'epi', 'count', 'st1', 'instead', 'ride', 'ot1', '∥2', 'epi', 'st1', 'state', 'embed', 'network', 'train', 'minimize', 'prediction', 'error', 'inverse', 'forward', 'dynamic', 'epi', 'indicate', 'episodic', 'count', 'ride', 'also', 'use', 'state', 'information', 'st1', 'episodic', 'count', 'policy', 'value', 'function', 'training', 'fair', 'compar', 'ison', 'policy', 'network', 'value', 'function', 'network', 'approach', 'input', 'observation', '×', 'put', 'share', 'feature', 'extraction', 'network', 'include', 'convolutional', 'layer', '×', 'padding', 'channel32', 'stride', 'respectively', 'elu', 'activation', 'ture', 'flatten', 'put', 'linear', 'layer', 'unit', 'relu', 'activation', 'lstm', 'layer', 'unit', 'share', 'feature', 'pass', 'separately', 'fullyconnected', 'layer', 'unit', 'output', 'action', 'dis', 'tribution', 'value', 'estimation', 'dynamic', 'model', 'implementation', 'dynamic', 'model', 'input', 'panorama', 'current', 'step', 'get', 'panorama', 'let', 'agent', 'rotate', 'time', 'catenate', 'observation', 'get', 'input', 'size', '×', 'pass', 'feature', 'extraction', 'module', 'structure', 'policy', 'value', 'function', 'network', 'input', 'first', 'linear', 'layer', 'concatenate', 'action', 'put', 'coder', 'linear', 'layer', 'size', 'reshape', 'back', '×', 'get', 'predict', 'observation', 'pre', 'train', 'dynamic', 'model', 'use', 'panot', 'ot1', 'pair', 'collect', 'random', 'policy', 'ride', 'also', 'require', 'training', 'dynamic', 'model', 'state', 'embed', 'network', 'input', 'dynamic', 'model', 'state', 'embed', 'action', 'forward', 'model', 'contain', 'fullyconnected', 'layer', 'unit', 'activate', 'relu', 'verse', 'dynamic', 'model', 'contain', 'fullyconnected', 'layer', 'unit', 'relu', 'activation', 'function', 'input', 'state', 'embedding', 'consecutive', 'step', 'hash', 'function', 'directly', 'apply', 'default', 'python', 'hash', 'function', 'hash', '×', 'observation', 'predict', 'future', 'observation', 'add', 'episodic', 'buffer', 'state', 'embed', 'ride', 'require', 'train', 'state', 'embed', 'network', 'input', 'observation', 'minigrid', 'dimension', 'contain', 'convolutional', 'layer', 'kernel', 'size', 'padding', 'stride', 'number', 'channel', 'respectively', 'activation', 'function', 'elu', 'follow', 'convolutional', 'layer', 'linear', 'layer', 'unit', 'relu', 'activation', 'c', 'ot1', 'c', 'ot1', '90th', 'percentile', 'similarity', 'score', 'observation', 'episodic', 'buffer', 'similar', 'ity', 'score', 'calculate', 'use', 'pretraine', 'episodic', 'curiosity', 'module', 'hyperparameter', 'visitation', 'count', 'gobi', 'store', 'flatten', '×', 'observation', 'step', 'noveld', 'ride', 'count', 'full', 'state', 'episodic', 'level', 'shape', 'vary', 'environment', 'environment', 'example', 'shape', '×', 'multiroom', 'environment', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'hyperparameter', 'table', 'show', 'value', 'hyper', 'parameter', 'share', 'different', 'method', 'parameter', 'name', 'batch', 'size', 'optimizer', 'learning', 'rate', 'step', 'discount', 'factor', 'weight', 'policy', 'entropy', 'loss', 'weight', 'value', 'function', 'loss', 'value', 'rmsprop', 'table', 'hyperparameter', 'experiment', 'minigrid', 'hyperparameter', 'share', 'method', 'experiment', 'use', 'gobi', 'minigrid', 'set', 'intrinsic', 'reward', 'coefficient', 'k', 'mean', 'forward', 'dynamic', 'model', 'step', 'time', 'action', 'space', 'small', 'discrete', 'instead', 'randomly', 'sample', 'action', 'directly', 'predict', 'future', 'observation', 'use', 'possible', 'action', 'list', 'hyperparameter', 'choice', 'intrinsic', 'decay', 'factor', 'ρ', 'table', 'value', 'choose', 'make', 'intrinsic', 'reward', 'large', 'beginning', 'training', 'nearzero', 'end', 'training', 'parameter', 'forward', 'step', 'intrinsic', 'decay', 'ˆfϕ', 'learn', 'rate', 'value', 'mrn7s8', '8e−7', 'mrn12s10', 'kcs5r3', 'om1q', 'om2q', 'omfull', 'table', 'hyperparameter', 'gobi', 'experiment', 'mini', 'grid', 'set', 'environment', 'suggest', 'official', 'codebase', 'ride', 'use', 'λ', 'environment', 'set', 'environment', 'make', 'initial', 'average', 'intrinsic', 'reward', 'similar', 'experiment', 'apply', 'base', 'reinforcement', 're3', 'rerun', 'official', 'code', 'get', 'result', 'environment', 'icm', 'follow', 'implementation', 'detail', 'list', 're3', 'implement', 'compatible', 'deepmind', 'control', 'task', 'fair', 'comparison', 'intrinsic', 'reward', 'design', 'differ', 'method', 'trinsic', 'reward', 'function', 'gobi', 'baseline', 'list', 'gobi', 'size', 'episodic', 'buffer', 'latter', 'part', 're3', 'intrinsic', 'reward', 'introduce', '•', 'log', 'yk−n', 'n', 'fθ', 'fix', 'representation', 'output', 'randomly', 'initial', 'ized', 'encoder', 'n', 'set', 'knear', 'neighbor', 'collect', 'beginning', 'training', '•', 'icm', 'ot1', 'ot1', 'scaling', 'factor', 'feature', 'vector', 'jointly', 'optimize', 'forward', 'prediction', 'model', 'inverse', 'dynam', 'ics', 'model', 'predict', 'feature', 'encoding', 'time', 'step', '•', 'rnd', 'ot1', '∥2', 'difference', 'fix', 'random', 'network', 'train', 'state', 'embed', 'network', 'train', 'minimize', 'ot1', '∥2', 'architecture', 'observation', 'size', 'environment', 'encoder', 'architecture', 'follow', 'one', 'yarat', 'contain', 'convolutional', 'layer', '×', 'kernel', 'channel32', 'stride2', 'relu', 'activation', 'output', 'pass', 'fully', 'connect', 'layer', 'normalize', 'layernorm', 'dynamic', 'model', 'forward', 'dynamic', 'model', 'use', 'generate', 'future', 'prediction', 'apply', 'world', 'model', 'structure', 'input', 'size', 'downsample', 'input', 'observation', 'instead', 'tune', 'world', 'model', 'layer', 'train', 'dynamic', 'model', 'together', 'policy', 'online', 'manner', 'instead', 'pretrain', 'take', 'many', 'episode', 'prediction', 'visually', 'reasonable', 'therefore', 'add', 'extra', 'effort', 'determine', 'many', 'datum', 'collect', 'pretrain', 'dynamic', 'model', 'a2', 'experiment', 'deepmind', 'control', 'suit', 'baseline', 'implementation', 'gobi', 'seo', 'icm', 'build', 'official', 'codebase', 're3', 'image', 'hash', 'observation', 'image', 'high', 'dimensional', 'space', 'prediction', 'usually', 'accu', 'rate', 'hash', 'image', 'low', 'dimension', 'avoid', 'take', 'much', 'space', 'collapse', 'similar', 'observation', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'prediction', 'follow', 'use', 'sim', 'ple', 'simhash', 'function', 'map', 'image', 'bit', 'specifically', 'project', 'flatten', 'image', 'random', 'initialize', 'vector', 'use', 'sign', 'output', 'vector', 'value', 'hash', 'code', 'hyperparameter', 'table', 'show', 'value', 'hyper', 'parameter', 'share', 'different', 'method', 'decrease', 'small', 'therefore', 'sometimes', 'hard', 'agent', 'learn', 'useful', 'result', 'unsatisfac', 'tory', 'performance', 'meanwhile', 'small', 'example', 'ρ', 'intrinsic', 'reward', 'large', 'later', 'stage', 'training', 'make', 'agent', 'focus', 'less', 'extrinsic', 'reward', 'therefore', 'policy', 'converge', 'slow', 'parameter', 'name', 'augmentation', 'observation', 'size', 'action', 'repeat', 'replay', 'buffer', 'size', 'initial', 'random', 'exploration', 'step', 'frame', 'stack', 'actor', 'learn', 'rate', 'critic', 'learn', 'rate', 'batch', 'size', 'near', 'neighbor', 'critic', 'target', 'update', 'value', 'crop', 'table', 'hyperparameter', 'experiment', 'deepmind', 'control', 'suit', 'hyperparameter', 'share', 'method', 'intrinsic', 'reward', 'coefficient', 'follow', 'good', 'choice', 'report', 're3', 'gobi', 'apply', 'intrinsic', 'reward', 'coefficient', 'intrinsic', 'reward', 'decay', 'ρ', 'one', 're3', 'fair', 'comparison', 'intrinsic', 'reward', 'specific', 'method', 'show', 'table', 'number', 'random', 'action', 'perform', 'hyperparameter', 'search', 'find', 'perform', 'well', 'task', 'number', 'forward', 'step', 'k', 'perform', 'hyperparameter', 'search', 'report', 'one', 'good', 'result', 'parameter', 'forward', 'step', 'k', 'random', 'action', 'value', 'pendulumswingup', 'table', 'hyperparameter', 'experiment', 'deepmind', 'control', 'suit', 'hyperparameter', 'specific', 'method', 'hyperparameter', 'intrinsic', 'reward', 'decay', 'figure', 'training', 'performance', 'gobi', 'minigrid', 'multiroom', 'n12s10', 'different', 'intrinsic', 'reward', 'decay', 'ρ', 'figure', 'training', 'performance', 'gobi', 'minigrid', 'multiroom', 'different', 'randomly', 'sample', 'action', 'step', 'b2', 'number', 'randomly', 'sample', 'action', 'minigrid', 'experiment', 'report', 'section', 'randomly', 'sample', 'action', 'minigrid', 'small', 'discrete', 'action', 'space', 'action', 'therefore', 'directly', 'predict', 'future', 'observation', 'action', 'ever', 'also', 'report', 'result', 'n', 'random', 'action', 'figure', 'summarize', 'n', 'similar', 'performance', 'minigrid', 'large', 'n', 'make', 'wallclock', 'training', 'time', 'long', 'slightly', 'slow', 'early', 'stage', 'still', 'outperform', 'previous', 'state', 'oftheart', 'overall', 'n', 'good', 'choice', 'minigrid', 'environment', 'figure', 'show', 'training', 'performance', 'differ', 'ent', 'intrinsic', 'reward', 'decay', 'ρ', 'choice', 'balance', 'relative', 'importance', 'extrinsic', 'intrinsic', 'reward', 'large', 'example', 'agent', 'find', 'goal', 'intrinsic', 'reward', 'already', 'c', 'exploration', 'behaviour', 'comparison', 'gobi', 'figure', 'visualize', 'policy', 'visitation', 'heatmap', 'gobi', 'multiroom', 'r', 'e', 'r', 'e', 'g', 'r', 'e', 'multiroomn12s10', 'environment', 'step', '9e7', 'e', 'r', 'e', 'g', 'r', 'e', 'n3', 'n10', 'n15', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'figure', 'heatmap', 'example', 'trajectory', 'different', 'training', 'step', 'environment', 'time', 'hour', 'noveld', 'gobi', '±0058', 'table', 'wallclock', 'training', 'time', 'comparison', 'hour', 'noveld', 'gobi', 'environment', 'minigrid', 'fail', 'learn', 'optimal', 'policy', 'still', 'capture', 'preference', 'heatmap', 'agent', 'train', 'prefer', 'go', 'corner', 'room', 'generally', 'low', 'similarity', 'score', 'state', 'middle', 'room', 'however', 'similarity', 'score', 'low', 'enough', 'state', 'add', 'episodic', 'buffer', 'continue', 'stay', 'state', 'maximize', 'intrinsic', 'reward', 'try', 'tune', 'similarity', 'score', 'threshold', 'use', 'grid', 'search', 'still', 'find', 'good', 'hyperparameter', 'choice', 'similarity', 'score', 'different', 'corner', 'share', 'consistent', 'value', 'see', 'figure', 'gobi', 'choose', 'visit', 'border', 'room', 'early', 'training', 'information', 'border', 'easily', 'predictable', 'information', 'middle', 'room', 'figure', 'illustrative', 'example', 'work', 'well', 'encourage', 'efficient', 'exploration', 'example', 'goal', 'include', 'state', 'episodic', 'buffer', 'quickly', 'gobi', 'move', 'directly', 'center', 'step', 'maximum', 'intrinsic', 'reward', 'choose', 'take', 'extra', 'step', 'exploration', 'mainly', 'focus', 'episodic', 'buffer', 'expand', 'figure', 'training', 'performance', 'comparison', 'environment', 'use', 'fix', 'pretraine', 'dynamic', 'model', 'use', 'pretraine', 'dynamic', 'model', 'online', 'pretraine', 'directly', 'train', 'dynamic', 'model', 'together', 'policy', 'training', 'wallclock', 'training', 'time', 'table', 'show', 'wallclock', 'time', 'need', 'train', 'method', 'environment', 'step', 'gobi', 'require', 'wallclock', 'time', 'need', 'train', 'noveld', 'number', 'environment', 'step', 'e', 'dynamic', 'training', 'experiment', 'section', 'report', 'result', 'apply', 'pretraine', 'forward', 'dynamic', 'gobi', 'minigrid', 'however', 'forward', 'dynamic', 'model', 'also', 'train', 'together', 'policy', 'training', 'figure', 'report', 'result', 'ablation', 'study', 'minigrid', 'environment', 'setting', 'use', 'pretraine', 'dynamic', 'model', 'keep', 'fix', 'train', 'policy', 'pretrain', 'dynamic', 'model', 'finetune', 'train', 'policy', 'pre', 'training', 'directly', 'train', 'dynamic', 'model', 'online', 'manner', 'summary', 'version', 'work', 'similarly', 'fact', 'train', 'dynamic', 'model', 'online', 'add', 'gobi', 'training', 'environment', 'episode', 'goal', 'agent', 'minigridmultiroomn7s8v0', 'episodic', 'curiosity', 'c', 'e', 'train', 'step', 'unseen', 'see', 'e', 'r', 'e', 'g', 'r', 'e', 'nopretrain', 'model', 'r2', 'gobi', 's0', 's0', 's1', 's0', 's1', 's0', 's1', 's1', 'visit', 'state', 'reachable', 'state', 'nonreachable', 'state', 'trajectory', 'direct', 'temporal', 'order', 'observe', 'transition', 'path', 'bidirectional', 'unreachable', 'transition', 'path', 'bidirectional', 'go', 'imagination', 'maximize', 'episodic', 'reachability', 'world', 'model', 'extra', 'wall', 'clock', 'training', 'time', 'use', 'option', 'main', 'experiment', 'ablation', 'study', 'illustration', 'section', 'provide', 'illustrative', 'example', 'consider', 'new', 'state', 'add', 'episodic', 'buffer', 'section', 'work', 'way', 'bad', 'method', 'example', 'show', 'figure', 'state', 'small', 'part', 'environment', 'want', 'policy', 'explore', 'part', 'quickly', 'possible', 'mark', 'state', 'reachable', 'quickly', 'possible', 'ever', 'order', 'maximize', 'stepwise', 'intrinsic', 'reward', 'agent', 'train', 'go', 'border', 'add', 'new', 'state', 'episodic', 'buffer', 'time', 'waste', 'many', 'unnecessary', 'step', 'beneficial', 'exploration']"
"Field evaluation of a mobile app for assisting blind and visually
  impaired travelers to find bus stops","[{'href': 'http://arxiv.org/abs/2309.10940v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2309.10940v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-09-19 21:39:32,"May 2023 

Classifying Organizations for Food 
System Ontologies using Natural 
Language Processing 

Tianyu JIANG a, Sonia VINOGRADOVA b, Nathan STRINGHAM a, 
E. Louise EARL  b, Allan D. HOLLANDER c, Patrick R. HUBER c, Ellen RILOFF  a,1, 
R. Sandra SCHILLO  b, Giorgio A. UBBIALI  d, Matthew LANGE  e, 
a University of Utah 
b University of Ottawa 
c University of California, Davis 
d University of Milan 
e IC-FOODS 
ORCiD ID: E. Louise Earl https://orcid.org/0000-0002-5646-0132, R. Sandra Schillo 
https://orcid.org/0000-0002-3468-0206, Giorgio A. Ubbiali 
https://orcid.org/0000-0001-7872-1770 , Matthew Lange 
https://orcid.org/0000-0002-6148-7962 

Abstract.  Our  research  explores  the  use  of  natural  language  processing  (NLP) 
methods to automatically classify entities for the purpose of knowledge graph pop- 
ulation and integration with food system ontologies. We have created NLP models 
that can automatically classify organizations with respect to categories associated 
with environmental issues as well as Standard Industrial Classification (SIC) codes, 
which are used by the U.S. government to characterize business activities. As in- 
put, the NLP models are provided with text snippets retrieved by Google’s search 
engine for each organization, which serves as a textual description of the organi- 
zation that is used for learning. Our experimental results show that NLP models 
can achieve reasonably good performance for these two classification tasks, and 
they rely on a general framework that could be applied to many other classification 
problems as well. We believe that NLP models represent a promising approach for 
automatically harvesting information to populate knowledge graphs and aligning 
the information with existing ontologies through shared categories and concepts. 

Keywords. food system ontologies, classification models, natural language processing, 
SIC, sustainability issues, unstructured data 

1.  Introduction 

Food systems include activities and relationships that are involved with the production, 
transport, and consumption of food, and thus are linked to a wide variety of natural and 
human systems (Tomich et al. [13]). Their extensive nature can have dramatic impacts 

1Corresponding Author: Ellen Riloff (riloff@cs.utah.edu). 

 
 
 
 
 
 
 
 
May 2023 

on these natural and human systems (IPBES [9], UNEP [15]). Conversely, food systems 
are vulnerable to changes in these other systems. Food activities also show a pivotal role 
in fostering human social and health-related issues. For instance, inequalities and injus- 
tices exist across the whole global food supply chain, as well as within related sectors 
(D’Odorico et al. [5], Nicole´tis and Termine [10]). To date, hunger, malnutrition, and 
micronutrient deficiencies, just to cite a few, still largely threaten humanity worldwide 
(Fanzo et al. [6], Fanzo and Davis [7], UNICEF [14]). 

As our world becomes more interconnected and interdependent, ontologies become 
useful ways of categorizing and relating information together. This is especially appli- 
cable to food systems, where data access, interoperability, and reusability are essential 
to  deal  with  the  interrelated  issues  arising  from  food  systems  activities.  An  ontology 
is a “formal theory” which provides a “commonly accepted” dictionary of terms, sup- 
ported by a “canonical syntax” and a set of axioms, for a knowledge domain of interest 
(Smith [12]). In doing so, an ontology offers a common semantic framework for that 
domain of knowledge (Smith [12], Hollander et al. [1]). Thus, an ontology fosters data 
access, interoperability, and reusability across several disparate resources, which employ 
that ontology as a common reference semantic standard (Hollander et al. [1]). Nowa- 
days, several ontologies focusing on food, health, and related aspects have been devel- 
oped  (Boulos  et  al.  [2],  Dooley  et  al.  [3]).  Here,  we  just  cite  a  few  noteworthy  ones 
as examples: 1) AGROVOC2 is a three-decade-long well-established “multilingual the- 
saurus”, addressing food and related domains of interest (Boulos et al. [2]). It belongs 
to the United Nations Food and Agriculture Organisation (FAO). 2) The Agronomy On- 
tology AgrO3 was developed within the frame of the CGIAR Platform for Big Data in 
Agriculture, and which proposes a vocabulary of terms, covering “agronomic manage- 
ment practices, implements, and variables used during agronomic experiments” (Dooley 
et al. [3]). 3) The Compositional Dietary Nutrition Ontology CDNO4 presents terms re- 
lated to “nutritional attributes from crops, livestock, and fisheries that contribute to hu- 
man diet and which are referenced in precision food commodity laboratory analytics” 
(Dooley et al. [3]). 4) The Food Ontology FoodOn5 provides a lexicon about “basic raw 
food source ingredients, process terms for packaging, cooking, and preservation, and an 
upper-level variety of product type schemes under which food products can be catego- 
rized”. FoodOn stands out as a fundamental ontology in addressing food-related aspects 
(Dooley et al. [4]). Further, FoodOn aims to state the lingua franca within the domain 
of food, for sharing and reusing food-related information both by humans and machines 
(Dooley et al. [4]). Despite the availability of food-health ontologies, the envisaged data 
access, interoperability and reusability across food industries and other food-related sec- 
tors, as we claimed above, appears to have not been reached yet (Tomich et al. [13]). 

In this paper, we present new research that uses artificial intelligence (AI) technol- 
ogy to automatically categorize organizations, ultimately for the purpose of linking them 
into food system ontologies. Our eventual goal is to automatically populate large knowl- 
edge graphs of information related to agriculture and food systems, where the concepts in 
the graph are aligned with well-established ontologies to ensure that the knowledge will 
be represented consistently and aligned with other resources and systems that rely on the 

2https://www.fao.org/agrovoc/ 
3https://bigdata.cgiar.org/resources/agronomy-ontology/ 
4https://cdno.info/ 
5https://github.com/FoodOntology/foodon/ 

 
 
 
May 2023 

same ontological frameworks. Populating knowledge graphs by hand is time-consuming 
and expensive, so AI technology offers the opportunity to automatically harvest infor- 
mation much more quickly and efficiently. 

Specifically, we focus on two classification tasks related to organizations. We aim 
to categorize organizations based on 1) a set of environmental issues that are relevant to 
environmental planning and food systems, and 2) standard industrial classification (SIC) 
codes6, which the U.S. government assigns to businesses to categorize the nature of their 
activities. SIC codes are analogous to North American Industry Classification System 
(NAICS) codes, which are used across North America. We have designed natural lan- 
guage processing (NLP) models that read text associated with an organization to auto- 
matically assign the organization to categories for these two tasks. In the following sec- 
tions, we describe the classification tasks in more detail, explain how we collect relevant 
texts for the NLP models to use, present the NLP technology underlying the classification 
models, and show experimental results for the two classification tasks. 

2.  Classification Tasks & Datasets 

2.1.  Environmental Issues Classification Task and Dataset 

There is a large amount of information currently available concerning the state of the 
environment. Around the world, many organizations are collecting and analyzing data. 
However, there remains a major gap in our ability to connect these data sources and make 
them “smart”. They typically use different formats and vocabularies, rendering them un- 
able to be used together. The conservation community lacks an informatics backbone 
to begin linking people and data in ways that enhance our capacity for informed deci- 
sion making in our effort to conserve and enhance the Earth’s ecosystems. This need is 
especially crucial as we enter an unprecedented era of rapid environmental change. 

One key question in environmental planning, food systems, and many other contexts 
is “Who is doing what where?”. “Who” can be people or organizations, “what” may be 
projects or other activities, and “where” could refer to many kinds of geographies. To 
help provide machine-readable answers to this question, Hollander et al. [1] developed 
an ontology called “PPOD” (People, Projects, Organizations, and Datasets).7 This ontol- 
ogy formally describes the characteristics of and relationships between these classes of 
information. 

Members of our team have instantiated the PPOD ontology with information con- 
cerning  the  conservation  of  working  landscapes  in  California.  This  knowledge  graph 
(KG) contains over 2,000 organizations which were identified and collected in an ad hoc 
manner through an array of online searches using terms such as “conservation”, “bio- 
diversity”, “grazing”, and “water supply”. Each organization is associated with multi- 
ple attributes that describe its structure and mission, such as hasOrgType, hasOrgActiv- 
ity, and issues. The “issues” attribute describes potential environmental issues associated 
with the organization. PPOD has pre-defined 44 high-level environmental issues called 
“integrated issues”, and 325 more fine-grained environmental issues called “component 
issues”. The ontology provides a detailed textual description for each issue label and 

6https://www.osha.gov/data/sic-manual 
7https://github.com/PPODschema 

 
 
 
 
 
 
 
May 2023 

Category 

Water 

Physical Infrastructure 

Wastes & Pollution 

Biodiversity 

Land & Soil 

Food Production 

Institutions 

Governance 

Protected Areas 

Sociocultural Systems 

Public Health 

Disasters 

Common Pool Resources 

Air & Climate 

Technology 

# of Organizations  % Percentage 

Example Organization 

845 

702 

578 

556 

535 

393 

345 

274 

253 

231 

179 

162 

128 

126 

122 

39.0 

32.4 

26.7 

25.7 

24.7 

18.2 

15.9 

12.7 

11.7 

10.7 

8.3 

7.5 

5.9 

5.8 

5.6 

American Rivers 

Rebuild NorthBay Foundation 

Heal the Ocean 

Feather River Land Trust 

Agricultural Research Service 

American Grassfed Association 

Southern California Edison 

Merced County 

American Forest Resource Council 

Enterprise Rancheria 

California Department of Public Health 

Tahoe Fire & Fuels Team 

Sustainable Conservation 

Irvine Global Warming Group 

CDFW Data and Technology Division 

Table 1.  Examples of environmental issues and how many organizations each issue is associated with. The 
last column shows an example organization labeled with each issue category. 

the relation between integrated issues and component issues. For example, component 
issues “Air Pollution”, “Air Quality”, “Greenhouse Gas Mitigation” and “Greenhouse 
Gas Emissions” are children of the integrated issue “Air & Climate”, which is described 
as “GHG emissions, ozone layer depletion, air quality, climate change influenced and 
extreme weather events, shifts in growing zones for key crops due to climate change.” 
Expert opinion was used to associate each organization with one or more issues. 

We define a task based on the PPOD ontology called environmental issues classi- 
fication. Given an organization, the task requires that the NLP model assign one or mul- 
tiple environmental issue category labels to the organization that describe the organi- 
zation’s activities and/or mission. The NLP model needs to be trained with a reasonable 
number of examples for each category, so we started with the most common categories 
in the existing PPOD data. We mapped all component issues to their parent integrated 
issues (could be more than one), then sorted the issues based on the number of organi- 
zations associated with each issue. Finally, we selected the 15 most common integrated 
issues to be our set of category labels. The resulting dataset contains 1,870 organizations 
that are associated with 15 environmental issue categories: Air & Climate, Biodiversity, 
Common Pool Resources, Disasters, Food Production, Governance, Institutions, Land 
& Soil, Physical Infrastructure, Protected Areas, Public Health, Sociocultural Systems, 
Technology, Wastes & Pollution, and Water. Table 1 shows the categories, the number 
and percentage of organizations that each category is associated with, and an example 
organization for each category. 

2.2.  Standard Industrial Classification (SIC) Task and Dataset 

Standard Industrial Classification (SIC) codes were created by the U.S. government to 
categorize businesses according to the industry that they serve and operate in. We be- 
lieve that incorporating industry classification such as SIC codes, which remain in use al- 
though replaced by the North American Industry Classification System in 1997, into food 
system ontologies is valuable for understanding the nature of an organization’s activi- 

 
 
 
 
 
May 2023 

ties and its economic and logistical relationships with other organizations (e.g., supply 
chain relationships). Although the SIC codes for many organizations can be looked up 
in government or business databases, having an AI model that can automatically assign 
SIC codes to an organization could be used to 1) categorize newly formed organizations 
quickly, without waiting for official databases to be updated, 2) categorize organizations 
outside of the U.S. with respect to these standardized industry codes, and 3) maintain the 
currency of a knowledge graph by automatically reclassifying organizations on a regular 
basis (say, annually) to reflect changes that an organization has made in its activities (e.g., 
expansion of business activities, or retraction). Toward this end, we define a second task 
called SIC code classification, which requires the NLP model to assign one or multiple 
SIC code category labels to an organization. 

The SIC codes are 4 digits long and are hierarchical. These digits represent the Divi- 
sion, Major Group, Industry Group, and Industry of an entity, respectively. For example, 
a company with code 0116 would belong to the “Soybeans” industry within the “Cash 
Grains” industry group and the “Agricultural Production Crops” major group. This sys- 
tem allows us to study companies at different levels of granularity by simply grouping 
companies according to the first 1,2,3 or 4 digits of their SIC codes. 

To train a NLP model for this task, we need examples of organizations and their asso- 
ciated SIC codes. Conveniently, the Securities and Exchange Commission (SEC) main- 
tains a publicly accessible database of U.S. companies called EDGAR. This database 
contains SIC codes for companies as well as their SEC filing reports. Of particular in- 
terest are the 10-K and 20-F forms, which provide a company’s annual report. These 
forms detail a range of information related to the company’s operations in the past year, 
including financial, legal, risk factors, and other information that allows stakeholders to 
assess the state of the business. So we downloaded these reports as well, as a source of 
textual information that the NLP model could potentially use. Specifically, we collected 
the natural language text from the “Item 1: Business” section of a company’s most recent 
10-K filing, as well as the company’s official SIC code. In the EDGAR database there is 
only one SIC code per company, despite the fact that in principle a company could have 
multiple codes associated with it. 

To collect company information, we started with a list of all 816,115 companies in 
the database and their Central Index Key (CIK) number, which is provided by the SEC.8 
Then we queried each CIK number in EDGAR to collect the name, SIC, SIC description 
and their 10-k forms. We focused our research on the 36,715 organizations that had all 
of these fields. We observed that the distribution of the data is highly skewed, with many 
SIC codes containing very few instances. This may be partly due to the fact that organi- 
zations are forced to pick a SIC/NAICS code when incorporating their organization, but 
business models change, and they may be involved in multiple lines of business that can 
be reflected by multiple SIC/NAICS codes. 

For our experiments, we created a balanced subset of the SEC data so that we have 
the same amount of information for each category and can fairly compare the perfor- 
mance of our NLP models across categories. We decided to focus on just the first 2 digits 
of each SIC code as the category labels, which helps to minimize data sparsity (because 
many of the longer 3-digit and 4-digit codes have relatively few organizations associated 
with them) and provides a useful high-level view of each company’s general type of busi- 

8https://www.sec.gov/Archives/edgar/cik-lookup-data.txt 

 
 
 
May 2023 

SIC  Description 

10  Metal Mining 

13 

20 

27 

28 

34 

35 

36 

37 

Oil and Gas Extraction 

Food and Kindred Products 

Printing, Publishing and Allied Industries 

Chemicals and Allied Products 

Fabricated Metal Products 

Industrial and Commercial Machinery ... 

Electronic 

Transportation  Equipment 

38  Measuring, Photographic, Medical, 

48 

49 

Communications 

Electric, Gas and Sanitary Services 

50  Wholesale Trade - Durable Goods 

51  Wholesale Trade - Nondurable Goods 

SIC  Description 

58 

Eating and Drinking Places 

59  Miscellaneous Retail 

60 

61 

62 

63 

65 

67 

70 

73 

79 

80 

87 

Depository Institutions 

Nondepository Credit Institutions 

Security 

Insurance Carriers 

Real Estate 

Holding and Other Investment Offices 

Hotels, Rooming Houses, Camps ... 

Business  Services 

Amusement and Recreation Services 

Health Services 

Engineering, Accounting, Research ... 

Table 2.  Descriptions for the most common SIC codes. 

ness operations. To create the dataset for our experiments, we selected all of the 2-digit 
SIC codes that have at least 200 associated companies, which resulted in the set of 27 
SIC codes shown in Table 2. Finally, we randomly sampled 200 companies for each of 
these codes, which created a balanced dataset containing 5,400 organizations with their 
2-digit SIC codes. 

2.3.  Organization Information Collection via Google Search 

Our goal is to create a classification model that is given a text about an organization as 
input and produces category labels for that organization as output. So a key question is: 
where can we find text that describes an organization? We initially considered using the 
official website for an organization as the input text because websites often contain in- 
formation about an organization’s initiatives, policies and practices. However, 1) some 
organizations do not have an official website, and 2) many websites do not allow auto- 
mated crawling, and in that case we cannot use a web scraper to automatically extract 
the text from the website. Of the 2,165 organizations in the environmental issues dataset, 
we found that only about half of the organizations’ websites could be crawled. 

As an alternative, we decided to use the Google Search Engine to retrieve textual 
information about organizations. For each organization, we give the organization’s name 
as a search query to the Google Search API and extract the first 10 returned results. The 
search results from Google provide several types of information, such as organic results, 
knowledge graph, local results, related questions, etc. Organic results are the algorith- 
mically calculated query results (as opposed to advertisements) that most users typically 
read, which includes the title, link, and a text “snippet” for each retrieved web page. We 
use the text snippet, which is the small block of text that appears underneath the link to 
a website. It is usually around 100-200 characters in length and typically provides users 
with a general description of the content of the website. For each organization, we then 
concatenate the text snippets from the top 10 retrieved websites into a single “pseudo- 
document” (PseudoDoc), which serves as the text data that we use for the organization. 
Figure 1 shows the pipeline for creating the PseudoDoc for an organization using the 
Google Search API. 

 
 
 
 
 
 
 
May 2023 

snippet 

…… 

The cattle at 5 Bar Beef have an 
idyllic life grazing on a 
multigenerational family ranch in 
east Orange County and are helping 
support wildfire mitigation and ... 

5 Bar Angus Ranch raises premium 
quality Angus Bulls for sale as well as 
home grown angus beef for sale. 
Angus cattle are proven in herd 
genetics and meat ... 

5 Bar Beef is a family ranch in 
Southern California dedicated to 
providing the best-quality and best- 
tasting 100% grass-fed and pasture- 
raised beef. 

5BarBeef. @5_beef. 100% Grass-fed 
beef, pasture raised holistically in 
Orange County, California. ... 
Manassero Farms is now carrying 5 
Bar Beef! 

...... 

Top N Search Results 

Collect “Snippets” 

Figure 1.  Download Google snippets for each organization as its textual representation. 

As we will show in Section 4, using these text snippets from retrieved web pages 
produced reasonably good classification models. We observed two things that explain 
why Google Search produced useful textual information about organizations. First, when 
an organization did have an official website, Google typically found it and ranked it as 
the #1 or #2 top hit. So in many cases, the text snippets returned for an organization 
include text from the organization’s own website. Second, the other websites retrieved 
by Google for an organization usually either (a) discussed the organization, or (b) dis- 
cussed similar organizations (i.e., organizations with similar names). Consequently, the 
text snippets from those websites often contained relevant information that could be use- 
ful for inferring the organization’s activities and mission. By using text snippets from 
10 retrieved websites, each pseudo-document contained information about the organiza- 
tion (or similar organizations) that originated from multiple sources, which collectively 
painted a good picture of the nature of the organization. 

3.  Methods 

3.1.  Background: Pre-trained Language Models 

Pretrained language models, such as BERT [8] and GPT-2 [11], have achieved great suc- 
cess in the field of Natural Language Processing because of their ability to absorb a lot 
of information about language from massive amounts of text, without any human su- 
pervision. These large language models are neural network (“deep learning”) architec- 
tures that can be additionally trained for a specific application task using a method called 
fine-tuning, where the model is provided with human-labeled data for the application 
task. During fine-tuning, the model combines the general knowledge about language that 
it previously absorbed during pre-training with the new information in the task-specific 
data. Fine-tuned models can perform very well for many application tasks, even when 
provided with only a small amount of task-specific data. 

For this work, we use a well-known pre-trained language model called BERT [8]. 
BERT has been pre-trained on 3.3 billion English words from Wikipedia and the Google 

 
 
 
 
 
 
 
 
 
 
May 2023 

Air & Climate 

  0.1 

Biodiversity 

  0.6 

... 

Water 

0.1 

BERT 

[CLS] 

Tok 1

...

Tok N 

  [SEP] 

  Tok 1 

... 

  Tok M 

Organization Text 

Label Description 

... 

Figure 2.  OrgModel-2 model architecture and an illustration example for organization 5 Bar Beef. 

Books text collection. We use the base variant of BERT which has 12 layers (transformer 
blocks),  768  hidden  units  (hidden  size),  and  12  self-attention  heads.  The  BERT-base 
model consists of approximately 110 million parameters (learned weights), offering a 
good balance between computational efficiency and performance across a wide range of 
natural language processing tasks. 

3.2.  Classification Models 

We created two different designs for our classification models — one basic fine-tuning 
design and one slightly more complex design. The first model, OrgModel-1, takes the 
text associated with an organization as input and fine-tunes the BERT language model 
with the “gold” training data (labeled examples) for the task. Specifically, we follow the 
common practice of using the embedding vector of the [CLS] token for the classification 
task and stacking a linear classification layer on top of BERT’s last layer, which produces 
an n-dimensional output vector, where n is the number of categories for the task. 

For  the  SIC  code  classification  task,  we  use  cross-entropy  loss  for  training.  The 
environmental issues classification task is slightly different because it is a multi-label 
problem  (an  organization  can  be  associated  with  more  than  one  issue),  so  we  further 
apply a sigmoid function to transform each dimension value to a number between 0 and 
1. If the number is ≥ 0.5, the system predicts Yes (meaning the organization belongs 
to this environmental issue category), otherwise No. We use binary cross-entropy loss 
during training. 

The second model, OrgModel-2, takes advantage of an additional source of infor- 
mation: the model is provided with expert-written descriptions for each category as in- 
put, along with the text associated with an organization. This provides the model with a 
definition for each category so that the model can potentially produce a richer semantic 
representation of the categories to help find the best match with an organization. 

Specifically, suppose the organization text is denoted by oi, and each category de- 
scription is denoted by d j  ( j = 1..n). We created n sequence pairs ⟨oi, d1⟩, ⟨oi, d2⟩, ..., 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
May 2023 

⟨oi, dn⟩ and asked a system to assign a number between 0 and 1 to each pair ⟨oi, d j⟩ 
representing the strength of association between organization oi and category d j. The 
OrgModel-2 model takes the text for an organization and n label descriptions and pre- 
dicts a strength value for each ⟨oi, d j⟩ pair. Figure 2 depicts the full architecture of the 
OrgModel-2 model. 

4.  Evaluation 

4.1.  Evaluation Metrics 

To  evaluate  the  ability  of  our  NLP  models  to  classify  organizations,  we  report  three 
evaluation metrics that are commonly used in the NLP research community: precision, 
recall and f1-score. Intuitively, precision captures the accuracy when predicting a cat- 
egory, while recall captures coverage for recognizing instances of the category. These 
metrics are defined with respect to a specific category C and computed as: precision = 
TP/(TP + FP), recall = TP/(TP + FN), f 1-score = 2/(precision−1 + recall−1), where 
TP (true positive) is the number of true instances of C that were correctly identified by 
the model; FP (false positive) is the number of instances that the model predicted as C 
but do not belong to C; FN (false negative) is the number of true instances of C that were 
not identified by the model. The f1-score is the harmonic mean of precision and recall, 
which is an average over precision and recall that also reflects how balanced they are 
(more balanced is better). 

In addition, we report micro and macro averaged scores for each evaluation met- 
ric, which provides an overall view of performance across the different categories. The 
micro average score aggregates the results for all instances (across all classes) and then 
calculates the metric. This gives more weight to the most frequent classes because they 
have more instances. In contrast, the macro average score calculates the metric for each 
class separately and then averages the results, which gives equal weight to all classes. 
For example, micro and macro averaged precision are defined as: micro  precision = 
∑n  TPi/(∑n    TPi + ∑n    FPi), macro precision = 1 ∑n    TPi/(TPi + FPi), where i in- 

i=1 

i=1 

i=1 

n    i=1 

dicates the i-th class, and n is the total number of class labels. 

4.2.  Results and Analysis 

4.2.1.  Environmental Issues Classification Results 

For our experiments, the 1,870 organizations in the environmental issues dataset were 
split into 1,370 for training and 500 for testing. Table 3 shows the experimental results 
for each environmental issue category. 

OrgModel-1  vs.  OrgModel-2  Our  OrgModel-1  system  achieved  76.8%  micro- 
averaged f1-score and 69.6% macro-averaged f1-score. By adding the environmental is- 
sue category descriptions, the OrgModel-2 achieved better performance with a 80.1% 
micro-averaged  f1  and  74.0%  macro-averaged  f1.  Overall,  we  see  good  precision  for 
most of the categories (87% micro-average), but recall is lower (74% micro-average). 

If we take a closer look at the individual categories, we can see that OrgModel-2 
achieved the best performance (>80% f1-score) for Biodiversity, Governance, Physical 

 
 
 
 
 
 
 
 
May 2023 

OrgModel-1 

OrgModel-2 

Precision 

Recall 

F1-score  

Precision 

Recall 

F1-score 

Air & Climate 

Biodiversity 

Common Pool Resources 

Disasters 

Food Production 

Governance 

Institutions 

Land & Soil 

Physical Infrastructure 

Protected Areas 

Public Health 

Sociocultural  Systems 

Technology 

Wastes & Pollution 

Water 

Micro Average 

Macro Average 

69.2 

80.6 

57.1 

85.7 

66.7 

97.5 

85.9 

74.4 

94.0 

77.2 

72.0 

83.3 

100.0 

83.7 

93.2 

84.5 

81.4 

32.1 

84.5 

40.0 

44.4 

47.3 

88.6 

62.6 

75.6 

83.0 

57.9 

40.9 

56.6 

66.7 

71.1 

79.2 

70.4 

62.0 

43.9 

82.5 

47.1 

58.5 

55.3 

92.9 

72.4 

75.0 

88.1 

66.2 

52.2 

67.4 

80.0 

76.9 

85.6 

76.8 

69.6 

75.0 

85.6 

70.0 

68.4 

81.2 

100.0 

85.5 

77.9 

95.4 

81.7 

58.3 

85.3 

100.0 

87.4 

94.4 

87.2 

83.1 

53.6 

80.4 

46.7 

48.1 

60.2 

94.3 

66.4 

72.5 

88.8 

64.5 

47.7 

54.7 

71.8 

76.3 

81.4 

74.2 

67.2 

62.5 

82.9 

56.0 

56.5 

69.1 

97.1 

74.7 

75.1 

92.0 

72.1 

52.5 

66.7 

83.6 

81.5 

87.4 

80.1 

74.0 

Table 3.  Environmental issues classification: OrgModel-1 and OrgModel-2 performance for each category. 

Infrastructure, Technology, Wastes & Pollution, and Water. The model struggled the most 
(< 60% f1 score) for Common Pool Resources, Disasters, and Public Health. 

Data Sparsity  We investigated whether the number of instances has an impact on the 
model performance. We focused on the 5 least common categories which are associated 
with fewer than 10 percent of all organizations in the dataset: Public Health, Disasters, 
Common Pool Resources, Air & Climate and Technology; and the 5 most common cate- 
gories which are associated with more than 20 percent of all organizations: Water, Phys- 
ical Infrastructure, Wastes & Pollution, Biodiversity, and Land & Soil. Figure 3 shows a 
plot of their f1-scores for both OrgModel-1 and OrgModel-2. Comparing rare categories 
(circles) with common categories (squares), we can see that the latter perform better with 
both OrgModel-1 and OrgModel-2. OrgModel-1’s average f1-score of the common cate- 
gories is 81.6% but the average f1-score of rare categories is only 56.3%. OrgModel-2’s 
average f1-score of the common categories is 83.8% and the average f1-score of rare 
categories is 62.2%. This huge gap indicates that performance on the rare categories will 
likely improve if we can get more human-annotated data. 

Component-Integrated Mapping  During our dataset construction for environmental 
issue  classification,  we  map  component  issues  to  integrated  issues  to  focus  on  a  lim- 
ited set of common labels. However, this many-to-many mapping can create some prob- 
lems. For example, the component issue Land Use is associated with the integrated issue 
Food Production. Yet not all organizations tagged with Land Use should be tagged with 
Food Production, e.g., organizations “Air Force Civil Engineer Center” and “Snowlands 
Network” don’t actually produce any food. For future work, we will consider a better 
alignment between component and integrated issues, or refine the label set by including 
component issues directly. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
May 2023 

100 

e
r
o
c
s
-
1
F

80 

60 

OrgModel-1 
OrgModel-2 

40 

T ech n olo g y 
Bio diversity 
P h ysical Infrastructure 
L an d  &  S oil 
P u blic H ealth 
D isasters 
m o n P o ol R eso urces 
A ir  &  Cli m ate 
W astes &  P ollutio n 
C o m

W ater 

Figure 3.  F1-score for each category. Circles ⃝ represent low frequency environmental issues and squares □ 
represent high frequency issues. 

4.2.2.  SIC Code Classification Results 

For the SIC code classification task, we split the 5,400 organizations into train, develop- 
ment, and test sets containing 2700, 900, and 1800 examples respectively. 

10-K Filing vs. Google PseudoDoc  Our first experiment explores the use of two dif- 
ferent types of textual data for the SIC code classification task: the Pseudo-documents 
created from Google’s retrieved text snippets, and the 10-K filing forms from the SEC 
database. We trained two different OrgModel-1 systems, one using textual data from the 
pseudo-documents and one using the 10-K filing reports. These NLP models are iden- 
tical except for the textual descriptions used in the training process. Table 4 shows that 
the model which used Google snippets as the text source for an organization strongly 
outperformed the model which used the text from 10-K forms.9 In fact, the model trained 
on Google snippets achieved a higher f1-score across every single category except for 
one (62 - Security And Commodity Brokers, Dealers, Exchanges, And Services). This 
category had the smallest difference in performance between the two models at 1.3%. 
In many cases, the model trained with Google snippets outperformed the model trained 
with 10-K forms by a significant margin leading to a 13% increase in macro-averaged 
f1-score. This approach is also more generalizable because many organizations do not 
have SEC filings. 

OrgModel-1  vs.  OrgModel-2  We  trained  both  OrgModel-1  and  OrgModel-2  with 
Google PseudoDoc texts for the SIC code classification task as well. For OrgModel-2, 
we also need a description for the category labels, and we experimented with 3 different 
types of information: 1) The shortest representation (Short) is simply the name of the 2 
digit Major Group. 2) The second representation (Tree) exploits the hierarchical nature 
of SIC codes by concatenating together the 2-digit name and the names for all the codes 
in its subtree. The motivation here is to include the specific subcategory information to 

9It is worth noting that about 4% of the organizations’ 10-K filings extracted are empty. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
May 2023 

10-K Filing 

Google PseudoDoc 

Class 

Recall 

Precision 

F1-Score  Recall 

Precision 

F1-Score 

10 
13 
20 
27 

28 
34 
35 

36 
37 
38 

48 
49 
50 

51 
58 
59 

60 
61 
62 

63 
65 
67 

70 
73 
79 

80 
87 

54.8 
67.7 
54.2 
67.1 

71.4 
38.0 
24.2 

28.5 
47.1 
63.3 

66.6 
68.9 
32.2 

28.1 
89.2 
48.4 

81.5 
70.0 
77.2 

55.9 
66.1 
49.3 

71.4 
28.0 
67.3 

73.7 
30.5 

Macro Avg 

56.4 

73.9 
66.6 
83.6 
70.4 

60.8 
45.0 
11.1 

36.6 
57.8 
61.2 

58.1 
80.9 
15.1 

13.4 
75.3 
40.7 

84.1 
71.0 
85.9 

91.0 
66.1 
50.7 

69.4 
26.6 
42.3 

70.3 
41.2 

57.4 

62.9 
67.1 
65.8 
68.8 

65.6 
41.2 
15.2 

32.1 
51.9 
62.2 

62.1 
74.4 
20.6 

18.1 
81.6 
44.2 

82.8 
70.5 
81.3 

69.3 
66.1 
50.0 

70.4 
27.3 
51.9 

72.0 
35.1 

80.2 
82.8 
77.4 
72.5 

71.7 
68.5 
46.3 

43.0 
68.8 
59.4 

73.5 
74.6 
73.6 

47.4 
86.4 
68.1 

90.6 
89.3 
75.9 

91.0 
69.5 
52.1 

85.7 
30.0 
75.7 

81.8 
54.2 

56.8 

70.0 

82.6 
84.1 
90.1 
73.7 

75.6 
52.1 
44.4 

51.6 
73.6 
75.8 

70.9 
84.1 
42.4 

41.7 
83.1 
59.2 

92.0 
85.5 
84.5 

91.0 
70.5 
52.1 

83.3 
35.0 
64.1 

84.3 
60.3 

69.9 

81.4 
83.4 
83.3 
73.1 

73.6 
59.2 
45.3 

46.9 
71.1 
66.6 

72.2 
79.1 
53.8 

44.4 
84.7 
63.3 

91.3 
87.4 
80.0 

91.0 
70.0 
52.1 

84.5 
32.3 
69.4 

83.0 
57.1 

69.9 

Table 4.  Performance of OrgModel-1 trained on different data sources. 

Label Desc. 

Precision 

Recall 

F1 

OrgModel-1 

- 

OrgModel-2 

Short 

Tree 
Long 

69.9 

47.0 

73.6 
73.6 

70.0 

69.9 

49.9 

73.6 
73.5 

46.1 

73.4 
73.1 

Table 5.  Macro average scores for OrgModel-1 and OrgModel-2 with different representations for the label 
description. 

create a richer representation of the parent category. 3) We used the plain text explanation 
(Long) of the Major Group found in the SIC manual. This is a written explanation of 
the criteria for an entity to be included in the specified Major Group. Table 5 shows the 
results. The short representation didn’t contain enough information to perform well. Be- 
tween the tree and long representations, we see similar performance in terms of f1-score. 
Comparing OrgModel-2 with tree description to OrgModel-1, OrgModel-2 achieved a 
3% increase in f1-score making it our best performing model on the SIC task. 

 
 
 
 
 
 
 
 
 
 
May 2023 

Overall,  the  classifier  achieves  reasonable  performance  across  the  different  cate- 
gories; however, there are a few categories (35, 50, 51, 67) where the performance is still 
weak, possibly due to being particularly broad and difficult to distinguish from other cat- 
egories. Yet, our model achieves greater than 70% f1-score on the majority of categories, 
illustrating the promise of using NLP models to automatically classify organizations. 

5.  Conclusion and Future Plans 

Our study has demonstrated the potential of using Natural Language Processing (NLP) 
techniques for the automatic acquisition of structured food system knowledge from un- 
structured  sources.  This  includes  the  classification  of  entities  involved  in  food  activ- 
ities,  and  their  linkage  to  social,  environmental,  and  health-related  issues.  Using  text 
snippets retrieved from Google’s search engine as a descriptive basis, our NLP mod- 
els were able to classify organizations according to environmental issue categories and 
Standard Industrial Classification (SIC) codes. Specifically, we build our models based 
on transformer-based language models. Our experimental results show that using textual 
data from Google Search achieved a better performance than using 10-K filings from 
organizations’ annual reports, which are provided by the Securities and Exchange Com- 
mission (SEC) database. We also show that by incorporating the description text of the 
environmental issue categories or SIC codes, our model can achieve better performance 
for both classification tasks. The promising results underline the applicability of this ap- 
proach to improve food ontologies as well as other intelligent food systems knowledge 
resources  with  little  to  no  human  supervision.  Our  work  illustrates  how  NLP  models 
hold the potential for a wide range of automatic categorization of food system actors and 
their activities into existing food, environment, and health system ontologies. These on- 
tologies instantiated by NLP models represent burgeoning yet powerful instruments for 
quick and efficient population of large food systems knowledge graphs with consistent 
knowledge representation. 

Our  research  opens  the  door  to  providing  a  critical  component  to  the  design  and 
creation of reusable cyberinfrastructure components capable of addressing major social- 
environmental issues like scaling climate actions in food systems. Other components will 
include the development of additional technological, knowledge, and relational infras- 
tructures that will build on recent advances in data, modeling, and management. Linking 
these components together affords the opportunity to make leading edge insights, tools, 
and practical guidance available to action partners across the food system. 

Acknowledgments 

We want to thank the anonymous reviewers for their valuable comments. This research 
was supported in part by the ICICLE project through NSF award OAC 2112606 and the 
Canadian Institutes of Health Research (CIHR) FRN 177412. 

References 

[1]  Hollander AD, Hoy C, Huber PR, Hyder A, Lange MC, Latham A, Quinn JF, Rig- 
gle CM, Tomich TP. Toward smart foodsheds: Using stakeholder engagement to 

 
 
 
 
 
May 2023 

improve informatics frameworks for regional food systems. Annals of the Ameri- 
can Association of Geographers. 2020. DOI: 10.1080/24694452.2019.1662764 
[2]  Boulos MN, Yassine A, Shirmohammadi S, Namahoot CS, Bru¨ckner M. Towards 
an “Internet of Food”: food ontologies for the internet of things. Future Internet. 
2015. 

[3]  Dooley D, Andre´s-Herna´ndez L, Bordea G, Carmody L, Cavalieri D, Chan L, 
Castellano-Escuder P, Lachat C, Mougin F, Vitali F, Yang C. Obo foundry food 
ontology interconnectivity. InCEUR Workshop Proceedings. 2021. 

[4]  Dooley  DM,  Griffiths  EJ,  Gosal  GS,  Buttigieg  PL,  Hoehndorf  R,  Lange  MC, 
Schriml LM, Brinkman FS, Hsiao WW. FoodOn: a harmonized food ontology to 
increase global food traceability, quality control and data integration. npj Science 
of Food. 2018. 

[5]  D’Odorico P, Carr JA, Davis KF, Dell’Angelo J, Seekell DA. Food inequality, 

injustice, and rights. BioScience. 2019. 

[6]  Fanzo J, Arabi M, Burlingame B, Haddad L, Kimenju S, Miller G, Nie F, Recine 
E, Serra-Majem L, Sinha D. Nutrition and food systems. A report by the high level 
panel of experts on food security and nutrition of the committee on world food 
security. 2017. 

[7]  Fanzo J, Davis C. Global food systems, diets, and nutrition. Springer International 

Publishing. 2021. 

[8]  Devlin J, Chang MW, Lee K, Toutanova K. BERT: Pre-training of deep bidirec- 
tional transformers for language understanding. In Proceedings of the 2019 Con- 
ference of the North American Chapter of the Association for Computational Lin- 
guistics: Human Language Technologies. 2019. 

[9]  Kotiaho  JS,  Halme  P.  The  IPBES  assessment  report  on  land  degradation  and 

restoration. IPBES Secretariat, UN Campus: Bonn, Germany. 2018. 

[10]  Nicole´tis E´ , Termine P. Reducing inequalities for food security and nutrition - 
HLPE  consultation  on  the  report’s  scope.  Global  Forum  on  Food  Security  and 
Nutrition (FSN Forum). 2022. 

[11]  Radford A, Wu J, Child R, Luan D, Amodei D, Sutskever I. Language models are 

unsupervised multitask learners. OpenAI blog. 2019. 

[12]  Smith B. Ontology. In Blackwell Guide to the Philosophy of Computing and In- 

formation, edited by Luciano Floridi. Oxford: Blackwell. 2003. 

[13]  Tomich TP, Hoy C, Dimock MR, Hollander AD, Huber PR, Hyder A, Lange MC, 
Riggle CM, Roberts MT, Quinn JF. Why do we need food systems informatics? 
Introduction to this special collection on smart and connected regional food sys- 
tems. Sustainability. 2023. 

[14]  FAO, IFAD, UNICEF, WFP and WHO. The state of food security and nutrition in 
the world 2021. Transforming food systems for food security, improved nutrition 
and affordable healthy diets for all. Rome, FAO. 2021. DOI: 10.4060/cb4474en 

[15]  United Nations Environment Programme. Emissions gap report 2022: The closing 
window - Climate crisis calls for rapid transformation of societies. Nairobi. 2022. 

 
 
","May 2023 Classifying Organizations for Food System Ontologies using Natural Language Processing Tianyu JIANG a , Sonia VINOGRADOVA b , Nathan STRINGHAM a , E. Louise EARL b , Allan D. HOLLANDER c , Patrick R. HUBER c , Ellen RILOFF a,1 , R. Sandra SCHILLO b , Giorgio A. UBBIALI d , Matthew LANGE e , a University of Utah b University of Ottawa c University of California , Davis d University of Milan e IC-FOODS ORCiD ID : E. Louise Earl https : //orcid.org/0000-0002-5646-0132 , R. Sandra Schillo https : //orcid.org/0000-0002-3468-0206 , Giorgio A. Ubbiali https : //orcid.org/0000-0001-7872-1770 , Matthew Lange https : //orcid.org/0000-0002-6148-7962 Abstract . Our research explores the use of natural language processing ( NLP ) methods to automatically classify entities for the purpose of knowledge graph pop- ulation and integration with food system ontologies . We have created NLP models that can automatically classify organizations with respect to categories associated with environmental issues as well as Standard Industrial Classification ( SIC ) codes , which are used by the U.S. government to characterize business activities . As in- put , the NLP models are provided with text snippets retrieved by Google ’ s search engine for each organization , which serves as a textual description of the organi- zation that is used for learning . Our experimental results show that NLP models can achieve reasonably good performance for these two classification tasks , and they rely on a general framework that could be applied to many other classification problems as well . We believe that NLP models represent a promising approach for automatically harvesting information to populate knowledge graphs and aligning the information with existing ontologies through shared categories and concepts . Keywords . food system ontologies , classification models , natural language processing , SIC , sustainability issues , unstructured data 1 . Introduction Food systems include activities and relationships that are involved with the production , transport , and consumption of food , and thus are linked to a wide variety of natural and human systems ( Tomich et al . [ 13 ] ) . Their extensive nature can have dramatic impacts 1Corresponding Author : Ellen Riloff ( riloff @ cs.utah.edu ) . May 2023 on these natural and human systems ( IPBES [ 9 ] , UNEP [ 15 ] ) . Conversely , food systems are vulnerable to changes in these other systems . Food activities also show a pivotal role in fostering human social and health-related issues . For instance , inequalities and injus- tices exist across the whole global food supply chain , as well as within related sectors ( D ’ Odorico et al . [ 5 ] , Nicole´tis and Termine [ 10 ] ) . To date , hunger , malnutrition , and micronutrient deficiencies , just to cite a few , still largely threaten humanity worldwide ( Fanzo et al . [ 6 ] , Fanzo and Davis [ 7 ] , UNICEF [ 14 ] ) . As our world becomes more interconnected and interdependent , ontologies become useful ways of categorizing and relating information together . This is especially appli- cable to food systems , where data access , interoperability , and reusability are essential to deal with the interrelated issues arising from food systems activities . An ontology is a “ formal theory ” which provides a “ commonly accepted ” dictionary of terms , sup- ported by a “ canonical syntax ” and a set of axioms , for a knowledge domain of interest ( Smith [ 12 ] ) . In doing so , an ontology offers a common semantic framework for that domain of knowledge ( Smith [ 12 ] , Hollander et al . [ 1 ] ) . Thus , an ontology fosters data access , interoperability , and reusability across several disparate resources , which employ that ontology as a common reference semantic standard ( Hollander et al . [ 1 ] ) . Nowa- days , several ontologies focusing on food , health , and related aspects have been devel- oped ( Boulos et al . [ 2 ] , Dooley et al . [ 3 ] ) . Here , we just cite a few noteworthy ones as examples : 1 ) AGROVOC2 is a three-decade-long well-established “ multilingual the- saurus ” , addressing food and related domains of interest ( Boulos et al . [ 2 ] ) . It belongs to the United Nations Food and Agriculture Organisation ( FAO ) . 2 ) The Agronomy On- tology AgrO3 was developed within the frame of the CGIAR Platform for Big Data in Agriculture , and which proposes a vocabulary of terms , covering “ agronomic manage- ment practices , implements , and variables used during agronomic experiments ” ( Dooley et al . [ 3 ] ) . 3 ) The Compositional Dietary Nutrition Ontology CDNO4 presents terms re- lated to “ nutritional attributes from crops , livestock , and fisheries that contribute to hu- man diet and which are referenced in precision food commodity laboratory analytics ” ( Dooley et al . [ 3 ] ) . 4 ) The Food Ontology FoodOn5 provides a lexicon about “ basic raw food source ingredients , process terms for packaging , cooking , and preservation , and an upper-level variety of product type schemes under which food products can be catego- rized ” . FoodOn stands out as a fundamental ontology in addressing food-related aspects ( Dooley et al . [ 4 ] ) . Further , FoodOn aims to state the lingua franca within the domain of food , for sharing and reusing food-related information both by humans and machines ( Dooley et al . [ 4 ] ) . Despite the availability of food-health ontologies , the envisaged data access , interoperability and reusability across food industries and other food-related sec- tors , as we claimed above , appears to have not been reached yet ( Tomich et al . [ 13 ] ) . In this paper , we present new research that uses artificial intelligence ( AI ) technol- ogy to automatically categorize organizations , ultimately for the purpose of linking them into food system ontologies . Our eventual goal is to automatically populate large knowl- edge graphs of information related to agriculture and food systems , where the concepts in the graph are aligned with well-established ontologies to ensure that the knowledge will be represented consistently and aligned with other resources and systems that rely on the 2https : //www.fao.org/agrovoc/ 3https : 4https : //cdno.info/ 5https : //github.com/FoodOntology/foodon/ May 2023 same ontological frameworks . Populating knowledge graphs by hand is time-consuming and expensive , so AI technology offers the opportunity to automatically harvest infor- mation much more quickly and efficiently . Specifically , we focus on two classification tasks related to organizations . We aim to categorize organizations based on 1 ) a set of environmental issues that are relevant to environmental planning and food systems , and 2 ) standard industrial classification ( SIC ) codes6 , which the U.S. government assigns to businesses to categorize the nature of their activities . SIC codes are analogous to North American Industry Classification System ( NAICS ) codes , which are used across North America . We have designed natural lan- guage processing ( NLP ) models that read text associated with an organization to auto- matically assign the organization to categories for these two tasks . In the following sec- tions , we describe the classification tasks in more detail , explain how we collect relevant texts for the NLP models to use , present the NLP technology underlying the classification models , and show experimental results for the two classification tasks . 2 . Classification Tasks & Datasets 2.1 . Environmental Issues Classification Task and Dataset There is a large amount of information currently available concerning the state of the environment . Around the world , many organizations are collecting and analyzing data . However , there remains a major gap in our ability to connect these data sources and make them “ smart ” . They typically use different formats and vocabularies , rendering them un- able to be used together . The conservation community lacks an informatics backbone to begin linking people and data in ways that enhance our capacity for informed deci- sion making in our effort to conserve and enhance the Earth ’ s ecosystems . This need is especially crucial as we enter an unprecedented era of rapid environmental change . One key question in environmental planning , food systems , and many other contexts is “ Who is doing what where ? ” . “ Who ” can be people or organizations , “ what ” may be projects or other activities , and “ where ” could refer to many kinds of geographies . To help provide machine-readable answers to this question , Hollander et al . [ 1 ] developed an ontology called “ PPOD ” ( People , Projects , Organizations , and Datasets ) .7 This ontol- ogy formally describes the characteristics of and relationships between these classes of information . Members of our team have instantiated the PPOD ontology with information con- cerning the conservation of working landscapes in California . This knowledge graph ( KG ) contains over 2,000 organizations which were identified and collected in an ad hoc manner through an array of online searches using terms such as “ conservation ” , “ bio- diversity ” , “ grazing ” , and “ water supply ” . Each organization is associated with multi- ple attributes that describe its structure and mission , such as hasOrgType , hasOrgActiv- ity , and issues . The “ issues ” attribute describes potential environmental issues associated with the organization . PPOD has pre-defined 44 high-level environmental issues called “ integrated issues ” , and 325 more fine-grained environmental issues called “ component issues ” . The ontology provides a detailed textual description for each issue label and 6https : //www.osha.gov/data/sic-manual 7https : //github.com/PPODschema May 2023 Category Water Physical Infrastructure Wastes & Pollution Biodiversity Land & Soil Food Production Institutions Governance Protected Areas Sociocultural Systems Public Health Disasters Common Pool Resources Air & Climate Technology # of Organizations % Percentage Example Organization 845 702 578 556 535 393 345 274 253 231 179 162 128 126 122 39.0 32.4 26.7 25.7 24.7 18.2 15.9 12.7 11.7 10.7 8.3 7.5 5.9 5.8 5.6 American Rivers Rebuild NorthBay Foundation Heal the Ocean Feather River Land Trust Agricultural Research Service American Grassfed Association Southern California Edison Merced County American Forest Resource Council Enterprise Rancheria California Department of Public Health Tahoe Fire & Fuels Team Sustainable Conservation Irvine Global Warming Group CDFW Data and Technology Division Table 1 . Examples of environmental issues and how many organizations each issue is associated with . The last column shows an example organization labeled with each issue category . the relation between integrated issues and component issues . For example , component issues “ Air Pollution ” , “ Air Quality ” , “ Greenhouse Gas Mitigation ” and “ Greenhouse Gas Emissions ” are children of the integrated issue “ Air & Climate ” , which is described as “ GHG emissions , ozone layer depletion , air quality , climate change influenced and extreme weather events , shifts in growing zones for key crops due to climate change. ” Expert opinion was used to associate each organization with one or more issues . We define a task based on the PPOD ontology called environmental issues classi- fication . Given an organization , the task requires that the NLP model assign one or mul- tiple environmental issue category labels to the organization that describe the organi- zation ’ s activities and/or mission . The NLP model needs to be trained with a reasonable number of examples for each category , so we started with the most common categories in the existing PPOD data . We mapped all component issues to their parent integrated issues ( could be more than one ) , then sorted the issues based on the number of organi- zations associated with each issue . Finally , we selected the 15 most common integrated issues to be our set of category labels . The resulting dataset contains 1,870 organizations that are associated with 15 environmental issue categories : Air & Climate , Biodiversity , Common Pool Resources , Disasters , Food Production , Governance , Institutions , Land & Soil , Physical Infrastructure , Protected Areas , Public Health , Sociocultural Systems , Technology , Wastes & Pollution , and Water . Table 1 shows the categories , the number and percentage of organizations that each category is associated with , and an example organization for each category . 2.2 . Standard Industrial Classification ( SIC ) Task and Dataset Standard Industrial Classification ( SIC ) codes were created by the U.S. government to categorize businesses according to the industry that they serve and operate in . We be- lieve that incorporating industry classification such as SIC codes , which remain in use al- though replaced by the North American Industry Classification System in 1997 , into food system ontologies is valuable for understanding the nature of an organization ’ s activi- May 2023 ties and its economic and logistical relationships with other organizations ( e.g. , supply chain relationships ) . Although the SIC codes for many organizations can be looked up in government or business databases , having an AI model that can automatically assign SIC codes to an organization could be used to 1 ) categorize newly formed organizations quickly , without waiting for official databases to be updated , 2 ) categorize organizations outside of the U.S. with respect to these standardized industry codes , and 3 ) maintain the currency of a knowledge graph by automatically reclassifying organizations on a regular basis ( say , annually ) to reflect changes that an organization has made in its activities ( e.g. , expansion of business activities , or retraction ) . Toward this end , we define a second task called SIC code classification , which requires the NLP model to assign one or multiple SIC code category labels to an organization . The SIC codes are 4 digits long and are hierarchical . These digits represent the Divi- sion , Major Group , Industry Group , and Industry of an entity , respectively . For example , a company with code 0116 would belong to the “ Soybeans ” industry within the “ Cash Grains ” industry group and the “ Agricultural Production Crops ” major group . This sys- tem allows us to study companies at different levels of granularity by simply grouping companies according to the first 1,2,3 or 4 digits of their SIC codes . To train a NLP model for this task , we need examples of organizations and their asso- ciated SIC codes . Conveniently , the Securities and Exchange Commission ( SEC ) main- tains a publicly accessible database of U.S. companies called EDGAR . This database contains SIC codes for companies as well as their SEC filing reports . Of particular in- terest are the 10-K and 20-F forms , which provide a company ’ s annual report . These forms detail a range of information related to the company ’ s operations in the past year , including financial , legal , risk factors , and other information that allows stakeholders to assess the state of the business . So we downloaded these reports as well , as a source of textual information that the NLP model could potentially use . Specifically , we collected the natural language text from the “ Item 1 : Business ” section of a company ’ s most recent 10-K filing , as well as the company ’ s official SIC code . In the EDGAR database there is only one SIC code per company , despite the fact that in principle a company could have multiple codes associated with it . To collect company information , we started with a list of all 816,115 companies in the database and their Central Index Key ( CIK ) number , which is provided by the SEC.8 Then we queried each CIK number in EDGAR to collect the name , SIC , SIC description and their 10-k forms . We focused our research on the 36,715 organizations that had all of these fields . We observed that the distribution of the data is highly skewed , with many SIC codes containing very few instances . This may be partly due to the fact that organi- zations are forced to pick a SIC/NAICS code when incorporating their organization , but business models change , and they may be involved in multiple lines of business that can be reflected by multiple SIC/NAICS codes . For our experiments , we created a balanced subset of the SEC data so that we have the same amount of information for each category and can fairly compare the perfor- mance of our NLP models across categories . We decided to focus on just the first 2 digits of each SIC code as the category labels , which helps to minimize data sparsity ( because many of the longer 3-digit and 4-digit codes have relatively few organizations associated with them ) and provides a useful high-level view of each company ’ s general type of busi- 8https : May 2023 SIC Description 10 Metal Mining 13 20 27 28 34 35 36 37 Oil and Gas Extraction Food and Kindred Products Printing , Publishing and Allied Industries Chemicals and Allied Products Fabricated Metal Products Industrial and Commercial Machinery ... Electronic Transportation Equipment 38 Measuring , Photographic , Medical , 48 49 Communications Electric , Gas and Sanitary Services 50 Wholesale Trade - Durable Goods 51 Wholesale Trade - Nondurable Goods SIC Description 58 Eating and Drinking Places 59 Miscellaneous Retail 60 61 62 63 65 67 70 73 79 80 87 Depository Institutions Nondepository Credit Institutions Security Insurance Carriers Real Estate Holding and Other Investment Offices Hotels , Rooming Houses , Camps ... Business Services Amusement and Recreation Services Health Services Engineering , Accounting , Research ... Table 2 . Descriptions for the most common SIC codes . ness operations . To create the dataset for our experiments , we selected all of the 2-digit SIC codes that have at least 200 associated companies , which resulted in the set of 27 SIC codes shown in Table 2 . Finally , we randomly sampled 200 companies for each of these codes , which created a balanced dataset containing 5,400 organizations with their 2-digit SIC codes . 2.3 . Organization Information Collection via Google Search Our goal is to create a classification model that is given a text about an organization as input and produces category labels for that organization as output . So a key question is : where can we find text that describes an organization ? We initially considered using the official website for an organization as the input text because websites often contain in- formation about an organization ’ s initiatives , policies and practices . However , 1 ) some organizations do not have an official website , and 2 ) many websites do not allow auto- mated crawling , and in that case we can not use a web scraper to automatically extract the text from the website . Of the 2,165 organizations in the environmental issues dataset , we found that only about half of the organizations ’ websites could be crawled . As an alternative , we decided to use the Google Search Engine to retrieve textual information about organizations . For each organization , we give the organization ’ s name as a search query to the Google Search API and extract the first 10 returned results . The search results from Google provide several types of information , such as organic results , knowledge graph , local results , related questions , etc . Organic results are the algorith- mically calculated query results ( as opposed to advertisements ) that most users typically read , which includes the title , link , and a text “ snippet ” for each retrieved web page . We use the text snippet , which is the small block of text that appears underneath the link to a website . It is usually around 100-200 characters in length and typically provides users with a general description of the content of the website . For each organization , we then concatenate the text snippets from the top 10 retrieved websites into a single “ pseudo- document ” ( PseudoDoc ) , which serves as the text data that we use for the organization . Figure 1 shows the pipeline for creating the PseudoDoc for an organization using the Google Search API . May 2023 snippet …… The cattle at 5 Bar Beef have an idyllic life grazing on a multigenerational family ranch in east Orange County and are helping support wildfire mitigation and ... 5 Bar Angus Ranch raises premium quality Angus Bulls for sale as well as home grown angus beef for sale . Angus cattle are proven in herd genetics and meat ... 5 Bar Beef is a family ranch in Southern California dedicated to providing the best-quality and best- tasting 100 % grass-fed and pasture- raised beef . 5BarBeef . @ 5_beef . 100 % Grass-fed beef , pasture raised holistically in Orange County , California . ... Manassero Farms is now carrying 5 Bar Beef ! ...... Top N Search Results Collect “ Snippets ” Figure 1 . Download Google snippets for each organization as its textual representation . As we will show in Section 4 , using these text snippets from retrieved web pages produced reasonably good classification models . We observed two things that explain why Google Search produced useful textual information about organizations . First , when an organization did have an official website , Google typically found it and ranked it as the # 1 or # 2 top hit . So in many cases , the text snippets returned for an organization include text from the organization ’ s own website . Second , the other websites retrieved by Google for an organization usually either ( a ) discussed the organization , or ( b ) dis- cussed similar organizations ( i.e. , organizations with similar names ) . Consequently , the text snippets from those websites often contained relevant information that could be use- ful for inferring the organization ’ s activities and mission . By using text snippets from 10 retrieved websites , each pseudo-document contained information about the organiza- tion ( or similar organizations ) that originated from multiple sources , which collectively painted a good picture of the nature of the organization . 3 . Methods 3.1 . Background : Pre-trained Language Models Pretrained language models , such as BERT [ 8 ] and GPT-2 [ 11 ] , have achieved great suc- cess in the field of Natural Language Processing because of their ability to absorb a lot of information about language from massive amounts of text , without any human su- pervision . These large language models are neural network ( “ deep learning ” ) architec- tures that can be additionally trained for a specific application task using a method called fine-tuning , where the model is provided with human-labeled data for the application task . During fine-tuning , the model combines the general knowledge about language that it previously absorbed during pre-training with the new information in the task-specific data . Fine-tuned models can perform very well for many application tasks , even when provided with only a small amount of task-specific data . For this work , we use a well-known pre-trained language model called BERT [ 8 ] . BERT has been pre-trained on 3.3 billion English words from Wikipedia and the Google May 2023 Air & Climate 0.1 Biodiversity 0.6 ... Water 0.1 BERT [ CLS ] Tok 1 ... Tok N [ SEP ] Tok 1 ... Tok M Organization Text Label Description ... Figure 2 . OrgModel-2 model architecture and an illustration example for organization 5 Bar Beef . Books text collection . We use the base variant of BERT which has 12 layers ( transformer blocks ) , 768 hidden units ( hidden size ) , and 12 self-attention heads . The BERT-base model consists of approximately 110 million parameters ( learned weights ) , offering a good balance between computational efficiency and performance across a wide range of natural language processing tasks . 3.2 . Classification Models We created two different designs for our classification models — one basic fine-tuning design and one slightly more complex design . The first model , OrgModel-1 , takes the text associated with an organization as input and fine-tunes the BERT language model with the “ gold ” training data ( labeled examples ) for the task . Specifically , we follow the common practice of using the embedding vector of the [ CLS ] token for the classification task and stacking a linear classification layer on top of BERT ’ s last layer , which produces an n-dimensional output vector , where n is the number of categories for the task . For the SIC code classification task , we use cross-entropy loss for training . The environmental issues classification task is slightly different because it is a multi-label problem ( an organization can be associated with more than one issue ) , so we further apply a sigmoid function to transform each dimension value to a number between 0 and 1 . If the number is ≥ 0.5 , the system predicts Yes ( meaning the organization belongs to this environmental issue category ) , otherwise No . We use binary cross-entropy loss during training . The second model , OrgModel-2 , takes advantage of an additional source of infor- mation : the model is provided with expert-written descriptions for each category as in- put , along with the text associated with an organization . This provides the model with a definition for each category so that the model can potentially produce a richer semantic representation of the categories to help find the best match with an organization . Specifically , suppose the organization text is denoted by oi , and each category de- scription is denoted by d j ( j = 1 .. n ) . We created n sequence pairs ⟨oi , d1⟩ , ⟨oi , d2⟩ , ... , May 2023 ⟨oi , dn⟩ and asked a system to assign a number between 0 and 1 to each pair ⟨oi , d j⟩ representing the strength of association between organization oi and category d j . The OrgModel-2 model takes the text for an organization and n label descriptions and pre- dicts a strength value for each ⟨oi , d j⟩ pair . Figure 2 depicts the full architecture of the OrgModel-2 model . 4 . Evaluation 4.1 . Evaluation Metrics To evaluate the ability of our NLP models to classify organizations , we report three evaluation metrics that are commonly used in the NLP research community : precision , recall and f1-score . Intuitively , precision captures the accuracy when predicting a cat- egory , while recall captures coverage for recognizing instances of the category . These metrics are defined with respect to a specific category C and computed as : precision = TP/ ( TP + FP ) , recall = TP/ ( TP + FN ) , f 1-score = 2/ ( precision−1 + recall−1 ) , where TP ( true positive ) is the number of true instances of C that were correctly identified by the model ; FP ( false positive ) is the number of instances that the model predicted as C but do not belong to C ; FN ( false negative ) is the number of true instances of C that were not identified by the model . The f1-score is the harmonic mean of precision and recall , which is an average over precision and recall that also reflects how balanced they are ( more balanced is better ) . In addition , we report micro and macro averaged scores for each evaluation met- ric , which provides an overall view of performance across the different categories . The micro average score aggregates the results for all instances ( across all classes ) and then calculates the metric . This gives more weight to the most frequent classes because they have more instances . In contrast , the macro average score calculates the metric for each class separately and then averages the results , which gives equal weight to all classes . For example , micro and macro averaged precision are defined as : micro precision = ∑n TPi/ ( ∑n TPi + ∑n FPi ) , macro precision = 1 ∑n TPi/ ( TPi + FPi ) , where i in- i=1 i=1 i=1 n i=1 dicates the i-th class , and n is the total number of class labels . 4.2 . Results and Analysis 4.2.1 . Environmental Issues Classification Results For our experiments , the 1,870 organizations in the environmental issues dataset were split into 1,370 for training and 500 for testing . Table 3 shows the experimental results for each environmental issue category . OrgModel-1 vs. OrgModel-2 Our OrgModel-1 system achieved 76.8 % micro- averaged f1-score and 69.6 % macro-averaged f1-score . By adding the environmental is- sue category descriptions , the OrgModel-2 achieved better performance with a 80.1 % micro-averaged f1 and 74.0 % macro-averaged f1 . Overall , we see good precision for most of the categories ( 87 % micro-average ) , but recall is lower ( 74 % micro-average ) . If we take a closer look at the individual categories , we can see that OrgModel-2 achieved the best performance ( > 80 % f1-score ) for Biodiversity , Governance , Physical May 2023 OrgModel-1 OrgModel-2 Precision Recall F1-score Precision Recall F1-score Air & Climate Biodiversity Common Pool Resources Disasters Food Production Governance Institutions Land & Soil Physical Infrastructure Protected Areas Public Health Sociocultural Systems Technology Wastes & Pollution Water Micro Average Macro Average 69.2 80.6 57.1 85.7 66.7 97.5 85.9 74.4 94.0 77.2 72.0 83.3 100.0 83.7 93.2 84.5 81.4 32.1 84.5 40.0 44.4 47.3 88.6 62.6 75.6 83.0 57.9 40.9 56.6 66.7 71.1 79.2 70.4 62.0 43.9 82.5 47.1 58.5 55.3 92.9 72.4 75.0 88.1 66.2 52.2 67.4 80.0 76.9 85.6 76.8 69.6 75.0 85.6 70.0 68.4 81.2 100.0 85.5 77.9 95.4 81.7 58.3 85.3 100.0 87.4 94.4 87.2 83.1 53.6 80.4 46.7 48.1 60.2 94.3 66.4 72.5 88.8 64.5 47.7 54.7 71.8 76.3 81.4 74.2 67.2 62.5 82.9 56.0 56.5 69.1 97.1 74.7 75.1 92.0 72.1 52.5 66.7 83.6 81.5 87.4 80.1 74.0 Table 3 . Environmental issues classification : OrgModel-1 and OrgModel-2 performance for each category . Infrastructure , Technology , Wastes & Pollution , and Water . The model struggled the most ( < 60 % f1 score ) for Common Pool Resources , Disasters , and Public Health . Data Sparsity We investigated whether the number of instances has an impact on the model performance . We focused on the 5 least common categories which are associated with fewer than 10 percent of all organizations in the dataset : Public Health , Disasters , Common Pool Resources , Air & Climate and Technology ; and the 5 most common cate- gories which are associated with more than 20 percent of all organizations : Water , Phys- ical Infrastructure , Wastes & Pollution , Biodiversity , and Land & Soil . Figure 3 shows a plot of their f1-scores for both OrgModel-1 and OrgModel-2 . Comparing rare categories ( circles ) with common categories ( squares ) , we can see that the latter perform better with both OrgModel-1 and OrgModel-2 . OrgModel-1 ’ s average f1-score of the common cate- gories is 81.6 % but the average f1-score of rare categories is only 56.3 % . OrgModel-2 ’ s average f1-score of the common categories is 83.8 % and the average f1-score of rare categories is 62.2 % . This huge gap indicates that performance on the rare categories will likely improve if we can get more human-annotated data . Component-Integrated Mapping During our dataset construction for environmental issue classification , we map component issues to integrated issues to focus on a lim- ited set of common labels . However , this many-to-many mapping can create some prob- lems . For example , the component issue Land Use is associated with the integrated issue Food Production . Yet not all organizations tagged with Land Use should be tagged with Food Production , e.g. , organizations “ Air Force Civil Engineer Center ” and “ Snowlands Network ” don ’ t actually produce any food . For future work , we will consider a better alignment between component and integrated issues , or refine the label set by including component issues directly . May 2023 100 e r o c s - 1 F 80 60 OrgModel-1 OrgModel-2 40 T ech n olo g y Bio diversity P h ysical Infrastructure L an d & S oil P u blic H ealth D isasters m o n P o ol R eso urces A ir & Cli m ate W astes & P ollutio n C o m W ater Figure 3 . F1-score for each category . Circles ⃝ represent low frequency environmental issues and squares □ represent high frequency issues . 4.2.2 . SIC Code Classification Results For the SIC code classification task , we split the 5,400 organizations into train , develop- ment , and test sets containing 2700 , 900 , and 1800 examples respectively . 10-K Filing vs. Google PseudoDoc Our first experiment explores the use of two dif- ferent types of textual data for the SIC code classification task : the Pseudo-documents created from Google ’ s retrieved text snippets , and the 10-K filing forms from the SEC database . We trained two different OrgModel-1 systems , one using textual data from the pseudo-documents and one using the 10-K filing reports . These NLP models are iden- tical except for the textual descriptions used in the training process . Table 4 shows that the model which used Google snippets as the text source for an organization strongly outperformed the model which used the text from 10-K forms.9 In fact , the model trained on Google snippets achieved a higher f1-score across every single category except for one ( 62 - Security And Commodity Brokers , Dealers , Exchanges , And Services ) . This category had the smallest difference in performance between the two models at 1.3 % . In many cases , the model trained with Google snippets outperformed the model trained with 10-K forms by a significant margin leading to a 13 % increase in macro-averaged f1-score . This approach is also more generalizable because many organizations do not have SEC filings . OrgModel-1 vs. OrgModel-2 We trained both OrgModel-1 and OrgModel-2 with Google PseudoDoc texts for the SIC code classification task as well . For OrgModel-2 , we also need a description for the category labels , and we experimented with 3 different types of information : 1 ) The shortest representation ( Short ) is simply the name of the 2 digit Major Group . 2 ) The second representation ( Tree ) exploits the hierarchical nature of SIC codes by concatenating together the 2-digit name and the names for all the codes in its subtree . The motivation here is to include the specific subcategory information to 9It is worth noting that about 4 % of the organizations ’ 10-K filings extracted are empty . May 2023 10-K Filing Google PseudoDoc Class Recall Precision F1-Score Recall Precision F1-Score 10 13 20 27 28 34 35 36 37 38 48 49 50 51 58 59 60 61 62 63 65 67 70 73 79 80 87 54.8 67.7 54.2 67.1 71.4 38.0 24.2 28.5 47.1 63.3 66.6 68.9 32.2 28.1 89.2 48.4 81.5 70.0 77.2 55.9 66.1 49.3 71.4 28.0 67.3 73.7 30.5 Macro Avg 56.4 73.9 66.6 83.6 70.4 60.8 45.0 11.1 36.6 57.8 61.2 58.1 80.9 15.1 13.4 75.3 40.7 84.1 71.0 85.9 91.0 66.1 50.7 69.4 26.6 42.3 70.3 41.2 57.4 62.9 67.1 65.8 68.8 65.6 41.2 15.2 32.1 51.9 62.2 62.1 74.4 20.6 18.1 81.6 44.2 82.8 70.5 81.3 69.3 66.1 50.0 70.4 27.3 51.9 72.0 35.1 80.2 82.8 77.4 72.5 71.7 68.5 46.3 43.0 68.8 59.4 73.5 74.6 73.6 47.4 86.4 68.1 90.6 89.3 75.9 91.0 69.5 52.1 85.7 30.0 75.7 81.8 54.2 56.8 70.0 82.6 84.1 90.1 73.7 75.6 52.1 44.4 51.6 73.6 75.8 70.9 84.1 42.4 41.7 83.1 59.2 92.0 85.5 84.5 91.0 70.5 52.1 83.3 35.0 64.1 84.3 60.3 69.9 81.4 83.4 83.3 73.1 73.6 59.2 45.3 46.9 71.1 66.6 72.2 79.1 53.8 44.4 84.7 63.3 91.3 87.4 80.0 91.0 70.0 52.1 84.5 32.3 69.4 83.0 57.1 69.9 Table 4 . Performance of OrgModel-1 trained on different data sources . Label Desc . Precision Recall F1 OrgModel-1 - OrgModel-2 Short Tree Long 69.9 47.0 73.6 73.6 70.0 69.9 49.9 73.6 73.5 46.1 73.4 73.1 Table 5 . Macro average scores for OrgModel-1 and OrgModel-2 with different representations for the label description . create a richer representation of the parent category . 3 ) We used the plain text explanation ( Long ) of the Major Group found in the SIC manual . This is a written explanation of the criteria for an entity to be included in the specified Major Group . Table 5 shows the results . The short representation didn ’ t contain enough information to perform well . Be- tween the tree and long representations , we see similar performance in terms of f1-score . Comparing OrgModel-2 with tree description to OrgModel-1 , OrgModel-2 achieved a 3 % increase in f1-score making it our best performing model on the SIC task . May 2023 Overall , the classifier achieves reasonable performance across the different cate- gories ; however , there are a few categories ( 35 , 50 , 51 , 67 ) where the performance is still weak , possibly due to being particularly broad and difficult to distinguish from other cat- egories . Yet , our model achieves greater than 70 % f1-score on the majority of categories , illustrating the promise of using NLP models to automatically classify organizations . 5 . Conclusion and Future Plans Our study has demonstrated the potential of using Natural Language Processing ( NLP ) techniques for the automatic acquisition of structured food system knowledge from un- structured sources . This includes the classification of entities involved in food activ- ities , and their linkage to social , environmental , and health-related issues . Using text snippets retrieved from Google ’ s search engine as a descriptive basis , our NLP mod- els were able to classify organizations according to environmental issue categories and Standard Industrial Classification ( SIC ) codes . Specifically , we build our models based on transformer-based language models . Our experimental results show that using textual data from Google Search achieved a better performance than using 10-K filings from organizations ’ annual reports , which are provided by the Securities and Exchange Com- mission ( SEC ) database . We also show that by incorporating the description text of the environmental issue categories or SIC codes , our model can achieve better performance for both classification tasks . The promising results underline the applicability of this ap- proach to improve food ontologies as well as other intelligent food systems knowledge resources with little to no human supervision . Our work illustrates how NLP models hold the potential for a wide range of automatic categorization of food system actors and their activities into existing food , environment , and health system ontologies . These on- tologies instantiated by NLP models represent burgeoning yet powerful instruments for quick and efficient population of large food systems knowledge graphs with consistent knowledge representation . Our research opens the door to providing a critical component to the design and creation of reusable cyberinfrastructure components capable of addressing major social- environmental issues like scaling climate actions in food systems . Other components will include the development of additional technological , knowledge , and relational infras- tructures that will build on recent advances in data , modeling , and management . Linking these components together affords the opportunity to make leading edge insights , tools , and practical guidance available to action partners across the food system . Acknowledgments We want to thank the anonymous reviewers for their valuable comments . This research was supported in part by the ICICLE project through NSF award OAC 2112606 and the Canadian Institutes of Health Research ( CIHR ) FRN 177412 . References [ 1 ] Hollander AD , Hoy C , Huber PR , Hyder A , Lange MC , Latham A , Quinn JF , Rig- gle CM , Tomich TP . Toward smart foodsheds : Using stakeholder engagement to May 2023 improve informatics frameworks for regional food systems . Annals of the Ameri- can Association of Geographers . 2020 . DOI : 10.1080/24694452.2019.1662764 [ 2 ] Boulos MN , Yassine A , Shirmohammadi S , Namahoot CS , Bru¨ckner M. Towards an “ Internet of Food ” : food ontologies for the internet of things . Future Internet . 2015 . [ 3 ] Dooley D , Andre´s-Herna´ndez L , Bordea G , Carmody L , Cavalieri D , Chan L , Castellano-Escuder P , Lachat C , Mougin F , Vitali F , Yang C. Obo foundry food ontology interconnectivity . InCEUR Workshop Proceedings . 2021 . [ 4 ] Dooley DM , Griffiths EJ , Gosal GS , Buttigieg PL , Hoehndorf R , Lange MC , Schriml LM , Brinkman FS , Hsiao WW . FoodOn : a harmonized food ontology to increase global food traceability , quality control and data integration . npj Science of Food . 2018 . [ 5 ] D ’ Odorico P , Carr JA , Davis KF , Dell ’ Angelo J , Seekell DA . Food inequality , injustice , and rights . BioScience . 2019 . [ 6 ] Fanzo J , Arabi M , Burlingame B , Haddad L , Kimenju S , Miller G , Nie F , Recine E , Serra-Majem L , Sinha D. Nutrition and food systems . A report by the high level panel of experts on food security and nutrition of the committee on world food security . 2017 . [ 7 ] Fanzo J , Davis C. Global food systems , diets , and nutrition . Springer International Publishing . 2021 . [ 8 ] Devlin J , Chang MW , Lee K , Toutanova K. BERT : Pre-training of deep bidirec- tional transformers for language understanding . In Proceedings of the 2019 Con- ference of the North American Chapter of the Association for Computational Lin- guistics : Human Language Technologies . 2019 . [ 9 ] Kotiaho JS , Halme P. The IPBES assessment report on land degradation and restoration . IPBES Secretariat , UN Campus : Bonn , Germany . 2018 . [ 10 ] Nicole´tis E´ , Termine P. Reducing inequalities for food security and nutrition - HLPE consultation on the report ’ s scope . Global Forum on Food Security and Nutrition ( FSN Forum ) . 2022 . [ 11 ] Radford A , Wu J , Child R , Luan D , Amodei D , Sutskever I . Language models are unsupervised multitask learners . OpenAI blog . 2019 . [ 12 ] Smith B. Ontology . In Blackwell Guide to the Philosophy of Computing and In- formation , edited by Luciano Floridi . Oxford : Blackwell . 2003 . [ 13 ] Tomich TP , Hoy C , Dimock MR , Hollander AD , Huber PR , Hyder A , Lange MC , Riggle CM , Roberts MT , Quinn JF . Why do we need food systems informatics ? Introduction to this special collection on smart and connected regional food sys- tems . Sustainability . 2023 . [ 14 ] FAO , IFAD , UNICEF , WFP and WHO . The state of food security and nutrition in the world 2021 . Transforming food systems for food security , improved nutrition and affordable healthy diets for all . Rome , FAO . 2021 . DOI : 10.4060/cb4474en [ 15 ] United Nations Environment Programme . Emissions gap report 2022 : The closing window - Climate crisis calls for rapid transformation of societies . Nairobi . 2022 .","['classify', 'organization', 'food', 'system', 'ontology', 'use', 'natural', 'language', 'processing', 'hollander', 'patrick', 'r', 'huber', 'c', 'ellen', 'riloff', 'r', 'giorgio', 'university', 'icfood', 'r', 'giorgio', 'ubbiali', 'https', 'research', 'explore', 'use', 'natural', 'language', 'processing', 'nlp', 'method', 'automatically', 'classify', 'entity', 'purpose', 'knowledge', 'graph', 'pop', 'ulation', 'integration', 'food', 'system', 'ontologie', 'create', 'nlp', 'model', 'automatically', 'classify', 'organization', 'respect', 'category', 'associate', 'environmental', 'issue', 'well', 'standard', 'industrial', 'classification', 'sic', 'code', 'use', 'government', 'characterize', 'business', 'activity', 'put', 'nlp', 'model', 'provide', 'text', 'snippet', 'retrieve', 'search', 'engine', 'organization', 'serve', 'textual', 'description', 'organi', 'zation', 'use', 'learn', 'experimental', 'result', 'show', 'nlp', 'model', 'achieve', 'reasonably', 'good', 'performance', 'classification', 'task', 'rely', 'general', 'framework', 'apply', 'many', 'classification', 'problem', 'well', 'believe', 'model', 'represent', 'promising', 'approach', 'automatically', 'harvesting', 'information', 'populate', 'knowledge', 'graph', 'align', 'information', 'exist', 'ontology', 'share', 'category', 'concept', 'keyword', 'food', 'system', 'ontologie', 'classification', 'model', 'natural', 'language', 'processing', 'sic', 'sustainability', 'issue', 'unstructured', 'datum', 'introduction', 'food', 'system', 'include', 'activity', 'relationship', 'involve', 'production', 'transport', 'consumption', 'food', 'thus', 'link', 'wide', 'variety', 'natural', 'human', 'system', 'extensive', 'nature', 'dramatic', 'impact', 'author', 'ellen', 'riloff', 'riloff', 'csutahedu', 'natural', 'human', 'system', 'ipbe', 'unep', 'conversely', 'food', 'system', 'vulnerable', 'change', 'system', 'food', 'activity', 'also', 'show', 'pivotal', 'role', 'foster', 'human', 'social', 'healthrelate', 'issue', 'instance', 'inequality', 'inju', 'tice', 'exist', 'whole', 'global', 'food', 'supply', 'chain', 'well', 'related', 'sector', 'odorico', 'nicole´tis', 'termine', 'date', 'hunger', 'malnutrition', 'micronutrient', 'deficiency', 'cite', 'still', 'largely', 'threaten', 'humanity', 'worldwide', 'fanzo', 'fanzo', 'unicef', 'world', 'become', 'interconnected', 'interdependent', 'ontology', 'become', 'useful', 'way', 'categorize', 'relate', 'information', 'together', 'especially', 'appli', 'cable', 'food', 'system', 'datum', 'access', 'interoperability', 'reusability', 'essential', 'deal', 'interrelated', 'issue', 'arise', 'food', 'system', 'activity', 'ontology', 'formal', 'theory', 'provide', 'commonly', 'accept', 'dictionary', 'term', 'sup', 'port', 'canonical', 'syntax', 'set', 'axiom', 'knowledge', 'domain', 'interest', 'ontology', 'offer', 'common', 'semantic', 'framework', 'domain', 'knowledge', 'hollander', 'thus', 'ontology', 'foster', 'datum', 'access', 'interoperability', 'reusability', 'several', 'disparate', 'resource', 'employ', 'ontology', 'common', 'reference', 'semantic', 'standard', 'hollander', 'day', 'several', 'ontology', 'focus', 'food', 'health', 'related', 'aspect', 'devel', 'ope', 'dooley', 'cite', 'noteworthy', 'one', 'example', 'agrovoc2', 'threedecadelong', 'wellestablished', 'multilingual', 'saurus', 'address', 'food', 'related', 'domain', 'interest', 'belong', 'agriculture', 'organisation', 'fao', 'agronomy', 'tology', 'agro3', 'develop', 'frame', 'cgiar', 'platform', 'big', 'datum', 'agriculture', 'propose', 'vocabulary', 'term', 'cover', 'agronomic', 'manage', 'ment', 'practice', 'implement', 'variable', 'use', 'agronomic', 'experiment', 'dooley', 'compositional', 'dietary', 'nutrition', 'ontology', 'cdno4', 'present', 'term', 'late', 'nutritional', 'attribute', 'crop', 'livestock', 'fishery', 'contribute', 'diet', 'reference', 'precision', 'food', 'commodity', 'laboratory', 'analytic', 'dooley', 'food', 'ontology', 'foodon5', 'provide', 'lexicon', 'basic', 'raw', 'food', 'source', 'ingredient', 'process', 'term', 'packaging', 'cooking', 'preservation', 'upperlevel', 'variety', 'product', 'type', 'scheme', 'food', 'product', 'catego', 'rize', 'foodon', 'stand', 'fundamental', 'ontology', 'address', 'foodrelated', 'aspect', 'dooley', 'foodon', 'aim', 'state', 'lingua', 'franca', 'domain', 'food', 'share', 'reuse', 'foodrelated', 'information', 'human', 'machine', 'availability', 'foodhealth', 'ontology', 'envisage', 'data', 'access', 'interoperability', 'reusability', 'food', 'industry', 'foodrelated', 'tor', 'claim', 'appear', 'reach', 'yet', 'tomich', 'paper', 'present', 'new', 'research', 'use', 'artificial', 'intelligence', 'ai', 'technol', 'ogy', 'automatically', 'categorize', 'organization', 'ultimately', 'purpose', 'link', 'food', 'system', 'ontologie', 'eventual', 'goal', 'automatically', 'populate', 'large', 'knowl', 'edge', 'graph', 'information', 'relate', 'agriculture', 'food', 'system', 'concept', 'graph', 'align', 'wellestablished', 'ontology', 'ensure', 'knowledge', 'represent', 'consistently', 'align', 'resource', 'system', 'rely', 'wwwfaoorgagrovoc', 'cdnoinfo', 'ontological', 'framework', 'populate', 'knowledge', 'graph', 'hand', 'timeconsuming', 'expensive', 'ai', 'technology', 'offer', 'opportunity', 'automatically', 'harvest', 'infor', 'mation', 'much', 'quickly', 'efficiently', 'specifically', 'focus', 'classification', 'task', 'relate', 'organization', 'aim', 'categorize', 'organization', 'base', 'set', 'environmental', 'issue', 'relevant', 'environmental', 'planning', 'food', 'system', 'standard', 'industrial', 'classification', 'sic', 'codes6', 'government', 'assign', 'business', 'categorize', 'nature', 'activity', 'sic', 'code', 'analogous', 'north', 'american', 'industry', 'classification', 'system', 'naic', 'code', 'use', 'design', 'natural', 'lan', 'guage', 'processing', 'nlp', 'model', 'read', 'text', 'associate', 'organization', 'auto', 'matically', 'assign', 'organization', 'category', 'task', 'follow', 'tion', 'describe', 'classification', 'task', 'detail', 'explain', 'collect', 'relevant', 'text', 'nlp', 'model', 'use', 'present', 'nlp', 'technology', 'underlie', 'classification', 'model', 'show', 'experimental', 'result', 'classification', 'task', 'classification', 'task', 'dataset', 'environmental', 'issue', 'classification', 'task', 'dataset', 'large', 'amount', 'information', 'currently', 'available', 'concern', 'state', 'environment', 'world', 'many', 'organization', 'collect', 'analyze', 'datum', 'however', 'remain', 'major', 'gap', 'ability', 'connect', 'datum', 'source', 'make', 'smart', 'typically', 'use', 'different', 'format', 'vocabulary', 'render', 'able', 'use', 'together', 'conservation', 'community', 'lack', 'informatic', 'backbone', 'begin', 'link', 'people', 'datum', 'way', 'enhance', 'capacity', 'inform', 'deci', 'sion', 'make', 'effort', 'conserve', 'enhance', 'earth', 'ecosystem', 'need', 'especially', 'crucial', 'enter', 'unprecedented', 'era', 'rapid', 'environmental', 'change', 'key', 'question', 'environmental', 'planning', 'food', 'system', 'many', 'context', 'people', 'organization', 'project', 'activity', 'refer', 'many', 'kind', 'geography', 'help', 'provide', 'machinereadable', 'answer', 'question', 'hollander', 'develop', 'ontology', 'call', 'ppod', 'people', 'project', 'organization', 'dataset', 'ontol', 'ogy', 'formally', 'describe', 'characteristic', 'relationship', 'class', 'information', 'member', 'team', 'instantiate', 'ppod', 'ontology', 'information', 'con', 'cerne', 'conservation', 'work', 'landscape', 'knowledge', 'graph', 'contain', 'organization', 'identify', 'collect', 'manner', 'array', 'online', 'search', 'use', 'term', 'conservation', 'diversity', 'graze', 'water', 'supply', 'organization', 'associate', 'attribute', 'describe', 'structure', 'mission', 'hasorgtype', 'ity', 'issue', 'issue', 'attribute', 'describe', 'potential', 'environmental', 'issue', 'associate', 'organization', 'predefine', 'highlevel', 'environmental', 'issue', 'call', 'integrate', 'issue', 'finegrained', 'environmental', 'issue', 'call', 'component', 'issue', 'ontology', 'provide', 'detailed', 'textual', 'description', 'issue', 'label', 'wwwoshagovdatasicmanual', 'githubcomppodschema', 'category', 'water', 'physical', 'infrastructure', 'waste', 'pollution', 'biodiversity', 'land', 'soil', 'food', 'production', 'institution', 'governance', 'protect', 'area', 'sociocultural', 'system', 'public', 'health', 'disaster', 'common', 'pool', 'resource', 'air', 'climate', 'technology', 'organization', 'percentage', 'example', 'organization', 'american', 'river', 'rebuild', 'heal', 'ocean', 'land', 'trust', 'agricultural', 'research', 'merce', 'public', 'health', 'tahoe', 'fire', 'fuel', 'team', 'sustainable', 'conservation', 'irvine', 'global', 'warming', 'group', 'cdfw', 'datum', 'technology', 'division', 'table', 'example', 'environmental', 'issue', 'many', 'organization', 'issue', 'associate', 'last', 'column', 'show', 'example', 'organization', 'label', 'issue', 'category', 'relation', 'integrate', 'issue', 'component', 'issue', 'example', 'component', 'issue', 'air', 'pollution', 'air', 'quality', 'greenhouse', 'gas', 'mitigation', 'greenhouse', 'gas', 'emission', 'child', 'integrate', 'issue', 'air', 'climate', 'describe', 'emission', 'ozone', 'layer', 'depletion', 'air', 'quality', 'climate', 'change', 'influence', 'extreme', 'weather', 'event', 'shift', 'grow', 'zone', 'key', 'crop', 'climate', 'change', 'expert', 'opinion', 'use', 'associate', 'organization', 'issue', 'define', 'task', 'base', 'ppod', 'ontology', 'call', 'environmental', 'issue', 'classi', 'fication', 'give', 'organization', 'task', 'require', 'model', 'assign', 'tiple', 'environmental', 'issue', 'category', 'label', 'organization', 'describe', 'activity', 'andor', 'mission', 'model', 'need', 'train', 'reasonable', 'number', 'example', 'category', 'start', 'common', 'category', 'exist', 'ppod', 'datum', 'map', 'component', 'issue', 'parent', 'integrate', 'issue', 'sort', 'issue', 'base', 'number', 'organi', 'zation', 'associate', 'issue', 'finally', 'select', 'common', 'integrate', 'issue', 'set', 'category', 'label', 'result', 'dataset', 'contain', 'organization', 'associate', 'environmental', 'issue', 'category', 'air', 'climate', 'biodiversity', 'common', 'pool', 'resource', 'disaster', 'food', 'production', 'governance', 'institution', 'land', 'soil', 'physical', 'infrastructure', 'protect', 'area', 'public', 'health', 'sociocultural', 'system', 'technology', 'waste', 'pollution', 'water', 'table', 'show', 'category', 'number', 'percentage', 'organization', 'category', 'associate', 'example', 'organization', 'category', 'standard', 'industrial', 'classification', 'sic', 'task', 'dataset', 'standard', 'industrial', 'classification', 'sic', 'code', 'create', 'government', 'categorize', 'business', 'accord', 'industry', 'serve', 'operate', 'lieve', 'incorporate', 'industry', 'classification', 'sic', 'code', 'remain', 'use', 'replace', 'north', 'american', 'industry', 'classification', 'system', 'food', 'system', 'ontology', 'valuable', 'understand', 'nature', 'organization', 'activi', 'tie', 'economic', 'logistical', 'relationship', 'organization', 'supply', 'chain', 'relationship', 'sic', 'code', 'many', 'organization', 'look', 'government', 'business', 'database', 'ai', 'model', 'automatically', 'assign', 'sic', 'code', 'organization', 'use', 'categorize', 'newly', 'form', 'organization', 'quickly', 'wait', 'official', 'database', 'update', 'categorize', 'organization', 'respect', 'standardized', 'industry', 'code', 'maintain', 'currency', 'knowledge', 'graph', 'automatically', 'reclassify', 'organization', 'regular', 'basis', 'say', 'annually', 'reflect', 'change', 'organization', 'make', 'activity', 'expansion', 'business', 'activity', 'retraction', 'end', 'define', 'second', 'task', 'call', 'sic', 'code', 'classification', 'require', 'nlp', 'model', 'assign', 'multiple', 'sic', 'code', 'category', 'label', 'organization', 'sic', 'code', 'digit', 'long', 'hierarchical', 'digit', 'represent', 'sion', 'major', 'group', 'industry', 'group', 'industry', 'entity', 'respectively', 'example', 'company', 'code', 'belong', 'soybean', 'industry', 'cash', 'grain', 'industry', 'group', 'agricultural', 'production', 'crop', 'major', 'group', 'tem', 'allow', 'study', 'company', 'different', 'level', 'granularity', 'simply', 'group', 'company', 'accord', 'first', 'digit', 'sic', 'code', 'train', 'nlp', 'model', 'task', 'need', 'example', 'organization', 'asso', 'ciate', 'sic', 'code', 'conveniently', 'security', 'main', 'tain', 'publicly', 'accessible', 'database', 'company', 'call', 'edgar', 'database', 'contain', 'sic', 'code', 'company', 'well', 'filing', 'report', 'particular', 'terest', '10k', '20f', 'form', 'provide', 'company', 'annual', 'report', 'form', 'detail', 'range', 'information', 'relate', 'company', 'operation', 'past', 'year', 'include', 'financial', 'legal', 'risk', 'factor', 'information', 'allow', 'stakeholder', 'assess', 'state', 'business', 'download', 'report', 'well', 'source', 'textual', 'information', 'nlp', 'model', 'potentially', 'use', 'specifically', 'collect', 'natural', 'language', 'text', 'item', 'business', 'section', 'company', 'recent', '10k', 'filing', 'well', 'company', 'official', 'sic', 'code', 'edgar', 'database', 'sic', 'code', 'company', 'fact', 'principle', 'company', 'multiple', 'code', 'associate', 'collect', 'company', 'information', 'start', 'list', 'company', 'database', 'central', 'index', 'key', 'number', 'provide', 'query', 'number', 'edgar', 'collect', 'name', 'sic', 'sic', 'description', '10k', 'form', 'focus', 'research', 'organization', 'field', 'observe', 'distribution', 'datum', 'highly', 'skewed', 'many', 'sic', 'code', 'contain', 'instance', 'partly', 'due', 'fact', 'organi', 'zation', 'force', 'pick', 'sicnaic', 'code', 'incorporate', 'organization', 'business', 'model', 'change', 'involve', 'multiple', 'line', 'business', 'reflect', 'multiple', 'sicnaic', 'code', 'experiment', 'create', 'balanced', 'subset', 'datum', 'amount', 'information', 'category', 'fairly', 'compare', 'perfor', 'mance', 'nlp', 'model', 'category', 'decide', 'focus', 'first', 'digit', 'sic', 'code', 'category', 'label', 'help', 'minimize', 'datum', 'sparsity', 'many', 'long', 'code', 'relatively', 'organization', 'associate', 'provide', 'useful', 'highlevel', 'view', 'company', 'general', 'type', 'sic', 'description', 'metal', 'mining', 'oil', 'gas', 'extraction', 'food', 'kindre', 'product', 'print', 'publishing', 'ally', 'industry', 'chemical', 'ally', 'product', 'fabricate', 'metal', 'product', 'industrial', 'commercial', 'machinery', 'electronic', 'transportation', 'equipment', 'measure', 'photographic', 'medical', 'communication', 'electric', 'gas', 'sanitary', 'service', 'wholesale', 'trade', 'durable', 'good', 'wholesale', 'trade', 'nondurable', 'good', 'sic', 'description', 'eat', 'drinking', 'place', 'miscellaneous', 'retail', 'depository', 'institution', 'nondepository', 'credit', 'institution', 'security', 'insurance', 'carrier', 'real', 'estate', 'holding', 'investment', 'office', 'hotel', 'room', 'house', 'camp', 'business', 'service', 'amusement', 'recreation', 'service', 'health', 'service', 'engineering', 'accounting', 'research', 'table', 'description', 'common', 'sic', 'code', 'ness', 'operation', 'create', 'dataset', 'experiment', 'select', 'sic', 'code', 'least', 'associated', 'company', 'result', 'set', 'sic', 'code', 'show', 'table', 'finally', 'randomly', 'sample', 'company', 'code', 'create', 'balanced', 'dataset', 'contain', 'organization', 'sic', 'code', 'organization', 'information', 'collection', 'goal', 'create', 'classification', 'model', 'give', 'text', 'organization', 'input', 'produce', 'category', 'label', 'organization', 'output', 'key', 'question', 'find', 'text', 'describe', 'organization', 'initially', 'consider', 'use', 'official', 'website', 'organization', 'input', 'text', 'website', 'often', 'contain', 'formation', 'organization', 'initiative', 'policy', 'practice', 'however', 'organization', 'official', 'website', 'many', 'website', 'allow', 'auto', 'mate', 'crawl', 'case', 'use', 'web', 'scraper', 'automatically', 'extract', 'text', 'website', 'organization', 'environmental', 'issue', 'dataset', 'find', 'half', 'organization', 'website', 'crawl', 'alternative', 'decide', 'use', 'search', 'engine', 'retrieve', 'textual', 'information', 'organization', 'organization', 'give', 'organization', 'name', 'search', 'query', 'search', 'api', 'extract', 'first', 'return', 'result', 'search', 'result', 'provide', 'several', 'type', 'information', 'organic', 'result', 'knowledge', 'graph', 'local', 'result', 'relate', 'question', 'organic', 'result', 'mically', 'calculate', 'query', 'result', 'oppose', 'advertisement', 'user', 'typically', 'read', 'include', 'title', 'link', 'text', 'snippet', 'retrieve', 'web', 'page', 'use', 'text', 'snippet', 'small', 'block', 'text', 'appear', 'link', 'website', 'usually', 'character', 'length', 'typically', 'provide', 'user', 'general', 'description', 'content', 'website', 'organization', 'concatenate', 'text', 'snippet', 'top', 'retrieve', 'website', 'single', 'pseudo', 'document', 'serve', 'text', 'datum', 'use', 'organization', 'figure', 'show', 'pipeline', 'create', 'organization', 'use', 'search', 'api', 'snippet', 'cattle', 'bar', 'beef', 'idyllic', 'life', 'graze', 'multigenerational', 'family', 'ranch', 'help', 'support', 'wildfire', 'mitigation', 'bar', 'angus', 'ranch', 'raise', 'premium', 'quality', 'angus', 'bull', 'sale', 'well', 'home', 'grow', 'angus', 'beef', 'sale', 'angus', 'cattle', 'prove', 'herd', 'genetic', 'meat', 'bar', 'beef', 'family', 'ranch', 'dedicate', 'provide', 'bestquality', 'well', 'taste', 'grassfe', 'pasture', 'raise', 'beef', 'grassfe', 'beef', 'pasture', 'raise', 'holistically', 'farm', 'carry', 'bar', 'beef', 'top', 'n', 'search', 'result', 'collect', 'snippet', 'figure', 'download', 'snippet', 'organization', 'textual', 'representation', 'show', 'section', 'use', 'text', 'snippet', 'retrieve', 'web', 'page', 'produce', 'reasonably', 'good', 'classification', 'model', 'observe', 'thing', 'explain', 'search', 'produce', 'useful', 'textual', 'information', 'organization', 'first', 'organization', 'official', 'website', 'typically', 'find', 'rank', 'top', 'hit', 'many', 'case', 'text', 'snippet', 'return', 'organization', 'include', 'text', 'organization', 'website', 'second', 'website', 'retrieve', 'organization', 'usually', 'discuss', 'organization', 'b', 'cuss', 'similar', 'organization', 'organization', 'similar', 'name', 'consequently', 'text', 'snippet', 'website', 'often', 'contain', 'relevant', 'information', 'use', 'ful', 'infer', 'organization', 'activity', 'mission', 'use', 'text', 'snippet', 'retrieve', 'website', 'pseudodocument', 'contain', 'information', 'organiza', 'tion', 'similar', 'organization', 'originate', 'multiple', 'source', 'collectively', 'paint', 'good', 'picture', 'nature', 'organization', 'method', 'background', 'pretraine', 'language', 'model', 'pretraine', 'language', 'model', 'gpt2', 'achieve', 'great', 'suc', 'cess', 'field', 'natural', 'language', 'processing', 'ability', 'absorb', 'lot', 'information', 'language', 'massive', 'amount', 'text', 'human', 'pervision', 'large', 'language', 'model', 'neural', 'network', 'deep', 'learn', 'architec', 'ture', 'additionally', 'train', 'specific', 'application', 'task', 'use', 'method', 'call', 'finetune', 'model', 'provide', 'humanlabeled', 'datum', 'application', 'task', 'finetune', 'model', 'combine', 'general', 'knowledge', 'language', 'previously', 'absorb', 'pretraine', 'new', 'information', 'datum', 'finetune', 'model', 'perform', 'well', 'many', 'application', 'task', 'even', 'provide', 'small', 'amount', 'taskspecific', 'datum', 'work', 'use', 'wellknown', 'pretraine', 'language', 'model', 'call', 'bert', 'pretraine', 'english', 'word', 'air', 'climate', 'biodiversity', 'water', 'bert', 'cls', 'tok', 'tok', 'n', 'sep', 'tok', 'tok', 'organization', 'text', 'label', 'description', 'figure', 'orgmodel2', 'model', 'architecture', 'illustration', 'example', 'organization', 'bar', 'beef', 'book', 'text', 'collection', 'use', 'base', 'variant', 'bert', 'layer', 'transformer', 'block', 'hide', 'unit', 'hide', 'size', 'selfattention', 'head', 'bertbase', 'model', 'consist', 'approximately', 'parameter', 'learn', 'weight', 'offer', 'good', 'balance', 'computational', 'efficiency', 'performance', 'wide', 'range', 'natural', 'language', 'processing', 'task', 'classification', 'model', 'create', 'different', 'design', 'classification', 'model', 'basic', 'finetuning', 'design', 'slightly', 'complex', 'design', 'first', 'model', 'orgmodel1', 'take', 'text', 'associate', 'organization', 'input', 'finetune', 'language', 'model', 'gold', 'training', 'datum', 'label', 'example', 'task', 'specifically', 'follow', 'common', 'practice', 'use', 'embed', 'vector', 'cls', 'token', 'classification', 'task', 'stack', 'linear', 'classification', 'layer', 'top', 'last', 'layer', 'produce', 'ndimensional', 'output', 'vector', 'n', 'number', 'category', 'task', 'sic', 'code', 'classification', 'task', 'use', 'crossentropy', 'loss', 'train', 'environmental', 'issue', 'classification', 'task', 'slightly', 'different', 'multilabel', 'problem', 'organization', 'associate', 'issue', 'far', 'apply', 'sigmoid', 'function', 'transform', 'dimension', 'value', 'number', 'number', 'system', 'predict', 'mean', 'organization', 'belong', 'environmental', 'issue', 'category', 'otherwise', 'use', 'binary', 'crossentropy', 'loss', 'train', 'second', 'model', 'orgmodel2', 'take', 'advantage', 'additional', 'source', 'mation', 'model', 'provide', 'expertwritten', 'description', 'category', 'put', 'text', 'associate', 'organization', 'provide', 'model', 'definition', 'category', 'model', 'potentially', 'produce', 'rich', 'semantic', 'representation', 'category', 'help', 'find', 'good', 'match', 'organization', 'specifically', 'suppose', 'organization', 'text', 'denote', 'category', 'de', 'scription', 'denote', 'j', 'create', 'n', 'sequence', 'pair', '⟨oi', 'dn⟩', 'ask', 'system', 'assign', 'number', 'pair', '⟨oi', 'j⟩', 'represent', 'strength', 'association', 'organization', 'oi', 'category', 'j', 'orgmodel2', 'model', 'take', 'text', 'organization', 'n', 'label', 'description', 'pre', 'dict', 'strength', 'value', '⟨oi', 'j⟩', 'pair', 'figure', 'depict', 'full', 'architecture', 'orgmodel2', 'model', 'evaluation', 'evaluation', 'metric', 'evaluate', 'ability', 'nlp', 'model', 'classify', 'organization', 'report', 'evaluation', 'metric', 'commonly', 'use', 'research', 'community', 'precision', 'recall', 'f1score', 'intuitively', 'precision', 'capture', 'accuracy', 'predict', 'cat', 'egory', 'capture', 'coverage', 'recognize', 'instance', 'category', 'metric', 'define', 'respect', 'specific', 'category', 'c', 'compute', 'precision', 'tp', 'recall', 'tp', 'recall−1', 'tp', 'true', 'positive', 'number', 'true', 'instance', 'c', 'correctly', 'identify', 'model', 'false', 'positive', 'number', 'instance', 'model', 'predict', 'c', 'belong', 'fn', 'false', 'negative', 'number', 'true', 'instance', 'c', 'identify', 'model', 'f1score', 'harmonic', 'mean', 'precision', 'recall', 'average', 'precision', 'recall', 'also', 'reflect', 'balanced', 'balanced', 'well', 'addition', 'report', 'average', 'score', 'evaluation', 'meet', 'provide', 'overall', 'view', 'performance', 'different', 'category', 'micro', 'average', 'score', 'aggregate', 'result', 'instance', 'class', 'calculate', 'metric', 'give', 'weight', 'frequent', 'class', 'instance', 'contrast', 'macro', 'average', 'score', 'calculate', 'metric', 'class', 'separately', 'average', 'result', 'give', 'equal', 'weight', 'class', 'example', 'macro', 'average', 'precision', 'define', 'precision', 'fpi', 'macro', 'precision', '∑n', 'tpi', 'fpi', 'dicate', 'class', 'n', 'total', 'number', 'class', 'label', 'result', 'analysis', 'environmental', 'issue', 'classification', 'result', 'experiment', 'organization', 'environmental', 'issue', 'dataset', 'split', 'training', 'testing', 'table', 'show', 'experimental', 'result', 'environmental', 'issue', 'category', 'orgmodel1', 'orgmodel2', 'orgmodel1', 'system', 'achieve', 'average', 'f1score', 'macroaverage', 'f1score', 'add', 'environmental', 'sue', 'category', 'description', 'orgmodel2', 'achieve', 'well', 'performance', 'microaverage', 'f1', 'macroaverage', 'overall', 'see', 'good', 'precision', 'category', 'microaverage', 'low', 'microaverage', 'take', 'close', 'look', 'individual', 'category', 'see', 'orgmodel2', 'achieve', 'good', 'performance', 'f1score', 'biodiversity', 'governance', 'physical', 'orgmodel1', 'orgmodel2', 'precision', 'recall', 'f1score', 'precision', 'recall', 'air', 'climate', 'biodiversity', 'common', 'pool', 'resource', 'disaster', 'food', 'production', 'governance', 'institution', 'land', 'soil', 'physical', 'infrastructure', 'protect', 'area', 'public', 'health', 'sociocultural', 'system', 'technology', 'waste', 'pollution', 'macro', 'average', 'table', 'environmental', 'issue', 'classification', 'orgmodel1', 'orgmodel2', 'performance', 'category', 'infrastructure', 'technology', 'waste', 'pollution', 'water', 'model', 'struggle', 'f1', 'score', 'common', 'pool', 'resource', 'disaster', 'public', 'health', 'datum', 'sparsity', 'investigate', 'number', 'instance', 'impact', 'model', 'performance', 'focus', 'least', 'common', 'category', 'associate', 'percent', 'organization', 'dataset', 'public', 'health', 'disaster', 'common', 'pool', 'resource', 'air', 'climate', 'technology', 'common', 'cate', 'gorie', 'associate', 'percent', 'organization', 'water', 'phy', 'ical', 'infrastructure', 'waste', 'pollution', 'biodiversity', 'land', 'soil', 'figure', 'show', 'plot', 'f1score', 'orgmodel1', 'orgmodel2', 'compare', 'rare', 'category', 'circle', 'common', 'category', 'square', 'see', 'latter', 'perform', 'well', 'orgmodel1', 'orgmodel2', 'average', 'f1score', 'common', 'cate', 'gorie', 'average', 'f1score', 'rare', 'category', 'orgmodel2', 'average', 'f1score', 'common', 'category', 'average', 'f1score', 'rare', 'category', 'huge', 'gap', 'indicate', 'performance', 'rare', 'category', 'likely', 'improve', 'get', 'humanannotated', 'datum', 'componentintegrate', 'mapping', 'dataset', 'construction', 'environmental', 'issue', 'classification', 'map', 'component', 'issue', 'integrate', 'issue', 'focus', 'ite', 'set', 'common', 'label', 'however', 'manytomany', 'mapping', 'create', 'prob', 'lem', 'example', 'component', 'issue', 'land', 'use', 'associate', 'integrate', 'issue', 'food', 'production', 'yet', 'organization', 'tag', 'land', 'use', 'tag', 'food', 'production', 'eg', 'organization', 'air', 'force', 'civil', 'engineer', 'center', 'snowland', 'network', 'actually', 'produce', 'food', 'future', 'work', 'consider', 'well', 'alignment', 'component', 'integrate', 'issue', 'refine', 'label', 'set', 'include', 'component', 'issue', 'directly', 'e', 'r', 'c', 'orgmodel1', 'orgmodel2', 'diversity', 'p', 'ysical', 'infrastructure', 'l', 'oil', 'blic', 'isaster', 'n', 'ol', 'r', 'eso', 'urce', 'cli', 'eat', 'aste', 'p', 'ater', 'figure', 'f1score', 'category', 'circle', 'represent', 'low', 'frequency', 'environmental', 'issue', 'square', 'represent', 'high', 'frequency', 'issue', 'sic', 'code', 'classification', 'result', 'sic', 'code', 'classification', 'task', 'split', 'organization', 'train', 'develop', 'ment', 'test', 'set', 'contain', 'example', 'respectively', '10k', 'filing', 'first', 'experiment', 'explore', 'use', 'dif', 'ferent', 'type', 'textual', 'datum', 'sic', 'code', 'classification', 'task', 'pseudodocument', 'create', 'retrieve', 'text', 'snippet', '10k', 'file', 'form', 'database', 'train', 'different', 'orgmodel1', 'system', 'use', 'textual', 'datum', 'pseudodocument', 'use', '10k', 'filing', 'report', 'nlp', 'model', 'iden', 'tical', 'textual', 'description', 'use', 'training', 'process', 'table', 'show', 'model', 'use', 'google', 'snippet', 'text', 'source', 'organization', 'strongly', 'outperform', 'model', 'use', 'text', '10k', 'forms9', 'fact', 'model', 'train', 'snippet', 'achieve', 'high', 'f1score', 'single', 'category', 'security', 'commodity', 'broker', 'dealer', 'exchange', 'service', 'category', 'small', 'difference', 'performance', 'model', 'many', 'case', 'model', 'train', 'snippet', 'outperform', 'model', 'train', '10k', 'form', 'significant', 'margin', 'lead', 'increase', 'macroaveraged', 'f1score', 'approach', 'also', 'generalizable', 'many', 'organization', 'filing', 'orgmodel1', 'orgmodel2', 'train', 'orgmodel1', 'orgmodel2', 'text', 'sic', 'code', 'classification', 'task', 'well', 'orgmodel2', 'also', 'need', 'description', 'category', 'label', 'experiment', 'different', 'type', 'information', 'short', 'representation', 'short', 'simply', 'name', 'digit', 'major', 'group', 'second', 'representation', 'tree', 'exploit', 'hierarchical', 'nature', 'sic', 'code', 'concatenate', 'together', 'name', 'name', 'code', 'subtree', 'motivation', 'include', 'specific', 'subcategory', 'information', '9it', 'worth', 'note', 'organization', '10k', 'filing', 'extract', 'empty', '10k', 'file', 'class', 'recall', 'f1score', 'recall', 'precision', 'macro', 'avg', 'table', 'performance', 'orgmodel1', 'train', 'different', 'data', 'source', 'label', 'desc', 'precision', 'recall', 'orgmodel1', 'orgmodel2', 'short', 'tree', 'long', 'table', 'macro', 'average', 'score', 'orgmodel1', 'orgmodel2', 'different', 'representation', 'label', 'description', 'create', 'rich', 'representation', 'parent', 'category', 'use', 'plain', 'text', 'explanation', 'long', 'major', 'group', 'find', 'sic', 'manual', 'write', 'explanation', 'criterion', 'entity', 'include', 'specified', 'major', 'group', 'table', 'show', 'result', 'short', 'representation', 'contain', 'enough', 'information', 'perform', 'well', 'tween', 'tree', 'long', 'representation', 'see', 'similar', 'performance', 'term', 'f1score', 'compare', 'orgmodel2', 'tree', 'description', 'orgmodel1', 'orgmodel2', 'achieve', 'increase', 'f1score', 'make', 'well', 'perform', 'model', 'sic', 'task', 'overall', 'classifier', 'achieve', 'reasonable', 'performance', 'different', 'cate', 'gorie', 'however', 'category', 'performance', 'still', 'weak', 'possibly', 'particularly', 'broad', 'difficult', 'distinguish', 'cat', 'egorie', 'yet', 'model', 'achieve', 'great', 'f1score', 'majority', 'category', 'illustrate', 'promise', 'use', 'nlp', 'model', 'automatically', 'classify', 'organization', 'conclusion', 'future', 'plan', 'study', 'demonstrate', 'potential', 'use', 'natural', 'language', 'processing', 'nlp', 'technique', 'automatic', 'acquisition', 'structured', 'food', 'system', 'knowledge', 'source', 'include', 'classification', 'entity', 'involve', 'food', 'activ', 'itie', 'linkage', 'social', 'environmental', 'healthrelate', 'issue', 'use', 'text', 'snippet', 'retrieve', 'search', 'engine', 'descriptive', 'basis', 'el', 'able', 'classify', 'organization', 'accord', 'environmental', 'issue', 'category', 'standard', 'industrial', 'classification', 'sic', 'code', 'specifically', 'build', 'model', 'base', 'transformerbase', 'language', 'model', 'experimental', 'result', 'show', 'use', 'textual', 'datum', 'search', 'achieve', 'well', 'performance', 'use', '10k', 'filing', 'organization', 'annual', 'report', 'provide', 'security', 'exchange', 'com', 'mission', 'database', 'also', 'show', 'incorporate', 'description', 'text', 'environmental', 'issue', 'category', 'sic', 'code', 'model', 'achieve', 'well', 'performance', 'classification', 'task', 'promise', 'result', 'underline', 'applicability', 'proach', 'improve', 'food', 'ontology', 'well', 'intelligent', 'food', 'system', 'knowledge', 'resource', 'little', 'human', 'supervision', 'work', 'illustrate', 'model', 'hold', 'potential', 'wide', 'range', 'automatic', 'categorization', 'food', 'system', 'actor', 'activity', 'exist', 'food', 'environment', 'health', 'system', 'ontologie', 'tologie', 'instantiate', 'nlp', 'model', 'represent', 'burgeon', 'yet', 'powerful', 'instrument', 'quick', 'efficient', 'population', 'large', 'food', 'system', 'knowledge', 'graph', 'consistent', 'knowledge', 'representation', 'research', 'open', 'door', 'provide', 'critical', 'component', 'design', 'creation', 'reusable', 'cyberinfrastructure', 'component', 'capable', 'address', 'major', 'social', 'environmental', 'issue', 'scale', 'climate', 'action', 'food', 'system', 'component', 'include', 'development', 'additional', 'technological', 'knowledge', 'relational', 'infra', 'tructure', 'build', 'recent', 'advance', 'datum', 'modeling', 'management', 'link', 'component', 'together', 'afford', 'opportunity', 'make', 'lead', 'edge', 'insight', 'tool', 'practical', 'guidance', 'available', 'action', 'partner', 'food', 'system', 'acknowledgment', 'want', 'thank', 'anonymous', 'reviewer', 'valuable', 'comment', 'research', 'support', 'part', 'icicle', 'project', 'award', 'oac', 'canadian', 'institute', 'health', 'research', 'cihr', 'reference', 'hollander', 'ad', 'huber', 'hyder', 'lange', 'quinn', 'jf', 'rig', 'tomich', 'tp', 'smart', 'foodshed', 'use', 'stakeholder', 'engagement', 'improve', 'informatic', 'framework', 'regional', 'food', 'system', 'annal', 'geographer', 'doi', 'yassine', 'shirmohammadi', 'namahoot', 'bru¨ckner', 'internet', 'food', 'food', 'ontology', 'internet', 'thing', 'future', 'internet', 'dooley', 'bordea', 'carmody', 'l', 'castellanoescuder', 'c', 'mougin', 'food', 'ontology', 'interconnectivity', 'inceur', 'workshop', 'proceeding', 'dooley', 'griffith', 'gosal', 'gs', 'r', 'lange', 'schriml', 'harmonize', 'food', 'ontology', 'increase', 'global', 'food', 'traceability', 'quality', 'control', 'data', 'integration', 'science', 'food', 'odorico', 'seekell', 'food', 'inequality', 'injustice', 'right', 'bioscience', 'fanzo', 'j', 'arabi', 'recine', 'e', 'l', 'sinha', 'nutrition', 'food', 'system', 'report', 'high', 'level', 'panel', 'expert', 'food', 'security', 'nutrition', 'committee', 'world', 'food', 'security', 'fanzo', 'system', 'diet', 'nutrition', 'springer', 'international', 'publishing', 'pretraining', 'deep', 'bidirec', 'tional', 'transformer', 'language', 'understanding', 'proceeding', 'con', 'ference', 'north', 'american', 'chapter', 'association', 'human', 'language', 'technology', 'kotiaho', 'halme', 'p', 'ipbe', 'assessment', 'report', 'land', 'degradation', 'restoration', 'ipbe', 'nicole´tis', 'e', '´', 'termine', 'p', 'reduce', 'inequality', 'food', 'security', 'nutrition', 'hlpe', 'consultation', 'report', 'scope', 'global', 'forum', 'food', 'security', 'nutrition', 'fsn', 'radford', 'child', 'r', 'sutskever', 'language', 'model', 'unsupervise', 'learner', 'blog', 'ontology', 'blackwell', 'guide', 'philosophy', 'compute', 'formation', 'edit', 'blackwell', 'tomich', 'tp', 'c', 'dimock', 'hollander', 'ad', 'huber', 'hyder', 'lange', 'mc', 'riggle', 'need', 'food', 'system', 'informatic', 'introduction', 'special', 'collection', 'smart', 'connected', 'regional', 'food', 'sys', 'tem', 'sustainability', 'fao', 'ifad', 'unicef', 'wfp', 'state', 'food', 'security', 'nutrition', 'world', 'transform', 'food', 'system', 'food', 'security', 'improve', 'nutrition', 'affordable', 'healthy', 'diet', 'fao', 'doi', 'emission', 'gap', 'report', 'closing', 'window', 'climate', 'crisis', 'call', 'rapid', 'transformation', 'society']"
"Classifying Organizations for Food System Ontologies using Natural
  Language Processing","[{'href': 'http://arxiv.org/abs/2309.10880v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2309.10880v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-09-19 19:07:48,"Why We Don’t Have AGI Yet 

Peter	Voss,	AIGO.ai,	Austin	TX,	USA,	peter@aigo.ai	
Mlađan	Jovanović,	Singidunum	University,	Belgrade	Serbia,	mjovanovic@singidunum.ac.rs	

Abstract	–	The	original	vision	of	AI	was	re-articulated	in	2002	via	the	term	‘Artificial	General	Intelligence’	
or	AGI.	This	vision	is	to	build	‘Thinking	Machines’	–	computer	systems	that	can	learn,	reason,	and	solve	
problems	similar	to	the	way	humans	do.	This	is	in	stark	contrast	to	the	‘Narrow	AI’	approach	practiced	
by	almost	everyone	in	the	field	over	the	many	decades.	While	several	large-scale	efforts	have	nominally	
been	working	on	AGI	(most	notably	DeepMind),	the	field	of	pure	focused	AGI	development	has	not	been	
well	 funded	 or	 promoted.	 This	 is	 surprising	 given	 the	 fantastic	 value	 that	 true	 AGI	 can	 bestow	 on	
humanity.	 In	 addition	 to	 the	 dearth	 of	 effort	 in	 this	 field,	 there	 are	 also	 several	 theoretical	 and	
methodical	 missteps	 that	 are	 hampering	 progress.	 We	 highlight	 why	 purely	 statistical	 approaches	 are	
unlikely	 to	 lead	 to	 AGI,	 and	 identify	 several	 crucial	 cognitive	 abilities	 required	 to	 achieve	 human-like	
adaptability	and	autonomous	learning.	We	conclude	with	a	survey	of	socio-technical	factors	that	have	
undoubtedly	slowed	progress	towards	AGI.	

Keywords:	AGI,	Cognitive	AI,	Adaptive	AI,	Human-Level	AI,	Cognitive	Architecture,	Third	Wave	of	AI.	

A Brief History of ‘AGI’ 
Originally,	the	term	‘Artificial	Intelligence’,	coined	by	John	McCarthy	in	1955	[1],	referred	to	machines	or	
computer	 programs	 that	 can	 think,	 learn,	 and	 reason	 the	 way	 humans	 do	 –	 that	 have	 the	 general	
cognitive	ability	that	we	possess.	At	the	time	he	expected	this	to	be	achieved	within	a	few	months!		

As	 it	 turned	 out	 this	 was	 a	 lot	 harder,	 so	 over	 the	 years	 and	 decades	 the	 field	 of	 ‘AI’	 morphed	 into	
‘Narrow	AI’	–	solving	just	one	(type	of)	problem	at	a	time.	An	often	overlooked	but	crucial	detrimental	
consequence	of	this	shift	was	that	focus	was	now	on	‘achieving	a	particular	goal	via	the	ingenuity	of	the	
programmer	or	data	scientist’	rather	than	‘how	do	we	build	a	system	that	has	general	intelligence’.		

Therefore,	AI’s	focus	had	shifted	from	having	internal	intelligence	to	utilizing	external	intelligence	(the	
programmer’s	 intelligence)	 to	 solve	 particular	 problems.	 This	 preoccupation	 with	 achieving	 specific	
narrow	goals	also	had	the	undesirable	side-effect	of	ignoring	the	importance	of	adaptation	and	agency.	
Intelligent	 entities	 must	 be	 able	 to	 autonomously	 adapt	 to	 changing	 circumstances	 and	 goals.	 The	
entities	are	agents	that	proactively	initiate	actions	in	their	surroundings	[2].	

By	2001	a	number	of	AI	researchers	had	independently	concluded	that	the	time	was	ripe	to	return	to	
the	original	vision	of	‘AI’	and	decided	to	join	forces	to	write	a	book	on	this	subject	[3].	In	2002,	three	of	
the	authors	(Ben	Goertzel,	Shane	Legg,	and	Peter	Voss)	coined	the	term	‘Artificial	General	Intelligence’	
for	the	book	title.	

AGI	 refers	 	 to	 creating	 (semi-)autonomous,	 adaptive	 computer	 systems	 with	 the	 general	 cognitive	
capabilities	 typical	 for	 	 humans.	 The	 ability	 to	 support	 abstraction,	 analogy,	 planning	 and	 problem-
solving.	

1	

	
	
	
	
Figure	1.	Comparison	of	external	and	internal	intelligence.	

The Value of AGI 
Imagine	a	computer	system	that	has	the	general	cognitive	prowess	and	knowledge	of	a	medical	cancer	
expert.	Now	imagine	a	million	copies	of	this	chipping	away	at	this	scourge.	Also	consider	the	following	
advantages	of	artificial	researchers	and	workers:	

!  Massively	lower	cost	than	humans	performing	cognitive	tasks.	
!  Much	better	at	communicating	and	sharing	knowledge	with	each	other	–	no	egos	to	get	in	the	way!	
!  Toiling	away	365/24/7,	much	faster	and	with	better	concentration.	
!  Not	having	the	various	‘distractions’	that	we	have	–	e.g.	family,	vacation,	hobbies,	etc.	
! 
!  A	much-improved	ability	to	think	logically,	and	to	perform	complex	planning	and	reasoning.	

‘Photographic	memory’,	and	instant	access	to	all	online	information.	

Now	 apply	 these	 powers	 to	 the	 many	 challenges	 facing	 humanity:	 energy,	 environment,	 poverty,	
physical	and	mental	wellbeing,	aging,	conflict	resolution,	governance,	etc.		

AGI	promises	to	be	able	to	significantly	increase	human	flourishing.	

GPT (Generative Pretrained Transformer) as an attempt to achieve AGI 
The	 recent	 success	 of	 transformer-based	 systems	 and	 other	 Large	 Language	 Models	 (LLMs)	 has	 given	
rise	 to	 speculations	 that	 these	 powerful	 systems	 may,	 with	 relatively	 minor	 enhancements,	 grow	 into	
AGI.	 This	 is	 extremely	 unlikely	 given	 the	 hard	 requirements	 for	 human-level	 AGI	 such	 as	 reliability	 [4],	
predictability	 [5],	 and	 non-toxicity	 [6];	 real-time,	 life-long	 learning;	 and	 high-level	 reasoning	 and	
metacognition.		

GPT-based	systems	are	by	definition	‘generative’	(they	produce	artificial	content	based	on	probabilities	
of	co-occurrences;	they	make	up	stuff)	and	pre-trained	(almost	all	of	their	knowledge	is	non-adaptive,	
not	 acquired	 interactively	 or	 in	 real-time).	 Due	 to	 their	 correlational	 nature	 LLMs	 fundamentally	 lack	
robust	 reasoning.	 Moreover,	 neural	 networks	 can	 perform	 poorly	 on	 previously	 learned	 tasks	 when	
exposed	to	new	data	and	learning	new	tasks	(known	as	catastrophic	forgetting)	[7].		

Despite	these	limitations,	properly	curated	and	cross-validated	LLM	queries	could	be	extremely	valuable	
for	 helping	 with	 the	 difficult	 task	 of	 training	 AGIs;	 helping	 to	 provide	 the	 massive	 amount	 of	 general	
knowledge	that	they	will	need.	

2	

	
	
	
	
	
	
Human-Like Cognitive Abilities – Cognitive AI 
Cognitive	 AI	 describes	 machine	 systems	 able	 to	 understand	 language,	 use	 commonsense	 knowledge,	
reason,	and	adapt	to	unseen	circumstances,	similar	to	humans	[8].	

AGI	 assistants	 and	 researchers	 that	 can	 help	 us	 solve	 important	 (and	 not	 so	 important)	 problems	 will	
need	 to	 operate	 in	 the	 real	 world,	 to	 have	 a	 deep	 understanding	 of	 life	 and	 science,	 to	 effectively	
communicate	with	us,	to	use	our	tools	and	systems,	and	to	be	able	to	learn	and	innovate.	This	requires	a	
specific	 approach	 to	 building	 AGI,	 one	 that	 focuses	 on	 real-time,	 life-long	 conceptual	 learning	 and	
reasoning.		

While	such	AGIs	will	be	super-human	in	many	ways,	they	will	be	constrained	by	having	to	operate	with	
incomplete	and	often	contradictory	information,	and	limited	time	and	resources	to	perform	their	tasks.	
On	the	other	hand,	they	will	not	require	human-level	sense-acuity	or	dexterity.	One	could	call	this	the	
Helen-Hawking	model	of	AGI	(Helen	Keller/	Stephen	Hawking)	–	AGI	with	human-level	cognition	but	not	
overall	 human-level	 physical	 ability.	 They	 do,	 however,	 need	 to	 have	 some	 means	 of	 capturing	 and	
interacting	 with	 our	 4D	 world.	 This	 could	 be	 accomplished	 via,	 for	 example,	 PC	 screen,	 keyboard,	 and	
mouse	access.	Beyond	that,	AGIs	will	also	be	excellent	tool	users,	just	like	us.	

We	see	that	Cognitive	AI	is	the	clearest,	and	most	definitive	and	direct	path	to	AGI.	

Figure	2.	Dimensions	of	Adaptive	Autonomous	Intelligence.	

Defining the ‘I’ in AGI 
Defining	‘intelligence’	as	such	is	a	thankless	task,	so	instead,	we	will	focus	on	a	practical	description	of	
the	 kind	 of	 cognition/	 intelligence	 required	 to	 achieve	 the	 AGI	 goals	 mentioned	 above.	 Essential	
requirements	include:	

""  The	ability	to	autonomously	learn	multi-dimensional	objects,	actions	and	sequences,	including	their	

appropriate	context.	

""  To	do	this	incrementally	in	real	time,	in	an	integrated	manner	(knowledge	representation).	
""  To	contextually	identify	known	objects,	actions,	and	sequences	given	partial	or	similar		input.	

3	

	
	
	
""  The	ability	to	generalize	and	to	form	new	concepts	and	analogies	autonomously.	
""  To	learn	to	associate	words	with	their	respective	concepts,	and	to	learn	language	by	understanding	

it.	

""  To	 learn	 action	 sequences	 and	 their	 associated	 ‘triggers’	 via	 aping,	 exploration,	 trial-and-error,	
reinforcement,	instructions,	reasoning,	and	by	other	means	(autonomous	and	semi-autonomous).	

""  The	ability	to	adapt	or	unlearn	existing	knowledge	and	skills.	
""  The	ability	to	reason	abstractly,	including	planning,	and	theory-of-mind	reasoning.	
""  Meta-cognitive	reasoning	and	control	(System	2	from	[9]).	
""  Heuristic	search	and	problem	solving	ability.	 
""  To	have	and	use	both	short-term	and	long-term	memory	for	context,	recognition,	and	reasoning.	
""  Means	to	focus	on	and	select	particular	features	available	both	externally	and	internally.	

This	list	is	not	exhaustive	but	does	cover	the	most	essential	cognitive	abilities	required	for	AGI.	The	ideas	
of	 AGI	 have	 been	 around	 for	 decades.	 But	 only	 recently,	 it	 has	 been	 recognized	 as	 an	 emerging	
technological	megatrend	[10].	

The Three Waves of AI 
A	few	years	ago	DARPA	presented	a	simple	chronological	taxonomy	of	AI	called	‘The	Three	Waves	of	AI’	
[11]	broken	up	as	follows:	

1)  Rule-based	 approaches	 also	 referred	 to	 as	 ‘GOFAI’	 (Good	 Old-Fashioned	 AI),	 which	 dominated	 the	
field	 until	 about	 2010	 is	 the	 first	 ‘wave’.	 This	 is	 characterized	 by	 largely	 hand-crafted	 data	 and	
algorithms.	 It	 includes	 expert	 systems,	 sophisticated	 logic	 and	 search	 algorithms,	 planning	 and	
scheduling	systems,	semantic	web	representation,	natural	language	processing	systems	and	the	like.	
Its	most	visible	successes	were	IBM’s	Deep	Blue	chess	champion	in	1997	and	Watson,	their	Jeopardy	
quiz	champion.	

2)  The	second	wave	hit	like	a	tsunami	around	2012	when	researchers	figured	out	how	to	build	neural	
networks	using	massive	amounts	of	data	and	computational	power,	including	GPU/TPUs.	This	led	to	
breakthroughs	in	translation,	image	and	speech	recognition,	mastery	of	many	games	(including	Go)	
and	 ultimately	 powerful	 vision,	 speech,	 and	 text	 generation	 via	 GPTs.	 Currently,	 the	 pinnacle	 of	
these	developments	is	represented	by	various	LLMs	such	as	ChatGPT.	This	wave	is	characterized	by	
statistical	and	reinforcement	learning;	much	of	it	is	un-	or	self-supervised.	

3)  This	final	wave	is	still	in	its	infancy.	Its	focus	fully	aligns	with	the	requirements	of	AGI:	Autonomous,	
real-time	 learning	 and	 adaptation,	 and	 high-level	 reasoning.	 It	 also	 expects	 concepts	 to	 be	 more	
grounded	in	reality	(as	opposed	to	language	statistics),	robust	few-shot	learning,	and	explainability.	
We	 would	 expect	 these	 systems	 to	 elegantly	 integrate	 sub-symbolic	 pattern	 matching	 with	 high-
level	 symbolic	 and	 linguistic	 reasoning.	 An	 obvious	 candidate	 for	 all	 of	 these	 requirements	 is	 the	
‘Cognitive	Architecture’	approach.	

4	

	
	
	
Figure	3.	The	Three	waves	of	AI.	Adapted	from	DARPA	[11].	

Cognitive Architectures 
Cognitive	 Architectures,	 or	 more	 generally	 ‘Cognitive	 AI’,	 are	 founded	 on	 the	 idea	 of	 creating	 systems	
that	 encompass	 and	 embody	 all	 of	 the	 essential	 structures	 required	 for	 a	 (human-level)	 mind.	
Importantly,	it	also	considers	how	these	structures	and	functions	need	to	work	together	in	conjunction	
with	changing	knowledge	and	skills	to	yield	intelligence	in	diverse,	dynamic	environments	[12].	

Various	 cognitive	 architecture	 projects	 have	 been	 active	 for	 a	 few	 decades,	 though	 so	 far	 none	 have	
shown	sufficient	commercial promise	to	be	widely	adopted	or	particularly	well-funded	[8].	The	reasons	
are	manifold	and	complex	(see	next	section),	but	a	common	theme	is	that	they	are	implemented	in	far	
too	modular	and	inefficient	ways	[13],	and	they	lack	a	deep	theory	of	learning	and	cognition	[14]. 

A	novel	Cognitive	Architecture	designed	to	overcome	these	limitations	is	detailed	in	‘Concepts	is	All	You	
Need:	A	More	Direct	Path	to	AGI’	[15].	

Why don’t we have AGI yet? 
The	 short	 answer	may	well	be	that	there	simply	hasn’t	been	a	project	with	the	right	approach/theory	
plus	an	adequate	amount	of	funding.	Recent	success	of	ChatGPT	suggests	that	hardware	limitations	may	
not	 be	 a	 major	 bottleneck	 at	 this	 time,	 making	 feasible	 highly	 sophisticated	 language	 production	 or	
‘inference’.	

A	longer	answer	includes	the	following	considerations:	

#  Undoubtedly	 a	 major	 factor	 is	 that	 in	 spite	 of	 tens	 of	 thousands	 of	 AI	 researchers	 working	 in	 the	
field,	 only	 a	 tiny	 number	 are,	 by	 their	 own	 admission	 or	 by	 objective	 analysis,	 actually	 directly	
working	on	achieving	AGI.	

#  One	objective	measure	is	whether	the	AI	work	done	involves	a	clearly	identified	step	or	aspect	of	
an	 overall	 detailed	 plan	 to	 achieve	 AGI.	 Very	 little	 AI	 work	 matches	 this	 criterion.	 Specifically,	
Generative	AI	research	does	not.	

#  Even	 projects	 dedicated	 to	 developing	 AGI	 are	 seldom	 implemented	 with	 an	 explicit	 theory	 that	
actually	 matches	 the	 requirements	 of	 the	 kind	 of	 autonomous,	 adaptive	 intelligence	 needed	 for	
AGI.	

5	

	
	
	
	
#  Because	 of	 the	 tremendous	 success	 of	 Statistical	 AI	 (as	 opposed	 to	 Cognitive	 AI)	 over	 the	 past	
decade,	 currently	 almost	 all	 of	 the	 leading	 experts	 and	 practitioners	 in	 the	 field	 come	 from	
statistics,	 mathematics,	 or	 formal	 logic.	 This	 makes	 it	 almost	 impossible	 for	 them	 to	 see	 AGI	
requirements	from	a	cognitive	perspective.	

#  Unfortunately,	motivations	and	incentives	for	individuals,	teams,	and	companies	are	poorly	aligned	
to	optimizing	progress	towards	AGI.	Quite	the	contrary.	For	academics	it	is	to	publish	rather	than	to	
develop.	 For	 companies	 it	 is	 to	 produce	 impressive	 demos,	 or	 to	 beat	 humans	 at	 some	 game	 or	
activity	in	order	to	secure	additional	funding.	For	most	it	is	to	beat	existing	benchmarks	and	not	to	
change	them.	

#  Using	 existing	 benchmarks	 for	 AGI	

is	 highly	 problematic:	 Firstly,	 focus	 on	

incremental	
improvements	to	specific	existing	benchmarks	takes	effort	away	from	working	on	other	problems	
that	are	actually	more	fundamental	to	achieving	AGI.	It	is	easier	to	work	on	things	that	you	know	
how	 to	 make	 progress	 on,	 than	 to	 tackle	 difficult	 unknown	 issues.	 Secondly,	 current	 benchmarks	
are	 extremely	 poor	 at	 measuring	 progress	 of	 proto-AGIs.	 Early	 AGI	 systems	 will	 by	 definition	 do	
very	 poorly	 on	 existing	 narrow	 benchmarks,	 as	 well	 as	 on	 high-level	 IQ	 or	 professional	 admission	
tests.	

#  Even	if	all	the	stars	are	aligned	in	favor	of	developing	AGI	–	a	good	theory	and	development	plan,	
great	 cognitive	 team	 and	 funding,	 the	 right	 benchmarks	 –	 there	 still	 lurks	 what	 we	 can	 call	 ‘The	
Narrow	AI	Trap’.	Human	nature	is	such	that	we	instinctively	want	to	show	maximal	progress	in	the	
shortest	 time.	 Unfortunately,	 for	 AGI	 this	 often	 means	 that	 we	 end	 up	 using	 external	 human	
intelligence	 to	 achieve	 a	 specific	 result	 or	 make	 progress	 on	 a	 given	 benchmark	 rather	 than	
implementing	it	in	a	way	that	puts	the	intelligence	(adaptive,	autonomous	problem-solving	ability)	
into	the	system.	It	takes	careful	discipline	to	avoid	this.	Naturally,	AI	efforts	that	are	only	nominally	
AGI	(without	good	theory	or	plan),	will	more	easily	fall	into	this	trap.	

Figure	4.	Pressure	for	near-term	results	and	for	beating	existing	non-AGI	benchmarks	tends	to	deflect	

projects	away	from	AGI	capabilities,	towards	narrower	or	commercial	implementations.	

6	

	
	
	
	
	
	
	
#  Finally,	it	is	worth	mentioning	a	lack	of	clear	vision	by	people	who	could	help	to	make	AGI	happen	
sooner.	 People	 who	 claim	 to	 not	 be	 motivated	 by	 money,	 but	 by	 helping	 mankind	 flourish.	 Yet	
many	put	their	effort,	reputation	and	money	behind	the	latest	fad	or	biggest	potential	short-term	
win.	

Conclusion 
The	 spectacular	 performance	 of	 recent	 GPT	 technology	 teases	 the	 possibility	 that	 we	 may	 at	 last	 be	
close	to	being	able	to	realize	the	original	vision	of	‘AI’	–	to	have	human-level	‘Thinking	Machines’.	The	
term	 ‘AGI’	 was	 coined	 to	 (re)focus	 on	 this	 objective,	 and	 to	 bring	 about	 technology	 that	 can	 help	 us	
solve	the	many	problems	that	humanity	faces,	to	enhance	human	flourishing.	

However,	a	detailed	analysis	of	what	human-level	cognition	requires	shows	that	most	of	the	technical	
approaches,	 motivations	 and	 benchmarks	 currently	 dominating	 the	 field	 of	 AI	 are	 not	 aligned	 with	
achieving	this	objective.	

In	order	to	accelerate	progress	towards	AGI	we	will	need	to	focus	on	the	core	requirements	of	human-
like	 cognition	 –	 on	 items	 like	 autonomous,	 real-time,	 incremental	 learning;	 concept	 formation;	 and	
metacognitive	control.	We	need	to	shift	from	Second	to	Third	Wave	AI,	from	Statistical	or	Generative	AI	
to	Cognitive	AI.	

Acknowledgment 
We	thank	Dr.	Pat	Langley	for	his	constructive	comments.	

References 
[1]	 McCarthy,	 J.,	 Minsky,	 M.	 L.,	 Rochester,	 N.,	 &	 Shannon,	 C.	 E.	 (2006).	 A	 Proposal	 for	 the	 Dartmouth	
Summer	Research	Project	on	Artificial	Intelligence,	August	31,	1955.	AI	Magazine,	27(4),	12.	

[2]	Gallagher,	S.	(2000).	Philosophical	conceptions	of	the	self:	implications	for	cognitive	science.	Trends	
in	cognitive	sciences,	4(1),	14-21.	

[3]	Goertzel,	B.	(2007).	Artificial	general	intelligence	(Vol.	2,	p.	1).	C.	Pennachin	(Ed.).	New	York:	Springer.	

[4]	 Zou,	 A.,	 Wang,	 Z.,	 Kolter,	 J.	 Z.,	 &	 Fredrikson,	 M.	 (2023).	 Universal	 and	 Transferable	 Adversarial	
Attacks	on	Aligned	Language	Models.	arXiv	preprint	arXiv:2307.15043.	

[5]	Chen,	L.,	Zaharia,	M.,	&	Zou,	J.	(2023).	How	is	ChatGPT's	behavior	changing	over	time?.	arXiv	preprint	
arXiv:2307.09009. 

[6]	 Wang,	 B.,	 Chen,	 W.,	 Pei,	 H.,	 Xie,	 et	 al.,	 (2023).	 DecodingTrust:	 A	 Comprehensive	 Assessment	 of	
Trustworthiness	in	GPT	Models.	arXiv	preprint	arXiv:2306.11698.	

[7]	 Kong,	 Y.,	 Liu,	 L.,	 Chen,	 H.,	 Kacprzyk,	 J.,	 &	 Tao,	 D.	 (2023).	 Overcoming	 Catastrophic	 Forgetting	 in	
Continual	 Learning	 by	 Exploring	 Eigenvalues	 of	 Hessian	 Matrix.	 IEEE	 Transactions	 on	 Neural	 Networks	
and	Learning	Systems.	

[8]	Kotseruba,	I.,	&	Tsotsos,	J.	K.	(2020).	40	years	of	cognitive	architectures:	core	cognitive	abilities	and	
practical	applications.	Artificial	Intelligence	Review,	53(1),	17-94.	

[9]	Kahneman,	D.	(2011).	Thinking,	fast	and	slow.	Farrar,	Straus	and	Giroux.	

[10]	 Bash,	 C.,	 Faraboschi,	 P.,	 Frachtenberg,	 E.,	 Laplante,	 P.,	 Milojicic,	 D.,	 &	 Saracco,	 R.	 (2023).	
Megatrends.	IEEE	Computer,	56(07),	93-100.	

[11]	 A	 DARPA	 Perspective	 on	 Artificial	 Intelligence	 (2017).	 https://www.darpa.mil/about-us/darpa-
perspective-on-ai.	(Accessed	07.08.2023).	

[12]	Langley,	P.	(2012).	The	Cognitive	Systems	Paradigm.	Advances	in	Cognitive	Systems,	1(1),	3-13.	

7	

	
	
	
	
[13]	 Langley,	 P.,	 Laird,	 J.	 E.,	 &	 Rogers,	 S.	 (2009).	 Cognitive	 architectures:	 Research	 issues	 and	
challenges.	Cognitive	Systems	Research,	10(2),	141-160.	

[14]	 Wang,	 P.	 (2012).	 Theories	 of	 Artificial	 Intelligence	 -	 Meta-theoretical	 Considerations.	 Theoretical	
Foundations	of	Artificial	General	Intelligence.	Paris:	Atlantis	Press.	

[15]	Voss,	P.,	&	Jovanovic,	M.	(2023).	Concepts	is	All	You	Need:	A	More	Direct	Path	to	AGI.	arXiv	preprint	
arXiv:2309.01622.	

8	

	
","Why We Don ’ t Have AGI Yet Peter Voss , AIGO.ai , Austin TX , USA , peter @ aigo.ai Mlađan Jovanović , Singidunum University , Belgrade Serbia , mjovanovic @ singidunum.ac.rs Abstract – The original vision of AI was re-articulated in 2002 via the term ‘ Artificial General Intelligence ’ or AGI . This vision is to build ‘ Thinking Machines ’ – computer systems that can learn , reason , and solve problems similar to the way humans do . This is in stark contrast to the ‘ Narrow AI ’ approach practiced by almost everyone in the field over the many decades . While several large-scale efforts have nominally been working on AGI ( most notably DeepMind ) , the field of pure focused AGI development has not been well funded or promoted . This is surprising given the fantastic value that true AGI can bestow on humanity . In addition to the dearth of effort in this field , there are also several theoretical and methodical missteps that are hampering progress . We highlight why purely statistical approaches are unlikely to lead to AGI , and identify several crucial cognitive abilities required to achieve human-like adaptability and autonomous learning . We conclude with a survey of socio-technical factors that have undoubtedly slowed progress towards AGI . Keywords : AGI , Cognitive AI , Adaptive AI , Human-Level AI , Cognitive Architecture , Third Wave of AI . A Brief History of ‘ AGI ’ Originally , the term ‘ Artificial Intelligence ’ , coined by John McCarthy in 1955 [ 1 ] , referred to machines or computer programs that can think , learn , and reason the way humans do – that have the general cognitive ability that we possess . At the time he expected this to be achieved within a few months ! As it turned out this was a lot harder , so over the years and decades the field of ‘ AI ’ morphed into ‘ Narrow AI ’ – solving just one ( type of ) problem at a time . An often overlooked but crucial detrimental consequence of this shift was that focus was now on ‘ achieving a particular goal via the ingenuity of the programmer or data scientist ’ rather than ‘ how do we build a system that has general intelligence ’ . Therefore , AI ’ s focus had shifted from having internal intelligence to utilizing external intelligence ( the programmer ’ s intelligence ) to solve particular problems . This preoccupation with achieving specific narrow goals also had the undesirable side-effect of ignoring the importance of adaptation and agency . Intelligent entities must be able to autonomously adapt to changing circumstances and goals . The entities are agents that proactively initiate actions in their surroundings [ 2 ] . By 2001 a number of AI researchers had independently concluded that the time was ripe to return to the original vision of ‘ AI ’ and decided to join forces to write a book on this subject [ 3 ] . In 2002 , three of the authors ( Ben Goertzel , Shane Legg , and Peter Voss ) coined the term ‘ Artificial General Intelligence ’ for the book title . AGI refers to creating ( semi- ) autonomous , adaptive computer systems with the general cognitive capabilities typical for humans . The ability to support abstraction , analogy , planning and problem- solving . 1 Figure 1 . Comparison of external and internal intelligence . The Value of AGI Imagine a computer system that has the general cognitive prowess and knowledge of a medical cancer expert . Now imagine a million copies of this chipping away at this scourge . Also consider the following advantages of artificial researchers and workers : ! Massively lower cost than humans performing cognitive tasks . ! Much better at communicating and sharing knowledge with each other – no egos to get in the way ! ! Toiling away 365/24/7 , much faster and with better concentration . ! Not having the various ‘ distractions ’ that we have – e.g . family , vacation , hobbies , etc . ! ! A much-improved ability to think logically , and to perform complex planning and reasoning . ‘ Photographic memory ’ , and instant access to all online information . Now apply these powers to the many challenges facing humanity : energy , environment , poverty , physical and mental wellbeing , aging , conflict resolution , governance , etc . AGI promises to be able to significantly increase human flourishing . GPT ( Generative Pretrained Transformer ) as an attempt to achieve AGI The recent success of transformer-based systems and other Large Language Models ( LLMs ) has given rise to speculations that these powerful systems may , with relatively minor enhancements , grow into AGI . This is extremely unlikely given the hard requirements for human-level AGI such as reliability [ 4 ] , predictability [ 5 ] , and non-toxicity [ 6 ] ; real-time , life-long learning ; and high-level reasoning and metacognition . GPT-based systems are by definition ‘ generative ’ ( they produce artificial content based on probabilities of co-occurrences ; they make up stuff ) and pre-trained ( almost all of their knowledge is non-adaptive , not acquired interactively or in real-time ) . Due to their correlational nature LLMs fundamentally lack robust reasoning . Moreover , neural networks can perform poorly on previously learned tasks when exposed to new data and learning new tasks ( known as catastrophic forgetting ) [ 7 ] . Despite these limitations , properly curated and cross-validated LLM queries could be extremely valuable for helping with the difficult task of training AGIs ; helping to provide the massive amount of general knowledge that they will need . 2 Human-Like Cognitive Abilities – Cognitive AI Cognitive AI describes machine systems able to understand language , use commonsense knowledge , reason , and adapt to unseen circumstances , similar to humans [ 8 ] . AGI assistants and researchers that can help us solve important ( and not so important ) problems will need to operate in the real world , to have a deep understanding of life and science , to effectively communicate with us , to use our tools and systems , and to be able to learn and innovate . This requires a specific approach to building AGI , one that focuses on real-time , life-long conceptual learning and reasoning . While such AGIs will be super-human in many ways , they will be constrained by having to operate with incomplete and often contradictory information , and limited time and resources to perform their tasks . On the other hand , they will not require human-level sense-acuity or dexterity . One could call this the Helen-Hawking model of AGI ( Helen Keller/ Stephen Hawking ) – AGI with human-level cognition but not overall human-level physical ability . They do , however , need to have some means of capturing and interacting with our 4D world . This could be accomplished via , for example , PC screen , keyboard , and mouse access . Beyond that , AGIs will also be excellent tool users , just like us . We see that Cognitive AI is the clearest , and most definitive and direct path to AGI . Figure 2 . Dimensions of Adaptive Autonomous Intelligence . Defining the ‘ I ’ in AGI Defining ‘ intelligence ’ as such is a thankless task , so instead , we will focus on a practical description of the kind of cognition/ intelligence required to achieve the AGI goals mentioned above . Essential requirements include : `` The ability to autonomously learn multi-dimensional objects , actions and sequences , including their appropriate context. `` To do this incrementally in real time , in an integrated manner ( knowledge representation ) . `` To contextually identify known objects , actions , and sequences given partial or similar input . 3 `` The ability to generalize and to form new concepts and analogies autonomously. `` To learn to associate words with their respective concepts , and to learn language by understanding it. `` To learn action sequences and their associated ‘ triggers ’ via aping , exploration , trial-and-error , reinforcement , instructions , reasoning , and by other means ( autonomous and semi-autonomous ) . `` The ability to adapt or unlearn existing knowledge and skills. `` The ability to reason abstractly , including planning , and theory-of-mind reasoning. `` Meta-cognitive reasoning and control ( System 2 from [ 9 ] ) . `` Heuristic search and problem solving ability. `` To have and use both short-term and long-term memory for context , recognition , and reasoning. `` Means to focus on and select particular features available both externally and internally . This list is not exhaustive but does cover the most essential cognitive abilities required for AGI . The ideas of AGI have been around for decades . But only recently , it has been recognized as an emerging technological megatrend [ 10 ] . The Three Waves of AI A few years ago DARPA presented a simple chronological taxonomy of AI called ‘ The Three Waves of AI ’ [ 11 ] broken up as follows : 1 ) Rule-based approaches also referred to as ‘ GOFAI ’ ( Good Old-Fashioned AI ) , which dominated the field until about 2010 is the first ‘ wave ’ . This is characterized by largely hand-crafted data and algorithms . It includes expert systems , sophisticated logic and search algorithms , planning and scheduling systems , semantic web representation , natural language processing systems and the like . Its most visible successes were IBM ’ s Deep Blue chess champion in 1997 and Watson , their Jeopardy quiz champion . 2 ) The second wave hit like a tsunami around 2012 when researchers figured out how to build neural networks using massive amounts of data and computational power , including GPU/TPUs . This led to breakthroughs in translation , image and speech recognition , mastery of many games ( including Go ) and ultimately powerful vision , speech , and text generation via GPTs . Currently , the pinnacle of these developments is represented by various LLMs such as ChatGPT . This wave is characterized by statistical and reinforcement learning ; much of it is un- or self-supervised . 3 ) This final wave is still in its infancy . Its focus fully aligns with the requirements of AGI : Autonomous , real-time learning and adaptation , and high-level reasoning . It also expects concepts to be more grounded in reality ( as opposed to language statistics ) , robust few-shot learning , and explainability . We would expect these systems to elegantly integrate sub-symbolic pattern matching with high- level symbolic and linguistic reasoning . An obvious candidate for all of these requirements is the ‘ Cognitive Architecture ’ approach . 4 Figure 3 . The Three waves of AI . Adapted from DARPA [ 11 ] . Cognitive Architectures Cognitive Architectures , or more generally ‘ Cognitive AI ’ , are founded on the idea of creating systems that encompass and embody all of the essential structures required for a ( human-level ) mind . Importantly , it also considers how these structures and functions need to work together in conjunction with changing knowledge and skills to yield intelligence in diverse , dynamic environments [ 12 ] . Various cognitive architecture projects have been active for a few decades , though so far none have shown sufficient commercial promise to be widely adopted or particularly well-funded [ 8 ] . The reasons are manifold and complex ( see next section ) , but a common theme is that they are implemented in far too modular and inefficient ways [ 13 ] , and they lack a deep theory of learning and cognition [ 14 ] . A novel Cognitive Architecture designed to overcome these limitations is detailed in ‘ Concepts is All You Need : A More Direct Path to AGI ’ [ 15 ] . Why don ’ t we have AGI yet ? The short answer may well be that there simply hasn ’ t been a project with the right approach/theory plus an adequate amount of funding . Recent success of ChatGPT suggests that hardware limitations may not be a major bottleneck at this time , making feasible highly sophisticated language production or ‘ inference ’ . A longer answer includes the following considerations : # Undoubtedly a major factor is that in spite of tens of thousands of AI researchers working in the field , only a tiny number are , by their own admission or by objective analysis , actually directly working on achieving AGI . # One objective measure is whether the AI work done involves a clearly identified step or aspect of an overall detailed plan to achieve AGI . Very little AI work matches this criterion . Specifically , Generative AI research does not . # Even projects dedicated to developing AGI are seldom implemented with an explicit theory that actually matches the requirements of the kind of autonomous , adaptive intelligence needed for AGI . 5 # Because of the tremendous success of Statistical AI ( as opposed to Cognitive AI ) over the past decade , currently almost all of the leading experts and practitioners in the field come from statistics , mathematics , or formal logic . This makes it almost impossible for them to see AGI requirements from a cognitive perspective . # Unfortunately , motivations and incentives for individuals , teams , and companies are poorly aligned to optimizing progress towards AGI . Quite the contrary . For academics it is to publish rather than to develop . For companies it is to produce impressive demos , or to beat humans at some game or activity in order to secure additional funding . For most it is to beat existing benchmarks and not to change them . # Using existing benchmarks for AGI is highly problematic : Firstly , focus on incremental improvements to specific existing benchmarks takes effort away from working on other problems that are actually more fundamental to achieving AGI . It is easier to work on things that you know how to make progress on , than to tackle difficult unknown issues . Secondly , current benchmarks are extremely poor at measuring progress of proto-AGIs . Early AGI systems will by definition do very poorly on existing narrow benchmarks , as well as on high-level IQ or professional admission tests . # Even if all the stars are aligned in favor of developing AGI – a good theory and development plan , great cognitive team and funding , the right benchmarks – there still lurks what we can call ‘ The Narrow AI Trap ’ . Human nature is such that we instinctively want to show maximal progress in the shortest time . Unfortunately , for AGI this often means that we end up using external human intelligence to achieve a specific result or make progress on a given benchmark rather than implementing it in a way that puts the intelligence ( adaptive , autonomous problem-solving ability ) into the system . It takes careful discipline to avoid this . Naturally , AI efforts that are only nominally AGI ( without good theory or plan ) , will more easily fall into this trap . Figure 4 . Pressure for near-term results and for beating existing non-AGI benchmarks tends to deflect projects away from AGI capabilities , towards narrower or commercial implementations . 6 # Finally , it is worth mentioning a lack of clear vision by people who could help to make AGI happen sooner . People who claim to not be motivated by money , but by helping mankind flourish . Yet many put their effort , reputation and money behind the latest fad or biggest potential short-term win . Conclusion The spectacular performance of recent GPT technology teases the possibility that we may at last be close to being able to realize the original vision of ‘ AI ’ – to have human-level ‘ Thinking Machines ’ . The term ‘ AGI ’ was coined to ( re ) focus on this objective , and to bring about technology that can help us solve the many problems that humanity faces , to enhance human flourishing . However , a detailed analysis of what human-level cognition requires shows that most of the technical approaches , motivations and benchmarks currently dominating the field of AI are not aligned with achieving this objective . In order to accelerate progress towards AGI we will need to focus on the core requirements of human- like cognition – on items like autonomous , real-time , incremental learning ; concept formation ; and metacognitive control . We need to shift from Second to Third Wave AI , from Statistical or Generative AI to Cognitive AI . Acknowledgment We thank Dr. Pat Langley for his constructive comments . References [ 1 ] McCarthy , J. , Minsky , M. L. , Rochester , N. , & Shannon , C. E. ( 2006 ) . A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence , August 31 , 1955 . AI Magazine , 27 ( 4 ) , 12 . [ 2 ] Gallagher , S. ( 2000 ) . Philosophical conceptions of the self : implications for cognitive science . Trends in cognitive sciences , 4 ( 1 ) , 14-21 . [ 3 ] Goertzel , B . ( 2007 ) . Artificial general intelligence ( Vol . 2 , p. 1 ) . C. Pennachin ( Ed. ) . New York : Springer . [ 4 ] Zou , A. , Wang , Z. , Kolter , J . Z. , & Fredrikson , M. ( 2023 ) . Universal and Transferable Adversarial Attacks on Aligned Language Models . arXiv preprint arXiv:2307.15043 . [ 5 ] Chen , L. , Zaharia , M. , & Zou , J . ( 2023 ) . How is ChatGPT 's behavior changing over time ? . arXiv preprint arXiv:2307.09009 . [ 6 ] Wang , B. , Chen , W. , Pei , H. , Xie , et al. , ( 2023 ) . DecodingTrust : A Comprehensive Assessment of Trustworthiness in GPT Models . arXiv preprint arXiv:2306.11698 . [ 7 ] Kong , Y. , Liu , L. , Chen , H. , Kacprzyk , J. , & Tao , D. ( 2023 ) . Overcoming Catastrophic Forgetting in Continual Learning by Exploring Eigenvalues of Hessian Matrix . IEEE Transactions on Neural Networks and Learning Systems . [ 8 ] Kotseruba , I. , & Tsotsos , J. K. ( 2020 ) . 40 years of cognitive architectures : core cognitive abilities and practical applications . Artificial Intelligence Review , 53 ( 1 ) , 17-94 . [ 9 ] Kahneman , D. ( 2011 ) . Thinking , fast and slow . Farrar , Straus and Giroux . [ 10 ] Bash , C. , Faraboschi , P. , Frachtenberg , E. , Laplante , P. , Milojicic , D. , & Saracco , R. ( 2023 ) . Megatrends . IEEE Computer , 56 ( 07 ) , 93-100 . [ 11 ] A DARPA Perspective on Artificial Intelligence ( 2017 ) . https : //www.darpa.mil/about-us/darpa- perspective-on-ai . ( Accessed 07.08.2023 ) . [ 12 ] Langley , P. ( 2012 ) . The Cognitive Systems Paradigm . Advances in Cognitive Systems , 1 ( 1 ) , 3-13 . 7 [ 13 ] Langley , P. , Laird , J. E. , & Rogers , S. ( 2009 ) . Cognitive architectures : Research issues and challenges . Cognitive Systems Research , 10 ( 2 ) , 141-160 . [ 14 ] Wang , P. ( 2012 ) . Theories of Artificial Intelligence - Meta-theoretical Considerations . Theoretical Foundations of Artificial General Intelligence . Paris : Atlantis Press . [ 15 ] Voss , P. , & Jovanovic , M. ( 2023 ) . Concepts is All You Need : A More Direct Path to AGI . arXiv preprint arXiv:2309.01622 . 8","['agi', 'yet', 'singidunumacrs', 'abstract', 'original', 'vision', 'rearticulate', 'term', 'artificial', 'general', 'intelligence', 'agi', 'vision', 'build', 'think', 'machine', 'computer', 'system', 'learn', 'reason', 'solve', 'problem', 'similar', 'way', 'human', 'stark', 'contrast', 'narrow', 'ai', 'approach', 'practice', 'almost', 'field', 'many', 'decade', 'several', 'largescale', 'effort', 'nominally', 'work', 'notably', 'deepmind', 'field', 'pure', 'focused', 'agi', 'development', 'well', 'fund', 'promote', 'surprising', 'give', 'fantastic', 'value', 'true', 'agi', 'bestow', 'humanity', 'addition', 'dearth', 'effort', 'field', 'also', 'several', 'theoretical', 'methodical', 'misstep', 'hamper', 'progress', 'highlight', 'purely', 'statistical', 'approach', 'unlikely', 'lead', 'agi', 'identify', 'several', 'crucial', 'cognitive', 'ability', 'require', 'achieve', 'humanlike', 'adaptability', 'autonomous', 'learning', 'conclude', 'survey', 'sociotechnical', 'factor', 'undoubtedly', 'slow', 'progress', 'agi', 'keyword', 'agi', 'cognitive', 'ai', 'adaptive', 'ai', 'humanlevel', 'ai', 'cognitive', 'architecture', 'third', 'wave', 'brief', 'history', 'agi', 'originally', 'term', 'artificial', 'intelligence', 'coin', 'refer', 'machine', 'computer', 'program', 'think', 'learn', 'reason', 'way', 'human', 'general', 'cognitive', 'ability', 'possess', 'time', 'expect', 'achieve', 'month', 'turn', 'lot', 'hard', 'year', 'decade', 'field', 'morph', 'narrow', 'ai', 'solve', 'type', 'problem', 'time', 'often', 'overlook', 'crucial', 'detrimental', 'consequence', 'shift', 'focus', 'achieve', 'particular', 'goal', 'ingenuity', 'programmer', 'datum', 'scientist', 'rather', 'build', 'system', 'general', 'intelligence', 'therefore', 'ai', 'focus', 'shift', 'internal', 'intelligence', 'utilize', 'external', 'intelligence', 'programmer', 'intelligence', 'solve', 'particular', 'problem', 'preoccupation', 'achieve', 'specific', 'narrow', 'goal', 'also', 'undesirable', 'sideeffect', 'ignore', 'importance', 'adaptation', 'agency', 'intelligent', 'entity', 'able', 'autonomously', 'adapt', 'change', 'circumstance', 'goal', 'entity', 'agent', 'proactively', 'initiate', 'action', 'surrounding', 'number', 'researcher', 'independently', 'conclude', 'time', 'ripe', 'return', 'original', 'vision', 'decide', 'join', 'force', 'write', 'book', 'subject', 'author', 'goertzel', 'shane', 'legg', 'voss', 'coin', 'term', 'artificial', 'general', 'intelligence', 'book', 'title', 'agi', 'refer', 'create', 'semi', 'autonomous', 'adaptive', 'computer', 'system', 'general', 'cognitive', 'capability', 'typical', 'human', 'ability', 'support', 'abstraction', 'analogy', 'planning', 'problem', 'solve', 'figure', 'comparison', 'external', 'internal', 'intelligence', 'value', 'agi', 'imagine', 'computer', 'system', 'general', 'cognitive', 'prowess', 'knowledge', 'medical', 'cancer', 'expert', 'imagine', 'copy', 'chip', 'away', 'scourge', 'also', 'consider', 'follow', 'advantage', 'artificial', 'researcher', 'worker', 'massively', 'low', 'cost', 'human', 'perform', 'cognitive', 'task', 'much', 'well', 'communicate', 'share', 'knowledge', 'egos', 'get', 'way', 'toil', 'away', 'much', 'fast', 'well', 'concentration', 'various', 'distraction', 'eg', 'family', 'vacation', 'hobby', 'muchimproved', 'ability', 'think', 'logically', 'perform', 'complex', 'planning', 'reasoning', 'photographic', 'memory', 'instant', 'access', 'online', 'information', 'apply', 'power', 'many', 'challenge', 'face', 'humanity', 'energy', 'environment', 'poverty', 'physical', 'mental', 'wellbeing', 'age', 'conflict', 'resolution', 'governance', 'agi', 'promise', 'able', 'significantly', 'increase', 'human', 'flourish', 'gpt', 'generative', 'pretraine', 'transformer', 'attempt', 'achieve', 'agi', 'recent', 'success', 'transformerbase', 'system', 'large', 'language', 'model', 'llm', 'give', 'rise', 'speculation', 'powerful', 'system', 'relatively', 'minor', 'enhancement', 'grow', 'agi', 'extremely', 'unlikely', 'give', 'hard', 'requirement', 'humanlevel', 'agi', 'reliability', 'predictability', 'nontoxicity', 'realtime', 'lifelong', 'learning', 'highlevel', 'reasoning', 'metacognition', 'gptbase', 'system', 'definition', 'generative', 'produce', 'artificial', 'content', 'base', 'probability', 'cooccurrence', 'make', 'stuff', 'pretraine', 'almost', 'knowledge', 'nonadaptive', 'acquire', 'interactively', 'realtime', 'correlational', 'nature', 'llm', 'fundamentally', 'lack', 'robust', 'reasoning', 'moreover', 'neural', 'network', 'perform', 'poorly', 'previously', 'learn', 'task', 'expose', 'new', 'datum', 'learn', 'new', 'task', 'know', 'catastrophic', 'forgetting', 'limitation', 'properly', 'curate', 'crossvalidate', 'llm', 'query', 'extremely', 'valuable', 'help', 'difficult', 'task', 'train', 'agis', 'help', 'provide', 'massive', 'amount', 'general', 'knowledge', 'need', 'humanlike', 'cognitive', 'ability', 'cognitive', 'ai', 'cognitive', 'describe', 'machine', 'system', 'able', 'understand', 'language', 'use', 'commonsense', 'knowledge', 'reason', 'adapt', 'unseen', 'circumstance', 'similar', 'human', 'agi', 'assistant', 'researcher', 'help', 'solve', 'important', 'important', 'problem', 'need', 'operate', 'real', 'world', 'deep', 'understanding', 'life', 'science', 'effectively', 'communicate', 'use', 'tool', 'system', 'able', 'learn', 'innovate', 'require', 'specific', 'approach', 'build', 'agi', 'one', 'focus', 'realtime', 'lifelong', 'conceptual', 'learning', 'reasoning', 'agis', 'superhuman', 'many', 'way', 'constrain', 'operate', 'incomplete', 'often', 'contradictory', 'information', 'limited', 'time', 'resource', 'perform', 'task', 'hand', 'require', 'humanlevel', 'senseacuity', 'dexterity', 'call', 'helenhawking', 'model', 'agi', 'hawk', 'agi', 'humanlevel', 'cognition', 'overall', 'humanlevel', 'physical', 'ability', 'however', 'need', 'mean', 'capture', 'interact', 'world', 'accomplish', 'example', 'pc', 'screen', 'keyboard', 'mouse', 'access', 'agis', 'also', 'excellent', 'tool', 'user', 'see', 'cognitive', 'ai', 'clear', 'definitive', 'direct', 'path', 'agi', 'figure', 'dimension', 'adaptive', 'autonomous', 'intelligence', 'define', 'agi', 'define', 'intelligence', 'thankless', 'task', 'instead', 'focus', 'practical', 'description', 'kind', 'cognition', 'intelligence', 'require', 'achieve', 'agi', 'goal', 'mention', 'essential', 'requirement', 'include', 'ability', 'autonomously', 'learn', 'multidimensional', 'object', 'action', 'sequence', 'include', 'appropriate', 'context', 'incrementally', 'real', 'time', 'integrate', 'manner', 'knowledge', 'representation', 'contextually', 'identify', 'know', 'object', 'action', 'sequence', 'give', 'partial', 'similar', 'input', 'ability', 'generalize', 'form', 'new', 'concept', 'analogy', 'autonomously', 'learn', 'associate', 'word', 'respective', 'concept', 'learn', 'language', 'understand', 'learn', 'action', 'sequence', 'associate', 'trigger', 'ape', 'exploration', 'reinforcement', 'instruction', 'reasoning', 'mean', 'autonomous', 'semiautonomous', 'ability', 'adapt', 'unlearn', 'exist', 'knowledge', 'skill', 'ability', 'reason', 'abstractly', 'include', 'planning', 'theoryofmind', 'reasoning', 'metacognitive', 'reasoning', 'control', 'system', 'heuristic', 'search', 'problem', 'solve', 'ability', 'use', 'shortterm', 'longterm', 'memory', 'context', 'recognition', 'reasoning', 'mean', 'focus', 'select', 'particular', 'feature', 'available', 'externally', 'internally', 'list', 'exhaustive', 'cover', 'essential', 'cognitive', 'ability', 'require', 'agi', 'idea', 'agi', 'around', 'decade', 'recently', 'recognize', 'emerge', 'technological', 'megatrend', 'wave', 'ai', 'year', 'ago', 'present', 'simple', 'chronological', 'taxonomy', 'call', 'wave', 'break', 'follow', 'rulebase', 'approach', 'also', 'refer', 'gofai', 'oldfashione', 'dominate', 'field', 'first', 'wave', 'characterize', 'largely', 'handcraft', 'datum', 'algorithm', 'include', 'expert', 'system', 'sophisticated', 'logic', 'search', 'algorithm', 'planning', 'scheduling', 'system', 'semantic', 'web', 'representation', 'natural', 'language', 'processing', 'system', 'visible', 'success', 'deep', 'blue', 'chess', 'champion', 'watson', 'jeopardy', 'quiz', 'champion', 'second', 'wave', 'hit', 'tsunami', 'researcher', 'figure', 'build', 'neural', 'network', 'use', 'massive', 'amount', 'datum', 'computational', 'power', 'include', 'lead', 'breakthrough', 'translation', 'image', 'speech', 'mastery', 'many', 'game', 'include', 'go', 'ultimately', 'powerful', 'vision', 'speech', 'text', 'generation', 'gpt', 'currently', 'pinnacle', 'development', 'represent', 'various', 'llm', 'chatgpt', 'wave', 'characterize', 'statistical', 'reinforcement', 'learning', 'much', 'selfsupervise', 'final', 'wave', 'still', 'infancy', 'focus', 'fully', 'align', 'requirement', 'agi', 'autonomous', 'realtime', 'learning', 'adaptation', 'highlevel', 'reasoning', 'also', 'expect', 'concept', 'ground', 'reality', 'oppose', 'language', 'statistic', 'robust', 'fewshot', 'learning', 'explainability', 'expect', 'system', 'elegantly', 'integrate', 'subsymbolic', 'pattern', 'match', 'high', 'level', 'symbolic', 'linguistic', 'reasoning', 'obvious', 'candidate', 'requirement', 'cognitive', 'architecture', 'approach', 'figure', 'wave', 'adapt', 'cognitive', 'architecture', 'cognitive', 'architecture', 'generally', 'cognitive', 'ai', 'found', 'idea', 'create', 'system', 'encompass', 'embody', 'essential', 'structure', 'require', 'humanlevel', 'mind', 'importantly', 'also', 'consider', 'structure', 'function', 'need', 'work', 'together', 'conjunction', 'change', 'knowledge', 'skill', 'yield', 'intelligence', 'diverse', 'dynamic', 'environment', 'various', 'cognitive', 'architecture', 'project', 'active', 'decade', 'far', 'none', 'show', 'sufficient', 'commercial', 'promise', 'widely', 'adopt', 'particularly', 'wellfunde', 'reason', 'manifold', 'complex', 'see', 'next', 'section', 'common', 'theme', 'implement', 'far', 'modular', 'inefficient', 'way', 'lack', 'deep', 'theory', 'learning', 'cognition', 'novel', 'cognitive', 'architecture', 'design', 'overcome', 'limitation', 'detail', 'concept', 'need', 'direct', 'path', 'agi', 'yet', 'short', 'answer', 'well', 'simply', 'project', 'right', 'approachtheory', 'adequate', 'amount', 'funding', 'recent', 'success', 'chatgpt', 'suggest', 'hardware', 'limitation', 'major', 'bottleneck', 'time', 'make', 'feasible', 'highly', 'sophisticated', 'language', 'production', 'inference', 'long', 'answer', 'include', 'follow', 'consideration', 'undoubtedly', 'major', 'factor', 'spite', 'ten', 'thousand', 'researcher', 'work', 'field', 'tiny', 'number', 'admission', 'objective', 'analysis', 'actually', 'directly', 'work', 'achieve', 'agi', 'objective', 'measure', 'work', 'involve', 'clearly', 'identify', 'step', 'aspect', 'overall', 'detailed', 'plan', 'achieve', 'agi', 'little', 'ai', 'work', 'match', 'criterion', 'specifically', 'generative', 'ai', 'research', 'even', 'project', 'dedicate', 'develop', 'agi', 'seldom', 'implement', 'explicit', 'theory', 'actually', 'match', 'requirement', 'kind', 'autonomous', 'adaptive', 'intelligence', 'need', 'agi', 'tremendous', 'success', 'statistical', 'ai', 'oppose', 'cognitive', 'ai', 'past', 'decade', 'currently', 'almost', 'lead', 'expert', 'practitioner', 'field', 'come', 'statistic', 'mathematic', 'formal', 'logic', 'make', 'almost', 'impossible', 'see', 'agi', 'requirement', 'cognitive', 'perspective', 'unfortunately', 'motivation', 'incentive', 'individual', 'team', 'company', 'poorly', 'align', 'optimize', 'progress', 'agi', 'contrary', 'academic', 'publish', 'rather', 'develop', 'company', 'produce', 'impressive', 'demos', 'beat', 'human', 'game', 'activity', 'order', 'secure', 'additional', 'funding', 'beat', 'exist', 'benchmark', 'change', 'use', 'exist', 'benchmark', 'agi', 'highly', 'problematic', 'firstly', 'focus', 'incremental', 'improvement', 'specific', 'exist', 'benchmark', 'take', 'effort', 'away', 'work', 'problem', 'actually', 'fundamental', 'achieve', 'agi', 'easy', 'work', 'thing', 'know', 'make', 'progress', 'tackle', 'difficult', 'unknown', 'issue', 'secondly', 'current', 'benchmark', 'extremely', 'poor', 'measure', 'progress', 'protoagis', 'early', 'agi', 'system', 'definition', 'poorly', 'exist', 'narrow', 'benchmark', 'well', 'highlevel', 'iq', 'professional', 'admission', 'test', 'even', 'star', 'align', 'favor', 'develop', 'agi', 'good', 'theory', 'development', 'plan', 'great', 'cognitive', 'team', 'fund', 'right', 'benchmark', 'still', 'lurk', 'call', 'narrow', 'trap', 'human', 'nature', 'instinctively', 'want', 'show', 'maximal', 'progress', 'short', 'time', 'unfortunately', 'agi', 'often', 'mean', 'end', 'use', 'external', 'human', 'intelligence', 'achieve', 'specific', 'result', 'make', 'progress', 'give', 'benchmark', 'rather', 'implement', 'way', 'put', 'intelligence', 'adaptive', 'autonomous', 'problemsolving', 'ability', 'system', 'take', 'careful', 'discipline', 'avoid', 'naturally', 'ai', 'effort', 'nominally', 'agi', 'good', 'theory', 'plan', 'easily', 'fall', 'trap', 'figure', 'pressure', 'nearterm', 'result', 'beat', 'exist', 'nonagi', 'benchmark', 'tend', 'deflect', 'project', 'away', 'agi', 'capability', 'narrow', 'commercial', 'implementation', 'finally', 'worth', 'mention', 'lack', 'clear', 'vision', 'people', 'help', 'make', 'happen', 'soon', 'people', 'claim', 'motivate', 'money', 'help', 'mankind', 'flourish', 'yet', 'many', 'put', 'effort', 'reputation', 'money', 'late', 'fad', 'big', 'potential', 'shortterm', 'win', 'conclusion', 'spectacular', 'performance', 'recent', 'gpt', 'technology', 'tease', 'possibility', 'last', 'close', 'able', 'realize', 'original', 'vision', 'humanlevel', 'thinking', 'machine', 'term', 'agi', 'coin', 'focus', 'objective', 'bring', 'technology', 'help', 'solve', 'many', 'problem', 'humanity', 'face', 'enhance', 'human', 'flourish', 'however', 'detailed', 'analysis', 'humanlevel', 'cognition', 'require', 'show', 'technical', 'approach', 'motivation', 'benchmark', 'currently', 'dominate', 'field', 'ai', 'align', 'achieve', 'objective', 'order', 'accelerate', 'progress', 'agi', 'need', 'focus', 'core', 'requirement', 'human', 'cognition', 'item', 'autonomous', 'realtime', 'incremental', 'learning', 'concept', 'formation', 'metacognitive', 'control', 'need', 'shift', 'second', 'third', 'wave', 'ai', 'statistical', 'generative', 'ai', 'cognitive', 'ai', 'acknowledgment', 'thank', 'dr', 'constructive', 'comment', 'reference', 'mccarthy', 'minsky', 'l', 'e', 'proposal', 'dartmouth', 'summer', 'research', 'project', 'artificial', 'intelligence', 'magazine', 'gallagher', 'philosophical', 'conception', 'self', 'implication', 'cognitive', 'science', 'trend', 'cognitive', 'science', 'goertzel', 'b', 'artificial', 'general', 'intelligence', 'vol', 'p', 'c', 'zou', 'kolter', 'fredrikson', 'universal', 'transferable', 'adversarial', 'attack', 'align', 'language', 'model', 'arxiv', 'preprint', 'l', 'j', 'behavior', 'change', 'time', 'arxiv', 'preprint', 'h', 'decodingtrust', 'comprehensive', 'assessment', 'trustworthiness', 'gpt', 'model', 'arxiv', 'preprint', 'arxiv230611698', 'overcome', 'catastrophic', 'forgetting', 'continual', 'learning', 'explore', 'eigenvalue', 'hessian', 'matrix', 'ieee', 'transaction', 'neural', 'network', 'learn', 'system', 'kotseruba', 'tsotsos', 'year', 'cognitive', 'architecture', 'core', 'cognitive', 'ability', 'practical', 'application', 'artificial', 'intelligence', 'review', 'kahneman', 'think', 'fast', 'slow', 'farrar', 'straus', 'giroux', 'bash', 'c', 'faraboschi', 'p', 'frachtenberg', 'e', 'laplante', 'p', 'milojicic', 'saracco', 'r', 'megatrend', 'ieee', 'computer', 'darpa', 'perspective', 'artificial', 'intelligence', 'https', 'perspectiveonai', 'access', 'cognitive', 'system', 'paradigm', 'advance', 'cognitive', 'system', 'roger', 'cognitive', 'architecture', 'research', 'issue', 'challenge', 'cognitive', 'system', 'research', 'theory', 'artificial', 'intelligence', 'metatheoretical', 'consideration', 'theoretical', 'foundation', 'artificial', 'general', 'intelligence', 'press', 'voss', 'p', 'jovanovic', 'concept', 'need', 'direct', 'path', 'agi', 'arxiv', 'preprint']"
