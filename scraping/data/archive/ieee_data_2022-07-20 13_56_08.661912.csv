title,url,date,text,cleaning,tokens
"
        DALL-E 2’s Failures Are the Most Interesting Thing About It
    ",https://spectrum.ieee.org/openai-dall-e-2,2022-07-14,"OpenAI’s text-to-image generator still struggles with text, science, faces, and bias IEEE Spectrum queried DALL-E 2 for an image of “a technology journalist writing an article about a new AI system that can create remarkable and strange images.” In response, it sent back only pictures of men.  In April, the artificial intelligence research lab OpenAI revealed DALL-E 2, the successor to 2021’s DALL-E. Both AI systems can generate astounding images from natural-language text descriptions; they’re capable of producing images that look like photos, illustrations, paintings, animations, and basically any other art style you can put into words. DALL-E 2 upped the ante with better resolution, faster processing, and an editor function that lets the user make changes within a generated image using only text commands, such as “replace that vase with a plant” or “make the dog’s nose bigger.” Users can also upload an image of their own and then tell the AI system how to riff on it.
 
	The world’s initial reactions to DALL-E 2 were amazement and delight. Any combination of objects and creatures could be brought together within seconds; any art style could be mimicked; any location could be depicted; and any lighting conditions could be portrayed. Who wouldn’t be impressed at the sight, for example, of a parrot flipping pancakes in the style of Picasso? There were also ripples of concern, as people cataloged the industries that could easily be disrupted by such a technology.
 
	OpenAI has not released the technology to the public, to commercial entities, or even to the AI community at large. “We share people’s concerns about misuse, and it’s something that we take really seriously,” OpenAI researcher 
	Mark Chen tells IEEE Spectrum.But the company did invite select people to experiment with DALL-E 2 and allowed them to share their results with the world. That policy of limited public testing stands in contrast to Google’s policy with its own just-released text-to-image generator, Imagen. When unveiling the system, Google announced that it would not be releasing code or a public demo due to risks of misuse and generation of harmful images. Google has released a handful of very impressive images but hasn’t shown the world any of the problematic content to which it had alluded.
 
	That makes the images that have come out from the early DALL-E 2 experimenters more interesting than ever. The results that have emerged over the last few months say a lot about the limits of today’s deep-learning technology, giving us a window into what AI understands about the human world—and what it totally doesn’t get.
 
	OpenAI kindly agreed to run some text prompts from 
	Spectrum through the system. The resulting images are scattered through this article.
 Spectrum asked for ""a Picasso-style painting of a parrot flipping pancakes,"" and DALL-E 2 served it up.
	OpenAI
	 
	DALL-E 2 was trained on approximately 650 million image-text pairs scraped from the Internet, according to 
	the paper that OpenAI posted to ArXiv. From that massive data set it learned the relationships between images and the words used to describe them. OpenAI filtered the data set before training to remove images that contained obvious violent, sexual, or hateful content. “The model isn’t exposed to these concepts,” says Chen, “so the likelihood of it generating things it hasn’t seen is very, very low.” But the researchers have clearly stated that such filtering has its limits and have noted that DALL-E 2 still has the potential to generate harmful material.
 
	Once this “encoder” model was trained to understand the relationships between text and images, OpenAI paired it with a decoder that generates images from text prompts using a process called diffusion, which begins with a random pattern of dots and slowly alters the pattern to create an image. Again, the company integrated certain filters to keep generated images in line with its 
	content policy and has pledged to keep updating those filters. Prompts that seem likely to produce forbidden content are blocked and, in an attempt to prevent deepfakes, it can't exactly reproduce faces it has seen during its training. Thus far, OpenAI has also used human reviewers to check images that have been flagged as possibly problematic.
 
	Because of DALL-E 2’s clear potential for misuse, OpenAI initially granted access to only a few hundred people, mostly AI researchers and artists. Unlike the lab’s language-generating model, 
	GPT-3, DALL-E 2 has not been made available for even limited commercial use, and OpenAI hasn’t publicly discussed a timetable for doing so. But from browsing the images that DALL-E 2 users have created and posted on forums such as Reddit, it does seem like some professions should be worried. For example, DALL-E 2 excels at food photography, at the type of stock photos used for corporate brochures and websites, and with illustrations that wouldn’t seem out of place on a dorm room poster or a magazine cover.
 Spectrum asked for a “New Yorker-style cartoon of an unemployed panda realizing her job eating bamboo has been taken by a robot.” OpenAI Here’s DALL-E 2’s response to the prompt: “An overweight old dog looks delighted that his younger and healthier dog friends have remembered his birthday, in the style of a greeting card.”OpenAI Spectrum reached out to a few entities within these threatened industries. A spokesperson for Getty Images, a leading supplier of stock photos, said the company isn’t worried. “Technologies such a DALL-E are no more a threat to our business than the two-decade reality of billions of cellphone cameras and the resulting trillions of images,” the spokesperson said. What’s more, the spokesperson said, before models such as DALL-E 2 can be used commercially, there are big questions to be answered about their use for generating deepfakes, the societal biases inherent in the generated images, and “the rights to the imagery and the people, places, and objects within the imagery that these models were trained on.” The last part of that sounds like a lawsuit brewing.
 
	Rachel Hill, CEO of the 
	Association of Illustrators, also brought up the issues of copyright and compensation for images’ use in training data. Hill admits that “AI platforms may attract art directors who want to reach for a fast and potentially lower-price illustration, particularly if they are not looking for something of exceptional quality.” But she still sees a strong human advantage: She notes that human illustrators help clients generate initial concepts, not just the final images, and that their work often relies “on human experience to communicate an emotion or opinion and connect with its viewer.” It remains to be seen, says Hill, whether DALL-E 2 and its equivalents could do the same, particularly when it comes to generating images that fit well with a narrative or match the tone of an article about current events.
 To gauge its ability to replicate the kinds of stock photos used in corporate communications, Spectrum asked for “a multiethnic group of blindfolded coworkers touching an elephant.”OpenAI 
	For all DALL-E 2’s strengths, the images that have emerged from eager experimenters show that it still has a lot to learn about the world. Here are three of its most obvious and interesting bugs.
 Text: It’s ironic that DALL-E 2 struggles to place comprehensible text in its images, given that it’s so adept at making sense of the text prompts that it uses to generate images. But users have discovered that asking for any kind of text usually results in a mishmash of letters. The AI blogger Janelle Shane had fun asking the system to create corporate logos and observing the resulting mess. It seems likely that a future version will correct this issue, however, particularly since OpenAI has plenty of text-generation expertise with its GPT-3 team. “Eventually a DALL-E successor will be able to spell Waffle House, and I will mourn that day,” Shane tells Spectrum. “I’ll just have to move on to a different method of messing with it.”
 To test DALL-E 2’s skills with text, Spectrum riffed on the famous Magritte painting that has the French words “Ceci n’est pas une pipe” below a picture of a pipe. Spectrum asked for the words “This is not a pipe” beneath a picture of a pipe. OpenAI Science: You could argue that DALL-E 2 understands some laws of science, since it can easily depict a dropped object falling or an astronaut floating in space. But asking for an anatomical diagram, an X-ray image, a mathematical proof, or a blueprint yields images that may be superficially right but are fundamentally all wrong. For example, Spectrum asked DALL-E 2 for an “illustration of the solar system, drawn to scale,” and got back some very strange versions of Earth and its far too many presumptive interplanetary neighbors—including our favorite, Planet Hard-Boiled Egg. “DALL-E doesn’t know what science is. It just knows how to read a caption and draw an illustration,” explains OpenAI researcher Aditya Ramesh, “so it tries to make up something that’s visually similar without understanding the meaning.”
 Spectrum asked for “an illustration of the solar system, drawn to scale,” and got back a very crowded and strange collection of planets, including a blobby Earth at lower left and something resembling a hard-boiled egg at upper left.OpenAI Faces: Sometimes, when DALL-E 2 tries to generate photorealistic images of people, the faces are pure nightmare fodder. That’s partly because, during its training, OpenAI introduced some deepfake safeguards to prevent it from memorizing faces that appear often on the Internet. The system also rejects uploaded images if they contain realistic faces of anyone, even nonfamous people. But an additional issue, an OpenAI representative tells Spectrum, is that the system was optimized for images with a single focus of attention. That’s why it’s great at portraits of imaginary people, such as this nuanced portrait produced when Spectrum asked for “an astronaut gazing back at Earth with a wistful expression on her face,” but pretty terrible at group shots and crowd scenes. Just look what happened when Spectrum asked for a picture of seven engineers gathered around a whiteboard.
 This image shows DALL-E 2’s skill with portraits. It also shows that the system’s gender bias can be overcome with careful prompts. This image was a response to the prompt “an astronaut gazing back at Earth with a wistful expression on her face.”OpenAI When DALL-E 2 is asked to generate pictures of more than one human at a time, things fall apart. This image of “seven engineers gathered around a white board” includes some monstrous faces and hands. OpenAI Bias: We’ll go a little deeper on this important topic. DALL-E 2 is considered a multimodal AI system because it was trained on images and text, and it exhibits a form of multimodal bias. For example, if a user asks it to generate images of a CEO, a builder, or a technology journalist, it will typically return images of men, based on the image-text pairs it saw in its training data.
 Spectrum queried DALL-E 2 for an image of “a technology journalist writing an article about a new AI system that can create remarkable and strange images.” This image shows one of its responses; the others are shown at the top of this article. OpenAI 
	OpenAI asked external researchers who work in this area to serve as a “red team” before DALL-E 2’s release, and their insights helped inform OpenAI’s write-up on 
	the system’s risks and limitations. They found that in addition to replicating societal stereotypes regarding gender, the system also over-represents white people and Western traditions and settings. One red team group, from the lab of Mohit Bansal at the University of North Carolina, Chapel Hill, had previously created a system that evaluated the first DALL-E for bias, called DALL-Eval, and they used it to check the second iteration as well. The group is now investigating the use of such evaluation systems earlier in the training process—perhaps sampling data sets before training and seeking additional images to fix problems of underrepresentation or using bias metrics as a penalty or reward signal to push the image-generating system in the right direction.
 
	Chen notes that a team at OpenAI has already begun experimenting with “machine-learning mitigations” to correct for bias. For example, during DALL-E 2’s training the team found that removing sexual content created a data set with more males than females, which caused the system to generate more images of males. “So we adjusted our training methodology and up-weighted images of females so they’re more likely to be generated,” Chen explains. Users can also help DALL-E 2 generate more diverse results by specifying gender, ethnicity, or geographical location using prompts such as “a female astronaut” or “a wedding in India.”
 
	But critics of OpenAI say the overall trend toward training models on massive uncurated data sets should be questioned. 
	Vinay Prabhu, an independent researcher who co-authored a 2021 paper about multimodal bias, feels that the AI research community overvalues scaling up models via “engineering brawn” and undervalues innovation. “There is this sense of faux claustrophobia that seems to have consumed the field where Wikipedia-based data sets spanning [about] 30 million image-text pairs are somehow ad hominem declared to be ‘too small’!” he tells Spectrum in an email.
 
	Prabhu champions the idea of creating smaller but “clean” data sets of image-text pairs from such sources as Wikipedia and e-books, including textbooks and manuals. “We could also launch (with the help of agencies like UNESCO for example) a global drive to contribute images with descriptions according to W3C’s 
	best practices and whatever is recommended by vision-disabled communities,” he suggests.
 
	The DALL-E 2 team says they’re eager to see what faults and failures early users discover as they experiment with the system, and they’re already thinking about next steps. “We’re very much interested in improving the general intelligence of the system,” says Ramesh, adding that the team hopes to build “a deeper understanding of language and its relationship to the world into DALL-E.” He notes that OpenAI’s text-generating GPT-3 has a surprisingly good understanding of common sense, science, and human behavior. “One aspirational goal could be to try to connect the knowledge that GPT-3 has to the image domain through DALL-E,” Ramesh says.
 
	As users have worked with DALL-E 2 over the past few months, their initial awe at its capabilities changed fairly quickly to bemusement at its quirks. As one experimenter put it in a 
	blog post, “Working with DALL-E definitely still feels like attempting to communicate with some kind of alien entity that doesn’t quite reason in the same ontology as humans, even if it theoretically understands the English language.” One day, maybe, OpenAI or its competitors will create something that approximates human artistry. For now, we’ll appreciate the marvels and laughs that come from an alien intelligence—perhaps hailing from Planet Hard-Boiled Egg.
 This article appears in the August 2022 print issue as “DALL-E 2’s Failures Show the Limits of AI.” Eliza Strickland is a senior editor at IEEE Spectrum, where she covers AI, biomedical engineering, and other topics. She holds a master's degree in journalism from Columbia University.
 ...Or did the metaverse just turn a shade more uncannily creepy?  Matthew S. Smith writes IEEE Spectrum's Gizmo column and is a freelance consumer-tech journalist. An avid gamer, he is a former staff editor at Digital Trends and is particularly fond of wearables, e-bikes, all things smartphone, and CES, which he has attended every year since 2009.
 Mesh to MetaHuman lets creators import a facial mesh to create a photorealistic 3D character. Creating your virtual clone isn’t as difficult as you’d think. Epic Games recently introduced Mesh to MetaHuman, a framework for creating photorealistic human characters. It lets creators sculpt an imported mesh to create a convincing character in less than an hour. “It’s incredibly simple compared to a lot of other tools,” says Stu Richards (a.k.a. Meta Mike), partner success lead at GigLabs and Cofounder of Versed. “I’d compare it to a character creator in a game.”                       This e-nose can detect glucose levels with 90 percent accuracy  Michelle Hampson is a freelance writer based in Halifax. She frequently contributes to Spectrum's Journal Watch coverage, which highlights newsworthy studies published in IEEE journals.
  This article is part of our exclusive IEEE Journal Watch series in partnership with IEEE Xplore.          Researchers at NYU have developed an AI solution that can leverage public video feeds to better inform decision makers Dexter Johnson is a contributing editor at IEEE Spectrum, with a focus on nanotechnology. This is a sponsored article brought to you by NYU’s Tandon School of Engineering. In the midst of the COVID-19 pandemic, in 2020, many research groups sought an effective method to determine mobility patterns and crowd densities on the streets of major cities like New York City to give insight into the effectiveness of stay-at-home and social distancing strategies. But sending teams of researchers out into the streets to observe and tabulate these numbers would have involved putting those researchers at risk of exposure to the very infection the strategies were meant to curb.
 
	Researchers at New York University’s (NYU) Connected Cities for Smart Mobility towards Accessible and Resilient Transportation (C2SMART) Center, a Tier 1 USDOT-funded University Transportation Center, developed a solution that not only eliminated the risk of infection to researchers, and which could easily be plugged into already existing public traffic camera feeds infrastructure, but also provided the most comprehensive data on crowd and traffic densities that had ever been compiled previously and cannot be easily detected by conventional traffic sensors.
                                      ","OpenAI’s text-to-image generator still struggles with text, science, faces, and bias IEEE Spectrum queried DALL-E 2 for an image of “a technology journalist writing an article about a new AI system that can create remarkable and strange images.” In response, it sent back only pictures of men. In April, the artificial intelligence research lab OpenAI revealed DALL-E 2, the successor to 2021’s DALL-E. Both AI systems can generate astounding images from natural-language text descriptions; they’re capable of producing images that look like photos, illustrations, paintings, animations, and basically any other art style you can put into words. DALL-E 2 upped the ante with better resolution, faster processing, and an editor function that lets the user make changes within a generated image using only text commands, such as “replace that vase with a plant” or “make the dog’s nose bigger.” Users can also upload an image of their own and then tell the AI system how to riff on it. The world’s initial reactions to DALL-E 2 were amazement and delight. Any combination of objects and creatures could be brought together within seconds; any art style could be mimicked; any location could be depicted; and any lighting conditions could be portrayed. Who wouldn’t be impressed at the sight, for example, of a parrot flipping pancakes in the style of Picasso? There were also ripples of concern, as people cataloged the industries that could easily be disrupted by such a technology. OpenAI has not released the technology to the public, to commercial entities, or even to the AI community at large. “We share people’s concerns about misuse, and it’s something that we take really seriously,” OpenAI researcher Mark Chen tells IEEE Spectrum.But the company did invite select people to experiment with DALL-E 2 and allowed them to share their results with the world. That policy of limited public testing stands in contrast to Google’s policy with its own just-released text-to-image generator, Imagen. When unveiling the system, Google announced that it would not be releasing code or a public demo due to risks of misuse and generation of harmful images. Google has released a handful of very impressive images but hasn’t shown the world any of the problematic content to which it had alluded. That makes the images that have come out from the early DALL-E 2 experimenters more interesting than ever. The results that have emerged over the last few months say a lot about the limits of today’s deep-learning technology, giving us a window into what AI understands about the human world—and what it totally doesn’t get. OpenAI kindly agreed to run some text prompts from Spectrum through the system. The resulting images are scattered through this article. Spectrum asked for ""a Picasso-style painting of a parrot flipping pancakes,"" and DALL-E 2 served it up. OpenAI DALL-E 2 was trained on approximately 650 million image-text pairs scraped from the Internet, according to the paper that OpenAI posted to ArXiv. From that massive data set it learned the relationships between images and the words used to describe them. OpenAI filtered the data set before training to remove images that contained obvious violent, sexual, or hateful content. “The model isn’t exposed to these concepts,” says Chen, “so the likelihood of it generating things it hasn’t seen is very, very low.” But the researchers have clearly stated that such filtering has its limits and have noted that DALL-E 2 still has the potential to generate harmful material. Once this “encoder” model was trained to understand the relationships between text and images, OpenAI paired it with a decoder that generates images from text prompts using a process called diffusion, which begins with a random pattern of dots and slowly alters the pattern to create an image. Again, the company integrated certain filters to keep generated images in line with its content policy and has pledged to keep updating those filters. Prompts that seem likely to produce forbidden content are blocked and, in an attempt to prevent deepfakes, it can't exactly reproduce faces it has seen during its training. Thus far, OpenAI has also used human reviewers to check images that have been flagged as possibly problematic. Because of DALL-E 2’s clear potential for misuse, OpenAI initially granted access to only a few hundred people, mostly AI researchers and artists. Unlike the lab’s language-generating model, GPT-3, DALL-E 2 has not been made available for even limited commercial use, and OpenAI hasn’t publicly discussed a timetable for doing so. But from browsing the images that DALL-E 2 users have created and posted on forums such as Reddit, it does seem like some professions should be worried. For example, DALL-E 2 excels at food photography, at the type of stock photos used for corporate brochures and websites, and with illustrations that wouldn’t seem out of place on a dorm room poster or a magazine cover. Spectrum asked for a “New Yorker-style cartoon of an unemployed panda realizing her job eating bamboo has been taken by a robot.” OpenAI Here’s DALL-E 2’s response to the prompt: “An overweight old dog looks delighted that his younger and healthier dog friends have remembered his birthday, in the style of a greeting card.”OpenAI Spectrum reached out to a few entities within these threatened industries. A spokesperson for Getty Images, a leading supplier of stock photos, said the company isn’t worried. “Technologies such a DALL-E are no more a threat to our business than the two-decade reality of billions of cellphone cameras and the resulting trillions of images,” the spokesperson said. What’s more, the spokesperson said, before models such as DALL-E 2 can be used commercially, there are big questions to be answered about their use for generating deepfakes, the societal biases inherent in the generated images, and “the rights to the imagery and the people, places, and objects within the imagery that these models were trained on.” The last part of that sounds like a lawsuit brewing. Rachel Hill, CEO of the Association of Illustrators, also brought up the issues of copyright and compensation for images’ use in training data. Hill admits that “AI platforms may attract art directors who want to reach for a fast and potentially lower-price illustration, particularly if they are not looking for something of exceptional quality.” But she still sees a strong human advantage: She notes that human illustrators help clients generate initial concepts, not just the final images, and that their work often relies “on human experience to communicate an emotion or opinion and connect with its viewer.” It remains to be seen, says Hill, whether DALL-E 2 and its equivalents could do the same, particularly when it comes to generating images that fit well with a narrative or match the tone of an article about current events. To gauge its ability to replicate the kinds of stock photos used in corporate communications, Spectrum asked for “a multiethnic group of blindfolded coworkers touching an elephant.”OpenAI For all DALL-E 2’s strengths, the images that have emerged from eager experimenters show that it still has a lot to learn about the world. Here are three of its most obvious and interesting bugs. Text: It’s ironic that DALL-E 2 struggles to place comprehensible text in its images, given that it’s so adept at making sense of the text prompts that it uses to generate images. But users have discovered that asking for any kind of text usually results in a mishmash of letters. The AI blogger Janelle Shane had fun asking the system to create corporate logos and observing the resulting mess. It seems likely that a future version will correct this issue, however, particularly since OpenAI has plenty of text-generation expertise with its GPT-3 team. “Eventually a DALL-E successor will be able to spell Waffle House, and I will mourn that day,” Shane tells Spectrum. “I’ll just have to move on to a different method of messing with it.” To test DALL-E 2’s skills with text, Spectrum riffed on the famous Magritte painting that has the French words “Ceci n’est pas une pipe” below a picture of a pipe. Spectrum asked for the words “This is not a pipe” beneath a picture of a pipe. OpenAI Science: You could argue that DALL-E 2 understands some laws of science, since it can easily depict a dropped object falling or an astronaut floating in space. But asking for an anatomical diagram, an X-ray image, a mathematical proof, or a blueprint yields images that may be superficially right but are fundamentally all wrong. For example, Spectrum asked DALL-E 2 for an “illustration of the solar system, drawn to scale,” and got back some very strange versions of Earth and its far too many presumptive interplanetary neighbors—including our favorite, Planet Hard-Boiled Egg. “DALL-E doesn’t know what science is. It just knows how to read a caption and draw an illustration,” explains OpenAI researcher Aditya Ramesh, “so it tries to make up something that’s visually similar without understanding the meaning.” Spectrum asked for “an illustration of the solar system, drawn to scale,” and got back a very crowded and strange collection of planets, including a blobby Earth at lower left and something resembling a hard-boiled egg at upper left.OpenAI Faces: Sometimes, when DALL-E 2 tries to generate photorealistic images of people, the faces are pure nightmare fodder. That’s partly because, during its training, OpenAI introduced some deepfake safeguards to prevent it from memorizing faces that appear often on the Internet. The system also rejects uploaded images if they contain realistic faces of anyone, even nonfamous people. But an additional issue, an OpenAI representative tells Spectrum, is that the system was optimized for images with a single focus of attention. That’s why it’s great at portraits of imaginary people, such as this nuanced portrait produced when Spectrum asked for “an astronaut gazing back at Earth with a wistful expression on her face,” but pretty terrible at group shots and crowd scenes. Just look what happened when Spectrum asked for a picture of seven engineers gathered around a whiteboard. This image shows DALL-E 2’s skill with portraits. It also shows that the system’s gender bias can be overcome with careful prompts. This image was a response to the prompt “an astronaut gazing back at Earth with a wistful expression on her face.”OpenAI When DALL-E 2 is asked to generate pictures of more than one human at a time, things fall apart. This image of “seven engineers gathered around a white board” includes some monstrous faces and hands. OpenAI Bias: We’ll go a little deeper on this important topic. DALL-E 2 is considered a multimodal AI system because it was trained on images and text, and it exhibits a form of multimodal bias. For example, if a user asks it to generate images of a CEO, a builder, or a technology journalist, it will typically return images of men, based on the image-text pairs it saw in its training data. Spectrum queried DALL-E 2 for an image of “a technology journalist writing an article about a new AI system that can create remarkable and strange images.” This image shows one of its responses; the others are shown at the top of this article. OpenAI OpenAI asked external researchers who work in this area to serve as a “red team” before DALL-E 2’s release, and their insights helped inform OpenAI’s write-up on the system’s risks and limitations. They found that in addition to replicating societal stereotypes regarding gender, the system also over-represents white people and Western traditions and settings. One red team group, from the lab of Mohit Bansal at the University of North Carolina, Chapel Hill, had previously created a system that evaluated the first DALL-E for bias, called DALL-Eval, and they used it to check the second iteration as well. The group is now investigating the use of such evaluation systems earlier in the training process—perhaps sampling data sets before training and seeking additional images to fix problems of underrepresentation or using bias metrics as a penalty or reward signal to push the image-generating system in the right direction. Chen notes that a team at OpenAI has already begun experimenting with “machine-learning mitigations” to correct for bias. For example, during DALL-E 2’s training the team found that removing sexual content created a data set with more males than females, which caused the system to generate more images of males. “So we adjusted our training methodology and up-weighted images of females so they’re more likely to be generated,” Chen explains. Users can also help DALL-E 2 generate more diverse results by specifying gender, ethnicity, or geographical location using prompts such as “a female astronaut” or “a wedding in India.” But critics of OpenAI say the overall trend toward training models on massive uncurated data sets should be questioned. Vinay Prabhu, an independent researcher who co-authored a 2021 paper about multimodal bias, feels that the AI research community overvalues scaling up models via “engineering brawn” and undervalues innovation. “There is this sense of faux claustrophobia that seems to have consumed the field where Wikipedia-based data sets spanning [about] 30 million image-text pairs are somehow ad hominem declared to be ‘too small’!” he tells Spectrum in an email. Prabhu champions the idea of creating smaller but “clean” data sets of image-text pairs from such sources as Wikipedia and e-books, including textbooks and manuals. “We could also launch (with the help of agencies like UNESCO for example) a global drive to contribute images with descriptions according to W3C’s best practices and whatever is recommended by vision-disabled communities,” he suggests. The DALL-E 2 team says they’re eager to see what faults and failures early users discover as they experiment with the system, and they’re already thinking about next steps. “We’re very much interested in improving the general intelligence of the system,” says Ramesh, adding that the team hopes to build “a deeper understanding of language and its relationship to the world into DALL-E.” He notes that OpenAI’s text-generating GPT-3 has a surprisingly good understanding of common sense, science, and human behavior. “One aspirational goal could be to try to connect the knowledge that GPT-3 has to the image domain through DALL-E,” Ramesh says. As users have worked with DALL-E 2 over the past few months, their initial awe at its capabilities changed fairly quickly to bemusement at its quirks. As one experimenter put it in a blog post, “Working with DALL-E definitely still feels like attempting to communicate with some kind of alien entity that doesn’t quite reason in the same ontology as humans, even if it theoretically understands the English language.” One day, maybe, OpenAI or its competitors will create something that approximates human artistry. For now, we’ll appreciate the marvels and laughs that come from an alien intelligence—perhaps hailing from Planet Hard-Boiled Egg. This article appears in the August 2022 print issue as “DALL-E 2’s Failures Show the Limits of AI.” Eliza Strickland is a senior editor at IEEE Spectrum, where she covers AI, biomedical engineering, and other topics. She holds a master's degree in journalism from Columbia University. ...Or did the metaverse just turn a shade more uncannily creepy? Matthew S. Smith writes IEEE Spectrum's Gizmo column and is a freelance consumer-tech journalist. An avid gamer, he is a former staff editor at Digital Trends and is particularly fond of wearables, e-bikes, all things smartphone, and CES, which he has attended every year since 2009. Mesh to MetaHuman lets creators import a facial mesh to create a photorealistic 3D character. Creating your virtual clone isn’t as difficult as you’d think. Epic Games recently introduced Mesh to MetaHuman, a framework for creating photorealistic human characters. It lets creators sculpt an imported mesh to create a convincing character in less than an hour. “It’s incredibly simple compared to a lot of other tools,” says Stu Richards (a.k.a. Meta Mike), partner success lead at GigLabs and Cofounder of Versed. “I’d compare it to a character creator in a game.” This e-nose can detect glucose levels with 90 percent accuracy Michelle Hampson is a freelance writer based in Halifax. She frequently contributes to Spectrum's Journal Watch coverage, which highlights newsworthy studies published in IEEE journals. This article is part of our exclusive IEEE Journal Watch series in partnership with IEEE Xplore. Researchers at NYU have developed an AI solution that can leverage public video feeds to better inform decision makers Dexter Johnson is a contributing editor at IEEE Spectrum, with a focus on nanotechnology. This is a sponsored article brought to you by NYU’s Tandon School of Engineering. In the midst of the COVID-19 pandemic, in 2020, many research groups sought an effective method to determine mobility patterns and crowd densities on the streets of major cities like New York City to give insight into the effectiveness of stay-at-home and social distancing strategies. But sending teams of researchers out into the streets to observe and tabulate these numbers would have involved putting those researchers at risk of exposure to the very infection the strategies were meant to curb. Researchers at New York University’s (NYU) Connected Cities for Smart Mobility towards Accessible and Resilient Transportation (C2SMART) Center, a Tier 1 USDOT-funded University Transportation Center, developed a solution that not only eliminated the risk of infection to researchers, and which could easily be plugged into already existing public traffic camera feeds infrastructure, but also provided the most comprehensive data on crowd and traffic densities that had ever been compiled previously and cannot be easily detected by conventional traffic sensors.","['texttoimage', 'generator', 'still', 'struggle', 'text', 'science', 'face', 'bias', 'ieee', 'spectrum', 'query', 'dalle', 'image', 'technology', 'journalist', 'write', 'article', 'new', 'ai', 'system', 'create', 'remarkable', 'strange', 'image', 'response', 'send', 'back', 'picture', 'man', 'artificial', 'intelligence', 'research', 'lab', 'openai', 'reveal', 'dalle', 'successor', 'dalle', 'ai', 'system', 'generate', 'astounding', 'image', 'naturallanguage', 'text', 'description', '’re', 'capable', 'produce', 'image', 'look', 'photo', 'illustration', 'painting', 'animation', 'basically', 'art', 'style', 'put', 'word', 'dalle', 'ante', 'well', 'resolution', 'fast', 'processing', 'editor', 'function', 'let', 'user', 'make', 'change', 'generate', 'image', 'use', 'text', 'command', 'replace', 'vase', 'plant', 'make', 'dog', 'nose', 'big', 'user', 'also', 'upload', 'image', 'tell', 'ai', 'system', 'riff', 'world', 'initial', 'reaction', 'dalle', 'amazement', 'delight', 'combination', 'object', 'creature', 'bring', 'together', 'second', 'art', 'style', 'mimic', 'location', 'depict', 'lighting', 'condition', 'portray', 'impress', 'sight', 'example', 'parrot', 'flip', 'pancake', 'style', 'picasso', 'also', 'ripple', 'concern', 'people', 'catalog', 'industry', 'easily', 'disrupt', 'technology', 'openai', 'release', 'technology', 'public', 'commercial', 'entity', 'even', 'community', 'large', 'share', 'people', 'concern', 'misuse', '’', 'take', 'really', 'seriously', 'openai', 'researcher', 'tell', 'ieee', 'company', 'invite', 'select', 'people', 'experiment', 'dalle', 'allow', 'share', 'result', 'world', 'policy', 'limited', 'public', 'testing', 'stand', 'contrast', 'policy', 'justrelease', 'texttoimage', 'generator', 'imagen', 'unveil', 'system', 'announce', 'release', 'code', 'public', 'demo', 'risk', 'misuse', 'generation', 'harmful', 'image', 'release', 'handful', 'impressive', 'image', 'show', 'world', 'problematic', 'content', 'allude', 'make', 'image', 'come', 'early', 'dalle', 'experimenter', 'interesting', 'ever', 'result', 'emerge', 'last', 'month', 'say', 'lot', 'limit', 'today', 'deeplearne', 'technology', 'give', 'window', 'understand', 'human', 'world', 'totally', 'get', 'openai', 'kindly', 'agree', 'run', 'text', 'prompt', 'spectrum', 'system', 'result', 'image', 'scatter', 'article', 'spectrum', 'ask', 'picassostyle', 'painting', 'parrot', 'flip', 'pancake', 'dalle', 'serve', 'openai', 'dalle', 'train', 'approximately', 'imagetext', 'pair', 'scrape', 'internet', 'accord', 'paper', 'openai', 'post', 'arxiv', 'massive', 'datum', 'set', 'learn', 'relationship', 'image', 'word', 'use', 'describe', 'openai', 'filter', 'datum', 'set', 'training', 'remove', 'image', 'contain', 'obvious', 'violent', 'sexual', 'hateful', 'content', 'model', 'expose', 'concept', 'say', 'likelihood', 'generate', 'thing', 'see', 'low', 'researcher', 'clearly', 'state', 'filtering', 'limit', 'note', 'dalle', 'still', 'potential', 'generate', 'harmful', 'material', 'encoder', 'model', 'train', 'understand', 'relationship', 'text', 'image', 'openai', 'pair', 'decoder', 'generate', 'image', 'text', 'prompt', 'use', 'process', 'call', 'diffusion', 'begin', 'random', 'pattern', 'dot', 'slowly', 'alter', 'pattern', 'create', 'image', 'company', 'integrate', 'certain', 'filter', 'keep', 'generate', 'image', 'line', 'content', 'policy', 'pledge', 'keep', 'update', 'filter', 'prompt', 'seem', 'likely', 'produce', 'forbid', 'content', 'block', 'attempt', 'prevent', 'deepfake', 'exactly', 'reproduce', 'face', 'see', 'training', 'thus', 'far', 'openai', 'also', 'use', 'human', 'reviewer', 'check', 'image', 'flag', 'possibly', 'problematic', 'dalle', 'clear', 'potential', 'misuse', 'openai', 'initially', 'grant', 'access', 'people', 'mostly', 'ai', 'researcher', 'artist', 'lab', 'languagegenerating', 'model', 'gpt3', 'dalle', 'make', 'available', 'even', 'limited', 'commercial', 'use', 'openai', 'publicly', 'discuss', 'timetable', 'browse', 'image', 'dalle', 'user', 'create', 'post', 'forum', 'reddit', 'seem', 'profession', 'worried', 'example', 'dalle', 'excel', 'food', 'photography', 'type', 'stock', 'photo', 'use', 'corporate', 'brochure', 'website', 'illustration', 'seem', 'place', 'dorm', 'room', 'poster', 'magazine', 'cover', 'spectrum', 'ask', 'new', 'yorkerstyle', 'cartoon', 'unemployed', 'panda', 'realize', 'job', 'eat', 'bamboo', 'take', 'robot', 'openai', '’s', 'response', 'prompt', 'overweight', 'old', 'dog', 'look', 'delighted', 'young', 'healthy', 'dog', 'friend', 'remember', 'birthday', 'style', 'greet', 'cardopenai', 'spectrum', 'reach', 'entity', 'threatened', 'industry', 'spokesperson', 'getty', 'image', 'lead', 'supplier', 'stock', 'photo', 'say', 'company', 'worried', 'technology', 'dalle', 'threat', 'business', 'twodecade', 'reality', 'billion', 'cellphone', 'camera', 'result', 'trillion', 'image', 'spokesperson', 'say', '’', 'spokesperson', 'say', 'model', 'dalle', 'use', 'commercially', 'big', 'question', 'answer', 'use', 'generate', 'deepfake', 'societal', 'bias', 'inherent', 'generate', 'image', 'right', 'imagery', 'people', 'place', 'object', 'imagery', 'model', 'train', 'last', 'part', 'sound', 'lawsuit', 'brewing', 'association', 'illustrator', 'also', 'bring', 'issue', 'copyright', 'compensation', 'image', 'use', 'training', 'datum', 'hill', 'admit', 'ai', 'platform', 'attract', 'art', 'director', 'want', 'reach', 'fast', 'potentially', 'lowerprice', 'illustration', 'particularly', 'look', 'exceptional', 'quality', 'still', 'see', 'strong', 'human', 'advantage', 'note', 'human', 'illustrator', 'help', 'client', 'generate', 'initial', 'concept', 'final', 'image', 'work', 'often', 'rely', 'human', 'experience', 'communicate', 'emotion', 'opinion', 'connect', 'viewer', 'remain', 'see', 'say', 'dalle', 'equivalent', 'particularly', 'come', 'generate', 'image', 'fit', 'well', 'narrative', 'match', 'tone', 'article', 'current', 'event', 'gauge', 'ability', 'replicate', 'kind', 'stock', 'photo', 'use', 'corporate', 'communication', 'spectrum', 'ask', 'multiethnic', 'group', 'blindfold', 'coworker', 'touch', 'elephantopenai', 'dalle', 'strength', 'image', 'emerge', 'eager', 'experimenter', 'show', 'still', 'lot', 'learn', 'world', 'obvious', 'interesting', 'bug', 'text', '’', 'ironic', 'dalle', 'struggle', 'place', 'comprehensible', 'text', 'image', 'give', '’', 'adept', 'make', 'sense', 'text', 'prompt', 'use', 'generate', 'image', 'user', 'discover', 'ask', 'kind', 'text', 'usually', 'result', 'mishmash', 'letter', 'shane', 'fun', 'ask', 'system', 'create', 'corporate', 'logo', 'observe', 'result', 'mess', 'seem', 'likely', 'future', 'version', 'correct', 'issue', 'however', 'particularly', 'openai', 'plenty', 'textgeneration', 'expertise', 'gpt3', 'team', 'eventually', 'dalle', 'successor', 'able', 'spell', 'waffle', 'mourn', 'day', 'shane', 'tell', 'spectrum', 'move', 'different', 'method', 'mess', 'test', 'dalle', '’s', 'skill', 'text', 'spectrum', 'riff', 'famous', 'magritte', 'painting', 'french', 'word', 'ceci', 'pipe', 'picture', 'pipe', 'spectrum', 'ask', 'word', 'pipe', 'picture', 'pipe', 'openai', 'science', 'argue', 'dalle', 'understand', 'law', 'science', 'easily', 'depict', 'drop', 'object', 'fall', 'astronaut', 'float', 'space', 'ask', 'anatomical', 'diagram', 'image', 'mathematical', 'proof', 'blueprint', 'yield', 'image', 'superficially', 'right', 'wrong', 'example', 'spectrum', 'ask', 'dalle', 'illustration', 'solar', 'system', 'draw', 'scale', 'get', 'back', 'strange', 'version', 'earth', 'far', 'many', 'presumptive', 'interplanetary', 'neighbor', 'include', 'favorite', 'planet', 'hardboile', 'egg', 'dalle', 'know', 'science', 'know', 'read', 'caption', 'draw', 'illustration', 'explain', 'openai', 'researcher', 'try', 'make', '’', 'visually', 'similar', 'understand', 'meaning', 'spectrum', 'ask', 'illustration', 'solar', 'system', 'draw', 'scale', 'get', 'back', 'crowded', 'strange', 'collection', 'planet', 'include', 'blobby', 'earth', 'lower', 'leave', 'resemble', 'hardboiled', 'egg', 'upper', 'leftopenai', 'face', 'sometimes', 'dalle', 'try', 'generate', 'photorealistic', 'image', 'people', 'face', 'pure', 'nightmare', 'fodder', '’', 'partly', 'training', 'openai', 'introduce', 'deepfake', 'safeguard', 'prevent', 'memorize', 'face', 'appear', 'often', 'internet', 'system', 'also', 'reject', 'upload', 'image', 'contain', 'realistic', 'face', 'even', 'nonfamous', 'people', 'additional', 'issue', 'openai', 'representative', 'tell', 'spectrum', 'system', 'optimize', 'image', 'single', 'focus', 'attention', '’', '’', 'great', 'portrait', 'imaginary', 'people', 'nuance', 'portrait', 'produce', 'spectrum', 'ask', 'astronaut', 'gaze', 'back', 'earth', 'wistful', 'expression', 'face', 'pretty', 'terrible', 'group', 'shot', 'crowd', 'scene', 'look', 'happen', 'spectrum', 'ask', 'picture', 'engineer', 'gather', 'whiteboard', 'image', 'show', 'dalle', 'skill', 'portrait', 'also', 'show', 'system', 'gender', 'bias', 'overcome', 'careful', 'prompt', 'image', 'response', 'prompt', 'astronaut', 'gaze', 'back', 'earth', 'wistful', 'expression', 'faceopenai', 'dalle', 'ask', 'generate', 'picture', 'human', 'time', 'thing', 'fall', 'apart', 'image', 'engineer', 'gather', 'board', 'include', 'monstrous', 'face', 'hand', 'openai', 'bias', 'go', 'little', 'deep', 'important', 'topic', 'dalle', 'consider', 'multimodal', 'ai', 'system', 'train', 'image', 'text', 'exhibit', 'form', 'multimodal', 'bias', 'example', 'user', 'ask', 'generate', 'image', 'ceo', 'builder', 'technology', 'journalist', 'typically', 'return', 'image', 'man', 'base', 'imagetext', 'pair', 'see', 'training', 'datum', 'spectrum', 'query', 'dalle', 'image', 'technology', 'journalist', 'write', 'article', 'new', 'ai', 'system', 'create', 'remarkable', 'strange', 'image', 'image', 'show', 'response', 'show', 'top', 'article', 'openai', 'openai', 'ask', 'external', 'researcher', 'work', 'area', 'serve', 'red', 'team', 'dalle', 'release', 'insight', 'help', 'inform', 'openai', 'writeup', 'system', 'risk', 'limitation', 'find', 'addition', 'replicate', 'societal', 'stereotype', 'regard', 'gender', 'system', 'also', 'overrepresent', 'white', 'people', 'western', 'tradition', 'setting', 'red', 'team', 'group', 'lab', 'mohit', 'bansal', 'previously', 'create', 'system', 'evaluate', 'first', 'dalle', 'bias', 'call', 'dalleval', 'use', 'check', 'second', 'iteration', 'well', 'group', 'investigate', 'use', 'evaluation', 'system', 'early', 'training', 'process', 'perhaps', 'sample', 'data', 'set', 'training', 'seek', 'additional', 'image', 'fix', 'problem', 'underrepresentation', 'use', 'bias', 'metric', 'penalty', 'reward', 'signal', 'push', 'imagegenerating', 'system', 'right', 'direction', 'note', 'team', 'openai', 'already', 'begin', 'experiment', 'machinelearne', 'mitigation', 'correct', 'bias', 'example', 'dalle', '’s', 'train', 'team', 'find', 'remove', 'sexual', 'content', 'create', 'data', 'set', 'male', 'female', 'cause', 'system', 'generate', 'image', 'male', 'adjust', 'training', 'methodology', 'upweighted', 'image', 'female', '’re', 'likely', 'generate', 'explain', 'user', 'also', 'help', 'dalle', 'generate', 'diverse', 'result', 'specify', 'gender', 'ethnicity', 'geographical', 'location', 'use', 'prompt', 'female', 'astronaut', 'wedding', 'critic', 'openai', 'say', 'overall', 'trend', 'training', 'model', 'massive', 'uncurated', 'datum', 'set', 'question', 'vinay', 'prabhu', 'independent', 'researcher', 'coauthore', 'paper', 'multimodal', 'bias', 'feel', 'research', 'community', 'overvalue', 'scale', 'model', 'engineering', 'brawn', 'undervalue', 'innovation', 'sense', 'seem', 'consume', 'field', 'wikipediabase', 'datum', 'set', 'span', 'imagetext', 'pair', 'somehow', 'ad', 'hominem', 'declare', 'small', 'tell', 'spectrum', 'email', 'prabhu', 'champion', 'idea', 'create', 'small', 'clean', 'datum', 'set', 'imagetext', 'pair', 'source', 'include', 'textbook', 'manual', 'also', 'launch', 'help', 'agency', 'example', 'global', 'drive', 'contribute', 'image', 'description', 'accord', 'good', 'practice', 'recommend', 'visiondisable', 'community', 'suggest', 'dalle', 'team', 'say', '’re', 'eager', 'see', 'fault', 'failure', 'early', 'user', 'discover', 'experiment', 'system', 'already', 'think', 'next', 'step', '’re', 'much', 'interested', 'improve', 'general', 'intelligence', 'system', 'say', 'ramesh', 'add', 'team', 'hope', 'build', 'deep', 'understanding', 'language', 'relationship', 'world', 'dalle', 'note', 'openai', '’s', 'textgenerate', 'gpt3', 'surprisingly', 'good', 'understanding', 'common', 'sense', 'science', 'human', 'behavior', 'aspirational', 'goal', 'try', 'connect', 'knowledge', 'gpt3', 'image', 'domain', 'dalle', 'ramesh', 'say', 'user', 'work', 'dalle', 'past', 'month', 'initial', 'awe', 'capability', 'change', 'fairly', 'quickly', 'bemusement', 'quirk', 'experimenter', 'put', 'blog', 'post', 'work', 'dalle', 'definitely', 'still', 'feel', 'attempt', 'communicate', 'kind', 'alien', 'entity', 'quite', 'reason', 'ontology', 'human', 'even', 'theoretically', 'understand', 'english', 'language', 'day', 'maybe', 'openai', 'competitor', 'create', 'approximate', 'human', 'artistry', 'appreciate', 'marvel', 'laugh', 'come', 'alien', 'intelligence', 'perhaps', 'hail', 'planet', 'hardboile', 'egg', 'article', 'appear', 'print', 'issue', 'dalle', 'failure', 'show', 'limit', 'eliza', 'strickland', 'senior', 'editor', 'ieee', 'spectrum', 'cover', 'biomedical', 'engineering', 'topic', 'hold', 'masters', 'degree', 'journalism', 'metaverse', 'turn', 'shade', 'uncannily', 'creepy', 'write', 'ieee', 'spectrum', 'gizmo', 'column', 'freelance', 'consumertech', 'journalist', 'avid', 'gamer', 'former', 'staff', 'editor', 'digital', 'trend', 'particularly', 'fond', 'wearable', 'ebike', 'thing', 'smartphone', 'ce', 'attend', 'year', 'mesh', 'let', 'creator', 'import', 'facial', 'mesh', 'create', 'photorealistic', 'character', 'create', 'virtual', 'clone', 'difficult', 'think', 'epic', 'game', 'recently', 'introduce', 'mesh', 'metahuman', 'framework', 'create', 'photorealistic', 'human', 'character', 'let', 'creator', 'sculpt', 'import', 'mesh', 'create', 'convincing', 'character', 'less', 'hour', '’', 'incredibly', 'simple', 'compare', 'lot', 'tool', 'say', 'aka', 'partner', 'success', 'lead', 'giglab', 'cofounder', 'versed', '’d', 'compare', 'character', 'creator', 'game', 'enose', 'detect', 'glucose', 'level', 'percent', 'accuracy', 'freelance', 'writer', 'base', 'frequently', 'contribute', 'spectrum', 'watch', 'coverage', 'highlight', 'newsworthy', 'study', 'publish', 'ieee', 'journal', 'article', 'part', 'exclusive', 'ieee', 'journal', 'partnership', 'ieee', 'xplore', 'researcher', 'develop', 'ai', 'solution', 'leverage', 'public', 'video', 'feed', 'well', 'inform', 'decision', 'maker', 'dexter', 'contribute', 'editor', 'ieee', 'spectrum', 'focus', 'nanotechnology', 'sponsor', 'article', 'bring', 'engineering', 'midst', 'covid19', 'pandemic', 'many', 'research', 'group', 'seek', 'effective', 'method', 'determine', 'mobility', 'pattern', 'crowd', 'density', 'street', 'major', 'city', 'give', 'insight', 'effectiveness', 'stayathome', 'social', 'distancing', 'strategy', 'send', 'team', 'researcher', 'street', 'observe', 'tabulate', 'number', 'involve', 'put', 'researcher', 'risk', 'exposure', 'infection', 'strategy', 'mean', 'curb', 'researcher', 'connect', 'city', 'smart', 'mobility', 'accessible', 'resilient', 'transportation', 'c2smart', 'center', 'tier', 'usdotfunded', 'university', 'transportation', 'center', 'develop', 'solution', 'eliminate', 'risk', 'infection', 'researcher', 'easily', 'plug', 'already', 'exist', 'public', 'traffic', 'camera', 'feed', 'infrastructure', 'also', 'provide', 'comprehensive', 'datum', 'crowd', 'traffic', 'density', 'ever', 'compile', 'previously', 'easily', 'detect', 'conventional', 'traffic', 'sensor']"
"
        What’s the Tech Background of an Autonomous-Vehicle Engineer?
    ",https://spectrum.ieee.org/av-engineer-jobs,2022-07-11,"They come from video games, finance, geospatial research, the hacker community, and more, says Cruise’s EVP of engineering Mo Elshenawy, Cruise’s executive vice president of engineering, looks to hire engineers who love to experiment. Cruise, the San-Francisco–based designer and operator of all-electric self-driving cars, employs nearly 2,000 engineers, including somewhere between 300 and 900 engineers with Ph.D. degrees. They work in hardware and software. They specialize in AI, security, and safety. And though, indeed, some have robotics, automation, or automotive backgrounds, many don’t. Instead, they come from an incredibly long list of different technical fields—e-commerce, finance, game development, animation, cameras, semiconductors, and app development. Here’s what Mohamed Elshenawy, Cruise’s executive vice president of engineering, told IEEE Spectrum about the company’s workforce. (Elshenawy himself came to Cruise from stints as chief technology officer at a financial services startup and leader of a technology team at Amazon.) IEEE Spectrum:Let’s start with the big picture of your engineering team. Mohamed Elshenawy: In AI, we have machine-learning (ML) engineers that build the on-the-road decision-making modules. We also have the engineers that help build the tools for our continuous-learning machine. We have data engineers and data scientists, and even UI folks that help with the tools that the main core ML engineers use. In robotics, we have AV foundations engineers, who build and maintain our robotics operating systems, and embedded systems developers. In our security and safety operations, we have engineers working on threat modeling, app security engineering, IT enterprise security, and the security of the vehicle itself, along with all the systems engineers responsible for test validation, generating test-case scenarios, and tracking it all. Our hardware engineers build our own EVs from the ground up, in partnership with GM and Honda. They handle the definition, design, development, and production of sensors, compute modules, and related hardware and include about 50 engineering disciplines, including acoustic engineers, power engineers, system-on-chips people, and so on. Finally, we have the product engineering team—that covers both user-facing and internal apps—and the infrastructure team which builds the technical foundations (cloud infrastructure, internal tools, etc.) that the rest of our engineers rely on every day to get work done. Where do these engineers generally come from? Elshenawy: Many of our AI engineers come from academia, consumer tech, and finance. Our simulation group is part of this team. They include several engineers that helped build The Sims and others that worked for gaming and animation studios like Pixar, LucasArts, and Ubisoft. Our hardware engineers include people who came from Kodak, JPL, and chipmakers, as well as academia. For robotics, we generally look to robotics, other automotive, and aerospace companies for hiring. On the security side, we hire a mix of researchers and practitioners—and even literal hackers, including the team that infamously hacked a Jeep. Our product and infrastructure engineers come from a variety of traditional engineering companies as well as startups; they’ve previously built videoconferencing software, cloud computing platforms, and even a meditation app. How has the mix shifted over the years? Elshenawy: We’re solving for a problem that is mainly rooted in general AI, so we’ve always been heavy on the AI side of things. Because we are cloud native, we are able to leverage a lot of the existing technology that is provided by cloud providers, such as Google Cloud Platform and Azure; we don’t need to reinvent that. So we’re leaning more heavily towards AI, robotics, and hardware over time. Also, we’re ramping up product engineering now that we have started charging members of the public to ride in fully driverless cars. We expect that to continue to grow there as we solve for the technology and expand to multiple cities in the United States and internationally. You mean people working on the customer-facing app? Elshenawy: That and a lot more. This includes the customer-facing app that lets you order a ride, the in-car experience, and all the fleet operation on the back end, where we control our fleet, placing our fleet ahead of demand and determining pricing, and all the services that keep these lights on. What do your engineers have in common? Elshenawy: The self-driving cars problem is a great AI problem, and some people think about it as essentially a research problem, because you’re pushing the state of the art. But when you think about how you are actually going to pragmatically ship something continuously, it’s all rooted in experimentation. So one common factor that we find in the engineers who are successful here, regardless of where in our organization that they land, is having the experimentation mind-set, the humble, resilient mind-set of someone who’s continuously curious and very agile in nature. There are certain types of engineers that don’t deal well with uncertainty and experimentation, and there are other engineers who thrive under an environment of continuous learning. So the common trait among all these engineers is that learning, curiosity, and experimentation mind-set, and having the agility to deal with an unknown problem like this one. What are the hardest roles to fill right now? Elshenawy: Software, in general, has a shortage and will always have less supply than demand in the coming years, particularly in AI, applied machine learning, and deep learning, and we will continue to need these engineers in many different areas as we grow. Robotics specializations, and in general, control theory, will be very important as we go forward and those areas will continually face high demand. Tekla S. Perry is a senior editor at IEEE Spectrum. Based in Palo Alto, Calif., she's been covering the people, companies, and technology that make Silicon Valley a special place for more than 40 years. An IEEE member, she holds a bachelor's degree in journalism from Michigan State University.
 His pivot from defense helped a tiny tuning-fork prevent SUV rollovers and plane crashes In 1992, Asad M. Madni sat at the helm of BEI Sensors and Controls, overseeing a product line that included a variety of sensor and inertial-navigation devices, but its customers were less varied—mainly, the aerospace and defense electronics industries.
 
	And he had a problem.
 
	The Cold War had ended, crashing the U.S. defense industry. And business wasn’t going to come back anytime soon. BEI needed to identify and capture new customers—and quickly.
                                                                     ","They come from video games, finance, geospatial research, the hacker community, and more, says Cruise’s EVP of engineering Mo Elshenawy, Cruise’s executive vice president of engineering, looks to hire engineers who love to experiment. Cruise, the San-Francisco–based designer and operator of all-electric self-driving cars, employs nearly 2,000 engineers, including somewhere between 300 and 900 engineers with Ph.D. degrees. They work in hardware and software. They specialize in AI, security, and safety. And though, indeed, some have robotics, automation, or automotive backgrounds, many don’t. Instead, they come from an incredibly long list of different technical fields—e-commerce, finance, game development, animation, cameras, semiconductors, and app development. Here’s what Mohamed Elshenawy, Cruise’s executive vice president of engineering, told IEEE Spectrum about the company’s workforce. (Elshenawy himself came to Cruise from stints as chief technology officer at a financial services startup and leader of a technology team at Amazon.) IEEE Spectrum:Let’s start with the big picture of your engineering team. Mohamed Elshenawy: In AI, we have machine-learning (ML) engineers that build the on-the-road decision-making modules. We also have the engineers that help build the tools for our continuous-learning machine. We have data engineers and data scientists, and even UI folks that help with the tools that the main core ML engineers use. In robotics, we have AV foundations engineers, who build and maintain our robotics operating systems, and embedded systems developers. In our security and safety operations, we have engineers working on threat modeling, app security engineering, IT enterprise security, and the security of the vehicle itself, along with all the systems engineers responsible for test validation, generating test-case scenarios, and tracking it all. Our hardware engineers build our own EVs from the ground up, in partnership with GM and Honda. They handle the definition, design, development, and production of sensors, compute modules, and related hardware and include about 50 engineering disciplines, including acoustic engineers, power engineers, system-on-chips people, and so on. Finally, we have the product engineering team—that covers both user-facing and internal apps—and the infrastructure team which builds the technical foundations (cloud infrastructure, internal tools, etc.) that the rest of our engineers rely on every day to get work done. Where do these engineers generally come from? Elshenawy: Many of our AI engineers come from academia, consumer tech, and finance. Our simulation group is part of this team. They include several engineers that helped build The Sims and others that worked for gaming and animation studios like Pixar, LucasArts, and Ubisoft. Our hardware engineers include people who came from Kodak, JPL, and chipmakers, as well as academia. For robotics, we generally look to robotics, other automotive, and aerospace companies for hiring. On the security side, we hire a mix of researchers and practitioners—and even literal hackers, including the team that infamously hacked a Jeep. Our product and infrastructure engineers come from a variety of traditional engineering companies as well as startups; they’ve previously built videoconferencing software, cloud computing platforms, and even a meditation app. How has the mix shifted over the years? Elshenawy: We’re solving for a problem that is mainly rooted in general AI, so we’ve always been heavy on the AI side of things. Because we are cloud native, we are able to leverage a lot of the existing technology that is provided by cloud providers, such as Google Cloud Platform and Azure; we don’t need to reinvent that. So we’re leaning more heavily towards AI, robotics, and hardware over time. Also, we’re ramping up product engineering now that we have started charging members of the public to ride in fully driverless cars. We expect that to continue to grow there as we solve for the technology and expand to multiple cities in the United States and internationally. You mean people working on the customer-facing app? Elshenawy: That and a lot more. This includes the customer-facing app that lets you order a ride, the in-car experience, and all the fleet operation on the back end, where we control our fleet, placing our fleet ahead of demand and determining pricing, and all the services that keep these lights on. What do your engineers have in common? Elshenawy: The self-driving cars problem is a great AI problem, and some people think about it as essentially a research problem, because you’re pushing the state of the art. But when you think about how you are actually going to pragmatically ship something continuously, it’s all rooted in experimentation. So one common factor that we find in the engineers who are successful here, regardless of where in our organization that they land, is having the experimentation mind-set, the humble, resilient mind-set of someone who’s continuously curious and very agile in nature. There are certain types of engineers that don’t deal well with uncertainty and experimentation, and there are other engineers who thrive under an environment of continuous learning. So the common trait among all these engineers is that learning, curiosity, and experimentation mind-set, and having the agility to deal with an unknown problem like this one. What are the hardest roles to fill right now? Elshenawy: Software, in general, has a shortage and will always have less supply than demand in the coming years, particularly in AI, applied machine learning, and deep learning, and we will continue to need these engineers in many different areas as we grow. Robotics specializations, and in general, control theory, will be very important as we go forward and those areas will continually face high demand. Tekla S. Perry is a senior editor at IEEE Spectrum. Based in Palo Alto, Calif., she's been covering the people, companies, and technology that make Silicon Valley a special place for more than 40 years. An IEEE member, she holds a bachelor's degree in journalism from Michigan State University. His pivot from defense helped a tiny tuning-fork prevent SUV rollovers and plane crashes In 1992, Asad M. Madni sat at the helm of BEI Sensors and Controls, overseeing a product line that included a variety of sensor and inertial-navigation devices, but its customers were less varied—mainly, the aerospace and defense electronics industries. And he had a problem. The Cold War had ended, crashing the U.S. defense industry. And business wasn’t going to come back anytime soon. BEI needed to identify and capture new customers—and quickly.","['come', 'video', 'finance', 'geospatial', 'research', 'hacker', 'community', 'say', 'evp', 'engineering', 'executive', 'vice', 'president', 'engineering', 'look', 'hire', 'engineer', 'love', 'experiment', 'cruise', 'sanfrancisco', 'base', 'designer', 'operator', 'allelectric', 'selfdriving', 'car', 'employ', 'nearly', 'engineer', 'include', 'somewhere', 'engineer', 'phd', 'degree', 'work', 'hardware', 'software', 'specialize', 'security', 'safety', 'indeed', 'robotic', 'automation', 'automotive', 'background', 'many', 'instead', 'come', 'incredibly', 'long', 'list', 'different', 'technical', 'field', 'finance', 'game', 'development', 'animation', 'camera', 'semiconductor', 'app', 'development', '’', 'mohamed', 'executive', 'vice', 'president', 'engineering', 'tell', 'ieee', 'spectrum', 'company', 'workforce', 'come', 'cruise', 'stint', 'chief', 'technology', 'officer', 'financial', 'service', 'startup', 'leader', 'technology', 'team', 'amazon', 'ieee', 'spectrumlet', 'start', 'big', 'picture', 'engineering', 'team', 'mohame', 'elshenawy', 'machinelearne', 'engineer', 'build', 'ontheroad', 'decisionmake', 'module', 'also', 'engineer', 'help', 'build', 'tool', 'continuouslearning', 'machine', 'datum', 'engineer', 'datum', 'scientist', 'even', 'folk', 'help', 'tool', 'main', 'core', 'engineer', 'use', 'robotic', 'foundation', 'engineer', 'build', 'maintain', 'robotic', 'operating', 'system', 'embed', 'system', 'developer', 'security', 'safety', 'operation', 'engineer', 'work', 'threat', 'model', 'app', 'security', 'engineering', 'enterprise', 'security', 'security', 'vehicle', 'system', 'engineer', 'responsible', 'test', 'validation', 'generating', 'testcase', 'scenario', 'track', 'hardware', 'engineer', 'build', 'evs', 'ground', 'partnership', 'handle', 'definition', 'design', 'development', 'production', 'sensor', 'compute', 'module', 'related', 'hardware', 'include', 'engineering', 'discipline', 'include', 'acoustic', 'engineer', 'power', 'engineer', 'systemonchip', 'people', 'finally', 'product', 'engineering', 'team', 'cover', 'userface', 'internal', 'app', 'infrastructure', 'team', 'build', 'technical', 'foundation', 'cloud', 'infrastructure', 'internal', 'tool', 'rest', 'engineer', 'rely', 'day', 'get', 'work', 'engineer', 'generally', 'come', 'elshenawy', 'many', 'engineer', 'come', 'academia', 'consumer', 'tech', 'finance', 'simulation', 'group', 'part', 'team', 'include', 'several', 'engineer', 'build', 'sim', 'work', 'gaming', 'animation', 'studio', 'pixar', 'lucasart', 'ubisoft', 'hardware', 'engineer', 'include', 'people', 'come', 'chipmaker', 'well', 'academia', 'robotic', 'generally', 'look', 'robotic', 'automotive', 'aerospace', 'company', 'hire', 'security', 'side', 'hire', 'mix', 'researcher', 'practitioner', 'even', 'literal', 'hacker', 'include', 'team', 'infamously', 'hack', 'jeep', 'product', 'infrastructure', 'engineer', 'come', 'variety', 'traditional', 'engineering', 'company', 'well', 'startup', 'previously', 'build', 'videoconferencing', 'software', 'cloud', 'computing', 'platform', 'even', 'meditation', 'app', 'mix', 'shift', 'year', 'elshenawy', 'solve', 'problem', 'mainly', 'root', 'general', 'always', 'heavy', 'ai', 'side', 'thing', 'cloud', 'native', 'able', 'leverage', 'lot', 'exist', 'technology', 'provide', 'cloud', 'provider', 'cloud', 'platform', 'azure', 'need', 'reinvent', 'lean', 'heavily', 'robotic', 'hardware', 'time', 'also', 'ramp', 'product', 'engineering', 'start', 'charge', 'member', 'public', 'ride', 'fully', 'driverless', 'car', 'expect', 'continue', 'grow', 'solve', 'technology', 'expand', 'multiple', 'city', 'internationally', 'mean', 'people', 'work', 'customerface', 'app', 'elshenawy', 'lot', 'include', 'customerface', 'app', 'let', 'order', 'ride', 'incar', 'experience', 'fleet', 'operation', 'back', 'end', 'control', 'fleet', 'place', 'fleet', 'ahead', 'demand', 'determine', 'pricing', 'service', 'keep', 'light', 'engineer', 'common', 'elshenawy', 'selfdriving', 'car', 'problem', 'great', 'ai', 'problem', 'people', 'think', 'essentially', 'research', 'problem', 'push', 'state', 'art', 'think', 'actually', 'go', 'pragmatically', 'ship', 'continuously', 'root', 'experimentation', 'common', 'factor', 'find', 'engineer', 'successful', 'regardless', 'organization', 'land', 'experimentation', 'mindset', 'humble', 'resilient', 'mindset', '’', 'continuously', 'curious', 'agile', 'nature', 'certain', 'type', 'engineer', 'deal', 'well', 'uncertainty', 'experimentation', 'engineer', 'thrive', 'environment', 'continuous', 'learning', 'common', 'trait', 'engineer', 'learn', 'curiosity', 'experimentation', 'mindset', 'agility', 'deal', 'unknown', 'problem', 'one', 'hard', 'role', 'fill', 'right', 'elshenawy', 'software', 'general', 'shortage', 'always', 'less', 'supply', 'demand', 'come', 'year', 'particularly', 'ai', 'apply', 'machine', 'learning', 'deep', 'learning', 'continue', 'need', 'engineer', 'many', 'different', 'area', 'grow', 'robotic', 'specialization', 'general', 'control', 'theory', 'important', 'go', 'forward', 'area', 'continually', 'face', 'high', 'demand', 'senior', 'editor', 'ieee', 'spectrum', 'base', 'cover', 'people', 'company', 'technology', 'make', 'silicon', 'special', 'place', 'year', 'ieee', 'member', 'hold', 'bachelor', 'degree', 'journalism', 'pivot', 'defense', 'help', 'tiny', 'tuningfork', 'prevent', 'suv', 'rollover', 'plane', 'crash', 'asad', 'madni', 'sit', 'helm', 'bei', 'sensor', 'control', 'oversee', 'product', 'line', 'include', 'variety', 'sensor', 'inertialnavigation', 'device', 'customer', 'less', 'varied', 'mainly', 'aerospace', 'defense', 'electronic', 'industry', 'problem', 'cold', 'war', 'end', 'crash', 'defense', 'business', 'go', 'come', 'back', 'anytime', 'soon', 'bei', 'need', 'identify', 'capture', 'new', 'customer', 'quickly']"
"
        Autonomous Drones Challenge Human Champions in First “Fair” Race
    ",https://spectrum.ieee.org/zurich-autonomous-drone-race,2022-07-06,"Vision-based AI drones outfly world-class human pilots Watching robots operate with speed and precision is always impressive, if not, at this point, always surprising. Sophisticated sensors and fast computing means that a powerful and agile robot, like a drone, that knows exactly where it is and exactly where it’s going can reliably move in highly dynamic ways. This is not to say that it’s easy for the drone, but if you’ve got a nice external localization system, a powerful off-board computer, and a talented team of roboticists, you can perform some amazingly agile high-speed maneuvers that most humans could never hope to match. I say “most” humans, because there are some exceptionally talented humans who are, in fact, able to achieve a level of performance similar to that of even the fastest and most agile drones. The sport of FPV (first-person view) drone racing tests what’s possible with absurdly powerful drones in the hands of humans who must navigate complex courses with speed and precision that seems like it shouldn’t be possible, all while relying solely on a video feed sent from a camera on the front of the drone to the pilot’s VR headset. It’s honestly astonishing to watch. A year ago, autonomous racing quadrotors from Davide Scaramuzza’s Robotics and Perception Group at the University of Zurich (UZH) proved that they could beat the world’s fastest humans in a drone race. However, the drones relied on a motion-capture system to provide very high resolution position information in real time, along with a computer sending control information from the safety and comfort of a nearby desk, which doesn’t really seem like a fair competition.  Earlier this month, a trio of champion drone racers traveled to Zurich for a rematch, but this time, the race would be fair: no motion-capture system. Nothing off-board. Just drones and humans using their own vision systems and their own computers (or brains) to fly around a drone racing track as fast as possible. To understand what kind of a challenge this is, it’s important to have some context for the level of speed and agility. So here’s a video of one of UZH’s racing drones completing three laps of a track using the motion-capture system and off-board computation. This particular demo isn’t “fair,” but it does give an indication of what peak performance of a racing drone looks like, with a reaction from one of the professional human pilots (Thomas Bitmatta) at the end:  As Thomas says at the end of the video, the autonomous drone made it through one lap of the course in 5.3 seconds. With a peak speed of 110 kilometers per hour, this was a staggering 1.8 seconds per lap faster than Thomas, who has twice won FPV drone racing’s MultiGP International World Cup. The autonomous drone has several advantages in this particular race. First, it has near-perfect state estimation, thanks to a motion-capture system that covers the entire course. In other words, the drone always knows exactly where it is, as well as its precise speed and orientation. Experienced human pilots develop an intuition for estimating the state of their system, but they can’t even watch their own drone while racing since they’re immersed in the first-person view the entire time. The second advantage the autonomous drone has is that it’s able to compute a trajectory that traverses the course in a time-optimal way, considering the course layout and the constraints imposed by the drone itself. Human pilots have to practice on a course for hours (or even days) to discover what they think is an optimal trajectory, but they have no way of knowing for sure whether their racing lines can be improved or not. Elia Kaufmann prepares one of UZH's vision-based racing drones on its launch platform.Evan Ackerman/IEEE Spectrum So what, then, would make for a drone race in which humans and robots can compete fairly but doesn’t ask the robots to be less robotic or the humans to be less human-y? Three world-class human pilots were invited to Zurich for this race. Along with Thomas Bitmatta, UZH hosted Alex Vanover (2019 Drone Racing League champion) and Marvin Schäpper (2021 Swiss Drone League champion). Each pilot had as much time as they wanted on the course in advance, flying more than 700 practice laps in total. And on a Friday night in a military aircraft hangar outside of Zurich, the races began. Here are some preliminary clips from one of the vision-based autonomous drones flying computer-to-head with a human; the human-piloted drone is red, while the autonomous drone is blue:  With a top speed of 80 km/h, the vision-based autonomous drone outraced the fastest human by 0.5 second during a three-lap race, where just one or two-tenths of a second is frequently the difference between a win and a loss. This victory for the vision-based autonomous drone is a big deal, as Davide Scaramuzza explains: I was at this event in Zurich, and I’d love to tell you more about it. I will tell you more about it, but as Davide says, the UZH researchers are working on publishing their results, meaning that all the fascinating details about exactly what happened and why will have to wait a bit until they’ve got everything properly written up. So stay tuned—we’ll have lots more for you on this. The University of Zurich provided travel support to assist us with covering this event in person. What SubT means for the future of autonomous robots An ANYmal robot from Team Cerberus autonomously explores a cave on DARPA’s Subterranean Challenge course. Deep below the Louisville, Ky., zoo lies a network of enormous caverns carved out of limestone. The caverns are dark. They’re dusty. They’re humid. And during one week in September 2021, they were full of the most sophisticated robots in the world. The robots (along with their human teammates) were there to tackle a massive underground course designed by DARPA, the Defense Advanced Research Projects Agency, as the culmination of its three-year Subterranean Challenge.
 
	The SubT was first announced in early 2018. DARPA designed the competition to advance practical robotics in extreme conditions, based around three distinct underground environments: human-made tunnels, the urban underground, and natural caves. To do well, the robots would have to work in teams to traverse and map completely unknown areas spanning kilometers, search out a variety of artifacts, and identify their locations with pinpoint accuracy under strict time constraints. To more closely mimic the scenarios in which first responders might utilize autonomous robots, robots experienced darkness, dust and smoke, and even DARPA-controlled rockfalls that occasionally blocked their progress.
                                                          ","Vision-based AI drones outfly world-class human pilots Watching robots operate with speed and precision is always impressive, if not, at this point, always surprising. Sophisticated sensors and fast computing means that a powerful and agile robot, like a drone, that knows exactly where it is and exactly where it’s going can reliably move in highly dynamic ways. This is not to say that it’s easy for the drone, but if you’ve got a nice external localization system, a powerful off-board computer, and a talented team of roboticists, you can perform some amazingly agile high-speed maneuvers that most humans could never hope to match. I say “most” humans, because there are some exceptionally talented humans who are, in fact, able to achieve a level of performance similar to that of even the fastest and most agile drones. The sport of FPV (first-person view) drone racing tests what’s possible with absurdly powerful drones in the hands of humans who must navigate complex courses with speed and precision that seems like it shouldn’t be possible, all while relying solely on a video feed sent from a camera on the front of the drone to the pilot’s VR headset. It’s honestly astonishing to watch. A year ago, autonomous racing quadrotors from Davide Scaramuzza’s Robotics and Perception Group at the University of Zurich (UZH) proved that they could beat the world’s fastest humans in a drone race. However, the drones relied on a motion-capture system to provide very high resolution position information in real time, along with a computer sending control information from the safety and comfort of a nearby desk, which doesn’t really seem like a fair competition. Earlier this month, a trio of champion drone racers traveled to Zurich for a rematch, but this time, the race would be fair: no motion-capture system. Nothing off-board. Just drones and humans using their own vision systems and their own computers (or brains) to fly around a drone racing track as fast as possible. To understand what kind of a challenge this is, it’s important to have some context for the level of speed and agility. So here’s a video of one of UZH’s racing drones completing three laps of a track using the motion-capture system and off-board computation. This particular demo isn’t “fair,” but it does give an indication of what peak performance of a racing drone looks like, with a reaction from one of the professional human pilots (Thomas Bitmatta) at the end: As Thomas says at the end of the video, the autonomous drone made it through one lap of the course in 5.3 seconds. With a peak speed of 110 kilometers per hour, this was a staggering 1.8 seconds per lap faster than Thomas, who has twice won FPV drone racing’s MultiGP International World Cup. The autonomous drone has several advantages in this particular race. First, it has near-perfect state estimation, thanks to a motion-capture system that covers the entire course. In other words, the drone always knows exactly where it is, as well as its precise speed and orientation. Experienced human pilots develop an intuition for estimating the state of their system, but they can’t even watch their own drone while racing since they’re immersed in the first-person view the entire time. The second advantage the autonomous drone has is that it’s able to compute a trajectory that traverses the course in a time-optimal way, considering the course layout and the constraints imposed by the drone itself. Human pilots have to practice on a course for hours (or even days) to discover what they think is an optimal trajectory, but they have no way of knowing for sure whether their racing lines can be improved or not. Elia Kaufmann prepares one of UZH's vision-based racing drones on its launch platform.Evan Ackerman/IEEE Spectrum So what, then, would make for a drone race in which humans and robots can compete fairly but doesn’t ask the robots to be less robotic or the humans to be less human-y? Three world-class human pilots were invited to Zurich for this race. Along with Thomas Bitmatta, UZH hosted Alex Vanover (2019 Drone Racing League champion) and Marvin Schäpper (2021 Swiss Drone League champion). Each pilot had as much time as they wanted on the course in advance, flying more than 700 practice laps in total. And on a Friday night in a military aircraft hangar outside of Zurich, the races began. Here are some preliminary clips from one of the vision-based autonomous drones flying computer-to-head with a human; the human-piloted drone is red, while the autonomous drone is blue: With a top speed of 80 km/h, the vision-based autonomous drone outraced the fastest human by 0.5 second during a three-lap race, where just one or two-tenths of a second is frequently the difference between a win and a loss. This victory for the vision-based autonomous drone is a big deal, as Davide Scaramuzza explains: I was at this event in Zurich, and I’d love to tell you more about it. I will tell you more about it, but as Davide says, the UZH researchers are working on publishing their results, meaning that all the fascinating details about exactly what happened and why will have to wait a bit until they’ve got everything properly written up. So stay tuned—we’ll have lots more for you on this. The University of Zurich provided travel support to assist us with covering this event in person. What SubT means for the future of autonomous robots An ANYmal robot from Team Cerberus autonomously explores a cave on DARPA’s Subterranean Challenge course. Deep below the Louisville, Ky., zoo lies a network of enormous caverns carved out of limestone. The caverns are dark. They’re dusty. They’re humid. And during one week in September 2021, they were full of the most sophisticated robots in the world. The robots (along with their human teammates) were there to tackle a massive underground course designed by DARPA, the Defense Advanced Research Projects Agency, as the culmination of its three-year Subterranean Challenge. The SubT was first announced in early 2018. DARPA designed the competition to advance practical robotics in extreme conditions, based around three distinct underground environments: human-made tunnels, the urban underground, and natural caves. To do well, the robots would have to work in teams to traverse and map completely unknown areas spanning kilometers, search out a variety of artifacts, and identify their locations with pinpoint accuracy under strict time constraints. To more closely mimic the scenarios in which first responders might utilize autonomous robots, robots experienced darkness, dust and smoke, and even DARPA-controlled rockfalls that occasionally blocked their progress.","['visionbase', 'drone', 'outfly', 'worldclass', 'human', 'pilot', 'watch', 'robot', 'operate', 'speed', 'precision', 'always', 'impressive', 'point', 'always', 'surprising', 'sophisticated', 'sensor', 'fast', 'computing', 'mean', 'powerful', 'agile', 'robot', 'drone', 'know', 'exactly', 'exactly', 'go', 'reliably', 'move', 'highly', 'dynamic', 'way', 'say', '’', 'easy', 'drone', 'get', 'nice', 'external', 'localization', 'system', 'powerful', 'offboard', 'computer', 'talented', 'team', 'roboticist', 'perform', 'amazingly', 'agile', 'highspeed', 'maneuver', 'human', 'never', 'hope', 'match', 'say', 'human', 'exceptionally', 'talented', 'human', 'fact', 'able', 'achieve', 'level', 'performance', 'similar', 'even', 'fast', 'agile', 'drone', 'sport', 'drone', 'racing', 'test', '’', 'possible', 'absurdly', 'powerful', 'drone', 'hand', 'human', 'navigate', 'complex', 'course', 'speed', 'precision', 'seem', 'possible', 'rely', 'solely', 'video', 'feed', 'send', 'camera', 'front', 'drone', 'pilot', 'vr', 'headset', '’', 'honestly', 'astonishing', 'watch', 'year', 'ago', 'autonomous', 'racing', 'quadrotor', 'davide', 'scaramuzza', 'robotic', 'perception', 'group', 'prove', 'beat', 'world', 'fast', 'human', 'drone', 'race', 'however', 'drone', 'rely', 'motioncapture', 'system', 'provide', 'high', 'resolution', 'position', 'information', 'real', 'time', 'computer', 'send', 'control', 'information', 'safety', 'comfort', 'nearby', 'desk', 'really', 'seem', 'fair', 'competition', 'early', 'month', 'trio', 'champion', 'drone', 'racer', 'travel', 'rematch', 'time', 'race', 'fair', 'motioncapture', 'system', 'offboard', 'drone', 'human', 'use', 'vision', 'system', 'computer', 'brain', 'fly', 'drone', 'racing', 'track', 'fast', 'possible', 'understand', 'kind', 'challenge', '’s', 'important', 'context', 'level', 'speed', 'agility', '’', 'video', '’s', 'racing', 'drone', 'complete', 'lap', 'track', 'use', 'motioncapture', 'system', 'offboard', 'computation', 'particular', 'demo', 'fair', 'give', 'indication', 'peak', 'performance', 'racing', 'drone', 'look', 'reaction', 'professional', 'human', 'pilot', 'end', 'say', 'end', 'video', 'autonomous', 'drone', 'make', 'lap', 'course', 'second', 'peak', 'speed', 'kilometer', 'hour', 'staggering', 'second', 'lap', 'fast', 'twice', 'win', 'drone', 'racing', 'autonomous', 'drone', 'several', 'advantage', 'particular', 'race', 'first', 'state', 'estimation', 'thank', 'motioncapture', 'system', 'cover', 'entire', 'course', 'word', 'drone', 'always', 'know', 'exactly', 'well', 'precise', 'speed', 'orientation', 'experience', 'human', 'pilot', 'develop', 'intuition', 'estimate', 'state', 'system', 'even', 'watch', 'drone', 'race', 'immerse', 'firstperson', 'view', 'entire', 'time', 'second', 'advantage', 'autonomous', 'drone', '’', 'able', 'compute', 'trajectory', 'traverse', 'course', 'timeoptimal', 'way', 'consider', 'course', 'layout', 'constraint', 'impose', 'drone', 'human', 'pilot', 'practice', 'course', 'hour', 'even', 'day', 'discover', 'think', 'optimal', 'trajectory', 'way', 'know', 'sure', 'racing', 'line', 'improve', 'prepare', 'uzhs', 'visionbase', 'racing', 'drone', 'launch', 'platformevan', 'ackermanieee', 'spectrum', 'make', 'drone', 'race', 'human', 'robot', 'compete', 'fairly', 'ask', 'robot', 'less', 'robotic', 'human', 'less', 'humany', 'worldclass', 'human', 'pilot', 'invite', 'zurich', 'race', 'host', 'alex', 'vanover', 'drone', 'racing', 'league', 'drone', 'league', 'champion', 'pilot', 'much', 'time', 'want', 'course', 'advance', 'fly', 'practice', 'lap', 'total', 'night', 'military', 'aircraft', 'hangar', 'outside', 'race', 'begin', 'preliminary', 'clip', 'visionbase', 'autonomous', 'drone', 'fly', 'computertohead', 'human', 'humanpiloted', 'drone', 'red', 'autonomous', 'drone', 'blue', 'top', 'speed', 'kmh', 'visionbase', 'autonomous', 'drone', 'outrace', 'fast', 'human', 'second', 'threelap', 'race', 'twotenth', 'second', 'frequently', 'difference', 'win', 'loss', 'victory', 'visionbase', 'autonomous', 'drone', 'big', 'deal', 'davide', 'scaramuzza', 'explain', 'event', '’d', 'love', 'tell', 'tell', 'davide', 'say', 'uzh', 'researcher', 'work', 'publish', 'result', 'mean', 'fascinating', 'detail', 'exactly', 'happen', 'wait', 'bit', 'get', 'properly', 'write', 'stay', 'tune', 'we’ll', 'lot', 'provide', 'travel', 'support', 'assist', 'cover', 'event', 'person', 'subt', 'mean', 'future', 'autonomous', 'robot', 'anymal', 'robot', 'autonomously', 'explore', 'cave', 'subterranean', 'challenge', 'course', 'deep', 'lie', 'network', 'enormous', 'cavern', 'carve', 'limestone', 'cavern', 'dark', '’re', 'dusty', '’re', 'humid', 'week', 'full', 'sophisticated', 'robot', 'world', 'robot', 'human', 'teammate', 'tackle', 'massive', 'underground', 'course', 'design', 'defense', 'advanced', 'research', 'project', 'agency', 'culmination', 'threeyear', 'subterranean', 'challenge', 'subt', 'first', 'announce', 'early', 'darpa', 'design', 'competition', 'advance', 'practical', 'robotic', 'extreme', 'condition', 'base', 'distinct', 'underground', 'environment', 'humanmade', 'tunnel', 'urban', 'underground', 'natural', 'cave', 'well', 'robot', 'work', 'team', 'traverse', 'map', 'completely', 'unknown', 'area', 'span', 'kilometer', 'search', 'variety', 'artifact', 'identify', 'location', 'pinpoint', 'accuracy', 'strict', 'time', 'constraint', 'closely', 'mimic', 'scenario', 'first', 'responder', 'utilize', 'autonomous', 'robot', 'robot', 'experience', 'darkness', 'dust', 'smoke', 'even', 'darpacontrolle', 'rockfall', 'occasionally', 'block', 'progress']"
"
        150,000 Qubits Printed on a Chip
    ",https://spectrum.ieee.org/silicon-spin-qubits,2022-07-14,"New silicon spin qubits also emit telecom-band light The data revealing the first optical observation of spins in silicon. Two-laser scans of a single spin reveal signature spin-split central peaks; here the experimental data is visualized as an extruded mosaic. Quantum computers can theoretically solve problems no classical computer ever could—even given billions of years—but only if they possess many components known as qubits. Now scientists have fabricated more than 150,000 silicon-based qubits on a chip that they may be able to link together with light, to help form powerful quantum computers connected by a quantum Internet. Classical computers switch transistors either on or off to represent data as ones or zeroes. In contrast, quantum computers use quantum bits, also known as qubits. Because of the surreal nature of quantum physics, qubits can exist in a state called superposition, in which they are essentially both 1 and 0 at the same time. This phenomenon lets each qubit perform two calculations at once. The more qubits are quantum mechanically linked, or entangled (see our explainer), within a quantum computer, the greater its computational power can grow, in an exponential fashion. Currently quantum computers are noisy intermediate-scale quantum (NISQ) platforms, meaning their qubits number up to a few hundred at most. To prove useful for practical applications, future quantum computers will likely need thousands of qubits to help compensate for errors. There are many different types of qubits under development, such as superconducting circuits, electromagnetically trapped ions, and even frozen neon. Recently scientists have discovered that so-called spin qubits manufactured in silicon may prove especially promising for quantum computing. “Silicon spins are some of nature’s very best natural qubits,” says study cosenior author Stephanie Simmons, a quantum engineer at Simon Fraser University in Burnaby, B.C., Canada. The “spin” in spin qubits is the angular momentum of a particle such as an electron or an atomic nucleus. Spin can point up or down in a manner analogous to a compass needle that points north or south. A spin qubit can exist in a superposition where it is oriented both ways at once. Silicon spin qubits are among the most stable qubits created to date. In addition, this technology can theoretically rapidly scale up with the support of the decades of work spent developing the global semiconductor industry. Until now, scientists had measured single spins only electrically in silicon. This in turn meant that the only way to entangle spins together was electromagnetically, “which must be done with qubits in very close proximity to each other,” Simmons says. “This is hard to scale from an engineering perspective.” Now, for the first time, researchers have detected single spins optically in qubits in silicon. Such optical access to spin qubits suggests it may one day be possible to use light to “have qubits entangling with each other across a chip, or across a data center as easily as if they’re side by side,” Simmons says. The new spin qubits are based on radiation damage centers—defects within silicon created using ion implantation or irradiation with high-energy electrons. Specifically, they are T centers, each comprised of two carbon atoms, one hydrogen atom, and an unpaired electron. Each T center features an unpaired electron spin and a hydrogen nuclear spin, each of which can serve as a qubit. The electron spin can stay coherent, or stable, for more than 2 milliseconds; the hydrogen nuclear spin can remain so for more than 1.1 seconds. “Our silicon spin qubits’ long lifetimes are already quite competitive, and we have ideas on how to push them far further,” Simmons says. The researchers printed 150,000 spots dubbed “micropucks” on commercial industry-standard silicon-on-insulator integrated photonic wafers. Each micropuck ranged from 0.5 to 2.2 micrometers wide and held one T center on average, says study lead author Daniel Higginbottom, at Simon Fraser University. Under the microscope: An array of thousands of micropucks.Simon Fraser University Under a magnetic field, the spin qubit states in each T center have slightly different energies, and each emit a different wavelength of light. This lets the scientists detect the states of each spin qubit optically in these T centers. The wavelengths these spin qubits emit lie in the near-infrared O-band. This means these spin qubits can link with other qubits by emitting the kind of light often used in telecommunications networks, helping qubits work together inside a quantum processor and helping quantum computers partner over a quantum Internet. In addition, “the electron and nuclear spin qubits can be operated together—the nuclear spin as a long-lived memory qubit and the electron spin as an optically coupled communication qubit, and information can be swapped between them using microwave fields,” Simmons says. “No other physical quantum system combines high-performance quantum memories, direct and strong links to telecom photons, and the commercial prospects of silicon, which is the world’s top platform for both modern microelectronics as well as integrated photonics.” Scientists have known about T centers since the 1970s. “We do not know why we are the first to start investigating T centers as qubits in silicon,” Simmons says. “It is possible that researchers assumed that candidate spin-photon qubits in silicon were simply less likely to compete with candidates in other materials such as diamond and silicon carbide. It’s a mystery to us.” All in all, “we are most excited about the fundamental scalability of these qubits,” Simmons says. “It’s a new entrant to the international race for a quantum computer, and we think the prospects are very bright.” Although the researchers have fabricated many qubits in this new study, “these have not yet been wired up into a working quantum computer,” Simmons cautions. “The optical access to these spins will make this wiring a lot easier than many other approaches, but this technology is still very young and there is a lot of work to be done.” The scientists detailed their findings online 13 June in the journal Nature. Charles Q. Choi is a science reporter who contributes regularly to IEEE Spectrum. He has written for Scientific American, The New York Times, Wired, and Science, among others. If technologists can’t perfect it, quantum computers will never be big Dates chiseled into an ancient tombstone have more in common with the data in your phone or laptop than you may realize. They both involve conventional, classical information, carried by hardware that is relatively immune to errors. The situation inside a quantum computer is far different: The information itself has its own idiosyncratic properties, and compared with standard digital microelectronics, state-of-the-art quantum-computer hardware is more than a billion trillion times as likely to suffer a fault. This tremendous susceptibility to errors is the single biggest problem holding back quantum computing from realizing its great promise.
 
	Fortunately, an approach known as quantum error correction (QEC) can remedy this problem, at least in principle. A mature body of theory built up over the past quarter century now provides a solid theoretical foundation, and experimentalists have demonstrated dozens of proof-of-principle 
	examples of QEC. But these experiments still have not reached the level of quality and sophistication needed to reduce the overall error rate in a system.
                                             ","New silicon spin qubits also emit telecom-band light The data revealing the first optical observation of spins in silicon. Two-laser scans of a single spin reveal signature spin-split central peaks; here the experimental data is visualized as an extruded mosaic. Quantum computers can theoretically solve problems no classical computer ever could—even given billions of years—but only if they possess many components known as qubits. Now scientists have fabricated more than 150,000 silicon-based qubits on a chip that they may be able to link together with light, to help form powerful quantum computers connected by a quantum Internet. Classical computers switch transistors either on or off to represent data as ones or zeroes. In contrast, quantum computers use quantum bits, also known as qubits. Because of the surreal nature of quantum physics, qubits can exist in a state called superposition, in which they are essentially both 1 and 0 at the same time. This phenomenon lets each qubit perform two calculations at once. The more qubits are quantum mechanically linked, or entangled (see our explainer), within a quantum computer, the greater its computational power can grow, in an exponential fashion. Currently quantum computers are noisy intermediate-scale quantum (NISQ) platforms, meaning their qubits number up to a few hundred at most. To prove useful for practical applications, future quantum computers will likely need thousands of qubits to help compensate for errors. There are many different types of qubits under development, such as superconducting circuits, electromagnetically trapped ions, and even frozen neon. Recently scientists have discovered that so-called spin qubits manufactured in silicon may prove especially promising for quantum computing. “Silicon spins are some of nature’s very best natural qubits,” says study cosenior author Stephanie Simmons, a quantum engineer at Simon Fraser University in Burnaby, B.C., Canada. The “spin” in spin qubits is the angular momentum of a particle such as an electron or an atomic nucleus. Spin can point up or down in a manner analogous to a compass needle that points north or south. A spin qubit can exist in a superposition where it is oriented both ways at once. Silicon spin qubits are among the most stable qubits created to date. In addition, this technology can theoretically rapidly scale up with the support of the decades of work spent developing the global semiconductor industry. Until now, scientists had measured single spins only electrically in silicon. This in turn meant that the only way to entangle spins together was electromagnetically, “which must be done with qubits in very close proximity to each other,” Simmons says. “This is hard to scale from an engineering perspective.” Now, for the first time, researchers have detected single spins optically in qubits in silicon. Such optical access to spin qubits suggests it may one day be possible to use light to “have qubits entangling with each other across a chip, or across a data center as easily as if they’re side by side,” Simmons says. The new spin qubits are based on radiation damage centers—defects within silicon created using ion implantation or irradiation with high-energy electrons. Specifically, they are T centers, each comprised of two carbon atoms, one hydrogen atom, and an unpaired electron. Each T center features an unpaired electron spin and a hydrogen nuclear spin, each of which can serve as a qubit. The electron spin can stay coherent, or stable, for more than 2 milliseconds; the hydrogen nuclear spin can remain so for more than 1.1 seconds. “Our silicon spin qubits’ long lifetimes are already quite competitive, and we have ideas on how to push them far further,” Simmons says. The researchers printed 150,000 spots dubbed “micropucks” on commercial industry-standard silicon-on-insulator integrated photonic wafers. Each micropuck ranged from 0.5 to 2.2 micrometers wide and held one T center on average, says study lead author Daniel Higginbottom, at Simon Fraser University. Under the microscope: An array of thousands of micropucks.Simon Fraser University Under a magnetic field, the spin qubit states in each T center have slightly different energies, and each emit a different wavelength of light. This lets the scientists detect the states of each spin qubit optically in these T centers. The wavelengths these spin qubits emit lie in the near-infrared O-band. This means these spin qubits can link with other qubits by emitting the kind of light often used in telecommunications networks, helping qubits work together inside a quantum processor and helping quantum computers partner over a quantum Internet. In addition, “the electron and nuclear spin qubits can be operated together—the nuclear spin as a long-lived memory qubit and the electron spin as an optically coupled communication qubit, and information can be swapped between them using microwave fields,” Simmons says. “No other physical quantum system combines high-performance quantum memories, direct and strong links to telecom photons, and the commercial prospects of silicon, which is the world’s top platform for both modern microelectronics as well as integrated photonics.” Scientists have known about T centers since the 1970s. “We do not know why we are the first to start investigating T centers as qubits in silicon,” Simmons says. “It is possible that researchers assumed that candidate spin-photon qubits in silicon were simply less likely to compete with candidates in other materials such as diamond and silicon carbide. It’s a mystery to us.” All in all, “we are most excited about the fundamental scalability of these qubits,” Simmons says. “It’s a new entrant to the international race for a quantum computer, and we think the prospects are very bright.” Although the researchers have fabricated many qubits in this new study, “these have not yet been wired up into a working quantum computer,” Simmons cautions. “The optical access to these spins will make this wiring a lot easier than many other approaches, but this technology is still very young and there is a lot of work to be done.” The scientists detailed their findings online 13 June in the journal Nature. Charles Q. Choi is a science reporter who contributes regularly to IEEE Spectrum. He has written for Scientific American, The New York Times, Wired, and Science, among others. If technologists can’t perfect it, quantum computers will never be big Dates chiseled into an ancient tombstone have more in common with the data in your phone or laptop than you may realize. They both involve conventional, classical information, carried by hardware that is relatively immune to errors. The situation inside a quantum computer is far different: The information itself has its own idiosyncratic properties, and compared with standard digital microelectronics, state-of-the-art quantum-computer hardware is more than a billion trillion times as likely to suffer a fault. This tremendous susceptibility to errors is the single biggest problem holding back quantum computing from realizing its great promise. Fortunately, an approach known as quantum error correction (QEC) can remedy this problem, at least in principle. A mature body of theory built up over the past quarter century now provides a solid theoretical foundation, and experimentalists have demonstrated dozens of proof-of-principle examples of QEC. But these experiments still have not reached the level of quality and sophistication needed to reduce the overall error rate in a system.","['new', 'silicon', 'spin', 'qubit', 'also', 'emit', 'telecomband', 'light', 'datum', 'reveal', 'first', 'optical', 'observation', 'spin', 'silicon', 'twolaser', 'scan', 'single', 'spin', 'reveal', 'signature', 'spinsplit', 'central', 'peak', 'experimental', 'datum', 'visualize', 'extruded', 'mosaic', 'quantum', 'computer', 'theoretically', 'solve', 'problem', 'classical', 'computer', 'ever', 'even', 'give', 'billion', 'year', 'possess', 'many', 'component', 'know', 'qubit', 'scientist', 'fabricate', 'siliconbase', 'qubit', 'chip', 'able', 'link', 'together', 'light', 'help', 'form', 'powerful', 'quantum', 'computer', 'connect', 'quantum', 'internet', 'classical', 'computer', 'switch', 'transistor', 'represent', 'datum', 'one', 'zero', 'contrast', 'quantum', 'computer', 'use', 'quantum', 'bit', 'also', 'know', 'qubit', 'surreal', 'nature', 'quantum', 'physics', 'qubit', 'exist', 'state', 'call', 'superposition', 'essentially', 'time', 'phenomenon', 'let', 'qubit', 'perform', 'calculation', 'qubit', 'mechanically', 'link', 'entangle', 'see', 'explainer', 'quantum', 'computer', 'great', 'computational', 'power', 'grow', 'exponential', 'fashion', 'currently', 'quantum', 'computer', 'noisy', 'intermediatescale', 'quantum', 'nisq', 'platform', 'mean', 'qubit', 'number', 'prove', 'useful', 'practical', 'application', 'future', 'quantum', 'computer', 'likely', 'need', 'thousand', 'qubit', 'help', 'compensate', 'error', 'many', 'different', 'type', 'qubit', 'development', 'superconducte', 'circuit', 'electromagnetically', 'trap', 'ion', 'even', 'frozen', 'neon', 'recently', 'scientist', 'discover', 'socalle', 'spin', 'qubit', 'manufacture', 'silicon', 'prove', 'especially', 'promise', 'quantum', 'compute', 'silicon', 'spin', 'nature', 'good', 'natural', 'qubit', 'say', 'study', 'author', 'simmon', 'quantum', 'engineer', 'spin', 'spin', 'qubit', 'angular', 'momentum', 'particle', 'electron', 'nucleus', 'spin', 'point', 'manner', 'analogous', 'compass', 'needle', 'point', 'north', 'south', 'spin', 'qubit', 'exist', 'superposition', 'orient', 'way', 'silicon', 'spin', 'qubit', 'stable', 'qubit', 'create', 'date', 'addition', 'technology', 'theoretically', 'rapidly', 'scale', 'support', 'decade', 'work', 'spend', 'develop', 'global', 'semiconductor', 'industry', 'scientist', 'measure', 'single', 'spin', 'electrically', 'silicon', 'turn', 'mean', 'way', 'entangle', 'spin', 'together', 'electromagnetically', 'qubit', 'close', 'proximity', 'simmon', 'say', 'hard', 'scale', 'engineering', 'perspective', 'first', 'time', 'researcher', 'detect', 'single', 'spin', 'optically', 'qubit', 'silicon', 'optical', 'access', 'spin', 'qubit', 'suggest', 'day', 'possible', 'use', 'light', 'qubit', 'entangle', 'chip', 'data', 'center', 'easily', '’re', 'side', 'side', 'simmon', 'say', 'new', 'spin', 'qubit', 'base', 'radiation', 'damage', 'center', 'defect', 'silicon', 'create', 'use', 'ion', 'implantation', 'irradiation', 'highenergy', 'electron', 'specifically', 'center', 'comprise', 'carbon', 'atom', 'hydrogen', 'atom', 'unpaired', 'electron', 'center', 'feature', 'unpaired', 'electron', 'spin', 'hydrogen', 'nuclear', 'spin', 'serve', 'qubit', 'electron', 'spin', 'stay', 'coherent', 'stable', 'millisecond', 'hydrogen', 'nuclear', 'spin', 'remain', 'second', 'silicon', 'spin', 'qubit', 'long', 'lifetime', 'already', 'quite', 'competitive', 'idea', 'push', 'far', 'simmon', 'say', 'researcher', 'print', 'spot', 'dub', 'micropuck', 'commercial', 'integrate', 'photonic', 'wafer', 'micropuck', 'range', 'micrometer', 'wide', 'hold', 'center', 'average', 'say', 'study', 'lead', 'author', 'microscope', 'array', 'thousand', 'micropuckssimon', 'magnetic', 'field', 'spin', 'qubit', 'state', 'center', 'slightly', 'different', 'energy', 'emit', 'different', 'wavelength', 'light', 'let', 'scientist', 'detect', 'state', 'spin', 'qubit', 'optically', 'center', 'wavelength', 'spin', 'qubit', 'emit', 'lie', 'nearinfrared', 'mean', 'spin', 'qubit', 'link', 'qubit', 'emit', 'kind', 'light', 'often', 'use', 'telecommunication', 'network', 'help', 'qubit', 'work', 'together', 'quantum', 'processor', 'help', 'quantum', 'computer', 'partner', 'quantum', 'internet', 'addition', 'electron', 'nuclear', 'spin', 'qubit', 'operate', 'together', 'nuclear', 'spin', 'longlived', 'memory', 'qubit', 'electron', 'spin', 'optically', 'couple', 'communication', 'qubit', 'information', 'swap', 'use', 'microwave', 'field', 'simmon', 'say', 'physical', 'quantum', 'system', 'combine', 'highperformance', 'quantum', 'memory', 'direct', 'strong', 'link', 'telecom', 'photon', 'commercial', 'prospect', 'silicon', 'world', 'top', 'platform', 'modern', 'microelectronic', 'well', 'integrate', 'photonic', 'scientist', 'know', 'center', '1970', 'know', 'first', 'start', 'investigate', 'center', 'qubit', 'silicon', 'say', 'possible', 'researcher', 'assume', 'candidate', 'qubit', 'silicon', 'simply', 'less', 'likely', 'compete', 'candidate', 'material', 'diamond', 'silicon', '’', 'mystery', 'excited', 'fundamental', 'scalability', 'qubit', 'simmon', 'say', '’', 'new', 'entrant', 'international', 'race', 'quantum', 'computer', 'think', 'prospect', 'bright', 'researcher', 'fabricate', 'many', 'qubit', 'new', 'study', 'yet', 'wire', 'work', 'quantum', 'computer', 'simmon', 'caution', 'optical', 'access', 'spin', 'make', 'wiring', 'lot', 'easy', 'many', 'approach', 'technology', 'still', 'young', 'lot', 'work', 'scientist', 'detail', 'finding', 'online', 'science', 'reporter', 'contribute', 'regularly', 'ieee', 'spectrum', 'write', 'scientific', 'wire', 'science', 'technologist', 'perfect', 'quantum', 'computer', 'never', 'big', 'date', 'chisel', 'ancient', 'tombstone', 'common', 'datum', 'phone', 'laptop', 'realize', 'involve', 'conventional', 'classical', 'information', 'carry', 'hardware', 'relatively', 'immune', 'error', 'situation', 'quantum', 'computer', 'far', 'different', 'information', 'idiosyncratic', 'property', 'compare', 'standard', 'digital', 'microelectronic', 'stateoftheart', 'quantumcomputer', 'hardware', 'time', 'likely', 'suffer', 'fault', 'tremendous', 'susceptibility', 'error', 'single', 'big', 'problem', 'hold', 'quantum', 'computing', 'realize', 'great', 'promise', 'fortunately', 'approach', 'know', 'quantum', 'error', 'correction', 'qec', 'remedy', 'problem', 'least', 'principle', 'mature', 'body', 'theory', 'build', 'past', 'quarter', 'century', 'provide', 'solid', 'theoretical', 'foundation', 'experimentalist', 'demonstrate', 'dozen', 'proofofprinciple', 'example', 'qec', 'experiment', 'still', 'reach', 'level', 'quality', 'sophistication', 'need', 'reduce', 'overall', 'error', 'rate', 'system']"
"
        RISC-V Guns for Raspberry Pi, Legacy Chips
    ",https://spectrum.ieee.org/risc-v-raspberry-pi,2022-07-13,"Chinese market, trade-war-weary engineers welcome open chip architecture 
	Two hardware makers are planning to offer chips later this year featuring the RISC-V free and open architecture standard, joining the US $180 Linux-capable StarFive 
	VisionFive RISC-V board that went on sale in January. In late June, Pine64 said it was designing a single-board computer for the market now dominated by Raspberry Pi, and Xcalibyte and DeepComputing said they would begin shipping RISC-V-based laptops at the end of the summer.
 
	The 12-year-old 
	RISC-V computer instruction set architecture standard belongs to no one and everyone, giving it unique appeal compared with Intel and Arm chips, which require licensing fees. At the same time, RISC-V’s relative novelty and reduced feature set and support are barriers to more widespread adoption. An open-source development effort last year to produce a Linux-capable mini-PC with RISC-V ended in failure. VisionFive was involved in that project, too. Like any new tech ecosystem, software support for RISC-V is more limited than in Raspberry Pi’s robust development community, says independent software engineer Leon Anavi in a review of the VisionFive. That said, he encouraged viewers to join in and contribute to the growing RISC-V community.
 
	“Consumer laptops are not the target of the RISC-V ecosystem. RISC-V is optimized for power consumption.”
	
	—William Li, Counterpoint Research
 
	RISC-V is the fifth generation of so-called reduced instruction set computers—hence the acronym—and it is focused on simplicity and power efficiency. When the Internet of Things started to take off, RISC-V’s moment seemed to have come; Huawei has 
	used the standard in wearables since 2018. RISC-V could achieve a 25 percent market share in the IoT by 2025, Counterpoint Research estimated in late 2021. “Consumer laptops are not the target of the RISC-V ecosystem,” says analyst William Li, the author of Counterpoint report. “RISC-V is optimized for power consumption.” 
	That has attracted AI-specific applications and cloud infrastructure (
	“RISC-V Dives Into AI,”IEEE Spectrum, April 2022).
 
	The openness of the standard has also attracted markets facing limits on their use of Intel and Arm intellectual property: No government can place sanctions on open chip designs. That has been a concern for Chinese hardware makers since the 
	trade war initiated by former U.S. president Donald Trump, and may help promote RISC-V sales in the event of restrictions on sales of Intel or Arm tech, wrote Deloitte analysts late last year. Alibaba has already taken some experimental steps in the direction of RISC-V, IEEE Spectrumwrote last year.
 
	Russian hardware makers also 
	began exploring RISC-V, even before the severe round of sanctions other countries placed on it after its 2022 escalation of its war with Ukraine. “In the second half of this year, we will keep track of Chinese and Russian companies to see if they invest in RISC-V and creating their own IP,” says Li. 
	One Chinese research institute, the Institute of Software at the Chinese Academy of Sciences (ISCAS), set out to build 2,000 RISC-powered laptops for development purposes, according to a July 2021 
	post by PLCT Lab director Wei Wu. In the PLCT Lab’s road map for 2022, Wu writes that the group will focus on enabling Linux and the most commonly used open software, including LibreOffice, for RISC-V laptops.
 
	That is one of the ironies of RISC-V being an open standard: It may gain adoption as trade barriers fragment the global market for chips.
 
	For now, however, the biggest market for RISC-V chips is in the global automotive industry, market research group Semico 
	reported last year on behalf of the RISC-V International industry group. Semico predicted that RISC-V will continue to gain shares of the automotive market.
 
	The future for chips may in fact be mixed, in a good way: Hardware makers can mix RISC-V, Arm, and Intel components in processor packages of their own making. Intel, for one, 
	encourages that on the grounds that customers might end up paying them to build such chips.
 
	And neither legacy-chip designer is standing still. Perhaps in response to RISC-V’s customizability, Arm, which while open charges a license fee, has been offering IoT customers more customizable options. “They’re going to try to defend their market share,“ Li predicts.
  Lucas Laursen is a journalist covering global development by way of science and technology with special interest in energy and agriculture. He has lived in and reported from the United States, United Kingdom, Switzerland, and Mexico.
 If technologists can’t perfect it, quantum computers will never be big Dates chiseled into an ancient tombstone have more in common with the data in your phone or laptop than you may realize. They both involve conventional, classical information, carried by hardware that is relatively immune to errors. The situation inside a quantum computer is far different: The information itself has its own idiosyncratic properties, and compared with standard digital microelectronics, state-of-the-art quantum-computer hardware is more than a billion trillion times as likely to suffer a fault. This tremendous susceptibility to errors is the single biggest problem holding back quantum computing from realizing its great promise.
 
	Fortunately, an approach known as quantum error correction (QEC) can remedy this problem, at least in principle. A mature body of theory built up over the past quarter century now provides a solid theoretical foundation, and experimentalists have demonstrated dozens of proof-of-principle 
	examples of QEC. But these experiments still have not reached the level of quality and sophistication needed to reduce the overall error rate in a system.
                                             ","Chinese market, trade-war-weary engineers welcome open chip architecture Two hardware makers are planning to offer chips later this year featuring the RISC-V free and open architecture standard, joining the US $180 Linux-capable StarFive VisionFive RISC-V board that went on sale in January. In late June, Pine64 said it was designing a single-board computer for the market now dominated by Raspberry Pi, and Xcalibyte and DeepComputing said they would begin shipping RISC-V-based laptops at the end of the summer. The 12-year-old RISC-V computer instruction set architecture standard belongs to no one and everyone, giving it unique appeal compared with Intel and Arm chips, which require licensing fees. At the same time, RISC-V’s relative novelty and reduced feature set and support are barriers to more widespread adoption. An open-source development effort last year to produce a Linux-capable mini-PC with RISC-V ended in failure. VisionFive was involved in that project, too. Like any new tech ecosystem, software support for RISC-V is more limited than in Raspberry Pi’s robust development community, says independent software engineer Leon Anavi in a review of the VisionFive. That said, he encouraged viewers to join in and contribute to the growing RISC-V community. “Consumer laptops are not the target of the RISC-V ecosystem. RISC-V is optimized for power consumption.” —William Li, Counterpoint Research RISC-V is the fifth generation of so-called reduced instruction set computers—hence the acronym—and it is focused on simplicity and power efficiency. When the Internet of Things started to take off, RISC-V’s moment seemed to have come; Huawei has used the standard in wearables since 2018. RISC-V could achieve a 25 percent market share in the IoT by 2025, Counterpoint Research estimated in late 2021. “Consumer laptops are not the target of the RISC-V ecosystem,” says analyst William Li, the author of Counterpoint report. “RISC-V is optimized for power consumption.” That has attracted AI-specific applications and cloud infrastructure ( “RISC-V Dives Into AI,”IEEE Spectrum, April 2022). The openness of the standard has also attracted markets facing limits on their use of Intel and Arm intellectual property: No government can place sanctions on open chip designs. That has been a concern for Chinese hardware makers since the trade war initiated by former U.S. president Donald Trump, and may help promote RISC-V sales in the event of restrictions on sales of Intel or Arm tech, wrote Deloitte analysts late last year. Alibaba has already taken some experimental steps in the direction of RISC-V, IEEE Spectrumwrote last year. Russian hardware makers also began exploring RISC-V, even before the severe round of sanctions other countries placed on it after its 2022 escalation of its war with Ukraine. “In the second half of this year, we will keep track of Chinese and Russian companies to see if they invest in RISC-V and creating their own IP,” says Li. One Chinese research institute, the Institute of Software at the Chinese Academy of Sciences (ISCAS), set out to build 2,000 RISC-powered laptops for development purposes, according to a July 2021 post by PLCT Lab director Wei Wu. In the PLCT Lab’s road map for 2022, Wu writes that the group will focus on enabling Linux and the most commonly used open software, including LibreOffice, for RISC-V laptops. That is one of the ironies of RISC-V being an open standard: It may gain adoption as trade barriers fragment the global market for chips. For now, however, the biggest market for RISC-V chips is in the global automotive industry, market research group Semico reported last year on behalf of the RISC-V International industry group. Semico predicted that RISC-V will continue to gain shares of the automotive market. The future for chips may in fact be mixed, in a good way: Hardware makers can mix RISC-V, Arm, and Intel components in processor packages of their own making. Intel, for one, encourages that on the grounds that customers might end up paying them to build such chips. And neither legacy-chip designer is standing still. Perhaps in response to RISC-V’s customizability, Arm, which while open charges a license fee, has been offering IoT customers more customizable options. “They’re going to try to defend their market share,“ Li predicts. Lucas Laursen is a journalist covering global development by way of science and technology with special interest in energy and agriculture. He has lived in and reported from the United States, United Kingdom, Switzerland, and Mexico. If technologists can’t perfect it, quantum computers will never be big Dates chiseled into an ancient tombstone have more in common with the data in your phone or laptop than you may realize. They both involve conventional, classical information, carried by hardware that is relatively immune to errors. The situation inside a quantum computer is far different: The information itself has its own idiosyncratic properties, and compared with standard digital microelectronics, state-of-the-art quantum-computer hardware is more than a billion trillion times as likely to suffer a fault. This tremendous susceptibility to errors is the single biggest problem holding back quantum computing from realizing its great promise. Fortunately, an approach known as quantum error correction (QEC) can remedy this problem, at least in principle. A mature body of theory built up over the past quarter century now provides a solid theoretical foundation, and experimentalists have demonstrated dozens of proof-of-principle examples of QEC. But these experiments still have not reached the level of quality and sophistication needed to reduce the overall error rate in a system.","['chinese', 'market', 'tradewarweary', 'engineer', 'welcome', 'open', 'chip', 'architecture', 'hardware', 'maker', 'plan', 'offer', 'chip', 'later', 'year', 'feature', 'riscv', 'free', 'open', 'architecture', 'standard', 'join', 'linuxcapable', 'starfive', 'visionfive', 'riscv', 'board', 'go', 'sale', 'late', 'say', 'design', 'singleboard', 'computer', 'market', 'dominate', 'raspberry', 'xcalibyte', 'deepcomputing', 'say', 'begin', 'ship', 'riscvbased', 'laptop', 'end', 'summer', 'riscv', 'computer', 'instruction', 'set', 'architecture', 'standard', 'belong', 'one', 'give', 'unique', 'appeal', 'compare', 'intel', 'arm', 'chip', 'require', 'licensing', 'fee', 'time', 'riscv', 'relative', 'novelty', 'reduce', 'feature', 'set', 'support', 'barrier', 'widespread', 'adoption', 'opensource', 'development', 'effort', 'last', 'year', 'produce', 'linuxcapable', 'minipc', 'riscv', 'end', 'failure', 'visionfive', 'involve', 'project', 'new', 'tech', 'ecosystem', 'software', 'support', 'riscv', 'limited', 'robust', 'development', 'community', 'say', 'independent', 'software', 'engineer', 'anavi', 'review', 'visionfive', 'say', 'encourage', 'viewer', 'join', 'contribute', 'grow', 'riscv', 'community', 'consumer', 'laptop', 'target', 'riscv', 'ecosystem', 'riscv', 'optimize', 'power', 'consumption', 'research', 'riscv', 'fifth', 'generation', 'socalled', 'reduce', 'instruction', 'set', 'computer', 'hence', 'acronym', 'focus', 'simplicity', 'power', 'efficiency', 'internet', 'thing', 'start', 'take', 'riscv', 'moment', 'seem', 'come', 'use', 'standard', 'wearable', 'riscv', 'achieve', 'percent', 'market', 'share', 'iot', 'counterpoint', 'research', 'estimate', 'late', 'consumer', 'laptop', 'target', 'riscv', 'ecosystem', 'say', 'author', 'counterpoint', 'report', 'riscv', 'optimize', 'power', 'consumption', 'attract', 'aispecific', 'application', 'cloud', 'infrastructure', 'riscv', 'dive', 'aiieee', 'spectrum', 'openness', 'standard', 'also', 'attract', 'market', 'face', 'limit', 'use', 'intel', 'arm', 'intellectual', 'property', 'government', 'place', 'sanction', 'open', 'chip', 'design', 'concern', 'chinese', 'hardware', 'maker', 'trade', 'war', 'initiate', 'former', 'help', 'promote', 'riscv', 'sale', 'event', 'restriction', 'sale', 'intel', 'arm', 'tech', 'write', 'analyst', 'late', 'last', 'year', 'alibaba', 'already', 'take', 'experimental', 'step', 'direction', 'riscv', 'ieee', 'spectrumwrote', 'last', 'year', 'russian', 'hardware', 'maker', 'also', 'begin', 'explore', 'riscv', 'even', 'severe', 'round', 'sanction', 'country', 'place', 'escalation', 'war', 'second', 'half', 'year', 'keep', 'track', 'chinese', 'russian', 'company', 'see', 'invest', 'riscv', 'create', 'ip', 'say', 'software', 'science', 'isca', 'set', 'build', 'riscpowered', 'laptop', 'development', 'purpose', 'accord', 'post', 'plct', 'road', 'map', 'write', 'group', 'focus', 'enable', 'linux', 'commonly', 'use', 'open', 'software', 'include', 'libreoffice', 'riscv', 'laptop', 'irony', 'riscv', 'open', 'standard', 'gain', 'adoption', 'trade', 'barrier', 'fragment', 'global', 'market', 'chip', 'however', 'big', 'market', 'riscv', 'chip', 'global', 'automotive', 'industry', 'market', 'research', 'group', 'semico', 'report', 'last', 'year', 'behalf', 'riscv', 'international', 'industry', 'group', 'semico', 'predict', 'riscv', 'continue', 'gain', 'share', 'automotive', 'market', 'future', 'chip', 'fact', 'mix', 'good', 'way', 'hardware', 'maker', 'mix', 'riscv', 'arm', 'intel', 'component', 'processor', 'package', 'make', 'intel', 'encourage', 'ground', 'customer', 'end', 'pay', 'build', 'chip', 'legacychip', 'designer', 'stand', 'still', 'perhaps', 'response', 'riscv', 'customizability', 'arm', 'open', 'charge', 'license', 'fee', 'offer', 'iot', 'customer', 'customizable', 'option', 'go', 'try', 'defend', 'market', 'share', 'predict', 'journalist', 'cover', 'global', 'development', 'way', 'science', 'technology', 'special', 'interest', 'energy', 'agriculture', 'live', 'report', 'technologist', 'perfect', 'quantum', 'computer', 'never', 'big', 'date', 'chisel', 'ancient', 'tombstone', 'common', 'datum', 'phone', 'laptop', 'realize', 'involve', 'conventional', 'classical', 'information', 'carry', 'hardware', 'relatively', 'immune', 'error', 'situation', 'quantum', 'computer', 'far', 'different', 'information', 'idiosyncratic', 'property', 'compare', 'standard', 'digital', 'microelectronic', 'stateoftheart', 'quantumcomputer', 'hardware', 'time', 'likely', 'suffer', 'fault', 'tremendous', 'susceptibility', 'error', 'single', 'big', 'problem', 'hold', 'quantum', 'computing', 'realize', 'great', 'promise', 'fortunately', 'approach', 'know', 'quantum', 'error', 'correction', 'qec', 'remedy', 'problem', 'least', 'principle', 'mature', 'body', 'theory', 'build', 'past', 'quarter', 'century', 'provide', 'solid', 'theoretical', 'foundation', 'experimentalist', 'demonstrate', 'dozen', 'proofofprinciple', 'example', 'qec', 'experiment', 'still', 'reach', 'level', 'quality', 'sophistication', 'need', 'reduce', 'overall', 'error', 'rate', 'system']"
"
        Lotfi Zadeh and the Birth of Fuzzy Logic
    ",https://spectrum.ieee.org/lotfi-zadeh,2022-07-09,"The inventor told us how he endured decades of opposition The denunciations were sometimes extreme. “Fuzzy theory is wrong, wrong, and pernicious,” said William Kahan, a highly regarded professor of computer sciences and mathematics at the University of California at Berkeley in 1975. “The danger of fuzzy theory is that it will encourage the sort of imprecise thinking that has brought us so much trouble.” Another berated the theory’s scientific laxity. “No doubt professor Zadeh’s enthusiasm for fuzziness has been reinforced by the prevailing political climate in the United States—one of unprecedented permissiveness,” said R. E. Kalman in 1972, who is now a professor at Florida State University in Tallahassee. “Fuzzification is a kind of scientific permissiveness, it tends to result in socially appealing slogans unaccompanied by the discipline of hard scientific work.” This article was first published as “Lotfi A. Zadeh.” It appeared in the June 1995 issue of IEEE Spectrum. A PDF version is available on IEEE Xplore. The photographs appeared in the original print version.  A multitude of other outspoken critics also disputed the theory of fuzzy logic, developed by Lotfi A. Zadeh in the mid-1960s. Some 20 years were to pass before the theory became widely accepted—capped by this year’s award of the IEEE Medal of Honor to Zadeh “for pioneering development of fuzzy logic and its many diverse applications.” Even today some critics remain. But Zadeh never wavered. He had found himself alone in his scientific opinions on several earlier occasions. “There is a picture of me in my study, taken when I was a student at the University of Tehran,” Zadeh told IEEE Spectrum. “I sit at a table, and above the table is a sign in Russian. ODIN, which means ‘alone.’ It was a proclamation of my independence.” Perhaps the confidence Zadeh had in his judgment despite some tough opposition, and his willingness to stand apart from the crowd, originated in a childhood of privilege. He was born in 1921 in Azerbaijan, then part of the Soviet Union, and moved to Iran at age 10. His parents—his father a businessman and newspaper correspondent, his mother a doctor—were comfortably well off. As a child, Zadeh was surrounded by governesses and tutors, while as a young adult, he had a personal servant. His career goal, for as long as he can remember, was to be an engineering professor. He never considered going into industry, he said, because money was no problem. Rather, he thought of scientific and engineering research as a type of religion, practiced at universities. Zadeh received an electrical engineering degree from the University of Tehran in 1942. But instead of taking the comfortable route—becoming a professor in Iran—he emigrated to the United States. “I could have stayed in Iran and become rich, but I felt that I could not do real scientific work there,” he told Spectrum. “Research in Iran was nonexistent.” Name Lotfi A. Zadeh Date of Birth Feb. 4, 1921 Birthplace Baku, Azerbaijan Height 178 cm Family Wife, Fay; children, Stella and Norman Education BSEE, University of Tehran, 1942; MSEE, Massachusetts Institute of Technology, 1946; PhD, Columbia University, 1949 First job Design and analysis of defense systems, International Electronics Corp., New York City, summer of 1944 Patents One U.S. patent, two Iranian patents. Favorite books “I made a conscious decision to stop reading fiction at age 15, when I was a voracious reader. I now read scientific books and other nonfiction only.” Favorite periodicals Four newspapers daily (The New York Times, San Francisco Chronicle, San Francisco Examiner, The Wall St. Journal or San Jose Mercury News), Business Week, The Economist Favorite kind of music Classical and electronic Favorite composers Sergey Prokofiev, Dimitry Shostakovich Computer A Hewlett-Packard workstation, which is used “only to print my e-mail; I dictate all my answers to my secretary.” Favorite television show “MacNeil/Lehrer Newshour” Least favorite food Any kind of shellfish Favorite restaurant Three Cs Café, an inexpensive crêperie in Berkeley, Calif. Favorite expression “No matter what you are told, take it as a compliment.” Favorite city Berkeley, Calif. Leisure activities Portrait photography (has photographed U.S. Presidents Richard Nixon and Harry Truman, as well as other notables), high-fidelity audio, garage sales Car Nissan Quest Minivan Languages spoken English, Russian, Iranian, French Airline mileage Two million miles in past 10 years on American and United Airlines alone, uncounted mileage on other airlines Key organizational memberships The IEEE, Association for Computing Machinery, International Fuzzy Systems Association, American Association for Artificial Intelligence Top awards The IEEE Medal of Honor (1995) and the Japan Honda Prize (1989) 
	After graduation, Zadeh had a business association with the US. Army Persian Gulf Command. That enabled him to be financially independent when he came to the United States to enroll in graduate school at the Massachusetts Institute of Technology (MIT) in Cambridge. “MIT didn’t have many graduate students at the time,” Zadeh recalled, “so it was fairly easy to get in, even though the University of Teheran had no track record.”
 
	“No doubt professor Zadeh’s enthusiasm for fuzziness has been reinforced by the prevailing political climate in the United States—one of unprecedented permissiveness,"" said R. E. Kalman in 1972
 
	MIT, it turned out, was an easy ride after the demanding course work Zadeh had faced in Tehran.
 
	His choice of subject for his master’s thesis, though, marked one of the first times he would sail against the prevailing technical winds. He chose to study helical antennas, a subject deemed unreasonable by the professor who had taught him antenna theory. Undaunted, Zadeh found another professor to supervise his work.
 
	“I felt that my judgment was correct, and the judgment of people who supposedly knew much more about the subject than I did was not correct,” Zadeh said. “This was one of many such situations. Helical antennas came into wide use in the ‘40s and OS, and my judgment was vindicated.”
 
	By the time Zadeh received his master’s degree in 1946, his parents had moved from Tehran to New York City. So instead of continuing at MIT, he searched out a post as an instructor at New York City’s Columbia University and began his Ph.D. studies there. His thesis on the frequency analysis of time-varying networks considered ways of analyzing systems that change in time.
 
	“It was not a breakthrough,” he recalled, “but it did make an impact and opened a certain direction in its field.”
 
	What he views as his first technical breakthrough came in 1950, when, as an assistant professor at Columbia, he coauthored a paper with his doctoral thesis advisor, John R. Ragazzini, on “An extension of Wiener’s theory of prediction.” This analysis of prediction of time series is often cited as an early classic in its field. This thesis introduced the use of a finite, rather than an infinite, preceding time interval of observation for subsequent smoothing and prediction in the presence of multiple signals and noises. This, and Zadeh’s other work while he was at Columbia, made him a well-known figure in the analysis of analog systems.
 
	As Zadeh was pretty much entrenched at Columbia, he surprised his colleagues when he packed up in 1959 and moved to the University of California at Berkeley.
 
	“I had not been looking for another position,” Zadeh said, “so the offer from Berkeley was unexpected.’’ It came from electrical engineering department chairman John Whinnery, who called him at home over the weekend and offered him a position. “If my line had been busy, I believe l would still be at Columbia,” Zadeh told Spectrum.
 
	Whinnery recalls it slightly differently. He had heard from a colleague that Zadeh had been toying with the idea of leaving Columbia. Minutes later, Whinnery picked up the phone and called him, arranged to meet him in New York City for dinner, and soon afterward hired him. Berkeley was then growing rapidly, and Whinnery was on the lookout for young scholars who were considered brilliant in their fields. Zadeh fit the bill.
 
	For Zadeh, moving to Berkeley was a simple decision to make: “I was happy at Columbia, but the job was too soft. It was a comfortable, undemanding environment; I was not challenged internally. I realized that at Berkeley my life would not be anywhere near as comfortable, but I felt that it would be good for me to be challenged.” Zadeh has never regretted the decision. To this day he remains at Berkeley, although by now as professor emeritus.
 
	A number of departmental colleagues felt that the trend toward computer science was a fad.
 
	At Berkeley, Zadeh initially continued his work in linear, nonlinear, and finite state systems analysis. But before long he became convinced that digital systems would grow in importance. Appointed as chairman of the electrical engineering department, he decided to act on that conviction, and immediately set about strengthening the role of computer science in the department’s curriculum. He also lobbied the electrical engineering community nationwide to recognize the importance of computer science.
 
	Once again, he found himself fighting conventional wisdom. A number of departmental colleagues felt that the trend toward computer science was a fad, and that computer science should not be assigned a high departmental priority. ‘They accused me of being an Yves St. Laurent,” Zadeh recalled, “a follower of fads.” Elsewhere, professors in the mathematics department, along with the head of the computer center, were lobbying to set up their own computer science department.
 
	Zadeh fought this battle as he has fought others, with polite persistence, his former chairman recollected. “We had many differences of opinion when he was chairman,” Whinnery said. “When he couldn’t convince people, he would get upset, but [even now] you can only tell this by the expression on his face. He doesn’t yell or scream. Then he goes ahead and does what he was going to do anyway. And mostly he’s been right, particularly about the importance of computers in electrical engineering.”
 
	Said Earl Cox, chief executive officer of the Metus Systems Group, Chappaqua, N.Y., who has known Zadeh since the ’70s: “I’ve never seen him anger anybody, even though he prides himself in going his own way, in thinking his own thoughts.” (Zadeh is also known for encouraging others to be independent. He insists his graduate students publish in their own name, noted former student Chin L. Chang, who is now president of Nicesoft Corp., Austin, Texas. That practice goes against custom.)
 
	Zadeh finally got his way in 1967: the name of the department was changed to electrical engineering and computer science (EECS). A separate computer science department was also established in Berkeley’s College of Letters, but after a few years it folded and became absorbed into EECS.
 
	While he was focusing on systems analysis, in the early 1960s, Zadeh began to feel that traditional systems analysis techniques were too precise for real-world problems. In a paper written in 1961, he mentioned that a new technique was needed, a “fuzzy” kind of mathematics. At the time, though, he had no clear idea how this would work.
 
	That idea came in July 1964. Zadeh was in New York City visiting his parents and planned to leave soon for Southern California, where he would spend several weeks at Rand Corp working on pattern recognition problems. With this upcoming work on his mind, his thoughts often turned to the use of imprecise categories for classification.
 
	“One night in New York,” Zadeh recalled, “I had a dinner engagement with some friends It was canceled, and I spent the evening by myself in my parents’ apartment 1 remember distinctly that the idea occurred to me then to introduce the concept of grade of membership [concepts that became the backbone of fuzzy set theory]. So it is quite possible that if that dinner engagement had not been canceled, the idea would not have occurred to me.”
 
	Fuzzy technology, Zadeh explained, is a means of computing with words—bigger, smaller, taller, shorter. For example, small can be multiplied by a few and added to large, or colder can be added to warmer to get something in between.
 Zadeh published his first fuzzy paper in 1965, convinced that he was onto something important, but wrote only sparingly on the topic until after he left Berkeley’s electrical engineering department chairmanship in 1968. Since then, fuzzy sets have been his full-time occupation. 
	Once the issue of classification had been solved, Zadeh could develop the theory of fuzzy sets quickly. Two weeks later he had a fairly fleshed-out group of concepts to present to his collaborator at Rand, Richard Bellman. “His response was enthusiastic,” Zadeh said, “and that was a source of encouragement to me-though had he been very critical, I wouldn’t have changed my mind.”
 
	Since he was Berkeley’s electrical engineering department chairman at the time and engaged in his struggle over the place of computer science at the university, Zadeh had little time to work on his new theory of fuzzy sets. He published his first paper in 1965, convinced that he was onto something important, but wrote only sparingly on the topic until after he left the department chairmanship in 1968. Since then, fuzzy sets have been his full-time occupation.
 
	“I continue to be an active player,” he said. “I am not merely an elder statesman who rests on his laurels. I give many talks, and this puts me under pressure. I must constantly think of new ideas to talk about and keep up with what others are doing.”
 
	Acceptance of fuzzy set theory by the technical community was slow in coming. Part of the problem was the name—“fuzzy” is hardly proper terminology. And Zadeh knew it.
 
	“I was cognizant of the fact that it would be controversial, but I could not think of any other, respectable term to describe what I had in mind, which was classes that do not have sharp boundaries, like clouds,” he said. “So I decided to do what I thought was right, regardless of how it might be perceived. And I’ve never regretted the name. I think it is better to be visible and provocative than to be bland.”
 
	And, as expected, fuzzy theory did cause controversy. Some people rejected it outright because of the name, without knowing the content. Others rejected it because of the theory’s focus on imprecision.
 
	 “I’ve never regretted the name. I think it is better to be visible and provocative than to be bland.”
	
	—Lotfi Zadeh
 
	In the late 1960s, it even garnered the passing attention of Congress as a prime example of the waste of government funds (much of Zadeh’s research was being funded by the 
	National Science Foundation). Former Senator William Proxmire (D-Wis.), the force behind the Golden Fleece Awards that honored such government boondoggles as $600 toilet seats, sent a letter to the foundation suggesting that such “fuzzy” garbage they were supporting should earn a Golden Fleece nomination. A flurry of correspondence from Zadeh and the foundation emerged in defense of the work.
 
	Zadeh remembers the challenge of developing his theories “in the face of opposition, even hostility. Someone with a thinner skin would have been traumatized,” he said.
 
	And Cox remarked, “He meets people who have written some really nasty things, and he’s nice to them.”
 
	But, observed Berkeley’s Whinnery, “I do think this lack of acceptance bothered him, although he now describes it with some humor.”
 
	Eventually, fuzzy theory was taken seriously—by the Japanese.
 
	Eventually, fuzzy theory was taken seriously—by the Japanese. And their implementations of it surprised even Zadeh.
 
	He at first had expected fuzzy sets to apply to fields in which conventional analytic techniques had been ineffectual, for work outside of the hard sciences, for work in philosophy, psychology, linguistics, biology, and so on. He also thought that the theory might apply to control systems, in engine control, for example. But he never expected it to be used in consumer products, which today is perhaps its biggest application, thanks to Japanese electronics companies.
 Matsushita Electric Industrial Co. was the first to apply fuzzy theory to a consumer product, a shower head that controlled water temperature, in 1987. Now numerous Japanese consumer products—dishwashers, washing machines, air conditioners, microwave ovens, cameras, camcorders, television sets, copiers, and even automobiles—quietly apply fuzzy technology.
 
	These products make use of fuzzy logic combined with sensors to simplify control. For example, cameras have several focusing spots and use fuzzy’s IF-THEN rules to calculate the optimal focus; camcorders use fuzzy logic for image stabilization; and washing machines use sensors to detect how dirty the water is and how quickly it is clearing to determine the length of wash cycles.
 
	The introduction of fuzzy products by the Japanese riveted press attention on this apparently “new” technology (some two decades after Zadeh had developed the theory). Growing acknowledgment of the theory by his colleagues followed, although some still reject it.
 
	Acceptance, colleagues say, has somewhat changed Zadeh. “Since fuzzy logic has turned into something with so much panache, and he has finally come into his own after being ignored for so many years, I think Lotfi has come out of his shell,” said Cox.
 
	“Had I not launched that theory, I would fall into the same category as many professors—be reasonably well known… but not have made a long-lasting impact.”
	
	—Lotfi Zadeh
 
	To date, hundreds of books have been published on the topic, and some 15 000 technical papers have been written (most, it seems, piled around his office, where stacks of papers leave only a narrow path from the door to his desk). Zadeh is now known as the Father of Fuzzy.
 
	“Had I not launched that theory,” said Zadeh, “I would fall into the same category as many professors—be reasonably well known, have attained a certain level of recognition, and written some books and papers, but not have made a long-lasting impact. So I consider myself to have been lucky that this thing came about.”
 
	“The important criterion of your impact is: has what you have done generated a following? With fuzzy sets, I can definitely say, ‘Yes.’”
	 Editor’s note: Lotfi Zadeh died in 2017 at the age of 96. Tekla S. Perry is a senior editor at IEEE Spectrum. Based in Palo Alto, Calif., she's been covering the people, companies, and technology that make Silicon Valley a special place for more than 40 years. An IEEE member, she holds a bachelor's degree in journalism from Michigan State University.
 ...Or did the metaverse just turn a shade more uncannily creepy?  Matthew S. Smith writes IEEE Spectrum's Gizmo column and is a freelance consumer-tech journalist. An avid gamer, he is a former staff editor at Digital Trends and is particularly fond of wearables, e-bikes, all things smartphone, and CES, which he has attended every year since 2009.
 Mesh to MetaHuman lets creators import a facial mesh to create a photorealistic 3D character. Creating your virtual clone isn’t as difficult as you’d think. Epic Games recently introduced Mesh to MetaHuman, a framework for creating photorealistic human characters. It lets creators sculpt an imported mesh to create a convincing character in less than an hour. “It’s incredibly simple compared to a lot of other tools,” says Stu Richards (a.k.a. Meta Mike), partner success lead at GigLabs and Cofounder of Versed. “I’d compare it to a character creator in a game.”                       This e-nose can detect glucose levels with 90 percent accuracy  Michelle Hampson is a freelance writer based in Halifax. She frequently contributes to Spectrum's Journal Watch coverage, which highlights newsworthy studies published in IEEE journals.
  This article is part of our exclusive IEEE Journal Watch series in partnership with IEEE Xplore.         ","The inventor told us how he endured decades of opposition The denunciations were sometimes extreme. “Fuzzy theory is wrong, wrong, and pernicious,” said William Kahan, a highly regarded professor of computer sciences and mathematics at the University of California at Berkeley in 1975. “The danger of fuzzy theory is that it will encourage the sort of imprecise thinking that has brought us so much trouble.” Another berated the theory’s scientific laxity. “No doubt professor Zadeh’s enthusiasm for fuzziness has been reinforced by the prevailing political climate in the United States—one of unprecedented permissiveness,” said R. E. Kalman in 1972, who is now a professor at Florida State University in Tallahassee. “Fuzzification is a kind of scientific permissiveness, it tends to result in socially appealing slogans unaccompanied by the discipline of hard scientific work.” This article was first published as “Lotfi A. Zadeh.” It appeared in the June 1995 issue of IEEE Spectrum. A PDF version is available on IEEE Xplore. The photographs appeared in the original print version. A multitude of other outspoken critics also disputed the theory of fuzzy logic, developed by Lotfi A. Zadeh in the mid-1960s. Some 20 years were to pass before the theory became widely accepted—capped by this year’s award of the IEEE Medal of Honor to Zadeh “for pioneering development of fuzzy logic and its many diverse applications.” Even today some critics remain. But Zadeh never wavered. He had found himself alone in his scientific opinions on several earlier occasions. “There is a picture of me in my study, taken when I was a student at the University of Tehran,” Zadeh told IEEE Spectrum. “I sit at a table, and above the table is a sign in Russian. ODIN, which means ‘alone.’ It was a proclamation of my independence.” Perhaps the confidence Zadeh had in his judgment despite some tough opposition, and his willingness to stand apart from the crowd, originated in a childhood of privilege. He was born in 1921 in Azerbaijan, then part of the Soviet Union, and moved to Iran at age 10. His parents—his father a businessman and newspaper correspondent, his mother a doctor—were comfortably well off. As a child, Zadeh was surrounded by governesses and tutors, while as a young adult, he had a personal servant. His career goal, for as long as he can remember, was to be an engineering professor. He never considered going into industry, he said, because money was no problem. Rather, he thought of scientific and engineering research as a type of religion, practiced at universities. Zadeh received an electrical engineering degree from the University of Tehran in 1942. But instead of taking the comfortable route—becoming a professor in Iran—he emigrated to the United States. “I could have stayed in Iran and become rich, but I felt that I could not do real scientific work there,” he told Spectrum. “Research in Iran was nonexistent.” Name Lotfi A. Zadeh Date of Birth Feb. 4, 1921 Birthplace Baku, Azerbaijan Height 178 cm Family Wife, Fay; children, Stella and Norman Education BSEE, University of Tehran, 1942; MSEE, Massachusetts Institute of Technology, 1946; PhD, Columbia University, 1949 First job Design and analysis of defense systems, International Electronics Corp., New York City, summer of 1944 Patents One U.S. patent, two Iranian patents. Favorite books “I made a conscious decision to stop reading fiction at age 15, when I was a voracious reader. I now read scientific books and other nonfiction only.” Favorite periodicals Four newspapers daily (The New York Times, San Francisco Chronicle, San Francisco Examiner, The Wall St. Journal or San Jose Mercury News), Business Week, The Economist Favorite kind of music Classical and electronic Favorite composers Sergey Prokofiev, Dimitry Shostakovich Computer A Hewlett-Packard workstation, which is used “only to print my e-mail; I dictate all my answers to my secretary.” Favorite television show “MacNeil/Lehrer Newshour” Least favorite food Any kind of shellfish Favorite restaurant Three Cs Café, an inexpensive crêperie in Berkeley, Calif. Favorite expression “No matter what you are told, take it as a compliment.” Favorite city Berkeley, Calif. Leisure activities Portrait photography (has photographed U.S. Presidents Richard Nixon and Harry Truman, as well as other notables), high-fidelity audio, garage sales Car Nissan Quest Minivan Languages spoken English, Russian, Iranian, French Airline mileage Two million miles in past 10 years on American and United Airlines alone, uncounted mileage on other airlines Key organizational memberships The IEEE, Association for Computing Machinery, International Fuzzy Systems Association, American Association for Artificial Intelligence Top awards The IEEE Medal of Honor (1995) and the Japan Honda Prize (1989) After graduation, Zadeh had a business association with the US. Army Persian Gulf Command. That enabled him to be financially independent when he came to the United States to enroll in graduate school at the Massachusetts Institute of Technology (MIT) in Cambridge. “MIT didn’t have many graduate students at the time,” Zadeh recalled, “so it was fairly easy to get in, even though the University of Teheran had no track record.” “No doubt professor Zadeh’s enthusiasm for fuzziness has been reinforced by the prevailing political climate in the United States—one of unprecedented permissiveness,"" said R. E. Kalman in 1972 MIT, it turned out, was an easy ride after the demanding course work Zadeh had faced in Tehran. His choice of subject for his master’s thesis, though, marked one of the first times he would sail against the prevailing technical winds. He chose to study helical antennas, a subject deemed unreasonable by the professor who had taught him antenna theory. Undaunted, Zadeh found another professor to supervise his work. “I felt that my judgment was correct, and the judgment of people who supposedly knew much more about the subject than I did was not correct,” Zadeh said. “This was one of many such situations. Helical antennas came into wide use in the ‘40s and OS, and my judgment was vindicated.” By the time Zadeh received his master’s degree in 1946, his parents had moved from Tehran to New York City. So instead of continuing at MIT, he searched out a post as an instructor at New York City’s Columbia University and began his Ph.D. studies there. His thesis on the frequency analysis of time-varying networks considered ways of analyzing systems that change in time. “It was not a breakthrough,” he recalled, “but it did make an impact and opened a certain direction in its field.” What he views as his first technical breakthrough came in 1950, when, as an assistant professor at Columbia, he coauthored a paper with his doctoral thesis advisor, John R. Ragazzini, on “An extension of Wiener’s theory of prediction.” This analysis of prediction of time series is often cited as an early classic in its field. This thesis introduced the use of a finite, rather than an infinite, preceding time interval of observation for subsequent smoothing and prediction in the presence of multiple signals and noises. This, and Zadeh’s other work while he was at Columbia, made him a well-known figure in the analysis of analog systems. As Zadeh was pretty much entrenched at Columbia, he surprised his colleagues when he packed up in 1959 and moved to the University of California at Berkeley. “I had not been looking for another position,” Zadeh said, “so the offer from Berkeley was unexpected.’’ It came from electrical engineering department chairman John Whinnery, who called him at home over the weekend and offered him a position. “If my line had been busy, I believe l would still be at Columbia,” Zadeh told Spectrum. Whinnery recalls it slightly differently. He had heard from a colleague that Zadeh had been toying with the idea of leaving Columbia. Minutes later, Whinnery picked up the phone and called him, arranged to meet him in New York City for dinner, and soon afterward hired him. Berkeley was then growing rapidly, and Whinnery was on the lookout for young scholars who were considered brilliant in their fields. Zadeh fit the bill. For Zadeh, moving to Berkeley was a simple decision to make: “I was happy at Columbia, but the job was too soft. It was a comfortable, undemanding environment; I was not challenged internally. I realized that at Berkeley my life would not be anywhere near as comfortable, but I felt that it would be good for me to be challenged.” Zadeh has never regretted the decision. To this day he remains at Berkeley, although by now as professor emeritus. A number of departmental colleagues felt that the trend toward computer science was a fad. At Berkeley, Zadeh initially continued his work in linear, nonlinear, and finite state systems analysis. But before long he became convinced that digital systems would grow in importance. Appointed as chairman of the electrical engineering department, he decided to act on that conviction, and immediately set about strengthening the role of computer science in the department’s curriculum. He also lobbied the electrical engineering community nationwide to recognize the importance of computer science. Once again, he found himself fighting conventional wisdom. A number of departmental colleagues felt that the trend toward computer science was a fad, and that computer science should not be assigned a high departmental priority. ‘They accused me of being an Yves St. Laurent,” Zadeh recalled, “a follower of fads.” Elsewhere, professors in the mathematics department, along with the head of the computer center, were lobbying to set up their own computer science department. Zadeh fought this battle as he has fought others, with polite persistence, his former chairman recollected. “We had many differences of opinion when he was chairman,” Whinnery said. “When he couldn’t convince people, he would get upset, but [even now] you can only tell this by the expression on his face. He doesn’t yell or scream. Then he goes ahead and does what he was going to do anyway. And mostly he’s been right, particularly about the importance of computers in electrical engineering.” Said Earl Cox, chief executive officer of the Metus Systems Group, Chappaqua, N.Y., who has known Zadeh since the ’70s: “I’ve never seen him anger anybody, even though he prides himself in going his own way, in thinking his own thoughts.” (Zadeh is also known for encouraging others to be independent. He insists his graduate students publish in their own name, noted former student Chin L. Chang, who is now president of Nicesoft Corp., Austin, Texas. That practice goes against custom.) Zadeh finally got his way in 1967: the name of the department was changed to electrical engineering and computer science (EECS). A separate computer science department was also established in Berkeley’s College of Letters, but after a few years it folded and became absorbed into EECS. While he was focusing on systems analysis, in the early 1960s, Zadeh began to feel that traditional systems analysis techniques were too precise for real-world problems. In a paper written in 1961, he mentioned that a new technique was needed, a “fuzzy” kind of mathematics. At the time, though, he had no clear idea how this would work. That idea came in July 1964. Zadeh was in New York City visiting his parents and planned to leave soon for Southern California, where he would spend several weeks at Rand Corp working on pattern recognition problems. With this upcoming work on his mind, his thoughts often turned to the use of imprecise categories for classification. “One night in New York,” Zadeh recalled, “I had a dinner engagement with some friends It was canceled, and I spent the evening by myself in my parents’ apartment 1 remember distinctly that the idea occurred to me then to introduce the concept of grade of membership [concepts that became the backbone of fuzzy set theory]. So it is quite possible that if that dinner engagement had not been canceled, the idea would not have occurred to me.” Fuzzy technology, Zadeh explained, is a means of computing with words—bigger, smaller, taller, shorter. For example, small can be multiplied by a few and added to large, or colder can be added to warmer to get something in between. Zadeh published his first fuzzy paper in 1965, convinced that he was onto something important, but wrote only sparingly on the topic until after he left Berkeley’s electrical engineering department chairmanship in 1968. Since then, fuzzy sets have been his full-time occupation. Once the issue of classification had been solved, Zadeh could develop the theory of fuzzy sets quickly. Two weeks later he had a fairly fleshed-out group of concepts to present to his collaborator at Rand, Richard Bellman. “His response was enthusiastic,” Zadeh said, “and that was a source of encouragement to me-though had he been very critical, I wouldn’t have changed my mind.” Since he was Berkeley’s electrical engineering department chairman at the time and engaged in his struggle over the place of computer science at the university, Zadeh had little time to work on his new theory of fuzzy sets. He published his first paper in 1965, convinced that he was onto something important, but wrote only sparingly on the topic until after he left the department chairmanship in 1968. Since then, fuzzy sets have been his full-time occupation. “I continue to be an active player,” he said. “I am not merely an elder statesman who rests on his laurels. I give many talks, and this puts me under pressure. I must constantly think of new ideas to talk about and keep up with what others are doing.” Acceptance of fuzzy set theory by the technical community was slow in coming. Part of the problem was the name—“fuzzy” is hardly proper terminology. And Zadeh knew it. “I was cognizant of the fact that it would be controversial, but I could not think of any other, respectable term to describe what I had in mind, which was classes that do not have sharp boundaries, like clouds,” he said. “So I decided to do what I thought was right, regardless of how it might be perceived. And I’ve never regretted the name. I think it is better to be visible and provocative than to be bland.” And, as expected, fuzzy theory did cause controversy. Some people rejected it outright because of the name, without knowing the content. Others rejected it because of the theory’s focus on imprecision. “I’ve never regretted the name. I think it is better to be visible and provocative than to be bland.” —Lotfi Zadeh In the late 1960s, it even garnered the passing attention of Congress as a prime example of the waste of government funds (much of Zadeh’s research was being funded by the National Science Foundation). Former Senator William Proxmire (D-Wis.), the force behind the Golden Fleece Awards that honored such government boondoggles as $600 toilet seats, sent a letter to the foundation suggesting that such “fuzzy” garbage they were supporting should earn a Golden Fleece nomination. A flurry of correspondence from Zadeh and the foundation emerged in defense of the work. Zadeh remembers the challenge of developing his theories “in the face of opposition, even hostility. Someone with a thinner skin would have been traumatized,” he said. And Cox remarked, “He meets people who have written some really nasty things, and he’s nice to them.” But, observed Berkeley’s Whinnery, “I do think this lack of acceptance bothered him, although he now describes it with some humor.” Eventually, fuzzy theory was taken seriously—by the Japanese. Eventually, fuzzy theory was taken seriously—by the Japanese. And their implementations of it surprised even Zadeh. He at first had expected fuzzy sets to apply to fields in which conventional analytic techniques had been ineffectual, for work outside of the hard sciences, for work in philosophy, psychology, linguistics, biology, and so on. He also thought that the theory might apply to control systems, in engine control, for example. But he never expected it to be used in consumer products, which today is perhaps its biggest application, thanks to Japanese electronics companies. Matsushita Electric Industrial Co. was the first to apply fuzzy theory to a consumer product, a shower head that controlled water temperature, in 1987. Now numerous Japanese consumer products—dishwashers, washing machines, air conditioners, microwave ovens, cameras, camcorders, television sets, copiers, and even automobiles—quietly apply fuzzy technology. These products make use of fuzzy logic combined with sensors to simplify control. For example, cameras have several focusing spots and use fuzzy’s IF-THEN rules to calculate the optimal focus; camcorders use fuzzy logic for image stabilization; and washing machines use sensors to detect how dirty the water is and how quickly it is clearing to determine the length of wash cycles. The introduction of fuzzy products by the Japanese riveted press attention on this apparently “new” technology (some two decades after Zadeh had developed the theory). Growing acknowledgment of the theory by his colleagues followed, although some still reject it. Acceptance, colleagues say, has somewhat changed Zadeh. “Since fuzzy logic has turned into something with so much panache, and he has finally come into his own after being ignored for so many years, I think Lotfi has come out of his shell,” said Cox. “Had I not launched that theory, I would fall into the same category as many professors—be reasonably well known… but not have made a long-lasting impact.” —Lotfi Zadeh To date, hundreds of books have been published on the topic, and some 15 000 technical papers have been written (most, it seems, piled around his office, where stacks of papers leave only a narrow path from the door to his desk). Zadeh is now known as the Father of Fuzzy. “Had I not launched that theory,” said Zadeh, “I would fall into the same category as many professors—be reasonably well known, have attained a certain level of recognition, and written some books and papers, but not have made a long-lasting impact. So I consider myself to have been lucky that this thing came about.” “The important criterion of your impact is: has what you have done generated a following? With fuzzy sets, I can definitely say, ‘Yes.’” Editor’s note: Lotfi Zadeh died in 2017 at the age of 96. Tekla S. Perry is a senior editor at IEEE Spectrum. Based in Palo Alto, Calif., she's been covering the people, companies, and technology that make Silicon Valley a special place for more than 40 years. An IEEE member, she holds a bachelor's degree in journalism from Michigan State University. ...Or did the metaverse just turn a shade more uncannily creepy? Matthew S. Smith writes IEEE Spectrum's Gizmo column and is a freelance consumer-tech journalist. An avid gamer, he is a former staff editor at Digital Trends and is particularly fond of wearables, e-bikes, all things smartphone, and CES, which he has attended every year since 2009. Mesh to MetaHuman lets creators import a facial mesh to create a photorealistic 3D character. Creating your virtual clone isn’t as difficult as you’d think. Epic Games recently introduced Mesh to MetaHuman, a framework for creating photorealistic human characters. It lets creators sculpt an imported mesh to create a convincing character in less than an hour. “It’s incredibly simple compared to a lot of other tools,” says Stu Richards (a.k.a. Meta Mike), partner success lead at GigLabs and Cofounder of Versed. “I’d compare it to a character creator in a game.” This e-nose can detect glucose levels with 90 percent accuracy Michelle Hampson is a freelance writer based in Halifax. She frequently contributes to Spectrum's Journal Watch coverage, which highlights newsworthy studies published in IEEE journals. This article is part of our exclusive IEEE Journal Watch series in partnership with IEEE Xplore.","['inventor', 'tell', 'endure', 'decade', 'opposition', 'denunciation', 'sometimes', 'extreme', 'fuzzy', 'theory', 'wrong', 'wrong', 'pernicious', 'say', 'highly', 'regard', 'professor', 'computer', 'science', 'mathematic', 'danger', 'fuzzy', 'theory', 'encourage', 'sort', 'imprecise', 'thinking', 'bring', 'much', 'trouble', 'berate', 'theory', 'scientific', 'laxity', 'doubt', 'enthusiasm', 'fuzziness', 'reinforce', 'prevail', 'political', 'climate', 'unprecedented', 'permissiveness', 'say', 'r', 'e', 'kalman', 'professor', 'fuzzification', 'kind', 'scientific', 'permissiveness', 'tend', 'result', 'socially', 'appealing', 'slogan', 'unaccompanied', 'discipline', 'hard', 'scientific', 'work', 'article', 'first', 'publish', 'lotfi', 'zadeh', 'appear', 'issue', 'ieee', 'spectrum', 'pdf', 'version', 'available', 'ieee', 'xplore', 'photograph', 'appear', 'original', 'print', 'version', 'multitude', 'outspoken', 'critic', 'also', 'dispute', 'theory', 'fuzzy', 'logic', 'develop', 'lotfi', 'zadeh', 'mid1960', 'year', 'pass', 'theory', 'widely', 'accept', 'cap', 'year', 'award', 'ieee', 'medal', 'honor', 'zadeh', 'pioneer', 'development', 'fuzzy', 'logic', 'many', 'diverse', 'application', 'even', 'today', 'critic', 'remain', 'zadeh', 'never', 'waver', 'find', 'alone', 'scientific', 'opinion', 'several', 'early', 'occasion', 'picture', 'study', 'take', 'student', 'tell', 'ieee', 'spectrum', 'sit', 'table', 'table', 'sign', 'russian', 'odin', 'mean', 'alone', 'proclamation', 'independence', 'perhaps', 'confidence', 'judgment', 'tough', 'opposition', 'willingness', 'stand', 'apart', 'crowd', 'originate', 'childhood', 'privilege', 'bear', 'part', 'move', 'age', 'parent', 'father', 'businessman', 'newspaper', 'correspondent', 'mother', 'doctor', 'comfortably', 'well', 'child', 'zadeh', 'surround', 'governess', 'tutor', 'young', 'adult', 'personal', 'servant', 'career', 'goal', 'long', 'remember', 'engineering', 'professor', 'never', 'consider', 'go', 'industry', 'say', 'money', 'problem', 'rather', 'think', 'scientific', 'engineering', 'research', 'type', 'religion', 'practice', 'university', 'receive', 'electrical', 'engineering', 'degree', 'university', 'tehran', 'instead', 'take', 'comfortable', 'route', 'become', 'professor', 'emigrate', 'stay', 'become', 'rich', 'feel', 'real', 'scientific', 'work', 'tell', 'spectrum', 'research', 'nonexistent', 'name', 'lotfi', 'zadeh', 'date', 'birth', 'birthplace', 'baku', 'family', 'wife', 'child', 'stella', 'norman', 'technology', 'first', 'job', 'design', 'analysis', 'defense', 'summer', 'patent', 'patent', 'iranian', 'patent', 'favorite', 'book', 'make', 'conscious', 'decision', 'stop', 'read', 'fiction', 'age', 'voracious', 'reader', 'read', 'scientific', 'book', 'nonfiction', 'favorite', 'periodical', 'newspaper', 'daily', 'examiner', 'business', 'week', 'economist', 'favorite', 'kind', 'music', 'classical', 'electronic', 'favorite', 'composer', 'sergey', 'prokofiev', 'dimitry', 'computer', 'hewlettpackard', 'workstation', 'use', 'print', 'email', 'dictate', 'answer', 'secretary', 'favorite', 'television', 'show', 'macneillehrer', 'least', 'favorite', 'food', 'kind', 'shellfish', 'favorite', 'restaurant', 'café', 'inexpensive', 'crêperie', 'favorite', 'expression', 'matter', 'tell', 'take', 'compliment', 'favorite', 'city', 'leisure', 'activity', 'portrait', 'photography', 'photograph', 'president', 'well', 'notable', 'audio', 'garage', 'sale', 'car', 'language', 'speak', 'english', 'russian', 'iranian', 'french', 'airline', 'mileage', 'mile', 'past', 'year', 'alone', 'uncounte', 'mileage', 'airline', 'key', 'organizational', 'membership', 'ieee', 'association', 'compute', 'machinery', 'international', 'artificial', 'intelligence', 'top', 'award', 'ieee', 'medal', 'honor', 'graduation', 'business', 'association', 'enable', 'financially', 'independent', 'come', 'enroll', 'graduate', 'school', 'mit', 'mit', 'many', 'graduate', 'student', 'time', 'recall', 'fairly', 'easy', 'get', 'even', 'university', 'teheran', 'track', 'record', 'doubt', 'enthusiasm', 'fuzziness', 'reinforce', 'prevail', 'political', 'climate', 'unprecedented', 'permissiveness', 'say', 'r', 'e', 'kalman', 'mit', 'turn', 'easy', 'ride', 'demanding', 'course', 'work', 'face', 'tehran', 'choice', 'subject', 'master', 'thesis', 'mark', 'first', 'time', 'sail', 'prevail', 'technical', 'wind', 'choose', 'study', 'helical', 'antenna', 'subject', 'deem', 'unreasonable', 'professor', 'teach', 'antenna', 'theory', 'find', 'professor', 'supervise', 'work', 'feel', 'judgment', 'correct', 'judgment', 'people', 'supposedly', 'know', 'much', 'subject', 'correct', 'say', 'many', 'situation', 'helical', 'antenna', 'come', 'wide', 'use', '40', 'os', 'judgment', 'vindicate', 'time', 'receive', 'master', 'degree', 'parent', 'move', 'tehran', 'instead', 'continue', 'mit', 'search', 'post', 'instructor', 'begin', 'phd', 'study', 'thesis', 'frequency', 'analysis', 'timevarying', 'network', 'consider', 'way', 'analyze', 'system', 'change', 'time', 'breakthrough', 'recall', 'make', 'impact', 'open', 'certain', 'direction', 'field', 'view', 'first', 'technical', 'breakthrough', 'come', 'assistant', 'professor', 'coauthore', 'paper', 'doctoral', 'ragazzini', 'extension', 'theory', 'prediction', 'analysis', 'prediction', 'time', 'series', 'often', 'cite', 'early', 'classic', 'field', 'thesis', 'introduce', 'use', 'finite', 'rather', 'infinite', 'precede', 'time', 'interval', 'observation', 'subsequent', 'smoothing', 'prediction', 'presence', 'multiple', 'signal', 'noise', 'work', 'make', 'wellknown', 'figure', 'analysis', 'analog', 'system', 'pretty', 'much', 'entrench', 'surprise', 'colleague', 'pack', 'move', 'look', 'position', 'zadeh', 'say', 'offer', 'unexpected', 'come', 'electrical', 'engineering', 'chairman', 'call', 'home', 'weekend', 'offer', 'position', 'line', 'busy', 'believe', 'still', 'tell', 'spectrum', 'whinnery', 'recall', 'slightly', 'differently', 'hear', 'colleague', 'toy', 'idea', 'leave', 'minute', 'later', 'whinnery', 'pick', 'phone', 'call', 'arrange', 'meet', 'dinner', 'soon', 'afterward', 'hire', 'grow', 'rapidly', 'whinnery', 'lookout', 'young', 'scholar', 'consider', 'brilliant', 'field', 'zadeh', 'fit', 'bill', 'move', 'simple', 'decision', 'make', 'happy', 'job', 'soft', 'comfortable', 'undemande', 'environment', 'challenge', 'internally', 'realize', 'life', 'anywhere', 'near', 'comfortable', 'feel', 'good', 'challenge', 'zadeh', 'never', 'regret', 'decision', 'day', 'remain', 'professor', 'emeritus', 'number', 'departmental', 'colleague', 'feel', 'trend', 'computer', 'science', 'fad', 'initially', 'continue', 'work', 'linear', 'finite', 'state', 'system', 'analysis', 'long', 'become', 'convinced', 'digital', 'system', 'grow', 'importance', 'appoint', 'chairman', 'electrical', 'engineering', 'department', 'decide', 'act', 'conviction', 'immediately', 'set', 'strengthen', 'role', 'computer', 'science', 'department', 'curriculum', 'also', 'lobby', 'electrical', 'engineering', 'community', 'nationwide', 'recognize', 'importance', 'computer', 'science', 'find', 'fight', 'conventional', 'wisdom', 'number', 'departmental', 'colleague', 'feel', 'trend', 'computer', 'science', 'fad', 'computer', 'science', 'assign', 'high', 'departmental', 'priority', 'accuse', 'yve', 'laurent', 'recall', 'follower', 'fad', 'professor', 'head', 'computer', 'center', 'lobby', 'set', 'computer', 'science', 'fight', 'battle', 'fight', 'polite', 'persistence', 'former', 'chairman', 'recollect', 'many', 'difference', 'opinion', 'chairman', 'say', 'convince', 'people', 'get', 'upset', 'even', 'tell', 'expression', 'face', 'yell', 'scream', 'go', 'ahead', 'go', 'anyway', 'mostly', 'right', 'particularly', 'importance', 'computer', 'electrical', 'engineering', 'say', 'chief', 'executive', 'officer', 'system', 'group', 'know', 'zadeh', '’', '70', 'never', 'see', 'anger', 'even', 'pride', 'go', 'way', 'think', 'thought', 'also', 'know', 'encourage', 'independent', 'insist', 'graduate', 'student', 'publish', 'name', 'note', 'former', 'student', 'president', 'practice', 'go', 'custom', 'finally', 'get', 'way', 'name', 'department', 'change', 'electrical', 'engineering', 'computer', 'science', 'eec', 'separate', 'computer', 'science', 'department', 'also', 'establish', 'college', 'letter', 'year', 'fold', 'absorb', 'eec', 'focus', 'system', 'analysis', 'early', '1960', 'zadeh', 'begin', 'feel', 'traditional', 'system', 'analysis', 'technique', 'precise', 'realworld', 'problem', 'paper', 'write', 'mention', 'new', 'technique', 'need', 'fuzzy', 'kind', 'mathematic', 'time', 'clear', 'idea', 'work', 'idea', 'come', 'zadeh', 'visit', 'parent', 'plan', 'leave', 'soon', 'southern', 'spend', 'several', 'week', 'work', 'pattern', 'recognition', 'problem', 'upcoming', 'work', 'mind', 'thought', 'often', 'turn', 'use', 'imprecise', 'category', 'classification', 'night', 'recall', 'dinner', 'engagement', 'friend', 'cancel', 'spend', 'evening', 'parent', 'apartment', 'remember', 'distinctly', 'idea', 'occur', 'introduce', 'concept', 'grade', 'membership', 'concept', 'become', 'backbone', 'fuzzy', 'set', 'theory', 'quite', 'possible', 'dinner', 'engagement', 'cancel', 'idea', 'occur', 'fuzzy', 'technology', 'explain', 'means', 'compute', 'word', 'big', 'small', 'tall', 'short', 'example', 'small', 'multiply', 'add', 'large', 'cold', 'add', 'warm', 'get', 'zadeh', 'publish', 'first', 'fuzzy', 'paper', 'convince', 'important', 'write', 'sparingly', 'topic', 'leave', 'electrical', 'engineering', 'department', 'chairmanship', 'fuzzy', 'set', 'fulltime', 'occupation', 'issue', 'classification', 'solve', 'zadeh', 'develop', 'theory', 'fuzzy', 'set', 'quickly', 'week', 'later', 'fairly', 'fleshedout', 'group', 'concept', 'present', 'collaborator', 'response', 'enthusiastic', 'say', 'source', 'encouragement', 'methough', 'critical', 'change', 'mind', 'electrical', 'engineering', 'department', 'chairman', 'time', 'engage', 'struggle', 'place', 'computer', 'science', 'university', 'zadeh', 'little', 'time', 'work', 'new', 'theory', 'fuzzy', 'set', 'publish', 'first', 'paper', 'convince', 'important', 'write', 'sparingly', 'topic', 'leave', 'department', 'chairmanship', 'fuzzy', 'set', 'fulltime', 'occupation', 'continue', 'active', 'player', 'say', 'merely', 'eld', 'statesman', 'rest', 'laurel', 'give', 'many', 'talk', 'put', 'pressure', 'constantly', 'think', 'new', 'idea', 'talk', 'keep', 'acceptance', 'fuzzy', 'set', 'theory', 'technical', 'community', 'slow', 'come', 'part', 'problem', 'name', 'fuzzy', 'hardly', 'proper', 'terminology', 'know', 'cognizant', 'fact', 'controversial', 'think', 'respectable', 'term', 'describe', 'mind', 'class', 'sharp', 'boundary', 'cloud', 'say', 'decide', 'think', 'right', 'regardless', 'perceive', 'never', 'regret', 'name', 'think', 'well', 'visible', 'provocative', 'bland', 'expect', 'fuzzy', 'theory', 'cause', 'controversy', 'people', 'reject', 'outright', 'name', 'know', 'content', 'reject', 'theory', 'focus', 'imprecision', 'never', 'regret', 'name', 'think', 'well', 'visible', 'provocative', 'bland', 'lotfi', 'zadeh', 'late', '1960', 'even', 'garner', 'pass', 'attention', 'prime', 'example', 'waste', 'government', 'fund', 'much', 'research', 'fund', 'national', 'science', 'former', 'dwis', 'force', 'golden', 'fleece', 'award', 'honor', 'government', 'boondoggle', 'toilet', 'seat', 'send', 'letter', 'foundation', 'suggest', 'fuzzy', 'garbage', 'support', 'earn', 'golden', 'fleece', 'nomination', 'flurry', 'correspondence', 'foundation', 'emerge', 'defense', 'work', 'remember', 'challenge', 'develop', 'theory', 'face', 'opposition', 'even', 'hostility', 'thin', 'skin', 'traumatize', 'say', 'remark', 'meet', 'people', 'write', 'really', 'nasty', 'thing', '’', 'nice', 'whinnery', 'think', 'lack', 'acceptance', 'bother', 'describe', 'humor', 'eventually', 'fuzzy', 'theory', 'take', 'seriously', 'japanese', 'eventually', 'fuzzy', 'theory', 'take', 'seriously', 'japanese', 'implementation', 'surprise', 'even', 'zadeh', 'first', 'expect', 'fuzzy', 'set', 'apply', 'field', 'conventional', 'analytic', 'technique', 'ineffectual', 'work', 'hard', 'science', 'work', 'philosophy', 'psychology', 'linguistic', 'biology', 'also', 'think', 'theory', 'apply', 'control', 'system', 'engine', 'control', 'example', 'never', 'expect', 'use', 'consumer', 'product', 'today', 'perhaps', 'big', 'application', 'thank', 'japanese', 'electronic', 'company', 'matsushita', 'electric', 'industrial', 'co', 'first', 'apply', 'fuzzy', 'theory', 'consumer', 'product', 'shower', 'head', 'control', 'water', 'temperature', 'numerous', 'japanese', 'consumer', 'product', 'dishwasher', 'machine', 'air', 'conditioner', 'microwave', 'oven', 'camera', 'camcorder', 'television', 'set', 'copier', 'even', 'automobile', 'quietly', 'apply', 'fuzzy', 'technology', 'product', 'make', 'use', 'fuzzy', 'logic', 'combine', 'sensor', 'simplify', 'control', 'example', 'camera', 'several', 'focus', 'spot', 'use', 'fuzzy', 'ifthen', 'rule', 'calculate', 'optimal', 'focus', 'camcorder', 'use', 'fuzzy', 'logic', 'image', 'stabilization', 'washing', 'machine', 'use', 'sensor', 'detect', 'dirty', 'water', 'quickly', 'clear', 'determine', 'length', 'wash', 'cycle', 'introduction', 'fuzzy', 'product', 'rivet', 'press', 'attention', 'apparently', 'new', 'technology', 'decade', 'develop', 'theory', 'grow', 'acknowledgment', 'theory', 'colleague', 'follow', 'still', 'reject', 'acceptance', 'colleague', 'say', 'somewhat', 'change', 'zadeh', 'fuzzy', 'logic', 'turn', 'much', 'panache', 'finally', 'come', 'ignore', 'many', 'year', 'think', 'come', 'shell', 'say', 'launch', 'theory', 'fall', 'category', 'many', 'professor', 'reasonably', 'well', 'know', 'make', 'longlasting', 'impact', 'lotfi', 'zadeh', 'date', 'hundred', 'book', 'publish', 'topic', 'technical', 'paper', 'write', 'seem', 'pile', 'office', 'stack', 'paper', 'leave', 'narrow', 'path', 'door', 'desk', 'know', 'father', 'fuzzy', 'launch', 'theory', 'say', 'fall', 'category', 'many', 'professor', 'reasonably', 'well', 'know', 'attain', 'certain', 'level', 'recognition', 'write', 'book', 'paper', 'make', 'longlasting', 'impact', 'consider', 'lucky', 'thing', 'come', 'important', 'criterion', 'impact', 'generate', 'following', 'fuzzy', 'set', 'definitely', 'say', 'editor', 'note', 'die', 'age', 'senior', 'editor', 'ieee', 'spectrum', 'base', 'cover', 'people', 'company', 'technology', 'make', 'silicon', 'special', 'place', 'year', 'ieee', 'member', 'hold', 'bachelor', 'degree', 'journalism', 'metaverse', 'turn', 'shade', 'uncannily', 'creepy', 'write', 'ieee', 'spectrum', 'gizmo', 'column', 'freelance', 'consumertech', 'journalist', 'avid', 'gamer', 'former', 'staff', 'editor', 'digital', 'trend', 'particularly', 'fond', 'wearable', 'ebike', 'thing', 'smartphone', 'ce', 'attend', 'year', 'mesh', 'let', 'creator', 'import', 'facial', 'mesh', 'create', 'photorealistic', 'character', 'create', 'virtual', 'clone', 'difficult', 'think', 'epic', 'game', 'recently', 'introduce', 'mesh', 'metahuman', 'framework', 'create', 'photorealistic', 'human', 'character', 'let', 'creator', 'sculpt', 'import', 'mesh', 'create', 'convincing', 'character', 'less', 'hour', '’', 'incredibly', 'simple', 'compare', 'lot', 'tool', 'say', 'aka', 'partner', 'success', 'lead', 'giglab', 'cofounder', 'versed', '’d', 'compare', 'character', 'creator', 'game', 'enose', 'detect', 'glucose', 'level', 'percent', 'accuracy', 'freelance', 'writer', 'base', 'frequently', 'contribute', 'spectrum', 'watch', 'coverage', 'highlight', 'newsworthy', 'study', 'publish', 'ieee', 'journal', 'article', 'part', 'exclusive', 'ieee', 'journal', 'partnership', 'ieee', 'xplore']"
"
        What Is the Future of Quantum-Proof Encryption?
    ",https://spectrum.ieee.org/post-quantum-cryptography-nist,2022-07-08,"Bright, according to officials at NIST’s Post-Quantum Cryptography program The first four algorithms that NIST has announced for post-quantum cryptography are based on structured lattices and hash functions, two families of math problems that could resist a quantum computer’s assault. On Tuesday, the National Institute of Standards and Technology (NIST) announced its first quantum-resistant algorithms—new encryption that will become the standard to guard against attacks by quantum computers, which are not yet here. The four algorithms are CRYSTALS-Kyber, for general encryption, and three schemes for digital encryption: CRYSTALS-Dilithium, FALCON, and SPHINCS+. Over the past few decades, NIST has managed encryption standards, introducing and vetting the schemes that protect and authenticate valuable digital information—from bank transactions to emails to your Netflix password. These encryption schemes are easy for the user to encode and decode, but hard for an attacker to break. This one-way functionality is like mixing colors: It’s easy to mix shades of blue and yellow to make green, but hard to tell by looking at a green which shades were used to create it. While these methods have been robust against classical attacks, they are known to be vulnerable to quantum algorithms. Quantum computers capable of breaking existing encryption with these algorithms are a ways off, but researchers say there’s no time to wait. Post-quantum cryptography is the future, and it’s here now. Last week, we spoke with Dustin Moody, a mathematician at NIST leading the post-quantum cryptography standardization process.  What is post-quantum cryptography, and why does NIST need a standardization process for it? Dustin MoodyNIST Dustin Moody: Researchers from a variety of backgrounds have been working on building what’s called a quantum computer. If a quantum computer is built that is large enough, there’s an algorithm you could run on this quantum computer that would break several of the most widely used cryptosystems that we have implemented and use today around the world. So post-quantum crypto is preparing new cryptosystems to replace those that would be vulnerable to attacks from a big enough quantum computer. And NIST is doing this because a few of the cryptosystems that we have standardized, namely the ones dealing with public-key cryptography, would be vulnerable. So we want to replace those standards with new ones that would not be vulnerable to attacks from a quantum computer. “You can actually be at risk from a quantum computer, even though a [high-performance] quantum computer does not yet exist. This is often called ‘harvest now, decrypt later.’”—Dustin Moody, NIST Now there’s two separate things you’re replacing, as I understand it; there’s both a key and a signature. Can you talk about both of those—and the difference between the two? Moody: With cryptography, you have many different kinds of tools that are needed to protect your information. One of these that people first think of is just encryption and scrambling your data, so your enemy can’t read it. That is typically enabled using public-key encryption. You then create a shared secret that you will actually use for a key for another type of cryptosystem that can do encryption a lot faster, a block cipher called AES. But this public-key encryption is used to create that initial key. So that’s the first functionality that we need to replace. The second is digital signatures. Instead of signing your name at the bottom of the letter to prove that you are the author, you can digitally do the same thing using cryptographic techniques. And that is also known to be vulnerable to a quantum computer. So it’s the second functionality that we’re trying to replace. The largest quantum computer is about 200-something qubits right now, and they’re not fault-tolerant. The largest number that one of these machines has factored with Shor’s algorithm is 21. There are various estimates out there for what it would take to crack RSA 2048, but you would need thousands of qubits at a minimum, and they would all need to be very, very high quality. What’s the rush? Why are we doing this now? You started this process in 2016. This is years, if not decades, ahead of time. Moody: First, standardizing cryptosystems and then getting them into products around the world takes a surprisingly long amount of time. From our past experience, switching from one crypto algorithm to another can take 10 to 20 years. And since we need to have this done before a quantum computer comes out, we've got to get all that work done ahead of time. And it can’t be rushed too quickly. You don’t have confidence in a cryptosystem if it was invented two weeks ago. We need years of people analyzing these algorithms to have confidence in their security. That’s reason one: It takes time to get ready. And then reason two is you can actually be at risk from a quantum computer, even though a quantum computer does not yet exist. This is often called “harvest now, decrypt later.” It’s the idea that your enemy could copy your data, which is encrypted, and they can hold onto it right now. They can’t read it. But maybe a quantum computer comes out in 10 years, and then they can get access to your data. If the information you’re protecting is valuable enough, then you’re already in trouble because of that threat. So that’s another reason that we need to be well ahead of the time that a quantum computer is built. How real is harvest now, decrypt later? I understand that there is the possibility, but is this really happening? Are people downloading data and squirreling it away so that when they get their quantum computers up and running, they can go through it? Moody: So, I don’t have access to classified material. NIST is not at that level, like the NSA and other people do that. But people I have talked to say that this is absolutely a threat and that it is occurring now at the nation-state level. “We’re going to standardize a number of things so that we have a diversity of different mathematical problems to base our security on.”—Dustin Moody, NIST The vulnerability in public-key encryption is because of quantum computers’ ultimate ability to have almost exponentially faster factoring of large prime numbers. What types of strategies are being used to create these new public keys? Can you run through a few of them? Moody: In crypto, we like to use ideas that have been around for a while. Since [Peter] Shor’s algorithm was discovered back in the ’90s, researchers have been looking into this. There are three big families where a lot of the solutions are coming from. The most popular one involves what are called lattices. This is a mathematical structure. You take basis vectors; you take integral linear combinations of them. And you can do some pretty interesting things cryptographically. There are no known quantum algorithms that do better than the classical attacks on cryptosystems based on lattices. Cryptosystems based on lattices seem to be the top contenders in terms of key size and efficiency. So it wasn’t surprising that we received a lot of lattice submissions. The second family is based on what are called error-correcting codes or code-based cryptography. These codes have been used in information security for a long time, because data gets sent on noisy channels. If you use error-correcting codes, you can account for the error and recover the message that was originally meant to be sent. We use ideas similar to what’s used in lattices with these codes. And there, they seem to be just a half-step behind the lattices in terms of key sizes and efficiency, but they’re pretty good as well. So we saw a number of code-based submissions. The third biggest family includes some signature schemes based on what’s called multivariate cryptography. You’ll use a multitude of variables, x1 to xn, and create a system of quadratic equations. And it’s very easy to define and evaluate one of these systems, but very hard to solve. So it turns out that works well for digital-signature schemes. Sort of like if you had a big squiggly line on a graph? It’s easy to draw, but it’s hard to actually figure out what function was used to plot it. Moody: Yeah, that’s the idea in a lot of cryptosystems. There’s a one-way thing—if you know the secret, you can do it quickly and easily. That allows you to decrypt or sign. An attacker doesn’t know that secret, and they can’t do anything. A signature system called Rainbow was recently broken. I understand roughly how you might test a classical encryption system, because we have classical computers. But we don’t have quantum computers. So how do you verify that these methods are actually quantum secure? Moody: There’s no guarantee that no one really is going to come along and come up with some new idea. That’s the case with the cryptosystems we use today in classical computers as well. Sure, I know RSA isn’t provably hard. Moody: When you add quantum computers to the mix, you get access to more tools, you get access to more quantum algorithms. And the best we can say is that a lot of smart people spend time looking at these, nobody has found any attacks, and they don’t seem to be getting close. The avenues don’t appear to be useful at all. That’s how we set up our competition—make sure that we had experts in the field, spend a number of years looking at these cryptosystems, and see that there are no attacks. And actually, Rainbow—it wasn’t a quantum attack that broke it; it was a classical attack. So these things have to be secured from both quantum computers as well as all the classical attacks as well. So at this point in the process, you really have narrowed it down to a couple of finalists from an initial selection. [Editor’s note: This took place prior to the July 5th announcement.] Moody: Yeah, we started out with 82. And right now we have seven finalists and eight alternates at the end of round three, which is going to end within a very short time, probably a week or two, or we’ll have ones that we will standardize. What happens then? Moody: We’re going to begin writing standards. These will be the algorithms that will be most widely used. We will also name a few that we’ll continue on into a fourth round of evaluation so that we have a few other algorithms. Because this is a new research field, we don’t want to put all our eggs in one basket and only have lattice algorithms, and then an attack comes along and we don’t have anything else. We’re going to standardize a number of things so that we have a diversity of different mathematical problems to base our security on. We’ll start writing the standards, which will take a year or two, and there’ll be a few that continue to be evaluated and might be selected for standardization at the end of the fourth round. What’s the difference between finalists and those getting standardized? Moody: Once we’ve named these algorithms, people know that these are going to be the ones that are gonna be in widespread use. There already are implementations, but people will be able to focus on the standardized ones. It’s an important step on the road to adoption. The industry needs standards before adoption can really get widespread. I understand that there are some patent disputes related to the algorithms. Moody: In crypto, most people don’t like patents, because they tend to hinder adoption. Companies don’t like to adopt algorithms that might be patented. At the beginning of our process, all the submitters had to let us know of any patents that they had. We were aware of some patents, which were not from the submitters—they were from some third parties. NIST has been in talks with these other parties to negotiate a solution that would be beneficial to both parties. I think you’ll see with our announcement that we’re happy with the outcome. We feel that the algorithms will be able to be widely adopted by people around the world. Dan Garisto is a freelance science journalist who covers physics and other physical sciences. His work has appeared in Scientific American, Physics, Symmetry, Undark, and other outlets. If technologists can’t perfect it, quantum computers will never be big Dates chiseled into an ancient tombstone have more in common with the data in your phone or laptop than you may realize. They both involve conventional, classical information, carried by hardware that is relatively immune to errors. The situation inside a quantum computer is far different: The information itself has its own idiosyncratic properties, and compared with standard digital microelectronics, state-of-the-art quantum-computer hardware is more than a billion trillion times as likely to suffer a fault. This tremendous susceptibility to errors is the single biggest problem holding back quantum computing from realizing its great promise.
 
	Fortunately, an approach known as quantum error correction (QEC) can remedy this problem, at least in principle. A mature body of theory built up over the past quarter century now provides a solid theoretical foundation, and experimentalists have demonstrated dozens of proof-of-principle 
	examples of QEC. But these experiments still have not reached the level of quality and sophistication needed to reduce the overall error rate in a system.
                                             ","Bright, according to officials at NIST’s Post-Quantum Cryptography program The first four algorithms that NIST has announced for post-quantum cryptography are based on structured lattices and hash functions, two families of math problems that could resist a quantum computer’s assault. On Tuesday, the National Institute of Standards and Technology (NIST) announced its first quantum-resistant algorithms—new encryption that will become the standard to guard against attacks by quantum computers, which are not yet here. The four algorithms are CRYSTALS-Kyber, for general encryption, and three schemes for digital encryption: CRYSTALS-Dilithium, FALCON, and SPHINCS+. Over the past few decades, NIST has managed encryption standards, introducing and vetting the schemes that protect and authenticate valuable digital information—from bank transactions to emails to your Netflix password. These encryption schemes are easy for the user to encode and decode, but hard for an attacker to break. This one-way functionality is like mixing colors: It’s easy to mix shades of blue and yellow to make green, but hard to tell by looking at a green which shades were used to create it. While these methods have been robust against classical attacks, they are known to be vulnerable to quantum algorithms. Quantum computers capable of breaking existing encryption with these algorithms are a ways off, but researchers say there’s no time to wait. Post-quantum cryptography is the future, and it’s here now. Last week, we spoke with Dustin Moody, a mathematician at NIST leading the post-quantum cryptography standardization process. What is post-quantum cryptography, and why does NIST need a standardization process for it? Dustin MoodyNIST Dustin Moody: Researchers from a variety of backgrounds have been working on building what’s called a quantum computer. If a quantum computer is built that is large enough, there’s an algorithm you could run on this quantum computer that would break several of the most widely used cryptosystems that we have implemented and use today around the world. So post-quantum crypto is preparing new cryptosystems to replace those that would be vulnerable to attacks from a big enough quantum computer. And NIST is doing this because a few of the cryptosystems that we have standardized, namely the ones dealing with public-key cryptography, would be vulnerable. So we want to replace those standards with new ones that would not be vulnerable to attacks from a quantum computer. “You can actually be at risk from a quantum computer, even though a [high-performance] quantum computer does not yet exist. This is often called ‘harvest now, decrypt later.’”—Dustin Moody, NIST Now there’s two separate things you’re replacing, as I understand it; there’s both a key and a signature. Can you talk about both of those—and the difference between the two? Moody: With cryptography, you have many different kinds of tools that are needed to protect your information. One of these that people first think of is just encryption and scrambling your data, so your enemy can’t read it. That is typically enabled using public-key encryption. You then create a shared secret that you will actually use for a key for another type of cryptosystem that can do encryption a lot faster, a block cipher called AES. But this public-key encryption is used to create that initial key. So that’s the first functionality that we need to replace. The second is digital signatures. Instead of signing your name at the bottom of the letter to prove that you are the author, you can digitally do the same thing using cryptographic techniques. And that is also known to be vulnerable to a quantum computer. So it’s the second functionality that we’re trying to replace. The largest quantum computer is about 200-something qubits right now, and they’re not fault-tolerant. The largest number that one of these machines has factored with Shor’s algorithm is 21. There are various estimates out there for what it would take to crack RSA 2048, but you would need thousands of qubits at a minimum, and they would all need to be very, very high quality. What’s the rush? Why are we doing this now? You started this process in 2016. This is years, if not decades, ahead of time. Moody: First, standardizing cryptosystems and then getting them into products around the world takes a surprisingly long amount of time. From our past experience, switching from one crypto algorithm to another can take 10 to 20 years. And since we need to have this done before a quantum computer comes out, we've got to get all that work done ahead of time. And it can’t be rushed too quickly. You don’t have confidence in a cryptosystem if it was invented two weeks ago. We need years of people analyzing these algorithms to have confidence in their security. That’s reason one: It takes time to get ready. And then reason two is you can actually be at risk from a quantum computer, even though a quantum computer does not yet exist. This is often called “harvest now, decrypt later.” It’s the idea that your enemy could copy your data, which is encrypted, and they can hold onto it right now. They can’t read it. But maybe a quantum computer comes out in 10 years, and then they can get access to your data. If the information you’re protecting is valuable enough, then you’re already in trouble because of that threat. So that’s another reason that we need to be well ahead of the time that a quantum computer is built. How real is harvest now, decrypt later? I understand that there is the possibility, but is this really happening? Are people downloading data and squirreling it away so that when they get their quantum computers up and running, they can go through it? Moody: So, I don’t have access to classified material. NIST is not at that level, like the NSA and other people do that. But people I have talked to say that this is absolutely a threat and that it is occurring now at the nation-state level. “We’re going to standardize a number of things so that we have a diversity of different mathematical problems to base our security on.”—Dustin Moody, NIST The vulnerability in public-key encryption is because of quantum computers’ ultimate ability to have almost exponentially faster factoring of large prime numbers. What types of strategies are being used to create these new public keys? Can you run through a few of them? Moody: In crypto, we like to use ideas that have been around for a while. Since [Peter] Shor’s algorithm was discovered back in the ’90s, researchers have been looking into this. There are three big families where a lot of the solutions are coming from. The most popular one involves what are called lattices. This is a mathematical structure. You take basis vectors; you take integral linear combinations of them. And you can do some pretty interesting things cryptographically. There are no known quantum algorithms that do better than the classical attacks on cryptosystems based on lattices. Cryptosystems based on lattices seem to be the top contenders in terms of key size and efficiency. So it wasn’t surprising that we received a lot of lattice submissions. The second family is based on what are called error-correcting codes or code-based cryptography. These codes have been used in information security for a long time, because data gets sent on noisy channels. If you use error-correcting codes, you can account for the error and recover the message that was originally meant to be sent. We use ideas similar to what’s used in lattices with these codes. And there, they seem to be just a half-step behind the lattices in terms of key sizes and efficiency, but they’re pretty good as well. So we saw a number of code-based submissions. The third biggest family includes some signature schemes based on what’s called multivariate cryptography. You’ll use a multitude of variables, x1 to xn, and create a system of quadratic equations. And it’s very easy to define and evaluate one of these systems, but very hard to solve. So it turns out that works well for digital-signature schemes. Sort of like if you had a big squiggly line on a graph? It’s easy to draw, but it’s hard to actually figure out what function was used to plot it. Moody: Yeah, that’s the idea in a lot of cryptosystems. There’s a one-way thing—if you know the secret, you can do it quickly and easily. That allows you to decrypt or sign. An attacker doesn’t know that secret, and they can’t do anything. A signature system called Rainbow was recently broken. I understand roughly how you might test a classical encryption system, because we have classical computers. But we don’t have quantum computers. So how do you verify that these methods are actually quantum secure? Moody: There’s no guarantee that no one really is going to come along and come up with some new idea. That’s the case with the cryptosystems we use today in classical computers as well. Sure, I know RSA isn’t provably hard. Moody: When you add quantum computers to the mix, you get access to more tools, you get access to more quantum algorithms. And the best we can say is that a lot of smart people spend time looking at these, nobody has found any attacks, and they don’t seem to be getting close. The avenues don’t appear to be useful at all. That’s how we set up our competition—make sure that we had experts in the field, spend a number of years looking at these cryptosystems, and see that there are no attacks. And actually, Rainbow—it wasn’t a quantum attack that broke it; it was a classical attack. So these things have to be secured from both quantum computers as well as all the classical attacks as well. So at this point in the process, you really have narrowed it down to a couple of finalists from an initial selection. [Editor’s note: This took place prior to the July 5th announcement.] Moody: Yeah, we started out with 82. And right now we have seven finalists and eight alternates at the end of round three, which is going to end within a very short time, probably a week or two, or we’ll have ones that we will standardize. What happens then? Moody: We’re going to begin writing standards. These will be the algorithms that will be most widely used. We will also name a few that we’ll continue on into a fourth round of evaluation so that we have a few other algorithms. Because this is a new research field, we don’t want to put all our eggs in one basket and only have lattice algorithms, and then an attack comes along and we don’t have anything else. We’re going to standardize a number of things so that we have a diversity of different mathematical problems to base our security on. We’ll start writing the standards, which will take a year or two, and there’ll be a few that continue to be evaluated and might be selected for standardization at the end of the fourth round. What’s the difference between finalists and those getting standardized? Moody: Once we’ve named these algorithms, people know that these are going to be the ones that are gonna be in widespread use. There already are implementations, but people will be able to focus on the standardized ones. It’s an important step on the road to adoption. The industry needs standards before adoption can really get widespread. I understand that there are some patent disputes related to the algorithms. Moody: In crypto, most people don’t like patents, because they tend to hinder adoption. Companies don’t like to adopt algorithms that might be patented. At the beginning of our process, all the submitters had to let us know of any patents that they had. We were aware of some patents, which were not from the submitters—they were from some third parties. NIST has been in talks with these other parties to negotiate a solution that would be beneficial to both parties. I think you’ll see with our announcement that we’re happy with the outcome. We feel that the algorithms will be able to be widely adopted by people around the world. Dan Garisto is a freelance science journalist who covers physics and other physical sciences. His work has appeared in Scientific American, Physics, Symmetry, Undark, and other outlets. If technologists can’t perfect it, quantum computers will never be big Dates chiseled into an ancient tombstone have more in common with the data in your phone or laptop than you may realize. They both involve conventional, classical information, carried by hardware that is relatively immune to errors. The situation inside a quantum computer is far different: The information itself has its own idiosyncratic properties, and compared with standard digital microelectronics, state-of-the-art quantum-computer hardware is more than a billion trillion times as likely to suffer a fault. This tremendous susceptibility to errors is the single biggest problem holding back quantum computing from realizing its great promise. Fortunately, an approach known as quantum error correction (QEC) can remedy this problem, at least in principle. A mature body of theory built up over the past quarter century now provides a solid theoretical foundation, and experimentalists have demonstrated dozens of proof-of-principle examples of QEC. But these experiments still have not reached the level of quality and sophistication needed to reduce the overall error rate in a system.","['bright', 'accord', 'official', 'nist', 'program', 'first', 'algorithm', 'nist', 'announce', 'postquantum', 'base', 'structured', 'lattice', 'hash', 'function', 'family', 'math', 'problem', 'resist', 'computer', 'assault', 'standard', 'technology', 'nist', 'announce', 'first', 'quantumresistant', 'algorithm', 'new', 'encryption', 'become', 'standard', 'guard', 'attack', 'quantum', 'computer', 'yet', 'algorithm', 'crystalskyber', 'general', 'encryption', 'scheme', 'digital', 'encryption', 'crystalsdilithium', 'falcon', 'sphinc', 'past', 'decade', 'nist', 'manage', 'encryption', 'standard', 'introduce', 'vet', 'scheme', 'protect', 'authenticate', 'valuable', 'digital', 'information', 'bank', 'transaction', 'email', 'netflix', 'password', 'encryption', 'scheme', 'easy', 'user', 'encode', 'decode', 'hard', 'attacker', 'break', 'oneway', 'functionality', 'mix', 'color', '’', 'easy', 'mix', 'shade', 'blue', 'yellow', 'make', 'green', 'hard', 'tell', 'look', 'green', 'shade', 'use', 'create', 'method', 'robust', 'classical', 'attack', 'know', 'vulnerable', 'quantum', 'algorithm', 'quantum', 'computer', 'capable', 'break', 'exist', 'encryption', 'algorithm', 'way', 'researcher', 'say', '’', 'time', 'wait', 'postquantum', 'future', '’', 'last', 'week', 'speak', 'mathematician', 'nist', 'lead', 'postquantum', 'cryptography', 'standardization', 'process', 'postquantum', 'nist', 'need', 'standardization', 'process', 'moody', 'researcher', 'variety', 'background', 'work', 'build', 'call', 'quantum', 'computer', 'quantum', 'computer', 'build', 'large', 'enough', '’', 'algorithm', 'run', 'quantum', 'computer', 'break', 'several', 'widely', 'use', 'cryptosystem', 'implement', 'use', 'today', 'world', 'prepare', 'new', 'cryptosystem', 'replace', 'vulnerable', 'attack', 'big', 'enough', 'quantum', 'computer', 'nist', 'cryptosystem', 'standardize', 'namely', 'one', 'deal', 'cryptography', 'vulnerable', 'want', 'replace', 'standard', 'new', 'one', 'vulnerable', 'attack', 'quantum', 'computer', 'actually', 'risk', 'quantum', 'computer', 'even', 'highperformance', 'quantum', 'computer', 'yet', 'exist', 'often', 'call', 'decrypt', 'moody', 'nist', '’', 'separate', 'thing', 'replace', 'understand', '’', 'key', 'signature', 'talk', 'difference', 'moody', 'cryptography', 'many', 'different', 'kind', 'tool', 'need', 'protect', 'information', 'people', 'first', 'think', 'encryption', 'scramble', 'datum', 'enemy', 'read', 'typically', 'enable', 'use', 'publickey', 'encryption', 'create', 'shared', 'secret', 'actually', 'use', 'key', 'type', 'cryptosystem', 'encryption', 'lot', 'fast', 'block', 'cipher', 'call', 'publickey', 'encryption', 'use', 'create', 'initial', 'key', '’', 'first', 'functionality', 'need', 'replace', 'second', 'digital', 'signature', 'instead', 'sign', 'name', 'bottom', 'letter', 'prove', 'author', 'digitally', 'thing', 'use', 'cryptographic', 'technique', 'also', 'know', 'vulnerable', 'quantum', 'computer', '’', 'second', 'functionality', 'try', 'replace', 'large', 'quantum', 'computer', 'qubit', 'right', '’re', 'faulttolerant', 'large', 'number', 'machine', 'factor', 'various', 'estimate', 'take', 'crack', 'rsa', 'need', 'thousand', 'qubit', 'minimum', 'need', 'high', 'quality', '’', 'rush', 'start', 'process', 'year', 'decade', 'ahead', 'time', 'moody', 'first', 'standardize', 'cryptosystem', 'get', 'product', 'world', 'take', 'surprisingly', 'long', 'amount', 'time', 'past', 'experience', 'switch', 'crypto', 'take', 'year', 'need', 'quantum', 'computer', 'come', 'get', 'get', 'work', 'ahead', 'time', 'rush', 'quickly', 'confidence', 'cryptosystem', 'invent', 'week', 'ago', 'need', 'year', 'people', 'analyze', 'algorithm', 'confidence', 'security', '’s', 'reason', 'take', 'time', 'get', 'ready', 'reason', 'actually', 'risk', 'quantum', 'computer', 'even', 'quantum', 'computer', 'yet', 'exist', 'often', 'call', 'harvest', 'decrypt', 'later', '’', 'idea', 'enemy', 'copy', 'datum', 'encrypt', 'hold', 'right', 'read', 'maybe', 'quantum', 'computer', 'come', 'year', 'get', 'access', 'datum', 'information', 'protect', 'valuable', 'enough', '’re', 'already', 'trouble', 'threat', '’', 'reason', 'need', 'well', 'ahead', 'time', 'quantum', 'computer', 'build', 'real', 'harvest', 'decrypt', 'later', 'understand', 'possibility', 'really', 'happen', 'people', 'download', 'datum', 'squirrele', 'away', 'get', 'quantum', 'computer', 'run', 'go', 'moody', 'access', 'classified', 'material', 'nist', 'level', 'nsa', 'people', 'people', 'talk', 'say', 'absolutely', 'threat', 'occur', 'nationstate', 'level', 'go', 'standardize', 'number', 'thing', 'diversity', 'different', 'mathematical', 'problem', 'base', 'security', 'dustin', 'moody', 'nist', 'vulnerability', 'encryption', 'quantum', 'computer', 'ultimate', 'ability', 'almost', 'exponentially', 'fast', 'factoring', 'large', 'prime', 'number', 'type', 'strategy', 'use', 'create', 'new', 'public', 'key', 'run', 'moody', 'crypto', 'like', 'use', 'idea', 'around', 'discover', 'back', '90', 'researcher', 'look', 'big', 'family', 'lot', 'solution', 'come', 'popular', 'one', 'involve', 'call', 'lattice', 'mathematical', 'structure', 'take', 'basis', 'vector', 'take', 'integral', 'linear', 'combination', 'pretty', 'interesting', 'thing', 'cryptographically', 'know', 'quantum', 'algorithm', 'well', 'classical', 'attack', 'cryptosystem', 'base', 'lattice', 'cryptosystem', 'base', 'lattice', 'seem', 'top', 'contender', 'term', 'key', 'size', 'efficiency', 'surprising', 'receive', 'lot', 'lattice', 'submission', 'second', 'family', 'base', 'call', 'errorcorrecting', 'code', 'codebase', 'cryptography', 'code', 'use', 'information', 'security', 'long', 'time', 'datum', 'send', 'noisy', 'channel', 'use', 'errorcorrecting', 'code', 'account', 'error', 'recover', 'message', 'originally', 'mean', 'send', 'use', 'idea', 'similar', 'use', 'lattice', 'code', 'seem', 'halfstep', 'lattice', 'term', 'key', 'size', 'efficiency', '’re', 'pretty', 'good', 'well', 'see', 'number', 'codebase', 'submission', 'third', 'big', 'family', 'include', 'signature', 'scheme', 'base', 'call', 'multivariate', 'cryptography', 'use', 'multitude', 'variable', 'x1', 'create', 'system', 'quadratic', 'equation', '’', 'easy', 'define', 'evaluate', 'system', 'hard', 'solve', 'turn', 'work', 'well', 'digitalsignature', 'scheme', 'sort', 'big', 'squiggly', 'line', 'graph', '’s', 'easy', 'draw', '’', 'hard', 'actually', 'figure', 'function', 'use', 'plot', 'moody', '’', 'idea', 'lot', 'cryptosystem', '’', 'oneway', 'thing', 'know', 'secret', 'quickly', 'easily', 'allow', 'decrypt', 'sign', 'attacker', 'know', 'secret', 'signature', 'system', 'call', 'recently', 'break', 'understand', 'roughly', 'test', 'classical', 'encryption', 'system', 'classical', 'computer', 'quantum', 'computer', 'verify', 'method', 'actually', 'quantum', 'secure', 'moody', '’', 'guarantee', 'one', 'really', 'go', 'come', 'along', 'come', 'new', 'idea', '’', 'case', 'cryptosystem', 'use', 'today', 'classical', 'computer', 'well', 'sure', 'know', 'provably', 'hard', 'moody', 'add', 'quantum', 'computer', 'mix', 'get', 'access', 'tool', 'get', 'access', 'quantum', 'algorithm', 'good', 'say', 'lot', 'smart', 'people', 'spend', 'time', 'look', 'find', 'attack', 'seem', 'get', 'close', 'avenue', 'appear', 'useful', '’', 'set', 'competition', 'make', 'sure', 'expert', 'field', 'spend', 'number', 'year', 'look', 'cryptosystem', 'see', 'attack', 'actually', 'rainbow', 'quantum', 'attack', 'break', 'classical', 'attack', 'thing', 'secure', 'quantum', 'computer', 'well', 'classical', 'attack', 'well', 'point', 'process', 'really', 'narrow', 'couple', 'finalist', 'initial', 'selection', 'editor', 'note', 'take', 'place', 'prior', '5th', 'announcement', 'moody', 'start', 'right', 'finalist', 'alternate', 'end', 'round', 'go', 'end', 'short', 'time', 'probably', 'week', 'one', 'standardize', 'happen', 'moody', 'go', 'begin', 'write', 'standard', 'algorithm', 'widely', 'use', 'also', 'name', 'continue', 'fourth', 'round', 'evaluation', 'algorithm', 'new', 'research', 'field', 'want', 'put', 'egg', 'basket', 'lattice', 'algorithm', 'attack', 'come', 'along', 'else', 'go', 'standardize', 'number', 'thing', 'diversity', 'different', 'mathematical', 'problem', 'base', 'security', 'start', 'write', 'standard', 'take', 'year', 'continue', 'evaluate', 'select', 'standardization', 'end', 'fourth', 'round', '’', 'difference', 'finalist', 'get', 'standardized', 'moody', 'name', 'algorithm', 'people', 'know', 'go', 'one', 'going', 'widespread', 'use', 'already', 'implementation', 'people', 'able', 'focus', 'standardized', 'one', '’', 'important', 'step', 'road', 'adoption', 'industry', 'need', 'standard', 'adoption', 'really', 'get', 'widespread', 'understand', 'patent', 'dispute', 'relate', 'algorithm', 'moody', 'people', 'like', 'patent', 'tend', 'hinder', 'adoption', 'company', 'like', 'adopt', 'algorithm', 'patent', 'beginning', 'process', 'submitter', 'let', 'know', 'patent', 'aware', 'patent', 'submitter', 'third', 'party', 'nist', 'talk', 'party', 'negotiate', 'solution', 'beneficial', 'party', 'think', 'see', 'announcement', '’re', 'happy', 'outcome', 'feel', 'algorithm', 'able', 'widely', 'adopt', 'people', 'world', 'freelance', 'science', 'journalist', 'cover', 'physics', 'physical', 'science', 'work', 'appear', 'scientific', 'american', 'symmetry', 'undark', 'outlet', 'technologist', 'perfect', 'quantum', 'computer', 'never', 'big', 'date', 'chisel', 'ancient', 'tombstone', 'common', 'datum', 'phone', 'laptop', 'realize', 'involve', 'conventional', 'classical', 'information', 'carry', 'hardware', 'relatively', 'immune', 'error', 'situation', 'quantum', 'computer', 'far', 'different', 'information', 'idiosyncratic', 'property', 'compare', 'standard', 'digital', 'microelectronic', 'stateoftheart', 'quantumcomputer', 'hardware', 'time', 'likely', 'suffer', 'fault', 'tremendous', 'susceptibility', 'error', 'single', 'big', 'problem', 'hold', 'quantum', 'computing', 'realize', 'great', 'promise', 'fortunately', 'approach', 'know', 'quantum', 'error', 'correction', 'qec', 'remedy', 'problem', 'least', 'principle', 'mature', 'body', 'theory', 'build', 'past', 'quarter', 'century', 'provide', 'solid', 'theoretical', 'foundation', 'experimentalist', 'demonstrate', 'dozen', 'proofofprinciple', 'example', 'qec', 'experiment', 'still', 'reach', 'level', 'quality', 'sophistication', 'need', 'reduce', 'overall', 'error', 'rate', 'system']"
"
        D-Wave’s 500-Qubit Machine Hits the Cloud
    ",https://spectrum.ieee.org/d-wave-quantum-computer,2022-07-07,"Experimental prototype offers sneak peek of 7,000-qubit quantum computer This animation depicts some of the concepts behind the quantum-computer company D-Wave’s topology for their latest prototype annealing quantum computer—Advantage2. When quantum-computing pioneer D-Wave releases its next-generation Advantage2 system in 2023 or 2024, the company expects its 7,000-qubit machine to be the most powerful quantum computer of its kind in the world. Now D-Wave is making an experimental prototype of Advantage2 immediately available for use over the cloud. Classical computers switch transistors either on or off to symbolize data as ones or zeroes. In contrast, quantum computers use quantum bits, or “qubits.” Because of the strange nature of quantum physics, qubits can exist in a state called superposition, in which they are essentially both 1 and 0 at the same time. This phenomenon lets each qubit perform two calculations at once. The more qubits are quantum mechanically linked, or entangled, within a quantum computer, the greater its computational power can grow, in an exponential fashion. The standard approach toward building quantum computers, called the gate model, involves arranging qubits in circuits and making them interact with each other in a fixed sequence. In contrast, D-Wave—based in Burnaby, B.C, Canada—has long focused on what are called annealing quantum computers. Quantum cousins of classical annealing computers, these machines find a lowest energy state by slowly cooling it down—in much the same way that metals and crystals are sometimes tempered so as to minimize imperfections. Quantum annealing machines, then, start off with a set of qubits whose interactions at their lowest energy state, called the ground state, represent the correct answer for a specific problem the researchers programmed it to solve. “Given the early positive results, we wanted to get it into the hands of developers and researchers now for exploration and learning.”—Emile Hoskinson, D-Wave The ideal application for annealing quantum computers may be solving optimization problems, says Emile Hoskinson, an experimental physicist and the director of quantum-annealing products at D-Wave. These seek to find the best answer from all possible solutions, such as mapping the fastest route from point A to point B. For instance, imagine trying to find the lowest point on a vast landscape covered in hills and valleys. A classical computer might start at a random spot on the surface and look around for a lower spot to explore until it cannot walk downhill anymore. This approach can often get stuck in a “local minimum,” a valley that is not actually the very lowest point on the surface. On the other hand, annealing quantum computers could make it possible to start at many spots on the surface at the same time, reducing the chance of becoming trapped in a local minimum. They can even essentially tunnel through a hill to see if there is a lower valley beyond it, or share data from multiple spots to find patterns that might lead to deeper points. Founded in 1999, D-Wave bills itself as the world’s first commercial supplier of quantum computers. The company has longprovedcontroversial, with many critics over the years questioning whether its machines are any more powerful than regular computers. Nevertheless, D-Wave has claimed its share of high-profile clients over the years. It sold its first quantum computing system, the 128-qubit D-Wave One, to Lockheed Martin in 2011, and shipped its 512-qubit D-Wave Two to NASA’s Quantum Artificial Intelligence Lab—launched in partnership with Google and the Universities Space Research Association—in 2013. When D-Wave’s Advantage2 comes online next year or the year after, it will be the world’s most powerful annealing quantum computer, Hoskinson says. Now the company is releasing an experimental prototype of Advantage2, with all the core functionality of the full-scale product available for testing. “Our broad portfolio of enterprise customers—such as Volkswagen, Save-on-Foods, Denso, Toyota, BBVA, NEC, Accenture, and Lockheed Martin—have built hundreds of early quantum applications in diverse areas such as resource scheduling, mobility, logistics, drug discovery, portfolio optimization, manufacturing processes, and much more,” Hoskinson says. “We expect the Advantage2 can be used to address problems with even greater complexity. When we talk about addressing a broader swath of problems, we mean the improved technology can tackle problems that are larger, more complex, and that cover a wider range of use cases across different verticals. It will address the same problems as before, but better and faster.” The prototype holds more than 500 superconducting flux qubits. The new design of the qubits enables what D-Wave calls its Zephyrtopology, which supports 20-way interqubit connectivity, up from 15 in the company’s prior generation, Advantage. “An analogy to illustrate the importance of connectivity is a social network, in which influence, and the complexity of interactions, grows with the number of connections between nodes,” Hoskinson says. “Complexity can mean problem size, such as the number of variables, constraints, and so on. It can also mean commercial and business application context—for example, if a particular business needs a fast time-to-solution because of business demand, such as changing schedules, supply-chain dependencies, and so on, then that makes the problem more complex. We see Advantage2 solving problems both better and faster, addressing both of these types of complex use cases.” The new qubit design also supports a higher energy scale, which makes the qubits less vulnerable to disruption from thermal fluctuations. This in turn reduces error rates in quantum computation. In tests, when the prototype’s qubits were arranged in their standard “native” topology, it found better solutions in up to 89 percent of cases when compared with Advantage, the company notes. When it came to problems requiring greater connectivity between qubits, multiple qubits can get linked together in a strategy called embedding, and Advantage2’s greater interqubit connectivity led the prototype to find better-quality solutions than Advantage in up to 82 percent of such problems. “Many commercially interesting problems require embedding,” Hoskinson says. “With the new Advantage2 Zephyr topology and increased energy scale, we see performance improvements for both native and embedded problems.” D-Wave did not originally plan to make its prototype available publicly, “but given the early positive results, we wanted to get it into the hands of developers and researchers now for exploration and learning,” Hoskinson says. “It’s about learning from our community to maximize commercial application performance as we build towards the final full-scale Advantage2 quantum computer.” Hoskinson notes that D-Wave is also working on a new fabrication process that should lead to dramatically less noise in the company’s quantum computers, increasing their chances of finding high-quality solutions. “While the prototype was developed in our current rapid-development fabrication stack, the eventual Advantage2 product will be produced in an all-new lower-noise stack,” he says. “We have early results for the new stack that show a seven-times reduction in low-frequency flux noise, a three-times reduction in integrated flux noise, and an order of magnitude reduction in high-frequency flux noise. This will go a long way toward further improving performance in the full Advantage2 system.” D-Wave made the prototype available over its Leap quantum cloud service in June. Charles Q. Choi is a science reporter who contributes regularly to IEEE Spectrum. He has written for Scientific American, The New York Times, Wired, and Science, among others. If technologists can’t perfect it, quantum computers will never be big Dates chiseled into an ancient tombstone have more in common with the data in your phone or laptop than you may realize. They both involve conventional, classical information, carried by hardware that is relatively immune to errors. The situation inside a quantum computer is far different: The information itself has its own idiosyncratic properties, and compared with standard digital microelectronics, state-of-the-art quantum-computer hardware is more than a billion trillion times as likely to suffer a fault. This tremendous susceptibility to errors is the single biggest problem holding back quantum computing from realizing its great promise.
 
	Fortunately, an approach known as quantum error correction (QEC) can remedy this problem, at least in principle. A mature body of theory built up over the past quarter century now provides a solid theoretical foundation, and experimentalists have demonstrated dozens of proof-of-principle 
	examples of QEC. But these experiments still have not reached the level of quality and sophistication needed to reduce the overall error rate in a system.
                                             ","Experimental prototype offers sneak peek of 7,000-qubit quantum computer This animation depicts some of the concepts behind the quantum-computer company D-Wave’s topology for their latest prototype annealing quantum computer—Advantage2. When quantum-computing pioneer D-Wave releases its next-generation Advantage2 system in 2023 or 2024, the company expects its 7,000-qubit machine to be the most powerful quantum computer of its kind in the world. Now D-Wave is making an experimental prototype of Advantage2 immediately available for use over the cloud. Classical computers switch transistors either on or off to symbolize data as ones or zeroes. In contrast, quantum computers use quantum bits, or “qubits.” Because of the strange nature of quantum physics, qubits can exist in a state called superposition, in which they are essentially both 1 and 0 at the same time. This phenomenon lets each qubit perform two calculations at once. The more qubits are quantum mechanically linked, or entangled, within a quantum computer, the greater its computational power can grow, in an exponential fashion. The standard approach toward building quantum computers, called the gate model, involves arranging qubits in circuits and making them interact with each other in a fixed sequence. In contrast, D-Wave—based in Burnaby, B.C, Canada—has long focused on what are called annealing quantum computers. Quantum cousins of classical annealing computers, these machines find a lowest energy state by slowly cooling it down—in much the same way that metals and crystals are sometimes tempered so as to minimize imperfections. Quantum annealing machines, then, start off with a set of qubits whose interactions at their lowest energy state, called the ground state, represent the correct answer for a specific problem the researchers programmed it to solve. “Given the early positive results, we wanted to get it into the hands of developers and researchers now for exploration and learning.”—Emile Hoskinson, D-Wave The ideal application for annealing quantum computers may be solving optimization problems, says Emile Hoskinson, an experimental physicist and the director of quantum-annealing products at D-Wave. These seek to find the best answer from all possible solutions, such as mapping the fastest route from point A to point B. For instance, imagine trying to find the lowest point on a vast landscape covered in hills and valleys. A classical computer might start at a random spot on the surface and look around for a lower spot to explore until it cannot walk downhill anymore. This approach can often get stuck in a “local minimum,” a valley that is not actually the very lowest point on the surface. On the other hand, annealing quantum computers could make it possible to start at many spots on the surface at the same time, reducing the chance of becoming trapped in a local minimum. They can even essentially tunnel through a hill to see if there is a lower valley beyond it, or share data from multiple spots to find patterns that might lead to deeper points. Founded in 1999, D-Wave bills itself as the world’s first commercial supplier of quantum computers. The company has longprovedcontroversial, with many critics over the years questioning whether its machines are any more powerful than regular computers. Nevertheless, D-Wave has claimed its share of high-profile clients over the years. It sold its first quantum computing system, the 128-qubit D-Wave One, to Lockheed Martin in 2011, and shipped its 512-qubit D-Wave Two to NASA’s Quantum Artificial Intelligence Lab—launched in partnership with Google and the Universities Space Research Association—in 2013. When D-Wave’s Advantage2 comes online next year or the year after, it will be the world’s most powerful annealing quantum computer, Hoskinson says. Now the company is releasing an experimental prototype of Advantage2, with all the core functionality of the full-scale product available for testing. “Our broad portfolio of enterprise customers—such as Volkswagen, Save-on-Foods, Denso, Toyota, BBVA, NEC, Accenture, and Lockheed Martin—have built hundreds of early quantum applications in diverse areas such as resource scheduling, mobility, logistics, drug discovery, portfolio optimization, manufacturing processes, and much more,” Hoskinson says. “We expect the Advantage2 can be used to address problems with even greater complexity. When we talk about addressing a broader swath of problems, we mean the improved technology can tackle problems that are larger, more complex, and that cover a wider range of use cases across different verticals. It will address the same problems as before, but better and faster.” The prototype holds more than 500 superconducting flux qubits. The new design of the qubits enables what D-Wave calls its Zephyrtopology, which supports 20-way interqubit connectivity, up from 15 in the company’s prior generation, Advantage. “An analogy to illustrate the importance of connectivity is a social network, in which influence, and the complexity of interactions, grows with the number of connections between nodes,” Hoskinson says. “Complexity can mean problem size, such as the number of variables, constraints, and so on. It can also mean commercial and business application context—for example, if a particular business needs a fast time-to-solution because of business demand, such as changing schedules, supply-chain dependencies, and so on, then that makes the problem more complex. We see Advantage2 solving problems both better and faster, addressing both of these types of complex use cases.” The new qubit design also supports a higher energy scale, which makes the qubits less vulnerable to disruption from thermal fluctuations. This in turn reduces error rates in quantum computation. In tests, when the prototype’s qubits were arranged in their standard “native” topology, it found better solutions in up to 89 percent of cases when compared with Advantage, the company notes. When it came to problems requiring greater connectivity between qubits, multiple qubits can get linked together in a strategy called embedding, and Advantage2’s greater interqubit connectivity led the prototype to find better-quality solutions than Advantage in up to 82 percent of such problems. “Many commercially interesting problems require embedding,” Hoskinson says. “With the new Advantage2 Zephyr topology and increased energy scale, we see performance improvements for both native and embedded problems.” D-Wave did not originally plan to make its prototype available publicly, “but given the early positive results, we wanted to get it into the hands of developers and researchers now for exploration and learning,” Hoskinson says. “It’s about learning from our community to maximize commercial application performance as we build towards the final full-scale Advantage2 quantum computer.” Hoskinson notes that D-Wave is also working on a new fabrication process that should lead to dramatically less noise in the company’s quantum computers, increasing their chances of finding high-quality solutions. “While the prototype was developed in our current rapid-development fabrication stack, the eventual Advantage2 product will be produced in an all-new lower-noise stack,” he says. “We have early results for the new stack that show a seven-times reduction in low-frequency flux noise, a three-times reduction in integrated flux noise, and an order of magnitude reduction in high-frequency flux noise. This will go a long way toward further improving performance in the full Advantage2 system.” D-Wave made the prototype available over its Leap quantum cloud service in June. Charles Q. Choi is a science reporter who contributes regularly to IEEE Spectrum. He has written for Scientific American, The New York Times, Wired, and Science, among others. If technologists can’t perfect it, quantum computers will never be big Dates chiseled into an ancient tombstone have more in common with the data in your phone or laptop than you may realize. They both involve conventional, classical information, carried by hardware that is relatively immune to errors. The situation inside a quantum computer is far different: The information itself has its own idiosyncratic properties, and compared with standard digital microelectronics, state-of-the-art quantum-computer hardware is more than a billion trillion times as likely to suffer a fault. This tremendous susceptibility to errors is the single biggest problem holding back quantum computing from realizing its great promise. Fortunately, an approach known as quantum error correction (QEC) can remedy this problem, at least in principle. A mature body of theory built up over the past quarter century now provides a solid theoretical foundation, and experimentalists have demonstrated dozens of proof-of-principle examples of QEC. But these experiments still have not reached the level of quality and sophistication needed to reduce the overall error rate in a system.","['experimental', 'prototype', 'offer', 'sneak', 'peek', 'quantum', 'computer', 'animation', 'depict', 'concept', 'quantumcomputer', 'company', 'dwave', '’s', 'topology', 'late', 'prototype', 'anneal', 'quantum', 'computer', 'advantage2', 'quantumcompute', 'pioneer', 'dwave', 'release', 'nextgeneration', 'advantage2', 'system', 'company', 'expect', '7000qubit', 'machine', 'powerful', 'quantum', 'computer', 'kind', 'world', 'dwave', 'make', 'experimental', 'prototype', 'advantage2', 'immediately', 'available', 'use', 'cloud', 'classical', 'computer', 'switch', 'transistor', 'symbolize', 'datum', 'one', 'zero', 'contrast', 'quantum', 'computer', 'use', 'quantum', 'bit', 'qubit', 'strange', 'nature', 'quantum', 'physics', 'qubit', 'exist', 'state', 'call', 'superposition', 'essentially', 'time', 'phenomenon', 'let', 'qubit', 'perform', 'calculation', 'qubit', 'mechanically', 'link', 'entangle', 'quantum', 'computer', 'great', 'computational', 'power', 'grow', 'exponential', 'fashion', 'standard', 'approach', 'build', 'quantum', 'computer', 'call', 'gate', 'model', 'involve', 'arrange', 'qubit', 'circuit', 'make', 'interact', 'fix', 'sequence', 'contrast', 'dwave', 'base', 'long', 'focus', 'call', 'anneal', 'quantum', 'computer', 'quantum', 'cousin', 'classical', 'annealing', 'computer', 'machine', 'find', 'low', 'energy', 'state', 'slowly', 'cool', 'much', 'way', 'metal', 'crystal', 'sometimes', 'temper', 'minimize', 'imperfection', 'quantum', 'anneal', 'machine', 'start', 'set', 'qubit', 'interaction', 'low', 'energy', 'state', 'call', 'ground', 'state', 'represent', 'correct', 'answer', 'specific', 'problem', 'researcher', 'program', 'solve', 'give', 'early', 'positive', 'result', 'want', 'get', 'hand', 'developer', 'researcher', 'exploration', 'learning', 'emile', 'hoskinson', 'dwave', 'ideal', 'application', 'anneal', 'quantum', 'computer', 'solve', 'optimization', 'problem', 'say', 'experimental', 'physicist', 'director', 'quantumanneale', 'product', 'dwave', 'seek', 'find', 'good', 'answer', 'possible', 'solution', 'map', 'fast', 'route', 'point', 'point', 'b', 'instance', 'imagine', 'try', 'find', 'low', 'point', 'vast', 'landscape', 'cover', 'hill', 'valley', 'classical', 'computer', 'start', 'random', 'spot', 'surface', 'look', 'around', 'low', 'spot', 'explore', 'walk', 'downhill', 'anymore', 'approach', 'often', 'stick', 'local', 'minimum', 'valley', 'actually', 'low', 'point', 'surface', 'hand', 'anneal', 'quantum', 'computer', 'make', 'possible', 'start', 'many', 'spot', 'surface', 'time', 'reduce', 'chance', 'trap', 'local', 'minimum', 'even', 'essentially', 'tunnel', 'hill', 'see', 'low', 'valley', 'share', 'datum', 'multiple', 'spot', 'find', 'pattern', 'lead', 'deep', 'point', 'found', 'dwave', 'bill', 'world', 'first', 'commercial', 'supplier', 'quantum', 'computer', 'company', 'longprovedcontroversial', 'many', 'critic', 'year', 'question', 'machine', 'powerful', 'regular', 'computer', 'nevertheless', 'dwave', 'claim', 'share', 'highprofile', 'client', 'year', 'sell', 'first', 'quantum', 'computing', 'system', '128qubit', 'dwave', 'ship', 'dwave', 'artificial', 'intelligence', 'lab', 'launch', 'partnership', 'university', 'space', '’s', 'advantage2', 'come', 'online', 'next', 'year', 'year', 'world', 'powerful', 'anneal', 'computer', 'say', 'company', 'release', 'experimental', 'prototype', 'advantage2', 'core', 'functionality', 'fullscale', 'product', 'available', 'test', 'broad', 'portfolio', 'enterprise', 'customer', 'volkswagen', 'saveonfood', 'denso', 'build', 'hundred', 'early', 'quantum', 'application', 'diverse', 'area', 'resource', 'scheduling', 'mobility', 'logistics', 'drug', 'discovery', 'portfolio', 'optimization', 'manufacturing', 'process', 'much', 'say', 'expect', 'advantage2', 'use', 'address', 'problem', 'even', 'great', 'complexity', 'talk', 'address', 'broad', 'swath', 'problem', 'mean', 'improved', 'technology', 'tackle', 'problem', 'large', 'complex', 'cover', 'wide', 'range', 'use', 'case', 'different', 'vertical', 'address', 'problem', 'well', 'fast', 'prototype', 'hold', 'superconducte', 'flux', 'qubit', 'new', 'design', 'qubit', 'enable', 'dwave', 'call', 'zephyrtopology', 'support', '20way', 'interqubit', 'connectivity', 'company', 'prior', 'generation', 'advantage', 'analogy', 'illustrate', 'importance', 'connectivity', 'social', 'network', 'influence', 'complexity', 'interaction', 'grow', 'number', 'connection', 'say', 'complexity', 'mean', 'problem', 'size', 'number', 'variable', 'constraint', 'also', 'mean', 'commercial', 'business', 'application', 'context', 'example', 'particular', 'business', 'need', 'fast', 'timetosolution', 'business', 'demand', 'change', 'schedule', 'supplychain', 'dependency', 'make', 'problem', 'complex', 'see', 'advantage2', 'solve', 'problem', 'well', 'fast', 'address', 'type', 'complex', 'use', 'case', 'new', 'qubit', 'design', 'also', 'support', 'high', 'energy', 'scale', 'make', 'qubit', 'less', 'vulnerable', 'disruption', 'thermal', 'fluctuation', 'turn', 'reduce', 'error', 'rate', 'quantum', 'computation', 'test', 'prototype', 'qubit', 'arrange', 'standard', 'native', 'topology', 'find', 'well', 'solution', 'percent', 'case', 'compare', 'advantage', 'company', 'note', 'come', 'problem', 'require', 'great', 'connectivity', 'qubit', 'multiple', 'qubit', 'link', 'together', 'strategy', 'call', 'embed', 'advantage2', 'great', 'interqubit', 'connectivity', 'lead', 'prototype', 'find', 'betterquality', 'solution', 'advantage', 'percent', 'problem', 'many', 'commercially', 'interesting', 'problem', 'require', 'embed', 'say', 'new', 'advantage2', 'topology', 'increase', 'energy', 'scale', 'see', 'performance', 'improvement', 'native', 'embed', 'problem', 'dwave', 'originally', 'plan', 'make', 'prototype', 'available', 'publicly', 'give', 'early', 'positive', 'result', 'want', 'get', 'hand', 'developer', 'researcher', 'exploration', 'say', '’', 'learn', 'community', 'maximize', 'commercial', 'application', 'performance', 'build', 'final', 'fullscale', 'advantage2', 'computer', 'note', 'dwave', 'also', 'work', 'new', 'fabrication', 'process', 'lead', 'dramatically', 'less', 'noise', 'company', 'quantum', 'computer', 'increase', 'chance', 'find', 'highquality', 'solution', 'prototype', 'develop', 'current', 'rapiddevelopment', 'fabrication', 'stack', 'eventual', 'advantage2', 'product', 'produce', 'allnew', 'lowernoise', 'stack', 'say', 'early', 'result', 'new', 'stack', 'show', 'seventime', 'reduction', 'lowfrequency', 'flux', 'noise', 'threetime', 'reduction', 'integrate', 'flux', 'noise', 'order', 'magnitude', 'reduction', 'highfrequency', 'flux', 'noise', 'go', 'long', 'way', 'far', 'improve', 'performance', 'full', 'advantage2', 'system', 'dwave', 'make', 'prototype', 'available', 'science', 'reporter', 'contribute', 'regularly', 'ieee', 'spectrum', 'write', 'scientific', 'wire', 'science', 'technologist', 'perfect', 'quantum', 'computer', 'never', 'big', 'date', 'chisel', 'ancient', 'tombstone', 'common', 'datum', 'phone', 'laptop', 'realize', 'involve', 'conventional', 'classical', 'information', 'carry', 'hardware', 'relatively', 'immune', 'error', 'situation', 'quantum', 'computer', 'far', 'different', 'information', 'idiosyncratic', 'property', 'compare', 'standard', 'digital', 'microelectronic', 'stateoftheart', 'quantumcomputer', 'hardware', 'time', 'likely', 'suffer', 'fault', 'tremendous', 'susceptibility', 'error', 'single', 'big', 'problem', 'hold', 'quantum', 'computing', 'realize', 'great', 'promise', 'fortunately', 'approach', 'know', 'quantum', 'error', 'correction', 'qec', 'remedy', 'problem', 'least', 'principle', 'mature', 'body', 'theory', 'build', 'past', 'quarter', 'century', 'provide', 'solid', 'theoretical', 'foundation', 'experimentalist', 'demonstrate', 'dozen', 'proofofprinciple', 'example', 'qec', 'experiment', 'still', 'reach', 'level', 'quality', 'sophistication', 'need', 'reduce', 'overall', 'error', 'rate', 'system']"
