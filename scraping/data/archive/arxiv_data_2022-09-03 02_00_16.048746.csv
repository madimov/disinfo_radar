title,url,date,text,cleaning,tokens
Dynamic Memory-based Curiosity: A Bootstrap Approach for Exploration,"[{'href': 'http://arxiv.org/abs/2208.11349v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2208.11349v1', 'rel': 'related', 'type': 'application/pdf'}]",2022-08-24 07:56:12,"2
2
0
2

g
u
A
2
1

]

C
H
.
s
c
[

1
v
3
1
2
6
0
.
8
0
2
2
:
v
i
X
r
a

What is it like to program with artiﬁcial intelligence?

Advait Sarkar
Microsoft Research
University of Cambridge
advait@microsoft.com

Andrew D. Gordon
Microsoft Research
University of Edinburgh
adg@microsoft.com

Carina Negreanu
Microsoft Research
cnegreanu@microsoft.com

Christian Poelitz
Microsoft Research
cpoelitz@microsoft.com

Sruti Srinivasa Ragavan
Microsoft Research
a-srutis@microsoft.com

Ben Zorn
Microsoft Research
ben.zorn@microsoft.com

Figure 1 – Code generation using the GitHub Copilot editor extension. The portion highlighted
in blue has been generated by the model. Left: a function body is generated based on a textual
description in a comment. Right: a set of test cases is generated. Source: copilot.github
.com

Abstract

Large language models, such as OpenAI’s codex and Deepmind’s AlphaCode, can generate code to solve
a variety of problems expressed in natural language. This technology has already been commercialised
in at least one widely-used programming editor extension: GitHub Copilot.

In this paper, we explore how programming with large language models (LLM-assisted programming)
is similar to, and differs from, prior conceptualisations of programmer assistance. We draw upon pub-
licly available experience reports of LLM-assisted programming, as well as prior usability and design
studies. We ﬁnd that while LLM-assisted programming shares some properties of compilation, pair
programming, and programming via search and reuse, there are fundamental differences both in the
technical possibilities as well as the practical experience. Thus, LLM-assisted programming ought to be
viewed as a new way of programming with its own distinct properties and challenges.

Finally, we draw upon observations from a user study in which non-expert end user programmers use
LLM-assisted tools for solving data tasks in spreadsheets. We discuss the issues that might arise, and
open research challenges, in applying large language models to end-user programming, particularly with
users who have little or no programming expertise.

1. Introduction
Inferential assistance for programmers has manifested in various forms, such as programming by demon-
stration, declarative programming languages, and program synthesis (Section 2). Large language models
such as GPT mark a quantitative and qualitative step-change in the automatic generation of code and nat-
ural language text. This can be attributed to cumulative innovations of vector-space word embeddings,
the transformer architecture, large text corpora, and pre-trained language models (Section 3).

1

 
 
 
 
 
 
These models have been commercialised in the form of APIs such as OpenAI Codex, or as programmer-
facing tools such as GitHub Copilot and Tabnine. These tools function as a sort of advanced autocom-
plete, able to synthesize multiple lines of code based on a prompt within the code editor, which may be
natural language (e.g., a comment), code (e.g., a function signature) or an ad-hoc mixture. The capa-
bilities of such tools go well beyond traditional syntax-directed autocomplete, and include the ability to
synthesize entire function bodies, write test cases, and complete repetitive patterns (Section 4). These
tools have reliability, safety, and security implications (Section 5).

Prior lab-based and telemetric research on the usability of such tools ﬁnds that developers generally
appreciate the capabilities of these tools and ﬁnd them to be a positive asset to the development expe-
rience, despite no strong effects on task completion times or correctness. Core usability issues include
the challenge of correctly framing prompts as well as the effort required to check and debug generated
code (Section 6).

Longitudinal experience reports of developers support some of the lab-based ﬁndings, while contradict-
ing others. The challenges of correctly framing prompts and the efforts of debugging also appear here.
However, there are many reports that these tools do in fact strongly reduce task time (i.e., speed up the
development process) (Section 7).

Programming with large language models invites comparison to related ways of programming, such
as search, compilation, and pair programming. While there are indeed similarities with each of these,
the empirical reports of the experience of such tools also show crucial differences. Search, compila-
tion, and pair programming are thus found to be inadequate metaphors for the nature of LLM-assisted
programming; it is a distinct way of programming with its own unique blend of properties (Section 8).

While LLM-assisted programming is currently geared towards expert programmers, arguably the great-
est beneﬁciaries of their abilities will be non-expert end-user programmers. Nonetheless, there are is-
sues with their direct application in end-user programming scenarios. Through a study of LLM-assisted
end-user programming in spreadsheets, we uncover issues in intent speciﬁcation, code correctness, com-
prehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area
(Section 9).

2. Prior conceptualisations of intelligent assistance for programmers
What counts as ‘intelligent assistance’ can be the subject of some debate. Do we select only features that
are driven by technologies that the artiﬁcial intelligence research community (itself undeﬁned) would
recognise as artiﬁcial intelligence? Do we include those that use expert-coded heuristics? Systems that
make inferences a human might disagree with, or those with the potential for error? Mixed-initiative
systems (Horvitz, 1999)? Or those that make the user feel intelligent, assisted, or empowered? While this
debate is beyond the scope of this paper, we feel that to properly contextualise the qualitative difference
made by large language models, a broad and inclusive approach to the term ‘intelligence’ is required.

End-user programming has long been home to inferential, or intelligent assistance. The strategy of
direct manipulation (Shneiderman & Norwood, 1993) is highly successful for certain types of limited,
albeit useful, computational tasks, where the interface being used (“what you see”, e.g., a text editor or
an image editor) to develop an information artefact can represent closely the artefact being developed
(“what you get”, e.g., a text document or an image). However, this strategy cannot be straightforwardly
applied to programs. Programs notate multiple possible paths of execution simultaneously, and they
deﬁne “behaviour to occur at some future time” (Blackwell, 2002b). Rendering multiple futures in the
present is a core problem of live programming research (Tanimoto, 2013), which aims to externalise
programs as they are edited (Basman et al., 2016).

The need to bridge the abstraction gap between direct manipulation and multiple paths of execution led to
the invention of programming by demonstration (PBD) (Kurlander et al., 1993; Lieberman, 2001; Myers,
1992). A form of inferential assistance, PBD allows end-user programmers to make concrete demon-
strations of desired behaviour that are generalised into executable programs. Despite their promise, PBD

2

systems have not achieved widespread success as end-user programming tools, although their idea sur-
vives in vestigial form as various “macro recording” tools, and the approach is seeing a resurgence with
the growing commercialisation of “robotic process automation”.

Programming language design has long been concerned with shifting the burden of intelligence be-
tween programmer, program, compiler, and user. Programming language compilers, in translating be-
tween high-level languages and machine code, are a kind of intelligent assistance for programmers. The
declarative language Prolog aspired to bring a kind of intelligence, where the programmer would only be
responsible for specifying (“declaring”) what to compute, but not how to compute it; that responsibility
was left to the interpreter. At the same time, the language was designed with intelligent applications
in mind. Indeed, it found widespread use within artiﬁcial intelligence and computational linguistics
research (Colmerauer & Roussel, 1996; Rouchy, 2006).

Formal veriﬁcation tools use a speciﬁcation language, such as Hoare triples (Hoare, 1969), and writing
such speciﬁcations can be considered programming at a ‘higher’ level of abstraction. Program synthesis,
in particular synthesis through reﬁnement, aims at intelligently transforming these rules into executable
and correct code. However, the term “program synthesis” is also used more broadly, and programs can
be synthesised from other sources than higher-level speciﬁcations. Concretely, program synthesis by
example, or simply programming by example (PBE), facilitates the generation of executable code from
input-output examples. An example of successfully commercialised PBE is Excel’s Flash Fill (Gulwani,
2011), which synthesises string transformations in spreadsheets from a small number of examples.

The Cognitive Dimensions framework (T. R. Green, 1989; T. Green & Blackwell, 1998) identiﬁes three
categories of programming activity: authoring, transcription, and modiﬁcation. Modern programmer as-
sistance encompasses each of these. For example, program synthesis tools transform the direct authoring
of code into the (arguably easier) authoring of examples. Intelligent code completions (Marasoiu et al.,
2015) support the direct authoring of code. Intelligent support for reuse, such as smart code copy/paste
(Allamanis & Brockschmidt, 2017) support transcription, and refactoring tools (Hermans et al., 2015)
support modiﬁcation. Researchers have investigated inferential support for navigating source code (Hen-
ley & Fleming, 2014), debugging (J. Williams et al., 2020), and selectively undoing code changes (Yoon
& Myers, 2015). Additionally, intelligent tools can also support learning (Cao et al., 2015).

Allamanis et al. (2018) assemble a literature review of research—at the intersection of machine learning,
programming languages, and software engineering—that seeks to adapt methods ﬁrst developed for
natural language, such as language models, to source code. The emergence of large bodies of open
source code, sometimes called “big code”, enabled this research area. Language models are sensitive to
lexical features like names, code formatting, and order of methods, while traditional tools like compilers
or code veriﬁers are not. The authors hypothesise that sensitivity to lexical features matters for software
engineering:

The naturalness hypothesis. Software is a form of human communication; software corpora have
similar statistical properties to natural language corpora; and these properties can be exploited to
build better software engineering tools.

The earliest evidence for this hypothesis goes back to research that used n-gram models to build a
code completion engine for Java that outperformed Eclipse’s completion feature (Hindle et al., 2012,
2016). The survey covers the methods and the applications they enable: recommender systems (such
as code autocompletion), debuggers, code analysers (such as type checkers (Raychev et al., 2015)), and
code synthesizers. These applications constitute intelligence assistance to programmers, but limited
by the capabilities of the underlying language models. We can expect the recent dramatic expansion in
capability of language models, which we discuss next, to magnify the effectiveness of these applications.

3. A brief overview of large language models for code generation
3.1. The transformer architecture and big datasets enable large pre-trained models
In the past decade, natural language processing has evolved both in the development of language models
(LMs) as well as tasks and evaluation. Mikolov et al. (2013) introduced Word2Vec, where vectors are as-

3

signed to words such that similar words are grouped together. This is done by looking at co-occurrences
in free text (like Wikipedia articles) and ignores the fact that words have multiple meanings depend-
ing on context. Long short-term memory (LSTM) neural networks (Hochreiter & Schmidhuber, 1997;
Sutskever et al., 2014) and later encoder-decoder networks, account for order in an input sequence. Self-
attention (Vaswani et al., 2017) signiﬁcantly simpliﬁed the prior networks by replacing each element
in the input by a weighted average of the rest of the input. Transformers combined the advantages of
(multi-head) attention and word embeddings, enriched with positional encodings (they add the order
information to the word embeddings) into one architecture. While there are many alternatives to trans-
formers for language modelling, in this paper when we mention a language model (LM) we will usually
imply a transformer-based language model.

There are large collections of unlabelled text data for the most common natural languages. For example,
the Common Crawl project1 produces around 20 TB of text data (from web pages) monthly, but labelled
task-speciﬁc data is less prevalent. This makes unsupervised training appealing which leads to the
concept of pre-trained LMs (J. Li et al., 2021). Pre-trained LMs are commonly trained to perform next-
word prediction (such as GPT models, e.g. (Brown et al., 2020)) where the model is trained to predict
the next word in a sequence or masked (such as Bert, e.g. (Devlin et al., 2019)) where the model is
trained to ﬁll a gap in a sequence.

Ideally, pre-trained LMs learn general-purpose abilities and knowledge by seeing large amounts of text,
which can then be transferred to downstream language tasks (where we have less labelled data) such as
question answering, ﬁction generation, text summarisation, etc. Fine-tuning is the process of adapting
a given pre-trained LM to different downstream tasks by introducing additional parameters and training
them using task-speciﬁc objective functions. In certain cases the pre-training objective also gets adjusted
to better suit the downstream task. Instead of (or on top of) ﬁne-tuning, the downstream task can be
reformulated to be similar to the original LLM training. In practice, this means expressing the task as
a set of instructions to the LLM via a prompt. So the goal, rather than deﬁning a learning objective
for a given task, is to ﬁnd a way to query the LLM to directly predict for the downstream task. This is
sometimes referred to as Pre-train, Prompt, Predict.2

3.2. Language models tuned for source code generation
The downstream task of interest to us in this paper is code generation, where we provide snippets of
code (including comments) and we want new code to be generated. Unlike other downstream tasks, a
large corpus of data is available from public code repositories such as GitHub. Code generation can be
divided into many sub-tasks, such as type decorators (variable type generation, e.g. (J. Wei et al., 2020)),
code summarization (comment generation, e.g. (Liu et al., 2021)), clone detection (duplicate detection,
e.g (Mou et al., 2016)), code translation (code migration from one language to another e.g. (Nguyen et
al., 2015)) etc. A recent benchmark that covers many tasks is CodeXGLUE (Lu et al., 2021).

LLM technology has brought us within reach of full-solution generation. Codex (Chen, Tworek, Jun,
Yuan, Ponde, et al., 2021), a version of GPT-3 ﬁne-tuned for code generation, can solve in one generation
on average 47/164 problems in the HumanEval code generation benchmark. HumanEval is a set of 164
hand-written programming problems, which include a function signature, docstring, body, and several
unit tests, with an average of 7.7 tests per problem. Smaller models have followed Codex, like GPT-J3
(ﬁne-tuned on top of GPT-2), CodeParrot4 (also ﬁne-tuned on top of GPT-2, targets Python generations),
PolyCoder (Xu, Alon, et al., 2022)(GPT-2 style but trained directly on code).

LLMs comparable in size to Codex include AlphaCode (Y. Li et al., 2022a) and PaLM-Coder (Chowd-
hery et al., 2022). AlphaCode is trained directly on GitHub data and ﬁne-tuned on coding competition
problems. It introduces a method to reduce from a large number of potential solutions (up to millions)

1https://commoncrawl.org/
2http://pretrain.nlpedia.ai/
3https://huggingface.co/docs/transformers/main/model_doc/gptj
4https://huggingface.co/blog/codeparrot

4

Figure 2 – Code generation using the GitHub Copilot editor extension. The portion highlighted in
blue has been generated by the model. Above: a repetitive time computation is extrapolated based
on two examples. Below: function body is generated from the signature and the ﬁrst line. Source:
copilot.github.com

to a handful of candidates (competitions permit a maximum of 10). On a dataset of 10000 programming
problems, if given 5 attempts Codex manages to solve around 3% of the problems versus AlphaCode
which manages around 4-7%. In competitions for which it was ﬁne-tuned (CodeContests) AlphaCode
manages a 34% success rate, on par with the average human competitor.

Despite promising results there are known shortcomings. Models can directly copy code (full solutions
or key parts of the solutions) from the training data, rather than generating new code. Though developers
make efforts to clean and retain only high-quality code, there are no guarantees of correctness and errors
can be directly propagated through generations.

Codex can also produce syntactically incorrect or undeﬁned code, and can invoke functions, variables,
and attributes that are undeﬁned or outside the scope of the codebase. Moreover, Codex struggles to
parse through increasingly long and higher-level or system-level speciﬁcations which can lead to mis-
takes in binding operations to variables (especially when the number of operations and variables in the
docstring is large). Various approaches have been explored to ﬁlter out bad generations or repair them
(especially for syntax errors).

Consistency is another issue and there is a trade-off between non-determinism and generation diversity.
Some parameter settings can control the diversity of generation (i.e., how diverse the different gener-
ations for a single prompt might be), but there is no guarantee that we will get the same generation if
we run the system at different times under the same settings. To alleviate this issue in measurements,
metrics such as pass@k (have a solution that passes the tests within k tries) have been modiﬁed to be
probabilistic.

4. Commercial programming tools that use large language models
OpenAI Codex is a version of GPT that is ﬁne-tuned on publicly available source code (Chen, Tworek,
Jun, Yuan, de Oliveira Pinto, et al., 2021). While Codex itself is not a programmer-facing tool, OpenAI
has commercialised it in the form of an API that can be built upon.

5

Figure 3 – Code generation using the Tabnine editor extension. The grey text after the cursor is
being suggested by the model based on the comment on the preceding line. Source: tabnine.com

Figure 4 – API suggestion using the Visual Studio IntelliCode feature. Source: Silver (2018)

The principal commercial implementation of Codex thus far has been in Github Copilot.5 Copilot is
an extension that can be installed into code editors such as Neovim, Jetbrains, and Visual Studio Code.
Copilot uses Codex, drawing upon the contents of the ﬁle being edited, related ﬁles in the project, and
ﬁle paths or URLs of repositories. When triggered, it generates code at the cursor location, in much the
same way as autocomplete.

To help expand developer expectations for the capabilities of Copilot beyond the previous standard uses
of autocomplete, suggested usage idioms for Copilot include: writing a comment explaining what a
function does, and the function signature, and allowing Copilot to complete the function body; complet-
ing boilerplate code; and deﬁning test cases (Figures 1 and 5). Programmers can cycle between different
generations from the model, and once a particular completion has been accepted it can be edited like any
other code.

As of 23 June 2022, Amazon has announced a Copilot-like feature called CodeWhisperer,6 which also
applies a large language model trained on a corpus of source code to generate autocompletions based
on comments and code. The marketing material describes a set of safety features, such as: detecting
when generated code is similar to code in the training set, detecting known security vulnerabilities in
the generated code, and “removing code that may be considered biased and unfair” (although this latter
claim induces skepticism). At present CodeWhisperer is not widely available and thus little is known of
its use in practice.

Other commercial implementations of AI-assisted autocompletion features include Visual Studio Intel-

5https://copilot.github.com/
6https://aws.amazon.com/codewhisperer/features/

6

licode (Silver, 2018) (Figure 4) and Tabnine (Figure 3)7. These are more limited in scope than Copilot
and their user experience is commensurable to that of using ‘traditional’ autocomplete, i.e., autocom-
plete that is driven by static analysis, syntax, and heuristics.8.The structure of the machine learning
model used by these implementations is not publicly disclosed; however, both rely on models that have
been trained on large corpora of publicly available source code.

It is interesting to note, that despite the wide variety of types of intelligent programmer assistance we
have discussed in Section 2 for several aspects of programming (authoring, transcription, modiﬁcation,
debugging, and learning), commercial implementations of assistance based on large language models
thus far are aimed primarily at authoring. Authoring can be viewed as the ﬁrst natural application of a
generative language model, but the programming knowledge in these models can of course be used for
assisting programmers in other activities, too.

5. Reliability, safety, and security implications of code-generating AI models
AI models that generate code present signiﬁcant challenges to issues related to reliability, safety, and
security. Since the output of the model can be a complex software artifact, determining if the out-
put is “correct” needs a much more nuanced evaluation than simple classiﬁcation tasks. Humans have
trouble evaluating the quality of software, and practices such as code review, applying static and dy-
namic analysis techniques, etc., have proven necessary to ensure good quality of human-written code.
Current methods for evaluating the quality of AI-generated code, as embodied in benchmarks such as
HumanEval (Chen, Tworek, Jun, Yuan, de Oliveira Pinto, et al., 2021), MBPP (Austin et al., 2021), and
CodeContests (Y. Li et al., 2022b), determine functional correctness of entire functions based on a set
of unit tests. Such evaluation approaches fail to consider issues of code readability, completeness, or the
presence of potential errors that software developers constantly struggle to overcome.

Previous work (Chen, Tworek, Jun, Yuan, de Oliveira Pinto, et al., 2021) explores numerous implications
of AI models that generate code, including issues of over-reliance, misalignment (the mismatch between
what the user prompt requests and what the user really wants), bias, economic impact, and security
implications. While these topics each are extensive and important, due to space limitations we only
brieﬂy mention them here and point to additional related work when possible. Over-reliance occurs
when individuals make optimistic assumptions about the correctness of the output of an AI model,
leading to harm. For code generating models, users may assume the code is correct, has no security
vulnerabilities, etc. and those assumptions may lead to lower quality or insecure code being written and
deployed. Existing deployments of AI models for code, such as GitHub Copilot (Ziegler, 2021), have
documentation that stresses the need to carefully review, test, and vet generated code just as a developer
would vet code from any external source. It remains to be seen if over-reliance issues related to AI code
generation will result in new software quality challenges.

Since AI that generates code is trained on large public repositories, there is potential for low-quality
training data to inﬂuence models to suggest low-quality code or code that contains security vulnera-
bilities. One early study of GitHub Copilot (Pearce et al., 2021) examines whether code suggestions
may contain known security vulnerabilities in a range of scenarios and ﬁnds cases where insecure code
is generated. Beyond carefully screening new code using existing static and dynamic tools that detect
security vulnerabilities in human-generated code, there are also possible mitigations that can reduce the
likelihood that the model will make such suggestions. These include improving the overall quality of the
training data by removing low-quality repositories, and ﬁne-tuning the large-language model speciﬁcally
to reduce the output of known insecure patterns.

6. Usability and design studies of AI-assisted programming
Vaithilingam et al. (2022) conducted a within-subjects comparative study (n=24) of Github Copilot,

7https://www.tabnine.com/
8As of 15 June 2022, Tabnine has announced a shift to language model-driven autocompletion that more closely resembles

the abilities of Copilot (Weiss, 2022).

7

comparing its user experience to that of traditional autocomplete (speciﬁcally, the Intellisense plugin,
not the same as the Intellicode feature mentioned previously). Participants failed to complete the tasks
more often with Copilot than with Intellisense, and there was no signiﬁcant effect on task completion
time. Perhaps unsurprisingly, the authors ﬁnd that assessing the correctness of generated code is difﬁcult
and an efﬁciency bottleneck, particularly when the code generated has a fundamental ﬂaw or inefﬁciency
that leads the programmer on an ultimately unsuccessful ‘wild goose chase’ of repair or debugging.
However, the overwhelming majority (19 of 24) of participants reported a strong preference for Copilot
in a post-task survey. While participants were less conﬁdent about the code generated by Copilot, they
almost universally (23 of 24) perceived it as more helpful, because it had the potential for generating
useful starting points and saving the programmer the effort of searching online for documented solutions
that could be the basis for reuse.

Ziegler et al. (2022) conducted a survey (n=2,047) of the perceived productivity of Copilot users in
the USA. They matched these to telemetric usage measurements of the Copilot add-in, which included
metrics such as how often an auto-completion was shown, how often it was accepted, how often it per-
sisted unchanged in the document for a certain time period, how often it persisted with minor variations
(e.g., measured by Levenshtein distance) and so on. They ﬁnd that the acceptance rate (the ratio of ac-
cepted suggestions to shown suggestions) is the strongest predictor of users’ perceived productivity due
to Copilot. Fascinatingly, they ﬁnd that the pattern of acceptance rates for all users in aggregate follows
a daily and weekly “circadian” rhythm, such that users are more likely to accept Copilot completions
out of working-hours and on weekends. However, for any given user, the acceptance rate depends on
that user’s normal working hours; suggestions outside of normal working hours are less likely to be
accepted. Future work is needed to see whether this ﬁnding replicates, and if so to establish how and
why acceptance rates are so signiﬁcantly affected by working hours.

Xu, Vasilescu, & Neubig (2022) conducted a within-subjects study (n=31) comparing the programming
experience with and without a code generation plugin. Their experimental plugin takes the form of a
text ﬁeld in which the user enters a natural language prompt, the system responds with a list of code
snippets, and when clicked the desired snippet is inserted at the cursor. This workﬂow differs from
Copilot’s, where the ‘prompt’ is text within the source ﬁle, and can contain a mix of natural language
comments and code. The plugin supported both code generation (using a tree-based neural network) and
code snippet retrieval (searching the programming forum Stack Overﬂow). Results from both generation
and retrieval are shown in the same list, but visually demarcated. The authors found no signiﬁcant effect
of the plugin on task completion time or program correctness. They found that simple queries were more
likely to be answered correctly through generation, and more complex queries requiring multiple steps
were more likely to be answered correctly though retrieval, and that it was possible to predict which
approach would succeed based on the word content of the queries. Further, they found that most (60%)
natural language queries that participants wrote in their experiment were not sufﬁciently well-speciﬁed
for a human expert to write code implementing those intents. Retrieved snippets were edited more
often than generated snippets, mostly to rename identiﬁers and choose different parameters. In a post-
experiment survey, participants reported mostly feeling neutral or somewhat positive (30 of 31). These
participants felt that the plugin was helpful for ﬁnding snippets they were aware of but cannot recall,
and less disruptive than using a browser, but the interaction worked better when the developer had a
pre-existing knowledge of the target APIs and frameworks, and it took experimentation to understand
the “correct way” to formulate queries. There was no clear indication of preference between retrieval
and generation.

Jiang et al. (2022) developed an LLM-based tool for converting natural language statements to code.
As in Xu, Vasilescu, & Neubig (2022), prompts are entered in a pop-up dialog invoked at the cursor
from within a code editor, rather than as comments. In a study (n = 14), participants were given a week
to complete two website-building tasks with the tool, while recording the screen, and were interviewed
afterwards. As in other studies, participants saw utility in the tool for facilitating quick API lookups
and for writing boilerplate code. They found that novice programmers’ queries were mainly natural

8

for
Figure 5 – Searching for code snippets using Bing Developer Assistant.
Stack Overﬂow is shown. Note how the query “generate md5 hash from string
@line” contains a hint about the identiﬁer line, which is used to rewrite the retrieved
snippet. Source: https://www.microsoft.com/en-us/research/publication/
building-bing-developer-assistant/

A result

language, whereas experts were more likely to mix code into their requests. While some queries were
abstract, and expressed high-level goals, most had low granularity, being “roughly equivalent to a line
of code”. To cope with model failures, participants used a variety of strategies to reword their query,
such as reducing the scope of the request or replacing words with alternatives, but no particular strategy
was observed to be more effective than any other. Participants struggled with forming a mental model of
what the model can understand and the “syntax” of the language it required – this is precisely the fuzzy
abstraction matching problem we described earlier, which the authors call an “uncanny valley”. The
authors suggest possible solutions such as automated rewording of prompts, suggesting simpler tasks,
suggesting task breakdowns, and better onboarding and tutorials.

Barke et al. (2022) studied how programmers (n = 20) use GitHub Copilot to complete short program-
ming tasks in Python, Rust, Haskell, and Java. Through analysis of screen recordings, the authors
identifed two primary modes of interaction with Copilot: acceleration, where the programmer has a
well-formed intent and Copilot speeds up code authoring in “small logical units”, and exploration, where
Copilot suggestions are used to assist the planning process, “help them get started, suggest potentially
useful structure and API calls, or explore alternative solutions”. In acceleration, long code suggestions,
which take time to read and evaluate, can break the programmer’s ﬂow. Participants developed heuristics
for quickly scanning suggestions, such as looking for the presence of certain keywords. In exploration,
participants were more likely to prompt using purely natural language comments, rather than a mix of
comments and code. Moreover, these prompt comments were often ‘cleaned’ subsequent to accepting a
suggestion, which implies a form of ‘instruction language’ that is separate from ‘explanation language’.

The Bing Developer Assistant (Y. Wei et al., 2015; Zhang et al., 2016) (also referred to as Bing Code
Search) was an experimental extension for Visual Studio initially released in 2015. It enabled an in-IDE,
identiﬁer-aware search for code snippets from forums such as Stack Overﬂow. It had the ability to rewrite
retrieved code to use identiﬁers from the programmer’s current ﬁle. A user study (n=14) comparing task
time in performing 45 short programming tasks with the extension versus regular web search found on
average 28% of time was saved with the extension. Morever telemetry data gathered over three weeks
(representing around 20,000 users and around 3,000 queries per day) showed that several programmers
used the feature frequently. Some used it repeatedly for related problems in quick succession, showing
its use in multi-step problems. Others issued the same query multiple times on separate days, suggesting

9

that the speed of auto-completion was useful even if the programmer knew the solution.

7. Experience reports
At present, there is not a lot of research on the user experience of programming with large language
models beyond the studies we have summarised in Section 6. However, as the availability of such tools
increases, professional programmers will gain long-term experience in their use. Many such program-
mers write about their experiences on personal blogs, which are then discussed in online communities
such as Hacker News. Inspired by the potential for these sources to provide rich qualitative data, as
pointed out by Barik (Barik et al., 2015; Sarkar et al., 2022), we draw upon a few such experience
reports. A full list of sources is provided Appendix A; below we summarise their key points.

7.1. Writing effective prompts is hard
As with several other applications of generative models, a key issue is the writing of prompts that in-
crease the likelihood of successful code generation. The mapping that these models learn between
natural language and code is very poorly understood. Through experimentation, some have developed
heuristics for prompts that improve the quality of the code generated by the model. One developer, after
building several applications and games with OpenAI’s code-davinci model (the second generation
Codex model), advises to “number your instructions” and creating “logic ﬁrst” before UI elements.
Another, in using Copilot to build a classiﬁer for natural language statements, suggests to provide “more
detail” in response to a failure to generate correct code. For example, when asking Copilot to “bina-
rize” an array fails, they re-write the prompt to “turn it into an array where [the ﬁrst value] is 1 and
[the second value] is 0” – effectively pseudocode – which generates a correct result.

Commenters on Hacker News are divided on the merits of efforts invested in developing techniques for
prompting. While some see it as a new level of abstraction for programming, others see it as indirectly
approaching more fundamental issues that ought to be solved with better tooling, documentation, and
language design:

“You’re not coding directly in the language, but now you’re coding in an implicit language provided
by Copilot. [...] all it really points out is that code documentation and discovery is terrible. But I’m
not for sure writing implicit code in comments is really a better approach than seeking ways to make
discovery of language and library features more discoverable.”

“[...] the comments used to generate the code via GitHub Copilot are just another very inefﬁcient
programming language.”

“[Responding to above] There is nonetheless something extremely valuable about being able to
write at different levels of abstraction when developing code. Copilot lets you do that in a way that
is way beyond what a normal programming language would let you do, which of course has its own,
very rigid, abstractions. For some parts of the code you’ll want to dive in and write every single line
in painstaking detail. For others [...] [Copilot] is maybe enough for your purposes. And being able
to have that ability, even if you think of it as just another programming language in itself, is huge.”

Being indiscriminately trained on a corpus containing code of varying ages and (subjective) quality has
drawbacks; developers encounter generated code which is technically correct, but contains practices
considered poor such as unrolled loops and hardcoded constants. One Copilot user found that:

“Copilot [...] has made my code more verbose. Lines of code can be liabilities. Longer ﬁles to parse,
and more instances to refactor. Before, where I might have tried to consolidate an API surface, I
ﬁnd myself maintaining [multiple instances].”

Another Copilot user reﬂected on their experience of trying to generate code that uses the fastai API,
which frequently changes:

“[...] since the latest version of fastai was only released in August 2020, GitHub Copilot was not able
to provide any relevant suggestions and instead provided code for using older versions of fastai. [...]
To me, this is a major concern [...] If we are using cutting edge tools [...] Copilot has no knowledge
of this and cannot provide useful suggestions.”

On the other hand, developers can also be exposed to better practices and APIs through these models.
The developer that found Copilot to make their code more verbose also observed that:

10

“Copilot gives structure to Go errors . [...] A common idiom is to wrap your errors with a context
string [which can be written in an inconsistent, ad-hoc style] [...] Since using Copilot, I haven’t
written a single one of these error handling lines manually. On top of that, the suggestions follow
a reasonable structure where I didn’t know structure had existed before. Copilot showed me how
to add structure in my code in unlikely places. For writing SQL, it helped me write those annoying
foreign key names in a consistent format [...]

[Additionally,] One of the more surprising features has been [that] [...] I ﬁnd myself discovering
new API methods, either higher-level ones or ones that are better for my use case.”

In order to discover new APIs, of course, the APIs themselves need to be well-designed. Indeed, in
some cases the spectacular utility of large language models can be largely attributed to the fact that API
designers have already done the hard work of creating an abstraction that is a good ﬁt for real use cases
(Myers & Stylos, 2016; Piccioni et al., 2013; Macvean et al., 2016). As a developer who used Copilot
to develop a sentiment classiﬁer for Twitter posts matching certain keywords remarks, “These kinds of
things are possible not just because of co pilot [sic] but also because we have awesome libraries which
have abstracted a lot of tough stuff.” This suggests that API design, not just for human developers but
also as a target for large language models, will be important in the near and mid-term future.

Moreover, breaking down a prompt at the ‘correct’ level of detail is also emerging as an important
developer skill. This requires at least some familiarity, or a good intuition, for the APIs available.
Breaking down prompts into steps so detailed that the programmer is effectively writing pseudocode,
can be viewed as an anti-pattern, and can give rise to the objections cited earlier that programming via
large language models is simply a “very inefﬁcient programming language”. We term this the problem
of fuzzy abstraction matching. The problem of ﬁguring out what the system can and can’t do, and
matching one’s intent and instructions with the capabilities of the system, is not new – it has been
well-documented in natural language interaction (Mu & Sarkar, 2019; Luger & Sellen, 2016). It is also
observed in programming notation design as the ‘match-mismatch’ hypothesis (T. R. Green & Petre,
1992; Chalhoub & Sarkar, 2022). In the broadest sense, these can be seen as special cases of Norman’s
“gulf of execution” (Hutchins et al., 1985), perhaps the central disciplinary problem of ﬁrst and second-
wave (Bødker, 2015) human-computer interaction research: ‘how do I get the computer to do what I
want it to do?’.

What distinguishes fuzzy abstraction matching from previous incarnations of this problem is the re-
silience to, and accommodation of, various levels of abstraction afforded by large language models. In
previous natural language interfaces, or programming languages, the user needed to form an extremely
speciﬁc mental model before they could express their ideas in machine terms. In contrast, large lan-
guage models can generate plausible and correct results for statements at an extremely wide range of
abstraction. In the context of programming assistance, this can range from asking the model to write
programs based on vague and underspeciﬁed statements, requiring domain knowledge to solve, through
to extremely speciﬁc and detailed instructions that are effectively pseudocode. This ﬂexibility is ulti-
mately a double-edged sword: it has a lower ﬂoor for users to start getting usable results, but a higher
ceiling for getting users to maximum productivity.

In the context of programming activities, exploratory programming, where the goal is unknown or ill-
deﬁned (Kery & Myers, 2017; Sarkar, 2016), does not ﬁt the framing of fuzzy abstraction matching (or
indeed any of the variations of the gulf of execution problem). When the very notion of a crystallised
user intent is questioned, or when the design objective is for the system to inﬂuence the intent of the user
(as with much designerly and third-wave HCI work), the fundamental interaction questions change. One
obvious role the system can play in these scenarios is to help users reﬁne their own concepts (Kulesza et
al., 2014) and decide what avenues to explore. Beyond noting that such activities exist, and fall outside
the framework we have proposed here, we will not explore them in greater detail in this paper.

7.2. The activity of programming shifts towards checking and unfamiliar debugging
When code can be generated quickly, as observed with the studies in Section 6, checking the correctness
of generating code becomes a major bottleneck. This shift, or tradeoff, of faster authoring at the expense

11

of greater time spent checking code, is not without criticism. For some it is the wrong balance of
priorities between system and programmer.

Correspondingly, some users have developed heuristics for when the cost of evaluating the correctness
of the code is greater than the time or effort saved by code generation, such as to focus on very short
(e.g., single line) completions and ignore longer completions.

Furthermore, some users have found that rather than having suggestions show all the time, which can
be distracting and time consuming, more intentional use can be made of Copilot by switching off auto-
suggestion and only triggering code completion manually using a keyboard shortcut. However, this
requires users to form a mental model of when Copilot is likely to help them in their workﬂow. This
mental model takes time and intentionality to build, and may be incorrect. Moreover, it introduces a
new cognitive burden of constantly evaluating whether the current situation would beneﬁt from LLM
assistance. Commenters on Hacker News raise these issues:

“I ﬁnd I spend my time reviewing Copilot suggestions (which are mostly wrong) rather than thinking
about code and actually doing the work.”

“[...] It’s much quicker to read code than to write it. In addition, 95% of Copilots suggestions are a
single line and they’re almost always right (and also totally optional).[...] I admit that I’m paranoid
every time it suggests more than 2 lines so I usually avoid it. [...] I’ve run into Copilot induced
headaches twice. Once was in the ﬁrst week or so of using it. I sweared off [sic] of using it for
anything more than a line then. Eventually I started to ease up since it was accurate so often and
then I learned my second lesson with another mistake. [...]”

“[...] writing code is not the bottleneck in need of optimization. Conceiving the solution is. Any time
“saved” through Copilot and it’s ilk is immediately nulliﬁed by having to check it’s correctness.
[...]”

“What I want is a copilot that ﬁnds errors [...] Invert the relationship. I don’t need some boilerplate
generator, I need a nitpicker that’s smarter than a linter. I’m the smart thinker with a biological
brain that is inattentive at times. Why is the computer trying to code and leaving mistake catching
to me? It’s backwards.”

“I turned off auto-suggest and that made a huge difference. Now I’ll use it when I know I’m doing
something repetitive that it’ll get easily, or if I’m not 100% sure what I want to do and I’m curious
what it suggests. This way I get the help without having it interrupt my thoughts with its suggestions.”

Another frequent experience is that language models can introduce subtle, difﬁcult to detect bugs, which
are not the kind that would be introduced by a human programmer writing code manually. Thus, existing
developer intuitions around the sources of errors in programs can be less useful, or even misleading,
when checking the correctness of generated code.

One developer reported their experience of having an incorrect, but plausible-sounding ﬁeld name sug-
gested by Copilot (accessTokenSecret instead of accessSecret) and the consequent wild
goose chase of debugging before discovering the problem. As sources of error, these tools are new,
and developers need to learn new craft practices for debugging. “There are zero places that can teach
you those things. You must experience them and unlock that kind of knowledge.”, the developer con-
cludes, “Don’t let code completion AI tools rule your work. [...] I don’t blame [Copilot] for this. I
blame myself. But whatever. At least I got some experience.”. Commenters on Hacker News report
similar experiences:

“[...] The biggest problem I’ve had is not that it doesn’t write correctly, it’s that it think it knows
how and then produce good looking code at a glance but with wrong logic. [...]”

“[...] it has proved to be very good at producing superﬁcially appealing output that can stand up
not only to a quick scan, but to a moderately deep reading, but still falls apart on a more careful
reading. [...] it’s an uncanny valley type effect. [...] it’s almost the most dangerous possible iteration
of it, where it’s good enough to fool a human functioning at anything other than the highest level
of attentiveness but not good enough to be correct all the time. See also, the dangers of almost
self-driving cars; either be self-driving or don’t but don’t expect halfway in between to work well.”

12

“[...] The code it generates _looks_ right but is usually wrong in really difﬁcult to spot ways but
things you’d never write yourself.”

Many developers reported concerns around such tools repeating private information, or repeating copy-
righted code verbatim, which might have implications for the licenses in their own projects. Notions of
the dangers of such “stochastic parrots” (Bender et al., 2021) are not new and have been well-explored,
and are not as directly connected to the user experience of programming assistance as some of the other
concerns we have listed here. As such, we will not enter that discussion in depth here, except to mention
that these concerns were present in several blog articles and online discussions.

Thus, in practice, programmers describe the challenges of writing effective prompts, misinterpreted
intent, code that includes subtle bugs or poor programming practices, the burden of inspecting and
checking that generated code is correct, and worries about private information, plagiarism and copyright.

7.3. These tools are useful for boilerplate and code reuse
Despite the challenges we have described so far in this section, the utility of these tools in certain contexts
is undeniable, and some programmers report having developed workﬂows, in certain contexts, that are
heavily dependent on AI assistance. Particularly for simple tasks that require a lot of “boilerplate”
code, or common tasks for which there are likely to be snippets of code online which prior to these AI
assistants would have required a web search to retrieve. Hacker News commenters write:

“These days not having Copilot is a pretty big productivity hit to me. The other day Copilot somehow
stopped offering completions for maybe an hour, and I was pretty shocked to realize how much I’ve
grown to rely on just hitting tab to complete the whole line. (I was writing Go at the time which is
on the boilerplatey side among the mainstream languages, so Copilot is particularly effective [...]”

“I use GTP-3 codex [sic] daily when working. It saves me time, helps me explore unfamiliar lan-
guages and APIs and generates approaches to solve problems. It can be shockingly good at coding
in narrow contexts. It would be a mistake to miss the developments happening in this area”

“[...] for a lot of quick programming questions, I’m ﬁnding I don’t even need a search engine. I just
use Github Copilot. For example, if I wanted to remember how to throw an exception I’d just write
that as a comment and let Copilot ﬁll in the syntax. Between that and ofﬁcial docs, don’t need a ton
else.”

“[...] It’s changing the way I write code in a way that I can already tell is allowing me to be much
lazier than I’ve previously been about learning various details of languages and libraries. [...]”

“[...] Github Copilot [...] pretty much replaced almost my entire usage of Stack Overﬂow.[...]”

“[...] GitHub Copilot really shines in rote work: when it can correctly infer what you are about to
do, it can and will assist you correctly. It’s not able to make big decisions, but in a pinch, it might
be able to give hints. [...] If used right, Copilot can give developers a signiﬁcant velocity boost,
especially in greenﬁeld projects where there is lots and lots of boilerplate to write. [...]”

8. The inadequacy of existing metaphors for AI-assisted programming
8.1. AI assistance as search
In research studies, as well as in reports of developer experiences, comparisons have been drawn between
the nature of AI programming assistance and programming by searching and reusing code from the
Internet (or from institutional repositories, or from the same project, or from a developer’s previous
projects).

The comparison between AI programming assistance and search is a natural one, and there are many
similarities. Superﬁcially, both have a similar starting point: a prompt or query that is predominantly
natural language (but which may also contain code snippets). From the user perspective, both have an
information asymmetry: the user does not know precisely what form the result will take. With both
search and AI assistance, for any given query, there will be several results, and the user will need to
invest time evaluating and comparing them. In both cases, the user may only get an inexact solution, or
indeed nothing like what they want, and the user may need to invest time adapting and repairing what
they get.

13

However, there are differences. When searching the web, programmers encounter not just code, but a
variety of types of results intermingled and enmeshed. These include code snippets interspersed with
human commentary, perhaps discussions on forums such as Stack Overﬂow, videos, and images. A
search may return new APIs or libraries related to the query, thus showing results at different levels of
abstraction. Search has signals of provenance: it is often (though not always) possible to determine
the source of a code snippet on the web. There is a lot of information scent priming to assist with the
information foraging task (Srinivasa Ragavan et al., 2016). In this way, programming with search is a
mixed media experience.

In contrast, programming with large language models can be said to be a ﬁxed media experience. The
only output is tokens (code, comments, and data) that can be represented within the context of the code
editor. This has some advantages: the increased speed of code insertion (which is the immediate aim)
often came up in experience reports. However, the learning, exploration, and discovery, and access to a
wide variety of sources and media types that occurs in web search is lost. Provenance, too is lost: it is
difﬁcult to determine whether the generation is original to the model, or a stochastic parroting (Bender
et al., 2021; Ziegler, 2021). Moreover, due to privacy, security, and intellectual property concerns, the
provenance of code generated by large language models may be withheld or even destroyed (Sarkar,
2022). This suggests that in future assistance experiences, mixed-media search might be integrated into
programmer assistance tools, or the models themselves might be made capable of generating more types
of results than the simple code autocomplete paradigm of current tools.

8.2. AI assistance as compilation
An alternative perspective is that AI assistance is more like a compiler.
In this view, programming
through natural language prompts and queries is a form of higher-level speciﬁcation, that is ‘compiled’
via the model to the source code in the target language, which is lower level.

Let us (crudely) assume that as programming notations travel along the abstraction continuum from
‘lower’ to ‘higher’ levels, the programmer becomes, ﬁrstly, less concerned with the mechanistic details
of program execution, and secondly, more and more declarative, specifying what computation is required
rather than how to compute it. In general, these are desirable properties of programming notations, but
they do not always make the activity of programming easier or more accessible. As people who write
code in declarative languages or formal veriﬁcation tools will tell you, it’s often much more difﬁcult to
specify the what than the how. The much more broadly adopted practice of test-driven development is
adjacent; while tests are not necessarily written in a higher-level language than the code, they aim to
capture a higher-level notion of correctness, the what of the problem being solved. Learning to be a
test engineer takes time and experience, and the entire distinct career path of “software engineer in test”
attests to the specialised requirements of programming at higher levels of abstraction.

Some would draw a distinction between programming in a speciﬁcation language and a compiled pro-
gramming language. Tony Hoare himself considers these different, on the grounds that while a compiler
only aims to map a program from the source language into a ﬁnite set of valid programs in the target
language, a speciﬁcation might be satisﬁed by an inﬁnite number of valid programs (pers comm., ﬁrst
author, ca. 2014). Thus the technical and interaction design problems of programming through speciﬁ-
cation reﬁnement encompasses, but is much broader than, the technical and interaction design problems
of compilers. While we acknowledge this distinction, there is insufﬁcient empirical evidence from the
experience reports summarised in Section 7 that working programmers themselves consistently make a
meaningful distinction between these concepts.

Programming with large language models, like in a higher-level notation, also allows the programmer to
be less concerned with details of the target language. For example, developers in our experience reports
relied on AI assistance to ﬁll in the correct syntax, or to discover and correctly use the appropriate API
call, thus allowing them to focus on higher-level aspects of the problem being solved. However, there
are fundamental differences between this experience and the experience of using a compiler. First, the
abstraction is not complete, i.e., a programmer cannot completely be unaware of the target language, they

14

must still be able to understand and evaluate the generated code in order to use such tools effectively.
With compilers, although knowledge of the target language can help experienced developers in certain
circumstances, it is far from a prerequisite for effective usage. Moreover, compilers can be relied on
almost universally to generate a correct and complete translation from source to target language, whereas
programming with AI assistance involves the active checking and adaptation of translated code. Next,
compilers are (comparatively) deterministic, in that they consistently produce the same output for the
same input, but this is not the case for current AI programming tools (although this is not a fundamental
limitation, and consistency can be enforced). Finally, though they are often criticised for being cryptic
and unhelpful (Barik et al., 2018), compilers do offer levels of interaction and feedback through warnings
and error messages, which help the programmer improve the code in the source language; there is
currently no such facility with AI programming tools and this strikes us as an area with potential for
innovation.

Perhaps more profoundly, while natural language can be used to express concepts at a higher abstraction
level, the range of abstraction expressible in natural language is much wider than with other forms of
programming notation. Traditional programming notations with ad-hoc abstraction capabilities (subrou-
tines, classes, etc.) allow programmers to manually raise the level of abstraction of their own code and
APIs. But with code generated by language models, as we have seen from the reports in Section 7, a
prompt can span the gamut from describing an entire application in a few sentences, to painstakingly
describing an algorithm in step-by-step pseudocode. Thus it would be a mistake to view programming
with AI assistance as another rung on the abstraction ladder. Rather, it can be viewed as a device that
can teleport the programmer to arbitrary rungs of the ladder as desired.

We close the discussion on AI assistance as a compiler with a few miscellaneous notes. The idea of
using natural language as a programming notation has a long history (e.g., (Miller, 1981; Lieberman
& Liu, 2006)), which we will not cover here. However, it is notable that there are many ways that
natural language has been integrated with programming, such as debugging (Ko & Myers, 2004). With
large language models, there are better capabilities for inference of intent and translation to code, but
therefore also the potential to open up new strategies for inspecting and explaining code. There are also
new failure modes for this paradigm of programming.

8.3. AI assistance as pair programming
The third common perspective is that AI-assisted programming is like pair programming. GitHub Copi-
lot’s commercial tagline describes it as “your AI pair programmer”. As opposed to search and compi-
lation, which are both relatively impersonal tools, the analogy with pair programming is evocative of a
more bespoke experience; assistance from a partner that understands more about your speciﬁc context
and what you’re trying to achieve. AI-assisted programming does have the potential to be more person-
alised, to the extent that it can take into consideration your speciﬁc source code and project ﬁles. As
Hacker News commenters write:

“[...] at one point it wrote an ENTIRE function by itself and it was correct. [...] it wasn’t some dumb
boilerplate initialization either, it was actual logic with some loops. The context awareness with it
is off the charts sometimes.[...]”

“[...] It’s like having the stereotypical “intern” as an associate built-in to your editor. [...] It’s also
ridiculously ﬂexible. When I start writing graphs in ASCII (cause I’m just quickly writing something
down in a scratch ﬁle) it’ll actually understand what I’m doing and start autocompleting textual
nodes in that ASCII graph.”

Besides personalisation, the analogy also recalls the conventional role-division of pair programming
between “driver” and “navigator”. When programming, one needs to form mental models of the program
at many layers: from the speciﬁc statement being worked on, to its context in a subroutine, to the role
that subroutine plays in a module, to the module within the program. However, code must be written at
the statement level, which forces developers to keep this lowest level constantly at the forefront of their
working memory. Experienced developers spend more time mapping out their code so that they can
spend less time writing it. Research into code display and navigation has explored how different ways

15

of presenting lines of code can help programmers better keep these different layers of mental models in
mind (Henley & Fleming, 2014). Pair programming, the argument goes, allows two partners to share the
burden of the mental model. The driver codes at the statement and subroutine level while the navigator
maps out the approach at the module and program level.

By analogy to pair programming, the AI assistant taking the role of the driver, a solo programmer can
now take the place of the navigator. But as we have seen, the experience of programming with AI
assistance does not consistently absolve the human programmer of the responsibility for understanding
the code at the statement and subroutine level. The programmer may be able to become “lazier [...]
about learning various details of syntax and libraries”, but the experience still involves much greater
statement-level checking.

While a pair programming session requires a conscious, negotiated decision to swap roles, a solo pro-
grammer with an AI assistant might ﬁnd themselves ﬂuidly traversing the spectrum from driving to
navigation, from one moment to the next. This may partially explain why, in a preliminary experiment
(n=21) comparing the experience of “pair programming” with GitHub Copilot to programming in a hu-
man pair either as driver or navigator, Imai (2022) ﬁnds that programmers write more lines of code with
Copilot than in a human pair, but these lines are of lower quality (more are subsequently deleted).

Moreover, meta-analyses of pair programming have shown mixed efﬁcacy of human pair programming
on task time, code quality and correctness (Salge & Berente, 2016; Hannay et al., 2009), suggesting
that emulating the pair programming experience is not necessarily a good target to aim for. Multiple
studies have concluded that the apparent successes of pair programming can be attributed, not to the
role division into driver and navigator, but rather the high degree of verbalisation that occurs when pair
programmers are forced to rationalise their decisions to each other (Hannay et al., 2009). Others have
found that programming in pairs induces greater focus out of a respect for shared time; pair programmers
are less likely to read emails, surf the web, or take long phone calls (L. A. Williams & Kessler, 2000).
These particular beneﬁts of pair programming are not captured at all by AI assistance tools.

The comparison to pair programming is thus relatively superﬁcial, and today’s experience of AI-assisted
programming is not comparable with pair programming to the same extent as it is with search or compi-
lation.

8.4. A distinct way of programming
LLM-assisted programming assistance bears similarities to search: both begin with a prompt, both have
an information asymmetry, there are several results, with inexact solutions. But there are differences:
search is mixed-media, whereas LLM assistance is ﬁxed. Search (often) has provenance, and language
models do not.

It also bears similarities to compilation and programming by speciﬁcation. Both enable programming at
a ‘higher’ level of abstraction (for some deﬁnition of higher). Yet unlike with compilers, a programmer
using AI assistance must still have a working knowledge of the target language, they must actively check
the output for correctness, and they get very little feedback for improving their ‘source’ code.

It also bears a superﬁcial similarity to pair programming, in that it promises to let the programmer take
the role of ‘navigator’, forming high-level mental models of the program while delegating the role of
‘driver’ to the language model. But unlike with pair programming, the human navigator must often hop
into the driver’s seat. And unlike with pair programming, LLM-assisted programming does not require
verbalisation, nor does it coerce greater focus out of a respect for shared time.

Thus existing metaphors do not completely capture the experience of LLM-assisted programming. It
is emerging as a distinct way of programming. It does not quite strike us as a distinct practice of pro-
gramming, as that term has been applied to communities of programmers united by similar ethos and
aims, such as enterprise software engineers, bricoleurs, live coders, and code benders; but as Bergström
& Blackwell (2016) note, there are no clear criteria by which we can deﬁne the boundaries of a prac-
tice. Nor does it strike us as being a new activity of programming as per the cognitive dimensions

16

Figure 6 – GridBook interface showing natural language formula in the spreadsheet grid.

framework, since AI assistance is clearly orthogonal to authoring, transcription, and modiﬁcation, being
applicable to each of these activities and others besides. Yet as a way of programming it seems to affect
programmer’s experience more profoundly than a feature such as autocomplete, having far-reaching im-
pact on their attitudes and practices of authoring, information foraging, debugging, refactoring, testing,
documentation, code maintenance, learning, and more.

9. Issues with application to end-user programming
The beneﬁts and challenges of programming with LLMs discussed so far concern the professional pro-
grammer, or a novice programmer in training. They have formal training in programming and, often,
some understanding of the imperfect nature of AI-generated code. But the majority of people who pro-
gram do not fall into this category. Instead, they are ordinary end users of computers who program to an
end. Such end-user programmers often lack knowledge of programming, or the workings of AI. They
also lack the inclination to acquire those skills.

It is reasonable to say that such end-user programmers (e.g., accountants, journalists, scientists, business
owners) stand to beneﬁt the most from AI assistance, such as LLMs. In an ideal world, an end-user
wanting to accomplish a task could do so by simply specifying their intent in familiar natural language
without prior knowledge of the underlying programming model, or its syntax and semantics. The code
will get generated and even automatically run to produce the desired output.

However, as we have seen so far, the world is not ideal and even trained programmers face various chal-
lenges when programming with AI. These challenges are only exacerbated for end-user programmers,
as a study by Srinivasa Ragavan et al. (2022) observes.

Participants in the study were data analysts (n=20) conducting exploratory data analysis in GridBook,
a natural-language augmented spreadsheet system. In GridBook (Figure 6, adopted from Srinivasa Ra-
gavan et al. (2022)) users can write spreadsheet formulas using the natural language (Figure 6: a-f); a
formal formula is then synthesized from the natural language utterance. GridBook also infers the con-
text of an utterance; for example, in Figure 6, the query in label 4 is a follow-up from label 3. Both the
natural language utterance and the synthesized formula are persisted for users to edit and manipulate.

17

9.1. Issue 1: Intent speciﬁcation, problem decomposition and computational thinking
When attempting to accomplish data analysis tasks using natural language, participants had to reﬁne
their speciﬁcation of intent in the natural language several times, before they arrived at the desired
result (if they did). The NL utterances were often underspeciﬁed, ambiguous, too complex, or contained
domain phrases not speciﬁed in the context (e.g., in the data being analyzed). Thus, the ﬁrst issue is to
communicate the capabilities of the system, and make it interpretable so users can see how their prompt
is being interpreted.

End-user programmers often also lack the key computational thinking skills (Wing, 2011), such as the
ability to decompose problems into subproblems, reformulate problems in ways that can be computed
by a system, etc. However, effective use of LLMs such as Codex requires such skills. For example,
if these models are most accurate when solutions to a problem are single line, then the user should be
able to break their problem into smaller sub-problems each of which can be solved in one or two lines.
Moreover, they might also lack the ability to frame a problem as generic computational problems, rather
than domain-speciﬁc problems. For example, a realtor is more likely to ask “which is the largest house”
(declaratively), instead of “which is the house with maximum constructed area” (procedurally).

Therefore, end-user computing environments powered by AI should help end-user programmers think
“computationally”: they must aid users in breaking down their problems to smaller steps, or guiding
users towards alternative strategies to specify or solve a problem (e.g., providing examples, offering
alternatives) or even seek procedural prompts where needed (e.g., for disambiguation).

9.2. Issue 2: Code correctness, quality and (over)conﬁdence
The second challenge is in verifying whether the code generated by the model is correct. In GridBook,
users were able to see the natural language utterance, synthesized formula and the result of the for-
mula. Of these, participants heavily relied on ‘eyeballing’ the ﬁnal output as a means of evaluating the
correctness of the code, rather than, for example, reading code or testing rigorously.

While this lack of rigorous testing by end-user programmers is unsurprising, some users, particularly
those with low computer self-efﬁcacy, might overestimate the accuracy of the AI, deepening the overcon-
ﬁdence end-user programmers are known to have in their programs’ accuracy Panko (2008). Moreover,
end-user programmers might not be able to discern the quality of non-functional aspects of the generated
code, such as security, robustness or performance issues.

9.3. Issue 3: Code comprehension and maintenance
A third challenge with AI-driven programming is the issue of code comprehension. During GridBook’s
user evaluation, participants mentioned that the generated formulas are hard to understand, even when
users were familiar with the target language. This has potentially severe consequences: from evaluating
the accuracy of the program by verifying logic, to the ability to customize code, to future debugging and
reuse. As we discussed earlier, this problem also exists for trained developers.

One approach to address this issue is for the AI system to include some notion of code readability or
comprehensibility as a factor in code synthesis, such as during the learning phase, or when ranking
suggestions, or even take it as input to the model (similar to the ‘temperature’ parameter in Codex). This
approach is useful more broadly to synthesize high quality code, such as optimizing for performance or
robustness. A second solution to tackle the comprehension problem is to explain the generated code to
their users in a manner that is less ‘programmerese’ and more centered around the user’s current task
and context. Initial evidence suggests that participants were open to these ideas; thus, these areas are
ripe for future exploration.

9.4. Issue 4: Consequences of automation in end-user programming
In any AI system, we need to consider the consequences of automation. End-user programmers are
known to turn to local experts or gardeners (end-user programmers with interest and expertise in pro-
gramming who serve as gurus in the end-user programming environment) when they are unable to solve
a part of the problem (Nardi, 1993; Sarkar & Gordon, 2018). Task-orientation tendencies combined with

18

challenges of completing their tasks easily also leaves end-user programmers with limited attention for
testing, or carefully learning what is going on with their programs. Assuming that LLMs and associated
user experiences will improve in the coming years, making end-user programming faster with LLMs
than without, it is tempting to wonder whether the programmer can be persuaded to invest the saved
time and attention to aspects such as learning or testing their programs; if so, what would it take to
inﬂuence behaviour changes?

Another question is in the role of such experts. We conjecture that LLMs or similar AI capabilities
will soon be able to answer a sizeable fraction of questions that end-user programmers will go to local
experts for. An open question therefore is how the ecosystem of end-user programmers in organizations
will change in their roles, importance and specialities. For example, will gardeners take on the role of
educating users on better taking advantage of AI? If so, how can we communicate the working of such
AI systems to technophile users and early adopters, so they can enable others in the organization?

9.5. Issue 5: No code, and the dilemma of the direct answer
Finally, it is not a foregone conclusion that users are even interested in code. As Blackwell’s model of
attention investment notes, in many cases the user may be content to perform an action manually, rather
than invest in creating a reusable automation (Blackwell, 2002a; J. Williams et al., 2020). Spreadsheet
users, in particular, are often not sensitive to the level of automation or automatability of a given work-
ﬂow, using a mix of manual, automated, and semi-automated techniques to achieve the goal at hand
(Pandita et al., 2018).

Spreadsheet users often need ad-hoc transformations of their data that they will, in all likelihood, never
need again. It may be that we can express this transformation as a program, but if the user is interested
in the output and not the program, is it important, or even necessary, to communicate this fact to the
user? One can argue that increasing the user’s awareness of the ﬂexibility and fallibility of the process of
delivering an inferred result (i.e., enabling them to critically evaluate the output (Sarkar et al., 2015)) can
build agency, conﬁdence, trust, and resilience. This issue is related to information retrieval’s “dilemma
of the direct answer” (Potthast et al., 2021), raised in response to the increased phenomenon of search
engines directly answering queries in addition to simply listing retrieved results.

However, if the programming language used is not related to the languages familiar to the end-user, or
the user is a complete novice, it is exceedingly difﬁcult for them to make any sense of it, as was shown by
Lau et al. (2021) in their study of Excel users encountering Python code. Yet, there are socio-technical
motivations for using an unfamiliar target language: long-term testing of LLM assistance shows that
it shines when paired with high-level APIs that capture use cases well (Section 7). One advantage of
the Python ecosystem is that it has an unparalleled set of libraries and APIs for data wrangling. An
LLM-assisted tool that emits Excel formulas is therefore less likely to solve user problems than Python
statements. In the longer term, this might be mitigated by developing a rich set of data manipulation
libraries in the Excel formula language.

10. Conclusion
Large language models have initiated a signiﬁcant change in the scope and quality of program code
that can be automatically generated, compared to previous approaches. Experience with commercially
available tools built on these models suggests that a they represent a new way of programming. LLM
assistance transforms almost every aspect of the experience of programming, including planning, au-
thoring, reuse, modiﬁcation, comprehension, and debugging.

In some aspects, LLM assistance resembles a highly intelligent and ﬂexible compiler, or a partner in pair
programming, or a seamless search-and-reuse feature. Yet in other aspects, LLM-assisted programming
has a ﬂavour all of its own, which presents new challenges and opportunities for human-centric pro-
gramming research. Moreover, there are even greater challenges in helping non-expert end users beneﬁt
from such tools.

19

A. Experience report sources
This appendix contains a list of sources we draw upon for the quotes and analysis in Section 7. While
all sources were included in our analysis, we did not draw direct quotes from every source in this list.

A.1. Blog posts and corresponding Hacker News discussions

1. Andrew Mayne, March 17 2022, “Building games and apps entirely through natural language
using OpenAI’s code-davinci model”. URL: https://andrewmayneblog.wordpress
.com/2022/03/17/building-games-and-apps-entirely-through-natural
-language-using-openais-davinci-code-model/.
Hacker News discussion:
https://news.ycombinator.com/item?id=30717773

2. Andrew Mouboussin, March 24 2022, “Building a No-Code Machine Learning Model by Chat-
ting with GitHub Copilot”. URL: https://www.surgehq.ai/blog/building-a-no
-code-toxicity-classifier-by-talking-to-copilot. Hacker News discussion:
https://news.ycombinator.com/item?id=30797381

3. Matt Rickard, August 17 2021, “One Month of Using GitHub Copilot”. URL: https://matt

-rickard.com/github-copilot-a-month-in/.

4. Nutanc, November 15 2021, “Using Github copilot to get the tweets for a keyword and
ﬁnd the sentiment of each tweet in 2 mins”. URL: https://nutanc.medium.com/
using-github-copilot-to-get-the-tweets-for-a-keyword-and-find
-the-sentiment-of-each-tweet-in-2-mins-9a531abedc84.

5. Tanishq Abraham, July 14 2021, “Coding with GitHub Copilot”. URL: https://tmabraham

.github.io/blog/github_copilot.

6. Aleksej Komnenovic, January 17 2022, “Don’t fully trust AI in dev work!
https://akom.me/dont-fully-trust-ai-in-dev-work-yet.

/yet”. URL:

A.2. Miscellaneous Hacker News discussions

1. https://news.ycombinator.com/item?id=30747211

2. https://news.ycombinator.com/item?id=31390371

3. https://news.ycombinator.com/item?id=31020229&p=2

4. https://news.ycombinator.com/item?id=29760171

5. https://news.ycombinator.com/item?id=31325154

6. https://news.ycombinator.com/item?id=31734110

7. https://news.ycombinator.com/item?id=31652939

8. https://news.ycombinator.com/item?id=30682841

9. https://news.ycombinator.com/item?id=31515938

10. https://news.ycombinator.com/item?id=31825742

20

References
Allamanis, M., Barr, E. T., Devanbu, P. T., & Sutton, C. (2018). A survey of machine learning for
big code and naturalness. ACM Comput. Surv., 51(4), 81:1–81:37. Retrieved from https://doi
.org/10.1145/3212695 doi: 10.1145/3212695

Allamanis, M., & Brockschmidt, M. (2017). Smartpaste: Learning to adapt source code. arXiv preprint

arXiv:1705.07867.

Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., . . . Sutton, C. (2021). Program
synthesis with large language models. arXiv. Retrieved from https://arxiv.org/abs/2108
.07732 doi: 10.48550/ARXIV.2108.07732

Barik, T., Ford, D., Murphy-Hill, E., & Parnin, C. (2018). How should compilers explain problems to
developers? In Proceedings of the 2018 26th acm joint meeting on european software engineering
conference and symposium on the foundations of software engineering (pp. 633–643).

Barik, T., Johnson, B., & Murphy-Hill, E. (2015). I heart hacker news: expanding qualitative research
ﬁndings by analyzing social news websites. In Proceedings of the 2015 10th joint meeting on foun-
dations of software engineering (pp. 882–885).

Barke, S., James, M. B., & Polikarpova, N. (2022). Grounded copilot: How programmers interact with
code-generating models. arXiv. Retrieved from https://arxiv.org/abs/2206.15000 doi:
10.48550/ARXIV.2206.15000

Basman, A., Church, L., Klokmose, C. N., & Clark, C. B.

(2016). Software and how it lives on-

embedding live programs in the world around them. In Ppig (p. 19).

Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the dangers of stochastic
parrots: Can language models be too big? In M. C. Elish, W. Isaac, & R. S. Zemel (Eds.), Facct
’21: 2021 ACM conference on fairness, accountability, and transparency, virtual event / toronto,
canada, march 3-10, 2021 (pp. 610–623). ACM. Retrieved from https://doi.org/10.1145/
3442188.3445922 doi: 10.1145/3442188.3445922

Bergström, I., & Blackwell, A. F. (2016). The practices of programming. In 2016 ieee symposium on

visual languages and human-centric computing (vl/hcc) (pp. 190–198).

Blackwell, A. F. (2002a). First steps in programming: A rationale for attention investment models.
In Proceedings ieee 2002 symposia on human centric computing languages and environments (pp.
2–10).

Blackwell, A. F. (2002b). What is programming? In Ppig (p. 20).

Bødker, S. (2015). Third-wave hci, 10 years later - participation and sharing. Interactions, 22(5), 24–31.

Retrieved from https://doi.org/10.1145/2804405 doi: 10.1145/2804405

Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., . . . Amodei, D.

(2020).

Language models are few-shot learners.

Cao, J., Fleming, S. D., Burnett, M., & Scafﬁdi, C. (2015). Idea garden: Situated support for problem

solving by end-user programmers. Interacting with Computers, 27(6), 640–660.

Chalhoub, G., & Sarkar, A. (2022). “It’s Freedom to Put Things Where My Mind Wants”: Understanding
In CHI Conference on
and Improving the User Experience of Structuring Data in Spreadsheets.
Human Factors in Computing Systems. New York, NY, USA: Association for Computing Machinery.
Retrieved from https://doi.org/10.1145/3491102.3501833
doi: 10.1145/3491102
.3501833

21

Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J.,

. . . Zaremba, W.
(2021). Evaluating large language models trained on code. CoRR, abs/2107.03374. Retrieved from
https://arxiv.org/abs/2107.03374

Chen, M., Tworek, J., Jun, H., Yuan, Q., Ponde, H., Kaplan, J., . . . Zaremba, W. (2021). Evaluating

large language models trained on code. ArXiv, abs/2107.03374.

Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., . . . Fiedel, N. (2022). Palm:

Scaling language modeling with pathways. ArXiv, abs/2204.02311.

Colmerauer, A., & Roussel, P. (1996). The birth of prolog. In History of programming languages—ii

(pp. 331–367).

Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019, June). BERT: Pre-training of deep bidi-
In Proceedings of the 2019 conference of the
rectional transformers for language understanding.
north American chapter of the association for computational linguistics: Human language technolo-
gies, volume 1 (long and short papers) (pp. 4171–4186). Minneapolis, Minnesota: Association for
Computational Linguistics. Retrieved from https://aclanthology.org/N19-1423 doi:
10.18653/v1/N19-1423

Green, T., & Blackwell, A. (1998). Cognitive dimensions of information artefacts: a tutorial. In Bcs hci

conference (Vol. 98, pp. 1–75).

Green, T. R. (1989). Cognitive dimensions of notations. People and computers V, 443–460.

Green, T. R., & Petre, M. (1992). When visual programs are harder to read than textual programs. In
Human-computer interaction: Tasks and organisation, proceedings of ecce-6 (6th european confer-
ence on cognitive ergonomics). gc van der veer, mj tauber, s. bagnarola and m. antavolits. rome, cud
(pp. 167–180).

Gulwani, S.

(2011). Automating string processing in spreadsheets using input-output examples.

In
T. Ball & M. Sagiv (Eds.), Proceedings of the 38th ACM SIGPLAN-SIGACT symposium on principles
of programming languages, POPL 2011, austin, tx, usa, january 26-28, 2011 (pp. 317–330). ACM.
Retrieved from https://doi.org/10.1145/1926385.1926423
doi: 10.1145/1926385
.1926423

Hannay, J. E., Dybå, T., Arisholm, E., & Sjøberg, D. I. (2009). The effectiveness of pair programming:

A meta-analysis. Information and software technology, 51(7), 1110–1122.

Henley, A. Z., & Fleming, S. D. (2014). The patchworks code editor: Toward faster navigation with
less code arranging and fewer navigation mistakes. In Proceedings of the sigchi conference on human
factors in computing systems (pp. 2511–2520).

Hermans, F., Pinzger, M., & van Deursen, A. (2015). Detecting and refactoring code smells in spread-

sheet formulas. Empirical Software Engineering, 20(2), 549–575.

Hindle, A., Barr, E. T., Gabel, M., Su, Z., & Devanbu, P. T. (2016). On the naturalness of software.
Commun. ACM, 59(5), 122–131. Retrieved from https://doi.org/10.1145/2902362 doi:
10.1145/2902362

Hindle, A., Barr, E. T., Su, Z., Gabel, M., & Devanbu, P. T.

(2012). On the naturalness of soft-
In M. Glinz, G. C. Murphy, & M. Pezzè (Eds.), 34th international conference on soft-
ware.
ware engineering, ICSE 2012, june 2-9, 2012, zurich, switzerland (pp. 837–847).
IEEE Com-
puter Society. Retrieved from https://doi.org/10.1109/ICSE.2012.6227135 doi:
10.1109/ICSE.2012.6227135

22

Hoare, C. A. R. (1969). An axiomatic basis for computer programming. Commun. ACM, 12(10), 576–
580. Retrieved from https://doi.org/10.1145/363235.363259 doi: 10.1145/363235
.363259

Hochreiter, S., & Schmidhuber, J.

(1997, nov). Long short-term memory. Neural Comput., 9(8),
1735–1780. Retrieved from https://doi.org/10.1162/neco.1997.9.8.1735 doi: 10
.1162/neco.1997.9.8.1735

Horvitz, E. (1999). Principles of mixed-initiative user interfaces. In Proceedings of the sigchi conference

on human factors in computing systems (pp. 159–166).

Hutchins, E. L., Hollan, J. D., & Norman, D. A. (1985). Direct manipulation interfaces. Hum. Comput.
Interact., 1(4), 311–338. Retrieved from https://doi.org/10.1207/s15327051hci0104
_2 doi: 10.1207/s15327051hci0104\_2

Imai, S. (2022). Is github copilot a substitute for human pair-programming? an empirical study. In
2022 ieee/acm 44th international conference on software engineering: Companion proceedings (icse-
companion) (pp. 319–321).

Jiang, E., Toh, E., Molina, A., Olson, K., Kayacik, C., Donsbach, A., . . . Terry, M. (2022). Discovering
the syntax and strategies of natural language programming with generative language models. In Chi
conference on human factors in computing systems (pp. 1–19).

Kery, M. B., & Myers, B. A. (2017). Exploring exploratory programming. In 2017 ieee symposium on

visual languages and human-centric computing (vl/hcc) (pp. 25–29).

Ko, A. J., & Myers, B. A. (2004). Designing the whyline: a debugging interface for asking questions
In Proceedings of the sigchi conference on human factors in computing

about program behavior.
systems (pp. 151–158).

Kulesza, T., Amershi, S., Caruana, R., Fisher, D., & Charles, D. (2014). Structured labeling for facilitat-
ing concept evolution in machine learning. In Proceedings of the sigchi conference on human factors
in computing systems (pp. 3075–3084).

Kurlander, D., Cypher, A., & Halbert, D. C. (1993). Watch what i do: programming by demonstration.

MIT press.

Lau, S., Srinivasa Ragavan, S. S., Milne, K., Barik, T., & Sarkar, A. (2021). Tweakit: Supporting end-
user programmers who transmogrify code. In Proceedings of the 2021 CHI Conference on Human
Factors in Computing Systems (pp. 1–12).

Li, J., Tang, T., Zhao, W. X., & Wen, J.-R. (2021, 8). Pretrained language model for text generation:
A survey. In Z.-H. Zhou (Ed.), Proceedings of the thirtieth international joint conference on artiﬁcial
intelligence, IJCAI-21 (pp. 4492–4499).
International Joint Conferences on Artiﬁcial Intelligence
Organization. Retrieved from https://doi.org/10.24963/ijcai.2021/612 (Survey
Track) doi: 10.24963/ijcai.2021/612

Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., . . . Vinyals, O.

(2022b).
Competition-level code generation with alphacode. arXiv. Retrieved from https://arxiv.org/
abs/2203.07814 doi: 10.48550/ARXIV.2203.07814

Li, Y., Choi, D. H., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., . . . Vinyals, O. (2022a).

Competition-level code generation with alphacode. ArXiv, abs/2203.07814.

Lieberman, H. (2001). Your wish is my command: Programming by example. Morgan Kaufmann.

23

Lieberman, H., & Liu, H. (2006). Feasibility studies for programming in natural language. In End user

development (pp. 459–473). Springer.

Liu, S., Chen, Y., Xie, X., Siow, J. K., & Liu, Y.

(2021). Retrieval-augmented generation for code
summarization via hybrid GNN. In International conference on learning representations. Retrieved
from https://openreview.net/forum?id=zv-typ1gPxA

Lu, S., Guo, D., Ren, S., Huang, J., Svyatkovskiy, A., Blanco, A., . . . Liu, S. (2021). Codexglue: A
machine learning benchmark dataset for code understanding and generation. ArXiv, abs/2102.04664.

Luger, E., & Sellen, A. (2016). ""like having a really bad pa"" the gulf between user expectation and
experience of conversational agents. In Proceedings of the 2016 chi conference on human factors in
computing systems (pp. 5286–5297).

Macvean, A., Church, L., Daughtry, J., & Citro, C. (2016). Api usability at scale. In Ppig (p. 26).

Marasoiu, M., Church, L., & Blackwell, A.

(2015). An empirical investigation of code completion

usage by professional software developers. In PPIG.

Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of
words and phrases and their compositionality. In C. Burges, L. Bottou, M. Welling, Z. Ghahramani,
& K. Weinberger (Eds.), Advances in neural information processing systems (Vol. 26). Curran As-
sociates, Inc. Retrieved from https://proceedings.neurips.cc/paper/2013/file/
9aa42b31882ec039965f3c4923ce901b-Paper.pdf

Miller, L. A. (1981). Natural language programming: Styles, strategies, and contrasts. IBM Systems

Journal, 20(2), 184–215.

Mou, L., Li, G., Zhang, L., Wang, T., & Jin, Z.

(2016). Convolutional neural networks over tree

structures for programming language processing. In Aaai.

Mu, J., & Sarkar, A. (2019). Do we need natural language? Exploring restricted language interfaces
In Extended Abstracts of the 2019 CHI Conference on Human Factors in

for complex domains.
Computing Systems (pp. 1–6).

Myers, B. A. (1992). Demonstrational interfaces: A step beyond direct manipulation. Computer, 25(8),

61–73.

Myers, B. A., & Stylos, J. (2016). Improving api usability. Communications of the ACM, 59(6), 62–69.

Nardi, B. A. (1993). A small matter of programming: perspectives on end user computing. MIT press.

Nguyen, A. T., Nguyen, T. T., & Nguyen, T. N. (2015). Divide-and-conquer approach for multi-phase
statistical migration for source code (t). 2015 30th IEEE/ACM International Conference on Automated
Software Engineering (ASE), 585-596.

Pandita, R., Parnin, C., Hermans, F., & Murphy-Hill, E. (2018). No half-measures: A study of manual
and tool-assisted end-user programming tasks in excel. In 2018 ieee symposium on visual languages
and human-centric computing (vl/hcc) (pp. 95–103).

Panko, R. R.

(2008). Reducing overconﬁdence in spreadsheet development.

arXiv preprint

arXiv:0804.0941.

Pearce, H., Ahmad, B., Tan, B., Dolan-Gavitt, B., & Karri, R. (2021). Asleep at the keyboard? assessing
the security of github copilot’s code contributions. arXiv. Retrieved from https://arxiv.org/
abs/2108.09293 doi: 10.48550/ARXIV.2108.09293

24

Piccioni, M., Furia, C. A., & Meyer, B. (2013). An empirical study of api usability. In 2013 acm/ieee

international symposium on empirical software engineering and measurement (pp. 5–14).

Potthast, M., Hagen, M., & Stein, B. (2021). The dilemma of the direct answer. In Acm sigir forum

(Vol. 54, pp. 1–12).

Raychev, V., Vechev, M. T., & Krause, A. (2015). Predicting program properties from ""big code"". In
S. K. Rajamani & D. Walker (Eds.), Proceedings of the 42nd annual ACM SIGPLAN-SIGACT sympo-
sium on principles of programming languages, POPL 2015, mumbai, india, january 15-17, 2015 (pp.
111–124). ACM. Retrieved from https://doi.org/10.1145/2676726.2677009 doi:
10.1145/2676726.2677009

Rouchy, P. (2006). Aspects of prolog history: Logic programming and professional dynamics. Blekinge

Institute of Technology, Sweden).(English). TeamEthno-Online(2), 85–100.

Salge, C. A. D. L., & Berente, N. (2016). Pair programming vs. solo programming: What do we know
after 15 years of research? In 2016 49th hawaii international conference on system sciences (hicss)
(pp. 5398–5406).

Sarkar, A.

(2016).

Interactive analytical modelling (Tech. Rep. No. UCAM-CL-TR-920). Uni-
versity of Cambridge, Computer Laboratory. Retrieved from https://www.cl.cam.ac.uk/
techreports/UCAM-CL-TR-920.pdf doi: 10.48456/tr-920

Sarkar, A.

(2022, March).

In Workshop on
Transparency and Explanations in Smart Systems (TeXSS), in conjunction with ACM Intelligent
User Interfaces (IUI 2022) (pp. 192–199). Retrieved from http://ceur-ws.org/Vol-3124/
paper22.pdf

Is explainable AI a race against model complexity?

Sarkar, A., & Gordon, A. D. (2018, September). How do people learn to use spreadsheets? (work in
progress). In Proceedings of the 29th Annual Conference of the Psychology of Programming Interest
Group (PPIG 2018) (pp. 28–35).

Sarkar, A., Jamnik, M., Blackwell, A. F., & Spott, M.

Interactive visual machine learning
(2015).
In 2015 IEEE Symposium on Visual Languages and Human-Centric Computing

in spreadsheets.
(VL/HCC) (pp. 159–163).

Sarkar, A., Srinivasa Ragavan, S., Williams, J., & Gordon, A. D. (2022). End-user encounters with
lambda abstraction in spreadsheets: Apollo’s bow or Achilles’ heel? In 2022 IEEE Symposium on
Visual Languages and Human-Centric Computing (VL/HCC).

Shneiderman, B., & Norwood, N. (1993). 1.1 direct manipulation: a step beyond programming. Sparks

of innovation in human-computer interaction, 17.

Silver, A.

(2018, May).

Introducing visual studio intellicode. Microsoft.

Retrieved from

https://devblogs.microsoft.com/visualstudio/introducing-visual
-studio-intellicode/

Srinivasa Ragavan, S., Hou, Z., Wang, Y., Gordon, A. D., Zhang, H., & Zhang, D. (2022). Gridbook:
Natural language formulas for the spreadsheet grid. In 27th international conference on intelligent
user interfaces (p. 345–368). New York, NY, USA: Association for Computing Machinery. Retrieved
from https://doi.org/10.1145/3490099.3511161 doi: 10.1145/3490099.3511161

Srinivasa Ragavan, S., Kuttal, S. K., Hill, C., Sarma, A., Piorkowski, D., & Burnett, M. (2016). Foraging
among an overabundance of similar variants. In Proceedings of the 2016 chi conference on human
factors in computing systems (pp. 3509–3521).

25

Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. In
Proceedings of the 27th international conference on neural information processing systems - volume
2 (p. 3104–3112). Cambridge, MA, USA: MIT Press.

Tanimoto, S. L. (2013). A perspective on the evolution of live programming. In 2013 1st international

workshop on live programming (live) (pp. 31–34).

Vaithilingam, P., Zhang, T., & Glassman, E. L.

(2022). Expectation vs. experience: Evaluating the
usability of code generation tools powered by large language models. In Chi conference on human
factors in computing systems extended abstracts (pp. 1–7).

Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., . . . Polosukhin, I. (2017).
Attention is all you need. In Proceedings of the 31st international conference on neural information
processing systems (p. 6000–6010). Red Hook, NY, USA: Curran Associates Inc.

Wei, J., Goyal, M., Durrett, G., & Dillig, I. (2020). Lambdanet: Probabilistic type inference using graph

neural networks. ArXiv, abs/2005.02161.

Wei, Y., Chandrasekaran, N., Gulwani, S., & Hamadi, Y. (2015, May). Building bing developer assistant
(Tech. Rep. No. MSR-TR-2015-36). Retrieved from https://www.microsoft.com/en-us/
research/publication/building-bing-developer-assistant/

Weiss, D. (2022, Jun). Blog / tabnine announcements / announcing our next-generation ai models. Tab-
nine. Retrieved from https://www.tabnine.com/blog/announcing-tabnine-next
-generation/

Williams, J., Negreanu, C., Gordon, A. D., & Sarkar, A. (2020). Understanding and inferring units
In 2020 IEEE Symposium on Visual Languages and Human-Centric Computing

in spreadsheets.
(VL/HCC) (pp. 1–9).

Williams, L. A., & Kessler, R. R. (2000). All i really need to know about pair programming i learned in

kindergarten. Communications of the ACM, 43(5), 108–114.

Wing, J. (2011). Research notebook: Computational thinking—what and why. The link magazine, 6,

20–23.

Xu, F. F., Alon, U., Neubig, G., & Hellendoorn, V. J. (2022). A systematic evaluation of large lan-
guage models of code. Proceedings of the 6th ACM SIGPLAN International Symposium on Machine
Programming.

Xu, F. F., Vasilescu, B., & Neubig, G.

In-IDE Code Generation from Natural Language:
Promise and Challenges. ACM Transactions on Software Engineering and Methodology (TOSEM),
31(2), 1–47.

(2022).

Yoon, Y., & Myers, B. A. (2015). Supporting selective undo in a code editor. In 2015 ieee/acm 37th

ieee international conference on software engineering (Vol. 1, pp. 223–233).

Zhang, H., Jain, A., Khandelwal, G., Kaushik, C., Ge, S., & Hu, W. (2016). Bing developer assistant:
improving developer productivity by recommending sample code. In Proceedings of the 2016 24th
acm sigsoft international symposium on foundations of software engineering (pp. 956–961).

Ziegler, A. (2021, Jun). Github copilot research recitation. Microsoft. Retrieved from https://

github.blog/2021-06-30-github-copilot-research-recitation/

Ziegler, A., Kalliamvakou, E., Simister, S., Sittampalam, G., Li, A., Rice, A., . . . Aftandilian, E. (2022).

Productivity assessment of neural code completion. arXiv preprint arXiv:2205.06537.

26

","2 2 0 2 g u A 2 1 ] C H . s c [ 1 v 3 1 2 6 0 . 8 0 2 2 : v i X r a What is it like to program with artiﬁcial intelligence? Advait Sarkar Microsoft Research University of Cambridge advait@microsoft.com Andrew D. Gordon Microsoft Research University of Edinburgh adg@microsoft.com Carina Negreanu Microsoft Research cnegreanu@microsoft.com Christian Poelitz Microsoft Research cpoelitz@microsoft.com Sruti Srinivasa Ragavan Microsoft Research a-srutis@microsoft.com Ben Zorn Microsoft Research ben.zorn@microsoft.com Figure 1 – Code generation using the GitHub Copilot editor extension. The portion highlighted in blue has been generated by the model. Left: a function body is generated based on a textual description in a comment. Right: a set of test cases is generated. Source: copilot.github .com Abstract Large language models, such as OpenAI’s codex and Deepmind’s AlphaCode, can generate code to solve a variety of problems expressed in natural language. This technology has already been commercialised in at least one widely-used programming editor extension: GitHub Copilot. In this paper, we explore how programming with large language models (LLM-assisted programming) is similar to, and differs from, prior conceptualisations of programmer assistance. We draw upon pub- licly available experience reports of LLM-assisted programming, as well as prior usability and design studies. We ﬁnd that while LLM-assisted programming shares some properties of compilation, pair programming, and programming via search and reuse, there are fundamental differences both in the technical possibilities as well as the practical experience. Thus, LLM-assisted programming ought to be viewed as a new way of programming with its own distinct properties and challenges. Finally, we draw upon observations from a user study in which non-expert end user programmers use LLM-assisted tools for solving data tasks in spreadsheets. We discuss the issues that might arise, and open research challenges, in applying large language models to end-user programming, particularly with users who have little or no programming expertise. 1. Introduction Inferential assistance for programmers has manifested in various forms, such as programming by demon- stration, declarative programming languages, and program synthesis (Section 2). Large language models such as GPT mark a quantitative and qualitative step-change in the automatic generation of code and nat- ural language text. This can be attributed to cumulative innovations of vector-space word embeddings, the transformer architecture, large text corpora, and pre-trained language models (Section 3). 1 These models have been commercialised in the form of APIs such as OpenAI Codex, or as programmer- facing tools such as GitHub Copilot and Tabnine. These tools function as a sort of advanced autocom- plete, able to synthesize multiple lines of code based on a prompt within the code editor, which may be natural language (e.g., a comment), code (e.g., a function signature) or an ad-hoc mixture. The capa- bilities of such tools go well beyond traditional syntax-directed autocomplete, and include the ability to synthesize entire function bodies, write test cases, and complete repetitive patterns (Section 4). These tools have reliability, safety, and security implications (Section 5). Prior lab-based and telemetric research on the usability of such tools ﬁnds that developers generally appreciate the capabilities of these tools and ﬁnd them to be a positive asset to the development expe- rience, despite no strong effects on task completion times or correctness. Core usability issues include the challenge of correctly framing prompts as well as the effort required to check and debug generated code (Section 6). Longitudinal experience reports of developers support some of the lab-based ﬁndings, while contradict- ing others. The challenges of correctly framing prompts and the efforts of debugging also appear here. However, there are many reports that these tools do in fact strongly reduce task time (i.e., speed up the development process) (Section 7). Programming with large language models invites comparison to related ways of programming, such as search, compilation, and pair programming. While there are indeed similarities with each of these, the empirical reports of the experience of such tools also show crucial differences. Search, compila- tion, and pair programming are thus found to be inadequate metaphors for the nature of LLM-assisted programming; it is a distinct way of programming with its own unique blend of properties (Section 8). While LLM-assisted programming is currently geared towards expert programmers, arguably the great- est beneﬁciaries of their abilities will be non-expert end-user programmers. Nonetheless, there are is- sues with their direct application in end-user programming scenarios. Through a study of LLM-assisted end-user programming in spreadsheets, we uncover issues in intent speciﬁcation, code correctness, com- prehension, LLM tuning, and end-user behaviour, and motivate the need for further study in this area (Section 9). 2. Prior conceptualisations of intelligent assistance for programmers What counts as ‘intelligent assistance’ can be the subject of some debate. Do we select only features that are driven by technologies that the artiﬁcial intelligence research community (itself undeﬁned) would recognise as artiﬁcial intelligence? Do we include those that use expert-coded heuristics? Systems that make inferences a human might disagree with, or those with the potential for error? Mixed-initiative systems (Horvitz, 1999)? Or those that make the user feel intelligent, assisted, or empowered? While this debate is beyond the scope of this paper, we feel that to properly contextualise the qualitative difference made by large language models, a broad and inclusive approach to the term ‘intelligence’ is required. End-user programming has long been home to inferential, or intelligent assistance. The strategy of direct manipulation (Shneiderman & Norwood, 1993) is highly successful for certain types of limited, albeit useful, computational tasks, where the interface being used (“what you see”, e.g., a text editor or an image editor) to develop an information artefact can represent closely the artefact being developed (“what you get”, e.g., a text document or an image). However, this strategy cannot be straightforwardly applied to programs. Programs notate multiple possible paths of execution simultaneously, and they deﬁne “behaviour to occur at some future time” (Blackwell, 2002b). Rendering multiple futures in the present is a core problem of live programming research (Tanimoto, 2013), which aims to externalise programs as they are edited (Basman et al., 2016). The need to bridge the abstraction gap between direct manipulation and multiple paths of execution led to the invention of programming by demonstration (PBD) (Kurlander et al., 1993; Lieberman, 2001; Myers, 1992). A form of inferential assistance, PBD allows end-user programmers to make concrete demon- strations of desired behaviour that are generalised into executable programs. Despite their promise, PBD 2 systems have not achieved widespread success as end-user programming tools, although their idea sur- vives in vestigial form as various “macro recording” tools, and the approach is seeing a resurgence with the growing commercialisation of “robotic process automation”. Programming language design has long been concerned with shifting the burden of intelligence be- tween programmer, program, compiler, and user. Programming language compilers, in translating be- tween high-level languages and machine code, are a kind of intelligent assistance for programmers. The declarative language Prolog aspired to bring a kind of intelligence, where the programmer would only be responsible for specifying (“declaring”) what to compute, but not how to compute it; that responsibility was left to the interpreter. At the same time, the language was designed with intelligent applications in mind. Indeed, it found widespread use within artiﬁcial intelligence and computational linguistics research (Colmerauer & Roussel, 1996; Rouchy, 2006). Formal veriﬁcation tools use a speciﬁcation language, such as Hoare triples (Hoare, 1969), and writing such speciﬁcations can be considered programming at a ‘higher’ level of abstraction. Program synthesis, in particular synthesis through reﬁnement, aims at intelligently transforming these rules into executable and correct code. However, the term “program synthesis” is also used more broadly, and programs can be synthesised from other sources than higher-level speciﬁcations. Concretely, program synthesis by example, or simply programming by example (PBE), facilitates the generation of executable code from input-output examples. An example of successfully commercialised PBE is Excel’s Flash Fill (Gulwani, 2011), which synthesises string transformations in spreadsheets from a small number of examples. The Cognitive Dimensions framework (T. R. Green, 1989; T. Green & Blackwell, 1998) identiﬁes three categories of programming activity: authoring, transcription, and modiﬁcation. Modern programmer as- sistance encompasses each of these. For example, program synthesis tools transform the direct authoring of code into the (arguably easier) authoring of examples. Intelligent code completions (Marasoiu et al., 2015) support the direct authoring of code. Intelligent support for reuse, such as smart code copy/paste (Allamanis & Brockschmidt, 2017) support transcription, and refactoring tools (Hermans et al., 2015) support modiﬁcation. Researchers have investigated inferential support for navigating source code (Hen- ley & Fleming, 2014), debugging (J. Williams et al., 2020), and selectively undoing code changes (Yoon & Myers, 2015). Additionally, intelligent tools can also support learning (Cao et al., 2015). Allamanis et al. (2018) assemble a literature review of research—at the intersection of machine learning, programming languages, and software engineering—that seeks to adapt methods ﬁrst developed for natural language, such as language models, to source code. The emergence of large bodies of open source code, sometimes called “big code”, enabled this research area. Language models are sensitive to lexical features like names, code formatting, and order of methods, while traditional tools like compilers or code veriﬁers are not. The authors hypothesise that sensitivity to lexical features matters for software engineering: The naturalness hypothesis. Software is a form of human communication; software corpora have similar statistical properties to natural language corpora; and these properties can be exploited to build better software engineering tools. The earliest evidence for this hypothesis goes back to research that used n-gram models to build a code completion engine for Java that outperformed Eclipse’s completion feature (Hindle et al., 2012, 2016). The survey covers the methods and the applications they enable: recommender systems (such as code autocompletion), debuggers, code analysers (such as type checkers (Raychev et al., 2015)), and code synthesizers. These applications constitute intelligence assistance to programmers, but limited by the capabilities of the underlying language models. We can expect the recent dramatic expansion in capability of language models, which we discuss next, to magnify the effectiveness of these applications. 3. A brief overview of large language models for code generation 3.1. The transformer architecture and big datasets enable large pre-trained models In the past decade, natural language processing has evolved both in the development of language models (LMs) as well as tasks and evaluation. Mikolov et al. (2013) introduced Word2Vec, where vectors are as- 3 signed to words such that similar words are grouped together. This is done by looking at co-occurrences in free text (like Wikipedia articles) and ignores the fact that words have multiple meanings depend- ing on context. Long short-term memory (LSTM) neural networks (Hochreiter & Schmidhuber, 1997; Sutskever et al., 2014) and later encoder-decoder networks, account for order in an input sequence. Self- attention (Vaswani et al., 2017) signiﬁcantly simpliﬁed the prior networks by replacing each element in the input by a weighted average of the rest of the input. Transformers combined the advantages of (multi-head) attention and word embeddings, enriched with positional encodings (they add the order information to the word embeddings) into one architecture. While there are many alternatives to trans- formers for language modelling, in this paper when we mention a language model (LM) we will usually imply a transformer-based language model. There are large collections of unlabelled text data for the most common natural languages. For example, the Common Crawl project1 produces around 20 TB of text data (from web pages) monthly, but labelled task-speciﬁc data is less prevalent. This makes unsupervised training appealing which leads to the concept of pre-trained LMs (J. Li et al., 2021). Pre-trained LMs are commonly trained to perform next- word prediction (such as GPT models, e.g. (Brown et al., 2020)) where the model is trained to predict the next word in a sequence or masked (such as Bert, e.g. (Devlin et al., 2019)) where the model is trained to ﬁll a gap in a sequence. Ideally, pre-trained LMs learn general-purpose abilities and knowledge by seeing large amounts of text, which can then be transferred to downstream language tasks (where we have less labelled data) such as question answering, ﬁction generation, text summarisation, etc. Fine-tuning is the process of adapting a given pre-trained LM to different downstream tasks by introducing additional parameters and training them using task-speciﬁc objective functions. In certain cases the pre-training objective also gets adjusted to better suit the downstream task. Instead of (or on top of) ﬁne-tuning, the downstream task can be reformulated to be similar to the original LLM training. In practice, this means expressing the task as a set of instructions to the LLM via a prompt. So the goal, rather than deﬁning a learning objective for a given task, is to ﬁnd a way to query the LLM to directly predict for the downstream task. This is sometimes referred to as Pre-train, Prompt, Predict.2 3.2. Language models tuned for source code generation The downstream task of interest to us in this paper is code generation, where we provide snippets of code (including comments) and we want new code to be generated. Unlike other downstream tasks, a large corpus of data is available from public code repositories such as GitHub. Code generation can be divided into many sub-tasks, such as type decorators (variable type generation, e.g. (J. Wei et al., 2020)), code summarization (comment generation, e.g. (Liu et al., 2021)), clone detection (duplicate detection, e.g (Mou et al., 2016)), code translation (code migration from one language to another e.g. (Nguyen et al., 2015)) etc. A recent benchmark that covers many tasks is CodeXGLUE (Lu et al., 2021). LLM technology has brought us within reach of full-solution generation. Codex (Chen, Tworek, Jun, Yuan, Ponde, et al., 2021), a version of GPT-3 ﬁne-tuned for code generation, can solve in one generation on average 47/164 problems in the HumanEval code generation benchmark. HumanEval is a set of 164 hand-written programming problems, which include a function signature, docstring, body, and several unit tests, with an average of 7.7 tests per problem. Smaller models have followed Codex, like GPT-J3 (ﬁne-tuned on top of GPT-2), CodeParrot4 (also ﬁne-tuned on top of GPT-2, targets Python generations), PolyCoder (Xu, Alon, et al., 2022)(GPT-2 style but trained directly on code). LLMs comparable in size to Codex include AlphaCode (Y. Li et al., 2022a) and PaLM-Coder (Chowd- hery et al., 2022). AlphaCode is trained directly on GitHub data and ﬁne-tuned on coding competition problems. It introduces a method to reduce from a large number of potential solutions (up to millions) 1https://commoncrawl.org/ 2http://pretrain.nlpedia.ai/ 3https://huggingface.co/docs/transformers/main/model_doc/gptj 4https://huggingface.co/blog/codeparrot 4 Figure 2 – Code generation using the GitHub Copilot editor extension. The portion highlighted in blue has been generated by the model. Above: a repetitive time computation is extrapolated based on two examples. Below: function body is generated from the signature and the ﬁrst line. Source: copilot.github.com to a handful of candidates (competitions permit a maximum of 10). On a dataset of 10000 programming problems, if given 5 attempts Codex manages to solve around 3% of the problems versus AlphaCode which manages around 4-7%. In competitions for which it was ﬁne-tuned (CodeContests) AlphaCode manages a 34% success rate, on par with the average human competitor. Despite promising results there are known shortcomings. Models can directly copy code (full solutions or key parts of the solutions) from the training data, rather than generating new code. Though developers make efforts to clean and retain only high-quality code, there are no guarantees of correctness and errors can be directly propagated through generations. Codex can also produce syntactically incorrect or undeﬁned code, and can invoke functions, variables, and attributes that are undeﬁned or outside the scope of the codebase. Moreover, Codex struggles to parse through increasingly long and higher-level or system-level speciﬁcations which can lead to mis- takes in binding operations to variables (especially when the number of operations and variables in the docstring is large). Various approaches have been explored to ﬁlter out bad generations or repair them (especially for syntax errors). Consistency is another issue and there is a trade-off between non-determinism and generation diversity. Some parameter settings can control the diversity of generation (i.e., how diverse the different gener- ations for a single prompt might be), but there is no guarantee that we will get the same generation if we run the system at different times under the same settings. To alleviate this issue in measurements, metrics such as pass@k (have a solution that passes the tests within k tries) have been modiﬁed to be probabilistic. 4. Commercial programming tools that use large language models OpenAI Codex is a version of GPT that is ﬁne-tuned on publicly available source code (Chen, Tworek, Jun, Yuan, de Oliveira Pinto, et al., 2021). While Codex itself is not a programmer-facing tool, OpenAI has commercialised it in the form of an API that can be built upon. 5 Figure 3 – Code generation using the Tabnine editor extension. The grey text after the cursor is being suggested by the model based on the comment on the preceding line. Source: tabnine.com Figure 4 – API suggestion using the Visual Studio IntelliCode feature. Source: Silver (2018) The principal commercial implementation of Codex thus far has been in Github Copilot.5 Copilot is an extension that can be installed into code editors such as Neovim, Jetbrains, and Visual Studio Code. Copilot uses Codex, drawing upon the contents of the ﬁle being edited, related ﬁles in the project, and ﬁle paths or URLs of repositories. When triggered, it generates code at the cursor location, in much the same way as autocomplete. To help expand developer expectations for the capabilities of Copilot beyond the previous standard uses of autocomplete, suggested usage idioms for Copilot include: writing a comment explaining what a function does, and the function signature, and allowing Copilot to complete the function body; complet- ing boilerplate code; and deﬁning test cases (Figures 1 and 5). Programmers can cycle between different generations from the model, and once a particular completion has been accepted it can be edited like any other code. As of 23 June 2022, Amazon has announced a Copilot-like feature called CodeWhisperer,6 which also applies a large language model trained on a corpus of source code to generate autocompletions based on comments and code. The marketing material describes a set of safety features, such as: detecting when generated code is similar to code in the training set, detecting known security vulnerabilities in the generated code, and “removing code that may be considered biased and unfair” (although this latter claim induces skepticism). At present CodeWhisperer is not widely available and thus little is known of its use in practice. Other commercial implementations of AI-assisted autocompletion features include Visual Studio Intel- 5https://copilot.github.com/ 6https://aws.amazon.com/codewhisperer/features/ 6 licode (Silver, 2018) (Figure 4) and Tabnine (Figure 3)7. These are more limited in scope than Copilot and their user experience is commensurable to that of using ‘traditional’ autocomplete, i.e., autocom- plete that is driven by static analysis, syntax, and heuristics.8.The structure of the machine learning model used by these implementations is not publicly disclosed; however, both rely on models that have been trained on large corpora of publicly available source code. It is interesting to note, that despite the wide variety of types of intelligent programmer assistance we have discussed in Section 2 for several aspects of programming (authoring, transcription, modiﬁcation, debugging, and learning), commercial implementations of assistance based on large language models thus far are aimed primarily at authoring. Authoring can be viewed as the ﬁrst natural application of a generative language model, but the programming knowledge in these models can of course be used for assisting programmers in other activities, too. 5. Reliability, safety, and security implications of code-generating AI models AI models that generate code present signiﬁcant challenges to issues related to reliability, safety, and security. Since the output of the model can be a complex software artifact, determining if the out- put is “correct” needs a much more nuanced evaluation than simple classiﬁcation tasks. Humans have trouble evaluating the quality of software, and practices such as code review, applying static and dy- namic analysis techniques, etc., have proven necessary to ensure good quality of human-written code. Current methods for evaluating the quality of AI-generated code, as embodied in benchmarks such as HumanEval (Chen, Tworek, Jun, Yuan, de Oliveira Pinto, et al., 2021), MBPP (Austin et al., 2021), and CodeContests (Y. Li et al., 2022b), determine functional correctness of entire functions based on a set of unit tests. Such evaluation approaches fail to consider issues of code readability, completeness, or the presence of potential errors that software developers constantly struggle to overcome. Previous work (Chen, Tworek, Jun, Yuan, de Oliveira Pinto, et al., 2021) explores numerous implications of AI models that generate code, including issues of over-reliance, misalignment (the mismatch between what the user prompt requests and what the user really wants), bias, economic impact, and security implications. While these topics each are extensive and important, due to space limitations we only brieﬂy mention them here and point to additional related work when possible. Over-reliance occurs when individuals make optimistic assumptions about the correctness of the output of an AI model, leading to harm. For code generating models, users may assume the code is correct, has no security vulnerabilities, etc. and those assumptions may lead to lower quality or insecure code being written and deployed. Existing deployments of AI models for code, such as GitHub Copilot (Ziegler, 2021), have documentation that stresses the need to carefully review, test, and vet generated code just as a developer would vet code from any external source. It remains to be seen if over-reliance issues related to AI code generation will result in new software quality challenges. Since AI that generates code is trained on large public repositories, there is potential for low-quality training data to inﬂuence models to suggest low-quality code or code that contains security vulnera- bilities. One early study of GitHub Copilot (Pearce et al., 2021) examines whether code suggestions may contain known security vulnerabilities in a range of scenarios and ﬁnds cases where insecure code is generated. Beyond carefully screening new code using existing static and dynamic tools that detect security vulnerabilities in human-generated code, there are also possible mitigations that can reduce the likelihood that the model will make such suggestions. These include improving the overall quality of the training data by removing low-quality repositories, and ﬁne-tuning the large-language model speciﬁcally to reduce the output of known insecure patterns. 6. Usability and design studies of AI-assisted programming Vaithilingam et al. (2022) conducted a within-subjects comparative study (n=24) of Github Copilot, 7https://www.tabnine.com/ 8As of 15 June 2022, Tabnine has announced a shift to language model-driven autocompletion that more closely resembles the abilities of Copilot (Weiss, 2022). 7 comparing its user experience to that of traditional autocomplete (speciﬁcally, the Intellisense plugin, not the same as the Intellicode feature mentioned previously). Participants failed to complete the tasks more often with Copilot than with Intellisense, and there was no signiﬁcant effect on task completion time. Perhaps unsurprisingly, the authors ﬁnd that assessing the correctness of generated code is difﬁcult and an efﬁciency bottleneck, particularly when the code generated has a fundamental ﬂaw or inefﬁciency that leads the programmer on an ultimately unsuccessful ‘wild goose chase’ of repair or debugging. However, the overwhelming majority (19 of 24) of participants reported a strong preference for Copilot in a post-task survey. While participants were less conﬁdent about the code generated by Copilot, they almost universally (23 of 24) perceived it as more helpful, because it had the potential for generating useful starting points and saving the programmer the effort of searching online for documented solutions that could be the basis for reuse. Ziegler et al. (2022) conducted a survey (n=2,047) of the perceived productivity of Copilot users in the USA. They matched these to telemetric usage measurements of the Copilot add-in, which included metrics such as how often an auto-completion was shown, how often it was accepted, how often it per- sisted unchanged in the document for a certain time period, how often it persisted with minor variations (e.g., measured by Levenshtein distance) and so on. They ﬁnd that the acceptance rate (the ratio of ac- cepted suggestions to shown suggestions) is the strongest predictor of users’ perceived productivity due to Copilot. Fascinatingly, they ﬁnd that the pattern of acceptance rates for all users in aggregate follows a daily and weekly “circadian” rhythm, such that users are more likely to accept Copilot completions out of working-hours and on weekends. However, for any given user, the acceptance rate depends on that user’s normal working hours; suggestions outside of normal working hours are less likely to be accepted. Future work is needed to see whether this ﬁnding replicates, and if so to establish how and why acceptance rates are so signiﬁcantly affected by working hours. Xu, Vasilescu, & Neubig (2022) conducted a within-subjects study (n=31) comparing the programming experience with and without a code generation plugin. Their experimental plugin takes the form of a text ﬁeld in which the user enters a natural language prompt, the system responds with a list of code snippets, and when clicked the desired snippet is inserted at the cursor. This workﬂow differs from Copilot’s, where the ‘prompt’ is text within the source ﬁle, and can contain a mix of natural language comments and code. The plugin supported both code generation (using a tree-based neural network) and code snippet retrieval (searching the programming forum Stack Overﬂow). Results from both generation and retrieval are shown in the same list, but visually demarcated. The authors found no signiﬁcant effect of the plugin on task completion time or program correctness. They found that simple queries were more likely to be answered correctly through generation, and more complex queries requiring multiple steps were more likely to be answered correctly though retrieval, and that it was possible to predict which approach would succeed based on the word content of the queries. Further, they found that most (60%) natural language queries that participants wrote in their experiment were not sufﬁciently well-speciﬁed for a human expert to write code implementing those intents. Retrieved snippets were edited more often than generated snippets, mostly to rename identiﬁers and choose different parameters. In a post- experiment survey, participants reported mostly feeling neutral or somewhat positive (30 of 31). These participants felt that the plugin was helpful for ﬁnding snippets they were aware of but cannot recall, and less disruptive than using a browser, but the interaction worked better when the developer had a pre-existing knowledge of the target APIs and frameworks, and it took experimentation to understand the “correct way” to formulate queries. There was no clear indication of preference between retrieval and generation. Jiang et al. (2022) developed an LLM-based tool for converting natural language statements to code. As in Xu, Vasilescu, & Neubig (2022), prompts are entered in a pop-up dialog invoked at the cursor from within a code editor, rather than as comments. In a study (n = 14), participants were given a week to complete two website-building tasks with the tool, while recording the screen, and were interviewed afterwards. As in other studies, participants saw utility in the tool for facilitating quick API lookups and for writing boilerplate code. They found that novice programmers’ queries were mainly natural 8 for Figure 5 – Searching for code snippets using Bing Developer Assistant. Stack Overﬂow is shown. Note how the query “generate md5 hash from string @line” contains a hint about the identiﬁer line, which is used to rewrite the retrieved snippet. Source: https://www.microsoft.com/en-us/research/publication/ building-bing-developer-assistant/ A result language, whereas experts were more likely to mix code into their requests. While some queries were abstract, and expressed high-level goals, most had low granularity, being “roughly equivalent to a line of code”. To cope with model failures, participants used a variety of strategies to reword their query, such as reducing the scope of the request or replacing words with alternatives, but no particular strategy was observed to be more effective than any other. Participants struggled with forming a mental model of what the model can understand and the “syntax” of the language it required – this is precisely the fuzzy abstraction matching problem we described earlier, which the authors call an “uncanny valley”. The authors suggest possible solutions such as automated rewording of prompts, suggesting simpler tasks, suggesting task breakdowns, and better onboarding and tutorials. Barke et al. (2022) studied how programmers (n = 20) use GitHub Copilot to complete short program- ming tasks in Python, Rust, Haskell, and Java. Through analysis of screen recordings, the authors identifed two primary modes of interaction with Copilot: acceleration, where the programmer has a well-formed intent and Copilot speeds up code authoring in “small logical units”, and exploration, where Copilot suggestions are used to assist the planning process, “help them get started, suggest potentially useful structure and API calls, or explore alternative solutions”. In acceleration, long code suggestions, which take time to read and evaluate, can break the programmer’s ﬂow. Participants developed heuristics for quickly scanning suggestions, such as looking for the presence of certain keywords. In exploration, participants were more likely to prompt using purely natural language comments, rather than a mix of comments and code. Moreover, these prompt comments were often ‘cleaned’ subsequent to accepting a suggestion, which implies a form of ‘instruction language’ that is separate from ‘explanation language’. The Bing Developer Assistant (Y. Wei et al., 2015; Zhang et al., 2016) (also referred to as Bing Code Search) was an experimental extension for Visual Studio initially released in 2015. It enabled an in-IDE, identiﬁer-aware search for code snippets from forums such as Stack Overﬂow. It had the ability to rewrite retrieved code to use identiﬁers from the programmer’s current ﬁle. A user study (n=14) comparing task time in performing 45 short programming tasks with the extension versus regular web search found on average 28% of time was saved with the extension. Morever telemetry data gathered over three weeks (representing around 20,000 users and around 3,000 queries per day) showed that several programmers used the feature frequently. Some used it repeatedly for related problems in quick succession, showing its use in multi-step problems. Others issued the same query multiple times on separate days, suggesting 9 that the speed of auto-completion was useful even if the programmer knew the solution. 7. Experience reports At present, there is not a lot of research on the user experience of programming with large language models beyond the studies we have summarised in Section 6. However, as the availability of such tools increases, professional programmers will gain long-term experience in their use. Many such program- mers write about their experiences on personal blogs, which are then discussed in online communities such as Hacker News. Inspired by the potential for these sources to provide rich qualitative data, as pointed out by Barik (Barik et al., 2015; Sarkar et al., 2022), we draw upon a few such experience reports. A full list of sources is provided Appendix A; below we summarise their key points. 7.1. Writing effective prompts is hard As with several other applications of generative models, a key issue is the writing of prompts that in- crease the likelihood of successful code generation. The mapping that these models learn between natural language and code is very poorly understood. Through experimentation, some have developed heuristics for prompts that improve the quality of the code generated by the model. One developer, after building several applications and games with OpenAI’s code-davinci model (the second generation Codex model), advises to “number your instructions” and creating “logic ﬁrst” before UI elements. Another, in using Copilot to build a classiﬁer for natural language statements, suggests to provide “more detail” in response to a failure to generate correct code. For example, when asking Copilot to “bina- rize” an array fails, they re-write the prompt to “turn it into an array where [the ﬁrst value] is 1 and [the second value] is 0” – effectively pseudocode – which generates a correct result. Commenters on Hacker News are divided on the merits of efforts invested in developing techniques for prompting. While some see it as a new level of abstraction for programming, others see it as indirectly approaching more fundamental issues that ought to be solved with better tooling, documentation, and language design: “You’re not coding directly in the language, but now you’re coding in an implicit language provided by Copilot. [...] all it really points out is that code documentation and discovery is terrible. But I’m not for sure writing implicit code in comments is really a better approach than seeking ways to make discovery of language and library features more discoverable.” “[...] the comments used to generate the code via GitHub Copilot are just another very inefﬁcient programming language.” “[Responding to above] There is nonetheless something extremely valuable about being able to write at different levels of abstraction when developing code. Copilot lets you do that in a way that is way beyond what a normal programming language would let you do, which of course has its own, very rigid, abstractions. For some parts of the code you’ll want to dive in and write every single line in painstaking detail. For others [...] [Copilot] is maybe enough for your purposes. And being able to have that ability, even if you think of it as just another programming language in itself, is huge.” Being indiscriminately trained on a corpus containing code of varying ages and (subjective) quality has drawbacks; developers encounter generated code which is technically correct, but contains practices considered poor such as unrolled loops and hardcoded constants. One Copilot user found that: “Copilot [...] has made my code more verbose. Lines of code can be liabilities. Longer ﬁles to parse, and more instances to refactor. Before, where I might have tried to consolidate an API surface, I ﬁnd myself maintaining [multiple instances].” Another Copilot user reﬂected on their experience of trying to generate code that uses the fastai API, which frequently changes: “[...] since the latest version of fastai was only released in August 2020, GitHub Copilot was not able to provide any relevant suggestions and instead provided code for using older versions of fastai. [...] To me, this is a major concern [...] If we are using cutting edge tools [...] Copilot has no knowledge of this and cannot provide useful suggestions.” On the other hand, developers can also be exposed to better practices and APIs through these models. The developer that found Copilot to make their code more verbose also observed that: 10 “Copilot gives structure to Go errors . [...] A common idiom is to wrap your errors with a context string [which can be written in an inconsistent, ad-hoc style] [...] Since using Copilot, I haven’t written a single one of these error handling lines manually. On top of that, the suggestions follow a reasonable structure where I didn’t know structure had existed before. Copilot showed me how to add structure in my code in unlikely places. For writing SQL, it helped me write those annoying foreign key names in a consistent format [...] [Additionally,] One of the more surprising features has been [that] [...] I ﬁnd myself discovering new API methods, either higher-level ones or ones that are better for my use case.” In order to discover new APIs, of course, the APIs themselves need to be well-designed. Indeed, in some cases the spectacular utility of large language models can be largely attributed to the fact that API designers have already done the hard work of creating an abstraction that is a good ﬁt for real use cases (Myers & Stylos, 2016; Piccioni et al., 2013; Macvean et al., 2016). As a developer who used Copilot to develop a sentiment classiﬁer for Twitter posts matching certain keywords remarks, “These kinds of things are possible not just because of co pilot [sic] but also because we have awesome libraries which have abstracted a lot of tough stuff.” This suggests that API design, not just for human developers but also as a target for large language models, will be important in the near and mid-term future. Moreover, breaking down a prompt at the ‘correct’ level of detail is also emerging as an important developer skill. This requires at least some familiarity, or a good intuition, for the APIs available. Breaking down prompts into steps so detailed that the programmer is effectively writing pseudocode, can be viewed as an anti-pattern, and can give rise to the objections cited earlier that programming via large language models is simply a “very inefﬁcient programming language”. We term this the problem of fuzzy abstraction matching. The problem of ﬁguring out what the system can and can’t do, and matching one’s intent and instructions with the capabilities of the system, is not new – it has been well-documented in natural language interaction (Mu & Sarkar, 2019; Luger & Sellen, 2016). It is also observed in programming notation design as the ‘match-mismatch’ hypothesis (T. R. Green & Petre, 1992; Chalhoub & Sarkar, 2022). In the broadest sense, these can be seen as special cases of Norman’s “gulf of execution” (Hutchins et al., 1985), perhaps the central disciplinary problem of ﬁrst and second- wave (Bødker, 2015) human-computer interaction research: ‘how do I get the computer to do what I want it to do?’. What distinguishes fuzzy abstraction matching from previous incarnations of this problem is the re- silience to, and accommodation of, various levels of abstraction afforded by large language models. In previous natural language interfaces, or programming languages, the user needed to form an extremely speciﬁc mental model before they could express their ideas in machine terms. In contrast, large lan- guage models can generate plausible and correct results for statements at an extremely wide range of abstraction. In the context of programming assistance, this can range from asking the model to write programs based on vague and underspeciﬁed statements, requiring domain knowledge to solve, through to extremely speciﬁc and detailed instructions that are effectively pseudocode. This ﬂexibility is ulti- mately a double-edged sword: it has a lower ﬂoor for users to start getting usable results, but a higher ceiling for getting users to maximum productivity. In the context of programming activities, exploratory programming, where the goal is unknown or ill- deﬁned (Kery & Myers, 2017; Sarkar, 2016), does not ﬁt the framing of fuzzy abstraction matching (or indeed any of the variations of the gulf of execution problem). When the very notion of a crystallised user intent is questioned, or when the design objective is for the system to inﬂuence the intent of the user (as with much designerly and third-wave HCI work), the fundamental interaction questions change. One obvious role the system can play in these scenarios is to help users reﬁne their own concepts (Kulesza et al., 2014) and decide what avenues to explore. Beyond noting that such activities exist, and fall outside the framework we have proposed here, we will not explore them in greater detail in this paper. 7.2. The activity of programming shifts towards checking and unfamiliar debugging When code can be generated quickly, as observed with the studies in Section 6, checking the correctness of generating code becomes a major bottleneck. This shift, or tradeoff, of faster authoring at the expense 11 of greater time spent checking code, is not without criticism. For some it is the wrong balance of priorities between system and programmer. Correspondingly, some users have developed heuristics for when the cost of evaluating the correctness of the code is greater than the time or effort saved by code generation, such as to focus on very short (e.g., single line) completions and ignore longer completions. Furthermore, some users have found that rather than having suggestions show all the time, which can be distracting and time consuming, more intentional use can be made of Copilot by switching off auto- suggestion and only triggering code completion manually using a keyboard shortcut. However, this requires users to form a mental model of when Copilot is likely to help them in their workﬂow. This mental model takes time and intentionality to build, and may be incorrect. Moreover, it introduces a new cognitive burden of constantly evaluating whether the current situation would beneﬁt from LLM assistance. Commenters on Hacker News raise these issues: “I ﬁnd I spend my time reviewing Copilot suggestions (which are mostly wrong) rather than thinking about code and actually doing the work.” “[...] It’s much quicker to read code than to write it. In addition, 95% of Copilots suggestions are a single line and they’re almost always right (and also totally optional).[...] I admit that I’m paranoid every time it suggests more than 2 lines so I usually avoid it. [...] I’ve run into Copilot induced headaches twice. Once was in the ﬁrst week or so of using it. I sweared off [sic] of using it for anything more than a line then. Eventually I started to ease up since it was accurate so often and then I learned my second lesson with another mistake. [...]” “[...] writing code is not the bottleneck in need of optimization. Conceiving the solution is. Any time “saved” through Copilot and it’s ilk is immediately nulliﬁed by having to check it’s correctness. [...]” “What I want is a copilot that ﬁnds errors [...] Invert the relationship. I don’t need some boilerplate generator, I need a nitpicker that’s smarter than a linter. I’m the smart thinker with a biological brain that is inattentive at times. Why is the computer trying to code and leaving mistake catching to me? It’s backwards.” “I turned off auto-suggest and that made a huge difference. Now I’ll use it when I know I’m doing something repetitive that it’ll get easily, or if I’m not 100% sure what I want to do and I’m curious what it suggests. This way I get the help without having it interrupt my thoughts with its suggestions.” Another frequent experience is that language models can introduce subtle, difﬁcult to detect bugs, which are not the kind that would be introduced by a human programmer writing code manually. Thus, existing developer intuitions around the sources of errors in programs can be less useful, or even misleading, when checking the correctness of generated code. One developer reported their experience of having an incorrect, but plausible-sounding ﬁeld name sug- gested by Copilot (accessTokenSecret instead of accessSecret) and the consequent wild goose chase of debugging before discovering the problem. As sources of error, these tools are new, and developers need to learn new craft practices for debugging. “There are zero places that can teach you those things. You must experience them and unlock that kind of knowledge.”, the developer con- cludes, “Don’t let code completion AI tools rule your work. [...] I don’t blame [Copilot] for this. I blame myself. But whatever. At least I got some experience.”. Commenters on Hacker News report similar experiences: “[...] The biggest problem I’ve had is not that it doesn’t write correctly, it’s that it think it knows how and then produce good looking code at a glance but with wrong logic. [...]” “[...] it has proved to be very good at producing superﬁcially appealing output that can stand up not only to a quick scan, but to a moderately deep reading, but still falls apart on a more careful reading. [...] it’s an uncanny valley type effect. [...] it’s almost the most dangerous possible iteration of it, where it’s good enough to fool a human functioning at anything other than the highest level of attentiveness but not good enough to be correct all the time. See also, the dangers of almost self-driving cars; either be self-driving or don’t but don’t expect halfway in between to work well.” 12 “[...] The code it generates _looks_ right but is usually wrong in really difﬁcult to spot ways but things you’d never write yourself.” Many developers reported concerns around such tools repeating private information, or repeating copy- righted code verbatim, which might have implications for the licenses in their own projects. Notions of the dangers of such “stochastic parrots” (Bender et al., 2021) are not new and have been well-explored, and are not as directly connected to the user experience of programming assistance as some of the other concerns we have listed here. As such, we will not enter that discussion in depth here, except to mention that these concerns were present in several blog articles and online discussions. Thus, in practice, programmers describe the challenges of writing effective prompts, misinterpreted intent, code that includes subtle bugs or poor programming practices, the burden of inspecting and checking that generated code is correct, and worries about private information, plagiarism and copyright. 7.3. These tools are useful for boilerplate and code reuse Despite the challenges we have described so far in this section, the utility of these tools in certain contexts is undeniable, and some programmers report having developed workﬂows, in certain contexts, that are heavily dependent on AI assistance. Particularly for simple tasks that require a lot of “boilerplate” code, or common tasks for which there are likely to be snippets of code online which prior to these AI assistants would have required a web search to retrieve. Hacker News commenters write: “These days not having Copilot is a pretty big productivity hit to me. The other day Copilot somehow stopped offering completions for maybe an hour, and I was pretty shocked to realize how much I’ve grown to rely on just hitting tab to complete the whole line. (I was writing Go at the time which is on the boilerplatey side among the mainstream languages, so Copilot is particularly effective [...]” “I use GTP-3 codex [sic] daily when working. It saves me time, helps me explore unfamiliar lan- guages and APIs and generates approaches to solve problems. It can be shockingly good at coding in narrow contexts. It would be a mistake to miss the developments happening in this area” “[...] for a lot of quick programming questions, I’m ﬁnding I don’t even need a search engine. I just use Github Copilot. For example, if I wanted to remember how to throw an exception I’d just write that as a comment and let Copilot ﬁll in the syntax. Between that and ofﬁcial docs, don’t need a ton else.” “[...] It’s changing the way I write code in a way that I can already tell is allowing me to be much lazier than I’ve previously been about learning various details of languages and libraries. [...]” “[...] Github Copilot [...] pretty much replaced almost my entire usage of Stack Overﬂow.[...]” “[...] GitHub Copilot really shines in rote work: when it can correctly infer what you are about to do, it can and will assist you correctly. It’s not able to make big decisions, but in a pinch, it might be able to give hints. [...] If used right, Copilot can give developers a signiﬁcant velocity boost, especially in greenﬁeld projects where there is lots and lots of boilerplate to write. [...]” 8. The inadequacy of existing metaphors for AI-assisted programming 8.1. AI assistance as search In research studies, as well as in reports of developer experiences, comparisons have been drawn between the nature of AI programming assistance and programming by searching and reusing code from the Internet (or from institutional repositories, or from the same project, or from a developer’s previous projects). The comparison between AI programming assistance and search is a natural one, and there are many similarities. Superﬁcially, both have a similar starting point: a prompt or query that is predominantly natural language (but which may also contain code snippets). From the user perspective, both have an information asymmetry: the user does not know precisely what form the result will take. With both search and AI assistance, for any given query, there will be several results, and the user will need to invest time evaluating and comparing them. In both cases, the user may only get an inexact solution, or indeed nothing like what they want, and the user may need to invest time adapting and repairing what they get. 13 However, there are differences. When searching the web, programmers encounter not just code, but a variety of types of results intermingled and enmeshed. These include code snippets interspersed with human commentary, perhaps discussions on forums such as Stack Overﬂow, videos, and images. A search may return new APIs or libraries related to the query, thus showing results at different levels of abstraction. Search has signals of provenance: it is often (though not always) possible to determine the source of a code snippet on the web. There is a lot of information scent priming to assist with the information foraging task (Srinivasa Ragavan et al., 2016). In this way, programming with search is a mixed media experience. In contrast, programming with large language models can be said to be a ﬁxed media experience. The only output is tokens (code, comments, and data) that can be represented within the context of the code editor. This has some advantages: the increased speed of code insertion (which is the immediate aim) often came up in experience reports. However, the learning, exploration, and discovery, and access to a wide variety of sources and media types that occurs in web search is lost. Provenance, too is lost: it is difﬁcult to determine whether the generation is original to the model, or a stochastic parroting (Bender et al., 2021; Ziegler, 2021). Moreover, due to privacy, security, and intellectual property concerns, the provenance of code generated by large language models may be withheld or even destroyed (Sarkar, 2022). This suggests that in future assistance experiences, mixed-media search might be integrated into programmer assistance tools, or the models themselves might be made capable of generating more types of results than the simple code autocomplete paradigm of current tools. 8.2. AI assistance as compilation An alternative perspective is that AI assistance is more like a compiler. In this view, programming through natural language prompts and queries is a form of higher-level speciﬁcation, that is ‘compiled’ via the model to the source code in the target language, which is lower level. Let us (crudely) assume that as programming notations travel along the abstraction continuum from ‘lower’ to ‘higher’ levels, the programmer becomes, ﬁrstly, less concerned with the mechanistic details of program execution, and secondly, more and more declarative, specifying what computation is required rather than how to compute it. In general, these are desirable properties of programming notations, but they do not always make the activity of programming easier or more accessible. As people who write code in declarative languages or formal veriﬁcation tools will tell you, it’s often much more difﬁcult to specify the what than the how. The much more broadly adopted practice of test-driven development is adjacent; while tests are not necessarily written in a higher-level language than the code, they aim to capture a higher-level notion of correctness, the what of the problem being solved. Learning to be a test engineer takes time and experience, and the entire distinct career path of “software engineer in test” attests to the specialised requirements of programming at higher levels of abstraction. Some would draw a distinction between programming in a speciﬁcation language and a compiled pro- gramming language. Tony Hoare himself considers these different, on the grounds that while a compiler only aims to map a program from the source language into a ﬁnite set of valid programs in the target language, a speciﬁcation might be satisﬁed by an inﬁnite number of valid programs (pers comm., ﬁrst author, ca. 2014). Thus the technical and interaction design problems of programming through speciﬁ- cation reﬁnement encompasses, but is much broader than, the technical and interaction design problems of compilers. While we acknowledge this distinction, there is insufﬁcient empirical evidence from the experience reports summarised in Section 7 that working programmers themselves consistently make a meaningful distinction between these concepts. Programming with large language models, like in a higher-level notation, also allows the programmer to be less concerned with details of the target language. For example, developers in our experience reports relied on AI assistance to ﬁll in the correct syntax, or to discover and correctly use the appropriate API call, thus allowing them to focus on higher-level aspects of the problem being solved. However, there are fundamental differences between this experience and the experience of using a compiler. First, the abstraction is not complete, i.e., a programmer cannot completely be unaware of the target language, they 14 must still be able to understand and evaluate the generated code in order to use such tools effectively. With compilers, although knowledge of the target language can help experienced developers in certain circumstances, it is far from a prerequisite for effective usage. Moreover, compilers can be relied on almost universally to generate a correct and complete translation from source to target language, whereas programming with AI assistance involves the active checking and adaptation of translated code. Next, compilers are (comparatively) deterministic, in that they consistently produce the same output for the same input, but this is not the case for current AI programming tools (although this is not a fundamental limitation, and consistency can be enforced). Finally, though they are often criticised for being cryptic and unhelpful (Barik et al., 2018), compilers do offer levels of interaction and feedback through warnings and error messages, which help the programmer improve the code in the source language; there is currently no such facility with AI programming tools and this strikes us as an area with potential for innovation. Perhaps more profoundly, while natural language can be used to express concepts at a higher abstraction level, the range of abstraction expressible in natural language is much wider than with other forms of programming notation. Traditional programming notations with ad-hoc abstraction capabilities (subrou- tines, classes, etc.) allow programmers to manually raise the level of abstraction of their own code and APIs. But with code generated by language models, as we have seen from the reports in Section 7, a prompt can span the gamut from describing an entire application in a few sentences, to painstakingly describing an algorithm in step-by-step pseudocode. Thus it would be a mistake to view programming with AI assistance as another rung on the abstraction ladder. Rather, it can be viewed as a device that can teleport the programmer to arbitrary rungs of the ladder as desired. We close the discussion on AI assistance as a compiler with a few miscellaneous notes. The idea of using natural language as a programming notation has a long history (e.g., (Miller, 1981; Lieberman & Liu, 2006)), which we will not cover here. However, it is notable that there are many ways that natural language has been integrated with programming, such as debugging (Ko & Myers, 2004). With large language models, there are better capabilities for inference of intent and translation to code, but therefore also the potential to open up new strategies for inspecting and explaining code. There are also new failure modes for this paradigm of programming. 8.3. AI assistance as pair programming The third common perspective is that AI-assisted programming is like pair programming. GitHub Copi- lot’s commercial tagline describes it as “your AI pair programmer”. As opposed to search and compi- lation, which are both relatively impersonal tools, the analogy with pair programming is evocative of a more bespoke experience; assistance from a partner that understands more about your speciﬁc context and what you’re trying to achieve. AI-assisted programming does have the potential to be more person- alised, to the extent that it can take into consideration your speciﬁc source code and project ﬁles. As Hacker News commenters write: “[...] at one point it wrote an ENTIRE function by itself and it was correct. [...] it wasn’t some dumb boilerplate initialization either, it was actual logic with some loops. The context awareness with it is off the charts sometimes.[...]” “[...] It’s like having the stereotypical “intern” as an associate built-in to your editor. [...] It’s also ridiculously ﬂexible. When I start writing graphs in ASCII (cause I’m just quickly writing something down in a scratch ﬁle) it’ll actually understand what I’m doing and start autocompleting textual nodes in that ASCII graph.” Besides personalisation, the analogy also recalls the conventional role-division of pair programming between “driver” and “navigator”. When programming, one needs to form mental models of the program at many layers: from the speciﬁc statement being worked on, to its context in a subroutine, to the role that subroutine plays in a module, to the module within the program. However, code must be written at the statement level, which forces developers to keep this lowest level constantly at the forefront of their working memory. Experienced developers spend more time mapping out their code so that they can spend less time writing it. Research into code display and navigation has explored how different ways 15 of presenting lines of code can help programmers better keep these different layers of mental models in mind (Henley & Fleming, 2014). Pair programming, the argument goes, allows two partners to share the burden of the mental model. The driver codes at the statement and subroutine level while the navigator maps out the approach at the module and program level. By analogy to pair programming, the AI assistant taking the role of the driver, a solo programmer can now take the place of the navigator. But as we have seen, the experience of programming with AI assistance does not consistently absolve the human programmer of the responsibility for understanding the code at the statement and subroutine level. The programmer may be able to become “lazier [...] about learning various details of syntax and libraries”, but the experience still involves much greater statement-level checking. While a pair programming session requires a conscious, negotiated decision to swap roles, a solo pro- grammer with an AI assistant might ﬁnd themselves ﬂuidly traversing the spectrum from driving to navigation, from one moment to the next. This may partially explain why, in a preliminary experiment (n=21) comparing the experience of “pair programming” with GitHub Copilot to programming in a hu- man pair either as driver or navigator, Imai (2022) ﬁnds that programmers write more lines of code with Copilot than in a human pair, but these lines are of lower quality (more are subsequently deleted). Moreover, meta-analyses of pair programming have shown mixed efﬁcacy of human pair programming on task time, code quality and correctness (Salge & Berente, 2016; Hannay et al., 2009), suggesting that emulating the pair programming experience is not necessarily a good target to aim for. Multiple studies have concluded that the apparent successes of pair programming can be attributed, not to the role division into driver and navigator, but rather the high degree of verbalisation that occurs when pair programmers are forced to rationalise their decisions to each other (Hannay et al., 2009). Others have found that programming in pairs induces greater focus out of a respect for shared time; pair programmers are less likely to read emails, surf the web, or take long phone calls (L. A. Williams & Kessler, 2000). These particular beneﬁts of pair programming are not captured at all by AI assistance tools. The comparison to pair programming is thus relatively superﬁcial, and today’s experience of AI-assisted programming is not comparable with pair programming to the same extent as it is with search or compi- lation. 8.4. A distinct way of programming LLM-assisted programming assistance bears similarities to search: both begin with a prompt, both have an information asymmetry, there are several results, with inexact solutions. But there are differences: search is mixed-media, whereas LLM assistance is ﬁxed. Search (often) has provenance, and language models do not. It also bears similarities to compilation and programming by speciﬁcation. Both enable programming at a ‘higher’ level of abstraction (for some deﬁnition of higher). Yet unlike with compilers, a programmer using AI assistance must still have a working knowledge of the target language, they must actively check the output for correctness, and they get very little feedback for improving their ‘source’ code. It also bears a superﬁcial similarity to pair programming, in that it promises to let the programmer take the role of ‘navigator’, forming high-level mental models of the program while delegating the role of ‘driver’ to the language model. But unlike with pair programming, the human navigator must often hop into the driver’s seat. And unlike with pair programming, LLM-assisted programming does not require verbalisation, nor does it coerce greater focus out of a respect for shared time. Thus existing metaphors do not completely capture the experience of LLM-assisted programming. It is emerging as a distinct way of programming. It does not quite strike us as a distinct practice of pro- gramming, as that term has been applied to communities of programmers united by similar ethos and aims, such as enterprise software engineers, bricoleurs, live coders, and code benders; but as Bergström & Blackwell (2016) note, there are no clear criteria by which we can deﬁne the boundaries of a prac- tice. Nor does it strike us as being a new activity of programming as per the cognitive dimensions 16 Figure 6 – GridBook interface showing natural language formula in the spreadsheet grid. framework, since AI assistance is clearly orthogonal to authoring, transcription, and modiﬁcation, being applicable to each of these activities and others besides. Yet as a way of programming it seems to affect programmer’s experience more profoundly than a feature such as autocomplete, having far-reaching im- pact on their attitudes and practices of authoring, information foraging, debugging, refactoring, testing, documentation, code maintenance, learning, and more. 9. Issues with application to end-user programming The beneﬁts and challenges of programming with LLMs discussed so far concern the professional pro- grammer, or a novice programmer in training. They have formal training in programming and, often, some understanding of the imperfect nature of AI-generated code. But the majority of people who pro- gram do not fall into this category. Instead, they are ordinary end users of computers who program to an end. Such end-user programmers often lack knowledge of programming, or the workings of AI. They also lack the inclination to acquire those skills. It is reasonable to say that such end-user programmers (e.g., accountants, journalists, scientists, business owners) stand to beneﬁt the most from AI assistance, such as LLMs. In an ideal world, an end-user wanting to accomplish a task could do so by simply specifying their intent in familiar natural language without prior knowledge of the underlying programming model, or its syntax and semantics. The code will get generated and even automatically run to produce the desired output. However, as we have seen so far, the world is not ideal and even trained programmers face various chal- lenges when programming with AI. These challenges are only exacerbated for end-user programmers, as a study by Srinivasa Ragavan et al. (2022) observes. Participants in the study were data analysts (n=20) conducting exploratory data analysis in GridBook, a natural-language augmented spreadsheet system. In GridBook (Figure 6, adopted from Srinivasa Ra- gavan et al. (2022)) users can write spreadsheet formulas using the natural language (Figure 6: a-f); a formal formula is then synthesized from the natural language utterance. GridBook also infers the con- text of an utterance; for example, in Figure 6, the query in label 4 is a follow-up from label 3. Both the natural language utterance and the synthesized formula are persisted for users to edit and manipulate. 17 9.1. Issue 1: Intent speciﬁcation, problem decomposition and computational thinking When attempting to accomplish data analysis tasks using natural language, participants had to reﬁne their speciﬁcation of intent in the natural language several times, before they arrived at the desired result (if they did). The NL utterances were often underspeciﬁed, ambiguous, too complex, or contained domain phrases not speciﬁed in the context (e.g., in the data being analyzed). Thus, the ﬁrst issue is to communicate the capabilities of the system, and make it interpretable so users can see how their prompt is being interpreted. End-user programmers often also lack the key computational thinking skills (Wing, 2011), such as the ability to decompose problems into subproblems, reformulate problems in ways that can be computed by a system, etc. However, effective use of LLMs such as Codex requires such skills. For example, if these models are most accurate when solutions to a problem are single line, then the user should be able to break their problem into smaller sub-problems each of which can be solved in one or two lines. Moreover, they might also lack the ability to frame a problem as generic computational problems, rather than domain-speciﬁc problems. For example, a realtor is more likely to ask “which is the largest house” (declaratively), instead of “which is the house with maximum constructed area” (procedurally). Therefore, end-user computing environments powered by AI should help end-user programmers think “computationally”: they must aid users in breaking down their problems to smaller steps, or guiding users towards alternative strategies to specify or solve a problem (e.g., providing examples, offering alternatives) or even seek procedural prompts where needed (e.g., for disambiguation). 9.2. Issue 2: Code correctness, quality and (over)conﬁdence The second challenge is in verifying whether the code generated by the model is correct. In GridBook, users were able to see the natural language utterance, synthesized formula and the result of the for- mula. Of these, participants heavily relied on ‘eyeballing’ the ﬁnal output as a means of evaluating the correctness of the code, rather than, for example, reading code or testing rigorously. While this lack of rigorous testing by end-user programmers is unsurprising, some users, particularly those with low computer self-efﬁcacy, might overestimate the accuracy of the AI, deepening the overcon- ﬁdence end-user programmers are known to have in their programs’ accuracy Panko (2008). Moreover, end-user programmers might not be able to discern the quality of non-functional aspects of the generated code, such as security, robustness or performance issues. 9.3. Issue 3: Code comprehension and maintenance A third challenge with AI-driven programming is the issue of code comprehension. During GridBook’s user evaluation, participants mentioned that the generated formulas are hard to understand, even when users were familiar with the target language. This has potentially severe consequences: from evaluating the accuracy of the program by verifying logic, to the ability to customize code, to future debugging and reuse. As we discussed earlier, this problem also exists for trained developers. One approach to address this issue is for the AI system to include some notion of code readability or comprehensibility as a factor in code synthesis, such as during the learning phase, or when ranking suggestions, or even take it as input to the model (similar to the ‘temperature’ parameter in Codex). This approach is useful more broadly to synthesize high quality code, such as optimizing for performance or robustness. A second solution to tackle the comprehension problem is to explain the generated code to their users in a manner that is less ‘programmerese’ and more centered around the user’s current task and context. Initial evidence suggests that participants were open to these ideas; thus, these areas are ripe for future exploration. 9.4. Issue 4: Consequences of automation in end-user programming In any AI system, we need to consider the consequences of automation. End-user programmers are known to turn to local experts or gardeners (end-user programmers with interest and expertise in pro- gramming who serve as gurus in the end-user programming environment) when they are unable to solve a part of the problem (Nardi, 1993; Sarkar & Gordon, 2018). Task-orientation tendencies combined with 18 challenges of completing their tasks easily also leaves end-user programmers with limited attention for testing, or carefully learning what is going on with their programs. Assuming that LLMs and associated user experiences will improve in the coming years, making end-user programming faster with LLMs than without, it is tempting to wonder whether the programmer can be persuaded to invest the saved time and attention to aspects such as learning or testing their programs; if so, what would it take to inﬂuence behaviour changes? Another question is in the role of such experts. We conjecture that LLMs or similar AI capabilities will soon be able to answer a sizeable fraction of questions that end-user programmers will go to local experts for. An open question therefore is how the ecosystem of end-user programmers in organizations will change in their roles, importance and specialities. For example, will gardeners take on the role of educating users on better taking advantage of AI? If so, how can we communicate the working of such AI systems to technophile users and early adopters, so they can enable others in the organization? 9.5. Issue 5: No code, and the dilemma of the direct answer Finally, it is not a foregone conclusion that users are even interested in code. As Blackwell’s model of attention investment notes, in many cases the user may be content to perform an action manually, rather than invest in creating a reusable automation (Blackwell, 2002a; J. Williams et al., 2020). Spreadsheet users, in particular, are often not sensitive to the level of automation or automatability of a given work- ﬂow, using a mix of manual, automated, and semi-automated techniques to achieve the goal at hand (Pandita et al., 2018). Spreadsheet users often need ad-hoc transformations of their data that they will, in all likelihood, never need again. It may be that we can express this transformation as a program, but if the user is interested in the output and not the program, is it important, or even necessary, to communicate this fact to the user? One can argue that increasing the user’s awareness of the ﬂexibility and fallibility of the process of delivering an inferred result (i.e., enabling them to critically evaluate the output (Sarkar et al., 2015)) can build agency, conﬁdence, trust, and resilience. This issue is related to information retrieval’s “dilemma of the direct answer” (Potthast et al., 2021), raised in response to the increased phenomenon of search engines directly answering queries in addition to simply listing retrieved results. However, if the programming language used is not related to the languages familiar to the end-user, or the user is a complete novice, it is exceedingly difﬁcult for them to make any sense of it, as was shown by Lau et al. (2021) in their study of Excel users encountering Python code. Yet, there are socio-technical motivations for using an unfamiliar target language: long-term testing of LLM assistance shows that it shines when paired with high-level APIs that capture use cases well (Section 7). One advantage of the Python ecosystem is that it has an unparalleled set of libraries and APIs for data wrangling. An LLM-assisted tool that emits Excel formulas is therefore less likely to solve user problems than Python statements. In the longer term, this might be mitigated by developing a rich set of data manipulation libraries in the Excel formula language. 10. Conclusion Large language models have initiated a signiﬁcant change in the scope and quality of program code that can be automatically generated, compared to previous approaches. Experience with commercially available tools built on these models suggests that a they represent a new way of programming. LLM assistance transforms almost every aspect of the experience of programming, including planning, au- thoring, reuse, modiﬁcation, comprehension, and debugging. In some aspects, LLM assistance resembles a highly intelligent and ﬂexible compiler, or a partner in pair programming, or a seamless search-and-reuse feature. Yet in other aspects, LLM-assisted programming has a ﬂavour all of its own, which presents new challenges and opportunities for human-centric pro- gramming research. Moreover, there are even greater challenges in helping non-expert end users beneﬁt from such tools. 19 A. Experience report sources This appendix contains a list of sources we draw upon for the quotes and analysis in Section 7. While all sources were included in our analysis, we did not draw direct quotes from every source in this list. A.1. Blog posts and corresponding Hacker News discussions 1. Andrew Mayne, March 17 2022, “Building games and apps entirely through natural language using OpenAI’s code-davinci model”. URL: https://andrewmayneblog.wordpress .com/2022/03/17/building-games-and-apps-entirely-through-natural -language-using-openais-davinci-code-model/. Hacker News discussion: https://news.ycombinator.com/item?id=30717773 2. Andrew Mouboussin, March 24 2022, “Building a No-Code Machine Learning Model by Chat- ting with GitHub Copilot”. URL: https://www.surgehq.ai/blog/building-a-no -code-toxicity-classifier-by-talking-to-copilot. Hacker News discussion: https://news.ycombinator.com/item?id=30797381 3. Matt Rickard, August 17 2021, “One Month of Using GitHub Copilot”. URL: https://matt -rickard.com/github-copilot-a-month-in/. 4. Nutanc, November 15 2021, “Using Github copilot to get the tweets for a keyword and ﬁnd the sentiment of each tweet in 2 mins”. URL: https://nutanc.medium.com/ using-github-copilot-to-get-the-tweets-for-a-keyword-and-find -the-sentiment-of-each-tweet-in-2-mins-9a531abedc84. 5. Tanishq Abraham, July 14 2021, “Coding with GitHub Copilot”. URL: https://tmabraham .github.io/blog/github_copilot. 6. Aleksej Komnenovic, January 17 2022, “Don’t fully trust AI in dev work! https://akom.me/dont-fully-trust-ai-in-dev-work-yet. /yet”. URL: A.2. Miscellaneous Hacker News discussions 1. https://news.ycombinator.com/item?id=30747211 2. https://news.ycombinator.com/item?id=31390371 3. https://news.ycombinator.com/item?id=31020229&p=2 4. https://news.ycombinator.com/item?id=29760171 5. https://news.ycombinator.com/item?id=31325154 6. https://news.ycombinator.com/item?id=31734110 7. https://news.ycombinator.com/item?id=31652939 8. https://news.ycombinator.com/item?id=30682841 9. https://news.ycombinator.com/item?id=31515938 10. https://news.ycombinator.com/item?id=31825742 20 References Allamanis, M., Barr, E. T., Devanbu, P. T., & Sutton, C. (2018). A survey of machine learning for big code and naturalness. ACM Comput. Surv., 51(4), 81:1–81:37. Retrieved from https://doi .org/10.1145/3212695 doi: 10.1145/3212695 Allamanis, M., & Brockschmidt, M. (2017). Smartpaste: Learning to adapt source code. arXiv preprint arXiv:1705.07867. Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., . . . Sutton, C. (2021). Program synthesis with large language models. arXiv. Retrieved from https://arxiv.org/abs/2108 .07732 doi: 10.48550/ARXIV.2108.07732 Barik, T., Ford, D., Murphy-Hill, E., & Parnin, C. (2018). How should compilers explain problems to developers? In Proceedings of the 2018 26th acm joint meeting on european software engineering conference and symposium on the foundations of software engineering (pp. 633–643). Barik, T., Johnson, B., & Murphy-Hill, E. (2015). I heart hacker news: expanding qualitative research ﬁndings by analyzing social news websites. In Proceedings of the 2015 10th joint meeting on foun- dations of software engineering (pp. 882–885). Barke, S., James, M. B., & Polikarpova, N. (2022). Grounded copilot: How programmers interact with code-generating models. arXiv. Retrieved from https://arxiv.org/abs/2206.15000 doi: 10.48550/ARXIV.2206.15000 Basman, A., Church, L., Klokmose, C. N., & Clark, C. B. (2016). Software and how it lives on- embedding live programs in the world around them. In Ppig (p. 19). Bender, E. M., Gebru, T., McMillan-Major, A., & Shmitchell, S. (2021). On the dangers of stochastic parrots: Can language models be too big? In M. C. Elish, W. Isaac, & R. S. Zemel (Eds.), Facct ’21: 2021 ACM conference on fairness, accountability, and transparency, virtual event / toronto, canada, march 3-10, 2021 (pp. 610–623). ACM. Retrieved from https://doi.org/10.1145/ 3442188.3445922 doi: 10.1145/3442188.3445922 Bergström, I., & Blackwell, A. F. (2016). The practices of programming. In 2016 ieee symposium on visual languages and human-centric computing (vl/hcc) (pp. 190–198). Blackwell, A. F. (2002a). First steps in programming: A rationale for attention investment models. In Proceedings ieee 2002 symposia on human centric computing languages and environments (pp. 2–10). Blackwell, A. F. (2002b). What is programming? In Ppig (p. 20). Bødker, S. (2015). Third-wave hci, 10 years later - participation and sharing. Interactions, 22(5), 24–31. Retrieved from https://doi.org/10.1145/2804405 doi: 10.1145/2804405 Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., . . . Amodei, D. (2020). Language models are few-shot learners. Cao, J., Fleming, S. D., Burnett, M., & Scafﬁdi, C. (2015). Idea garden: Situated support for problem solving by end-user programmers. Interacting with Computers, 27(6), 640–660. Chalhoub, G., & Sarkar, A. (2022). “It’s Freedom to Put Things Where My Mind Wants”: Understanding In CHI Conference on and Improving the User Experience of Structuring Data in Spreadsheets. Human Factors in Computing Systems. New York, NY, USA: Association for Computing Machinery. Retrieved from https://doi.org/10.1145/3491102.3501833 doi: 10.1145/3491102 .3501833 21 Chen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., . . . Zaremba, W. (2021). Evaluating large language models trained on code. CoRR, abs/2107.03374. Retrieved from https://arxiv.org/abs/2107.03374 Chen, M., Tworek, J., Jun, H., Yuan, Q., Ponde, H., Kaplan, J., . . . Zaremba, W. (2021). Evaluating large language models trained on code. ArXiv, abs/2107.03374. Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., . . . Fiedel, N. (2022). Palm: Scaling language modeling with pathways. ArXiv, abs/2204.02311. Colmerauer, A., & Roussel, P. (1996). The birth of prolog. In History of programming languages—ii (pp. 331–367). Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019, June). BERT: Pre-training of deep bidi- In Proceedings of the 2019 conference of the rectional transformers for language understanding. north American chapter of the association for computational linguistics: Human language technolo- gies, volume 1 (long and short papers) (pp. 4171–4186). Minneapolis, Minnesota: Association for Computational Linguistics. Retrieved from https://aclanthology.org/N19-1423 doi: 10.18653/v1/N19-1423 Green, T., & Blackwell, A. (1998). Cognitive dimensions of information artefacts: a tutorial. In Bcs hci conference (Vol. 98, pp. 1–75). Green, T. R. (1989). Cognitive dimensions of notations. People and computers V, 443–460. Green, T. R., & Petre, M. (1992). When visual programs are harder to read than textual programs. In Human-computer interaction: Tasks and organisation, proceedings of ecce-6 (6th european confer- ence on cognitive ergonomics). gc van der veer, mj tauber, s. bagnarola and m. antavolits. rome, cud (pp. 167–180). Gulwani, S. (2011). Automating string processing in spreadsheets using input-output examples. In T. Ball & M. Sagiv (Eds.), Proceedings of the 38th ACM SIGPLAN-SIGACT symposium on principles of programming languages, POPL 2011, austin, tx, usa, january 26-28, 2011 (pp. 317–330). ACM. Retrieved from https://doi.org/10.1145/1926385.1926423 doi: 10.1145/1926385 .1926423 Hannay, J. E., Dybå, T., Arisholm, E., & Sjøberg, D. I. (2009). The effectiveness of pair programming: A meta-analysis. Information and software technology, 51(7), 1110–1122. Henley, A. Z., & Fleming, S. D. (2014). The patchworks code editor: Toward faster navigation with less code arranging and fewer navigation mistakes. In Proceedings of the sigchi conference on human factors in computing systems (pp. 2511–2520). Hermans, F., Pinzger, M., & van Deursen, A. (2015). Detecting and refactoring code smells in spread- sheet formulas. Empirical Software Engineering, 20(2), 549–575. Hindle, A., Barr, E. T., Gabel, M., Su, Z., & Devanbu, P. T. (2016). On the naturalness of software. Commun. ACM, 59(5), 122–131. Retrieved from https://doi.org/10.1145/2902362 doi: 10.1145/2902362 Hindle, A., Barr, E. T., Su, Z., Gabel, M., & Devanbu, P. T. (2012). On the naturalness of soft- In M. Glinz, G. C. Murphy, & M. Pezzè (Eds.), 34th international conference on soft- ware. ware engineering, ICSE 2012, june 2-9, 2012, zurich, switzerland (pp. 837–847). IEEE Com- puter Society. Retrieved from https://doi.org/10.1109/ICSE.2012.6227135 doi: 10.1109/ICSE.2012.6227135 22 Hoare, C. A. R. (1969). An axiomatic basis for computer programming. Commun. ACM, 12(10), 576– 580. Retrieved from https://doi.org/10.1145/363235.363259 doi: 10.1145/363235 .363259 Hochreiter, S., & Schmidhuber, J. (1997, nov). Long short-term memory. Neural Comput., 9(8), 1735–1780. Retrieved from https://doi.org/10.1162/neco.1997.9.8.1735 doi: 10 .1162/neco.1997.9.8.1735 Horvitz, E. (1999). Principles of mixed-initiative user interfaces. In Proceedings of the sigchi conference on human factors in computing systems (pp. 159–166). Hutchins, E. L., Hollan, J. D., & Norman, D. A. (1985). Direct manipulation interfaces. Hum. Comput. Interact., 1(4), 311–338. Retrieved from https://doi.org/10.1207/s15327051hci0104 _2 doi: 10.1207/s15327051hci0104\_2 Imai, S. (2022). Is github copilot a substitute for human pair-programming? an empirical study. In 2022 ieee/acm 44th international conference on software engineering: Companion proceedings (icse- companion) (pp. 319–321). Jiang, E., Toh, E., Molina, A., Olson, K., Kayacik, C., Donsbach, A., . . . Terry, M. (2022). Discovering the syntax and strategies of natural language programming with generative language models. In Chi conference on human factors in computing systems (pp. 1–19). Kery, M. B., & Myers, B. A. (2017). Exploring exploratory programming. In 2017 ieee symposium on visual languages and human-centric computing (vl/hcc) (pp. 25–29). Ko, A. J., & Myers, B. A. (2004). Designing the whyline: a debugging interface for asking questions In Proceedings of the sigchi conference on human factors in computing about program behavior. systems (pp. 151–158). Kulesza, T., Amershi, S., Caruana, R., Fisher, D., & Charles, D. (2014). Structured labeling for facilitat- ing concept evolution in machine learning. In Proceedings of the sigchi conference on human factors in computing systems (pp. 3075–3084). Kurlander, D., Cypher, A., & Halbert, D. C. (1993). Watch what i do: programming by demonstration. MIT press. Lau, S., Srinivasa Ragavan, S. S., Milne, K., Barik, T., & Sarkar, A. (2021). Tweakit: Supporting end- user programmers who transmogrify code. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (pp. 1–12). Li, J., Tang, T., Zhao, W. X., & Wen, J.-R. (2021, 8). Pretrained language model for text generation: A survey. In Z.-H. Zhou (Ed.), Proceedings of the thirtieth international joint conference on artiﬁcial intelligence, IJCAI-21 (pp. 4492–4499). International Joint Conferences on Artiﬁcial Intelligence Organization. Retrieved from https://doi.org/10.24963/ijcai.2021/612 (Survey Track) doi: 10.24963/ijcai.2021/612 Li, Y., Choi, D., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., . . . Vinyals, O. (2022b). Competition-level code generation with alphacode. arXiv. Retrieved from https://arxiv.org/ abs/2203.07814 doi: 10.48550/ARXIV.2203.07814 Li, Y., Choi, D. H., Chung, J., Kushman, N., Schrittwieser, J., Leblond, R., . . . Vinyals, O. (2022a). Competition-level code generation with alphacode. ArXiv, abs/2203.07814. Lieberman, H. (2001). Your wish is my command: Programming by example. Morgan Kaufmann. 23 Lieberman, H., & Liu, H. (2006). Feasibility studies for programming in natural language. In End user development (pp. 459–473). Springer. Liu, S., Chen, Y., Xie, X., Siow, J. K., & Liu, Y. (2021). Retrieval-augmented generation for code summarization via hybrid GNN. In International conference on learning representations. Retrieved from https://openreview.net/forum?id=zv-typ1gPxA Lu, S., Guo, D., Ren, S., Huang, J., Svyatkovskiy, A., Blanco, A., . . . Liu, S. (2021). Codexglue: A machine learning benchmark dataset for code understanding and generation. ArXiv, abs/2102.04664. Luger, E., & Sellen, A. (2016). ""like having a really bad pa"" the gulf between user expectation and experience of conversational agents. In Proceedings of the 2016 chi conference on human factors in computing systems (pp. 5286–5297). Macvean, A., Church, L., Daughtry, J., & Citro, C. (2016). Api usability at scale. In Ppig (p. 26). Marasoiu, M., Church, L., & Blackwell, A. (2015). An empirical investigation of code completion usage by professional software developers. In PPIG. Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In C. Burges, L. Bottou, M. Welling, Z. Ghahramani, & K. Weinberger (Eds.), Advances in neural information processing systems (Vol. 26). Curran As- sociates, Inc. Retrieved from https://proceedings.neurips.cc/paper/2013/file/ 9aa42b31882ec039965f3c4923ce901b-Paper.pdf Miller, L. A. (1981). Natural language programming: Styles, strategies, and contrasts. IBM Systems Journal, 20(2), 184–215. Mou, L., Li, G., Zhang, L., Wang, T., & Jin, Z. (2016). Convolutional neural networks over tree structures for programming language processing. In Aaai. Mu, J., & Sarkar, A. (2019). Do we need natural language? Exploring restricted language interfaces In Extended Abstracts of the 2019 CHI Conference on Human Factors in for complex domains. Computing Systems (pp. 1–6). Myers, B. A. (1992). Demonstrational interfaces: A step beyond direct manipulation. Computer, 25(8), 61–73. Myers, B. A., & Stylos, J. (2016). Improving api usability. Communications of the ACM, 59(6), 62–69. Nardi, B. A. (1993). A small matter of programming: perspectives on end user computing. MIT press. Nguyen, A. T., Nguyen, T. T., & Nguyen, T. N. (2015). Divide-and-conquer approach for multi-phase statistical migration for source code (t). 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), 585-596. Pandita, R., Parnin, C., Hermans, F., & Murphy-Hill, E. (2018). No half-measures: A study of manual and tool-assisted end-user programming tasks in excel. In 2018 ieee symposium on visual languages and human-centric computing (vl/hcc) (pp. 95–103). Panko, R. R. (2008). Reducing overconﬁdence in spreadsheet development. arXiv preprint arXiv:0804.0941. Pearce, H., Ahmad, B., Tan, B., Dolan-Gavitt, B., & Karri, R. (2021). Asleep at the keyboard? assessing the security of github copilot’s code contributions. arXiv. Retrieved from https://arxiv.org/ abs/2108.09293 doi: 10.48550/ARXIV.2108.09293 24 Piccioni, M., Furia, C. A., & Meyer, B. (2013). An empirical study of api usability. In 2013 acm/ieee international symposium on empirical software engineering and measurement (pp. 5–14). Potthast, M., Hagen, M., & Stein, B. (2021). The dilemma of the direct answer. In Acm sigir forum (Vol. 54, pp. 1–12). Raychev, V., Vechev, M. T., & Krause, A. (2015). Predicting program properties from ""big code"". In S. K. Rajamani & D. Walker (Eds.), Proceedings of the 42nd annual ACM SIGPLAN-SIGACT sympo- sium on principles of programming languages, POPL 2015, mumbai, india, january 15-17, 2015 (pp. 111–124). ACM. Retrieved from https://doi.org/10.1145/2676726.2677009 doi: 10.1145/2676726.2677009 Rouchy, P. (2006). Aspects of prolog history: Logic programming and professional dynamics. Blekinge Institute of Technology, Sweden).(English). TeamEthno-Online(2), 85–100. Salge, C. A. D. L., & Berente, N. (2016). Pair programming vs. solo programming: What do we know after 15 years of research? In 2016 49th hawaii international conference on system sciences (hicss) (pp. 5398–5406). Sarkar, A. (2016). Interactive analytical modelling (Tech. Rep. No. UCAM-CL-TR-920). Uni- versity of Cambridge, Computer Laboratory. Retrieved from https://www.cl.cam.ac.uk/ techreports/UCAM-CL-TR-920.pdf doi: 10.48456/tr-920 Sarkar, A. (2022, March). In Workshop on Transparency and Explanations in Smart Systems (TeXSS), in conjunction with ACM Intelligent User Interfaces (IUI 2022) (pp. 192–199). Retrieved from http://ceur-ws.org/Vol-3124/ paper22.pdf Is explainable AI a race against model complexity? Sarkar, A., & Gordon, A. D. (2018, September). How do people learn to use spreadsheets? (work in progress). In Proceedings of the 29th Annual Conference of the Psychology of Programming Interest Group (PPIG 2018) (pp. 28–35). Sarkar, A., Jamnik, M., Blackwell, A. F., & Spott, M. Interactive visual machine learning (2015). In 2015 IEEE Symposium on Visual Languages and Human-Centric Computing in spreadsheets. (VL/HCC) (pp. 159–163). Sarkar, A., Srinivasa Ragavan, S., Williams, J., & Gordon, A. D. (2022). End-user encounters with lambda abstraction in spreadsheets: Apollo’s bow or Achilles’ heel? In 2022 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC). Shneiderman, B., & Norwood, N. (1993). 1.1 direct manipulation: a step beyond programming. Sparks of innovation in human-computer interaction, 17. Silver, A. (2018, May). Introducing visual studio intellicode. Microsoft. Retrieved from https://devblogs.microsoft.com/visualstudio/introducing-visual -studio-intellicode/ Srinivasa Ragavan, S., Hou, Z., Wang, Y., Gordon, A. D., Zhang, H., & Zhang, D. (2022). Gridbook: Natural language formulas for the spreadsheet grid. In 27th international conference on intelligent user interfaces (p. 345–368). New York, NY, USA: Association for Computing Machinery. Retrieved from https://doi.org/10.1145/3490099.3511161 doi: 10.1145/3490099.3511161 Srinivasa Ragavan, S., Kuttal, S. K., Hill, C., Sarma, A., Piorkowski, D., & Burnett, M. (2016). Foraging among an overabundance of similar variants. In Proceedings of the 2016 chi conference on human factors in computing systems (pp. 3509–3521). 25 Sutskever, I., Vinyals, O., & Le, Q. V. (2014). Sequence to sequence learning with neural networks. In Proceedings of the 27th international conference on neural information processing systems - volume 2 (p. 3104–3112). Cambridge, MA, USA: MIT Press. Tanimoto, S. L. (2013). A perspective on the evolution of live programming. In 2013 1st international workshop on live programming (live) (pp. 31–34). Vaithilingam, P., Zhang, T., & Glassman, E. L. (2022). Expectation vs. experience: Evaluating the usability of code generation tools powered by large language models. In Chi conference on human factors in computing systems extended abstracts (pp. 1–7). Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., . . . Polosukhin, I. (2017). Attention is all you need. In Proceedings of the 31st international conference on neural information processing systems (p. 6000–6010). Red Hook, NY, USA: Curran Associates Inc. Wei, J., Goyal, M., Durrett, G., & Dillig, I. (2020). Lambdanet: Probabilistic type inference using graph neural networks. ArXiv, abs/2005.02161. Wei, Y., Chandrasekaran, N., Gulwani, S., & Hamadi, Y. (2015, May). Building bing developer assistant (Tech. Rep. No. MSR-TR-2015-36). Retrieved from https://www.microsoft.com/en-us/ research/publication/building-bing-developer-assistant/ Weiss, D. (2022, Jun). Blog / tabnine announcements / announcing our next-generation ai models. Tab- nine. Retrieved from https://www.tabnine.com/blog/announcing-tabnine-next -generation/ Williams, J., Negreanu, C., Gordon, A. D., & Sarkar, A. (2020). Understanding and inferring units In 2020 IEEE Symposium on Visual Languages and Human-Centric Computing in spreadsheets. (VL/HCC) (pp. 1–9). Williams, L. A., & Kessler, R. R. (2000). All i really need to know about pair programming i learned in kindergarten. Communications of the ACM, 43(5), 108–114. Wing, J. (2011). Research notebook: Computational thinking—what and why. The link magazine, 6, 20–23. Xu, F. F., Alon, U., Neubig, G., & Hellendoorn, V. J. (2022). A systematic evaluation of large lan- guage models of code. Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming. Xu, F. F., Vasilescu, B., & Neubig, G. In-IDE Code Generation from Natural Language: Promise and Challenges. ACM Transactions on Software Engineering and Methodology (TOSEM), 31(2), 1–47. (2022). Yoon, Y., & Myers, B. A. (2015). Supporting selective undo in a code editor. In 2015 ieee/acm 37th ieee international conference on software engineering (Vol. 1, pp. 223–233). Zhang, H., Jain, A., Khandelwal, G., Kaushik, C., Ge, S., & Hu, W. (2016). Bing developer assistant: improving developer productivity by recommending sample code. In Proceedings of the 2016 24th acm sigsoft international symposium on foundations of software engineering (pp. 956–961). Ziegler, A. (2021, Jun). Github copilot research recitation. Microsoft. Retrieved from https:// github.blog/2021-06-30-github-copilot-research-recitation/ Ziegler, A., Kalliamvakou, E., Simister, S., Sittampalam, G., Li, A., Rice, A., . . . Aftandilian, E. (2022). Productivity assessment of neural code completion. arXiv preprint arXiv:2205.06537. 26","['g', 'u', 'x', 'like', 'program', 'artiﬁcial', 'intelligence', 'research', 'adgmicrosoftcom', 'research', 'cpoelitzmicrosoftcom', 'research', 'benzornmicrosoftcom', 'figure', 'code', 'generation', 'use', 'editor', 'extension', 'portion', 'highlight', 'blue', 'generate', 'model', 'leave', 'function', 'body', 'generate', 'base', 'textual', 'description', 'comment', 'right', 'set', 'test', 'case', 'generate', 'source', 'copilotgithub', 'com', 'abstract', 'large', 'language', 'model', 'openai', 'codex', '’s', 'alphacode', 'generate', 'code', 'solve', 'variety', 'problem', 'express', 'natural', 'language', 'technology', 'already', 'commercialise', 'least', 'widelyused', 'programming', 'editor', 'extension', 'copilot', 'paper', 'explore', 'program', 'large', 'language', 'model', 'llmassisted', 'programming', 'similar', 'differ', 'prior', 'conceptualisation', 'programmer', 'assistance', 'draw', 'pub', 'licly', 'available', 'experience', 'report', 'llmassisted', 'programming', 'well', 'prior', 'usability', 'design', 'study', 'ﬁnd', 'llmassisted', 'programming', 'share', 'property', 'compilation', 'pair', 'programming', 'programming', 'search', 'reuse', 'fundamental', 'difference', 'technical', 'possibility', 'well', 'practical', 'experience', 'thus', 'llmassisted', 'programming', 'view', 'new', 'way', 'programming', 'distinct', 'property', 'challenge', 'finally', 'draw', 'observation', 'user', 'study', 'nonexpert', 'end', 'user', 'programmer', 'use', 'llmassisted', 'tool', 'solve', 'datum', 'task', 'spreadsheet', 'discuss', 'issue', 'arise', 'open', 'research', 'challenge', 'apply', 'large', 'language', 'model', 'enduser', 'programming', 'particularly', 'user', 'little', 'programming', 'expertise', 'introduction', 'inferential', 'assistance', 'programmer', 'manifest', 'various', 'form', 'program', 'declarative', 'programming', 'language', 'program', 'synthesis', 'section', 'large', 'language', 'model', 'mark', 'quantitative', 'qualitative', 'stepchange', 'automatic', 'generation', 'code', 'nat', 'ural', 'language', 'text', 'attribute', 'cumulative', 'innovation', 'vectorspace', 'word', 'embedding', 'transformer', 'architecture', 'large', 'text', 'pretraine', 'language', 'model', 'section', 'model', 'commercialise', 'form', 'apis', 'openai', 'codex', 'programmer', 'face', 'tool', 'copilot', 'tabnine', 'tool', 'function', 'sort', 'advanced', 'autocom', 'plete', 'able', 'synthesize', 'multiple', 'line', 'code', 'base', 'prompt', 'code', 'editor', 'natural', 'language', 'eg', 'comment', 'code', 'eg', 'function', 'signature', 'adhoc', 'mixture', 'bilitie', 'tool', 'go', 'well', 'traditional', 'syntaxdirected', 'autocomplete', 'include', 'ability', 'synthesize', 'entire', 'function', 'body', 'write', 'test', 'case', 'complete', 'repetitive', 'pattern', 'section', 'tool', 'reliability', 'safety', 'security', 'implication', 'section', 'prior', 'labbased', 'telemetric', 'research', 'usability', 'tool', 'ﬁnd', 'developer', 'generally', 'appreciate', 'capability', 'tool', 'positive', 'asset', 'development', 'rience', 'strong', 'effect', 'task', 'completion', 'time', 'correctness', 'core', 'usability', 'issue', 'include', 'challenge', 'correctly', 'frame', 'prompt', 'well', 'effort', 'require', 'check', 'debug', 'generate', 'code', 'section', 'longitudinal', 'experience', 'report', 'developer', 'support', 'labbase', 'ﬁnding', 'contradict', 'e', 'challenge', 'correctly', 'frame', 'prompt', 'effort', 'debug', 'also', 'appear', 'however', 'many', 'report', 'tool', 'fact', 'strongly', 'reduce', 'task', 'time', 'speed', 'development', 'process', 'section', 'programming', 'large', 'language', 'model', 'invite', 'comparison', 'related', 'way', 'programming', 'search', 'compilation', 'pair', 'programming', 'indeed', 'similarity', 'empirical', 'report', 'experience', 'tool', 'also', 'show', 'crucial', 'difference', 'search', 'tion', 'pair', 'programming', 'thus', 'find', 'inadequate', 'metaphor', 'nature', 'llmassisted', 'programming', 'distinct', 'way', 'programming', 'unique', 'blend', 'property', 'section', 'llmassisted', 'programming', 'currently', 'gear', 'expert', 'programmer', 'arguably', 'great', 'est', 'beneﬁciarie', 'ability', 'nonexpert', 'enduser', 'programmer', 'nonetheless', 'sue', 'direct', 'application', 'enduser', 'programming', 'scenario', 'study', 'llmassisted', 'enduser', 'programming', 'spreadsheet', 'uncover', 'issue', 'intent', 'speciﬁcation', 'code', 'correctness', 'com', 'prehension', 'llm', 'tune', 'enduser', 'behaviour', 'motivate', 'need', 'study', 'area', 'section', 'prior', 'conceptualisation', 'intelligent', 'assistance', 'programmer', 'count', 'intelligent', 'assistance', 'subject', 'debate', 'select', 'feature', 'drive', 'technology', 'artiﬁcial', 'intelligence', 'research', 'community', 'undeﬁne', 'recognise', 'artiﬁcial', 'intelligence', 'include', 'use', 'expertcode', 'heuristic', 'system', 'make', 'inference', 'human', 'disagree', 'potential', 'error', 'system', 'make', 'user', 'feel', 'intelligent', 'assist', 'empower', 'debate', 'scope', 'paper', 'feel', 'properly', 'contextualise', 'qualitative', 'difference', 'make', 'large', 'language', 'model', 'broad', 'inclusive', 'approach', 'term', 'intelligence', 'require', 'enduser', 'programming', 'long', 'home', 'inferential', 'intelligent', 'assistance', 'strategy', 'direct', 'manipulation', 'shneiderman', 'norwood', 'highly', 'successful', 'certain', 'type', 'limited', 'useful', 'computational', 'task', 'interface', 'use', 'see', 'eg', 'text', 'editor', 'image', 'editor', 'develop', 'information', 'artefact', 'represent', 'closely', 'artefact', 'develop', 'get', 'text', 'document', 'image', 'however', 'strategy', 'straightforwardly', 'apply', 'program', 'program', 'notate', 'multiple', 'possible', 'path', 'execution', 'simultaneously', 'deﬁne', 'behaviour', 'occur', 'future', 'time', 'blackwell', 'render', 'multiple', 'future', 'present', 'core', 'problem', 'live', 'programming', 'research', 'tanimoto', 'aim', 'externalise', 'program', 'edit', 'need', 'bridge', 'abstraction', 'gap', 'direct', 'manipulation', 'multiple', 'path', 'execution', 'lead', 'invention', 'programming', 'demonstration', 'pbd', 'kurlander', 'form', 'inferential', 'assistance', 'pbd', 'allow', 'enduser', 'programmer', 'make', 'concrete', 'demon', 'stration', 'desire', 'behaviour', 'generalise', 'executable', 'program', 'promise', 'pbd', 'system', 'achieve', 'widespread', 'success', 'enduser', 'programming', 'tool', 'idea', 'sur', 'vive', 'vestigial', 'form', 'various', 'macro', 'recording', 'tool', 'approach', 'see', 'resurgence', 'grow', 'commercialisation', 'robotic', 'process', 'automation', 'programming', 'language', 'design', 'long', 'concern', 'shift', 'burden', 'intelligence', 'tween', 'programmer', 'program', 'compiler', 'user', 'programming', 'language', 'compiler', 'translate', 'tween', 'highlevel', 'language', 'machine', 'code', 'kind', 'intelligent', 'assistance', 'programmer', 'declarative', 'language', 'prolog', 'aspire', 'bring', 'kind', 'intelligence', 'programmer', 'responsible', 'specify', 'declare', 'compute', 'compute', 'responsibility', 'leave', 'interpreter', 'time', 'language', 'design', 'intelligent', 'application', 'mind', 'indeed', 'find', 'widespread', 'use', 'artiﬁcial', 'intelligence', 'computational', 'roussel', 'rouchy', 'formal', 'veriﬁcation', 'tool', 'use', 'speciﬁcation', 'language', 'hoare', 'triple', 'hoare', 'write', 'speciﬁcation', 'consider', 'program', 'high', 'level', 'abstraction', 'program', 'synthesis', 'particular', 'synthesis', 'reﬁnement', 'aim', 'intelligently', 'transform', 'rule', 'executable', 'correct', 'code', 'however', 'term', 'program', 'synthesis', 'also', 'use', 'broadly', 'program', 'synthesise', 'source', 'higherlevel', 'speciﬁcation', 'concretely', 'program', 'synthesis', 'example', 'simply', 'program', 'example', 'pbe', 'facilitate', 'generation', 'executable', 'code', 'inputoutput', 'example', 'example', 'successfully', 'commercialise', 'excel', 'fill', 'synthesise', 'string', 'transformation', 'spreadsheet', 'small', 'number', 'example', 'cognitive', 'dimension', 'framework', 'r', 'green', 'green', 'blackwell', 'identiﬁes', 'category', 'programming', 'activity', 'author', 'transcription', 'modiﬁcation', 'modern', 'programmer', 'sistance', 'encompass', 'example', 'program', 'synthesis', 'tool', 'transform', 'direct', 'authoring', 'code', 'arguably', 'easy', 'authoring', 'example', 'intelligent', 'code', 'completion', 'marasoiu', 'support', 'direct', 'authoring', 'code', 'intelligent', 'support', 'reuse', 'smart', 'code', 'copypaste', 'brockschmidt', 'support', 'transcription', 'refactoring', 'tool', 'herman', 'support', 'modiﬁcation', 'researcher', 'investigate', 'inferential', 'support', 'navigate', 'source', 'code', 'hen', 'fleme', 'debug', 'selectively', 'undo', 'code', 'change', 'additionally', 'intelligent', 'tool', 'also', 'support', 'learn', 'assemble', 'literature', 'review', 'research', 'intersection', 'machine', 'learning', 'programming', 'language', 'software', 'engineering', 'seek', 'adapt', 'method', 'ﬁrst', 'develop', 'natural', 'language', 'language', 'model', 'source', 'code', 'emergence', 'large', 'body', 'open', 'source', 'code', 'sometimes', 'call', 'big', 'code', 'enable', 'research', 'area', 'language', 'model', 'sensitive', 'lexical', 'feature', 'name', 'code', 'format', 'order', 'method', 'traditional', 'tool', 'compiler', 'code', 'veriﬁer', 'author', 'hypothesise', 'sensitivity', 'lexical', 'feature', 'matter', 'software', 'engineering', 'naturalness', 'hypothesis', 'software', 'form', 'human', 'communication', 'software', 'similar', 'statistical', 'property', 'natural', 'language', 'corpus', 'property', 'exploit', 'build', 'well', 'software', 'engineering', 'tool', 'early', 'evidence', 'hypothesis', 'go', 'back', 'research', 'use', 'ngram', 'model', 'build', 'code', 'completion', 'engine', 'java', 'outperform', 'completion', 'feature', 'hindle', 'survey', 'cover', 'method', 'application', 'enable', 'recommender', 'system', 'code', 'autocompletion', 'debugger', 'code', 'analyser', 'type', 'checker', 'raychev', 'code', 'synthesizer', 'application', 'constitute', 'intelligence', 'assistance', 'programmer', 'limit', 'capability', 'underlie', 'language', 'model', 'expect', 'recent', 'dramatic', 'expansion', 'capability', 'language', 'model', 'discuss', 'next', 'magnify', 'effectiveness', 'application', 'brief', 'overview', 'large', 'language', 'model', 'code', 'generation', 'transformer', 'architecture', 'big', 'dataset', 'enable', 'large', 'pretraine', 'model', 'past', 'decade', 'natural', 'language', 'processing', 'evolve', 'development', 'language', 'model', 'lm', 'well', 'task', 'evaluation', 'mikolov', 'introduce', 'vector', 'sign', 'word', 'similar', 'word', 'group', 'together', 'look', 'cooccurrence', 'free', 'text', 'wikipedia', 'article', 'ignore', 'fact', 'word', 'multiple', 'meaning', 'depend', 'e', 'context', 'long', 'memory', 'lstm', 'neural', 'network', 'hochreiter', 'schmidhuber', 'sutskever', 'later', 'encoderdecod', 'network', 'account', 'order', 'input', 'sequence', 'self', 'attention', 'vaswani', 'signiﬁcantly', 'simpliﬁe', 'prior', 'network', 'replace', 'element', 'input', 'weighted', 'average', 'rest', 'input', 'transformer', 'combine', 'advantage', 'multihead', 'attention', 'word', 'embedding', 'enrich', 'positional', 'encoding', 'add', 'order', 'information', 'word', 'embedding', 'architecture', 'many', 'alternative', 'former', 'language', 'modelling', 'paper', 'mention', 'language', 'model', 'usually', 'imply', 'transformerbase', 'language', 'model', 'large', 'collection', 'unlabelled', 'text', 'datum', 'common', 'natural', 'language', 'example', 'common', 'crawl', 'project1', 'produce', 'tb', 'text', 'datum', 'web', 'page', 'monthly', 'label', 'taskspeciﬁc', 'datum', 'less', 'prevalent', 'make', 'unsupervised', 'training', 'appealing', 'lead', 'concept', 'pretraine', 'lm', 'pretraine', 'lm', 'commonly', 'train', 'perform', 'next', 'word', 'prediction', 'gpt', 'model', 'et', 'model', 'train', 'predict', 'next', 'word', 'sequence', 'mask', 'model', 'train', 'ﬁll', 'gap', 'sequence', 'ideally', 'pretraine', 'lm', 'learn', 'generalpurpose', 'ability', 'knowledge', 'see', 'large', 'amount', 'text', 'transfer', 'downstream', 'language', 'task', 'less', 'label', 'datum', 'question', 'answer', 'ﬁction', 'generation', 'text', 'summarisation', 'etc', 'finetune', 'process', 'adapt', 'give', 'pretraine', 'different', 'downstream', 'task', 'introduce', 'additional', 'parameter', 'train', 'use', 'taskspeciﬁc', 'objective', 'function', 'certain', 'case', 'pretraine', 'objective', 'also', 'adjust', 'well', 'suit', 'downstream', 'task', 'instead', 'top', 'ﬁnetune', 'downstream', 'task', 'reformulate', 'similar', 'original', 'llm', 'training', 'practice', 'mean', 'express', 'task', 'set', 'instruction', 'llm', 'prompt', 'goal', 'rather', 'deﬁne', 'learn', 'objective', 'give', 'task', 'way', 'query', 'llm', 'directly', 'predict', 'downstream', 'task', 'sometimes', 'refer', 'pretrain', 'prompt', 'predict2', 'language', 'model', 'tune', 'source', 'code', 'generation', 'downstream', 'task', 'interest', 'paper', 'code', 'generation', 'provide', 'snippet', 'code', 'include', 'comment', 'want', 'new', 'code', 'generate', 'downstream', 'task', 'large', 'corpus', 'datum', 'available', 'public', 'code', 'repository', 'generation', 'divide', 'many', 'subtask', 'type', 'decorator', 'variable', 'type', 'generation', 'code', 'summarization', 'comment', 'generation', 'clone', 'detection', 'duplicate', 'detection', 'code', 'translation', 'code', 'migration', 'language', 'nguyen', 'recent', 'benchmark', 'cover', 'many', 'task', 'llm', 'technology', 'bring', 'reach', 'fullsolution', 'generation', 'codex', 'ponde', 'version', 'gpt3', 'ﬁnetune', 'code', 'generation', 'solve', 'generation', 'average', 'problem', 'humaneval', 'set', 'handwritten', 'programming', 'problem', 'include', 'function', 'signature', 'docstre', 'body', 'several', 'unit', 'test', 'average', 'test', 'problem', 'small', 'model', 'follow', 'codex', 'gptj3', 'ﬁnetune', 'top', 'also', 'ﬁnetune', 'top', 'gpt2', 'target', 'python', 'generation', 'polycoder', 'style', 'train', 'directly', 'code', 'llm', 'comparable', 'size', 'codex', 'include', 'alphacode', 'palmcoder', 'chowd', 'hery', 'alphacode', 'train', 'directly', 'ﬁnetune', 'code', 'competition', 'problem', 'introduce', 'method', 'reduce', 'large', 'number', 'potential', 'solution', 'million', 'figure', 'code', 'generation', 'use', 'editor', 'extension', 'portion', 'highlight', 'blue', 'generate', 'model', 'repetitive', 'time', 'computation', 'extrapolate', 'base', 'example', 'function', 'body', 'generate', 'signature', 'ﬁrst', 'line', 'source', 'copilotgithubcom', 'handful', 'candidate', 'competition', 'permit', 'maximum', 'dataset', 'programming', 'problem', 'give', 'attempt', 'codex', 'manage', 'solve', 'problem', 'alphacode', 'manage', 'competition', 'ﬁnetune', 'codecontest', 'alphacode', 'manage', 'success', 'rate', 'par', 'average', 'human', 'competitor', 'promise', 'result', 'know', 'shortcoming', 'model', 'directly', 'copy', 'code', 'full', 'solution', 'key', 'part', 'solution', 'training', 'datum', 'rather', 'generate', 'new', 'code', 'developer', 'make', 'effort', 'clean', 'retain', 'highquality', 'code', 'guarantee', 'correctness', 'error', 'directly', 'propagate', 'generation', 'codex', 'also', 'produce', 'syntactically', 'incorrect', 'undeﬁned', 'code', 'invoke', 'function', 'variable', 'attribute', 'undeﬁned', 'scope', 'codebase', 'moreover', 'codex', 'struggle', 'parse', 'increasingly', 'long', 'higherlevel', 'systemlevel', 'speciﬁcation', 'lead', 'mis', 'take', 'bind', 'operation', 'variable', 'especially', 'number', 'operation', 'variable', 'docstring', 'large', 'various', 'approach', 'explore', 'ﬁlter', 'bad', 'generation', 'repair', 'especially', 'syntax', 'error', 'consistency', 'issue', 'tradeoff', 'nondeterminism', 'generation', 'diversity', 'parameter', 'setting', 'control', 'diversity', 'generation', 'diverse', 'different', 'gener', 'ation', 'single', 'prompt', 'guarantee', 'get', 'generation', 'run', 'system', 'different', 'time', 'setting', 'alleviate', 'issue', 'measurement', 'metric', 'passk', 'solution', 'pass', 'test', 'try', 'modiﬁe', 'probabilistic', 'commercial', 'programming', 'tool', 'use', 'large', 'language', 'model', 'openai', 'codex', 'version', 'ﬁnetune', 'publicly', 'available', 'source', 'code', 'codex', 'programmerfacing', 'tool', 'openai', 'commercialise', 'form', 'api', 'build', 'figure', 'code', 'generation', 'use', 'tabnine', 'editor', 'extension', 'grey', 'text', 'cursor', 'suggest', 'model', 'base', 'comment', 'precede', 'line', 'source', 'tabninecom', 'figure', 'api', 'suggestion', 'use', 'visual', 'studio', 'intellicode', 'feature', 'source', 'silver', 'principal', 'commercial', 'implementation', 'codex', 'thus', 'far', 'copilot5', 'copilot', 'extension', 'instal', 'code', 'editor', 'jetbrain', 'visual', 'studio', 'code', 'copilot', 'use', 'codex', 'draw', 'content', 'edit', 'related', 'ﬁle', 'project', 'path', 'url', 'repository', 'trigger', 'generate', 'code', 'cursor', 'location', 'much', 'way', 'autocomplete', 'help', 'expand', 'developer', 'expectation', 'capability', 'copilot', 'previous', 'standard', 'use', 'autocomplete', 'suggest', 'usage', 'idiom', 'copilot', 'include', 'write', 'comment', 'explain', 'function', 'function', 'signature', 'allow', 'copilot', 'complete', 'function', 'body', 'complet', 'e', 'boilerplate', 'code', 'deﬁne', 'test', 'case', 'figure', 'programmer', 'cycle', 'different', 'generation', 'model', 'particular', 'completion', 'accept', 'edit', 'code', 'amazon', 'announce', 'copilotlike', 'feature', 'call', 'codewhisperer6', 'also', 'apply', 'large', 'language', 'model', 'train', 'corpus', 'source', 'code', 'generate', 'autocompletion', 'base', 'comment', 'code', 'marketing', 'material', 'describe', 'set', 'safety', 'feature', 'detect', 'generate', 'code', 'similar', 'code', 'training', 'set', 'detect', 'known', 'security', 'vulnerability', 'generate', 'code', 'remove', 'code', 'consider', 'biased', 'unfair', 'latter', 'claim', 'induce', 'skepticism', 'present', 'codewhisperer', 'widely', 'available', 'thus', 'little', 'know', 'use', 'practice', 'commercial', 'implementation', 'aiassiste', 'autocompletion', 'feature', 'include', 'visual', 'studio', 'silver', 'figure', 'tabnine', 'figure', 'limited', 'scope', 'copilot', 'user', 'experience', 'commensurable', 'use', 'traditional', 'autocomplete', 'plete', 'drive', 'static', 'analysis', 'syntax', 'heuristics8the', 'structure', 'machine', 'learning', 'model', 'use', 'implementation', 'publicly', 'disclose', 'however', 'rely', 'model', 'train', 'large', 'corpus', 'publicly', 'available', 'source', 'code', 'interesting', 'note', 'wide', 'variety', 'type', 'intelligent', 'programmer', 'assistance', 'discuss', 'section', 'several', 'aspect', 'program', 'author', 'transcription', 'modiﬁcation', 'debug', 'learn', 'commercial', 'implementation', 'assistance', 'base', 'large', 'language', 'model', 'thus', 'far', 'aim', 'primarily', 'author', 'authoring', 'view', 'ﬁrst', 'natural', 'application', 'generative', 'language', 'model', 'programming', 'knowledge', 'model', 'course', 'use', 'assist', 'programmer', 'activity', 'reliability', 'safety', 'security', 'implication', 'codegenerate', 'model', 'ai', 'model', 'generate', 'code', 'present', 'signiﬁcant', 'challenge', 'issue', 'relate', 'reliability', 'safety', 'security', 'output', 'model', 'complex', 'software', 'artifact', 'determine', 'put', 'correct', 'need', 'much', 'nuance', 'evaluation', 'simple', 'classiﬁcation', 'task', 'human', 'trouble', 'evaluate', 'quality', 'software', 'practice', 'code', 'review', 'apply', 'static', 'dy', 'namic', 'analysis', 'technique', 'prove', 'necessary', 'ensure', 'good', 'quality', 'humanwritten', 'code', 'current', 'method', 'evaluate', 'quality', 'aigenerated', 'code', 'embody', 'benchmark', 'mbpp', 'codecontest', 'determine', 'functional', 'correctness', 'entire', 'function', 'base', 'set', 'unit', 'test', 'evaluation', 'approach', 'fail', 'consider', 'issue', 'code', 'readability', 'completeness', 'presence', 'potential', 'error', 'software', 'developer', 'constantly', 'struggle', 'overcome', 'previous', 'work', 'explore', 'numerous', 'implication', 'ai', 'model', 'generate', 'code', 'include', 'issue', 'overreliance', 'mismatch', 'user', 'prompt', 'request', 'user', 'really', 'want', 'bias', 'economic', 'impact', 'security', 'implication', 'topic', 'extensive', 'important', 'space', 'limitation', 'brieﬂy', 'mention', 'point', 'additional', 'related', 'work', 'possible', 'overreliance', 'occur', 'individual', 'make', 'optimistic', 'assumption', 'correctness', 'output', 'model', 'lead', 'harm', 'code', 'generating', 'model', 'user', 'assume', 'code', 'correct', 'security', 'vulnerability', 'assumption', 'lead', 'low', 'quality', 'insecure', 'code', 'write', 'deploy', 'exist', 'deployment', 'ai', 'model', 'code', 'documentation', 'stress', 'need', 'carefully', 'review', 'test', 'vet', 'generate', 'code', 'developer', 'vet', 'code', 'external', 'source', 'remain', 'see', 'overreliance', 'issue', 'relate', 'ai', 'code', 'generation', 'result', 'new', 'software', 'quality', 'challenge', 'generate', 'code', 'train', 'large', 'public', 'repository', 'potential', 'lowquality', 'training', 'datum', 'inﬂuence', 'model', 'suggest', 'lowquality', 'code', 'code', 'contain', 'security', 'vulnera', 'bilitie', 'early', 'study', 'examine', 'code', 'suggestion', 'contain', 'know', 'security', 'vulnerability', 'range', 'scenario', 'ﬁnd', 'case', 'insecure', 'code', 'generate', 'carefully', 'screen', 'new', 'code', 'use', 'exist', 'static', 'dynamic', 'tool', 'detect', 'security', 'vulnerability', 'humangenerate', 'code', 'also', 'possible', 'mitigation', 'reduce', 'likelihood', 'model', 'make', 'suggestion', 'include', 'improve', 'overall', 'quality', 'training', 'datum', 'remove', 'lowquality', 'repository', 'ﬁnetune', 'largelanguage', 'model', 'speciﬁcally', 'reduce', 'output', 'know', 'insecure', 'pattern', 'usability', 'design', 'study', 'aiassiste', 'programming', 'conduct', 'withinsubject', 'comparative', 'study', 'n24', '8as', 'tabnine', 'announce', 'shift', 'language', 'autocompletion', 'closely', 'resemble', 'ability', 'copilot', 'weiss', 'compare', 'user', 'experience', 'traditional', 'autocomplete', 'speciﬁcally', 'intellisense', 'plugin', 'intellicode', 'feature', 'mention', 'previously', 'participant', 'fail', 'complete', 'task', 'often', 'copilot', 'intellisense', 'signiﬁcant', 'effect', 'task', 'completion', 'time', 'perhaps', 'unsurprisingly', 'author', 'ﬁnd', 'assess', 'correctness', 'generate', 'code', 'difﬁcult', 'efﬁciency', 'bottleneck', 'particularly', 'code', 'generate', 'fundamental', 'ﬂaw', 'inefﬁciency', 'lead', 'programmer', 'ultimately', 'unsuccessful', 'wild', 'goose', 'chase', 'repair', 'debug', 'however', 'overwhelming', 'majority', 'participant', 'report', 'strong', 'preference', 'copilot', 'posttask', 'survey', 'participant', 'less', 'conﬁdent', 'code', 'generate', 'copilot', 'almost', 'universally', 'perceive', 'helpful', 'potential', 'generate', 'useful', 'starting', 'point', 'save', 'programmer', 'effort', 'search', 'online', 'document', 'solution', 'basis', 'reuse', 'conduct', 'survey', 'perceive', 'productivity', 'copilot', 'user', 'usa', 'match', 'telemetric', 'usage', 'measurement', 'copilot', 'addin', 'include', 'metric', 'often', 'autocompletion', 'show', 'often', 'accept', 'often', 'siste', 'unchanged', 'document', 'certain', 'time', 'period', 'often', 'persist', 'minor', 'variation', 'measure', 'levenshtein', 'distance', 'ﬁnd', 'acceptance', 'rate', 'ratio', 'cepte', 'suggestion', 'show', 'suggestion', 'strong', 'predictor', 'user', 'perceive', 'productivity', 'copilot', 'fascinatingly', 'ﬁnd', 'pattern', 'acceptance', 'rate', 'user', 'aggregate', 'follow', 'daily', 'weekly', 'circadian', 'rhythm', 'user', 'likely', 'accept', 'copilot', 'completion', 'workinghour', 'weekend', 'however', 'give', 'user', 'acceptance', 'rate', 'depend', 'user', 'normal', 'work', 'hour', 'suggestion', 'outside', 'normal', 'working', 'hour', 'less', 'likely', 'accept', 'future', 'work', 'need', 'see', 'ﬁnde', 'replicate', 'establish', 'acceptance', 'rate', 'signiﬁcantly', 'affect', 'work', 'hour', 'conduct', 'withinsubject', 'study', 'n31', 'compare', 'programming', 'experience', 'code', 'generation', 'plugin', 'experimental', 'plugin', 'take', 'form', 'text', 'ﬁeld', 'user', 'enter', 'natural', 'language', 'prompt', 'system', 'respond', 'list', 'code', 'snippet', 'click', 'desire', 'snippet', 'insert', 'cursor', 'workﬂow', 'differ', 'prompt', 'text', 'source', 'contain', 'mix', 'natural', 'language', 'comment', 'code', 'plugin', 'support', 'code', 'generation', 'use', 'treebased', 'neural', 'network', 'code', 'retrieval', 'search', 'programming', 'forum', 'stack', 'overﬂow', 'result', 'generation', 'retrieval', 'show', 'list', 'visually', 'demarcate', 'author', 'find', 'signiﬁcant', 'effect', 'plugin', 'task', 'completion', 'time', 'program', 'correctness', 'find', 'simple', 'query', 'likely', 'answer', 'correctly', 'generation', 'complex', 'query', 'require', 'multiple', 'step', 'likely', 'answer', 'correctly', 'retrieval', 'possible', 'predict', 'approach', 'succeed', 'base', 'word', 'content', 'query', 'far', 'find', 'natural', 'language', 'query', 'participant', 'write', 'experiment', 'sufﬁciently', 'wellspeciﬁe', 'human', 'expert', 'write', 'code', 'implement', 'intent', 'retrieve', 'snippet', 'edit', 'often', 'generate', 'snippet', 'mostly', 'rename', 'identiﬁer', 'choose', 'different', 'parameter', 'post', 'experiment', 'survey', 'participant', 'report', 'mostly', 'feel', 'neutral', 'somewhat', 'positive', 'participant', 'feel', 'plugin', 'helpful', 'ﬁnde', 'snippet', 'aware', 'recall', 'less', 'disruptive', 'use', 'browser', 'interaction', 'work', 'well', 'developer', 'preexisting', 'knowledge', 'target', 'apis', 'framework', 'take', 'experimentation', 'understand', 'correct', 'way', 'formulate', 'query', 'clear', 'indication', 'preference', 'retrieval', 'generation', 'develop', 'llmbased', 'tool', 'convert', 'natural', 'language', 'statement', 'code', 'neubig', 'prompt', 'enter', 'popup', 'dialog', 'invoke', 'cursor', 'code', 'editor', 'rather', 'comment', 'study', 'participant', 'give', 'week', 'complete', 'websitebuilding', 'task', 'tool', 'record', 'screen', 'interview', 'afterwards', 'study', 'participant', 'see', 'utility', 'tool', 'facilitate', 'quick', 'api', 'lookup', 'write', 'boilerplate', 'code', 'find', 'novice', 'programmer', 'query', 'mainly', 'natural', 'figure', 'search', 'code', 'snippet', 'use', 'bing', 'developer', 'assistant', 'show', 'note', 'query', 'generate', 'md5', 'hash', 'string', 'line', 'contain', 'hint', 'identiﬁer', 'line', 'use', 'rewrite', 'retrieve', 'snippet', 'source', 'buildingbingdeveloperassistant', 'result', 'language', 'expert', 'likely', 'mix', 'code', 'request', 'query', 'abstract', 'express', 'highlevel', 'goal', 'low', 'granularity', 'roughly', 'equivalent', 'line', 'code', 'cope', 'model', 'failure', 'participant', 'use', 'variety', 'strategy', 'reword', 'query', 'reduce', 'scope', 'request', 'replace', 'word', 'alternative', 'particular', 'strategy', 'observe', 'effective', 'participant', 'struggle', 'form', 'mental', 'model', 'model', 'understand', 'syntax', 'language', 'require', 'precisely', 'fuzzy', 'abstraction', 'matching', 'problem', 'describe', 'early', 'author', 'call', 'uncanny', 'valley', 'author', 'suggest', 'possible', 'solution', 'automate', 'rewording', 'prompt', 'suggest', 'simple', 'task', 'suggest', 'task', 'breakdown', 'well', 'onboarding', 'tutorial', 'barke', 'study', 'programmer', 'use', 'copilot', 'complete', 'short', 'program', 'ming', 'task', 'rust', 'haskell', 'java', 'analysis', 'screen', 'recording', 'author', 'identife', 'primary', 'mode', 'interaction', 'copilot', 'acceleration', 'programmer', 'wellformed', 'intent', 'copilot', 'speed', 'code', 'author', 'small', 'logical', 'unit', 'exploration', 'copilot', 'suggestion', 'use', 'assist', 'planning', 'process', 'help', 'start', 'suggest', 'potentially', 'useful', 'structure', 'api', 'call', 'explore', 'alternative', 'solution', 'acceleration', 'long', 'code', 'suggestion', 'take', 'time', 'read', 'evaluate', 'break', 'programmer', 'participant', 'develop', 'heuristic', 'quickly', 'scan', 'suggestion', 'look', 'presence', 'certain', 'keyword', 'exploration', 'participant', 'likely', 'prompt', 'use', 'purely', 'natural', 'language', 'comment', 'rather', 'mix', 'comment', 'code', 'moreover', 'prompt', 'comment', 'often', 'clean', 'subsequent', 'accept', 'suggestion', 'imply', 'form', 'instruction', 'language', 'separate', 'bing', 'developer', 'assistant', 'also', 'refer', 'bing', 'code', 'search', 'experimental', 'extension', 'visual', 'studio', 'initially', 'release', 'enable', 'inide', 'identiﬁeraware', 'search', 'code', 'snippet', 'forum', 'stack', 'overﬂow', 'ability', 'rewrite', 'retrieve', 'code', 'use', 'identiﬁer', 'programmer', 'current', 'user', 'study', 'n14', 'compare', 'task', 'time', 'perform', 'short', 'programming', 'task', 'extension', 'regular', 'web', 'search', 'find', 'average', 'time', 'save', 'extension', 'morever', 'telemetry', 'datum', 'gather', 'week', 'represent', 'user', 'around', 'query', 'day', 'show', 'several', 'programmer', 'use', 'feature', 'frequently', 'use', 'repeatedly', 'related', 'problem', 'quick', 'succession', 'show', 'use', 'multistep', 'problem', 'issue', 'query', 'multiple', 'time', 'separate', 'day', 'suggest', 'speed', 'autocompletion', 'useful', 'even', 'programmer', 'know', 'solution', 'experience', 'report', 'present', 'lot', 'research', 'user', 'experience', 'programming', 'large', 'language', 'model', 'study', 'summarise', 'section', 'however', 'availability', 'tool', 'increase', 'professional', 'programmer', 'gain', 'longterm', 'experience', 'use', 'many', 'program', 'mer', 'write', 'experience', 'personal', 'blog', 'discuss', 'online', 'community', 'hacker', 'news', 'inspire', 'potential', 'source', 'provide', 'rich', 'qualitative', 'datum', 'point', 'draw', 'experience', 'report', 'full', 'list', 'source', 'provide', 'appendix', 'summarise', 'key', 'point', 'write', 'effective', 'prompt', 'hard', 'several', 'application', 'generative', 'model', 'key', 'issue', 'writing', 'prompt', 'crease', 'likelihood', 'successful', 'code', 'generation', 'mapping', 'model', 'learn', 'natural', 'language', 'code', 'poorly', 'understand', 'experimentation', 'develop', 'heuristic', 'prompt', 'improve', 'quality', 'code', 'generate', 'model', 'developer', 'build', 'several', 'application', 'game', 'model', 'second', 'generation', 'codex', 'model', 'advise', 'number', 'instruction', 'create', 'logic', 'ﬁrst', 'ui', 'element', 'use', 'copilot', 'build', 'classiﬁer', 'natural', 'language', 'statement', 'suggest', 'provide', 'detail', 'response', 'failure', 'generate', 'correct', 'code', 'example', 'ask', 'copilot', 'rize', 'array', 'fail', 'rewrite', 'prompt', 'turn', 'array', 'ﬁrst', 'value', 'second', 'value', 'effectively', 'pseudocode', 'generate', 'correct', 'result', 'commenter', 'hacker', 'news', 'divide', 'merit', 'effort', 'invest', 'develop', 'technique', 'prompt', 'see', 'new', 'level', 'abstraction', 'program', 'see', 'indirectly', 'approach', 'fundamental', 'issue', 'solve', 'well', 'tooling', 'documentation', 'language', 'design', 'code', 'directly', 'language', 'code', 'implicit', 'language', 'provide', 'copilot', 'really', 'point', 'code', 'documentation', 'discovery', 'terrible', '’m', 'sure', 'write', 'implicit', 'code', 'comment', 'really', 'well', 'approach', 'seek', 'way', 'make', 'discovery', 'language', 'library', 'feature', 'discoverable', 'comment', 'use', 'generate', 'code', 'copilot', 'inefﬁcient', 'programming', 'language', 'respond', 'nonetheless', 'extremely', 'valuable', 'able', 'write', 'different', 'level', 'abstraction', 'develop', 'code', 'copilot', 'let', 'way', 'way', 'normal', 'programming', 'language', 'let', 'course', 'rigid', 'abstraction', 'part', 'code', 'want', 'dive', 'write', 'single', 'line', 'painstaking', 'detail', 'copilot', 'maybe', 'enough', 'purpose', 'able', 'ability', 'even', 'think', 'programming', 'language', 'huge', 'indiscriminately', 'train', 'corpus', 'contain', 'code', 'vary', 'age', 'subjective', 'quality', 'drawback', 'developer', 'encounter', 'generate', 'code', 'technically', 'correct', 'contain', 'practice', 'consider', 'poor', 'unrolled', 'loop', 'hardcoded', 'constant', 'copilot', 'user', 'find', 'copilot', 'make', 'code', 'verbose', 'line', 'code', 'liability', 'long', 'ﬁle', 'parse', 'instance', 'refactor', 'try', 'consolidate', 'api', 'surface', 'ﬁnd', 'maintain', 'multiple', 'instance', 'copilot', 'user', 'reﬂecte', 'experience', 'try', 'generate', 'code', 'use', 'fastai', 'api', 'frequently', 'change', 'late', 'version', 'fastai', 'release', 'copilot', 'able', 'provide', 'relevant', 'suggestion', 'instead', 'provide', 'code', 'use', 'old', 'version', 'fastai', 'major', 'concern', 'use', 'cut', 'edge', 'tool', 'copilot', 'knowledge', 'provide', 'useful', 'suggestion', 'hand', 'developer', 'also', 'expose', 'well', 'practice', 'apis', 'model', 'developer', 'find', 'copilot', 'make', 'code', 'verbose', 'also', 'observe', 'copilot', 'give', 'structure', 'go', 'error', 'common', 'idiom', 'wrap', 'error', 'context', 'string', 'write', 'inconsistent', 'adhoc', 'style', 'use', 'copilot', 'write', 'single', 'error', 'handle', 'line', 'manually', 'top', 'suggestion', 'follow', 'reasonable', 'structure', 'know', 'structure', 'exist', 'copilot', 'show', 'add', 'structure', 'code', 'unlikely', 'place', 'write', 'sql', 'help', 'write', 'annoying', 'foreign', 'key', 'name', 'consistent', 'format', 'additionally', 'surprising', 'feature', 'discover', 'new', 'api', 'method', 'higherlevel', 'one', 'one', 'well', 'use', 'case', 'order', 'discover', 'new', 'apis', 'course', 'apis', 'need', 'welldesigne', 'indeed', 'case', 'spectacular', 'utility', 'large', 'language', 'model', 'largely', 'attribute', 'fact', 'api', 'designer', 'already', 'hard', 'work', 'create', 'abstraction', 'good', 'ﬁt', 'real', 'use', 'case', 'macvean', 'developer', 'use', 'copilot', 'develop', 'sentiment', 'classiﬁer', 'twitter', 'post', 'match', 'certain', 'keyword', 'remark', 'kind', 'thing', 'possible', 'co', 'pilot', 'sic', 'also', 'awesome', 'library', 'abstract', 'lot', 'tough', 'stuff', 'suggest', 'api', 'design', 'human', 'developer', 'also', 'target', 'large', 'language', 'model', 'important', 'near', 'midterm', 'future', 'moreover', 'break', 'prompt', 'correct', 'level', 'detail', 'also', 'emerge', 'important', 'developer', 'skill', 'require', 'least', 'familiarity', 'good', 'intuition', 'apis', 'available', 'break', 'prompt', 'step', 'detailed', 'programmer', 'effectively', 'write', 'pseudocode', 'view', 'antipattern', 'give', 'rise', 'objection', 'cite', 'early', 'programming', 'large', 'language', 'model', 'simply', 'inefﬁcient', 'programming', 'language', 'term', 'problem', 'fuzzy', 'abstraction', 'match', 'problem', 'ﬁgure', 'system', 'match', '’s', 'intent', 'instruction', 'capability', 'system', 'new', 'welldocumente', 'natural', 'language', 'interaction', 'sarkar', 'lug', 'sellen', 'also', 'observe', 'programming', 'notation', 'design', 'hypothesis', 'r', 'petre', 'chalhoub', 'sarkar', 'broad', 'sense', 'see', 'special', 'case', 'execution', 'hutchin', 'perhaps', 'central', 'disciplinary', 'problem', 'ﬁrst', 'second', 'wave', 'bødker', 'humancomputer', 'interaction', 'research', 'get', 'computer', 'want', 'distinguish', 'fuzzy', 'abstraction', 'match', 'previous', 'incarnation', 'problem', 'silience', 'accommodation', 'various', 'level', 'abstraction', 'afford', 'large', 'language', 'model', 'previous', 'natural', 'language', 'interface', 'programming', 'language', 'user', 'need', 'form', 'extremely', 'speciﬁc', 'mental', 'model', 'express', 'idea', 'machine', 'term', 'contrast', 'large', 'guage', 'model', 'generate', 'plausible', 'correct', 'result', 'statement', 'extremely', 'wide', 'range', 'abstraction', 'context', 'programming', 'assistance', 'range', 'ask', 'model', 'write', 'program', 'base', 'vague', 'underspeciﬁed', 'statement', 'require', 'domain', 'knowledge', 'solve', 'extremely', 'speciﬁc', 'detailed', 'instruction', 'effectively', 'pseudocode', 'ﬂexibility', 'mately', 'doubleedge', 'sword', 'low', 'ﬂoor', 'user', 'start', 'get', 'usable', 'result', 'high', 'ceiling', 'get', 'user', 'maximum', 'productivity', 'context', 'programming', 'activity', 'exploratory', 'programming', 'goal', 'unknown', 'ill', 'deﬁned', 'kery', 'ﬁt', 'framing', 'fuzzy', 'abstraction', 'matching', 'indeed', 'variation', 'execution', 'problem', 'notion', 'crystallised', 'user', 'intent', 'question', 'design', 'objective', 'system', 'inﬂuence', 'intent', 'user', 'much', 'designerly', 'thirdwave', 'hci', 'work', 'fundamental', 'interaction', 'question', 'change', 'obvious', 'role', 'system', 'play', 'scenario', 'help', 'user', 'reﬁne', 'concept', 'decide', 'avenue', 'explore', 'note', 'activity', 'exist', 'fall', 'framework', 'propose', 'explore', 'great', 'detail', 'paper', 'activity', 'programming', 'shift', 'check', 'unfamiliar', 'debugging', 'code', 'generate', 'quickly', 'observe', 'study', 'section', 'check', 'correctness', 'generate', 'code', 'become', 'major', 'bottleneck', 'shift', 'tradeoff', 'fast', 'author', 'expense', 'great', 'time', 'spend', 'check', 'code', 'criticism', 'wrong', 'balance', 'priority', 'system', 'programmer', 'correspondingly', 'user', 'develop', 'heuristic', 'cost', 'evaluate', 'correctness', 'code', 'great', 'time', 'effort', 'save', 'code', 'generation', 'focus', 'short', 'single', 'line', 'completion', 'ignore', 'long', 'completion', 'furthermore', 'user', 'find', 'rather', 'suggestion', 'show', 'time', 'distract', 'time', 'consume', 'intentional', 'use', 'make', 'copilot', 'switch', 'auto', 'suggestion', 'trigger', 'code', 'completion', 'manually', 'use', 'keyboard', 'shortcut', 'however', 'require', 'user', 'form', 'mental', 'model', 'copilot', 'likely', 'help', 'workﬂow', 'mental', 'model', 'take', 'time', 'intentionality', 'build', 'incorrect', 'moreover', 'introduce', 'new', 'cognitive', 'burden', 'constantly', 'evaluate', 'current', 'situation', 'beneﬁt', 'llm', 'assistance', 'commenter', 'hacker', 'news', 'raise', 'issue', 'spend', 'time', 'review', 'copilot', 'suggestion', 'mostly', 'wrong', 'rather', 'think', 'code', 'actually', 'work', '’', 'much', 'quick', 'read', 'code', 'write', 'addition', 'copilot', 'suggestion', 'single', 'line', '’re', 'almost', 'always', 'right', 'also', 'totally', 'optional', 'admit', '’m', 'paranoid', 'time', 'suggest', 'line', 'usually', 'avoid', 'run', 'copilot', 'induce', 'headache', 'twice', 'ﬁrst', 'week', 'use', 'swear', 'sic', 'use', 'line', 'eventually', 'start', 'ease', 'accurate', 'often', 'learn', 'second', 'lesson', 'mistake', 'write', 'code', 'bottleneck', 'need', 'optimization', 'conceive', 'solution', 'time', 'save', 'copilot', '’', 'ilk', 'immediately', 'nulliﬁe', 'check', 'want', 'copilot', 'ﬁnd', 'error', 'invert', 'relationship', 'need', 'boilerplate', 'generator', 'need', 'nitpicker', '’', 'smart', 'linter', '’m', 'smart', 'thinker', 'biological', 'brain', 'inattentive', 'time', 'computer', 'try', 'code', 'leave', 'mistake', 'catch', '’', 'backwards', 'turn', 'autosuggest', 'make', 'huge', 'difference', 'use', 'know', 'repetitive', 'get', 'easily', '’m', 'sure', 'want', '’m', 'curious', 'suggest', 'way', 'get', 'help', 'interrupt', 'thought', 'suggestion', 'frequent', 'experience', 'language', 'model', 'introduce', 'subtle', 'difﬁcult', 'detect', 'bug', 'kind', 'introduce', 'human', 'programmer', 'write', 'code', 'manually', 'thus', 'exist', 'developer', 'intuition', 'source', 'error', 'program', 'less', 'useful', 'even', 'misleading', 'check', 'correctness', 'generate', 'code', 'developer', 'report', 'experience', 'incorrect', 'plausiblesounde', 'ﬁeld', 'name', 'geste', 'copilot', 'accesstokensecret', 'instead', 'accesssecret', 'consequent', 'wild', 'goose', 'chase', 'debug', 'discover', 'problem', 'source', 'error', 'tool', 'new', 'developer', 'need', 'learn', 'new', 'craft', 'practice', 'debug', 'place', 'teach', 'thing', 'experience', 'unlock', 'kind', 'knowledge', 'developer', 'con', 'clude', 'let', 'code', 'completion', 'tool', 'rule', 'work', 'blame', 'copilot', 'blame', 'least', 'get', 'experience', 'commenter', 'hacker', 'news', 'report', 'similar', 'experience', 'big', 'problem', 'write', 'correctly', '’', 'think', 'know', 'produce', 'good', 'look', 'code', 'glance', 'wrong', 'logic', 'prove', 'good', 'produce', 'superﬁcially', 'appeal', 'output', 'stand', 'quick', 'scan', 'moderately', 'deep', 'reading', 'still', 'fall', 'apart', 'careful', 'reading', '’', 'uncanny', 'valley', 'type', 'effect', '’', 'almost', 'dangerous', 'possible', 'iteration', '’', 'good', 'enough', 'fool', 'human', 'functioning', 'high', 'level', 'attentiveness', 'good', 'enough', 'correct', 'time', 'see', 'also', 'danger', 'almost', 'selfdrive', 'car', 'selfdrive', 'expect', 'halfway', 'work', 'well', 'code', 'generate', 'look', 'right', 'usually', 'wrong', 'really', 'difﬁcult', 'spot', 'way', 'thing', 'never', 'write', 'many', 'developer', 'report', 'concern', 'tool', 'repeat', 'private', 'information', 'repeat', 'copy', 'right', 'code', 'verbatim', 'implication', 'license', 'project', 'notion', 'danger', 'stochastic', 'parrot', 'bender', 'new', 'wellexplore', 'directly', 'connect', 'user', 'experience', 'programming', 'assistance', 'concern', 'list', 'enter', 'discussion', 'depth', 'mention', 'concern', 'present', 'several', 'blog', 'article', 'online', 'discussion', 'thus', 'practice', 'programmer', 'describe', 'challenge', 'write', 'effective', 'prompt', 'misinterpret', 'intent', 'code', 'include', 'subtle', 'bug', 'poor', 'programming', 'practice', 'burden', 'inspect', 'check', 'generate', 'code', 'correct', 'worry', 'private', 'information', 'plagiarism', 'copyright', 'tool', 'useful', 'boilerplate', 'code', 'reuse', 'challenge', 'describe', 'far', 'section', 'utility', 'tool', 'certain', 'contexts', 'undeniable', 'programmer', 'report', 'develop', 'workﬂow', 'certain', 'contexts', 'heavily', 'dependent', 'assistance', 'particularly', 'simple', 'task', 'require', 'lot', 'boilerplate', 'code', 'common', 'task', 'likely', 'snippet', 'code', 'online', 'prior', 'assistant', 'require', 'web', 'search', 'retrieve', 'hacker', 'news', 'commenter', 'write', 'day', 'copilot', 'pretty', 'big', 'productivity', 'hit', 'day', 'copilot', 'somehow', 'stop', 'offer', 'completion', 'maybe', 'hour', 'pretty', 'shocked', 'realize', 'much', 'grow', 'rely', 'hit', 'tab', 'complete', 'whole', 'line', 'write', 'go', 'time', 'boilerplatey', 'side', 'mainstream', 'language', 'copilot', 'particularly', 'effective', 'use', 'gtp3', 'codex', 'sic', 'daily', 'work', 'save', 'time', 'help', 'explore', 'unfamiliar', 'lan', 'guage', 'apis', 'generate', 'approach', 'solve', 'problem', 'shockingly', 'good', 'code', 'narrow', 'contexts', 'mistake', 'miss', 'development', 'happen', 'area', 'lot', 'quick', 'programming', 'question', 'ﬁnde', 'even', 'need', 'search', 'engine', 'use', 'copilot', 'example', 'want', 'remember', 'throw', 'exception', '’d', 'write', 'comment', 'let', 'copilot', 'ﬁll', 'syntax', 'ofﬁcial', 'doc', 'need', 'ton', 'else', 'change', 'way', 'write', 'code', 'way', 'already', 'tell', 'allow', 'much', 'lazy', 'previously', 'learn', 'various', 'detail', 'language', 'library', 'pretty', 'much', 'replace', 'almost', 'entire', 'usage', 'stack', 'copilot', 'really', 'shine', 'rote', 'work', 'correctly', 'infer', 'assist', 'correctly', '’', 'able', 'make', 'big', 'decision', 'pinch', 'able', 'give', 'hint', 'use', 'right', 'copilot', 'give', 'developer', 'signiﬁcant', 'velocity', 'boost', 'especially', 'greenﬁeld', 'project', 'lot', 'lot', 'boilerplate', 'write', 'inadequacy', 'exist', 'metaphor', 'aiassisted', 'programming', 'ai', 'assistance', 'search', 'research', 'study', 'well', 'report', 'developer', 'experience', 'comparison', 'draw', 'nature', 'programming', 'assistance', 'programming', 'search', 'reuse', 'code', 'internet', 'institutional', 'repository', 'project', 'developer', 'previous', 'project', 'comparison', 'programming', 'assistance', 'search', 'natural', 'many', 'similarity', 'superﬁcially', 'similar', 'starting', 'point', 'prompt', 'query', 'predominantly', 'natural', 'language', 'also', 'contain', 'code', 'snippet', 'user', 'perspective', 'information', 'asymmetry', 'user', 'know', 'precisely', 'form', 'result', 'take', 'search', 'ai', 'assistance', 'give', 'query', 'several', 'result', 'user', 'need', 'invest', 'time', 'evaluate', 'compare', 'case', 'user', 'get', 'inexact', 'solution', 'indeed', 'want', 'user', 'need', 'invest', 'time', 'adapt', 'repair', 'get', 'however', 'difference', 'search', 'web', 'programmer', 'encounter', 'code', 'variety', 'type', 'result', 'intermingle', 'enmesh', 'include', 'code', 'snippet', 'intersperse', 'human', 'commentary', 'perhaps', 'discussion', 'forum', 'stack', 'overﬂow', 'video', 'image', 'search', 'return', 'new', 'apis', 'library', 'relate', 'query', 'thus', 'show', 'result', 'different', 'level', 'abstraction', 'search', 'signal', 'provenance', 'often', 'always', 'possible', 'determine', 'source', 'code', 'snippet', 'web', 'lot', 'information', 'scent', 'prime', 'assist', 'information', 'forage', 'task', 'way', 'program', 'search', 'mixed', 'media', 'experience', 'contrast', 'programming', 'large', 'language', 'model', 'say', 'ﬁxed', 'media', 'experience', 'output', 'token', 'code', 'comment', 'datum', 'represent', 'context', 'code', 'editor', 'advantage', 'increase', 'speed', 'code', 'insertion', 'immediate', 'aim', 'often', 'come', 'experience', 'report', 'however', 'learning', 'exploration', 'discovery', 'access', 'wide', 'variety', 'source', 'medium', 'type', 'occur', 'web', 'search', 'lose', 'provenance', 'lose', 'difﬁcult', 'determine', 'generation', 'original', 'model', 'stochastic', 'parrot', 'bender', 'ziegler', 'moreover', 'privacy', 'security', 'intellectual', 'property', 'concern', 'provenance', 'code', 'generate', 'large', 'language', 'model', 'withhold', 'even', 'destroy', 'suggest', 'future', 'assistance', 'experience', 'mixedmedia', 'search', 'integrate', 'programmer', 'assistance', 'tool', 'model', 'make', 'capable', 'generate', 'type', 'result', 'simple', 'code', 'autocomplete', 'paradigm', 'current', 'tool', 'ai', 'assistance', 'compilation', 'alternative', 'perspective', 'assistance', 'compiler', 'view', 'program', 'natural', 'language', 'prompt', 'query', 'form', 'higherlevel', 'speciﬁcation', 'compile', 'model', 'source', 'code', 'target', 'language', 'low', 'level', 'let', 'crudely', 'assume', 'programming', 'notation', 'travel', 'abstraction', 'continuum', 'low', 'high', 'level', 'programmer', 'become', 'ﬁrstly', 'less', 'concerned', 'mechanistic', 'detail', 'program', 'execution', 'secondly', 'declarative', 'specify', 'computation', 'require', 'rather', 'compute', 'general', 'desirable', 'property', 'programming', 'notation', 'always', 'make', 'activity', 'programming', 'easy', 'accessible', 'people', 'write', 'code', 'declarative', 'language', 'formal', 'veriﬁcation', 'tool', 'tell', '’', 'often', 'much', 'difﬁcult', 'specify', 'much', 'broadly', 'adopt', 'practice', 'testdriven', 'development', 'adjacent', 'test', 'necessarily', 'write', 'higherlevel', 'language', 'code', 'aim', 'capture', 'higherlevel', 'notion', 'correctness', 'problem', 'solve', 'learn', 'test', 'engineer', 'take', 'time', 'experience', 'entire', 'distinct', 'career', 'path', 'software', 'engineer', 'test', 'attest', 'specialised', 'requirement', 'programming', 'high', 'level', 'abstraction', 'draw', 'distinction', 'programming', 'speciﬁcation', 'language', 'compile', 'pro', 'gramme', 'language', 'tony', 'hoare', 'consider', 'different', 'ground', 'compiler', 'aim', 'map', 'program', 'source', 'language', 'ﬁnite', 'set', 'valid', 'program', 'target', 'language', 'speciﬁcation', 'satisﬁe', 'inﬁnite', 'number', 'valid', 'program', 'per', 'comm', 'author', 'thus', 'technical', 'interaction', 'design', 'problem', 'program', 'speciﬁ', 'cation', 'reﬁnement', 'encompasse', 'much', 'broad', 'technical', 'interaction', 'design', 'problem', 'compiler', 'acknowledge', 'distinction', 'insufﬁcient', 'empirical', 'evidence', 'experience', 'report', 'summarise', 'section', 'working', 'programmer', 'consistently', 'make', 'meaningful', 'distinction', 'concept', 'program', 'large', 'language', 'model', 'higherlevel', 'notation', 'also', 'allow', 'programmer', 'less', 'concerned', 'detail', 'target', 'language', 'example', 'developer', 'experience', 'report', 'rely', 'assistance', 'ﬁll', 'correct', 'syntax', 'discover', 'correctly', 'use', 'appropriate', 'api', 'call', 'thus', 'allow', 'focus', 'higherlevel', 'aspect', 'problem', 'solve', 'however', 'fundamental', 'difference', 'experience', 'experience', 'use', 'compiler', 'first', 'abstraction', 'complete', 'programmer', 'completely', 'unaware', 'target', 'language', 'still', 'able', 'understand', 'evaluate', 'generate', 'code', 'order', 'use', 'tool', 'effectively', 'compiler', 'knowledge', 'target', 'language', 'help', 'experienced', 'developer', 'certain', 'circumstance', 'far', 'prerequisite', 'effective', 'usage', 'moreover', 'compiler', 'rely', 'almost', 'universally', 'generate', 'correct', 'complete', 'translation', 'source', 'target', 'language', 'program', 'ai', 'assistance', 'involve', 'active', 'checking', 'adaptation', 'translate', 'code', 'next', 'compiler', 'comparatively', 'deterministic', 'consistently', 'produce', 'output', 'input', 'case', 'current', 'programming', 'tool', 'fundamental', 'limitation', 'consistency', 'enforce', 'finally', 'often', 'criticise', 'cryptic', 'unhelpful', 'barik', 'compiler', 'offer', 'level', 'interaction', 'feedback', 'warning', 'error', 'message', 'help', 'programmer', 'improve', 'code', 'source', 'language', 'currently', 'facility', 'programming', 'tool', 'strike', 'area', 'potential', 'innovation', 'perhaps', 'profoundly', 'natural', 'language', 'use', 'express', 'concept', 'high', 'abstraction', 'level', 'range', 'abstraction', 'expressible', 'natural', 'language', 'much', 'wide', 'form', 'program', 'notation', 'traditional', 'programming', 'notation', 'adhoc', 'abstraction', 'capabilitie', 'subrou', 'tine', 'class', 'allow', 'programmer', 'manually', 'raise', 'level', 'abstraction', 'code', 'apis', 'code', 'generate', 'language', 'model', 'see', 'report', 'section', 'prompt', 'span', 'gamut', 'describe', 'entire', 'application', 'sentence', 'painstakingly', 'describe', 'algorithm', 'stepbystep', 'pseudocode', 'thus', 'mistake', 'view', 'program', 'ai', 'assistance', 'rung', 'abstraction', 'ladder', 'view', 'device', 'teleport', 'programmer', 'arbitrary', 'rung', 'ladder', 'desire', 'close', 'discussion', 'ai', 'assistance', 'compiler', 'miscellaneous', 'note', 'idea', 'use', 'natural', 'language', 'programming', 'notation', 'long', 'history', 'cover', 'however', 'notable', 'many', 'way', 'natural', 'language', 'integrate', 'program', 'debug', 'large', 'language', 'model', 'well', 'capability', 'inference', 'intent', 'translation', 'code', 'therefore', 'also', 'potential', 'open', 'new', 'strategy', 'inspect', 'explain', 'code', 'also', 'new', 'failure', 'mode', 'paradigm', 'program', 'ai', 'assistance', 'pair', 'program', 'third', 'common', 'perspective', 'aiassiste', 'programming', 'pair', 'programming', 'github', 'commercial', 'tagline', 'describe', 'ai', 'pair', 'programmer', 'oppose', 'search', 'compi', 'lation', 'relatively', 'impersonal', 'tool', 'analogy', 'pair', 'programming', 'evocative', 'bespoke', 'experience', 'assistance', 'partner', 'understand', 'speciﬁc', 'context', 'try', 'achieve', 'aiassisted', 'programming', 'potential', 'person', 'alise', 'extent', 'take', 'consideration', 'speciﬁc', 'source', 'code', 'project', 'ﬁle', 'hacker', 'news', 'commenter', 'write', 'point', 'write', 'entire', 'function', 'correct', 'dumb', 'boilerplate', 'initialization', 'actual', 'logic', 'loop', 'context', 'awareness', 'chart', 'sometimes', '’', 'stereotypical', 'intern', 'associate', 'builtin', 'editor', '’', 'also', 'ridiculously', 'ﬂexible', 'start', 'write', 'graph', 'ascii', 'cause', 'quickly', 'write', 'scratch', 'actually', 'understand', 'start', 'autocomplete', 'textual', 'node', 'ascii', 'graph', 'personalisation', 'analogy', 'also', 'recall', 'conventional', 'roledivision', 'pair', 'programming', 'driver', 'navigator', 'program', 'need', 'form', 'mental', 'model', 'program', 'many', 'layer', 'speciﬁc', 'statement', 'work', 'context', 'subroutine', 'role', 'subroutine', 'play', 'module', 'module', 'program', 'however', 'code', 'write', 'statement', 'level', 'force', 'developer', 'keep', 'low', 'level', 'constantly', 'forefront', 'work', 'memory', 'experienced', 'developer', 'spend', 'time', 'map', 'code', 'spend', 'less', 'time', 'write', 'research', 'code', 'display', 'navigation', 'explore', 'different', 'way', 'present', 'line', 'code', 'help', 'programmer', 'well', 'keep', 'different', 'layer', 'mental', 'model', 'mind', 'fleme', 'pair', 'programming', 'argument', 'go', 'allow', 'partner', 'share', 'burden', 'mental', 'model', 'driver', 'code', 'statement', 'subroutine', 'level', 'navigator', 'map', 'approach', 'module', 'program', 'level', 'analogy', 'pair', 'program', 'assistant', 'take', 'role', 'driver', 'solo', 'programmer', 'take', 'place', 'navigator', 'see', 'experience', 'programming', 'ai', 'assistance', 'consistently', 'absolve', 'human', 'programmer', 'responsibility', 'understand', 'code', 'statement', 'subroutine', 'level', 'programmer', 'able', 'become', 'lazy', 'learn', 'various', 'detail', 'syntax', 'library', 'experience', 'still', 'involve', 'much', 'great', 'statementlevel', 'checking', 'pair', 'programming', 'session', 'require', 'conscious', 'negotiate', 'decision', 'swap', 'role', 'solo', 'grammer', 'ai', 'assistant', 'ﬂuidly', 'traverse', 'spectrum', 'drive', 'navigation', 'moment', 'next', 'partially', 'explain', 'preliminary', 'experiment', 'n21', 'compare', 'experience', 'pair', 'programming', 'copilot', 'program', 'man', 'pair', 'driver', 'ﬁnd', 'programmer', 'write', 'line', 'code', 'copilot', 'human', 'pair', 'line', 'low', 'quality', 'subsequently', 'delete', 'moreover', 'metaanalyse', 'pair', 'programming', 'show', 'mixed', 'efﬁcacy', 'human', 'pair', 'programming', 'task', 'time', 'code', 'quality', 'correctness', 'hannay', 'suggest', 'emulate', 'pair', 'programming', 'experience', 'necessarily', 'good', 'target', 'aim', 'multiple', 'study', 'conclude', 'apparent', 'success', 'pair', 'programming', 'attribute', 'role', 'division', 'driver', 'navigator', 'rather', 'high', 'degree', 'verbalisation', 'occur', 'pair', 'programmer', 'force', 'rationalise', 'decision', 'hannay', 'find', 'programming', 'pair', 'induce', 'great', 'focus', 'respect', 'share', 'time', 'pair', 'programmer', 'less', 'likely', 'read', 'email', 'surf', 'web', 'take', 'long', 'phone', 'call', 'kessler', 'particular', 'beneﬁts', 'pair', 'programming', 'capture', 'ai', 'assistance', 'tool', 'comparison', 'pair', 'programming', 'thus', 'relatively', 'superﬁcial', 'today', 'experience', 'aiassisted', 'programming', 'comparable', 'pair', 'programming', 'extent', 'search', 'lation', 'distinct', 'way', 'program', 'llmassisted', 'programming', 'assistance', 'bear', 'similarity', 'search', 'begin', 'prompt', 'information', 'asymmetry', 'several', 'result', 'inexact', 'solution', 'difference', 'search', 'mixedmedia', 'llm', 'assistance', 'ﬁxe', 'search', 'often', 'provenance', 'language', 'model', 'also', 'bear', 'similarity', 'compilation', 'programming', 'speciﬁcation', 'enable', 'program', 'high', 'level', 'abstraction', 'deﬁnition', 'high', 'yet', 'unlike', 'compiler', 'programmer', 'use', 'ai', 'assistance', 'still', 'work', 'knowledge', 'target', 'language', 'actively', 'check', 'output', 'correctness', 'get', 'little', 'feedback', 'improve', 'source', 'code', 'also', 'bear', 'superﬁcial', 'similarity', 'pair', 'programming', 'promise', 'let', 'programmer', 'take', 'role', 'navigator', 'form', 'highlevel', 'mental', 'model', 'program', 'delegate', 'role', 'driver', 'language', 'model', 'pair', 'program', 'human', 'navigator', 'often', 'hop', 'driver', 'seat', 'pair', 'programming', 'llmassisted', 'programming', 'require', 'verbalisation', 'coerce', 'great', 'focus', 'respect', 'share', 'time', 'thus', 'exist', 'metaphor', 'completely', 'capture', 'experience', 'llmassisted', 'programming', 'emerge', 'distinct', 'way', 'programming', 'quite', 'strike', 'distinct', 'practice', 'pro', 'gramme', 'term', 'apply', 'community', 'programmer', 'unite', 'similar', 'ethos', 'aim', 'enterprise', 'software', 'engineer', 'bricoleur', 'live', 'coder', 'code', 'bender', 'blackwell', 'note', 'clear', 'criterion', 'deﬁne', 'boundary', 'prac', 'tice', 'strike', 'new', 'activity', 'programming', 'cognitive', 'dimension', 'figure', 'gridbook', 'interface', 'show', 'natural', 'language', 'formula', 'spreadsheet', 'grid', 'framework', 'assistance', 'clearly', 'orthogonal', 'author', 'transcription', 'modiﬁcation', 'applicable', 'activity', 'besides', 'yet', 'way', 'programming', 'seem', 'affect', 'programmer', 'experience', 'profoundly', 'feature', 'autocomplete', 'farreache', 'pact', 'attitude', 'practice', 'author', 'information', 'forage', 'debug', 'refactoring', 'testing', 'documentation', 'code', 'maintenance', 'learning', 'issue', 'application', 'enduser', 'program', 'beneﬁts', 'challenge', 'programming', 'llm', 'discuss', 'far', 'concern', 'professional', 'pro', 'grammer', 'novice', 'programmer', 'training', 'formal', 'training', 'programming', 'often', 'understanding', 'imperfect', 'nature', 'aigenerate', 'code', 'majority', 'people', 'pro', 'gram', 'fall', 'category', 'instead', 'ordinary', 'end', 'user', 'computer', 'program', 'end', 'enduser', 'programmer', 'often', 'lack', 'knowledge', 'programming', 'working', 'also', 'lack', 'inclination', 'acquire', 'skill', 'reasonable', 'say', 'enduser', 'programmer', 'eg', 'accountant', 'journalist', 'scientist', 'business', 'owner', 'stand', 'beneﬁt', 'ai', 'assistance', 'llm', 'ideal', 'world', 'enduser', 'want', 'accomplish', 'task', 'simply', 'specify', 'intent', 'familiar', 'natural', 'language', 'prior', 'knowledge', 'underlying', 'programming', 'model', 'syntax', 'semantic', 'code', 'generate', 'even', 'automatically', 'run', 'produce', 'desire', 'output', 'however', 'see', 'far', 'world', 'ideal', 'even', 'train', 'programmer', 'face', 'various', 'chal', 'lenge', 'program', 'challenge', 'exacerbate', 'enduser', 'programmer', 'study', 'observe', 'participant', 'study', 'datum', 'analyst', 'n20', 'conduct', 'exploratory', 'datum', 'analysis', 'gridbook', 'naturallanguage', 'augment', 'spreadsheet', 'system', 'gridbook', 'figure', 'adopt', 'user', 'write', 'spreadsheet', 'formula', 'use', 'natural', 'language', 'figure', 'formal', 'formula', 'synthesize', 'natural', 'language', 'utterance', 'gridbook', 'also', 'infer', 'con', 'text', 'utterance', 'example', 'figure', 'query', 'label', 'followup', 'label', 'natural', 'language', 'utterance', 'synthesized', 'formula', 'persist', 'user', 'edit', 'manipulate', 'issue', 'intent', 'speciﬁcation', 'problem', 'decomposition', 'computational', 'thinking', 'attempt', 'accomplish', 'datum', 'analysis', 'task', 'use', 'natural', 'language', 'participant', 'reﬁne', 'speciﬁcation', 'intent', 'natural', 'language', 'several', 'time', 'arrive', 'desire', 'result', 'utterance', 'often', 'underspeciﬁed', 'ambiguous', 'complex', 'contain', 'domain', 'phrase', 'speciﬁe', 'context', 'eg', 'datum', 'analyze', 'thus', 'ﬁrst', 'issue', 'communicate', 'capability', 'system', 'make', 'interpretable', 'user', 'see', 'prompt', 'interpret', 'enduser', 'programmer', 'often', 'also', 'lack', 'key', 'computational', 'thinking', 'skill', 'wing', 'ability', 'decompose', 'problem', 'subproblem', 'reformulate', 'problem', 'way', 'compute', 'system', 'however', 'effective', 'use', 'llm', 'codex', 'require', 'skill', 'example', 'model', 'accurate', 'solution', 'problem', 'single', 'line', 'user', 'able', 'break', 'problem', 'small', 'subproblem', 'solve', 'line', 'moreover', 'also', 'lack', 'ability', 'frame', 'problem', 'generic', 'computational', 'problem', 'rather', 'domainspeciﬁc', 'problem', 'example', 'realtor', 'likely', 'ask', 'large', 'house', 'declaratively', 'instead', 'house', 'maximum', 'construct', 'area', 'procedurally', 'therefore', 'endus', 'computing', 'environment', 'power', 'help', 'enduser', 'programmer', 'think', 'computationally', 'aid', 'user', 'break', 'problem', 'small', 'step', 'guide', 'user', 'alternative', 'strategy', 'specify', 'solve', 'problem', 'eg', 'provide', 'example', 'offer', 'alternative', 'even', 'seek', 'procedural', 'prompt', 'need', 'disambiguation', 'issue', 'code', 'correctness', 'quality', 'overconﬁdence', 'second', 'challenge', 'verify', 'code', 'generate', 'model', 'correct', 'gridbook', 'user', 'able', 'see', 'natural', 'language', 'utterance', 'synthesize', 'formula', 'result', 'mula', 'participant', 'heavily', 'rely', 'eyeball', 'ﬁnal', 'output', 'means', 'evaluate', 'correctness', 'code', 'rather', 'example', 'read', 'code', 'testing', 'rigorously', 'lack', 'rigorous', 'testing', 'enduser', 'programmer', 'unsurprise', 'user', 'particularly', 'low', 'computer', 'selfefﬁcacy', 'overestimate', 'accuracy', 'ai', 'deepen', 'overcon', 'ﬁdence', 'enduser', 'programmer', 'know', 'program', 'accuracy', 'panko', 'moreover', 'enduser', 'programmer', 'able', 'discern', 'quality', 'nonfunctional', 'aspect', 'generate', 'code', 'security', 'robustness', 'performance', 'issue', 'issue', 'code', 'comprehension', 'maintenance', 'third', 'challenge', 'programming', 'issue', 'code', 'comprehension', 'user', 'evaluation', 'participant', 'mention', 'generate', 'formula', 'hard', 'understand', 'even', 'user', 'familiar', 'target', 'language', 'potentially', 'severe', 'consequence', 'evaluate', 'accuracy', 'program', 'verify', 'logic', 'ability', 'customize', 'code', 'future', 'debugging', 'reuse', 'discuss', 'early', 'problem', 'also', 'exist', 'train', 'developer', 'approach', 'address', 'issue', 'ai', 'system', 'include', 'notion', 'code', 'readability', 'comprehensibility', 'factor', 'code', 'synthesis', 'learning', 'phase', 'rank', 'suggestion', 'even', 'take', 'input', 'model', 'similar', 'temperature', 'parameter', 'codex', 'approach', 'useful', 'broadly', 'synthesize', 'high', 'quality', 'code', 'optimize', 'performance', 'robustness', 'second', 'solution', 'tackle', 'comprehension', 'problem', 'explain', 'generate', 'code', 'user', 'manner', 'less', 'programmerese', 'center', 'user', 'current', 'task', 'context', 'initial', 'evidence', 'suggest', 'participant', 'open', 'idea', 'thus', 'area', 'ripe', 'future', 'exploration', 'issue', 'consequence', 'automation', 'enduser', 'programming', 'ai', 'system', 'need', 'consider', 'consequence', 'automation', 'enduser', 'programmer', 'know', 'turn', 'local', 'expert', 'gardener', 'enduser', 'programmer', 'interest', 'expertise', 'pro', 'gramming', 'serve', 'guru', 'enduser', 'programming', 'environment', 'unable', 'solve', 'part', 'problem', 'gordon', 'taskorientation', 'tendency', 'combine', 'challenge', 'complete', 'task', 'easily', 'also', 'leave', 'enduser', 'programmer', 'limited', 'attention', 'testing', 'carefully', 'learn', 'go', 'program', 'assume', 'llm', 'associated', 'user', 'experience', 'improve', 'come', 'year', 'make', 'enduser', 'programming', 'fast', 'llm', 'tempting', 'wonder', 'programmer', 'persuade', 'invest', 'save', 'time', 'attention', 'aspect', 'learn', 'test', 'program', 'take', 'inﬂuence', 'behaviour', 'change', 'question', 'role', 'expert', 'conjecture', 'llm', 'similar', 'capability', 'soon', 'able', 'answer', 'sizeable', 'fraction', 'question', 'enduser', 'programmer', 'go', 'local', 'expert', 'open', 'question', 'therefore', 'ecosystem', 'enduser', 'programmer', 'organization', 'change', 'role', 'importance', 'speciality', 'example', 'gardener', 'take', 'role', 'educate', 'user', 'well', 'take', 'advantage', 'communicate', 'working', 'ai', 'system', 'technophile', 'user', 'early', 'adopter', 'enable', 'organization', 'issue', 'code', 'dilemma', 'direct', 'answer', 'finally', 'foregone', 'conclusion', 'user', 'even', 'interested', 'code', 'blackwell', 'model', 'attention', 'investment', 'note', 'many', 'case', 'user', 'content', 'perform', 'action', 'manually', 'rather', 'invest', 'create', 'reusable', 'automation', 'spreadsheet', 'user', 'particular', 'often', 'sensitive', 'level', 'automation', 'automatability', 'give', 'work', 'ﬂow', 'use', 'mix', 'manual', 'automate', 'semiautomate', 'technique', 'achieve', 'goal', 'hand', 'pandita', 'spreadsheet', 'user', 'often', 'need', 'adhoc', 'transformation', 'datum', 'likelihood', 'never', 'need', 'express', 'transformation', 'program', 'user', 'interested', 'output', 'program', 'important', 'even', 'necessary', 'communicate', 'fact', 'user', 'argue', 'increase', 'user', 'awareness', 'ﬂexibility', 'fallibility', 'process', 'deliver', 'infer', 'result', 'enable', 'critically', 'evaluate', 'output', 'sarkar', 'build', 'agency', 'conﬁdence', 'trust', 'resilience', 'issue', 'relate', 'dilemma', 'direct', 'answer', 'potthast', 'raise', 'response', 'increase', 'phenomenon', 'search', 'engine', 'directly', 'answer', 'query', 'addition', 'simply', 'list', 'retrieved', 'result', 'however', 'programming', 'language', 'use', 'relate', 'language', 'familiar', 'enduser', 'user', 'complete', 'novice', 'exceedingly', 'difﬁcult', 'make', 'sense', 'show', 'lau', 'study', 'excel', 'user', 'encounter', 'code', 'sociotechnical', 'motivation', 'use', 'unfamiliar', 'target', 'language', 'longterm', 'testing', 'llm', 'assistance', 'show', 'shine', 'pair', 'highlevel', 'apis', 'capture', 'use', 'case', 'section', 'advantage', 'ecosystem', 'unparalleled', 'set', 'library', 'apis', 'datum', 'wrangle', 'llmassisted', 'tool', 'emit', 'excel', 'formula', 'therefore', 'less', 'likely', 'solve', 'user', 'problem', 'statement', 'long', 'term', 'mitigate', 'develop', 'rich', 'set', 'data', 'manipulation', 'library', 'excel', 'formula', 'language', 'conclusion', 'large', 'language', 'model', 'initiate', 'signiﬁcant', 'change', 'scope', 'quality', 'program', 'code', 'automatically', 'generate', 'compare', 'previous', 'approach', 'experience', 'commercially', 'available', 'tool', 'build', 'model', 'suggest', 'represent', 'new', 'way', 'program', 'llm', 'assistance', 'transform', 'almost', 'aspect', 'experience', 'programming', 'include', 'planning', 'thore', 'reuse', 'modiﬁcation', 'comprehension', 'debugging', 'aspect', 'llm', 'assistance', 'resemble', 'highly', 'intelligent', 'ﬂexible', 'compiler', 'partner', 'pair', 'programming', 'seamless', 'searchandreuse', 'feature', 'yet', 'aspect', 'llmassisted', 'programming', 'ﬂavour', 'present', 'new', 'challenge', 'opportunity', 'humancentric', 'pro', 'gramme', 'research', 'moreover', 'even', 'great', 'challenge', 'help', 'nonexpert', 'end', 'user', 'beneﬁt', 'tool', 'experience', 'report', 'source', 'appendix', 'contain', 'list', 'source', 'draw', 'quote', 'analysis', 'section', 'source', 'include', 'analysis', 'draw', 'direct', 'quote', 'source', 'list', 'blog', 'post', 'correspond', 'hacker', 'news', 'discussion', 'building', 'game', 'app', 'entirely', 'natural', 'language', 'use', 'com20220317buildinggamesandappsentirelythroughnatural', 'languageusingopenaisdavincicodemodel', 'hacker', 'news', 'discussion', 'build', 'nocode', 'machine', 'learning', 'model', 'chat', 'te', 'url', 'codetoxicityclassifierbytalkingtocopilot', 'hacker', 'news', 'discussion', 'rickard', 'month', 'use', 'url', 'rickardcomgithubcopilotamonthin', 'nutanc', 'use', 'copilot', 'get', 'tweet', 'keyword', 'sentiment', 'tweet', 'min', 'code', 'url', 'githubiobloggithubcopilot', 'aleksej', 'fully', 'trust', 'ai', 'dev', 'work', 'yet', 'hacker', 'news', 'discussion', 'reference', 'allamani', 'devanbu', 'p', 'survey', 'machine', 'learning', 'big', 'code', 'naturalness', 'acm', 'comput', 'surv', 'retrieve', 'smartpaste', 'learn', 'adapt', 'source', 'code', 'preprint', 'odena', 'nye', 'program', 'synthesis', 'large', 'language', 'model', 'retrieve', 'compiler', 'explain', 'problem', 'developer', 'proceeding', '26th', 'acm', 'joint', 'meeting', 'european', 'software', 'engineering', 'conference', 'symposium', 'foundation', 'software', 'engineering', 'heart', 'hacker', 'news', 'expand', 'qualitative', 'research', 'ﬁnding', 'analyze', 'social', 'news', 'website', 'proceeding', '10th', 'joint', 'meeting', 'foun', 'dation', 'software', 'engineering', 'ground', 'copilot', 'programmer', 'interact', 'codegenerate', 'model', 'retrieve', 'church', 'l', 'clark', 'software', 'live', 'embed', 'live', 'program', 'world', 'ppig', 'bender', 'e', 'shmitchell', 'danger', 'stochastic', 'parrot', 'language', 'model', 'big', 'elish', 'zemel', 'ed', 'facct', 'acm', 'conference', 'fairness', 'accountability', 'transparency', 'virtual', 'event', 'acm', 'retrieve', 'bergström', 'blackwell', 'practice', 'programming', 'ieee', 'symposium', 'visual', 'language', 'humancentric', 'compute', 'blackwell', 'first', 'step', 'program', 'rationale', 'attention', 'investment', 'model', 'proceeding', 'ieee', 'symposia', 'human', 'centric', 'computing', 'language', 'environment', 'blackwell', 'program', 'ppig', 'bødker', 'thirdwave', 'hci', 'year', 'later', 'participation', 'share', 'interaction', 'retrieve', 'ryder', 'amodei', 'language', 'model', 'fewshot', 'learner', 'idea', 'garden', 'situate', 'support', 'problem', 'solve', 'enduser', 'programmer', 'interact', 'computer', 'chalhoub', 'sarkar', '’', 'freedom', 'put', 'thing', 'mind', 'want', 'understanding', 'conference', 'improve', 'user', 'experience', 'structure', 'datum', 'spreadsheet', 'human', 'factor', 'compute', 'system', 'compute', 'machinery', 'retrieve', 'doi', 'p', 'evaluate', 'large', 'language', 'model', 'train', 'code', 'corr', 'abs210703374', 'retrieve', 'q', 'h', 'kaplan', 'evaluate', 'large', 'language', 'model', 'train', 'code', 'robert', 'fiedel', 'palm', 'scale', 'language', 'modeling', 'roussel', 'p', 'birth', 'prolog', 'history', 'programming', 'language', 'pretraining', 'deep', 'bidi', 'proceeding', 'conference', 'rectional', 'transformer', 'language', 'understand', 'north', 'american', 'chapter', 'association', 'language', 'technolo', 'gy', 'volume', 'long', 'short', 'paper', 'computational', 'linguistic', 'retrieve', 'blackwell', 'cognitive', 'dimension', 'information', 'artefact', 'tutorial', 'vol', 'pp', 'r', 'cognitive', 'dimension', 'notation', 'people', 'computer', 'green', 'r', 'petre', 'visual', 'program', 'hard', 'read', 'textual', 'program', 'humancomputer', 'interaction', 'task', 'organisation', 'proceeding', 'ecce6', '6th', 'european', 'confer', 'ence', 'cognitive', 'ergonomic', 'antavolit', 'automate', 'string', 'processing', 'spreadsheet', 'use', 'inputoutput', 'example', 'proceeding', '38th', 'acm', 'sigplansigact', 'symposium', 'principle', 'programming', 'language', 'popl', 'acm', 'retrieve', 'doi', 'hannay', 'e', 'effectiveness', 'pair', 'program', 'metaanalysis', 'information', 'software', 'technology', 'henley', 'fleming', 'patchwork', 'code', 'editor', 'fast', 'navigation', 'less', 'code', 'arrange', 'navigation', 'mistake', 'proceeding', 'conference', 'human', 'factor', 'compute', 'system', 'detect', 'refactore', 'code', 'smell', 'spread', 'sheet', 'formula', 'empirical', 'software', 'engineering', 'hindle', 'devanbu', 'p', 'naturalness', 'software', 'commun', 'acm', 'retrieve', 'hindle', 'gabel', 'devanbu', 'p', 'naturalness', 'soft', 'glinz', 'pezzè', 'ed', '34th', 'international', 'conference', 'soft', 'ware', 'ware', 'switzerland', 'ieee', 'com', 'puter', 'society', 'retrieve', 'hoare', 'c', 'r', 'axiomatic', 'basis', 'computer', 'programming', 'commun', 'acm', 'retrieve', 'doi', 'hochreiter', 'schmidhuber', 'nov', 'long', 'shortterm', 'memory', 'neural', 'comput', 'retrieve', 'doi', 'principle', 'mixedinitiative', 'user', 'interface', 'proceeding', 'conference', 'human', 'factor', 'compute', 'system', 'hutchin', 'l', 'direct', 'manipulation', 'interface', 'hum', 'comput', 'retrieve', 'substitute', 'human', 'pairprogramme', 'empirical', 'study', 'ieeeacm', '44th', 'international', 'conference', 'software', 'engineering', 'companion', 'proceeding', 'companion', 'e', 'toh', 'e', 'donsbach', 'discover', 'syntax', 'strategy', 'natural', 'language', 'programming', 'generative', 'language', 'model', 'conference', 'human', 'factor', 'compute', 'system', 'kery', 'explore', 'exploratory', 'programming', 'ieee', 'symposium', 'visual', 'language', 'humancentric', 'compute', 'design', 'whyline', 'debugging', 'interface', 'ask', 'question', 'proceeding', 'conference', 'human', 'factor', 'compute', 'program', 'behavior', 'system', 'structure', 'labeling', 'facilitat', 'e', 'concept', 'evolution', 'machine', 'learning', 'proceeding', 'conference', 'human', 'factor', 'compute', 'system', 'kurlander', 'cypher', 'halbert', 'watch', 'program', 'demonstration', 'mit', 'press', 'milne', 'sarkar', 'tweakit', 'support', 'end', 'user', 'programmer', 'code', 'proceeding', 'chi', 'conference', 'human', 'factor', 'compute', 'system', 'pretraine', 'language', 'model', 'text', 'generation', 'survey', 'proceeding', 'thirtieth', 'international', 'joint', 'conference', 'artiﬁcial', 'intelligence', 'ijcai21', 'international', 'joint', 'conference', 'artiﬁcial', 'intelligence', 'organization', 'retrieve', 'survey', 'r', 'vinyal', 'competitionlevel', 'code', 'generation', 'retrieve', 'r', 'vinyal', 'competitionlevel', 'code', 'generation', 'wish', 'command', 'programming', 'example', 'feasibility', 'study', 'program', 'natural', 'language', 'end', 'user', 'development', 'retrievalaugmente', 'generation', 'code', 'summarization', 'hybrid', 'gnn', 'international', 'conference', 'learn', 'representation', 'retrieve', 'blanco', 'codexglue', 'machine', 'learn', 'benchmark', 'dataset', 'code', 'understanding', 'generation', 'lug', 'sellen', 'really', 'bad', 'gulf', 'user', 'expectation', 'experience', 'conversational', 'agent', 'proceeding', 'chi', 'conference', 'human', 'factor', 'compute', 'system', 'macvean', 'church', 'l', 'daughtry', 'api', 'usability', 'scale', 'ppig', 'p', 'church', 'l', 'blackwell', 'empirical', 'investigation', 'code', 'completion', 'usage', 'professional', 'software', 'developer', 'ppig', 'mikolov', 'sutskever', 'distribute', 'representation', 'word', 'phrase', 'compositionality', 'burge', 'bottou', 'well', 'weinberger', 'ed', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'curran', 'retrieve', 'miller', 'natural', 'language', 'programming', 'style', 'strategy', 'contrast', 'l', 'convolutional', 'neural', 'network', 'tree', 'structure', 'program', 'language', 'processing', 'sarkar', 'need', 'natural', 'language', 'explore', 'restrict', 'language', 'interface', 'extended', 'abstract', 'conference', 'human', 'factor', 'complex', 'domain', 'computing', 'system', 'demonstrational', 'interface', 'step', 'direct', 'manipulation', 'computer', 'myer', 'b', 'improve', 'api', 'usability', 'communication', 'acm', 'nardi', 'b', 'small', 'matter', 'program', 'perspective', 'end', 'user', 'computing', 'nguyen', 'divideandconquer', 'approach', 'multiphase', 'statistical', 'migration', 'source', 'code', '30th', 'ieeeacm', 'international', 'conference', 'automate', 'software', 'engineering', 'ase', 'herman', 'halfmeasure', 'study', 'manual', 'toolassiste', 'enduser', 'programming', 'task', 'excel', 'ieee', 'symposium', 'visual', 'language', 'humancentric', 'compute', 'panko', 'r', 'r', 'reduce', 'overconﬁdence', 'spreadsheet', 'development', 'preprint', 'r', 'asleep', 'keyboard', 'assess', 'security', 'contribution', 'retrieve', 'piccioni', 'meyer', 'b', 'empirical', 'study', 'api', 'usability', 'acmieee', 'international', 'symposium', 'empirical', 'software', 'engineering', 'measurement', 'potthast', 'b', 'dilemma', 'direct', 'answer', 'vol', 'raychev', 'krause', 'predict', 'program', 'property', 'big', 'code', 'walker', 'ed', 'proceeding', '42nd', 'annual', 'acm', 'sigplansigact', 'sium', 'principle', 'programming', 'language', 'popl', 'mumbai', 'acm', 'retrieve', 'rouchy', 'p', 'aspect', 'prolog', 'history', 'logic', 'programming', 'professional', 'dynamic', 'swedenenglish', 'teamethnoonline2', 'berente', 'n', 'pair', 'programming', 'solo', 'programming', 'know', 'year', 'research', 'conference', 'system', 'science', 'hicss', 'sarkar', 'interactive', 'analytical', 'modelling', 'tech', 'rep', 'ucamcltr920', 'uni', 'versity', 'computer', 'laboratory', 'retrieve', 'march', 'workshop', 'transparency', 'explanation', 'smart', 'system', 'texss', 'conjunction', 'acm', 'intelligent', 'user', 'interface', 'retrieve', 'paper22pdf', 'explainable', 'ai', 'race', 'model', 'complexity', 'gordon', 'people', 'learn', 'use', 'spreadsheet', 'work', 'progress', 'proceeding', '29th', 'annual', 'conference', 'psychology', 'program', 'interest', 'group', 'ppig', 'sarkar', 'blackwell', 'interactive', 'visual', 'machine', 'learn', 'ieee', 'symposium', 'visual', 'language', 'humancentric', 'computing', 'spreadsheet', 'vlhcc', 'sarkar', 'enduser', 'encounter', 'lambda', 'abstraction', 'bow', 'achille', 'heel', 'ieee', 'symposium', 'visual', 'language', 'humancentric', 'compute', 'norwood', 'direct', 'manipulation', 'step', 'programming', 'spark', 'innovation', 'humancomputer', 'interaction', 'silver', 'introduce', 'visual', 'studio', 'retrieve', 'h', 'gridbook', 'natural', 'language', 'formula', 'spreadsheet', 'grid', '27th', 'international', 'conference', 'intelligent', 'user', 'interface', 'p', 'compute', 'machinery', 'retrieve', 'piorkowski', 'forage', 'overabundance', 'similar', 'variant', 'proceeding', 'chi', 'conference', 'human', 'factor', 'compute', 'system', 'sutskever', 'vinyal', 'sequence', 'sequence', 'learn', 'neural', 'network', 'proceeding', '27th', 'international', 'conference', 'neural', 'information', 'processing', 'system', 'volume', 'p', 'perspective', 'evolution', 'live', 'programming', '1st', 'international', 'workshop', 'live', 'programming', 'live', 'vaithilingam', 'expectation', 'experience', 'evaluate', 'usability', 'code', 'generation', 'tool', 'power', 'large', 'language', 'model', 'conference', 'human', 'factor', 'compute', 'system', 'extend', 'abstract', 'vaswani', 'shazeer', 'polosukhin', 'attention', 'need', 'proceeding', '31st', 'international', 'conference', 'neural', 'information', 'processing', 'system', 'p', 'red', 'hook', 'lambdanet', 'probabilistic', 'type', 'inference', 'use', 'graph', 'network', 'hamadi', 'build', 'bing', 'developer', 'assistant', 'tech', 'rep', 'msrtr201536', 'retrieve', 'researchpublicationbuildingbingdeveloperassistant', 'blog', 'tabnine', 'announcement', 'announce', 'nextgeneration', 'ai', 'model', 'tab', 'retrieve', 'gordon', 'sarkar', 'understanding', 'infer', 'unit', 'ieee', 'symposium', 'visual', 'language', 'humancentric', 'computing', 'spreadsheet', 'kessler', 'r', 'r', 'really', 'need', 'know', 'pair', 'programming', 'learn', 'kindergarten', 'communication', 'acm', 'wing', 'research', 'notebook', 'computational', 'thinking', 'link', 'magazine', 'hellendoorn', 'systematic', 'evaluation', 'large', 'guage', 'model', 'code', 'proceeding', '6th', 'acm', 'international', 'symposium', 'machine', 'programming', 'vasilescu', 'neubig', 'g', 'inide', 'code', 'generation', 'natural', 'language', 'promise', 'challenge', 'acm', 'transaction', 'software', 'engineering', 'methodology', 'yoon', 'support', 'selective', 'undo', 'code', 'editor', 'ieeeacm', '37th', 'ieee', 'international', 'conference', 'software', 'engineering', 'vol', 'bing', 'developer', 'assistant', 'improve', 'developer', 'productivity', 'recommend', 'sample', 'code', 'proceeding', '24th', 'international', 'symposium', 'foundation', 'software', 'engineering', 'research', 'recitation', 'retrieve', 'kalliamvakou', 'e', 'simister', 'rice', 'aftandilian', 'e', 'productivity', 'assessment', 'neural', 'code', 'preprint']"
What is it like to program with artificial intelligence?,"[{'href': 'http://arxiv.org/abs/2208.06213v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2208.06213v1', 'rel': 'related', 'type': 'application/pdf'}]",2022-08-12 10:48:46,"Deep Learning and Health Informatics for Smart Monitoring 
and Diagnosis 

Amin Gasmi 

30 Octobre 2020 

Abstract    The  connection  between  the  design  and  delivery  of  health  care  services  using  information 
technology  is  known  as  health  informatics.  It  involves  data  usage,  validation,  and  transfer  of  an  integrated 
medical analysis using neural networks of multi-layer deep learning techniques to analyze complex data. For 
instance, Google incorporated “DeepMind” health mobile tool that integrates & leverage medical data needed 
to enhance professional healthcare delivery to patients. Moorfield Eye Hospital London introduced DeepMind 
Research Algorithms with dozens of retinal scans attributes while DeepMind UCL handled the identification 
of cancerous tissues using CT & MRI Scan tools. Atomise analyzed drugs and chemicals with Deep Learning 
Neural  Networks  to  identify  accurate  pre-clinical  prescriptions.  Health  informatics  makes  medical  care 
intelligent,  interactive,  cost-effective,  and  accessible;  especially  with  DL  application  tools  for  detecting  the 
actual cause of diseases. The extensive use of neural network tools leads to the expansion of different medical 
disciplines which mitigates data complexity and enhances 3-4D overlap images using target point label data 
detectors that support data augmentation, un-semi-supervised learning, multi-modality and transfer learning 
architecture.  Health  science  over  the  years  focused  on  artificial  intelligence  tools  for  care  delivery,  chronic 
care management, prevention/wellness, clinical supports, and diagnosis. The outcome of their research leads 
to  cardiac  arrest  diagnosis  through  Heart  Signal  Computer-Aided  Diagnostic  tool  (CADX)  and  other  multi-
functional  deep  learning  techniques  that  offer  care,  diagnosis  &  treatment.  Health  informatics  provides 
monitored  outcomes  of  human  body  organs  through  medical  images  that  classify  interstitial  lung  disease, 
detects image nodules for reconstruction & tumor segmentation. The emergent medical research applications 
gave  rise  to  clinical-pathological  human-level  performing  tools  for  handling  Radiological,  Ophthalmological, 
and  Dental  diagnosis.  This  research  will  evaluate  methodologies,  Deep  learning  architectures,  approaches, 
bio-informatics,  specified  function  requirements,  monitoring  tools,  ANN  (artificial  neural  network),  data 
labeling  &  annotation  algorithms  that  control  data  validation,  modeling,  and  diagnosis  of  different  diseases 
using smart monitoring health informatics applications. 

Keywords:  Health  Informatics  Diagnosis,  DL  Smart  Monitoring  App,  DL/ML  Health  Informatics,  Deep 
Learning Algorithms, Health Informatics Devices. 

1 

 
 
 
 
 
 
 
 
Introduction 

The fundamental use of deep learning in neural networks commenced as a result of experts 

study  of  complex  neurons,  layers,  and  its  architectural  paradigms.  This  study  allowed  to 

monitor  data,  its  extended  layer  pipeline,  and  non-linear  outputs  generated  from  low-

dimensional  input  space  projection.  Health  informatics  involve  the  generation  of  an 

automatic  character  set  of  human  cells  with  expert  intrusions.  Medical  imaging  in  health 

informatics can be elaborated to determine implicit internal organs like fibroids and polyps 

tissue  irregularities.  It  can  also  be  used  to  study  morphological  tumors  (Fakoor  et 

al.2013)[1] 

Biologically,  health  informatics  have  anticipated  translational  features  utilized  for 

nucleotide DNA & RNA sequential protein strands.  Convolutional  neural  nets (CNNs)  as a 

deep  learning  approach  in  health  informatics  have  architectural  layers  and  filters  for 

reducing,  rectifying,  and  modifying  poohing  layers.  The  layers  help  to  originate  abstract 

features  found  in  the  visual  cortex  and  receptive  fields  while  other  architectures  like 

restructured  Boltzmann  machines,  deep  belief  networks  DBNs,  stacked  autoencoders, 

extended network and recurrent neural nets (RNNs); assist the advancement of graphical 

process units (GPUs) that impact the growth of deep learning applications.  

Experts  previously  proposed  pre-GPU  and  CNNs  as  parallel  algebraic  operations  with 

matrixes  needed  for  experiments  in  clinics.  To  integrate  deep  learning  architectures  in 

health informatics, its essential to label data and implement activation functions known as 

“transfer  functions  and  weights”.  The  transfer  function  must  classify  linear  patterns  to 

adjust  the weights.  McClelland et a. 1987 [3] proposed neural networks with hidden layers 

of  perceptrons,  stages,  and  epochs  for  new  data  input  samples  &  weights  with  neurons 

adjustable  based  learning  process,  named  “Delta  Rule”.  The  rule  aids  neural  network 

training, exploitation, and backpropagation routines. 

Rumelhart  et  al.1988  [4]  observed  the  random  values  given  to  the  network  weights  to 

determine  it’s  iterative  training  processes  and  minimize  the  difference  between  network 

outputs  and  desired  outcomes.  Rumelhart  et  al.1988  [4]  also  furthered  the  study  of 

iterative  training  using  gradient  descent  techniques  to  reduce  surface  errors  in  the 

2 

 
experiment.  Deep  learning  accelerates  supervised  and  un-supervised  labeled  data, 

whereby  supervised  labeled  data  train  deep  neural  network  to  understand  its  weight, 

minimize  errors,  and  predict  the  targeted  value  for  classifying  the  unsupervised  labeled 

data. Meanwhile, unsupervised deep learning data are utilized for clustering, reduction of 

dimension and featured extraction (Ngiam et al.2011)[2]. 

Artificial Neural network and its variants 

Four deep learning architectures such as Auto-encoder, RBM, CNN, and RNN are mentioned 

to  assist  health  informatics  prediction  and  diagnosis.  The  autoencoder  is  referred  to  as 

feed-forwarder two-phase network that handles encoder and decoder tasks using input X 

and hidden H which represents non-linear equations stated below; 

H  -  stand  for  non-linear  activation  functions  that  decodes  maps  hidden  in  the 

representation. Thus, the original hidden representation can also be calculated with  

Z -If the model parameters optimize and minimize errors in the auto-encoder variants, the 

reconstructing  error  collection  data  =  N,  the  sample  square  error  optimization  =  (Xi=  f 

(xi))2 

Xi represents the ith sample of the unsupervised data, h stands for hidden representation 

and X for data sample (Bengio et al. 2007)[61]. 

The image below demonstrates the difference between physical based, conventional data-

driven, and deep learning auto-encoder algorithm.  

The  conventional  auto-encoder  data-model  requires  handcrafting  features  for  each 

individual  trained  module  and  cannot  handle  large  datasets.  Deep  learning  autoencoder 

methods provide  end-to-end envisioned data structure without handcrafting features and 

train jointly large datasets; 

3 

 
 
 
 
Fig 1. Autoencoder schematic illustration [78] 

According  to  the  diagram  above,  the  learned  transformation  in  the  autoencoder  must  be 

sparse with constraints that implores the hidden unit with an optimizing function written 

below; 

 (Xi= f (xi))2   

M= hidden layer size 

Ki=divergence hidden units and jth hidden neuron.  

The conventional auto-encoder has an additional denoising network that corrects corrupt 

version  of  the  data  input,  reconstruct,  clean  and  train  sample  data  X.  it  also  has  staking 

structure which puts together output lth layers as input (L+1)t-th layer to represent higher 

level and provide solutions to deep neural network model (Vincent et al.2008)[62]. 

4 

 
 
 
 
 
 
 
 
 
 
 
 
 
RBM variants 

Restricted  Boltzmann  machine  has  two-layers  (NN)  bipartite  graph  consisting  of  two 

visible groups known as units V and hidden unit h with an asymmetric link between both, 

but doesn’t connect their nodes.  

RBM model parameters = (w,b,a) energy functions.  

Where  =  Wij –Vi- hj. 

Wij -connecting weight between units 

Vi- total number 1 and hidden unit 

Hi -the total number of Ji bi and ai, which shows the joint RBM distribution over the unit 

based energy function  equated as p(v, hj, Z -partitioned  function/normalization factors).  

The conditional probabilities of the hidden & visible units h and V will be  

P (hj =I/Vj ) 

P (Vi=I/Vj = logistic function  

The w-learning approach is achieved using a contrastive divergence tool (CD). 

Deep belief network variants 

DBN is made up of stack multiple RBM with output ith layer (hidden unit and input (L+1)-

th visible layer. DBN has a common similarity with SDA due to its large layer unsupervised 

pattern in handling pre-trained data parameters.  

Deep Boltzmann machine learning approach contains hidden units grouped into layers of 

single connectivity constraints with its full connection found between subsequent and non-

neighboring layers.  

5 

 
 
 
Convolutional neural network and its variants 

CNN  was  utilized  to  perform  image  spatial  processing  via  weights  &  pooling  properties. 

CNN serves the purpose of authenticating natural language  & speech recognition. It helps 

to learn about the alternating abstract features, stack convolutions & pool operations. The 

two dimensional CNN can be compared to a one-dimensional model using input sequence 

data X=(Xi………………….Xt)where t represents lengths of sequence, Vi-d respectively.  

The convolutional dot production can be filtered with vector U 

Where Ci = 

Where  XT  stands  for  matrix  x,  b  and  the  output  Ci  is  seen  as  the  activated  filter  U  that 

correspond with Xi; I + m-1. The slide filtering window features a map vector of Cj =(C1, C2, 

……………………(l-M+1) 

The  J  represents  the  index  J-th  filter  that  corresponds  with  multi-windows  (Xi;  m,  X2: 

m+1…………….X1-m + 1:1). 

CNN has a max-pooling layer that is capable of reducing the length of the featured map and 

minimized  the  numbers  of  modeled  parameters.  It  has  a  hypermeter  pooling  layer 

denotation of MAX operation with consecutive value S and feature map Cj.  

The compressed feature h= (h, h2, --------- +1) 

Hj= max (c(j-1)s, C (J-1) S+1, …………….C, S-1). 

To predict data possibilities, the alternating CNN max-pooling layers can fully be connected 

to the softmax layer.  

Recurrent neural network and its variants 

Schmidhuber (2015)[63] highlights the arbitrary length sequence  of  pattern input, which 

builds  the  connection  between  direct  cycle  and  multi-layer  perceptron.  RNN  trains  back-

propagated  supervised  data  with  subsequent  input  and  targeted  datasets  (Jaeger, 

6 

 
2002)[64].  It’s functional transition step T shows time information (Xt) moves from prior 

hidden output ht-1 to update the current hidden output ht = H (t,ht-1). 

H - non-linear & differential transforming function. 

Ht- learned representation showing input data and length T. Also, the conventional multi-

layer  perceptron  mapped  the  obtainable  ht  representation  to  make  the  prediction 

successfully.  

The simple function “Vanilla RNN”, can be equated as-ht  

W and H that represent transformation matrixes while b =bias vector.  

Vanilla RNN suffers vanishing gradient problem due to back-propagation, but can easily be 

restored  with  LSTM  and  gate  recurrent  neural  networks  (GRU)  to  prevent  errors  and 

explosion. (Chung et al.2014)[65]. 

The  advanced  version  of  LSTM  &  GRUs  has  a  multi-layer  recurrent  bi-directional  model 

capable of offering structural flexibility.  

Fig 2.  One-layer CNN, pooling layers, fully connected one Softmax Layer [79] 

7 

 
 
Health monitoring applications and wearables 

Rose et al. 2010 [5] implemented hierarchical clustering methods to detect mammographic 

image data. The image below shows health monitoring applications necessary for capturing 

arrays  of  pervasive  sensors  worn  or  implanted  in  the  body  to  capture  ambient  inertia 

motion, ECG patches, smart watches, EEG, and prosthetics (Johnson et al.2016) [6]. 

Pervasive sensors are wearables implanted as ambient sensors that monitor human health 

and accurately estimate food intake, energy expenditure, tackles obesity, chronic diseases, 

and care for patients with disabilities. Patients undergoing rehabilitation and critical care 

situation are often implanted with assisting devices to check vital signs (Pouladzadeh et al. 

2016)[7]. 

During  epidemics, the  escalation  of health-related issues  like  obesity,  and cardiovascular 

diseases are controlled with energy expenditure/activity recognition tool, since it controls 

the amount of diet by monitoring calorie intake. CNN can alternatively be used to recognize 

and  monitor  accurately  food  intake  by  adopting  cloud  computing,  size-calibrating,  and 

distance estimation tools. 

Pouladzadeh  et  al.  2016  [7]  combined  DL  method  with 

invariant  hierarchical 

representation  of  video  using  two-layer  3D  convolution  &  max-pooling  large  inputs  to 

recognize  human  daily  activities.  Yalcin,  2016[9]  used  RGB  D-video  sequence  to  classify 

human  activities  and  mount  surveillance  on  elderly  and  child  care  clinics.  CNN  has 

furthered the detection of baby’s fall & crawls while alerting caregivers by raising an alarm. 

The  RBMs  work  together  on  smartphones  &  watches  (Assisting  devices),  with  audio  & 

tactile  feedback  application,  specifically  used  to  detect  visual  impairment.  Some  assistive 

device consists of CNN DL algorithms that recognize hand gestures, sign languages, sterile 

surroundings,  and  permits  touch-less  human-computer-interaction  (HRI).    Huang  et 

al.2015[8]  introduced  a  deep  neural  network  (DNN)  for  sign  language  recognition  using 

real-sense  data  that  coordinates  finger  joints  inputs  without  handcraft  features.  DL 

machine ensures that health monitoring is achieved with discrete targeted values  applied 

through Softmax later (prognosis and linear regression layer), that limits human labor and 

expert’s skills. 

8 

 
Sun  et  al.  (2016)[41]  used  a  one-layer  auto-encoder  neural  network  to  classify  health-

machine  motor  fault  recognition  and  repair  while  Lu  et  al.  (2017)[42]  diagnose  rotary 

health machine faults with components of stacked denoising AE in the three hidden notable 

layers.  Most  devices  for  vital  signs  like  ECG,  BCG  (ballistocardiogram)  are  built  with  DL 

applications. Technology advancement brought about wearable photos or videos attached 

to  outfits,  and  embedded  sensors  placed  on  chairs,  car  seats,  and  mattresses  (e.g.  Fitbit 

wrist band tracker controlled with mobile apps and add-ons). 

Experts studied the use of a genetic triaxle algorithm known as accelerometer bracelets to 

trace walking patterns (e.g. falls and seizure inpatients). Research declared that prolonged 

sedentary lifestyle can cause adverse health outcomes which made clinicians adopt the use 

of  wearable  devices  for  monitoring  patients'  health  and  advice  physical  activity  when 

necessary.  Choo  et  al.  2017[76]  used  wearable  devices  to  trace  language  patterns  of 

mother-child connection and childhood psychological development. Choi et al. (2017)[75] 

monitored  stress  patterns  using  mentally  equipped  sensors  powered  by  Ml/DL  to 

understand stress in children and adults by following their heartbeat, blood pressure, and 

temperature. 

According  to  our  research,  the  electrodermal  activity  tool  (EDA)  known  as  the  “emotion 

Board”  has  helped  to  measure  skin  reaction  to  stress.  However,  SVM  and  LDA  help  to 

classify stress and show up to 82.8% result. 

Chen  et  al.  (2018)  monitored  heat  stroke  using  a  fuzzy  logic  technique  to  display  an 

inferential  signal  on  smart  devices.  The  design  of  wireless  communication  profoundly 

changed  patient’s  management  through  point-to-care  diagnostic  devices 

like  EMS 

(emergency medical service) used in emergency rooms & ICU. Some ICU systems revealed 

beyond  vital  signs  to  the  extent  of  detecting  patients'  posture/position,  toxic  gases,  and 

heat flux.    Winokur et  al. 2013[28] found  wearable devices valuable  for monitoring heart 

rate, recording ECG, 3D representation of Sternal Seismocardiogram (SCG). 

Da He et al. 2012 [27]  introduced ear device and wearable cardio-meter defibrillator WCD) 

to prevent arrhythmic sudden death of patients. Fryar et al. 2017(12) detect hypertension 

9 

 
with  physiological  signals  from  cerebral  blood  flow-meter  (CBF)  that  estimates 

hemodynamic cephalic symptoms in patients. 

Deep learning architectures, descriptions, and key points 

Deep  learning  networks  are  frameworks  for  classifying  or  regressing  data  which  have 

either hidden or visible output layers. Some have more than two hidden layers that allow 

the  expression  of  complex  or  non-linear  hypothesis.  Deep  neural  networks  have 

successfully  been used in bio-informatics but lack training  authentication due to its back-

propagated layers and slow learning process.  

Hinton  and  Salakhutdinov,  2006  [10]  discussed  deep  auto-encoder  designed  to  extract 

features  and  later  dimensional  reduction  with  its  input,  hidden,  and  output  layers.  Deep 

auto-encoder consists of similar input & output nodes, which help to recreate input vectors 

and handles unsupervised learning techniques. 

The  deep  auto-encoder  is  vital  for  labeling  data,  and  robust  representation  (Sparse- 

AutEU). However, it does need pre-training to undergo the full training process.  The deep 

belief network RBM composition has each sub-network hidden layers & visible layers with 

undirected  connections.  The  two  layers  permit  unsupervised  &  supervised  training 

networks to initialize network commands, inference tracing for handling sampling process, 

and training procedures. (Hinton et al. 2016)[10]. 

Salakhutdinov  and  Hinton,  2009  [11]  states  the  difference  between  deep  belief  network 

and  deep  Boltzmann  machine  network.  According  to  his  laid  emphasis,  Boltzmann  has 

conditional  independent  layers  that  are  undirected  but  uses  stochastic  algorithms  to 

maximize lower bounds, incorporate robust inference and ambiguous inputs. Boltzman  DL 

can  also  handle  complex  time  inference  that  is  higher  than  DBN;  while  optimizing  large 

dataset parameters. 

The  continual  progression  in  neural  networks  led  to  the  proposition  of  recurrent  neural 

networks  with  the  capacity  to  analyze  huge  data  streams,  memorize  sequential  events, 

model  time  dependencies,  and  process  natural  languages.  The  recurrent  neural  network 

faces  a  challenge  of  vanishing  exploding  gradients.  (Williams  and    Zipser,  1989)[13].  The 

10 

 
convolutional  neural  network  is  communicably  used  since  its  quite  compatible  with  2D 

data  and  transforms  filtered  input  to  3D  output  for  neuron  activations  (LeCun  et  al. 

1998)[14].  CNN  supports  Neuro-biological  modeling,  which  performs  visual  cortex  using 

flow neuron connections and many varied applications like Google Net & Clarifa. The main 

challenge in CNN is the hierarchical visual feature used to input large labeled datasets. The 

parallel  GPU  acceleration  offers  hardware  capacity  need  to  compute  DNN  on  clouds  and 

multi-core  processors.  The  recurrent  neural  network  comes  with  a  hidden  capacity  to 

analyze  several  data,  which  made  Bengio  et  al.  (1994)[61]  discuss  RNN  variation  called 

Long-Short  term  memory  unit  (LSTM).  LSTM  solves  gradient  vanishing  problems  using 

long-input sequences. 

LSTM can be used to exploit stored information, write and read information without errors 

during training. It’s compatible with RNN and shares the same weight whilst aiding natural 

language processing like modeling, speech recognition, and image description. 

Ackley  et  al.  1986  [16]  emphasized  on  the  variant  Boltzmann  machine  (RBM)  type  of  

stochastic  neural  networks  with  Gaussian  learning  procedures  called  GIBBS  sampling. 

GIBBS  sampling  adjusts  weights,  minimize  errors,  and  model  the  variable  relationship 

probability.  Wang  et  al  .  2016  [17]  reviewed  the  graphical  probability  model  with 

stochastic  units  and  characterize  the  conditional  independence  between  variables  and 

directed acyclic graph. 

Carreira and Hinton, 2005 [18]  mentioned the contrastive divergence algorithm (CD) used 

in  conjunction  with  RBM  to  handle  unsupervised  learning  algorithms.  It  has  positive  and 

negative  phases,  whereby  the  positive  phase  encourages  network  configuration  and  the 

negative phase recreates current network configurations. CNN has regular correlated local 

data with multi-dimensional input that can be significant in back-propagation, adjusting of 

number  parameters  that  support  the  neuro-biological  visual  cortex  model.  The  visual 

cortex in CNN has receptive local field maps that move granularity anterior image inputs to 

a convolved sub-sampled output through small filters (Hubel and Wiesel, 1962)[19]. 

11 

 
 
DNN learning architectures 

Deep  neural  network  architecture  known  as  input-output  deep  architecture  (IODA)  can 

resolve  different  image  labeling  issues  by  assigning  labels  to  each  image  pixel.    DNN 

services  both hyperspectral images, whereas spectral &  spatial features come together to 

form  hierarchical  models  that  characterize  human  body  issues.  Kondo  et  al.  2014[20] 

employed  a  group  method  of  data  handling  (GMDH)  with  a  hybrid  multi-layer  neural 

process  to  authenticate  polynomial  activated  functions.  The  essence  of  GMDH  is  to 

recognize liver and spleen data while performing principal component regression analysis. 

The same technique can be used to identify Cancer Mcyarduim, right, and left kidney issues. 

Application of deep neural network to translational bioinformatics 

Table 1 demonstrates software explored with CUBA/NVIDIA to aid GPU acceleration which 

Wolfram  Mathetica  and  Nervana  (2020)[74]  used  to  provide  cloud  training  process 

systems in combination with neuromorphic electronic system hardware. 

Most  computational  neuroscience  simulations  are  conducted  with  neurons  &  synapses 

chips,  integrated  into  hardware  like  (IBM)  true  north,  (Spinnaker),  and  Curie  (intel).  The 

main purpose of bioinformatics as a discipline is to explore, investigate, and understand the 

biological molecular level and its processes. Past human genome project (HGP) researched 

raw  data  to  develop  new  hypotheses  of  genes,  and  environmental  factors  related  to  the 

creation  of  human  genetic  proteins.  To  diagnose  diseases  using  biotechnology,  the  first 

human  genome  motivating  principle  is  “P4”  (personalized,  preventive,  participatory,  and 

predictive medicine) (Hood et al.2011)[22]. 

The  predictive  health  informatics  hold  attributes  for  encoding  DNA  of  the  living  beings 

while analyzes the alleles, environmental factors leading to diseases like cancer, and design 

targeted therapeutic procedures as a remedy. (Leung et al.2016)[23]. 

 The  concept  of  pharmacogenomics  is  focused  on  evaluating  varieties  of  drugs  &  its 

response  to  gene-related  treatment  for  aliments  especially  personalized  diagnosis  with 

fewer  side  effects.  Epigenomics  investigates  interactive  proteins  and  its  higher-level 

12 

 
processes, and response while transcriptome (mRNA), Proteome and Metabolome modify 

gene’s response to its environments. 

Genetic  variants  are  uniquely  designed  with  slicing  codes  that  predict  the  differences  in 

human tissues, especially how it  changes  as  a  result  of genetic variation.  The  alternate  of 

slicing  code  helps  to  technically  generate  gene  prediction  of  slicing  patterns  meant  to 

comprehend gene phenotypes and its drug effects on autism, spinal muscular atrophy, and 

hereditary cancer. (Leung et al.2016)[23]. 

A  quantitative  activity  structure  relationship  was  meant  to  predict  protein-protein 

coordinations  which  are  usually  structured  with  molecular  information,  compound 

interactive protein; for predicting proteins used for drug discovery. Compound interactive 

protein virtual analysis influenced the discovery of new compounds, toxic substances, and 

the interpretation of drugs related to targeted cells. 

In  health  informatics,  deep  learning  models  are  utilized  to  enhance  DNA  methylation  for 

providing  visible  outlooks  of  human  chromosomes.  It  can  be  used  to  identify  unstable 

chromosomes, error translation, cell transcription, differentiation, and cancer progression. 

(Angermueller et al.2016)[24]. 

Pastur-Romay et al. 2016 [25] named Chembl database in pharmacogenomics that detects 

millions  of  compounds  descriptions  used  to  develop  &  target  drug  evolutions,  since  the 

mentioned  database  encrypts  molecular  fingerprints,  and  understand  traditional  Ml 

approaches.  Chembl  database  also  helps  to  reduce  data  complexity  in  molecular  RNA  by 

binding predictive proteins together using RNA structural tertiary profiled outcome (Zhang 

et al. 2016)[49]. 

Fakoor et al. (2013)[1] utilized the autoencoder model to explore genetic data from diverse 

cancer  patients  to  identify  similar  microarrays  in  the  datasets.  Ibrahim  et  al.2014  [26] 

detailed  the  effect  of  active  learning  methods  using  DBN  to  feature  MicroRNA  for 

classifying  the  performance  of  different  cancer  diseases  like  hepatocellular  carcinoma. 

Deep learning approaches were adopted by Khadem et al. (2015)[28] to beat breast cancer 

disease  through  an  attribute  &  noise  combination  of  BDN  &  Bayesian  network  that  helps 

13 

 
the  extraction  of  micro-array  data.  Experts  considered  deep  learning  more  effective  than 

SVM  in  detecting  slicing  code  of  different  genetic  variants,  which  according  to 

Angermueller  et  al.  (2016)[24]  DNN  predicts  DNA  methylation  from  an  incomplete 

sequence  of  methylated  data.  It  also  predicts  embryonic  stem  cells  and  baseline 

comparison to show genome downstream demonstration. Deep learning was mentioned to 

have outpace conventional techniques, as Kernes et al. (2016) used graph convolutions to 

encrypt molecular features,  physical  properties, and  assay  activities  that  permit potential 

collaboration of molecular encoded information. 

Deep learning used for medical imaging procedure 

Experts  found  DL  relevant  in  diagnosing  illnesses  and  interpreting  medical  images.  The 

processes  are  conversantly  enabled  by  CAD  (computer-aided  diagnosis)  for  assimilating 

the  cause  of  diseases.  CAD  model  helps  to  identify  causes  of  neurological  Alzheimers, 

sclerosis, and stroke progression through brain scans, multi-modal mapping of the infected 

region. 

Over the years, convolutional neural network aids computer vision, especially the ability to 

personalize  GPU  to  show  parallel  brain  pathology  (Havaei  et  al.2016)[29].  It  further 

demonstrates  CAD  segmentation  and  shapes  the  analysis  of  the  human  brain.  CAD  has 

helped to overcome the challenges of difference in intensity & shapes of tumors and lesions 

using image protocols. Though, issues associated with CAD may include pathological tissue 

overlapping with healthy samples, RICIAN-Noise, non-Isotropic issues, and bias field effects 

evident  in  magnetic  resonance  images  (MRI).  Sometimes,  the  MRI  cannot  be  handled 

automatically by CAD but requires a similar ML approach to decrypt data complexity and 

extract features through conventional approaches (Greenspan et al.2016)[30]. 

CNN  as  a  deep  learning  approach  works  better  than  CAD  in  terms  of  data  manipulation, 

operating  patch  images  of  abnormal  tissues  (e.g.  CNNs  medical  imaging  for  lung  diseases 

coordinated  with  computed  tomography  image).  Experts  used  CNN  and  CT  imaging 

applications to classify the manifestation of tuberculosis, the cell of the  neural progenitor 

from somatic source, and hemorrhage color Fundus image detection. Yan et al (2016)[31] 

classified  different  anatomies  with  CT  to  understand  human  organ  recognition  using 

14 

 
multistaged  frameworks  to  extract  patches  of  pre-trained  stages.  Jamaluddin  et  al.2016 

seem  it  essential  to  use  CNN  for  the  segmentation  of  Isotense  brain  tissue  and  brain 

extraction through a multi-modality image tool.  Avendi et al. 2016[32] described how DL 

algorithms encode deformable model parameters and facilitate left ventricle segmentation 

necessary  for  short-axis  cardiac  imaging.  CNN  tools  have  2D  image  components  for 

segmenting  MRI  &  CT  in  3D  format,  to  eradicate  issues  found  in  anisotropic  voxel  sizing. 

CNN was adopted in orthogonal patch extraction to segment axis, sagittal, and corona view 

which reduces time and overfitting problems. (Fritscher et al.2016)[33]. 

Common  limitations  of  CNN  include  its  non-spatial  dependencies  and  the  need  for  pre-

processing to bring conditional random fields. These issues can be altered by substituting 

with  conventional  ML  approaches  to  solve  problems  of  incomplete  data  training,  limited 

annotated data, cost/time, and manual medical image annotations. 

Previously,  manual  annotation  was  accepted  to  help  the  detection  of  medical  images,  but 

crowdsourcing  according  to  (Greenspan  et  al.2016)[30]  is  a  viable  alternative  due  to  its 

affordability,  error-free  medical  image  analysis.    Havaei  et  al.  2016[29]  used  a  transfer 

learning and fine-tuning approach to alleviate incomplete training issues on CNN, allowing 

the  pre-trained  data  to  be  labeled  manually.  Tajbakhsh  et  al.  (2016)[53]  described  the 

similarity between natural images and medical images by using the fine-tuning process to 

repeat  the  same  experiment.  Shin  et  al.  (2016)[34]  applied  transfer  learning  to  natural 

images of a thorax-lymph node to detect lung disease and the result shows consistency in 

performance without losses. 

Chen  et  al  (2015)[35]    identified  fetal  abdominal  standards  with  a  transfer  learning 

approach  to  display  low-layer  CNN  pre-training  effects  on  natural  images  while 

implementing  multi-tasking  to  handle  the  CAD  image  imbalance.  Cheng  et  al.2016[36] 

utilized  denoising  autoencoder  to  diagnose  breast  legions  and  pulmonary  nodules  in  CT 

scans.  Shan  et  al.  (2016)  [37]tried  Stack  Sparse  Autoencoder  on  Microaneurysms  Fundus 

images  to  detect  diabetic  retinopathy  whilst  uses  Softmax  Output  Layer  to  show 

Alzheimer's disease prediction with functional magnetic resonance images (fMRI). Li et al. 

(2015)[38]  used  the  RBM  method  to  effect  biomarkers  from  MRI  and  position  emission 

15 

 
tomography  (PET  SCAN)  and  the  result  of  the  scan  shows  6%  accuracy.  Kuang  et  al. 

(2014)[39]  discriminate  attention  deficit  hyperactivity  disorder  with  the  same  FMRI 

application. 

Hence,  experts  extracted  RBM  latent  hierarchical  3D  patch  features  from  the  brain  using 

image segmented tools and Brosch et al. (2013)[40] implored manifold learning method to 

study 3D brain images, its full automated shape, and cranial nerves. Deep learning methods 

are  known  to  outpace  conventional  approach  through  low-contact  optic  tracts  and  other 

human  pathological  anatomies.  Beaulieu-Jones  et  al.  2018  [60]  found  pipeline  models 

relevant  in  detecting  &  segmenting  objects  to  achieve  an  automatic  volumetric  image 

process  called  marginal  space  DL.  MSDL  handled  hierarchical  marginal  spacing  with 

automatic features to detect deep learning datasets. 

Literature review 

Unsupervised learning techniques are characterized by an unlabeled dataset using metrics 

of low-high dimensional subspace anomalies for detecting clusters of data. (E.g. Prediction 

of heart & hepatitis diseases). Collins and Yao, 2018 [43] defined prognosis as the method 

of predicting disease with clinical practice settings whilst showing multi-modal data. Wang 

et  al.  2012  [44]  use  prognosis  to  diagnose  diabetics  registered  in  electronic  health  data 

records.  Medical  image  analysis  follows  enhancement,  detection,  classification,  and 

segmentation procedure to reconstruct and store data. Chen et al. 2017 [45]  implemented 

the  reconstruction  of  MRI  and  CT  image  datasets  using  generative  adversarial  networks 

(GANS). 

The  generative  adversarial  network  (GAN)  offers  MRI  reconstruction  by  cleaning  motion 

pictures,  artifacts,  and  handling  image  fusion  &  registration.  El-Gamal  et  al.  (2016)[46] 

noted the significance of image registration in surgical spine implant, tumor removal, and 

neuro-surgical  process.  56  developed  an  image  registration  framework  called  “Quick-

Silver”, for large deformation mapping and diffeomorphic metric prediction. Before image 

registration,  data  retrieval  enables  physicians  to  check  the  large  images  of  patients' 

repeated  visits  to  the  clinic.  Zech  et  al.  2018  [47]  shared  natural  language  processing 

methods for annotating retrieved images from clinical radiological reports. 

16 

 
To achieve real-time health monitoring with DL wearables, IOT sensors, and smart devices, 

DL  clouds  must  be  integrated  into  smart  devices  to  attain  the  required  results.  DL  had 

found its place in clinical workflows for predicting & diagnosing diabetes, dengue, heart & 

liver  diseases,  whereby  IBM  advanced  CAD  system  to  CADX  that  displays  automatically 

fatty liver in Kurtosis image (MA et al. 2016)[48]. 

Zhang, 2019 [49] utilized clinical reinforcement learning to study the optimal diagnosis and 

treat patients by characterizing its performance evaluation with different methods (Q value 

iteration, tabular learning, Q-iteration, and deep Q-learning). The RL method helps to treat 

sepsis  in  intensive  care  units.  The  same  clinical  time-series  data  were  studied  to  provide 

medical intervention to patients in intensive care units by using CNN and LSTM to predict 

traumatic  brain  damage,  estimate  the  mean-variance  of  arterial  blood  pressure  and 

intracranial pressure monitoring (Rau, 2018) [50]. 

Recently,  experts  have  adopted  Attention  Models  to  forecast  ICU  activities,  integrate 

multivariance time-series measurement, and controlling unexpected respiratory issues. To 

control  NIP  challenges,  Neveol,  2018[52]  used  the  CLAMP  Toolkit  to  monitor  different 

states of clinical text analysis of language acronyms, disparity, and quality variance. Several 

doctors studied clinical documentation, especially on how to use clinical speech and audio 

processing to minimize time spent on administrative tasks and medical reports. (Wallace, 

2019)[51].  Speech  and  audio  processing  serve  the  purpose  of  identifying  disorders  using 

vocal hyper-functional tools to review patients with dementia and Alzheimers. 

Limitations 

Privacy  and  security  challenges  are  primary  limitations  discovered  in  deep  learning 

algorithms. The issue of data collection vulnerabilities is experienced during DL adoption of 

large datasets which also consumes time and human efforts.  The problem of incorrect or 

altered  datasets  can  lead  to  wrong  diagnoses.  Latif  et  al.  2018  [54]  disclosed  that 

instrumental  and  environmental  noise  from  smart  machines  can  cause  an  unnecessary 

disturbance, especially MRI multi-shots, high sensitive modal-motion, and an increased risk 

of mis-diagnosis due to mistakes in artifacts; can be detrimental to human health. 

17 

 
Unqualified  physicians  without  knowledge  of  data  analytics  can  commit  unforgivable 

errors  in  medical  diagnosis.  Caruana  et  al.  2015  [55]  explained  the  difficulties  in  data 

labeling and  annotation while  86 lamented  about  ambiguous  medical  image classification 

which  may  lead  to  confusion  and  disagreement  between  physicians.  Xia  et  al.  2012  [56] 

indicate that the use of inappropriate algorithms can be detrimental and life-threatening; if 

improper  annotation  happens  while  suggesting  the  use  of  meticulous  approaches  in  the 

labeling  of  datasets  to  limit  inefficiencies.  Due  to  limited  or  imbalance  datasets,  wrong 

diagnoses  can  cause  death  of  millions,  and  missing  data  sparsity  values  can  lead  to 

unmeasured or repetition in taking samples. Biggio et al. 2012 [57] viewed model training 

vulnerabilities,  as  improper  training  or  incomplete  breach  of  privacy  causing  model 

poisoning and data theft. To corrupt an already collected data is known as “data poisoning” 

which  requires  security,  especially  during  digital  forensics    &  bio-metrics.  In  case  of 

compromise during deep learning deployment, realistic healthcare settings will experience 

distribution shifts, leading to incomplete data vulnerability in the testing phase.   

Security and recommendations 

Numerous  security  threats,  influence  &  violations  are  associated  with  DL  algorithms, 

constituting  to  integrity  attack,  and  other  vulnerabilities.  Such  an  act  can  destroy  the 

progress  of  DL  in  health  and  other  fields  of  science.  Usama  et  al.  2019[58]  mentioned 

adversarial machine learning vulnerabilities inserted in input samples to evade privacy and 

data integrity.  

A data breach can cause modal poisoning & privacy evasion; whereby clinical deep learning 

applications are constantly under an attack. However, safety, privacy, ethical regulations &  

policy are being reinstalled to ensure the quality of data exchange standards. 

David et al. (2015)[59] recommends hyper-plane commodity data cryptography to control 

data breach in naïve Bayes classifiers. Zhu et al. (2018)[66] suggest the use of polynomial 

aggregation and random masking protect SVM with non-linear kernel algorithms.  

Jagieiski  et  al.  (2018)  indicate  that  data  privacy  can  be  reassured  with  a  TRIM  tool  to 

protect  linear  creations.  Lui  et  al.  Ascertained  that  DL  frameworks  can  be  secured  with 

18 

 
XMPP  serve  while  Malalhi  et  al  (2019[68]  named  Paillier  homomorphic  encryption  for 

security Naïve Bayes, SVM neural network and FKnn-CBR used to rescue liver patients in 

India hospitals. Takabi et al. (2016)[69] suggest homomorphic encryption for deep neural 

networks  that  control  more  than  15  datasets  in  repositories.  To  guarantee  the  safety  of 

logistic regression, Kim et al. (2018) [70] recommends homomorphic encryption to secure 

medical  binary  datasets.    To  update  healthcare  infrastructure,  Finlayson  et  al.  2019  [71] 

suggest  the  use  of  the  international  classification  of  disease  system  which  helps  to 

minimize dataset vulnerabilities. However, privacy can be preserved with a cryptographic 

approach, homomorphic encryption, garbled  circuiting, and secured  processors.  The Intel 

SGX processor offers confidentiality and authorized access to systems like K-mean, decision 

trees, and SVM (Ohrimenko et al. 2016)[72].  Google Inc added federated learning method 

to distribute data, decentralize scheme and predict heart-related diseases. McMahan et al. 

2017 [73]. 

To control adversarial attacks, it's important to modify models using defensive distillation, 

network verification, gradient regularization, and classifier robustification. 

Conclusion 

Deep learning and health informatics algorithms will continually expand to other branches 

of science, as wearable smart monitoring devices are presently used to track and diagnose 

Parkinson's  diseases.  Google  Glass  conducted  prototype  child  therapeutic  analysis  to 

monitor  and  diagnose  autism  spectrum  disorder.  To  preserve  mental  health,  psychiatric 

hospitals  are  screened,  diagnosing,  and  monitoring  depression  with  a  system-on-chip 

solution that accelerates filters, and reveals heart rates on ECG. Smart monitoring devices 

are unique, compatible, embedded with DL, and simple to operate. However, aging adults 

may find it challenging. 

The  future  of  DL  and  health  informatics  depends  on  the  recent  5G  wireless  network, 

proposed to bring about new devices for  testing red protein (Hemoglobin); especially for 

transporting  oxygen  to  the  blood.  The  accuracy  of  clinical  results  can  be  validated  with  a 

cross-validation approach to unravel the results.  

19 

 
Reference 

1.  Fakoor,  R.,  Ladhak,  F.,  Nazi,  A.,  Huber,  M.  :  Using  deep  learning  to  enhance  cancer 

diagnosis and classiﬁcation,” in Proc. ICML, (2013). 

2.  Ngiam,  J.,  Coates,    A.,  Lahiri,  A.,  Prochnow,  B.  Q.,  Le,    V.,  Ng,  A.  Y.  :On  optimization 

methods for deep learning,” in Proc. ICML, (2011),pp. 265–272. 

3.  McClelland,  J.  L.,  Rumelhart,  D.  E.  :Parallel  distributed  processing.  MIT  Press 

Cambridge, MA, (1987), vol. 2. 

4.  Rumelhart,  D.  E.,    Hinton,  G.  E.,  Williams,  R.  J.  :Neurocomputing:  Foundations  of 
research,”  J.  A.  Anderson  and  E.  Rosenfeld,  Eds.Cambridge,  MA,  USA:  MIT  Press, 
(1988), ch. Learning Representations by Back-propagating Errors, pp. 696–699. 

5.  Rose, D. C., Arel, I., Karnowski, T. P., Paquet, V. C.: Applying deep-layered clustering 

to mammography image analytics,” in BSEC, (2010), pp. 1–4. 

6.  Johnson, A. E. W.,  Ghassemi, M. M., Nemati, S., Niehaus, K. E., Clifton, D. A., Clifford, G. 
D. :Machine learning and decision support in critical care,” Proceedings of the IEEE, 
vol. 104, no. 2, pp. 444–466, Feb (2016). 

7.  Pouladzadeh,  P.,    Kuhad,  S.  V.  B.,  Peddi,  A.,  Shir-Mohammadi,  S.  :Food  calorie 

measurement using deep learning neural network,” in I2MTC, (2016), pp. 1–6. 

8.  Huang, J., Zhou, W., Li, H., Li, W.: Sign language recognition using real-sense,” in IEEE 

ChinaSIP, (2015), pp. 166–170. 

9.  Yalcin¸  H.  :Human  activity  recognition  using  deep  belief  networks,”  in,  (2016),  pp. 

1649–1652. 

10. Hinton, G. E., Salakhutdinov, R. R.: Reducing the dimensionality of data with neural 

networks,” Science, vol. 313, no. 5786, pp. 504–507,(2006). 

11. Hinton, G. E., Osindero, S., Teh, Y.W.: A fast learning algorithm for deep belief nets,” 

Neural Comput., vol. 18, no. 7, pp. 1527–1554 (2006). 

12. Fryar,  C.  D.,  Ostchega,  Y.,  Hales,  C.  M.,  Zhang,  G.,  &  Kruszon-Moran,  D.  (2017). 
Hypertension  Prevalence  and  Control  Among  Adults:  United  States,  2015-2016. 
NCHS Data Brief (289), 1-8. 

13. Williams,  R.  J.,  Zipser,  D.:  A  learning  algorithm  for  continually  running  fully 
recurrent neural networks,” Neural Comput., vol. 1, no. 2, pp. 270–280, (1989). 

20 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
14. LeCun,  Y.,  Bottou,  L.,  Bengio,  Y.,  Haffner,  P.  :Gradient-based  learning  applied  to 
document  recognition,”  Proceedings  of  the  IEEE,  vol.  86,  no.  11,  pp.  2278–2324, 
(1998). 

15. Bengio, Y., Simard, P., Frasconi, P.: Learning long-term dependencies with gradient 
descent are difﬁcult,” IEEE Trans. Neural Netw., vol. 5, no. 2, pp. 157–166, (1994). 

16. Ackley,  D.,  Hinton,  G.,  Sejnowski,  T.:  Learning  and  relearning  in  Boltzmann 
machines,”  Parallel  Distributed  Processing:  Explorations  microstructure  of 
Cognition, (1986). 

17. Wang, H., Yeung, D.Y.: Towards Bayesian Deep Learning: A Survey,” ArXiv  e-prints, 

Apr. 2016. 

18. Carreira-Perpignan,  M.  A.,  Hinton,  G.    :On  contrastive  divergence  learning.”  in 

AISTATS, vol. 10, (2005), pp. 33–40. 

19. Hubel  D.  H.,  Wiesel,  T.  N.:  Receptive  ﬁelds,  binocular  interaction  and  functional 
architecture in the cat’s visual cortex,” The Journal of physiology, vol. 160, no. 1, pp. 
106–154, (1962). 

20. Kondo, T., Ueno, J., Takao, S.: Medical image recognition of abdominal multi-organ by 
hybrid  multi-layered  gmdh-type  neural  network  using  principal  component-
regression analysis,” in CALENDAR,(2014), pp. 157–163. 

21. Szegedy, C., Zaremba, W., Sutskever, I.,  Bruna, J.,  Erhan, D.,  Good fellow, I. J., Fergus, 
R. :Intriguing properties of neural networks.”CoRR, vol. abs/1312.6199, (2013). 

22. Hood, L., Friend, S. H.: Predictive, personalized, preventive, participatory (p4) cancer 
medicine,” Nature Reviews Clinical Oncology, vol. 8, no. 3, pp. 184–187, (2011). 

23. Leung,  M.  K.,  Delong,  A.,  Alipanahi,  B.,  Frey,  B.  J.:  Machine  learning  in  genomic 
medicine:  A  review  of  computational  problems  and  data  sets,”  Proceedings  of  the 
IEEE, vol. 104, no. 1, pp. 176–197,(2016). 

24. Angermueller, C., Parnamaa, T., Parts, L., Stegle, O.: Deep learning for computational 

biology,” Molecular Systems Biology, vol. 12, no. 7, p. 878, (2016). 

25. Pastur-Romay, L.  A., Cedar, F. A.,  Pazos,  A.,  Porto-Pazos, B. :Deep artiﬁcial neural 
networks  and  neuro  morphic  chips  for  big  data  analysis:  Pharmaceutical  and 
bioinformatics applications,” International Journal of Molecular Sciences, vol. 17, no. 
8, p. 1313, (2016). 

26. Ibrahim,  R.,    Yousri,  N.  A.,    Ismail,  M.  A.,  El-Makky,    N.  M.  :Multi-level  gene/miRNA 
feature  selection  using  deep  belief  nets  and  active  learning,”  in  EMBC,  (2014),  pp. 
3957–3960. 

21 

 
 
 
 
 
 
 
 
 
 
 
 
 
27. Da  He,  D.,  Winokur,  E.  S.,  &  Sodini,  C.  G.  (2012).  An  ear-worn  continuous 
ballistocardiogram (BCG) sensor for cardiovascular monitoring. Paper presented at 
the Engineering in Medicine and Biology Society (EMBC), 2012 Annual International 
Conference of the IEEE. 

28. Winokur, E. S., Delano, M. K., & Sodini, C. G. (2013). A wearable cardiac monitor for 
long-term  data  acquisition  and  analysis.  IEEE  Transactions  on  Biomedical 
Engineering, 60(1), 189-192. 

29. Havaei, M., Guizard, N., Larochelle, H., Jodoin, P.: Deep learning trends for focal brain 

pathology segmentation in MRI,” CoRR, vol.abs/1607.05258, (2016). 

30. Greenspan,  H.,Van  Ginneken,  B.,  Summers,  R.  M.  :Guest  editorial  deep  learning  in 
medical imaging: Overview and future promise of an exciting new technique,” IEEE 
Trans. Med. Imag., vol. 35, no. 5, pp.1153–1159, May (2016). 

31. Yan, Z., Zhan, Y.,  Peng, Z., Liao, S., Shinagawa, Y., Zhang, S.,  Metaxas, D. N., Zhou, X. S. 
:Multi-instance deep learning: Discover discriminative local anatomies for body part 
recognition,” IEEE Trans.Med. Image, vol. 35, no. 5, pp. 1332–1343, (2016). 

32. Avendi, M., Kheradvar, A., Jafarkhani, H.: A combined deep-learning and deformable-
model approach to fully automatic segmentation of the left ventricle in cardiac MRI,” 
Medical image analysis, vol. 30, pp. 108–119, (2016). 

33. Fritscher,  K.,    Raudaschl,  P.,  Zafﬁno,    P.,    Spadea,  M.  F.,    Sharp,  G.  C.,  Schubert,    R. 
:Deep  neural  networks  for  fast  segmentation  of  3dmedical  images,”  in  MICCAI, 
(2016), pp. 158–165. 

34. Shin,  H.C.,    Roth,  H.  R.,  Gao,    M.,    Lu,  L.,    Xu,  I.,    Nogues,  J.,    Yao,  D.,    Mollura,  R., 
Summers,  M.  :Deep  convolutional  neural  networks  for  computer-aided  detection: 
Cnn  architectures,  dataset characteristics, and transfer learning,” IEEE  Trans.  Med. 
Imag., vol. 35, no. 5, pp.1285–1298, (2016). 

35. Chen, H., Ni, D., Qin, J., Li, S., Wang, X. T., Heng, P. A.: Standard plane localization in 
fetal  ultrasound  via  domain  transferred  deep  neural  networks,”  IEEE  J.  Biomed. 
Health Inform. vol. 19, no. 5, pp. 1627–1636, (2015). 

36. Cheng, Z., Ni, D., Chou, Y.H., Qin, J. C., Tiu, M., Chang, Y.C., Huang, C. S., Shen, D., Chen, 
C.  M.:  Computer-aided  diagnosis  with  deep  learning  architecture:  Applications  to 
breast lesions in our images and pulmonary nodules in ct scans,” Scientiﬁc reports, 
vol. 6, (2016). 

37. Shan,  J.,  Li,  L.:  A  deep  learning  method  for  micro-aneurysm  detection  in  fundus 

images,” in IEEE CHASE, (2016), pp. 357–358. 

22 

 
 
 
 
 
 
 
 
 
 
 
 
 
38. Li, F., Tran, L., Thung, K. H., Ji, S., Shen, D., Li, J.: A robust deep model for improved 
classiﬁcation of ad/MCI patients,” IEEE J. Biomed. Health Inform. vol. 19, no. 5, pp. 
1610–1616, Sept (2015). 

39. Kuang, D., He, L.: Classiﬁcation on ADHD with deep learning,” in CCBD, Nov 2014, pp. 

27–32. 

40. Brosch, T., Tam, R., Initiative et al., A. D. N.: Manifold learning of brain MRIs by deep 

learning,” in MICCAI, 2013, pp. 633–640. 

41. Sun, W., Shao, S., Zhao, R., Yan, R., Zhang, X., Chen, X.: A sparse auto-encoder-based 
faults  classification,” 

induction  motor 

deep  neural  network  approach 
Measurement, vol. 89, pp. 171–178, (2016). 

for 

42. Lu, C., Wang, Z. Y., Qin, W.L., Ma, J.: Fault diagnosis of rotary machinery components 
using  a  stacked  denoising  auto  encoder-based  health  state  identification,”  Signal 
Processing, vol. 130, pp. 377–388, (2017). 

43. Collins,  A.,  Yao,  Y.:  Machine  learning  approaches:  Data  integration  for  disease 
prediction  and  prognosis,”  in  Applied  Computational  Genomics.  Springer,  (2018), 
pp. 137–141. 

44. Wang,  Z.,  Shah,  A.  D.,    Tate,  A.  R.,    Denaxas,  S.,    Shawe-Taylor,  J.,    Hemingway,  H. 
:Extracting diagnoses and investigation results from unstructured text in electronic 
health records by semi-sup (2012) 

45. Chen, H., Zhang, Y., Kalra, M. K.,  Lin, F.,  Chen, Y.,  Liao, P.,  Zhou, J., Wang, G. : Low-
dose  ct  with  a  residual  encoder-decoder  convolutional  neural  network,”  IEEE 
transactions on medical imaging, vol. 36no. 12, pp. 2524–2535, (2017). 

46. El-Gamal,  F.  E.,  Elmogy,  A.  M.,  Atwan,  A.:  Current  trends  in  medical  image 
registration  and  fusion,”  Egyptian  Informatics  Journal  vol.  17,  no.  1,  pp.  99–124, 
(2016). 

47. Zech, J.,  Pain, M.,  Titano, J., Badgeley,  M.,  Schefflein, J., Su,  A., Costa,  A.,  Bederson, 
J., Lehar, J., Oermann, E. K. :Natural language-based machine learning models for the 
annotation  of  clinical  radiology  reports,”  Radiology,  vol.  287,  no.  2,  pp.  570–580, 
(2018). 

48. Ma, H.Y., Zhou, Z., Wu, S., Wan, Y.L., Tsui, P.H. :A computer-aided diagnosis scheme 
for detection of fatty liver in vivo based on ultrasound kurtosis imaging,” Journal of 
medical systems, vol. 40, no. 1,p. 33, (2016). 

23 

 
 
 
 
 
 
 
 
 
 
 
 
49. Zhang, Z., et al.  : Reinforcement learning in clinical medicine: a method to optimize 
dynamic  treatment  regime  over  time,”  Annals  of  translational  medicine,  vol.  7,  no. 
14, 2019. 

50. Rau,  C.S.,  Kuo,  P.  J.,  Chien,  P.C.,  Huang,  C.Y.,  Hsieh,  H.Y.,  Hsieh,  C.H.  :Mortality 
prediction  in  patients  with  isolated  moderate  and  severe  traumatic  brain  injury 
using machine learning models,” PloS one, vol. 13, no. 11, p. e0207192, (2018). 

51. Wallace,  D.  S.:  The  role  of  speech  recognition  in  clinical  documentation,”  Nuance 
Available: 
on 

Communications, 
https://www.hisa.org.au/slides/hic18/wed/SimonWallace.pdf 

14-Dec2019. 

[Online]. 

access 

2018, 

52. Neveol,  A.,  Dalianis,  H.,  Velupillai,  S.,  Savova,  G.,  Zweigenbaum,  P.  :Clinical  natural 
language processing in languages other than English: opportunities and challenges,” 
Journal of biomedical semantics, vol. 9, no. 1, p. 12, (2018). 

53. Tajbakhsh, N., Shin, J. Y., Gurudu, S. R., Hurst, R. T., Kendall, C. B., Gotway, M. B., Liang, 
J.:  Convolutional  neural  networks  for  medical  image  analysis:  Full  training  or  ﬁne 
tuning?” IEEE Trans.Med. Imag., vol. 35, no. 5, pp. 1299–1312, 2016. 

54. Latif,  S., Asim, M.,  Usman, M.,  Qadir,  J., Rana,  R. :Automating motion  correction in 
multishot  MRI  using  generative  adversarial  networks,”  Published  as  Workshop 
Paper at 32nd Conference on Neural Information Processing Systems (NIPS 2018). 

55. Caruana, R., Lou, Y., Gehrke,  J., Koch, P., Sturm,  M., Elhadad, N. :Intelligible models 
for  healthcare:  Predicting  pneumonia  risk  and  hospital  30-day  readmission,”  in 
Proceedings  of  the  21st  ACM  SIGKDD  International  Conference  on  Knowledge 
Discovery and Data Mining. ACM, (2015), pp. 1721–1730. 

56. Xia, F., Yetisgen-Yildiz, M. :Clinical corpus annotation: challenges and strategies,” in 
Proceedings  of  the  Third  Workshop  on  Building  and  Evaluating  Resources  for 
Biomedical  Text  Mining  (BioTxtM’2012)  in  conjunction  with  the  International 
Conference  on  Language  Resources  and  Evaluation  (LREC),  Istanbul,  Turkey, 
(2012). 

57. Biggio, B., Nelson, B., Laskov, P. :Poisoning attacks against support vector machines,” 
in 29th International Conference on Machine Learning, (2012), pp. 1807–1814. 

58. Usama,  M.,  Qadir,    J.,  Al-Fuqaha,    A.,  Hamdi,  M.  :The  adversarial  machine  learning 
conundrum:  Can  the  insecurity  of  ml  become  the  Achilles’  heel  of  cognitive 
networks?” arXiv preprint arXiv:1906.00679, (2019). 

59. David, B.,  Dowsley, R.,  Katti, R., Nascimento, A. C. :Efficient unconditionally secure 
comparison  and  privacy-preserving  machine  learning  classification  protocols,”  in 
International Conference on Provable Security. Springer, (2015), pp. 354–367. 

24 

 
 
 
 
 
 
 
 
 
 
 
60. Beaulieu-Jones,  B.  K.,  Yuan,  W.,  Finlayson,  S.  G.,  Wu,    Z.  S.  :Privacy-preserving 
distributed  deep  learning  for  clinical  data,”  Machine  Learning  for  Health  (ML4H) 
Workshop at NeurIPS, (2018). 

61. Bengio, Y.,  Lamblin, P.,  Popovici, D.,  Larochelle et al., H. :Greedy layer-wise training 
of  deep  networks,”  Advances  in  neural  information  processing  systems,  vol.  19,  p. 
153, (2007). 

62. Vincent,  P.,  Larochelle,  H.,  Bengio,  Y.,    Manzagol,  P.A.  :Extracting  and  composing 
robust  features  with  denoising  autoencoders,”  in  Proceedings  of  the  25th 
international conference on Machine learning. ACM, (2008), pp. 1096–1103. 

63. Schmidhuber, J. :Deep learning in neural networks: An overview,” Neural Networks, 
vol.  61,  pp.  85–117,  (2015),  published  online  2014;  based  on  TR  arXiv:1404.7828 
[cs.NE]. 

64. Jaeger,  H.  :Tutorial  on  training  recurrent  neural  networks,  covering  BPPT,  RTRL, 
EKF  and  the”  echo  state  network”  approach.  GMD  For  schungszentrum 
Informationstechnik, 2002. 

65. Chung,  J.,    Gulcehre,  C.,  Cho,    K.,  Bengio,Y.  :Empirical  evaluation  of  gated  recurrent 
neural networks on sequence modeling,” arXiv preprint ar X iv:1412.3555, (2014). 

66. Zhu,  W., Liu, C., Fan, W.,  Xie,  X.  :Deep 3d dual-path  nets for  automated  pulmonary 
in  2018  IEEE  Winter  Conference  on 

nodule  detection  and  classification,” 
Applications of Computer Vision (WACV). IEEE, (2018), pp. 673–681. 

67. Jagielski,  M.,    Oprea,  A.,  Biggio,    B.,  Liu,  C.,  Nita-Rotaru,  C.,  Li,  B.  :Manipulating 
machine learning: Poisoning Attacks and countermeasures for regression learning,” 
in 2018 IEEE Symposium on Security and Privacy (SP). IEEE, (2018), pp. 19–35. 

68. Malathi,  D.,    Logesh,  R.,  Subramaniyaswamy,  V.,    Vijayakumar,  V.,    Sangaiah,  A. 
:Hybrid  reasoning-based  privacy-aware  disease  prediction  support  system,” 
Computers & Electrical Engineering, vol. 73, pp. 114–127, (2019). 

69. Takabi,  H.,  Hesamifard,  E.,    Ghasemi,  M.  :Privacy-preserving  multiparty  machine 
learning  with  homomorphic  encryption,”  in  29th  Annual  Conference  on  Neural 
Information Processing Systems (NIPS), 2016. 

70. Kim,  M.,    Song,  Y.,    Wang,  S.,  Xia,  Y.,    Jiang,  X.  :Secure  logistic  regression  based  on 
homomorphic encryption: Design and evaluation,” JMIR medical informatics, vol. 6, 
no. 2, p. e19, (2018). 

71. Finlayson,  S.  G.,  Bowers,    J.  D.,  Ito,      J.  J.,  Zittrain,    L.,  Beam,  A.  L.,  Kohane,  I.  S. 
:Adversarial  attacks  on  medical  machine  learning,”  Science,  vol.  363,  no.  6433,  pp. 
1287–1289, (2019). 

25 

 
 
 
 
 
 
 
 
 
 
 
 
72. Ohrimenko, O.,  Schuster, F.,  Fournet, C., Mehta, A., Nowozin, S., Vaswani,  K, Costa, 
M. :Oblivious multi-party machine learning on trusted processors,” in 25th USENIX 
Security Symposium (USENIX Security 16), (2016), pp. 619–636. 

73. McMahan, H. B.,  Moore, E.,  Ramage, D., Hampson et al., S. :Communication-efficient 
learning  of  deep  networks  from  decentralized  data,”  Proceedings  of  the  20  the 
International  Conference  on  Artificial  Intelligence  and  Statistics  (AISTATS)  JMLR: 
W&CP volume54, (2017). 

74. Nervana 

Systems, 
Available:https://github.com/NervanaSystems/neon (2020). 

“Neon,” 

[Online]. 

75. Choi,  Y.,  Jeon,  Y.-M.,  Wang,  L.,  &  Kim,  K.  (2017).  A  Biological  Signal-Based  Stress 
Monitoring Framework for Children Using Wearable Devices. Sensors, 17(9), 1936. 
76. Choo, D., Dettman, S., Dowell, R., & Cowan, R. (2017). Talking to Toddlers: Drawing 
on  Mothers'  Perceptions  of  Using  Wearable  and  Mobile  Technology  in  the  Home. 
Studies in health technology and informatics, 239, 21-27. 

77. Chen,  S.-T.,  Lin,  S.-S.,  Lan,  C.-W., &  Hsu,  H.-Y. (2018).  Design  and  Development  of  a 

Wearable Device for Heat Stroke Detection. Sensors, 18(1), 17. 

78. Ravì,  D.,  Wong,  C.,  Deligianni,  F.,  Berthelot,  M.,  Andreu-Perez,  J.,    Lo,  B.,    Yang,  G. 
:Deep  Learning  for  Health  Informatics.  IEEE  journal  of  biomedical  and  health 
informatics. PP. 10.1109/JBHI.2016.2636665 (2016). 

79. Rui, Z., Ruqiang,  Y., Zhenghua, C., Kezhi M.,  Peng,  W., Robert,G. :Deep Learning and 

Its Applications to Machine; Health Monitoring: A Survey 
JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST (2015) 

26 

 
 
 
 
 
","Deep Learning and Health Informatics for Smart Monitoring and Diagnosis Amin Gasmi 30 Octobre 2020 Abstract The connection between the design and delivery of health care services using information technology is known as health informatics. It involves data usage, validation, and transfer of an integrated medical analysis using neural networks of multi-layer deep learning techniques to analyze complex data. For instance, Google incorporated “DeepMind” health mobile tool that integrates & leverage medical data needed to enhance professional healthcare delivery to patients. Moorfield Eye Hospital London introduced DeepMind Research Algorithms with dozens of retinal scans attributes while DeepMind UCL handled the identification of cancerous tissues using CT & MRI Scan tools. Atomise analyzed drugs and chemicals with Deep Learning Neural Networks to identify accurate pre-clinical prescriptions. Health informatics makes medical care intelligent, interactive, cost-effective, and accessible; especially with DL application tools for detecting the actual cause of diseases. The extensive use of neural network tools leads to the expansion of different medical disciplines which mitigates data complexity and enhances 3-4D overlap images using target point label data detectors that support data augmentation, un-semi-supervised learning, multi-modality and transfer learning architecture. Health science over the years focused on artificial intelligence tools for care delivery, chronic care management, prevention/wellness, clinical supports, and diagnosis. The outcome of their research leads to cardiac arrest diagnosis through Heart Signal Computer-Aided Diagnostic tool (CADX) and other multi- functional deep learning techniques that offer care, diagnosis & treatment. Health informatics provides monitored outcomes of human body organs through medical images that classify interstitial lung disease, detects image nodules for reconstruction & tumor segmentation. The emergent medical research applications gave rise to clinical-pathological human-level performing tools for handling Radiological, Ophthalmological, and Dental diagnosis. This research will evaluate methodologies, Deep learning architectures, approaches, bio-informatics, specified function requirements, monitoring tools, ANN (artificial neural network), data labeling & annotation algorithms that control data validation, modeling, and diagnosis of different diseases using smart monitoring health informatics applications. Keywords: Health Informatics Diagnosis, DL Smart Monitoring App, DL/ML Health Informatics, Deep Learning Algorithms, Health Informatics Devices. 1 Introduction The fundamental use of deep learning in neural networks commenced as a result of experts study of complex neurons, layers, and its architectural paradigms. This study allowed to monitor data, its extended layer pipeline, and non-linear outputs generated from low- dimensional input space projection. Health informatics involve the generation of an automatic character set of human cells with expert intrusions. Medical imaging in health informatics can be elaborated to determine implicit internal organs like fibroids and polyps tissue irregularities. It can also be used to study morphological tumors (Fakoor et al.2013)[1] Biologically, health informatics have anticipated translational features utilized for nucleotide DNA & RNA sequential protein strands. Convolutional neural nets (CNNs) as a deep learning approach in health informatics have architectural layers and filters for reducing, rectifying, and modifying poohing layers. The layers help to originate abstract features found in the visual cortex and receptive fields while other architectures like restructured Boltzmann machines, deep belief networks DBNs, stacked autoencoders, extended network and recurrent neural nets (RNNs); assist the advancement of graphical process units (GPUs) that impact the growth of deep learning applications. Experts previously proposed pre-GPU and CNNs as parallel algebraic operations with matrixes needed for experiments in clinics. To integrate deep learning architectures in health informatics, its essential to label data and implement activation functions known as “transfer functions and weights”. The transfer function must classify linear patterns to adjust the weights. McClelland et a. 1987 [3] proposed neural networks with hidden layers of perceptrons, stages, and epochs for new data input samples & weights with neurons adjustable based learning process, named “Delta Rule”. The rule aids neural network training, exploitation, and backpropagation routines. Rumelhart et al.1988 [4] observed the random values given to the network weights to determine it’s iterative training processes and minimize the difference between network outputs and desired outcomes. Rumelhart et al.1988 [4] also furthered the study of iterative training using gradient descent techniques to reduce surface errors in the 2 experiment. Deep learning accelerates supervised and un-supervised labeled data, whereby supervised labeled data train deep neural network to understand its weight, minimize errors, and predict the targeted value for classifying the unsupervised labeled data. Meanwhile, unsupervised deep learning data are utilized for clustering, reduction of dimension and featured extraction (Ngiam et al.2011)[2]. Artificial Neural network and its variants Four deep learning architectures such as Auto-encoder, RBM, CNN, and RNN are mentioned to assist health informatics prediction and diagnosis. The autoencoder is referred to as feed-forwarder two-phase network that handles encoder and decoder tasks using input X and hidden H which represents non-linear equations stated below; H - stand for non-linear activation functions that decodes maps hidden in the representation. Thus, the original hidden representation can also be calculated with Z -If the model parameters optimize and minimize errors in the auto-encoder variants, the reconstructing error collection data = N, the sample square error optimization = (Xi= f (xi))2 Xi represents the ith sample of the unsupervised data, h stands for hidden representation and X for data sample (Bengio et al. 2007)[61]. The image below demonstrates the difference between physical based, conventional data- driven, and deep learning auto-encoder algorithm. The conventional auto-encoder data-model requires handcrafting features for each individual trained module and cannot handle large datasets. Deep learning autoencoder methods provide end-to-end envisioned data structure without handcrafting features and train jointly large datasets; 3 Fig 1. Autoencoder schematic illustration [78] According to the diagram above, the learned transformation in the autoencoder must be sparse with constraints that implores the hidden unit with an optimizing function written below; (Xi= f (xi))2 M= hidden layer size Ki=divergence hidden units and jth hidden neuron. The conventional auto-encoder has an additional denoising network that corrects corrupt version of the data input, reconstruct, clean and train sample data X. it also has staking structure which puts together output lth layers as input (L+1)t-th layer to represent higher level and provide solutions to deep neural network model (Vincent et al.2008)[62]. 4 RBM variants Restricted Boltzmann machine has two-layers (NN) bipartite graph consisting of two visible groups known as units V and hidden unit h with an asymmetric link between both, but doesn’t connect their nodes. RBM model parameters = (w,b,a) energy functions. Where = Wij –Vi- hj. Wij -connecting weight between units Vi- total number 1 and hidden unit Hi -the total number of Ji bi and ai, which shows the joint RBM distribution over the unit based energy function equated as p(v, hj, Z -partitioned function/normalization factors). The conditional probabilities of the hidden & visible units h and V will be P (hj =I/Vj ) P (Vi=I/Vj = logistic function The w-learning approach is achieved using a contrastive divergence tool (CD). Deep belief network variants DBN is made up of stack multiple RBM with output ith layer (hidden unit and input (L+1)- th visible layer. DBN has a common similarity with SDA due to its large layer unsupervised pattern in handling pre-trained data parameters. Deep Boltzmann machine learning approach contains hidden units grouped into layers of single connectivity constraints with its full connection found between subsequent and non- neighboring layers. 5 Convolutional neural network and its variants CNN was utilized to perform image spatial processing via weights & pooling properties. CNN serves the purpose of authenticating natural language & speech recognition. It helps to learn about the alternating abstract features, stack convolutions & pool operations. The two dimensional CNN can be compared to a one-dimensional model using input sequence data X=(Xi………………….Xt)where t represents lengths of sequence, Vi-d respectively. The convolutional dot production can be filtered with vector U Where Ci = Where XT stands for matrix x, b and the output Ci is seen as the activated filter U that correspond with Xi; I + m-1. The slide filtering window features a map vector of Cj =(C1, C2, ……………………(l-M+1) The J represents the index J-th filter that corresponds with multi-windows (Xi; m, X2: m+1…………….X1-m + 1:1). CNN has a max-pooling layer that is capable of reducing the length of the featured map and minimized the numbers of modeled parameters. It has a hypermeter pooling layer denotation of MAX operation with consecutive value S and feature map Cj. The compressed feature h= (h, h2, --------- +1) Hj= max (c(j-1)s, C (J-1) S+1, …………….C, S-1). To predict data possibilities, the alternating CNN max-pooling layers can fully be connected to the softmax layer. Recurrent neural network and its variants Schmidhuber (2015)[63] highlights the arbitrary length sequence of pattern input, which builds the connection between direct cycle and multi-layer perceptron. RNN trains back- propagated supervised data with subsequent input and targeted datasets (Jaeger, 6 2002)[64]. It’s functional transition step T shows time information (Xt) moves from prior hidden output ht-1 to update the current hidden output ht = H (t,ht-1). H - non-linear & differential transforming function. Ht- learned representation showing input data and length T. Also, the conventional multi- layer perceptron mapped the obtainable ht representation to make the prediction successfully. The simple function “Vanilla RNN”, can be equated as-ht W and H that represent transformation matrixes while b =bias vector. Vanilla RNN suffers vanishing gradient problem due to back-propagation, but can easily be restored with LSTM and gate recurrent neural networks (GRU) to prevent errors and explosion. (Chung et al.2014)[65]. The advanced version of LSTM & GRUs has a multi-layer recurrent bi-directional model capable of offering structural flexibility. Fig 2. One-layer CNN, pooling layers, fully connected one Softmax Layer [79] 7 Health monitoring applications and wearables Rose et al. 2010 [5] implemented hierarchical clustering methods to detect mammographic image data. The image below shows health monitoring applications necessary for capturing arrays of pervasive sensors worn or implanted in the body to capture ambient inertia motion, ECG patches, smart watches, EEG, and prosthetics (Johnson et al.2016) [6]. Pervasive sensors are wearables implanted as ambient sensors that monitor human health and accurately estimate food intake, energy expenditure, tackles obesity, chronic diseases, and care for patients with disabilities. Patients undergoing rehabilitation and critical care situation are often implanted with assisting devices to check vital signs (Pouladzadeh et al. 2016)[7]. During epidemics, the escalation of health-related issues like obesity, and cardiovascular diseases are controlled with energy expenditure/activity recognition tool, since it controls the amount of diet by monitoring calorie intake. CNN can alternatively be used to recognize and monitor accurately food intake by adopting cloud computing, size-calibrating, and distance estimation tools. Pouladzadeh et al. 2016 [7] combined DL method with invariant hierarchical representation of video using two-layer 3D convolution & max-pooling large inputs to recognize human daily activities. Yalcin, 2016[9] used RGB D-video sequence to classify human activities and mount surveillance on elderly and child care clinics. CNN has furthered the detection of baby’s fall & crawls while alerting caregivers by raising an alarm. The RBMs work together on smartphones & watches (Assisting devices), with audio & tactile feedback application, specifically used to detect visual impairment. Some assistive device consists of CNN DL algorithms that recognize hand gestures, sign languages, sterile surroundings, and permits touch-less human-computer-interaction (HRI). Huang et al.2015[8] introduced a deep neural network (DNN) for sign language recognition using real-sense data that coordinates finger joints inputs without handcraft features. DL machine ensures that health monitoring is achieved with discrete targeted values applied through Softmax later (prognosis and linear regression layer), that limits human labor and expert’s skills. 8 Sun et al. (2016)[41] used a one-layer auto-encoder neural network to classify health- machine motor fault recognition and repair while Lu et al. (2017)[42] diagnose rotary health machine faults with components of stacked denoising AE in the three hidden notable layers. Most devices for vital signs like ECG, BCG (ballistocardiogram) are built with DL applications. Technology advancement brought about wearable photos or videos attached to outfits, and embedded sensors placed on chairs, car seats, and mattresses (e.g. Fitbit wrist band tracker controlled with mobile apps and add-ons). Experts studied the use of a genetic triaxle algorithm known as accelerometer bracelets to trace walking patterns (e.g. falls and seizure inpatients). Research declared that prolonged sedentary lifestyle can cause adverse health outcomes which made clinicians adopt the use of wearable devices for monitoring patients' health and advice physical activity when necessary. Choo et al. 2017[76] used wearable devices to trace language patterns of mother-child connection and childhood psychological development. Choi et al. (2017)[75] monitored stress patterns using mentally equipped sensors powered by Ml/DL to understand stress in children and adults by following their heartbeat, blood pressure, and temperature. According to our research, the electrodermal activity tool (EDA) known as the “emotion Board” has helped to measure skin reaction to stress. However, SVM and LDA help to classify stress and show up to 82.8% result. Chen et al. (2018) monitored heat stroke using a fuzzy logic technique to display an inferential signal on smart devices. The design of wireless communication profoundly changed patient’s management through point-to-care diagnostic devices like EMS (emergency medical service) used in emergency rooms & ICU. Some ICU systems revealed beyond vital signs to the extent of detecting patients' posture/position, toxic gases, and heat flux. Winokur et al. 2013[28] found wearable devices valuable for monitoring heart rate, recording ECG, 3D representation of Sternal Seismocardiogram (SCG). Da He et al. 2012 [27] introduced ear device and wearable cardio-meter defibrillator WCD) to prevent arrhythmic sudden death of patients. Fryar et al. 2017(12) detect hypertension 9 with physiological signals from cerebral blood flow-meter (CBF) that estimates hemodynamic cephalic symptoms in patients. Deep learning architectures, descriptions, and key points Deep learning networks are frameworks for classifying or regressing data which have either hidden or visible output layers. Some have more than two hidden layers that allow the expression of complex or non-linear hypothesis. Deep neural networks have successfully been used in bio-informatics but lack training authentication due to its back- propagated layers and slow learning process. Hinton and Salakhutdinov, 2006 [10] discussed deep auto-encoder designed to extract features and later dimensional reduction with its input, hidden, and output layers. Deep auto-encoder consists of similar input & output nodes, which help to recreate input vectors and handles unsupervised learning techniques. The deep auto-encoder is vital for labeling data, and robust representation (Sparse- AutEU). However, it does need pre-training to undergo the full training process. The deep belief network RBM composition has each sub-network hidden layers & visible layers with undirected connections. The two layers permit unsupervised & supervised training networks to initialize network commands, inference tracing for handling sampling process, and training procedures. (Hinton et al. 2016)[10]. Salakhutdinov and Hinton, 2009 [11] states the difference between deep belief network and deep Boltzmann machine network. According to his laid emphasis, Boltzmann has conditional independent layers that are undirected but uses stochastic algorithms to maximize lower bounds, incorporate robust inference and ambiguous inputs. Boltzman DL can also handle complex time inference that is higher than DBN; while optimizing large dataset parameters. The continual progression in neural networks led to the proposition of recurrent neural networks with the capacity to analyze huge data streams, memorize sequential events, model time dependencies, and process natural languages. The recurrent neural network faces a challenge of vanishing exploding gradients. (Williams and Zipser, 1989)[13]. The 10 convolutional neural network is communicably used since its quite compatible with 2D data and transforms filtered input to 3D output for neuron activations (LeCun et al. 1998)[14]. CNN supports Neuro-biological modeling, which performs visual cortex using flow neuron connections and many varied applications like Google Net & Clarifa. The main challenge in CNN is the hierarchical visual feature used to input large labeled datasets. The parallel GPU acceleration offers hardware capacity need to compute DNN on clouds and multi-core processors. The recurrent neural network comes with a hidden capacity to analyze several data, which made Bengio et al. (1994)[61] discuss RNN variation called Long-Short term memory unit (LSTM). LSTM solves gradient vanishing problems using long-input sequences. LSTM can be used to exploit stored information, write and read information without errors during training. It’s compatible with RNN and shares the same weight whilst aiding natural language processing like modeling, speech recognition, and image description. Ackley et al. 1986 [16] emphasized on the variant Boltzmann machine (RBM) type of stochastic neural networks with Gaussian learning procedures called GIBBS sampling. GIBBS sampling adjusts weights, minimize errors, and model the variable relationship probability. Wang et al . 2016 [17] reviewed the graphical probability model with stochastic units and characterize the conditional independence between variables and directed acyclic graph. Carreira and Hinton, 2005 [18] mentioned the contrastive divergence algorithm (CD) used in conjunction with RBM to handle unsupervised learning algorithms. It has positive and negative phases, whereby the positive phase encourages network configuration and the negative phase recreates current network configurations. CNN has regular correlated local data with multi-dimensional input that can be significant in back-propagation, adjusting of number parameters that support the neuro-biological visual cortex model. The visual cortex in CNN has receptive local field maps that move granularity anterior image inputs to a convolved sub-sampled output through small filters (Hubel and Wiesel, 1962)[19]. 11 DNN learning architectures Deep neural network architecture known as input-output deep architecture (IODA) can resolve different image labeling issues by assigning labels to each image pixel. DNN services both hyperspectral images, whereas spectral & spatial features come together to form hierarchical models that characterize human body issues. Kondo et al. 2014[20] employed a group method of data handling (GMDH) with a hybrid multi-layer neural process to authenticate polynomial activated functions. The essence of GMDH is to recognize liver and spleen data while performing principal component regression analysis. The same technique can be used to identify Cancer Mcyarduim, right, and left kidney issues. Application of deep neural network to translational bioinformatics Table 1 demonstrates software explored with CUBA/NVIDIA to aid GPU acceleration which Wolfram Mathetica and Nervana (2020)[74] used to provide cloud training process systems in combination with neuromorphic electronic system hardware. Most computational neuroscience simulations are conducted with neurons & synapses chips, integrated into hardware like (IBM) true north, (Spinnaker), and Curie (intel). The main purpose of bioinformatics as a discipline is to explore, investigate, and understand the biological molecular level and its processes. Past human genome project (HGP) researched raw data to develop new hypotheses of genes, and environmental factors related to the creation of human genetic proteins. To diagnose diseases using biotechnology, the first human genome motivating principle is “P4” (personalized, preventive, participatory, and predictive medicine) (Hood et al.2011)[22]. The predictive health informatics hold attributes for encoding DNA of the living beings while analyzes the alleles, environmental factors leading to diseases like cancer, and design targeted therapeutic procedures as a remedy. (Leung et al.2016)[23]. The concept of pharmacogenomics is focused on evaluating varieties of drugs & its response to gene-related treatment for aliments especially personalized diagnosis with fewer side effects. Epigenomics investigates interactive proteins and its higher-level 12 processes, and response while transcriptome (mRNA), Proteome and Metabolome modify gene’s response to its environments. Genetic variants are uniquely designed with slicing codes that predict the differences in human tissues, especially how it changes as a result of genetic variation. The alternate of slicing code helps to technically generate gene prediction of slicing patterns meant to comprehend gene phenotypes and its drug effects on autism, spinal muscular atrophy, and hereditary cancer. (Leung et al.2016)[23]. A quantitative activity structure relationship was meant to predict protein-protein coordinations which are usually structured with molecular information, compound interactive protein; for predicting proteins used for drug discovery. Compound interactive protein virtual analysis influenced the discovery of new compounds, toxic substances, and the interpretation of drugs related to targeted cells. In health informatics, deep learning models are utilized to enhance DNA methylation for providing visible outlooks of human chromosomes. It can be used to identify unstable chromosomes, error translation, cell transcription, differentiation, and cancer progression. (Angermueller et al.2016)[24]. Pastur-Romay et al. 2016 [25] named Chembl database in pharmacogenomics that detects millions of compounds descriptions used to develop & target drug evolutions, since the mentioned database encrypts molecular fingerprints, and understand traditional Ml approaches. Chembl database also helps to reduce data complexity in molecular RNA by binding predictive proteins together using RNA structural tertiary profiled outcome (Zhang et al. 2016)[49]. Fakoor et al. (2013)[1] utilized the autoencoder model to explore genetic data from diverse cancer patients to identify similar microarrays in the datasets. Ibrahim et al.2014 [26] detailed the effect of active learning methods using DBN to feature MicroRNA for classifying the performance of different cancer diseases like hepatocellular carcinoma. Deep learning approaches were adopted by Khadem et al. (2015)[28] to beat breast cancer disease through an attribute & noise combination of BDN & Bayesian network that helps 13 the extraction of micro-array data. Experts considered deep learning more effective than SVM in detecting slicing code of different genetic variants, which according to Angermueller et al. (2016)[24] DNN predicts DNA methylation from an incomplete sequence of methylated data. It also predicts embryonic stem cells and baseline comparison to show genome downstream demonstration. Deep learning was mentioned to have outpace conventional techniques, as Kernes et al. (2016) used graph convolutions to encrypt molecular features, physical properties, and assay activities that permit potential collaboration of molecular encoded information. Deep learning used for medical imaging procedure Experts found DL relevant in diagnosing illnesses and interpreting medical images. The processes are conversantly enabled by CAD (computer-aided diagnosis) for assimilating the cause of diseases. CAD model helps to identify causes of neurological Alzheimers, sclerosis, and stroke progression through brain scans, multi-modal mapping of the infected region. Over the years, convolutional neural network aids computer vision, especially the ability to personalize GPU to show parallel brain pathology (Havaei et al.2016)[29]. It further demonstrates CAD segmentation and shapes the analysis of the human brain. CAD has helped to overcome the challenges of difference in intensity & shapes of tumors and lesions using image protocols. Though, issues associated with CAD may include pathological tissue overlapping with healthy samples, RICIAN-Noise, non-Isotropic issues, and bias field effects evident in magnetic resonance images (MRI). Sometimes, the MRI cannot be handled automatically by CAD but requires a similar ML approach to decrypt data complexity and extract features through conventional approaches (Greenspan et al.2016)[30]. CNN as a deep learning approach works better than CAD in terms of data manipulation, operating patch images of abnormal tissues (e.g. CNNs medical imaging for lung diseases coordinated with computed tomography image). Experts used CNN and CT imaging applications to classify the manifestation of tuberculosis, the cell of the neural progenitor from somatic source, and hemorrhage color Fundus image detection. Yan et al (2016)[31] classified different anatomies with CT to understand human organ recognition using 14 multistaged frameworks to extract patches of pre-trained stages. Jamaluddin et al.2016 seem it essential to use CNN for the segmentation of Isotense brain tissue and brain extraction through a multi-modality image tool. Avendi et al. 2016[32] described how DL algorithms encode deformable model parameters and facilitate left ventricle segmentation necessary for short-axis cardiac imaging. CNN tools have 2D image components for segmenting MRI & CT in 3D format, to eradicate issues found in anisotropic voxel sizing. CNN was adopted in orthogonal patch extraction to segment axis, sagittal, and corona view which reduces time and overfitting problems. (Fritscher et al.2016)[33]. Common limitations of CNN include its non-spatial dependencies and the need for pre- processing to bring conditional random fields. These issues can be altered by substituting with conventional ML approaches to solve problems of incomplete data training, limited annotated data, cost/time, and manual medical image annotations. Previously, manual annotation was accepted to help the detection of medical images, but crowdsourcing according to (Greenspan et al.2016)[30] is a viable alternative due to its affordability, error-free medical image analysis. Havaei et al. 2016[29] used a transfer learning and fine-tuning approach to alleviate incomplete training issues on CNN, allowing the pre-trained data to be labeled manually. Tajbakhsh et al. (2016)[53] described the similarity between natural images and medical images by using the fine-tuning process to repeat the same experiment. Shin et al. (2016)[34] applied transfer learning to natural images of a thorax-lymph node to detect lung disease and the result shows consistency in performance without losses. Chen et al (2015)[35] identified fetal abdominal standards with a transfer learning approach to display low-layer CNN pre-training effects on natural images while implementing multi-tasking to handle the CAD image imbalance. Cheng et al.2016[36] utilized denoising autoencoder to diagnose breast legions and pulmonary nodules in CT scans. Shan et al. (2016) [37]tried Stack Sparse Autoencoder on Microaneurysms Fundus images to detect diabetic retinopathy whilst uses Softmax Output Layer to show Alzheimer's disease prediction with functional magnetic resonance images (fMRI). Li et al. (2015)[38] used the RBM method to effect biomarkers from MRI and position emission 15 tomography (PET SCAN) and the result of the scan shows 6% accuracy. Kuang et al. (2014)[39] discriminate attention deficit hyperactivity disorder with the same FMRI application. Hence, experts extracted RBM latent hierarchical 3D patch features from the brain using image segmented tools and Brosch et al. (2013)[40] implored manifold learning method to study 3D brain images, its full automated shape, and cranial nerves. Deep learning methods are known to outpace conventional approach through low-contact optic tracts and other human pathological anatomies. Beaulieu-Jones et al. 2018 [60] found pipeline models relevant in detecting & segmenting objects to achieve an automatic volumetric image process called marginal space DL. MSDL handled hierarchical marginal spacing with automatic features to detect deep learning datasets. Literature review Unsupervised learning techniques are characterized by an unlabeled dataset using metrics of low-high dimensional subspace anomalies for detecting clusters of data. (E.g. Prediction of heart & hepatitis diseases). Collins and Yao, 2018 [43] defined prognosis as the method of predicting disease with clinical practice settings whilst showing multi-modal data. Wang et al. 2012 [44] use prognosis to diagnose diabetics registered in electronic health data records. Medical image analysis follows enhancement, detection, classification, and segmentation procedure to reconstruct and store data. Chen et al. 2017 [45] implemented the reconstruction of MRI and CT image datasets using generative adversarial networks (GANS). The generative adversarial network (GAN) offers MRI reconstruction by cleaning motion pictures, artifacts, and handling image fusion & registration. El-Gamal et al. (2016)[46] noted the significance of image registration in surgical spine implant, tumor removal, and neuro-surgical process. 56 developed an image registration framework called “Quick- Silver”, for large deformation mapping and diffeomorphic metric prediction. Before image registration, data retrieval enables physicians to check the large images of patients' repeated visits to the clinic. Zech et al. 2018 [47] shared natural language processing methods for annotating retrieved images from clinical radiological reports. 16 To achieve real-time health monitoring with DL wearables, IOT sensors, and smart devices, DL clouds must be integrated into smart devices to attain the required results. DL had found its place in clinical workflows for predicting & diagnosing diabetes, dengue, heart & liver diseases, whereby IBM advanced CAD system to CADX that displays automatically fatty liver in Kurtosis image (MA et al. 2016)[48]. Zhang, 2019 [49] utilized clinical reinforcement learning to study the optimal diagnosis and treat patients by characterizing its performance evaluation with different methods (Q value iteration, tabular learning, Q-iteration, and deep Q-learning). The RL method helps to treat sepsis in intensive care units. The same clinical time-series data were studied to provide medical intervention to patients in intensive care units by using CNN and LSTM to predict traumatic brain damage, estimate the mean-variance of arterial blood pressure and intracranial pressure monitoring (Rau, 2018) [50]. Recently, experts have adopted Attention Models to forecast ICU activities, integrate multivariance time-series measurement, and controlling unexpected respiratory issues. To control NIP challenges, Neveol, 2018[52] used the CLAMP Toolkit to monitor different states of clinical text analysis of language acronyms, disparity, and quality variance. Several doctors studied clinical documentation, especially on how to use clinical speech and audio processing to minimize time spent on administrative tasks and medical reports. (Wallace, 2019)[51]. Speech and audio processing serve the purpose of identifying disorders using vocal hyper-functional tools to review patients with dementia and Alzheimers. Limitations Privacy and security challenges are primary limitations discovered in deep learning algorithms. The issue of data collection vulnerabilities is experienced during DL adoption of large datasets which also consumes time and human efforts. The problem of incorrect or altered datasets can lead to wrong diagnoses. Latif et al. 2018 [54] disclosed that instrumental and environmental noise from smart machines can cause an unnecessary disturbance, especially MRI multi-shots, high sensitive modal-motion, and an increased risk of mis-diagnosis due to mistakes in artifacts; can be detrimental to human health. 17 Unqualified physicians without knowledge of data analytics can commit unforgivable errors in medical diagnosis. Caruana et al. 2015 [55] explained the difficulties in data labeling and annotation while 86 lamented about ambiguous medical image classification which may lead to confusion and disagreement between physicians. Xia et al. 2012 [56] indicate that the use of inappropriate algorithms can be detrimental and life-threatening; if improper annotation happens while suggesting the use of meticulous approaches in the labeling of datasets to limit inefficiencies. Due to limited or imbalance datasets, wrong diagnoses can cause death of millions, and missing data sparsity values can lead to unmeasured or repetition in taking samples. Biggio et al. 2012 [57] viewed model training vulnerabilities, as improper training or incomplete breach of privacy causing model poisoning and data theft. To corrupt an already collected data is known as “data poisoning” which requires security, especially during digital forensics & bio-metrics. In case of compromise during deep learning deployment, realistic healthcare settings will experience distribution shifts, leading to incomplete data vulnerability in the testing phase. Security and recommendations Numerous security threats, influence & violations are associated with DL algorithms, constituting to integrity attack, and other vulnerabilities. Such an act can destroy the progress of DL in health and other fields of science. Usama et al. 2019[58] mentioned adversarial machine learning vulnerabilities inserted in input samples to evade privacy and data integrity. A data breach can cause modal poisoning & privacy evasion; whereby clinical deep learning applications are constantly under an attack. However, safety, privacy, ethical regulations & policy are being reinstalled to ensure the quality of data exchange standards. David et al. (2015)[59] recommends hyper-plane commodity data cryptography to control data breach in naïve Bayes classifiers. Zhu et al. (2018)[66] suggest the use of polynomial aggregation and random masking protect SVM with non-linear kernel algorithms. Jagieiski et al. (2018) indicate that data privacy can be reassured with a TRIM tool to protect linear creations. Lui et al. Ascertained that DL frameworks can be secured with 18 XMPP serve while Malalhi et al (2019[68] named Paillier homomorphic encryption for security Naïve Bayes, SVM neural network and FKnn-CBR used to rescue liver patients in India hospitals. Takabi et al. (2016)[69] suggest homomorphic encryption for deep neural networks that control more than 15 datasets in repositories. To guarantee the safety of logistic regression, Kim et al. (2018) [70] recommends homomorphic encryption to secure medical binary datasets. To update healthcare infrastructure, Finlayson et al. 2019 [71] suggest the use of the international classification of disease system which helps to minimize dataset vulnerabilities. However, privacy can be preserved with a cryptographic approach, homomorphic encryption, garbled circuiting, and secured processors. The Intel SGX processor offers confidentiality and authorized access to systems like K-mean, decision trees, and SVM (Ohrimenko et al. 2016)[72]. Google Inc added federated learning method to distribute data, decentralize scheme and predict heart-related diseases. McMahan et al. 2017 [73]. To control adversarial attacks, it's important to modify models using defensive distillation, network verification, gradient regularization, and classifier robustification. Conclusion Deep learning and health informatics algorithms will continually expand to other branches of science, as wearable smart monitoring devices are presently used to track and diagnose Parkinson's diseases. Google Glass conducted prototype child therapeutic analysis to monitor and diagnose autism spectrum disorder. To preserve mental health, psychiatric hospitals are screened, diagnosing, and monitoring depression with a system-on-chip solution that accelerates filters, and reveals heart rates on ECG. Smart monitoring devices are unique, compatible, embedded with DL, and simple to operate. However, aging adults may find it challenging. The future of DL and health informatics depends on the recent 5G wireless network, proposed to bring about new devices for testing red protein (Hemoglobin); especially for transporting oxygen to the blood. The accuracy of clinical results can be validated with a cross-validation approach to unravel the results. 19 Reference 1. Fakoor, R., Ladhak, F., Nazi, A., Huber, M. : Using deep learning to enhance cancer diagnosis and classiﬁcation,” in Proc. ICML, (2013). 2. Ngiam, J., Coates, A., Lahiri, A., Prochnow, B. Q., Le, V., Ng, A. Y. :On optimization methods for deep learning,” in Proc. ICML, (2011),pp. 265–272. 3. McClelland, J. L., Rumelhart, D. E. :Parallel distributed processing. MIT Press Cambridge, MA, (1987), vol. 2. 4. Rumelhart, D. E., Hinton, G. E., Williams, R. J. :Neurocomputing: Foundations of research,” J. A. Anderson and E. Rosenfeld, Eds.Cambridge, MA, USA: MIT Press, (1988), ch. Learning Representations by Back-propagating Errors, pp. 696–699. 5. Rose, D. C., Arel, I., Karnowski, T. P., Paquet, V. C.: Applying deep-layered clustering to mammography image analytics,” in BSEC, (2010), pp. 1–4. 6. Johnson, A. E. W., Ghassemi, M. M., Nemati, S., Niehaus, K. E., Clifton, D. A., Clifford, G. D. :Machine learning and decision support in critical care,” Proceedings of the IEEE, vol. 104, no. 2, pp. 444–466, Feb (2016). 7. Pouladzadeh, P., Kuhad, S. V. B., Peddi, A., Shir-Mohammadi, S. :Food calorie measurement using deep learning neural network,” in I2MTC, (2016), pp. 1–6. 8. Huang, J., Zhou, W., Li, H., Li, W.: Sign language recognition using real-sense,” in IEEE ChinaSIP, (2015), pp. 166–170. 9. Yalcin¸ H. :Human activity recognition using deep belief networks,” in, (2016), pp. 1649–1652. 10. Hinton, G. E., Salakhutdinov, R. R.: Reducing the dimensionality of data with neural networks,” Science, vol. 313, no. 5786, pp. 504–507,(2006). 11. Hinton, G. E., Osindero, S., Teh, Y.W.: A fast learning algorithm for deep belief nets,” Neural Comput., vol. 18, no. 7, pp. 1527–1554 (2006). 12. Fryar, C. D., Ostchega, Y., Hales, C. M., Zhang, G., & Kruszon-Moran, D. (2017). Hypertension Prevalence and Control Among Adults: United States, 2015-2016. NCHS Data Brief (289), 1-8. 13. Williams, R. J., Zipser, D.: A learning algorithm for continually running fully recurrent neural networks,” Neural Comput., vol. 1, no. 2, pp. 270–280, (1989). 20 14. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P. :Gradient-based learning applied to document recognition,” Proceedings of the IEEE, vol. 86, no. 11, pp. 2278–2324, (1998). 15. Bengio, Y., Simard, P., Frasconi, P.: Learning long-term dependencies with gradient descent are difﬁcult,” IEEE Trans. Neural Netw., vol. 5, no. 2, pp. 157–166, (1994). 16. Ackley, D., Hinton, G., Sejnowski, T.: Learning and relearning in Boltzmann machines,” Parallel Distributed Processing: Explorations microstructure of Cognition, (1986). 17. Wang, H., Yeung, D.Y.: Towards Bayesian Deep Learning: A Survey,” ArXiv e-prints, Apr. 2016. 18. Carreira-Perpignan, M. A., Hinton, G. :On contrastive divergence learning.” in AISTATS, vol. 10, (2005), pp. 33–40. 19. Hubel D. H., Wiesel, T. N.: Receptive ﬁelds, binocular interaction and functional architecture in the cat’s visual cortex,” The Journal of physiology, vol. 160, no. 1, pp. 106–154, (1962). 20. Kondo, T., Ueno, J., Takao, S.: Medical image recognition of abdominal multi-organ by hybrid multi-layered gmdh-type neural network using principal component- regression analysis,” in CALENDAR,(2014), pp. 157–163. 21. Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Good fellow, I. J., Fergus, R. :Intriguing properties of neural networks.”CoRR, vol. abs/1312.6199, (2013). 22. Hood, L., Friend, S. H.: Predictive, personalized, preventive, participatory (p4) cancer medicine,” Nature Reviews Clinical Oncology, vol. 8, no. 3, pp. 184–187, (2011). 23. Leung, M. K., Delong, A., Alipanahi, B., Frey, B. J.: Machine learning in genomic medicine: A review of computational problems and data sets,” Proceedings of the IEEE, vol. 104, no. 1, pp. 176–197,(2016). 24. Angermueller, C., Parnamaa, T., Parts, L., Stegle, O.: Deep learning for computational biology,” Molecular Systems Biology, vol. 12, no. 7, p. 878, (2016). 25. Pastur-Romay, L. A., Cedar, F. A., Pazos, A., Porto-Pazos, B. :Deep artiﬁcial neural networks and neuro morphic chips for big data analysis: Pharmaceutical and bioinformatics applications,” International Journal of Molecular Sciences, vol. 17, no. 8, p. 1313, (2016). 26. Ibrahim, R., Yousri, N. A., Ismail, M. A., El-Makky, N. M. :Multi-level gene/miRNA feature selection using deep belief nets and active learning,” in EMBC, (2014), pp. 3957–3960. 21 27. Da He, D., Winokur, E. S., & Sodini, C. G. (2012). An ear-worn continuous ballistocardiogram (BCG) sensor for cardiovascular monitoring. Paper presented at the Engineering in Medicine and Biology Society (EMBC), 2012 Annual International Conference of the IEEE. 28. Winokur, E. S., Delano, M. K., & Sodini, C. G. (2013). A wearable cardiac monitor for long-term data acquisition and analysis. IEEE Transactions on Biomedical Engineering, 60(1), 189-192. 29. Havaei, M., Guizard, N., Larochelle, H., Jodoin, P.: Deep learning trends for focal brain pathology segmentation in MRI,” CoRR, vol.abs/1607.05258, (2016). 30. Greenspan, H.,Van Ginneken, B., Summers, R. M. :Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique,” IEEE Trans. Med. Imag., vol. 35, no. 5, pp.1153–1159, May (2016). 31. Yan, Z., Zhan, Y., Peng, Z., Liao, S., Shinagawa, Y., Zhang, S., Metaxas, D. N., Zhou, X. S. :Multi-instance deep learning: Discover discriminative local anatomies for body part recognition,” IEEE Trans.Med. Image, vol. 35, no. 5, pp. 1332–1343, (2016). 32. Avendi, M., Kheradvar, A., Jafarkhani, H.: A combined deep-learning and deformable- model approach to fully automatic segmentation of the left ventricle in cardiac MRI,” Medical image analysis, vol. 30, pp. 108–119, (2016). 33. Fritscher, K., Raudaschl, P., Zafﬁno, P., Spadea, M. F., Sharp, G. C., Schubert, R. :Deep neural networks for fast segmentation of 3dmedical images,” in MICCAI, (2016), pp. 158–165. 34. Shin, H.C., Roth, H. R., Gao, M., Lu, L., Xu, I., Nogues, J., Yao, D., Mollura, R., Summers, M. :Deep convolutional neural networks for computer-aided detection: Cnn architectures, dataset characteristics, and transfer learning,” IEEE Trans. Med. Imag., vol. 35, no. 5, pp.1285–1298, (2016). 35. Chen, H., Ni, D., Qin, J., Li, S., Wang, X. T., Heng, P. A.: Standard plane localization in fetal ultrasound via domain transferred deep neural networks,” IEEE J. Biomed. Health Inform. vol. 19, no. 5, pp. 1627–1636, (2015). 36. Cheng, Z., Ni, D., Chou, Y.H., Qin, J. C., Tiu, M., Chang, Y.C., Huang, C. S., Shen, D., Chen, C. M.: Computer-aided diagnosis with deep learning architecture: Applications to breast lesions in our images and pulmonary nodules in ct scans,” Scientiﬁc reports, vol. 6, (2016). 37. Shan, J., Li, L.: A deep learning method for micro-aneurysm detection in fundus images,” in IEEE CHASE, (2016), pp. 357–358. 22 38. Li, F., Tran, L., Thung, K. H., Ji, S., Shen, D., Li, J.: A robust deep model for improved classiﬁcation of ad/MCI patients,” IEEE J. Biomed. Health Inform. vol. 19, no. 5, pp. 1610–1616, Sept (2015). 39. Kuang, D., He, L.: Classiﬁcation on ADHD with deep learning,” in CCBD, Nov 2014, pp. 27–32. 40. Brosch, T., Tam, R., Initiative et al., A. D. N.: Manifold learning of brain MRIs by deep learning,” in MICCAI, 2013, pp. 633–640. 41. Sun, W., Shao, S., Zhao, R., Yan, R., Zhang, X., Chen, X.: A sparse auto-encoder-based faults classification,” induction motor deep neural network approach Measurement, vol. 89, pp. 171–178, (2016). for 42. Lu, C., Wang, Z. Y., Qin, W.L., Ma, J.: Fault diagnosis of rotary machinery components using a stacked denoising auto encoder-based health state identification,” Signal Processing, vol. 130, pp. 377–388, (2017). 43. Collins, A., Yao, Y.: Machine learning approaches: Data integration for disease prediction and prognosis,” in Applied Computational Genomics. Springer, (2018), pp. 137–141. 44. Wang, Z., Shah, A. D., Tate, A. R., Denaxas, S., Shawe-Taylor, J., Hemingway, H. :Extracting diagnoses and investigation results from unstructured text in electronic health records by semi-sup (2012) 45. Chen, H., Zhang, Y., Kalra, M. K., Lin, F., Chen, Y., Liao, P., Zhou, J., Wang, G. : Low- dose ct with a residual encoder-decoder convolutional neural network,” IEEE transactions on medical imaging, vol. 36no. 12, pp. 2524–2535, (2017). 46. El-Gamal, F. E., Elmogy, A. M., Atwan, A.: Current trends in medical image registration and fusion,” Egyptian Informatics Journal vol. 17, no. 1, pp. 99–124, (2016). 47. Zech, J., Pain, M., Titano, J., Badgeley, M., Schefflein, J., Su, A., Costa, A., Bederson, J., Lehar, J., Oermann, E. K. :Natural language-based machine learning models for the annotation of clinical radiology reports,” Radiology, vol. 287, no. 2, pp. 570–580, (2018). 48. Ma, H.Y., Zhou, Z., Wu, S., Wan, Y.L., Tsui, P.H. :A computer-aided diagnosis scheme for detection of fatty liver in vivo based on ultrasound kurtosis imaging,” Journal of medical systems, vol. 40, no. 1,p. 33, (2016). 23 49. Zhang, Z., et al. : Reinforcement learning in clinical medicine: a method to optimize dynamic treatment regime over time,” Annals of translational medicine, vol. 7, no. 14, 2019. 50. Rau, C.S., Kuo, P. J., Chien, P.C., Huang, C.Y., Hsieh, H.Y., Hsieh, C.H. :Mortality prediction in patients with isolated moderate and severe traumatic brain injury using machine learning models,” PloS one, vol. 13, no. 11, p. e0207192, (2018). 51. Wallace, D. S.: The role of speech recognition in clinical documentation,” Nuance Available: on Communications, https://www.hisa.org.au/slides/hic18/wed/SimonWallace.pdf 14-Dec2019. [Online]. access 2018, 52. Neveol, A., Dalianis, H., Velupillai, S., Savova, G., Zweigenbaum, P. :Clinical natural language processing in languages other than English: opportunities and challenges,” Journal of biomedical semantics, vol. 9, no. 1, p. 12, (2018). 53. Tajbakhsh, N., Shin, J. Y., Gurudu, S. R., Hurst, R. T., Kendall, C. B., Gotway, M. B., Liang, J.: Convolutional neural networks for medical image analysis: Full training or ﬁne tuning?” IEEE Trans.Med. Imag., vol. 35, no. 5, pp. 1299–1312, 2016. 54. Latif, S., Asim, M., Usman, M., Qadir, J., Rana, R. :Automating motion correction in multishot MRI using generative adversarial networks,” Published as Workshop Paper at 32nd Conference on Neural Information Processing Systems (NIPS 2018). 55. Caruana, R., Lou, Y., Gehrke, J., Koch, P., Sturm, M., Elhadad, N. :Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission,” in Proceedings of the 21st ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, (2015), pp. 1721–1730. 56. Xia, F., Yetisgen-Yildiz, M. :Clinical corpus annotation: challenges and strategies,” in Proceedings of the Third Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM’2012) in conjunction with the International Conference on Language Resources and Evaluation (LREC), Istanbul, Turkey, (2012). 57. Biggio, B., Nelson, B., Laskov, P. :Poisoning attacks against support vector machines,” in 29th International Conference on Machine Learning, (2012), pp. 1807–1814. 58. Usama, M., Qadir, J., Al-Fuqaha, A., Hamdi, M. :The adversarial machine learning conundrum: Can the insecurity of ml become the Achilles’ heel of cognitive networks?” arXiv preprint arXiv:1906.00679, (2019). 59. David, B., Dowsley, R., Katti, R., Nascimento, A. C. :Efficient unconditionally secure comparison and privacy-preserving machine learning classification protocols,” in International Conference on Provable Security. Springer, (2015), pp. 354–367. 24 60. Beaulieu-Jones, B. K., Yuan, W., Finlayson, S. G., Wu, Z. S. :Privacy-preserving distributed deep learning for clinical data,” Machine Learning for Health (ML4H) Workshop at NeurIPS, (2018). 61. Bengio, Y., Lamblin, P., Popovici, D., Larochelle et al., H. :Greedy layer-wise training of deep networks,” Advances in neural information processing systems, vol. 19, p. 153, (2007). 62. Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.A. :Extracting and composing robust features with denoising autoencoders,” in Proceedings of the 25th international conference on Machine learning. ACM, (2008), pp. 1096–1103. 63. Schmidhuber, J. :Deep learning in neural networks: An overview,” Neural Networks, vol. 61, pp. 85–117, (2015), published online 2014; based on TR arXiv:1404.7828 [cs.NE]. 64. Jaeger, H. :Tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the” echo state network” approach. GMD For schungszentrum Informationstechnik, 2002. 65. Chung, J., Gulcehre, C., Cho, K., Bengio,Y. :Empirical evaluation of gated recurrent neural networks on sequence modeling,” arXiv preprint ar X iv:1412.3555, (2014). 66. Zhu, W., Liu, C., Fan, W., Xie, X. :Deep 3d dual-path nets for automated pulmonary in 2018 IEEE Winter Conference on nodule detection and classification,” Applications of Computer Vision (WACV). IEEE, (2018), pp. 673–681. 67. Jagielski, M., Oprea, A., Biggio, B., Liu, C., Nita-Rotaru, C., Li, B. :Manipulating machine learning: Poisoning Attacks and countermeasures for regression learning,” in 2018 IEEE Symposium on Security and Privacy (SP). IEEE, (2018), pp. 19–35. 68. Malathi, D., Logesh, R., Subramaniyaswamy, V., Vijayakumar, V., Sangaiah, A. :Hybrid reasoning-based privacy-aware disease prediction support system,” Computers & Electrical Engineering, vol. 73, pp. 114–127, (2019). 69. Takabi, H., Hesamifard, E., Ghasemi, M. :Privacy-preserving multiparty machine learning with homomorphic encryption,” in 29th Annual Conference on Neural Information Processing Systems (NIPS), 2016. 70. Kim, M., Song, Y., Wang, S., Xia, Y., Jiang, X. :Secure logistic regression based on homomorphic encryption: Design and evaluation,” JMIR medical informatics, vol. 6, no. 2, p. e19, (2018). 71. Finlayson, S. G., Bowers, J. D., Ito, J. J., Zittrain, L., Beam, A. L., Kohane, I. S. :Adversarial attacks on medical machine learning,” Science, vol. 363, no. 6433, pp. 1287–1289, (2019). 25 72. Ohrimenko, O., Schuster, F., Fournet, C., Mehta, A., Nowozin, S., Vaswani, K, Costa, M. :Oblivious multi-party machine learning on trusted processors,” in 25th USENIX Security Symposium (USENIX Security 16), (2016), pp. 619–636. 73. McMahan, H. B., Moore, E., Ramage, D., Hampson et al., S. :Communication-efficient learning of deep networks from decentralized data,” Proceedings of the 20 the International Conference on Artificial Intelligence and Statistics (AISTATS) JMLR: W&CP volume54, (2017). 74. Nervana Systems, Available:https://github.com/NervanaSystems/neon (2020). “Neon,” [Online]. 75. Choi, Y., Jeon, Y.-M., Wang, L., & Kim, K. (2017). A Biological Signal-Based Stress Monitoring Framework for Children Using Wearable Devices. Sensors, 17(9), 1936. 76. Choo, D., Dettman, S., Dowell, R., & Cowan, R. (2017). Talking to Toddlers: Drawing on Mothers' Perceptions of Using Wearable and Mobile Technology in the Home. Studies in health technology and informatics, 239, 21-27. 77. Chen, S.-T., Lin, S.-S., Lan, C.-W., & Hsu, H.-Y. (2018). Design and Development of a Wearable Device for Heat Stroke Detection. Sensors, 18(1), 17. 78. Ravì, D., Wong, C., Deligianni, F., Berthelot, M., Andreu-Perez, J., Lo, B., Yang, G. :Deep Learning for Health Informatics. IEEE journal of biomedical and health informatics. PP. 10.1109/JBHI.2016.2636665 (2016). 79. Rui, Z., Ruqiang, Y., Zhenghua, C., Kezhi M., Peng, W., Robert,G. :Deep Learning and Its Applications to Machine; Health Monitoring: A Survey JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST (2015) 26","['deep', 'learning', 'health', 'informatic', 'smart', 'monitoring', 'diagnosis', 'amin', 'gasmi', 'octobre', 'abstract', 'connection', 'design', 'delivery', 'health', 'care', 'service', 'use', 'information', 'technology', 'know', 'health', 'informatic', 'involve', 'data', 'usage', 'validation', 'transfer', 'integrate', 'medical', 'analysis', 'use', 'neural', 'network', 'multilayer', 'deep', 'learning', 'technique', 'analyze', 'complex', 'datum', 'instance', 'incorporate', 'deepmind', 'health', 'mobile', 'tool', 'integrate', 'leverage', 'medical', 'datum', 'need', 'enhance', 'professional', 'healthcare', 'delivery', 'patient', 'moorfield', 'eye', 'hospital', 'introduce', 'deepmind', 'research', 'algorithm', 'dozen', 'retinal', 'scan', 'attribute', 'deepmind', 'ucl', 'handle', 'identification', 'cancerous', 'tissue', 'use', 'mri', 'scan', 'tool', 'atomise', 'analyze', 'drug', 'chemical', 'deep', 'learn', 'neural', 'network', 'identify', 'accurate', 'preclinical', 'prescription', 'health', 'informatic', 'make', 'medical', 'care', 'intelligent', 'interactive', 'costeffective', 'accessible', 'especially', 'dl', 'application', 'tool', 'detect', 'actual', 'cause', 'disease', 'extensive', 'use', 'neural', 'network', 'tool', 'lead', 'expansion', 'different', 'medical', 'discipline', 'mitigate', 'data', 'complexity', 'enhance', 'overlap', 'image', 'use', 'target', 'point', 'label', 'datum', 'detector', 'support', 'datum', 'augmentation', 'unsemisupervised', 'learn', 'multimodality', 'transfer', 'learn', 'architecture', 'health', 'science', 'year', 'focus', 'artificial', 'intelligence', 'tool', 'care', 'delivery', 'chronic', 'care', 'management', 'preventionwellness', 'clinical', 'support', 'diagnosis', 'outcome', 'research', 'lead', 'cardiac', 'arrest', 'diagnosis', 'heart', 'signal', 'computeraide', 'diagnostic', 'tool', 'cadx', 'multi', 'functional', 'deep', 'learning', 'technique', 'offer', 'care', 'diagnosis', 'treatment', 'health', 'informatic', 'provide', 'monitor', 'outcome', 'human', 'body', 'organ', 'medical', 'image', 'classify', 'interstitial', 'lung', 'disease', 'detect', 'image', 'nodule', 'reconstruction', 'tumor', 'segmentation', 'emergent', 'medical', 'research', 'application', 'give', 'rise', 'clinicalpathological', 'humanlevel', 'perform', 'tool', 'handle', 'radiological', 'ophthalmological', 'dental', 'diagnosis', 'research', 'evaluate', 'methodology', 'deep', 'learn', 'architecture', 'approach', 'bioinformatic', 'specify', 'function', 'requirement', 'monitor', 'tool', 'artificial', 'neural', 'network', 'datum', 'labeling', 'annotation', 'algorithm', 'control', 'datum', 'validation', 'modeling', 'diagnosis', 'different', 'disease', 'use', 'smart', 'monitoring', 'health', 'informatic', 'application', 'keyword', 'health', 'informatic', 'diagnosis', 'smart', 'monitor', 'dlml', 'health', 'informatic', 'deep', 'learn', 'algorithm', 'health', 'informatic', 'device', 'introduction', 'fundamental', 'use', 'deep', 'learning', 'neural', 'network', 'commence', 'result', 'expert', 'study', 'complex', 'neuron', 'layer', 'architectural', 'paradigm', 'study', 'allow', 'monitor', 'datum', 'extended', 'layer', 'pipeline', 'nonlinear', 'output', 'generate', 'low', 'dimensional', 'input', 'space', 'projection', 'health', 'informatic', 'involve', 'generation', 'automatic', 'character', 'set', 'human', 'cell', 'expert', 'intrusion', 'medical', 'imaging', 'health', 'informatic', 'elaborate', 'determine', 'implicit', 'internal', 'organ', 'fibroid', 'polyp', 'tissue', 'irregularity', 'also', 'use', 'study', 'morphological', 'tumor', 'fakoor', 'biologically', 'health', 'informatic', 'anticipate', 'translational', 'feature', 'utilize', 'rna', 'sequential', 'protein', 'strand', 'convolutional', 'neural', 'net', 'cnn', 'deep', 'learning', 'approach', 'health', 'informatic', 'architectural', 'layer', 'filter', 'reduce', 'rectifying', 'modifying', 'poohe', 'layer', 'layer', 'help', 'originate', 'abstract', 'feature', 'find', 'visual', 'cortex', 'receptive', 'field', 'architecture', 'restructure', 'machine', 'deep', 'belief', 'network', 'dbns', 'stack', 'autoencoder', 'extend', 'network', 'recurrent', 'neural', 'net', 'rnn', 'assist', 'advancement', 'graphical', 'process', 'unit', 'gpus', 'impact', 'growth', 'deep', 'learning', 'application', 'expert', 'previously', 'propose', 'pregpu', 'cnn', 'parallel', 'algebraic', 'operation', 'matrix', 'need', 'experiment', 'clinic', 'integrate', 'deep', 'learning', 'architecture', 'health', 'informatic', 'essential', 'label', 'datum', 'implement', 'activation', 'function', 'know', 'transfer', 'function', 'weight', 'transfer', 'function', 'classify', 'linear', 'pattern', 'adjust', 'weight', 'mcclelland', 'propose', 'neural', 'network', 'hidden', 'layer', 'perceptron', 'stage', 'epoch', 'new', 'datum', 'input', 'sample', 'weight', 'neuron', 'adjustable', 'base', 'learning', 'process', 'name', 'delta', 'rule', 'rule', 'network', 'training', 'exploitation', 'backpropagation', 'routine', 'rumelhart', 'observe', 'random', 'value', 'give', 'network', 'weight', 'determine', 'iterative', 'training', 'process', 'minimize', 'difference', 'network', 'output', 'desire', 'rumelhart', 'also', 'study', 'iterative', 'training', 'use', 'gradient', 'descent', 'technique', 'reduce', 'surface', 'error', 'experiment', 'deep', 'learning', 'accelerate', 'supervised', 'unsupervised', 'label', 'datum', 'supervise', 'label', 'datum', 'train', 'deep', 'neural', 'network', 'understand', 'weight', 'minimize', 'error', 'predict', 'target', 'value', 'classify', 'unsupervised', 'label', 'datum', 'meanwhile', 'unsupervised', 'deep', 'learning', 'datum', 'utilize', 'cluster', 'reduction', 'dimension', 'feature', 'extraction', 'artificial', 'neural', 'network', 'variant', 'deep', 'learning', 'architecture', 'autoencod', 'rbm', 'rnn', 'mention', 'assist', 'health', 'informatic', 'prediction', 'diagnosis', 'autoencoder', 'refer', 'feedforwarder', 'twophase', 'network', 'handle', 'encoder', 'decoder', 'task', 'use', 'input', 'hide', 'h', 'represent', 'nonlinear', 'equation', 'state', 'stand', 'nonlinear', 'activation', 'function', 'decode', 'map', 'hide', 'representation', 'thus', 'original', 'hide', 'representation', 'also', 'calculate', 'model', 'parameter', 'optimize', 'minimize', 'error', 'autoencoder', 'variant', 'reconstructing', 'error', 'collection', 'datum', 'sample', 'square', 'error', 'optimization', 'represent', 'sample', 'unsupervised', 'datum', 'h', 'stand', 'hidden', 'representation', 'x', 'datum', 'sample', 'bengio', 'image', 'demonstrate', 'difference', 'physical', 'base', 'conventional', 'datum', 'drive', 'deep', 'learning', 'autoencod', 'conventional', 'autoencoder', 'datamodel', 'require', 'handcraft', 'feature', 'individual', 'train', 'module', 'handle', 'large', 'dataset', 'deep', 'learn', 'autoencod', 'method', 'provide', 'endtoend', 'envision', 'data', 'structure', 'handcraft', 'feature', 'train', 'jointly', 'large', 'dataset', 'fig', 'autoencod', 'schematic', 'illustration', 'accord', 'diagram', 'learn', 'transformation', 'autoencoder', 'sparse', 'constraint', 'implore', 'hide', 'unit', 'optimize', 'function', 'write', 'hide', 'size', 'hide', 'unit', 'conventional', 'autoencoder', 'additional', 'denoising', 'network', 'correct', 'corrupt', 'version', 'datum', 'input', 'reconstruct', 'clean', 'train', 'sample', 'datum', 'also', 'stake', 'structure', 'put', 'together', 'output', 'lth', 'layer', 'input', 'l1tth', 'layer', 'represent', 'high', 'level', 'provide', 'solution', 'deep', 'neural', 'network', 'model', 'vincent', 'rbm', 'variant', 'restrict', 'boltzmann', 'machine', 'twolayer', 'bipartite', 'graph', 'consist', 'visible', 'group', 'know', 'unit', 'hidden', 'unit', 'h', 'asymmetric', 'link', 'connect', 'node', 'rbm', 'model', 'parameter', 'wba', 'energy', 'function', 'wij', 'connect', 'weight', 'unit', 'total', 'number', 'hide', 'unit', 'total', 'number', 'ai', 'show', 'joint', 'rbm', 'distribution', 'unit', 'base', 'energy', 'function', 'equate', 'partitioned', 'functionnormalization', 'factor', 'conditional', 'probability', 'hide', 'visible', 'unit', 'h', 'v', 'p', 'p', 'viivj', 'logistic', 'function', 'wlearning', 'approach', 'achieve', 'use', 'contrastive', 'divergence', 'tool', 'cd', 'deep', 'belief', 'network', 'variant', 'dbn', 'make', 'stack', 'multiple', 'rbm', 'output', 'layer', 'hide', 'unit', 'input', 'l1', 'visible', 'layer', 'dbn', 'common', 'similarity', 'sda', 'large', 'layer', 'unsupervised', 'pattern', 'handle', 'pretraine', 'data', 'parameter', 'deep', 'boltzmann', 'machine', 'learning', 'approach', 'contain', 'hidden', 'unit', 'group', 'layer', 'single', 'connectivity', 'constraint', 'full', 'connection', 'find', 'subsequent', 'non', 'neighboring', 'layer', 'convolutional', 'neural', 'network', 'variant', 'utilize', 'perform', 'image', 'spatial', 'processing', 'weight', 'pool', 'property', 'serve', 'purpose', 'authenticate', 'natural', 'language', 'speech', 'recognition', 'help', 'learn', 'alternate', 'abstract', 'feature', 'stack', 'convolution', 'pool', 'operation', 'dimensional', 'cnn', 'compare', 'onedimensional', 'model', 'use', 'input', 'sequence', 'datum', 'xxi', 'represent', 'length', 'sequence', 'vid', 'respectively', 'convolutional', 'dot', 'production', 'filter', 'vector', 'u', 'ci', 'stand', 'matrix', 'output', 'ci', 'see', 'activate', 'filter', 'u', 'correspond', 'slide', 'filter', 'window', 'feature', 'map', 'vector', 'lm1', 'represent', 'index', 'filter', 'correspond', 'multiwindow', 'maxpoole', 'layer', 'capable', 'reduce', 'length', 'feature', 'map', 'minimize', 'number', 'model', 'parameter', 'hypermeter', 'pool', 'layer', 'denotation', 'max', 'operation', 'consecutive', 'value', 'feature', 'map', 'cj', 'compressed', 'feature', 'h', 'h', 'h2', 's1', 's1', 'predict', 'data', 'possibility', 'alternate', 'maxpoole', 'layer', 'fully', 'connect', 'softmax', 'layer', 'recurrent', 'neural', 'network', 'variant', 'schmidhuber', 'highlight', 'arbitrary', 'length', 'sequence', 'pattern', 'input', 'build', 'connection', 'direct', 'cycle', 'multilayer', 'perceptron', 'rnn', 'train', 'back', 'propagate', 'supervised', 'datum', 'subsequent', 'input', 'target', 'dataset', 'jaeger', '’', 'functional', 'transition', 'step', 'show', 'time', 'information', 'move', 'prior', 'hide', 'output', 'update', 'current', 'hidden', 'output', 'nonlinear', 'differential', 'transforming', 'function', 'learn', 'representation', 'show', 'input', 'datum', 'length', 'also', 'conventional', 'multi', 'layer', 'perceptron', 'map', 'obtainable', 'ht', 'representation', 'make', 'prediction', 'successfully', 'simple', 'function', 'vanilla', 'rnn', 'equate', 'asht', 'h', 'represent', 'transformation', 'matrix', 'bias', 'vector', 'vanilla', 'rnn', 'suffer', 'vanish', 'gradient', 'problem', 'backpropagation', 'easily', 'restore', 'lstm', 'gate', 'recurrent', 'neural', 'network', 'gru', 'prevent', 'error', 'explosion', 'chung', 'et', 'al201465', 'advanced', 'version', 'lstm', 'multilayer', 'recurrent', 'bidirectional', 'model', 'capable', 'offer', 'structural', 'flexibility', 'fig', 'onelayer', 'pool', 'layer', 'fully', 'connect', 'softmax', 'layer', 'health', 'monitoring', 'application', 'wearable', 'rise', 'implement', 'hierarchical', 'clustering', 'method', 'detect', 'mammographic', 'image', 'datum', 'image', 'show', 'health', 'monitoring', 'application', 'necessary', 'capture', 'array', 'pervasive', 'sensor', 'wear', 'implant', 'body', 'capture', 'ambient', 'inertia', 'motion', 'ecg', 'patch', 'smart', 'watch', 'eeg', 'prosthetic', 'pervasive', 'sensor', 'wearable', 'implant', 'ambient', 'sensor', 'monitor', 'human', 'health', 'accurately', 'estimate', 'food', 'intake', 'energy', 'expenditure', 'tackle', 'obesity', 'chronic', 'disease', 'care', 'patient', 'disability', 'patient', 'undergo', 'rehabilitation', 'critical', 'care', 'situation', 'often', 'implant', 'assist', 'device', 'check', 'vital', 'sign', 'pouladzadeh', 'epidemic', 'escalation', 'healthrelate', 'issue', 'obesity', 'cardiovascular', 'disease', 'control', 'energy', 'expenditureactivity', 'recognition', 'tool', 'control', 'amount', 'diet', 'monitor', 'calorie', 'intake', 'alternatively', 'use', 'recognize', 'monitor', 'accurately', 'food', 'intake', 'adopt', 'cloud', 'compute', 'sizecalibrating', 'distance', 'estimation', 'tool', 'pouladzadeh', 'combine', 'dl', 'method', 'invariant', 'hierarchical', 'representation', 'video', 'use', 'twolayer', 'convolution', 'maxpoole', 'large', 'input', 'recognize', 'human', 'daily', 'activity', 'yalcin', 'use', 'dvideo', 'sequence', 'classify', 'human', 'activity', 'surveillance', 'elderly', 'child', 'care', 'clinic', 'detection', 'baby', 'fall', 'crawl', 'alert', 'caregiver', 'raise', 'alarm', 'rbms', 'work', 'together', 'smartphone', 'watch', 'assist', 'device', 'audio', 'feedback', 'application', 'specifically', 'use', 'detect', 'visual', 'impairment', 'assistive', 'device', 'consist', 'algorithm', 'recognize', 'hand', 'gesture', 'sign', 'language', 'sterile', 'surrounding', 'permit', 'touchless', 'humancomputerinteraction', 'introduce', 'deep', 'neural', 'network', 'dnn', 'sign', 'language', 'recognition', 'use', 'realsense', 'datum', 'coordinate', 'finger', 'joint', 'input', 'handcraft', 'feature', 'dl', 'machine', 'ensure', 'health', 'monitoring', 'achieve', 'discrete', 'target', 'value', 'apply', 'softmax', 'later', 'prognosis', 'linear', 'regression', 'layer', 'limit', 'human', 'labor', 'expert', 'skill', 'sun', 'use', 'onelayer', 'autoencod', 'neural', 'network', 'classify', 'health', 'machine', 'motor', 'fault', 'recognition', 'repair', 'diagnose', 'rotary', 'health', 'machine', 'fault', 'component', 'stack', 'denoise', 'hide', 'notable', 'layer', 'device', 'vital', 'sign', 'build', 'dl', 'application', 'technology', 'advancement', 'bring', 'wearable', 'photo', 'video', 'attach', 'outfits', 'embed', 'sensor', 'place', 'chair', 'car', 'seat', 'mattress', 'eg', 'fitbit', 'wrist', 'band', 'tracker', 'control', 'mobile', 'app', 'addon', 'expert', 'study', 'use', 'genetic', 'triaxle', 'know', 'bracelet', 'trace', 'walk', 'pattern', 'fall', 'seizure', 'inpatient', 'research', 'declare', 'prolong', 'sedentary', 'lifestyle', 'cause', 'adverse', 'health', 'outcome', 'make', 'clinician', 'adopt', 'use', 'wearable', 'device', 'monitor', 'patient', 'health', 'advice', 'physical', 'activity', 'necessary', 'choo', 'use', 'wearable', 'device', 'trace', 'language', 'pattern', 'motherchild', 'connection', 'childhood', 'psychological', 'development', 'choi', 'monitor', 'stress', 'pattern', 'use', 'mentally', 'equip', 'sensor', 'power', 'mldl', 'understand', 'stress', 'child', 'adult', 'follow', 'heartbeat', 'blood', 'pressure', 'temperature', 'accord', 'research', 'electrodermal', 'activity', 'tool', 'eda', 'know', 'emotion', 'board', 'help', 'measure', 'skin', 'reaction', 'stress', 'however', 'svm', 'lda', 'help', 'classify', 'stress', 'show', 'result', 'monitor', 'heat', 'stroke', 'use', 'fuzzy', 'logic', 'technique', 'display', 'inferential', 'signal', 'smart', 'device', 'design', 'wireless', 'communication', 'profoundly', 'change', 'patient', 'management', 'diagnostic', 'device', 'em', 'emergency', 'medical', 'service', 'use', 'emergency', 'room', 'icu', 'icu', 'system', 'reveal', 'vital', 'sign', 'extent', 'detect', 'patient', 'postureposition', 'toxic', 'gas', 'heat', 'flux', 'winokur', 'find', 'wearable', 'device', 'valuable', 'monitor', 'heart', 'rate', 'recording', 'ecg', 'representation', 'sternal', 'seismocardiogram', 'introduce', 'ear', 'device', 'wearable', 'cardiometer', 'defibrillator', 'prevent', 'arrhythmic', 'sudden', 'death', 'patient', 'fryar', 'detect', 'hypertension', 'physiological', 'signal', 'cerebral', 'blood', 'flowmeter', 'estimate', 'hemodynamic', 'cephalic', 'symptom', 'patient', 'deep', 'learn', 'architecture', 'description', 'key', 'point', 'deep', 'learning', 'network', 'framework', 'classify', 'regress', 'datum', 'hide', 'visible', 'output', 'layer', 'hide', 'layer', 'allow', 'expression', 'complex', 'nonlinear', 'hypothesis', 'deep', 'neural', 'network', 'successfully', 'use', 'bioinformatics', 'lack', 'training', 'authentication', 'back', 'propagate', 'layer', 'slow', 'learning', 'process', 'salakhutdinov', 'discuss', 'deep', 'autoencoder', 'design', 'extract', 'feature', 'later', 'dimensional', 'reduction', 'input', 'hide', 'output', 'layer', 'deep', 'autoencoder', 'consist', 'similar', 'input', 'output', 'node', 'help', 'recreate', 'input', 'vector', 'handle', 'unsupervised', 'learning', 'technique', 'deep', 'autoencoder', 'vital', 'label', 'datum', 'robust', 'representation', 'however', 'need', 'pretraine', 'undergo', 'full', 'training', 'process', 'deep', 'belief', 'network', 'rbm', 'composition', 'subnetwork', 'hidden', 'layer', 'visible', 'layer', 'undirected', 'connection', 'layer', 'permit', 'unsupervised', 'supervised', 'training', 'network', 'initialize', 'network', 'command', 'inference', 'trace', 'handle', 'sample', 'process', 'training', 'procedure', 'hinton', 'salakhutdinov', 'state', 'difference', 'deep', 'belief', 'network', 'deep', 'boltzmann', 'machine', 'network', 'accord', 'lay', 'emphasis', 'boltzmann', 'conditional', 'independent', 'layer', 'undirecte', 'use', 'stochastic', 'algorithm', 'maximize', 'low', 'bound', 'incorporate', 'robust', 'inference', 'ambiguous', 'input', 'boltzman', 'also', 'handle', 'complex', 'time', 'inference', 'high', 'dbn', 'optimize', 'large', 'dataset', 'parameter', 'continual', 'progression', 'neural', 'network', 'lead', 'proposition', 'recurrent', 'neural', 'network', 'capacity', 'analyze', 'huge', 'data', 'streams', 'memorize', 'sequential', 'event', 'model', 'time', 'dependency', 'process', 'natural', 'language', 'recurrent', 'neural', 'network', 'face', 'challenge', 'vanish', 'explode', 'gradient', 'zipser', 'convolutional', 'neural', 'network', 'communicably', 'use', 'quite', 'compatible', 'datum', 'transform', 'filter', 'input', 'output', 'neuron', 'activation', 'lecun', 'support', 'neurobiological', 'modeling', 'perform', 'visual', 'cortex', 'use', 'flow', 'neuron', 'connection', 'many', 'varied', 'application', 'main', 'challenge', 'hierarchical', 'visual', 'feature', 'use', 'input', 'large', 'label', 'dataset', 'parallel', 'acceleration', 'offer', 'hardware', 'capacity', 'need', 'compute', 'dnn', 'cloud', 'multicore', 'processor', 'recurrent', 'neural', 'network', 'come', 'hide', 'capacity', 'analyze', 'several', 'datum', 'make', 'bengio', 'discuss', 'rnn', 'variation', 'call', 'term', 'memory', 'unit', 'lstm', 'lstm', 'solve', 'gradient', 'vanish', 'problem', 'use', 'longinput', 'sequence', 'lstm', 'use', 'exploit', 'store', 'information', 'write', 'read', 'information', 'error', 'train', '’', 'compatible', 'rnn', 'share', 'weight', 'aid', 'natural', 'language', 'processing', 'modeling', 'speech', 'recognition', 'image', 'description', 'ackley', 'emphasize', 'variant', 'boltzmann', 'machine', 'rbm', 'type', 'stochastic', 'neural', 'network', 'gaussian', 'procedure', 'call', 'gibb', 'sample', 'gibb', 'sample', 'adjust', 'weight', 'minimize', 'error', 'model', 'variable', 'relationship', 'probability', 'review', 'graphical', 'probability', 'model', 'stochastic', 'unit', 'characterize', 'conditional', 'independence', 'variable', 'direct', 'acyclic', 'graph', 'carreira', 'mention', 'contrastive', 'divergence', 'cd', 'use', 'conjunction', 'rbm', 'handle', 'unsupervised', 'learning', 'algorithm', 'positive', 'negative', 'phase', 'positive', 'phase', 'encourage', 'network', 'configuration', 'negative', 'phase', 'recreate', 'current', 'network', 'configuration', 'regular', 'correlate', 'local', 'datum', 'multidimensional', 'input', 'significant', 'backpropagation', 'adjusting', 'number', 'parameter', 'support', 'neurobiological', 'visual', 'cortex', 'model', 'visual', 'cortex', 'receptive', 'local', 'field', 'map', 'move', 'granularity', 'anterior', 'image', 'input', 'convolved', 'subsample', 'output', 'small', 'filter', 'wiesel', 'dnn', 'learn', 'architecture', 'deep', 'neural', 'network', 'architecture', 'know', 'inputoutput', 'deep', 'architecture', 'ioda', 'resolve', 'different', 'image', 'labeling', 'issue', 'assign', 'label', 'image', 'pixel', 'dnn', 'service', 'hyperspectral', 'image', 'spectral', 'spatial', 'feature', 'come', 'together', 'form', 'hierarchical', 'model', 'characterize', 'human', 'body', 'issue', 'kondo', 'employ', 'group', 'method', 'datum', 'handle', 'gmdh', 'hybrid', 'multilayer', 'neural', 'process', 'authenticate', 'polynomial', 'activate', 'function', 'essence', 'gmdh', 'recognize', 'liver', 'spleen', 'datum', 'perform', 'principal', 'component', 'regression', 'analysis', 'technique', 'use', 'identify', 'cancer', 'mcyarduim', 'right', 'leave', 'kidney', 'issue', 'application', 'deep', 'neural', 'network', 'translational', 'bioinformatics', 'table', 'demonstrate', 'software', 'explore', 'cubanvidia', 'aid', 'acceleration', 'use', 'provide', 'cloud', 'training', 'process', 'system', 'combination', 'neuromorphic', 'electronic', 'system', 'hardware', 'computational', 'neuroscience', 'simulation', 'conduct', 'neuron', 'synapsis', 'chip', 'integrate', 'hardware', 'true', 'north', 'spinnaker', 'intel', 'main', 'purpose', 'bioinformatics', 'discipline', 'explore', 'investigate', 'understand', 'biological', 'molecular', 'level', 'process', 'human', 'genome', 'project', 'research', 'raw', 'datum', 'develop', 'new', 'hypothesis', 'gene', 'environmental', 'factor', 'relate', 'creation', 'human', 'genetic', 'protein', 'diagnose', 'disease', 'use', 'biotechnology', 'first', 'human', 'genome', 'motivate', 'principle', 'p4', 'personalize', 'preventive', 'participatory', 'predictive', 'medicine', 'hood', 'predictive', 'health', 'informatic', 'hold', 'attribute', 'encode', 'dna', 'live', 'analyze', 'allele', 'environmental', 'factor', 'lead', 'disease', 'cancer', 'design', 'target', 'therapeutic', 'procedure', 'remedy', 'leung', 'et', 'al201623', 'concept', 'pharmacogenomic', 'focus', 'evaluate', 'variety', 'drug', 'response', 'generelate', 'treatment', 'aliment', 'especially', 'personalize', 'diagnosis', 'side', 'effect', 'epigenomic', 'investigate', 'interactive', 'protein', 'higherlevel', 'process', 'response', 'transcriptome', 'mrna', 'proteome', 'metabolome', 'gene', 'response', 'environment', 'genetic', 'variant', 'uniquely', 'design', 'slicing', 'code', 'predict', 'difference', 'human', 'tissue', 'especially', 'change', 'result', 'genetic', 'variation', 'alternate', 'slice', 'code', 'help', 'technically', 'generate', 'gene', 'prediction', 'slice', 'pattern', 'mean', 'comprehend', 'gene', 'phenotype', 'drug', 'effect', 'autism', 'spinal', 'muscular', 'atrophy', 'hereditary', 'cancer', 'quantitative', 'activity', 'structure', 'relationship', 'mean', 'predict', 'proteinprotein', 'coordination', 'usually', 'structure', 'molecular', 'information', 'compound', 'interactive', 'protein', 'predict', 'protein', 'use', 'drug', 'discovery', 'compound', 'interactive', 'protein', 'virtual', 'analysis', 'influence', 'discovery', 'new', 'compound', 'toxic', 'substance', 'interpretation', 'drug', 'relate', 'target', 'cell', 'health', 'informatic', 'deep', 'learning', 'model', 'utilize', 'enhance', 'dna', 'methylation', 'provide', 'visible', 'outlook', 'human', 'chromosome', 'use', 'identify', 'unstable', 'chromosome', 'error', 'translation', 'cell', 'transcription', 'differentiation', 'cancer', 'progression', 'angermueller', 'al201624', 'pasturromay', 'name', 'chembl', 'database', 'pharmacogenomic', 'detect', 'million', 'compound', 'description', 'use', 'develop', 'target', 'drug', 'evolution', 'mention', 'database', 'encrypt', 'molecular', 'fingerprint', 'understand', 'traditional', 'ml', 'approach', 'chembl', 'database', 'also', 'help', 'reduce', 'datum', 'complexity', 'molecular', 'rna', 'bind', 'predictive', 'protein', 'together', 'use', 'structural', 'tertiary', 'profile', 'outcome', 'utilize', 'autoencod', 'model', 'explore', 'genetic', 'datum', 'diverse', 'cancer', 'patient', 'identify', 'similar', 'microarray', 'dataset', 'et', 'al2014', 'detail', 'effect', 'active', 'learning', 'method', 'use', 'dbn', 'feature', 'microrna', 'classify', 'performance', 'different', 'cancer', 'disease', 'hepatocellular', 'carcinoma', 'deep', 'learning', 'approach', 'adopt', 'beat', 'breast', 'cancer', 'disease', 'attribute', 'noise', 'combination', 'network', 'help', 'extraction', 'microarray', 'datum', 'expert', 'consider', 'deep', 'learn', 'effective', 'svm', 'detect', 'slice', 'code', 'different', 'genetic', 'variant', 'accord', 'angermueller', 'dnn', 'predict', 'dna', 'methylation', 'incomplete', 'sequence', 'methylate', 'datum', 'also', 'predict', 'embryonic', 'stem', 'cell', 'baseline', 'comparison', 'show', 'genome', 'downstream', 'demonstration', 'deep', 'learning', 'mention', 'outpace', 'conventional', 'technique', 'kerne', 'use', 'graph', 'convolution', 'encrypt', 'molecular', 'feature', 'physical', 'property', 'assay', 'activity', 'permit', 'potential', 'collaboration', 'molecular', 'encode', 'information', 'deep', 'learning', 'use', 'medical', 'imaging', 'procedure', 'expert', 'find', 'relevant', 'diagnose', 'illness', 'interpret', 'medical', 'image', 'process', 'conversantly', 'enable', 'computeraide', 'diagnosis', 'assimilate', 'cause', 'disease', 'model', 'help', 'identify', 'cause', 'neurological', 'alzheimer', 'sclerosis', 'stroke', 'progression', 'brain', 'scan', 'multimodal', 'mapping', 'infected', 'region', 'year', 'computer', 'vision', 'especially', 'ability', 'personalize', 'show', 'parallel', 'brain', 'pathology', 'far', 'demonstrate', 'segmentation', 'shape', 'analysis', 'human', 'brain', 'help', 'overcome', 'challenge', 'difference', 'intensity', 'shape', 'tumor', 'lesion', 'use', 'image', 'protocol', 'issue', 'associate', 'include', 'pathological', 'tissue', 'overlap', 'healthy', 'sample', 'riciannoise', 'nonisotropic', 'issue', 'bias', 'field', 'effect', 'evident', 'magnetic', 'resonance', 'image', 'mri', 'sometimes', 'mri', 'handle', 'automatically', 'require', 'similar', 'ml', 'approach', 'decrypt', 'datum', 'complexity', 'extract', 'feature', 'conventional', 'approach', 'deep', 'learning', 'approach', 'work', 'well', 'term', 'datum', 'manipulation', 'operate', 'patch', 'image', 'abnormal', 'tissue', 'eg', 'cnn', 'medical', 'imaging', 'lung', 'disease', 'coordinate', 'compute', 'tomography', 'image', 'expert', 'use', 'ct', 'imaging', 'application', 'classify', 'manifestation', 'tuberculosis', 'cell', 'neural', 'progenitor', 'somatic', 'source', 'hemorrhage', 'color', 'image', 'detection', 'classify', 'different', 'anatomy', 'understand', 'human', 'organ', 'recognition', 'use', 'multistage', 'framework', 'extract', 'patch', 'pretraine', 'stage', 'jamaluddin', 'seem', 'essential', 'use', 'segmentation', 'isotense', 'brain', 'tissue', 'brain', 'extraction', 'multimodality', 'image', 'tool', 'avendi', 'describe', 'algorithm', 'encode', 'deformable', 'model', 'parameter', 'facilitate', 'leave', 'ventricle', 'segmentation', 'necessary', 'shortaxis', 'cardiac', 'tool', 'image', 'component', 'segment', 'ct', 'format', 'eradicate', 'issue', 'find', 'anisotropic', 'adopt', 'orthogonal', 'patch', 'extraction', 'segment', 'axis', 'sagittal', 'corona', 'view', 'reduce', 'time', 'overfitting', 'problem', 'fritscher', 'al201633', 'common', 'limitation', 'include', 'nonspatial', 'dependency', 'need', 'pre', 'processing', 'bring', 'conditional', 'random', 'field', 'issue', 'alter', 'substitute', 'conventional', 'ml', 'approach', 'solve', 'problem', 'incomplete', 'datum', 'training', 'limit', 'annotate', 'datum', 'costtime', 'manual', 'medical', 'image', 'annotation', 'previously', 'manual', 'annotation', 'accept', 'help', 'detection', 'medical', 'image', 'crowdsource', 'accord', 'viable', 'alternative', 'affordability', 'errorfree', 'medical', 'image', 'analysis', 'havaei', 'use', 'transfer', 'learn', 'finetune', 'approach', 'alleviate', 'incomplete', 'training', 'issue', 'allow', 'pretraine', 'datum', 'label', 'manually', 'describe', 'similarity', 'natural', 'image', 'medical', 'image', 'use', 'finetune', 'process', 'repeat', 'experiment', 'apply', 'transfer', 'learn', 'natural', 'image', 'thoraxlymph', 'node', 'detect', 'lung', 'disease', 'result', 'show', 'consistency', 'performance', 'loss', 'identify', 'fetal', 'abdominal', 'standard', 'transfer', 'learn', 'approach', 'display', 'lowlayer', 'pretraine', 'effect', 'natural', 'image', 'implement', 'multitaske', 'handle', 'image', 'imbalance', 'utilize', 'denoise', 'autoencod', 'diagnose', 'breast', 'legion', 'pulmonary', 'nodule', 'ct', 'scan', '37trie', 'stack', 'sparse', 'autoencoder', 'microaneurysm', 'image', 'detect', 'diabetic', 'retinopathy', 'use', 'softmax', 'output', 'layer', 'show', 'prediction', 'functional', 'magnetic', 'resonance', 'image', 'use', 'rbm', 'method', 'effect', 'biomarker', 'mri', 'position', 'emission', 'tomography', 'pet', 'result', 'show', 'accuracy', 'discriminate', 'attention', 'deficit', 'hyperactivity', 'disorder', 'fmri', 'application', 'hence', 'expert', 'extract', 'rbm', 'latent', 'hierarchical', 'patch', 'feature', 'brain', 'use', 'image', 'segment', 'tool', 'brosch', 'implore', 'manifold', 'learning', 'method', 'study', 'brain', 'image', 'full', 'automated', 'shape', 'cranial', 'nerve', 'deep', 'learning', 'method', 'know', 'outpace', 'conventional', 'approach', 'lowcontact', 'optic', 'tract', 'human', 'pathological', 'anatomy', 'beaulieujone', 'find', 'pipeline', 'model', 'relevant', 'detect', 'segment', 'object', 'achieve', 'automatic', 'volumetric', 'image', 'process', 'call', 'marginal', 'space', 'handle', 'hierarchical', 'marginal', 'spacing', 'automatic', 'feature', 'detect', 'deep', 'learning', 'dataset', 'literature', 'review', 'unsupervised', 'learning', 'technique', 'characterize', 'unlabeled', 'dataset', 'use', 'metric', 'lowhigh', 'dimensional', 'subspace', 'anomaly', 'detect', 'cluster', 'datum', 'eg', 'prediction', 'heart', 'hepatitis', 'disease', 'collin', 'define', 'prognosis', 'method', 'predict', 'disease', 'clinical', 'practice', 'setting', 'show', 'multimodal', 'datum', 'use', 'prognosis', 'diagnose', 'diabetic', 'register', 'electronic', 'health', 'datum', 'record', 'medical', 'image', 'analysis', 'follow', 'enhancement', 'detection', 'classification', 'segmentation', 'procedure', 'reconstruct', 'store', 'datum', 'implement', 'reconstruction', 'mri', 'ct', 'image', 'dataset', 'use', 'generative', 'adversarial', 'network', 'gan', 'generative', 'adversarial', 'network', 'gan', 'offer', 'mri', 'reconstruction', 'clean', 'motion', 'picture', 'artifact', 'handle', 'image', 'fusion', 'registration', 'elgamal', 'note', 'significance', 'image', 'registration', 'surgical', 'spine', 'implant', 'tumor', 'removal', 'neurosurgical', 'process', 'develop', 'image', 'registration', 'framework', 'call', 'quick', 'silver', 'large', 'deformation', 'mapping', 'diffeomorphic', 'metric', 'prediction', 'image', 'registration', 'datum', 'retrieval', 'enable', 'physician', 'check', 'large', 'image', 'patient', 'repeat', 'visit', 'clinic', 'zech', 'share', 'natural', 'language', 'processing', 'method', 'annotate', 'retrieve', 'image', 'clinical', 'radiological', 'report', 'achieve', 'realtime', 'health', 'monitoring', 'wearable', 'iot', 'sensor', 'smart', 'device', 'cloud', 'integrate', 'smart', 'device', 'attain', 'required', 'result', 'dl', 'find', 'place', 'clinical', 'workflow', 'predict', 'diagnosing', 'diabetes', 'dengue', 'heart', 'liver', 'disease', 'advanced', 'system', 'cadx', 'display', 'automatically', 'fatty', 'liver', 'kurtosis', 'image', 'utilize', 'clinical', 'reinforcement', 'learning', 'study', 'optimal', 'diagnosis', 'treat', 'patient', 'characterize', 'performance', 'evaluation', 'different', 'method', 'value', 'iteration', 'tabular', 'learn', 'qiteration', 'deep', 'qlearne', 'rl', 'method', 'help', 'treat', 'sepsis', 'intensive', 'care', 'unit', 'clinical', 'timeserie', 'datum', 'study', 'provide', 'medical', 'intervention', 'patient', 'intensive', 'care', 'unit', 'use', 'lstm', 'predict', 'traumatic', 'brain', 'damage', 'estimate', 'meanvariance', 'arterial', 'blood', 'pressure', 'intracranial', 'pressure', 'monitoring', 'recently', 'expert', 'adopt', 'attention', 'model', 'forecast', 'icu', 'activity', 'integrate', 'multivariance', 'timeserie', 'measurement', 'control', 'unexpected', 'respiratory', 'issue', 'control', 'nip', 'challenge', 'use', 'clamp', 'toolkit', 'monitor', 'different', 'state', 'clinical', 'text', 'analysis', 'language', 'acronym', 'disparity', 'quality', 'variance', 'several', 'doctor', 'study', 'clinical', 'documentation', 'especially', 'use', 'clinical', 'speech', 'audio', 'processing', 'minimize', 'time', 'spend', 'administrative', 'task', 'medical', 'report', 'wallace', 'speech', 'audio', 'processing', 'serve', 'purpose', 'identify', 'disorder', 'use', 'vocal', 'hyperfunctional', 'tool', 'review', 'patient', 'dementia', 'alzheimer', 'limitation', 'privacy', 'security', 'challenge', 'primary', 'limitation', 'discover', 'deep', 'learning', 'algorithm', 'issue', 'datum', 'collection', 'vulnerability', 'experience', 'dl', 'adoption', 'large', 'dataset', 'also', 'consume', 'time', 'human', 'effort', 'problem', 'incorrect', 'alter', 'dataset', 'lead', 'wrong', 'diagnosis', 'disclose', 'instrumental', 'environmental', 'noise', 'smart', 'machine', 'cause', 'unnecessary', 'disturbance', 'especially', 'mri', 'multishot', 'high', 'sensitive', 'modalmotion', 'increase', 'risk', 'misdiagnosis', 'mistake', 'artifact', 'detrimental', 'human', 'health', 'unqualified', 'physician', 'knowledge', 'datum', 'analytic', 'commit', 'unforgivable', 'error', 'medical', 'diagnosis', 'caruana', 'explain', 'difficulty', 'datum', 'labeling', 'annotation', 'lament', 'ambiguous', 'medical', 'image', 'classification', 'lead', 'confusion', 'disagreement', 'physician', 'indicate', 'use', 'inappropriate', 'algorithm', 'detrimental', 'lifethreatene', 'improper', 'annotation', 'happen', 'suggest', 'use', 'meticulous', 'approach', 'labeling', 'dataset', 'limit', 'inefficiency', 'limited', 'imbalance', 'dataset', 'wrong', 'diagnosis', 'cause', 'death', 'million', 'miss', 'datum', 'sparsity', 'value', 'lead', 'unmeasured', 'repetition', 'take', 'sample', 'biggio', 'view', 'model', 'training', 'vulnerability', 'improper', 'training', 'incomplete', 'breach', 'privacy', 'cause', 'model', 'poisoning', 'datum', 'theft', 'corrupt', 'already', 'collect', 'datum', 'know', 'datum', 'poisoning', 'require', 'security', 'especially', 'digital', 'forensic', 'biometric', 'case', 'compromise', 'deep', 'learning', 'deployment', 'realistic', 'healthcare', 'setting', 'experience', 'distribution', 'shift', 'lead', 'incomplete', 'datum', 'vulnerability', 'testing', 'phase', 'security', 'recommendation', 'numerous', 'security', 'threat', 'influence', 'violation', 'associate', 'dl', 'algorithm', 'constitute', 'integrity', 'attack', 'vulnerability', 'act', 'destroy', 'progress', 'dl', 'health', 'field', 'science', 'mention', 'adversarial', 'machine', 'learning', 'vulnerability', 'insert', 'input', 'sample', 'evade', 'privacy', 'datum', 'integrity', 'data', 'breach', 'cause', 'modal', 'poisoning', 'privacy', 'evasion', 'clinical', 'deep', 'learning', 'application', 'constantly', 'attack', 'however', 'safety', 'privacy', 'ethical', 'regulation', 'policy', 'reinstall', 'ensure', 'quality', 'datum', 'exchange', 'standard', 'recommend', 'commodity', 'datum', 'cryptography', 'control', 'datum', 'breach', 'naïve', 'baye', 'classifier', 'suggest', 'use', 'polynomial', 'aggregation', 'random', 'masking', 'protect', 'nonlinear', 'kernel', 'algorithm', 'indicate', 'datum', 'privacy', 'reassure', 'trim', 'tool', 'protect', 'linear', 'creation', 'lui', 'ascertain', 'framework', 'secure', 'xmpp', 'serve', 'name', 'pailli', 'homomorphic', 'encryption', 'security', 'network', 'fknncbr', 'use', 'rescue', 'liver', 'patient', 'hospital', 'suggest', 'homomorphic', 'encryption', 'deep', 'neural', 'network', 'control', 'dataset', 'repository', 'guarantee', 'safety', 'logistic', 'regression', 'recommend', 'homomorphic', 'encryption', 'secure', 'medical', 'binary', 'dataset', 'update', 'healthcare', 'infrastructure', 'finlayson', 'suggest', 'use', 'international', 'classification', 'disease', 'system', 'help', 'minimize', 'dataset', 'vulnerability', 'privacy', 'preserve', 'cryptographic', 'approach', 'homomorphic', 'encryption', 'garble', 'circuit', 'secure', 'processor', 'intel', 'sgx', 'processor', 'offer', 'confidentiality', 'authorized', 'access', 'system', 'kmean', 'decision', 'tree', 'svm', 'ohrimenko', 'add', 'federated', 'learning', 'method', 'distribute', 'data', 'decentralize', 'scheme', 'predict', 'heartrelated', 'disease', 'control', 'adversarial', 'attack', 'important', 'modify', 'model', 'use', 'defensive', 'distillation', 'network', 'verification', 'gradient', 'regularization', 'classifier', 'robustification', 'conclusion', 'deep', 'learning', 'health', 'informatic', 'algorithm', 'continually', 'expand', 'branch', 'science', 'wearable', 'smart', 'monitoring', 'device', 'presently', 'use', 'track', 'diagnose', 'parkinson', 'disease', 'glass', 'conduct', 'prototype', 'child', 'therapeutic', 'analysis', 'monitor', 'diagnose', 'autism', 'spectrum', 'disorder', 'preserve', 'mental', 'health', 'psychiatric', 'hospital', 'screen', 'diagnose', 'monitoring', 'depression', 'systemonchip', 'solution', 'accelerate', 'filter', 'reveal', 'heart', 'rate', 'ecg', 'smart', 'monitoring', 'device', 'unique', 'compatible', 'embed', 'dl', 'simple', 'operate', 'however', 'age', 'adult', 'find', 'challenge', 'future', 'dl', 'health', 'informatic', 'depend', 'recent', 'g', 'wireless', 'network', 'propose', 'bring', 'new', 'device', 'test', 'red', 'protein', 'hemoglobin', 'especially', 'transport', 'oxygen', 'blood', 'accuracy', 'clinical', 'result', 'validate', 'crossvalidation', 'approach', 'unravel', 'result', 'reference', 'fakoor', 'r', 'ladhak', 'huber', 'use', 'deep', 'learning', 'enhance', 'cancer', 'diagnosis', 'classiﬁcation', 'ngiam', 'coate', 'lahiri', 'prochnow', 'b', 'q', 'optimization', 'method', 'deep', 'learning', 'icml', '2011pp', 'mcclelland', 'e', 'parallel', 'distribute', 'processing', 'mit', 'press', 'vol', 'rumelhart', 'neurocomputing', 'foundation', 'research', 'anderson', 'rosenfeld', 'press', 'ch', 'learn', 'representation', 'backpropagate', 'error', 'rise', 'c', 'arel', 'karnowski', 'paquet', 'apply', 'deeplayere', 'cluster', 'mammography', 'image', 'analytic', 'bsec', 'clifford', 'g', 'machine', 'learning', 'decision', 'support', 'critical', 'care', 'proceeding', 'ieee', 'vol', 'pp', 'feb', 'v', 'b', 'peddi', 'shirmohammadi', 'food', 'calorie', 'measurement', 'use', 'deep', 'learn', 'neural', 'network', 'i2mtc', 'sign', 'language', 'recognition', 'use', 'realsense', 'ieee', 'chinasip', 'h', 'human', 'activity', 'recognition', 'use', 'deep', 'belief', 'network', 'salakhutdinov', 'r', 'r', 'reduce', 'dimensionality', 'datum', 'neural', 'network', 'science', 'vol', 'pp', 'hinton', 'osindero', 'teh', 'fast', 'learning', 'deep', 'belief', 'net', 'neural', 'comput', 'vol', 'pp', 'fryar', 'hale', 'hypertension', 'prevalence', 'control', 'adult', 'nch', 'datum', 'brief', 'william', 'learn', 'continually', 'run', 'fully', 'recurrent', 'neural', 'network', 'neural', 'comput', 'vol', 'lecun', 'bottou', 'l', 'bengio', 'haffn', 'gradientbased', 'learning', 'apply', 'document', 'recognition', 'proceeding', 'ieee', 'vol', 'bengio', 'simard', 'p', 'frasconi', 'p', 'learn', 'longterm', 'dependency', 'gradient', 'descent', 'difﬁcult', 'ieee', 'neural', 'vol', 'sejnowski', 'learning', 'relearn', 'boltzmann', 'machine', 'parallel', 'distribute', 'processing', 'exploration', 'microstructure', 'cognition', 'bayesian', 'deep', 'learn', 'survey', 'arxiv', 'eprint', 'apr', 'carreiraperpignan', 'hinton', 'g', 'contrastive', 'divergence', 'learning', 'aistat', 'vol', 'hubel', 'wiesel', 'receptive', 'ﬁeld', 'binocular', 'interaction', 'functional', 'architecture', 'cat', 'visual', 'cortex', 'vol', 'kondo', 'medical', 'image', 'recognition', 'abdominal', 'multiorgan', 'hybrid', 'multilayere', 'gmdhtype', 'neural', 'network', 'use', 'principal', 'component', 'regression', 'analysis', 'pp', 'zaremba', 'sutskever', 'bruna', 'good', 'fellow', 'fergus', 'r', 'intriguing', 'property', 'neural', 'hood', 'l', 'friend', 'predictive', 'personalize', 'preventive', 'participatory', 'p4', 'cancer', 'medicine', 'review', 'clinical', 'oncology', 'vol', 'pp', 'machine', 'learning', 'genomic', 'medicine', 'review', 'computational', 'problem', 'data', 'set', 'proceeding', 'ieee', 'vol', 'pp', 'angermueller', 'parnamaa', 'part', 'l', 'stegle', 'deep', 'learning', 'computational', 'biology', 'molecular', 'system', 'biology', 'vol', 'p', 'pasturromay', 'cedar', 'portopazos', 'deep', 'artiﬁcial', 'neural', 'network', 'morphic', 'chip', 'big', 'datum', 'analysis', 'pharmaceutical', 'bioinformatics', 'application', 'international', 'journal', 'molecular', 'science', 'vol', 'p', 'ibrahim', 'r', 'n', 'ismail', 'elmakky', 'multilevel', 'genemirna', 'feature', 'selection', 'use', 'deep', 'belief', 'net', 'active', 'learning', 'embc', 'da', 'winokur', 'sodini', 'earworn', 'sensor', 'cardiovascular', 'monitoring', 'paper', 'present', 'engineering', 'medicine', 'biology', 'society', 'embc', 'annual', 'international', 'conference', 'ieee', 'winokur', 'wearable', 'cardiac', 'monitor', 'longterm', 'datum', 'acquisition', 'analysis', 'ieee', 'transaction', 'biomedical', 'engineering', 'havaei', 'h', 'jodoin', 'p', 'deep', 'learning', 'trend', 'focal', 'brain', 'pathology', 'segmentation', 'hvan', 'b', 'summer', 'r', 'guest', 'editorial', 'deep', 'learning', 'medical', 'imaging', 'overview', 'future', 'promise', 'exciting', 'new', 'technique', 'ieee', 'pp1153–1159', 'multiinstance', 'deep', 'learning', 'discover', 'discriminative', 'local', 'anatomy', 'body', 'part', 'recognition', 'ieee', 'transme', 'image', 'vol', 'h', 'combined', 'deeplearning', 'deformable', 'model', 'approach', 'fully', 'automatic', 'segmentation', 'left', 'ventricle', 'cardiac', 'mri', 'medical', 'image', 'analysis', 'vol', 'p', 'spadea', 'sharp', 'schubert', 'deep', 'neural', 'network', 'fast', 'segmentation', 'image', 'miccai', 'r', 'nogue', 'mollura', 'r', 'summer', 'deep', 'convolutional', 'neural', 'network', 'computeraided', 'detection', 'architecture', 'dataset', 'characteristic', 'transfer', 'learn', 'ieee', 'standard', 'plane', 'localization', 'fetal', 'ultrasound', 'domain', 'transfer', 'deep', 'neural', 'network', 'ieee', 'biomed', 'health', 'inform', 'vol', 'computeraide', 'diagnosis', 'deep', 'learning', 'architecture', 'application', 'breast', 'lesion', 'image', 'pulmonary', 'nodule', 'ct', 'scan', 'scientiﬁc', 'report', 'vol', 'deep', 'learning', 'method', 'microaneurysm', 'detection', 'fundus', 'image', 'ieee', 'chase', 'robust', 'deep', 'model', 'improved', 'classiﬁcation', 'admci', 'patient', 'ieee', 'biomed', 'health', 'inform', 'vol', 'pp', 'kuang', 'l', 'classiﬁcation', 'adhd', 'deep', 'learning', 'brosch', 'initiative', 'manifold', 'learning', 'brain', 'mris', 'deep', 'learning', 'miccai', 'sun', 'sparse', 'autoencoderbase', 'fault', 'classification', 'induction', 'motor', 'deep', 'neural', 'network', 'approach', 'measurement', 'vol', 'pp', 'fault', 'diagnosis', 'rotary', 'machinery', 'component', 'use', 'stack', 'denoise', 'auto', 'encoderbase', 'health', 'state', 'identification', 'signal', 'processing', 'vol', 'collin', 'machine', 'learning', 'approach', 'data', 'integration', 'disease', 'prediction', 'prognosis', 'apply', 'springer', 'shah', 'tate', 'r', 'shawetaylor', 'h', 'extract', 'diagnosis', 'investigation', 'result', 'unstructured', 'text', 'electronic', 'health', 'record', 'low', 'dose', 'ct', 'residual', 'encoderdecod', 'neural', 'network', 'ieee', 'transaction', 'medical', 'imaging', 'vol', '36no', 'elgamal', 'e', 'elmogy', 'current', 'trend', 'medical', 'image', 'registration', 'fusion', 'egyptian', 'informatic', 'vol', 'zech', 'pain', 'costa', 'bederson', 'natural', 'languagebased', 'machine', 'learning', 'model', 'annotation', 'clinical', 'radiology', 'report', 'radiology', 'vol', 'pp', 'tsui', 'computeraided', 'diagnosis', 'scheme', 'detection', 'fatty', 'liver', 'vivo', 'base', 'ultrasound', 'kurtosis', 'medical', 'system', 'vol', '1p', 'reinforcement', 'learning', 'clinical', 'medicine', 'method', 'optimize', 'dynamic', 'treatment', 'regime', 'time', 'annal', 'translational', 'medicine', 'vol', 'mortality', 'prediction', 'patient', 'isolated', 'moderate', 'severe', 'traumatic', 'brain', 'injury', 'use', 'machine', 'learning', 'model', 'plo', 'vol', 'p', 'wallace', 'role', 'speech', 'recognition', 'clinical', 'documentation', 'nuance', 'available', 'communication', 'online', 'access', 'neveol', 'savova', 'g', 'zweigenbaum', 'p', 'clinical', 'natural', 'language', 'processing', 'language', 'english', 'opportunity', 'challenge', 'biomedical', 'semantic', 'vol', 'p', 'hurst', 'r', 'kendall', 'gotway', 'neural', 'network', 'medical', 'image', 'analysis', 'full', 'training', 'ﬁne', 'tuning', 'ieee', 'transme', 'r', 'automate', 'motion', 'correction', 'multishot', 'mri', 'use', 'generative', 'adversarial', 'network', 'publish', 'workshop', 'paper', '32nd', 'conference', 'neural', 'information', 'processing', 'system', 'nip', 'caruana', 'r', 'intelligible', 'model', 'healthcare', 'predict', 'pneumonia', 'risk', 'hospital', '30day', 'readmission', 'proceeding', '21st', 'international', 'conference', 'knowledge', 'discovery', 'datum', 'mining', 'acm', 'xia', 'yetisgenyildiz', 'clinical', 'corpus', 'annotation', 'challenge', 'strategy', 'proceeding', 'third', 'workshop', 'build', 'evaluate', 'resource', 'biomedical', 'text', 'mining', 'biotxtm’2012', 'conjunction', 'international', 'conference', 'language', 'resource', 'evaluation', 'biggio', 'b', 'laskov', 'p', 'poisoning', 'attack', 'support', 'vector', 'machine', '29th', 'international', 'conference', 'machine', 'learning', 'alfuqaha', 'hamdi', 'adversarial', 'machine', 'learning', 'conundrum', 'insecurity', 'become', 'achille', 'heel', 'cognitive', 'network', 'preprint', 'r', 'c', 'efficient', 'unconditionally', 'secure', 'comparison', 'privacypreserve', 'machine', 'learn', 'classification', 'protocol', 'international', 'conference', 'provable', 'security', 'springer', 'beaulieujone', 'privacypreserving', 'distribute', 'deep', 'learning', 'clinical', 'datum', 'machine', 'learning', 'health', 'ml4h', 'workshop', 'bengio', 'lamblin', 'greedy', 'layerwise', 'training', 'deep', 'network', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'p', 'vincent', 'p', 'larochelle', 'h', 'bengio', 'extract', 'composing', 'robust', 'feature', 'denoise', 'autoencoder', 'proceeding', '25th', 'international', 'conference', 'machine', 'learning', 'acm', 'schmidhuber', 'deep', 'learning', 'neural', 'network', 'overview', 'neural', 'network', 'vol', 'publish', 'online', 'base', 'csne', 'jaeger', 'h', 'tutorial', 'train', 'recurrent', 'neural', 'network', 'cover', 'state', 'network', 'approach', 'gmd', 'schungszentrum', 'informationstechnik', 'empirical', 'evaluation', 'gate', 'recurrent', 'neural', 'network', 'sequence', 'model', 'preprint', 'deep', 'dualpath', 'net', 'automate', 'pulmonary', 'ieee', 'winter', 'conference', 'nodule', 'detection', 'classification', 'application', 'computer', 'vision', 'wacv', 'ieee', 'jagielski', 'oprea', 'b', 'manipulate', 'machine', 'learn', 'poisoning', 'attack', 'countermeasure', 'regression', 'learn', 'ieee', 'symposium', 'security', 'privacy', 'sp', 'ieee', 'malathi', 'logesh', 'r', 'subramaniyaswamy', 'vijayakumar', 'sangaiah', 'hybrid', 'reasoningbase', 'privacyaware', 'disease', 'prediction', 'support', 'system', 'computer', 'electrical', 'engineering', 'vol', 'takabi', 'h', 'hesamifard', 'privacypreserve', 'multiparty', 'machine', 'learn', 'homomorphic', 'encryption', '29th', 'annual', 'conference', 'neural', 'information', 'processing', 'system', 'nip', 'secure', 'logistic', 'regression', 'base', 'homomorphic', 'encryption', 'design', 'evaluation', 'medical', 'informatic', 'vol', 'p', 'e19', 'finlayson', 'bower', 'l', 'kohane', 'adversarial', 'attack', 'medical', 'machine', 'learn', 'science', 'vol', 'ohrimenko', 'schuster', 'fournet', 'mehta', 'nowozin', 'vaswani', 'oblivious', 'multiparty', 'machine', 'learning', 'trust', 'processor', '25th', 'security', 'symposium', 'usenix', 'security', 'moore', 'e', 'ramage', 'hampson', 'learning', 'deep', 'network', 'decentralized', 'datum', 'proceeding', 'international', 'conference', 'artificial', 'intelligence', 'statistic', 'aistat', 'system', 'available', 'online', 'choi', 'biological', 'signalbase', 'stress', 'monitoring', 'framework', 'child', 'use', 'wearable', 'device', 'sensor', 'choo', 'dowell', 'r', 'r', 'talk', 'toddler', 'draw', 'mother', 'perception', 'use', 'wearable', 'mobile', 'technology', 'home', 'study', 'health', 'technology', 'informatic', 'design', 'development', 'wearable', 'device', 'heat', 'stroke', 'detection', 'sensor', 'ravì', 'deep', 'learning', 'health', 'informatic', 'ieee', 'journal', 'biomedical', 'health', 'informatic', 'rui', 'deep', 'learning', 'application', 'machine', 'health', 'monitor', 'survey', 'journal', 'class', 'file', 'vol']"
Deep Learning and Health Informatics for Smart Monitoring and Diagnosis,"[{'href': 'http://arxiv.org/abs/2208.03143v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2208.03143v1', 'rel': 'related', 'type': 'application/pdf'}]",2022-08-05 13:07:59,"2
2
0
2

g
u
A
6
2

]

C
D
.
s
c
[

2
v
5
9
1
2
1
.
8
0
2
2
:
v
i
X
r
a

ExpoCloud: a Framework for Time and
Budget-Eﬀective Parameter Space Explorations Using a
Cloud Compute Engine

Meir Goldenberg1

Jerusalem College of Technology

Abstract

Large parameter space explorations are among the most time consuming yet

critically important tasks in many ﬁelds of modern research. ExpoCloud enables

the researcher to harness cloud compute resources to achieve time and budget-

eﬀective large-scale concurrent parameter space explorations.

ExpoCloud enables maximal possible levels of concurrency by creating com-

pute instances on-the-ﬂy, saves money by terminating unneeded instances, pro-

vides a mechanism for saving both time and money by avoiding the exploration

of parameter settings that are as hard or harder than the parameter settings

whose exploration timed out. Eﬀective fault tolerance mechanisms make Ex-

poCloud suitable for large experiments.

ExpoCloud provides an interface that allows its use under various cloud envi-

ronments. As a proof of concept, we implemented a class supporting the Google

Compute Engine (GCE). We also implemented a class that simulates a cloud

environment on the local machine, thereby facilitating further development of

ExpoCloud.

The article describes ExpoCloud’s features and provides a usage example.

The software is well documented and is available under the MIT license [1, 2].

Keywords: parameter space exploration, distributed computing, cloud

compute engine, large-scale.

1Email address: mgoldenb@g.jct.ac.il

Preprint submitted to Journal of Parallel and Distributed Computing

August 29, 2022

 
 
 
 
 
 
Introduction

Large parameter space explorations are among the most time consuming yet

critically important tasks in many ﬁelds of modern research. For example, com-

puter science research is often concerned with the study of algorithms for solving

computational problems, whereby the algorithm’s behavior and the computa-

tion time for solving the problem are controlled by a number of parameters.

The possible settings of these parameters form a large parameter space, whose

thorough exploration requires that the algorithm be run to solve a number of

problem instances for each parameter setting of both the algorithm and the

problem. It is our assumption in this work that individual parameter settings

can be explored concurrently and independently of each other.

In the absence of a tool that makes large-scale parameter explorations easy

to accomplish, researchers resort to running ad hoc scripts either on a local

machine or on a cluster. Most recently, cloud-based compute engines became a

budget-friendly option. The amount of computational power available through

such services is usually much greater than that available in the research clusters.

However, the amount of technical expertise and scripting required to set up an

experiment that harnesses these resources may prove to be a stumbling block.

As a result, the researchers adopt simplifying limitations, such as using multiple

threads on a single compute instance [3].

The vision

We envisioned a framework that would let the researcher deﬁne his/her work-

load and achieve maximal concurrency while economizing on his/her time and

money, allowing ﬂexibility in choosing the cloud platform and providing fault

tolerance.

ExpoCloud [1] is our implementation of the above vision.

It realizes the

words that appear above in italics as follows:

2

• The workload is a list of tasks, each deﬁned by a setting of parameters. It

is computed at the commencement of the experiment and passed to the

framework for automated execution.

• Maximal concurrency is achieved by creating a new compute instance as

often as is allowed by the cloud platform, for as long as there are tasks to

assign.

• Economizing on time is achieved by letting the user specify a deadline and

a hardness (deﬁned below) for each task. When a task takes more time to

execute than the time speciﬁed by the deadline, we say that the task has

timed out. ExpoCloud terminates timed out tasks automatically.

A task’s hardness is a tuple of parameter values that correlate with the

time required to execute the task. The researcher speciﬁes which subset

of parameters determines a task’s hardness and provides a method that

compares hardnesses of two tasks. When a task times out, the framework

terminates all currently running tasks that are as hard or harder than

the timed out task. It also avoids running such tasks in the future. The

framework executes the tasks in the order from the easiest to the hardest,

so as to maximize the number of tasks that do not have to be executed.

• Economizing on money is achieved by deleting a compute instance as soon

as it is done with the tasks assigned to it and there are no more tasks to

be assigned.

• ExpoCloud provides great ﬂexibility for choosing the cloud platform. To

adapt to a given cloud platform, one needs to merely provide an extension

class with methods to create, terminate and list compute instances. In

addition, the researcher is in full control of the properties of the compute

instances, since all of them are created based on machine images speciﬁed

by the researcher.

• Fault tolerance means that the computation would proceed even if one or

more compute instances fail for any reason.

3

Before moving on to the main part of the article, we introduce an example

that we will use to demonstrate the framework’s design and usage.

The example parameter exploration

Consider the agent assignment problem, as follows. A team of n agents needs

to complete a project consisting of m tasks, where n ≥ m. The tasks have to

be performed sequentially. For each agent i and task j, we are given tij, the

amount of time, in seconds, that the agent i requires to complete the task j.

The problem is to assign an agent to each task, such that no agent is assigned to

more than one task and the total time of completing the project is minimized.

Suppose we use the classical branch and bound (B&B) search algorithm for

solving this problem, as follows. The algorithm is recursive. It starts with an

empty assignment, whereby no agent is assigned to a task. At each recursive

call, it extends the current partial assignment by assigning an agent to the next

task. When all tasks have been assigned an agent, we say that the assignment

is full. At this base case of the recursion, the algorithm updates the currently

best full assignment and the corresponding time for completing the project.

The advantage of B&B search over the brute-force search is the so called

B&B cutoﬀ. Namely, whenever the time corresponding to the current partial

assignment is greater than that of the best full assignment, the current assign-

ment can be discarded without losing the solution optimality.

A more eﬃcient version of this algorithm uses a heuristic. Given a partial

assignment, the heuristic is a lower bound on the time needed to complete the

remaining tasks. This bound is computed by assigning the best of the unused

agents to each of the remaining tasks, while allowing the assignment of the same

remaining agent to more than one remaining task. Whenever the sum of the

time corresponding to the current partial assignment and the heuristic is greater

than that of the best full assignment, the current assignment can be discarded.

Thus, we have three algorithmic variants - the brute-force search, the classi-

cal B&B search and the B&B search with a heuristic. To thoroughly understand

the properties of the agent assignment problem and the B&B search’s perfor-

4

mance for solving it, we need to run each algorithmic variant to solve a number

of generated problem instances for many possible settings of the number of

agents n and the number of tasks m.

What range of values should we consider for the number of agents n and the

number of tasks m? Without a framework like ExpoCloud, this question is not

easily answered. First, the range will depend on the algorithmic variant. The

brute-force search will only be able to handle small problems, while B&B with a

heuristic might be able so solve much larger instances. Knowing his/her budget

of time for the whole experiment, the researcher might decide on a deadline per

problem instance. He/she might then perform several test runs to get a feeling

for how much time each algorithmic variant takes to solve problem instances

of various sizes. Even after this laborious tuning stage, the researcher will still

run the risk of some instances taking disproportionately long time, possibly

stumbling the whole experiment.

With ExpoCloud, the question is really easy. First the researcher writes

a short class that deﬁnes a task as running one algorithmic variant to solve a

single problem instance for one particular setting of n and m. After deciding

on a deadline, the researcher picks a large range of values for n and m, with the

upper bounds that for sure cannot be solved by the best algorithmic variant.

He/she writes a single nested loop to generate all the tasks. All of this is shown

in the next section.

Next, the researcher notices that larger values of n correspond to harder

problem instances and so do larger values of m. It is also clear that the same

instance is likely to be solved faster by the B&B search with a heuristic than

with the classical B&B, which is in turn faster than the brute-force algorithm.

The researcher deﬁnes several short methods informing the framework of these

observations and oﬀ the experiment goes. ExpoCloud will care both for stopping

a problem instance as soon as it times out and for not attempting exploring

parameter settings that are as hard or harder.

The researcher does not need to worry about deciding on the number of

compute instances and creating those instances. Neither does he need to worry

5

about stopping compute instances when the experiment is done. The results

are easily obtained in a nice tabular format, which is again speciﬁed with a few

short methods.

If the researcher wants to run the experiment locally, e.g. on his/her laptop,

he/she can do that as well. ExpoCloud makes it easy to use as many CPUs of the

researcher’s machine as desired. Furthermore, this run is actually a simulation

of performing the experiment on the cloud. It is thus a powerful tool to facilitate

further development of the framework.

ExpoCloud is written in Python and is available on GitHub under the MIT

license [1]. The GitHub page contains the user documentation and links to the

developer’s documentation, where the source code is described [2].

The next section details the features of the framework and shows in full how

the above example experiment is setup and run.

Material and methods

The overall architecture

The overall architecture of ExpoCloud is shown in Figure 1. It is a server-

client architecture that uses a pull model to assign jobs to clients. Previous

research [4] has shown suitability of such an architecture for distributed scientiﬁc

computations.

A distinguishing attribute of ExpoCloud is that it creates compute instances

on-the-ﬂy. Creating clients on-the-ﬂy enables ExpoCloud to harness the great

potential for large-scale concurrency provided by cloud-based compute engines.

Creating replacement servers on-the-ﬂy enables ExpoCloud to achieve eﬀective

fault tolerance.

Two features of the architecture are not shown in Figure 1. First, there are

two-way communication channels between the clients and the backup server. We

detail the need for these channels in the section on fault tolerance below. Second,

a client creates and manages worker processes. Each worker is responsible for

executing a single task and communicating the results to the client.

6

Figure 1: The overall architecture of ExpoCloud

The next section demonstrates how one can specify the example experiment

described in the introduction. We will then show how the individual components

of the architecture are implemented to provide time and budget eﬃciency as

described in the introduction.

The example experiment

To set up an experiment, one needs to write a short Python script that

creates the primary server object, while providing it with the description of the

tasks to be executed, the conﬁguration of the compute engine and other optional

arguments.

We now show a possible script for exploring the parameter space when solv-

ing the agent assignment problem using B&B. Here is the part of the script that

constructs the list of tasks:

t a s k s = [ ]

m a x n t a s k s = 50

n i n s t a n c e s p e r s e t t i n g = 20

f o r o p t i o n s

in [ { Option .NO CUTOFFS} , { } , { Option . HEURISTIC } ] :

f o r n t a s k s

in range ( 2 , m a x n t a s k s + 1 ) :

7

f o r n a g e n t s

in range ( n t a s k s , 2 ∗ n t a s k s ) :

i n s t a n c e s = g e n e r a t e i n s t a n c e s (

n t a s k s , n a g e n t s ,

f i r s t i d = 0 ,

l a s t i d = n i n s t a n c e s p e r s e t t i n g − 1 )

f o r i n s t a n c e in i n s t a n c e s :

t a s k s . append (

Task ( Algorithm ( o p t i o n s ,

i n s t a n c e ) ) )

The outer loop iterates over the three variants of the algorithm: the brute-

force search, the classical B&B search and the B&B search with a heuristic.

The following two nested loops iterate over the possible values of n and m. For

each parameter setting, a task is formed for each of the 20 generated problem

instances. This task is added to the list tasks.

The key component here is the Task class, which the researcher needs to

provide. For our experiment, this class may look as follows:

c l a s s Task ( AbstractTask ) :

def

i n i t

( s e l f , a l g o r i t h m ,

t i m e o u t = 6 0 ) :

super ( Task ,

s e l f ) .

i n i t

( a l g o r i t h m ,

t i m e o u t )

def p a r a m e t e r t i t l e s ( s e l f ) :

return s e l f . i n s t a n c e . p a r a m e t e r t i t l e s ( ) + ( ” Options ” , )

def p a r a m e t e r s ( s e l f ) :

return s e l f . i n s t a n c e . p a r a m e t e r s ( ) + ( s e t 2 s t r ( s e l f . o p t i o n s ) , )

def h a r d n e s s p a r a m e t e r s ( s e l f ) :

def o p t i o n s 2 h a r d n e s s ( o p t i o n s ) :

i f Option . HEURISTIC in o p t i o n s : return 0

i f Option .NO CUTOFFS in o p t i o n s : return 2

return 1

return (

8

o p t i o n s 2 h a r d n e s s ( s e l f . o p t i o n s ) ,

s e l f . i n s t a n c e . n t a s k s ,

s e l f . i n s t a n c e . n a g e n t s )

def

r e s u l t t i t l e s ( s e l f ) :

return s e l f . a l g o r i t h m . r e s u l t t i t l e s ( )

def run ( s e l f ) :

return s e l f . a l g o r i t h m . s e a r c h ( )

def g r o u p p a r a m e t e r t i t l e s ( s e l f ) :

return f i l t e r o u t ( s e l f . p a r a m e t e r t i t l e s ( ) ,

( ’ i d ’ , ) )

A brief description of each method follows:

• parameter_titles - returns the tuple of parameter names, which would

appear as column titles in the formatted output. In the example imple-

mentation, these consist of the parameters of the problem instance, such

as the number of agents and the number of tasks, appended by the pa-

rameters of the search algorithm being used.

• parameters - returns the tuple of parameter values describing the task.

• hardness_parameters - returns the subset of parameters used to deter-

mine the task’s hardness. The default implementation in AbstractTask

says that task T1 is as hard or harder than task T2 if all the hardness

parameters of the former are greater than or equal to the corresponding

parameters of the latter. Note how the shown code converts the param-

eters of the search algorithm into a number, so as to adapt this default

implementation.

Internally, the hardness of a task is stored as an instance of the

Hardness class deﬁned inside AbstractTask. The Task class derives from

AbstractTask and may provide its own deﬁnition of Hardness, thereby

9

gaining full control over the way in which the hardnesses of two tasks are

compared.

• result_titles - returns the tuple of names of output quantities, such

as the optimal time for executing the project and the time taken by the

search algorithm. The actual tuple of output quantities is returned by the

run method described below.

• run - executes the task by running the search algorithm to solve the prob-

lem instance. If the algorithm is implemented in Python, as in our exam-

ple, the suitable method of the algorithm object is run. Otherwise, the

algorithm can be run as a shell command.

• group_parameter_titles - returns the tuple of parameter names that

determine groups of tasks, as we now explain. Consider a state of the

experiment, whereby results for three out of twenty problem instances for a

particular setting of parameters have been computed. Suppose that a task

timed out at this point, which disqualiﬁed the remaining sixteen tasks as

being too hard. It stands to reason that the results for the three executed

tasks should be discarded, since the average of the output quantities over

only three tasks would have low statistical signiﬁcance. On the other

hand, had we obtained results for eighteen instances before a particularly

hard task timed out, we may want to keep the results for this setting of

parameters.

ExpoCloud makes the decision of whether to keep a parameter setting on

a per-group basis. A group consists of all the tasks with the same values

of the parameters returned by the group_parameter_titles method.2 A

group is kept when the number of solved tasks in the group is at least

as large as the optional min_group_size argument to the constructor of

the server object. In the shown implementation, a group is deﬁned by all

2This is somewhat similar to the idea of the GROUP BY clause in SQL.

10

the parameters besides the id of the problem instance within a particular

setting of parameters.

The default value of the min_group_size argument is zero, which means

that all the results are kept.

The next section of the script speciﬁes the conﬁguration for the compute

engine and passes this conﬁguration to the constructor of the engine object:

c o n f i g = {

’ p r e f i x ’ :

’ agent−a s s i g n m e n t ’ ,

’ p r o j e c t ’ :

’ bnb−agent−a s s i g n m e n t ’ ,

’ zone ’ :

’ us−c e n t r a l 1 −a ’ ,

’ s e r v e r i m a g e ’ :

’ s e r v e r −t e m p l a t e ’ ,

’ c l i e n t i m a g e ’ :

’ c l i e n t −t e m p l a t e ’ ,

’ r o o t f o l d e r ’ :

’ ˜/ ExpoCloud ’ ,

’ p r o j e c t f o l d e r ’ :

’ examples . a g e n t a s s i g n m e n t ’

}

e n g i n e = GCE( c o n f i g )

The conﬁguration is a dictionary with the following keys:

• prefix - the preﬁx used for the automatically generated names of compute

instances. Several experiments with diﬀerent preﬁxes may be conducted

simultaneously.

• project - the name identifying the project on the cloud platform.

• zone - the zone to which the allocated compute instances will pertain.

The current implementation of the GCE engine is limited to use a single

zone. This limitation may be lifted in the future to enable an even larger

scalability.

• server_image and client_image - the names of the machine images stor-

ing the conﬁguration (such as the CPU family, the number of CPUs, the

amount of RAM, etc) of all future server and client instances, respectively.

An inexpensive conﬁguration with one or two CPUs may be used for a

11

server, while one may opt for 64 or more CPUs per instance for a client.

ExpoCloud’s clients make use of all the available CPUs automatically.

• root_folder - the folder in which ExpoCloud resides on all the compute

instances.

• project_folder - the folder in which the user-provided scripts reside.

The folder must be speciﬁed in the dotted format as shown in the listing.3

In our case, the engine being used is the Google Compute Engine (GCE).

Some dictionary keys for other engines may diﬀer. For example, zone is a GCE

concept and a more suitable key name may be used in the extension class for

another platform.

Lastly, we construct the primary server object and call its run method:

S e r v e r ( t a s k s , e n g i n e ) . run ( )

Once the experiment completes, the main ExpoCloud folder at the primary

server will have an output folder containing a results ﬁle and a folder for each

client instance. Such a client folder will contain ﬁles with the events sent by the

client. ExpoCloud provides a script for convenient viewing of both the results

and the client events related to the execution of the tasks.

ExpoCloud provides a local machine engine for running an experiment lo-

cally. The only change in the above script concerns the construction of the

engine object:

e n g i n e=L o c a l E n g i n e ( ’ examples . a g e n t a s s i g n m e n t ’ )

Once the experiment completes, the main ExpoCloud folder will have an

output folder for each of the servers, as well as a ﬁle for stdout and stderr

for each client. Running the experiment locally is useful both for small initial

explorations. It also enables rapid development, since it makes it unnecessary

3This is the format in which the path must be speciﬁed when using the -m command-line

argument to python.

12

to copy each updated version to the cloud and avoids the latencies associated

with using the cloud.

We now describe in detail how the primary server operates.

The primary server

We ﬁrst describe how the primary server stores the tasks, then outline the

workings of the run method at a high level, and lastly zoom in on the message-

handling part of the primary server.

a. The tasks-related lists

There are three tasks-related lists - the actual list of tasks and two auxiliary

lists used for performance and fault tolerance. We describe them in turn.

The list of tasks, called tasks, is sorted in the order of non-decreasing hard-

ness of tasks. This order maximizes the number of tasks that are not attempted

as a result of a previous task timing out. The original order of tasks is restored

prior to the printing of results.

The list tasks_from_failed consists of indices of the tasks that have been

assigned to a client, but not completed due to a failure of the client instance.

When a client requests tasks, the tasks in tasks_from_failed are assigned ﬁrst.

The next task from tasks is assigned only if tasks_from_failed is empty.

Lastly, the list min_hard consists of hardnesses of tasks that have timed

out. Whenever the server is about to assign a task, it ﬁrst checks whether the

hardness of the task is equal or greater than any of the elements in min_hard.

min_hard is kept small by only storing the minimal elements.

b. The run method

The primary server object’s run method executes an inﬁnite loop. An iter-

ation of this loop performs the following actions:

1. Informs the backup server that the primary server is continuing to function

properly. We refer to such a message as a health update.

13

2. Handles handshake requests from newly started instances. The instance

can be either a backup server or a client. We refer to the instance that

has shaken hands with the primary server as an active instance.

In response to a handshake request, two-way communication channel with

the instance is established.4 In contrast to this channel, the queue for ac-

cepting handshakes is created by the primary server’s constructor. When

an instance is started, it gets the IP address of the primary server and the

port number for handshake requests as command line arguments.

In addition, if the instance is a client, a folder for storing the client events

is created.

3. Handles messages from clients. We outline the messages and how they are

handled in the next section.

4. Creates either the backup server or a new client instance. The creation of

the backup server takes precedence. If the backup server is already running

or the researcher opted to not use a backup server for the experiment, then

a new client is created. Cloud compute engines do not let users to create

instances in quick succession. Therefore, ExpoCloud uses exponentially

increasing delays between attempts at creating cloud instances.

5. Terminates unhealthy instances. An active instance is unhealthy if it failed

to send health updates to the server for the period of time speciﬁed by

the HEALTH_UPDATE_LIMIT constant. A non-active instance is unhealthy

if it failed to shake hands with the primary server for the period of time

speciﬁed by the INSTANCE_MAX_NON_ACTIVE_TIME constant.

6. Outputs the results once there are no tasks that have not been assigned

to clients and all clients completed the tasks assigned to them.

The servers do not stop once the results are output. Thus, the fault tolerance

4Namely, the instance owns two queues registered with a SyncManager object. The pri-

mary server creates the two corresponding queues at its end. SyncManager is part of the

multiprocessing module of the Python standard library. It provides for low-latency commu-

nication, which makes the distributed approach eﬀective even for ﬁne-grained tasks.

14

mechanisms continue to protect the results against a possible primary server

instance failure.

c. The handling of messages

The following is an outline of messages that may arrive to the primary server

from the backup server and the client instances:

• HEALTH_UPDATE - the health update coming from either the backup server

or a client. The primary server simply saves the timestamp of the last

health update for each instance.

• REQUEST_TASKS - the request for tasks by a client. The body of the message

speciﬁes the number of tasks requested. If there are remaining unassigned

tasks, the GRANT_TASKS message is sent in response. The body of this

message contains the tasks assigned to the requesting client, including

both the parameters and the full representation of the problem instances

to be solved. If there are no unassigned tasks, the response is the NO_-

FURTHER_TASKS message.

• RESULT - the result of executing a task. The primary server stores the

result with the task object.

• REPORT_HARD_TASK - the report about a timed out task. The primary

server updates the min_hard list and sends the APPLY_DOMINO_EFFECT

message to all the clients, so they can terminate any task that is as hard

or harder than the task just timed out.

• LOG and EXCEPTION - the report about an event related to executing a

task or to an exception, respectively, sent by a client. The primary server

stores the event in the ﬁtting ﬁle corresponding to the client.

• BYE - the client is done, which means that it had sent to the primary server

the results for all the tasks assigned to it and had previously received the

NO_FURTHER_TASKS message. The primary server terminates the client

instance, so the researcher will not incur any further charges.

15

The primary server forwards a copy of each message from a client to the

backup server. This keeps the backup server up-to-date and ready to take over

should the primary server instance fail. This is further detailed in the section

on fault tolerance below.

We will now describe the operation of the clients.

The clients

We ﬁrst describe the main loop of the client object’s run method, then detail

how the workers are managed and lastly zoom in on the message-handling part

of the client.

a. The main loop

In contrast to the primary server, the client’s main loop is not inﬁnite – it

stops when there are no tasks assigned to the client, and no more tasks that can

be assigned to it by the primary server (i.e. the NO_FURTHER_TASKS message

has been received).

Each iteration of the main loop performs the following actions:

1. Sends the health update to the servers.

2. Processes workers as detailed in the next section.

3. Requests tasks from the primary server, subject to availability of idle

CPUs and the NO_FURTHER_TASKS message not having been received. Note

that the tasks requested previously, but not yet granted are taken into

account when determining how many idle CPUs there are.

4. Processes messages from the primary server as detailed in a separate sec-

tion below.

5. If new tasks have been granted by the primary server, starts the worker

processes to execute them.

Foe each message sent to the primary server, the client sends a copy of

the message to the backup server. The need for this is explained in the below

section on fault tolerance. That section also details what the client does with

the incoming messages from the backup server.

16

Once the main loop is exited, the client sends the BYE message and completes.

b. The management of workers

Each task is performed by a separate worker process. The client performs

three action to manage the workers:

• Processes messages arriving from the workers. A worker can send two

messages - WORKER_STARTED and WORKER_DONE. In response to either mes-

sage, the client sends the LOG message with the corresponding body to the

servers. The WORKER_DONE message results in sending the RESULT message

as well.

• Takes accounting of the worker processes that are no longer alive (i.e.

either done or terminated), so as to be able to assign the released CPUs

to other tasks.

• Terminates processes whose tasks timed out. The client sends the

REPORT_HARD_TASK message to the servers for each timed out task.

c. The handling of messages from the primary server

The following is an outline of messages that may arrive to the client from

the primary server:

• GRANT_TASKS - one or more tasks have been assigned to the client. The

task is added to tasks list and a LOG message is sent to the servers to

record the event of the receipt.

• APPLY_DOMINO_EFFECT - the hardness of a task that timed out is reported

by the primary server. The client terminates all workers currently per-

forming tasks of equal or greater hardness.

• NO_FURTHER_TASKS - the primary server informs that there are no more

tasks to be assigned. The client stores this information, so as to avoid

requesting tasks and exit the main loop once all the worker processes are

completed.

17

In addition to the above messages, there are the STOP, RESUME and SWAP_-

QUEUES messages, used to achieve fault tolerance. These are detailed in the next

section.

Fault tolerance

One standard technique for achieving fault tolerance in a distributed system

is by using redundancy [5]. This is the approach we follow by employing a

backup server that mirrors the primary one and substitutes for it in the case of

a failure. A backup server is not used when the computation is performed using

the local machine engine. As mentioned above, the researcher may choose to

disable the use of the backup server. This may be desired for a short experiment.

We distinguish between three kinds of failure: client instance failure, backup

server failure and primary server failure. Client failure does not require any

special action besides registering the failure and re-assigning the tasks previ-

ously assigned to the failed client. The latter is achieved by maintaining the

tasks_from_failed list, as described above. In contrast, care needs to be taken

to achieve correctness of recovery after a server failure. The following sections

detail how this is achieved.

a. Creation of the backup server

The primary server creates the backup server in the same way as it creates

clients. When a backup server instance does not yet exist, its creation takes

precedence over the creation of a new client.

Note that the backup server maybe created either at the beginning of the

computation or after a server failure.5 Therefore, we need to create the backup

server under the assumption that the distributed computation is in progress.

To make sure that the newly created backup server is fully synchronized

with the primary server, the primary server freezes its state prior to creating

5We will see below how the case of primary server failure is reduced to the case of the

backup server failure.

18

the backup server. First, it stops accepting handshake requests from new client

instances. Second, it sends the STOP message to the active clients, which causes

them to refrain from actions that may result in messages to the server. An

exception is made for the health reports, which the clients continue to send.

Next, the primary server serializes its full state into a ﬁle in the output folder,

creates a new instance on the compute engine, and copies the output folder to

it.

It then starts the backup server script on the new instance. This script

unserializes the server object and runs its assume_backup_role method. As the

name suggests, this method converts the primary server object into a backup

server one. First, it disconnects the server object from the clients’ channels

for communicating with the primary server and connects it to the channels for

communicating with the backup server. Second, it creates a two-way channel

for communicating with the primary server. Lastly, it shakes hands with the

primary server, whereby two-way communication between them is established.

Upon this handshake, the primary server resumes accepting handshake requests

from new client instances and sends the RESUME message to the clients, so they

can resume normal operation. Finally, the backup server script starts the main

event loop of the server object.

b. Primary and backup server coordination

Whenever a new client shakes hands with the primary server, the latter sends

the NEW_CLIENT message to the backup server with the information about the

client. In response to this message the backup server creates the client object

and establishes communication with it. Similarly, whenever the primary server

detects a client failure, it sends the CLIENT_TERMINATED message to the backup

server, which destroys the corresponding client object.

When a client sends a message to the primary server, it sends a copy of the

message to the backup server. Thus, the backup server receives two copies of

each message sent by the client. The copy received directly from the client is

needed for the case when the primary server fails before forwarding the message

to the backup server. The copy received from the primary server is needed to

19

keep the two servers synchronized, as described below.

The backup server takes actions based on the copy of the message received

from the primary server.

It simply pops the corresponding message received

directly from the client oﬀ the queue. When the backup server registers the pri-

mary server failure, it will be ready to take over, with all the messages received

directly from the clients after the last message forwarded by the primary server.

The backup server processes messages from clients in the same exact way

as the primary server.

It also sends messages to the clients that mirror the

messages sent from the primary server.

The mechanism of the backup server taking actions based on the copy of

the message received from the primary server takes care of two possible causes

of desynchronization. First, a client may fail after sending a message to the

primary server, but before sending a copy to the backup server. Second, due

to race conditions, it is possible for the two servers to handle messages from

diﬀerent clients, such as requests for tasks, in diﬀerent order and end up in

diﬀerent states.

Similarly to how the backup server processes two copies of each message

from a client, the clients processes two copies of each message from the servers

- one received from the primary server and the other received from the backup

server. A client performs actions only based on the messages received from

the primary server and pops oﬀ the queue the corresponding messages received

from the backup server. When the primary server fails, the remaining messages

received from the backup server are treated as if they were from the primary

server, as detailed in the next section.

c. Handling server failure

In response to the backup server failure, the primary server simply creates

the new backup server as outlined in the last section.

In the case of the primary server failure, the backup server changes its own

role to being the primary server. It then proceeds to create a temporary connec-

tion to each client’s inbound queue for communication with the primary server

20

and sends a SWAP message. In response to this message, the client swaps the

queues for communicating with the primary server with those for communicat-

ing with the backup server. After this, the client is ready to proceed normally.

Thus, the case of the primary server failure is now reduced to the case of the

backup server failure discussed above.

One special case is when the primary server fails after creating a client

instance, but before the new client shakes hands and the backup server is up-

dated. In this case, there is a dangling client instance incurring charges for the

researcher. To avoid this, as part of the backup server assuming the role of the

primary server, it requests from the engine the list of all compute instances and

deletes all client instances that are not represented by an existing client object.

Discussion and conclusions

We have presented the ExpoCloud framework for distributed computing us-

ing cloud compute engines. Unlike the existing tools geared towards business

workloads [6], ExpoCloud is speciﬁcally designed to make it easy to execute

large parameter-space explorations. It addresses the four main concerns of the

researcher: ease of deﬁning the workload, harnessing as much compute power

as can be used to speed up the experiment, eliminating computations that do

not or are unlikely to complete in a reasonable amount of time, and avoid-

ing unnecessary charges. Combined with mechanisms for fault tolerance, these

properties make ExpoCloud a ﬁtting tool for many research projects requiring

large-scale parameter-space explorations. Future work may consider executing

workloads with task dependencies, integrating ExpoCloud with existing tools,

and addressing security concerns.

Acknowledgements

Access to the Google Compute Engine was provided through the Israel Data

Science Initiative.

21

References

[1] M. Goldenberg, ExpoCloud’s page on GitHub.

URL https://github.com/mgoldenbe/ExpoCloud

[2] M. Goldenberg, ExpoCloud developer’s documentation.

URL https://expocloud.netlify.app

[3] A. Pollack, Tutorial: parallelize your python code and run it on Google

Cloud.

URL https://youtu.be/i4aFiIB5urA

[4] C. Pinchak, P. Lu, J. Schaeﬀer, M. Goldenberg, The canadian internet-

worked scientiﬁc supercomputer, 17th International Symposium on High

Performance Computing Systems and Applications (HPCS) (2003) 193–199.

[5] C. Storm, Fault Tolerance in Distributed Computing, Vieweg+Teubner Ver-

lag, Wiesbaden, 2012, pp. 13–79. doi:10.1007/978-3-8348-2381-6_2.

URL https://doi.org/10.1007/978-3-8348-2381-6_2

[6] B. Burns, B. Grant, D. Oppenheimer, E. Brewer, J. Wilkes, Borg, omega,

and kubernetes, Communications of the ACM 59 (5) (2016) 50–57.

22

","2 2 0 2 g u A 6 2 ] C D . s c [ 2 v 5 9 1 2 1 . 8 0 2 2 : v i X r a ExpoCloud: a Framework for Time and Budget-Eﬀective Parameter Space Explorations Using a Cloud Compute Engine Meir Goldenberg1 Jerusalem College of Technology Abstract Large parameter space explorations are among the most time consuming yet critically important tasks in many ﬁelds of modern research. ExpoCloud enables the researcher to harness cloud compute resources to achieve time and budget- eﬀective large-scale concurrent parameter space explorations. ExpoCloud enables maximal possible levels of concurrency by creating com- pute instances on-the-ﬂy, saves money by terminating unneeded instances, pro- vides a mechanism for saving both time and money by avoiding the exploration of parameter settings that are as hard or harder than the parameter settings whose exploration timed out. Eﬀective fault tolerance mechanisms make Ex- poCloud suitable for large experiments. ExpoCloud provides an interface that allows its use under various cloud envi- ronments. As a proof of concept, we implemented a class supporting the Google Compute Engine (GCE). We also implemented a class that simulates a cloud environment on the local machine, thereby facilitating further development of ExpoCloud. The article describes ExpoCloud’s features and provides a usage example. The software is well documented and is available under the MIT license [1, 2]. Keywords: parameter space exploration, distributed computing, cloud compute engine, large-scale. 1Email address: mgoldenb@g.jct.ac.il Preprint submitted to Journal of Parallel and Distributed Computing August 29, 2022 Introduction Large parameter space explorations are among the most time consuming yet critically important tasks in many ﬁelds of modern research. For example, com- puter science research is often concerned with the study of algorithms for solving computational problems, whereby the algorithm’s behavior and the computa- tion time for solving the problem are controlled by a number of parameters. The possible settings of these parameters form a large parameter space, whose thorough exploration requires that the algorithm be run to solve a number of problem instances for each parameter setting of both the algorithm and the problem. It is our assumption in this work that individual parameter settings can be explored concurrently and independently of each other. In the absence of a tool that makes large-scale parameter explorations easy to accomplish, researchers resort to running ad hoc scripts either on a local machine or on a cluster. Most recently, cloud-based compute engines became a budget-friendly option. The amount of computational power available through such services is usually much greater than that available in the research clusters. However, the amount of technical expertise and scripting required to set up an experiment that harnesses these resources may prove to be a stumbling block. As a result, the researchers adopt simplifying limitations, such as using multiple threads on a single compute instance [3]. The vision We envisioned a framework that would let the researcher deﬁne his/her work- load and achieve maximal concurrency while economizing on his/her time and money, allowing ﬂexibility in choosing the cloud platform and providing fault tolerance. ExpoCloud [1] is our implementation of the above vision. It realizes the words that appear above in italics as follows: 2 • The workload is a list of tasks, each deﬁned by a setting of parameters. It is computed at the commencement of the experiment and passed to the framework for automated execution. • Maximal concurrency is achieved by creating a new compute instance as often as is allowed by the cloud platform, for as long as there are tasks to assign. • Economizing on time is achieved by letting the user specify a deadline and a hardness (deﬁned below) for each task. When a task takes more time to execute than the time speciﬁed by the deadline, we say that the task has timed out. ExpoCloud terminates timed out tasks automatically. A task’s hardness is a tuple of parameter values that correlate with the time required to execute the task. The researcher speciﬁes which subset of parameters determines a task’s hardness and provides a method that compares hardnesses of two tasks. When a task times out, the framework terminates all currently running tasks that are as hard or harder than the timed out task. It also avoids running such tasks in the future. The framework executes the tasks in the order from the easiest to the hardest, so as to maximize the number of tasks that do not have to be executed. • Economizing on money is achieved by deleting a compute instance as soon as it is done with the tasks assigned to it and there are no more tasks to be assigned. • ExpoCloud provides great ﬂexibility for choosing the cloud platform. To adapt to a given cloud platform, one needs to merely provide an extension class with methods to create, terminate and list compute instances. In addition, the researcher is in full control of the properties of the compute instances, since all of them are created based on machine images speciﬁed by the researcher. • Fault tolerance means that the computation would proceed even if one or more compute instances fail for any reason. 3 Before moving on to the main part of the article, we introduce an example that we will use to demonstrate the framework’s design and usage. The example parameter exploration Consider the agent assignment problem, as follows. A team of n agents needs to complete a project consisting of m tasks, where n ≥ m. The tasks have to be performed sequentially. For each agent i and task j, we are given tij, the amount of time, in seconds, that the agent i requires to complete the task j. The problem is to assign an agent to each task, such that no agent is assigned to more than one task and the total time of completing the project is minimized. Suppose we use the classical branch and bound (B&B) search algorithm for solving this problem, as follows. The algorithm is recursive. It starts with an empty assignment, whereby no agent is assigned to a task. At each recursive call, it extends the current partial assignment by assigning an agent to the next task. When all tasks have been assigned an agent, we say that the assignment is full. At this base case of the recursion, the algorithm updates the currently best full assignment and the corresponding time for completing the project. The advantage of B&B search over the brute-force search is the so called B&B cutoﬀ. Namely, whenever the time corresponding to the current partial assignment is greater than that of the best full assignment, the current assign- ment can be discarded without losing the solution optimality. A more eﬃcient version of this algorithm uses a heuristic. Given a partial assignment, the heuristic is a lower bound on the time needed to complete the remaining tasks. This bound is computed by assigning the best of the unused agents to each of the remaining tasks, while allowing the assignment of the same remaining agent to more than one remaining task. Whenever the sum of the time corresponding to the current partial assignment and the heuristic is greater than that of the best full assignment, the current assignment can be discarded. Thus, we have three algorithmic variants - the brute-force search, the classi- cal B&B search and the B&B search with a heuristic. To thoroughly understand the properties of the agent assignment problem and the B&B search’s perfor- 4 mance for solving it, we need to run each algorithmic variant to solve a number of generated problem instances for many possible settings of the number of agents n and the number of tasks m. What range of values should we consider for the number of agents n and the number of tasks m? Without a framework like ExpoCloud, this question is not easily answered. First, the range will depend on the algorithmic variant. The brute-force search will only be able to handle small problems, while B&B with a heuristic might be able so solve much larger instances. Knowing his/her budget of time for the whole experiment, the researcher might decide on a deadline per problem instance. He/she might then perform several test runs to get a feeling for how much time each algorithmic variant takes to solve problem instances of various sizes. Even after this laborious tuning stage, the researcher will still run the risk of some instances taking disproportionately long time, possibly stumbling the whole experiment. With ExpoCloud, the question is really easy. First the researcher writes a short class that deﬁnes a task as running one algorithmic variant to solve a single problem instance for one particular setting of n and m. After deciding on a deadline, the researcher picks a large range of values for n and m, with the upper bounds that for sure cannot be solved by the best algorithmic variant. He/she writes a single nested loop to generate all the tasks. All of this is shown in the next section. Next, the researcher notices that larger values of n correspond to harder problem instances and so do larger values of m. It is also clear that the same instance is likely to be solved faster by the B&B search with a heuristic than with the classical B&B, which is in turn faster than the brute-force algorithm. The researcher deﬁnes several short methods informing the framework of these observations and oﬀ the experiment goes. ExpoCloud will care both for stopping a problem instance as soon as it times out and for not attempting exploring parameter settings that are as hard or harder. The researcher does not need to worry about deciding on the number of compute instances and creating those instances. Neither does he need to worry 5 about stopping compute instances when the experiment is done. The results are easily obtained in a nice tabular format, which is again speciﬁed with a few short methods. If the researcher wants to run the experiment locally, e.g. on his/her laptop, he/she can do that as well. ExpoCloud makes it easy to use as many CPUs of the researcher’s machine as desired. Furthermore, this run is actually a simulation of performing the experiment on the cloud. It is thus a powerful tool to facilitate further development of the framework. ExpoCloud is written in Python and is available on GitHub under the MIT license [1]. The GitHub page contains the user documentation and links to the developer’s documentation, where the source code is described [2]. The next section details the features of the framework and shows in full how the above example experiment is setup and run. Material and methods The overall architecture The overall architecture of ExpoCloud is shown in Figure 1. It is a server- client architecture that uses a pull model to assign jobs to clients. Previous research [4] has shown suitability of such an architecture for distributed scientiﬁc computations. A distinguishing attribute of ExpoCloud is that it creates compute instances on-the-ﬂy. Creating clients on-the-ﬂy enables ExpoCloud to harness the great potential for large-scale concurrency provided by cloud-based compute engines. Creating replacement servers on-the-ﬂy enables ExpoCloud to achieve eﬀective fault tolerance. Two features of the architecture are not shown in Figure 1. First, there are two-way communication channels between the clients and the backup server. We detail the need for these channels in the section on fault tolerance below. Second, a client creates and manages worker processes. Each worker is responsible for executing a single task and communicating the results to the client. 6 Figure 1: The overall architecture of ExpoCloud The next section demonstrates how one can specify the example experiment described in the introduction. We will then show how the individual components of the architecture are implemented to provide time and budget eﬃciency as described in the introduction. The example experiment To set up an experiment, one needs to write a short Python script that creates the primary server object, while providing it with the description of the tasks to be executed, the conﬁguration of the compute engine and other optional arguments. We now show a possible script for exploring the parameter space when solv- ing the agent assignment problem using B&B. Here is the part of the script that constructs the list of tasks: t a s k s = [ ] m a x n t a s k s = 50 n i n s t a n c e s p e r s e t t i n g = 20 f o r o p t i o n s in [ { Option .NO CUTOFFS} , { } , { Option . HEURISTIC } ] : f o r n t a s k s in range ( 2 , m a x n t a s k s + 1 ) : 7 f o r n a g e n t s in range ( n t a s k s , 2 ∗ n t a s k s ) : i n s t a n c e s = g e n e r a t e i n s t a n c e s ( n t a s k s , n a g e n t s , f i r s t i d = 0 , l a s t i d = n i n s t a n c e s p e r s e t t i n g − 1 ) f o r i n s t a n c e in i n s t a n c e s : t a s k s . append ( Task ( Algorithm ( o p t i o n s , i n s t a n c e ) ) ) The outer loop iterates over the three variants of the algorithm: the brute- force search, the classical B&B search and the B&B search with a heuristic. The following two nested loops iterate over the possible values of n and m. For each parameter setting, a task is formed for each of the 20 generated problem instances. This task is added to the list tasks. The key component here is the Task class, which the researcher needs to provide. For our experiment, this class may look as follows: c l a s s Task ( AbstractTask ) : def i n i t ( s e l f , a l g o r i t h m , t i m e o u t = 6 0 ) : super ( Task , s e l f ) . i n i t ( a l g o r i t h m , t i m e o u t ) def p a r a m e t e r t i t l e s ( s e l f ) : return s e l f . i n s t a n c e . p a r a m e t e r t i t l e s ( ) + ( ” Options ” , ) def p a r a m e t e r s ( s e l f ) : return s e l f . i n s t a n c e . p a r a m e t e r s ( ) + ( s e t 2 s t r ( s e l f . o p t i o n s ) , ) def h a r d n e s s p a r a m e t e r s ( s e l f ) : def o p t i o n s 2 h a r d n e s s ( o p t i o n s ) : i f Option . HEURISTIC in o p t i o n s : return 0 i f Option .NO CUTOFFS in o p t i o n s : return 2 return 1 return ( 8 o p t i o n s 2 h a r d n e s s ( s e l f . o p t i o n s ) , s e l f . i n s t a n c e . n t a s k s , s e l f . i n s t a n c e . n a g e n t s ) def r e s u l t t i t l e s ( s e l f ) : return s e l f . a l g o r i t h m . r e s u l t t i t l e s ( ) def run ( s e l f ) : return s e l f . a l g o r i t h m . s e a r c h ( ) def g r o u p p a r a m e t e r t i t l e s ( s e l f ) : return f i l t e r o u t ( s e l f . p a r a m e t e r t i t l e s ( ) , ( ’ i d ’ , ) ) A brief description of each method follows: • parameter_titles - returns the tuple of parameter names, which would appear as column titles in the formatted output. In the example imple- mentation, these consist of the parameters of the problem instance, such as the number of agents and the number of tasks, appended by the pa- rameters of the search algorithm being used. • parameters - returns the tuple of parameter values describing the task. • hardness_parameters - returns the subset of parameters used to deter- mine the task’s hardness. The default implementation in AbstractTask says that task T1 is as hard or harder than task T2 if all the hardness parameters of the former are greater than or equal to the corresponding parameters of the latter. Note how the shown code converts the param- eters of the search algorithm into a number, so as to adapt this default implementation. Internally, the hardness of a task is stored as an instance of the Hardness class deﬁned inside AbstractTask. The Task class derives from AbstractTask and may provide its own deﬁnition of Hardness, thereby 9 gaining full control over the way in which the hardnesses of two tasks are compared. • result_titles - returns the tuple of names of output quantities, such as the optimal time for executing the project and the time taken by the search algorithm. The actual tuple of output quantities is returned by the run method described below. • run - executes the task by running the search algorithm to solve the prob- lem instance. If the algorithm is implemented in Python, as in our exam- ple, the suitable method of the algorithm object is run. Otherwise, the algorithm can be run as a shell command. • group_parameter_titles - returns the tuple of parameter names that determine groups of tasks, as we now explain. Consider a state of the experiment, whereby results for three out of twenty problem instances for a particular setting of parameters have been computed. Suppose that a task timed out at this point, which disqualiﬁed the remaining sixteen tasks as being too hard. It stands to reason that the results for the three executed tasks should be discarded, since the average of the output quantities over only three tasks would have low statistical signiﬁcance. On the other hand, had we obtained results for eighteen instances before a particularly hard task timed out, we may want to keep the results for this setting of parameters. ExpoCloud makes the decision of whether to keep a parameter setting on a per-group basis. A group consists of all the tasks with the same values of the parameters returned by the group_parameter_titles method.2 A group is kept when the number of solved tasks in the group is at least as large as the optional min_group_size argument to the constructor of the server object. In the shown implementation, a group is deﬁned by all 2This is somewhat similar to the idea of the GROUP BY clause in SQL. 10 the parameters besides the id of the problem instance within a particular setting of parameters. The default value of the min_group_size argument is zero, which means that all the results are kept. The next section of the script speciﬁes the conﬁguration for the compute engine and passes this conﬁguration to the constructor of the engine object: c o n f i g = { ’ p r e f i x ’ : ’ agent−a s s i g n m e n t ’ , ’ p r o j e c t ’ : ’ bnb−agent−a s s i g n m e n t ’ , ’ zone ’ : ’ us−c e n t r a l 1 −a ’ , ’ s e r v e r i m a g e ’ : ’ s e r v e r −t e m p l a t e ’ , ’ c l i e n t i m a g e ’ : ’ c l i e n t −t e m p l a t e ’ , ’ r o o t f o l d e r ’ : ’ ˜/ ExpoCloud ’ , ’ p r o j e c t f o l d e r ’ : ’ examples . a g e n t a s s i g n m e n t ’ } e n g i n e = GCE( c o n f i g ) The conﬁguration is a dictionary with the following keys: • prefix - the preﬁx used for the automatically generated names of compute instances. Several experiments with diﬀerent preﬁxes may be conducted simultaneously. • project - the name identifying the project on the cloud platform. • zone - the zone to which the allocated compute instances will pertain. The current implementation of the GCE engine is limited to use a single zone. This limitation may be lifted in the future to enable an even larger scalability. • server_image and client_image - the names of the machine images stor- ing the conﬁguration (such as the CPU family, the number of CPUs, the amount of RAM, etc) of all future server and client instances, respectively. An inexpensive conﬁguration with one or two CPUs may be used for a 11 server, while one may opt for 64 or more CPUs per instance for a client. ExpoCloud’s clients make use of all the available CPUs automatically. • root_folder - the folder in which ExpoCloud resides on all the compute instances. • project_folder - the folder in which the user-provided scripts reside. The folder must be speciﬁed in the dotted format as shown in the listing.3 In our case, the engine being used is the Google Compute Engine (GCE). Some dictionary keys for other engines may diﬀer. For example, zone is a GCE concept and a more suitable key name may be used in the extension class for another platform. Lastly, we construct the primary server object and call its run method: S e r v e r ( t a s k s , e n g i n e ) . run ( ) Once the experiment completes, the main ExpoCloud folder at the primary server will have an output folder containing a results ﬁle and a folder for each client instance. Such a client folder will contain ﬁles with the events sent by the client. ExpoCloud provides a script for convenient viewing of both the results and the client events related to the execution of the tasks. ExpoCloud provides a local machine engine for running an experiment lo- cally. The only change in the above script concerns the construction of the engine object: e n g i n e=L o c a l E n g i n e ( ’ examples . a g e n t a s s i g n m e n t ’ ) Once the experiment completes, the main ExpoCloud folder will have an output folder for each of the servers, as well as a ﬁle for stdout and stderr for each client. Running the experiment locally is useful both for small initial explorations. It also enables rapid development, since it makes it unnecessary 3This is the format in which the path must be speciﬁed when using the -m command-line argument to python. 12 to copy each updated version to the cloud and avoids the latencies associated with using the cloud. We now describe in detail how the primary server operates. The primary server We ﬁrst describe how the primary server stores the tasks, then outline the workings of the run method at a high level, and lastly zoom in on the message- handling part of the primary server. a. The tasks-related lists There are three tasks-related lists - the actual list of tasks and two auxiliary lists used for performance and fault tolerance. We describe them in turn. The list of tasks, called tasks, is sorted in the order of non-decreasing hard- ness of tasks. This order maximizes the number of tasks that are not attempted as a result of a previous task timing out. The original order of tasks is restored prior to the printing of results. The list tasks_from_failed consists of indices of the tasks that have been assigned to a client, but not completed due to a failure of the client instance. When a client requests tasks, the tasks in tasks_from_failed are assigned ﬁrst. The next task from tasks is assigned only if tasks_from_failed is empty. Lastly, the list min_hard consists of hardnesses of tasks that have timed out. Whenever the server is about to assign a task, it ﬁrst checks whether the hardness of the task is equal or greater than any of the elements in min_hard. min_hard is kept small by only storing the minimal elements. b. The run method The primary server object’s run method executes an inﬁnite loop. An iter- ation of this loop performs the following actions: 1. Informs the backup server that the primary server is continuing to function properly. We refer to such a message as a health update. 13 2. Handles handshake requests from newly started instances. The instance can be either a backup server or a client. We refer to the instance that has shaken hands with the primary server as an active instance. In response to a handshake request, two-way communication channel with the instance is established.4 In contrast to this channel, the queue for ac- cepting handshakes is created by the primary server’s constructor. When an instance is started, it gets the IP address of the primary server and the port number for handshake requests as command line arguments. In addition, if the instance is a client, a folder for storing the client events is created. 3. Handles messages from clients. We outline the messages and how they are handled in the next section. 4. Creates either the backup server or a new client instance. The creation of the backup server takes precedence. If the backup server is already running or the researcher opted to not use a backup server for the experiment, then a new client is created. Cloud compute engines do not let users to create instances in quick succession. Therefore, ExpoCloud uses exponentially increasing delays between attempts at creating cloud instances. 5. Terminates unhealthy instances. An active instance is unhealthy if it failed to send health updates to the server for the period of time speciﬁed by the HEALTH_UPDATE_LIMIT constant. A non-active instance is unhealthy if it failed to shake hands with the primary server for the period of time speciﬁed by the INSTANCE_MAX_NON_ACTIVE_TIME constant. 6. Outputs the results once there are no tasks that have not been assigned to clients and all clients completed the tasks assigned to them. The servers do not stop once the results are output. Thus, the fault tolerance 4Namely, the instance owns two queues registered with a SyncManager object. The pri- mary server creates the two corresponding queues at its end. SyncManager is part of the multiprocessing module of the Python standard library. It provides for low-latency commu- nication, which makes the distributed approach eﬀective even for ﬁne-grained tasks. 14 mechanisms continue to protect the results against a possible primary server instance failure. c. The handling of messages The following is an outline of messages that may arrive to the primary server from the backup server and the client instances: • HEALTH_UPDATE - the health update coming from either the backup server or a client. The primary server simply saves the timestamp of the last health update for each instance. • REQUEST_TASKS - the request for tasks by a client. The body of the message speciﬁes the number of tasks requested. If there are remaining unassigned tasks, the GRANT_TASKS message is sent in response. The body of this message contains the tasks assigned to the requesting client, including both the parameters and the full representation of the problem instances to be solved. If there are no unassigned tasks, the response is the NO_- FURTHER_TASKS message. • RESULT - the result of executing a task. The primary server stores the result with the task object. • REPORT_HARD_TASK - the report about a timed out task. The primary server updates the min_hard list and sends the APPLY_DOMINO_EFFECT message to all the clients, so they can terminate any task that is as hard or harder than the task just timed out. • LOG and EXCEPTION - the report about an event related to executing a task or to an exception, respectively, sent by a client. The primary server stores the event in the ﬁtting ﬁle corresponding to the client. • BYE - the client is done, which means that it had sent to the primary server the results for all the tasks assigned to it and had previously received the NO_FURTHER_TASKS message. The primary server terminates the client instance, so the researcher will not incur any further charges. 15 The primary server forwards a copy of each message from a client to the backup server. This keeps the backup server up-to-date and ready to take over should the primary server instance fail. This is further detailed in the section on fault tolerance below. We will now describe the operation of the clients. The clients We ﬁrst describe the main loop of the client object’s run method, then detail how the workers are managed and lastly zoom in on the message-handling part of the client. a. The main loop In contrast to the primary server, the client’s main loop is not inﬁnite – it stops when there are no tasks assigned to the client, and no more tasks that can be assigned to it by the primary server (i.e. the NO_FURTHER_TASKS message has been received). Each iteration of the main loop performs the following actions: 1. Sends the health update to the servers. 2. Processes workers as detailed in the next section. 3. Requests tasks from the primary server, subject to availability of idle CPUs and the NO_FURTHER_TASKS message not having been received. Note that the tasks requested previously, but not yet granted are taken into account when determining how many idle CPUs there are. 4. Processes messages from the primary server as detailed in a separate sec- tion below. 5. If new tasks have been granted by the primary server, starts the worker processes to execute them. Foe each message sent to the primary server, the client sends a copy of the message to the backup server. The need for this is explained in the below section on fault tolerance. That section also details what the client does with the incoming messages from the backup server. 16 Once the main loop is exited, the client sends the BYE message and completes. b. The management of workers Each task is performed by a separate worker process. The client performs three action to manage the workers: • Processes messages arriving from the workers. A worker can send two messages - WORKER_STARTED and WORKER_DONE. In response to either mes- sage, the client sends the LOG message with the corresponding body to the servers. The WORKER_DONE message results in sending the RESULT message as well. • Takes accounting of the worker processes that are no longer alive (i.e. either done or terminated), so as to be able to assign the released CPUs to other tasks. • Terminates processes whose tasks timed out. The client sends the REPORT_HARD_TASK message to the servers for each timed out task. c. The handling of messages from the primary server The following is an outline of messages that may arrive to the client from the primary server: • GRANT_TASKS - one or more tasks have been assigned to the client. The task is added to tasks list and a LOG message is sent to the servers to record the event of the receipt. • APPLY_DOMINO_EFFECT - the hardness of a task that timed out is reported by the primary server. The client terminates all workers currently per- forming tasks of equal or greater hardness. • NO_FURTHER_TASKS - the primary server informs that there are no more tasks to be assigned. The client stores this information, so as to avoid requesting tasks and exit the main loop once all the worker processes are completed. 17 In addition to the above messages, there are the STOP, RESUME and SWAP_- QUEUES messages, used to achieve fault tolerance. These are detailed in the next section. Fault tolerance One standard technique for achieving fault tolerance in a distributed system is by using redundancy [5]. This is the approach we follow by employing a backup server that mirrors the primary one and substitutes for it in the case of a failure. A backup server is not used when the computation is performed using the local machine engine. As mentioned above, the researcher may choose to disable the use of the backup server. This may be desired for a short experiment. We distinguish between three kinds of failure: client instance failure, backup server failure and primary server failure. Client failure does not require any special action besides registering the failure and re-assigning the tasks previ- ously assigned to the failed client. The latter is achieved by maintaining the tasks_from_failed list, as described above. In contrast, care needs to be taken to achieve correctness of recovery after a server failure. The following sections detail how this is achieved. a. Creation of the backup server The primary server creates the backup server in the same way as it creates clients. When a backup server instance does not yet exist, its creation takes precedence over the creation of a new client. Note that the backup server maybe created either at the beginning of the computation or after a server failure.5 Therefore, we need to create the backup server under the assumption that the distributed computation is in progress. To make sure that the newly created backup server is fully synchronized with the primary server, the primary server freezes its state prior to creating 5We will see below how the case of primary server failure is reduced to the case of the backup server failure. 18 the backup server. First, it stops accepting handshake requests from new client instances. Second, it sends the STOP message to the active clients, which causes them to refrain from actions that may result in messages to the server. An exception is made for the health reports, which the clients continue to send. Next, the primary server serializes its full state into a ﬁle in the output folder, creates a new instance on the compute engine, and copies the output folder to it. It then starts the backup server script on the new instance. This script unserializes the server object and runs its assume_backup_role method. As the name suggests, this method converts the primary server object into a backup server one. First, it disconnects the server object from the clients’ channels for communicating with the primary server and connects it to the channels for communicating with the backup server. Second, it creates a two-way channel for communicating with the primary server. Lastly, it shakes hands with the primary server, whereby two-way communication between them is established. Upon this handshake, the primary server resumes accepting handshake requests from new client instances and sends the RESUME message to the clients, so they can resume normal operation. Finally, the backup server script starts the main event loop of the server object. b. Primary and backup server coordination Whenever a new client shakes hands with the primary server, the latter sends the NEW_CLIENT message to the backup server with the information about the client. In response to this message the backup server creates the client object and establishes communication with it. Similarly, whenever the primary server detects a client failure, it sends the CLIENT_TERMINATED message to the backup server, which destroys the corresponding client object. When a client sends a message to the primary server, it sends a copy of the message to the backup server. Thus, the backup server receives two copies of each message sent by the client. The copy received directly from the client is needed for the case when the primary server fails before forwarding the message to the backup server. The copy received from the primary server is needed to 19 keep the two servers synchronized, as described below. The backup server takes actions based on the copy of the message received from the primary server. It simply pops the corresponding message received directly from the client oﬀ the queue. When the backup server registers the pri- mary server failure, it will be ready to take over, with all the messages received directly from the clients after the last message forwarded by the primary server. The backup server processes messages from clients in the same exact way as the primary server. It also sends messages to the clients that mirror the messages sent from the primary server. The mechanism of the backup server taking actions based on the copy of the message received from the primary server takes care of two possible causes of desynchronization. First, a client may fail after sending a message to the primary server, but before sending a copy to the backup server. Second, due to race conditions, it is possible for the two servers to handle messages from diﬀerent clients, such as requests for tasks, in diﬀerent order and end up in diﬀerent states. Similarly to how the backup server processes two copies of each message from a client, the clients processes two copies of each message from the servers - one received from the primary server and the other received from the backup server. A client performs actions only based on the messages received from the primary server and pops oﬀ the queue the corresponding messages received from the backup server. When the primary server fails, the remaining messages received from the backup server are treated as if they were from the primary server, as detailed in the next section. c. Handling server failure In response to the backup server failure, the primary server simply creates the new backup server as outlined in the last section. In the case of the primary server failure, the backup server changes its own role to being the primary server. It then proceeds to create a temporary connec- tion to each client’s inbound queue for communication with the primary server 20 and sends a SWAP message. In response to this message, the client swaps the queues for communicating with the primary server with those for communicat- ing with the backup server. After this, the client is ready to proceed normally. Thus, the case of the primary server failure is now reduced to the case of the backup server failure discussed above. One special case is when the primary server fails after creating a client instance, but before the new client shakes hands and the backup server is up- dated. In this case, there is a dangling client instance incurring charges for the researcher. To avoid this, as part of the backup server assuming the role of the primary server, it requests from the engine the list of all compute instances and deletes all client instances that are not represented by an existing client object. Discussion and conclusions We have presented the ExpoCloud framework for distributed computing us- ing cloud compute engines. Unlike the existing tools geared towards business workloads [6], ExpoCloud is speciﬁcally designed to make it easy to execute large parameter-space explorations. It addresses the four main concerns of the researcher: ease of deﬁning the workload, harnessing as much compute power as can be used to speed up the experiment, eliminating computations that do not or are unlikely to complete in a reasonable amount of time, and avoid- ing unnecessary charges. Combined with mechanisms for fault tolerance, these properties make ExpoCloud a ﬁtting tool for many research projects requiring large-scale parameter-space explorations. Future work may consider executing workloads with task dependencies, integrating ExpoCloud with existing tools, and addressing security concerns. Acknowledgements Access to the Google Compute Engine was provided through the Israel Data Science Initiative. 21 References [1] M. Goldenberg, ExpoCloud’s page on GitHub. URL https://github.com/mgoldenbe/ExpoCloud [2] M. Goldenberg, ExpoCloud developer’s documentation. URL https://expocloud.netlify.app [3] A. Pollack, Tutorial: parallelize your python code and run it on Google Cloud. URL https://youtu.be/i4aFiIB5urA [4] C. Pinchak, P. Lu, J. Schaeﬀer, M. Goldenberg, The canadian internet- worked scientiﬁc supercomputer, 17th International Symposium on High Performance Computing Systems and Applications (HPCS) (2003) 193–199. [5] C. Storm, Fault Tolerance in Distributed Computing, Vieweg+Teubner Ver- lag, Wiesbaden, 2012, pp. 13–79. doi:10.1007/978-3-8348-2381-6_2. URL https://doi.org/10.1007/978-3-8348-2381-6_2 [6] B. Burns, B. Grant, D. Oppenheimer, E. Brewer, J. Wilkes, Borg, omega, and kubernetes, Communications of the ACM 59 (5) (2016) 50–57. 22","['g', 'u', 'expocloud', 'framework', 'time', 'budgeteﬀective', 'parameter', 'space', 'exploration', 'use', 'cloud', 'compute', 'engine', 'goldenberg1', 'technology', 'abstract', 'large', 'parameter', 'space', 'exploration', 'time', 'consume', 'critically', 'important', 'task', 'many', 'ﬁeld', 'modern', 'research', 'expocloud', 'enable', 'researcher', 'harness', 'cloud', 'compute', 'resource', 'achieve', 'time', 'budget', 'eﬀective', 'largescale', 'concurrent', 'parameter', 'space', 'exploration', 'enable', 'maximal', 'possible', 'level', 'concurrency', 'create', 'com', 'pute', 'instance', 'ontheﬂy', 'save', 'money', 'terminate', 'unneeded', 'instance', 'pro', 'vide', 'mechanism', 'save', 'time', 'money', 'avoid', 'exploration', 'parameter', 'setting', 'hard', 'hard', 'parameter', 'setting', 'exploration', 'time', 'eﬀective', 'fault', 'tolerance', 'mechanism', 'make', 'pocloud', 'suitable', 'large', 'experiment', 'provide', 'interface', 'allow', 'use', 'various', 'cloud', 'envi', 'ronment', 'proof', 'concept', 'implement', 'class', 'support', 'compute', 'engine', 'gce', 'also', 'implement', 'class', 'simulate', 'cloud', 'environment', 'local', 'machine', 'thereby', 'facilitate', 'development', 'article', 'describe', 'feature', 'provide', 'usage', 'example', 'software', 'well', 'document', 'available', 'mit', 'license', 'keyword', 'parameter', 'space', 'exploration', 'distribute', 'compute', 'cloud', 'compute', 'engine', 'largescale', 'address', 'mgoldenbgjctacil', 'preprint', 'submit', 'journal', 'parallel', 'distribute', 'computing', 'introduction', 'large', 'parameter', 'space', 'exploration', 'time', 'consume', 'critically', 'important', 'task', 'many', 'ﬁeld', 'modern', 'research', 'example', 'com', 'puter', 'science', 'research', 'often', 'concerned', 'study', 'algorithm', 'solve', 'computational', 'problem', 'behavior', 'computa', 'tion', 'time', 'solve', 'problem', 'control', 'number', 'parameter', 'possible', 'setting', 'parameter', 'form', 'large', 'parameter', 'space', 'thorough', 'exploration', 'require', 'run', 'solve', 'number', 'problem', 'instance', 'parameter', 'setting', 'problem', 'assumption', 'work', 'individual', 'parameter', 'setting', 'explore', 'concurrently', 'independently', 'absence', 'tool', 'make', 'parameter', 'exploration', 'easy', 'accomplish', 'researcher', 'resort', 'run', 'ad', 'script', 'local', 'machine', 'cluster', 'recently', 'cloudbase', 'compute', 'engine', 'become', 'budgetfriendly', 'option', 'amount', 'computational', 'power', 'available', 'service', 'usually', 'much', 'great', 'available', 'research', 'cluster', 'amount', 'technical', 'expertise', 'scripting', 'require', 'set', 'experiment', 'harness', 'resource', 'prove', 'stumble', 'block', 'result', 'researcher', 'adopt', 'simplify', 'limitation', 'use', 'multiple', 'thread', 'single', 'compute', 'instance', 'vision', 'envision', 'framework', 'let', 'researcher', 'deﬁne', 'hisher', 'work', 'load', 'achieve', 'maximal', 'concurrency', 'economize', 'hisher', 'time', 'money', 'allow', 'ﬂexibility', 'choose', 'cloud', 'platform', 'provide', 'fault', 'tolerance', 'implementation', 'vision', 'realize', 'word', 'appear', 'italic', 'follow', '•', 'workload', 'list', 'task', 'deﬁne', 'setting', 'parameter', 'compute', 'commencement', 'experiment', 'pass', 'framework', 'automate', 'execution', 'maximal', 'concurrency', 'achieve', 'create', 'new', 'compute', 'instance', 'often', 'allow', 'cloud', 'platform', 'long', 'task', 'assign', 'economize', 'time', 'achieve', 'let', 'user', 'specify', 'deadline', 'hardness', 'deﬁne', 'task', 'task', 'take', 'time', 'execute', 'time', 'speciﬁe', 'deadline', 'say', 'task', 'time', 'expocloud', 'terminate', 'time', 'task', 'automatically', 'task', '’s', 'tuple', 'parameter', 'value', 'correlate', 'time', 'require', 'execute', 'task', 'researcher', 'speciﬁes', 'subset', 'parameter', 'determine', 'task', '’s', 'hardness', 'provide', 'method', 'compare', 'hardness', 'task', 'task', 'time', 'framework', 'terminate', 'currently', 'run', 'task', 'hard', 'hard', 'time', 'task', 'also', 'avoid', 'run', 'task', 'future', 'framework', 'execute', 'task', 'order', 'easy', 'hard', 'maximize', 'number', 'task', 'execute', 'economize', 'money', 'achieve', 'delete', 'compute', 'instance', 'soon', 'task', 'assign', 'task', 'assign', 'provide', 'great', 'ﬂexibility', 'choose', 'cloud', 'platform', 'adapt', 'give', 'cloud', 'platform', 'need', 'merely', 'provide', 'extension', 'class', 'method', 'create', 'terminate', 'list', 'compute', 'instance', 'addition', 'researcher', 'full', 'control', 'property', 'compute', 'instance', 'create', 'base', 'machine', 'image', 'speciﬁe', 'researcher', 'fault', 'tolerance', 'mean', 'computation', 'proceed', 'even', 'compute', 'instance', 'fail', 'reason', 'move', 'main', 'part', 'article', 'introduce', 'example', 'use', 'demonstrate', 'framework', 'design', 'usage', 'example', 'parameter', 'exploration', 'consider', 'agent', 'assignment', 'problem', 'follow', 'team', 'agent', 'need', 'complete', 'project', 'consist', 'task', 'task', 'perform', 'sequentially', 'agent', 'task', 'give', 'tij', 'amount', 'time', 'second', 'agent', 'require', 'complete', 'task', 'problem', 'assign', 'agent', 'task', 'agent', 'assign', 'task', 'total', 'time', 'complete', 'project', 'minimize', 'suppose', 'use', 'classical', 'branch', 'bind', 'bb', 'search', 'solve', 'problem', 'follow', 'recursive', 'start', 'empty', 'assignment', 'agent', 'assign', 'task', 'recursive', 'call', 'extend', 'current', 'partial', 'assignment', 'assign', 'agent', 'next', 'task', 'task', 'assign', 'agent', 'say', 'assignment', 'full', 'base', 'case', 'recursion', 'update', 'currently', 'good', 'full', 'assignment', 'corresponding', 'time', 'complete', 'project', 'advantage', 'bb', 'search', 'bruteforce', 'search', 'call', 'bb', 'cutoﬀ', 'namely', 'time', 'correspond', 'current', 'partial', 'assignment', 'great', 'good', 'full', 'assignment', 'current', 'assign', 'ment', 'discard', 'lose', 'solution', 'optimality', 'eﬃcient', 'version', 'use', 'heuristic', 'give', 'partial', 'assignment', 'heuristic', 'lower', 'bind', 'time', 'need', 'complete', 'remain', 'task', 'bind', 'compute', 'assign', 'good', 'unused', 'agent', 'remain', 'task', 'allow', 'assignment', 'remain', 'agent', 'remain', 'task', 'sum', 'time', 'correspond', 'current', 'partial', 'assignment', 'heuristic', 'great', 'good', 'full', 'assignment', 'current', 'assignment', 'discard', 'thus', 'algorithmic', 'variant', 'bruteforce', 'search', 'classi', 'bb', 'search', 'bb', 'search', 'heuristic', 'thoroughly', 'understand', 'property', 'agent', 'assignment', 'problem', 'search', 'perfor', 'mance', 'solve', 'need', 'run', 'algorithmic', 'variant', 'solve', 'number', 'generate', 'problem', 'instance', 'many', 'possible', 'setting', 'number', 'agent', 'number', 'task', 'range', 'value', 'consider', 'number', 'agent', 'number', 'task', 'framework', 'question', 'easily', 'answer', 'first', 'range', 'depend', 'algorithmic', 'variant', 'bruteforce', 'search', 'able', 'handle', 'small', 'problem', 'heuristic', 'able', 'solve', 'much', 'large', 'instance', 'know', 'hisher', 'budget', 'time', 'whole', 'experiment', 'researcher', 'decide', 'deadline', 'problem', 'instance', 'heshe', 'perform', 'several', 'test', 'run', 'get', 'feeling', 'much', 'time', 'algorithmic', 'variant', 'take', 'solve', 'problem', 'instance', 'various', 'size', 'even', 'laborious', 'tuning', 'stage', 'researcher', 'still', 'run', 'risk', 'instance', 'take', 'disproportionately', 'long', 'time', 'possibly', 'stumble', 'whole', 'experiment', 'question', 'really', 'easy', 'first', 'researcher', 'write', 'short', 'class', 'deﬁne', 'task', 'run', 'algorithmic', 'variant', 'solve', 'single', 'problem', 'instance', 'particular', 'setting', 'n', 'decide', 'deadline', 'researcher', 'pick', 'large', 'range', 'value', 'n', 'upper', 'bound', 'sure', 'solve', 'good', 'algorithmic', 'variant', 'write', 'single', 'nested', 'loop', 'generate', 'task', 'show', 'next', 'section', 'researcher', 'notice', 'large', 'value', 'correspond', 'hard', 'problem', 'instance', 'large', 'value', 'also', 'clear', 'instance', 'likely', 'solve', 'fast', 'bb', 'search', 'heuristic', 'classical', 'bb', 'turn', 'fast', 'bruteforce', 'researcher', 'deﬁne', 'several', 'short', 'method', 'inform', 'framework', 'observation', 'experiment', 'go', 'care', 'stop', 'problem', 'instance', 'soon', 'time', 'attempt', 'explore', 'parameter', 'setting', 'hard', 'hard', 'researcher', 'need', 'worry', 'decide', 'number', 'compute', 'instance', 'create', 'instance', 'need', 'worry', 'stop', 'compute', 'instance', 'experiment', 'result', 'easily', 'obtain', 'nice', 'tabular', 'format', 'speciﬁe', 'short', 'method', 'researcher', 'want', 'run', 'experiment', 'locally', 'eg', 'hisher', 'laptop', 'well', 'make', 'easy', 'use', 'many', 'cpus', 'researcher', 'machine', 'desire', 'furthermore', 'run', 'actually', 'simulation', 'perform', 'experiment', 'cloud', 'thus', 'powerful', 'tool', 'facilitate', 'development', 'framework', 'write', 'available', 'github', 'mit', 'license', 'page', 'contain', 'user', 'documentation', 'link', 'developer', 'documentation', 'source', 'code', 'describe', 'next', 'section', 'detail', 'feature', 'framework', 'show', 'full', 'example', 'experiment', 'setup', 'run', 'material', 'method', 'overall', 'architecture', 'overall', 'architecture', 'show', 'figure', 'server', 'client', 'architecture', 'use', 'pull', 'model', 'assign', 'job', 'client', 'previous', 'research', 'show', 'suitability', 'architecture', 'distribute', 'scientiﬁc', 'computation', 'distinguish', 'attribute', 'create', 'compute', 'instance', 'ontheﬂy', 'create', 'client', 'ontheﬂy', 'enable', 'expocloud', 'harness', 'great', 'potential', 'largescale', 'concurrency', 'provide', 'cloudbase', 'compute', 'engine', 'create', 'replacement', 'server', 'ontheﬂy', 'enable', 'expocloud', 'achieve', 'eﬀective', 'fault', 'tolerance', 'feature', 'architecture', 'show', 'figure', 'first', 'twoway', 'communication', 'channel', 'client', 'backup', 'server', 'detail', 'need', 'channel', 'section', 'fault', 'tolerance', 'second', 'client', 'create', 'manage', 'worker', 'process', 'worker', 'responsible', 'execute', 'single', 'task', 'communicate', 'result', 'client', 'figure', 'overall', 'architecture', 'next', 'section', 'demonstrate', 'specify', 'example', 'experiment', 'describe', 'introduction', 'show', 'individual', 'component', 'architecture', 'implement', 'provide', 'time', 'budget', 'eﬃciency', 'describe', 'introduction', 'example', 'experiment', 'set', 'experiment', 'need', 'write', 'short', 'python', 'script', 'create', 'primary', 'server', 'object', 'provide', 'description', 'task', 'execute', 'conﬁguration', 'compute', 'engine', 'optional', 'argument', 'show', 'possible', 'script', 'explore', 'parameter', 'space', 'solv', 'e', 'agent', 'assignment', 'problem', 'use', 'bb', 'part', 'script', 'construct', 'list', 'task', 'x', 'n', 'c', 'e', 'p', 'e', 'r', 'e', 'r', 'p', 'option', 'cutoff', 'option', 'heuristic', 'r', 'x', 'n', 'r', 'g', 'e', '∗', 'c', 'g', 'e', 'e', 'e', 'c', 'e', 'r', 'n', 'c', 'e', 'p', 'e', 'r', 'e', 'r', 'n', 'c', 'e', 'c', 'append', 'task', 'p', 'n', 'c', 'e', 'outer', 'loop', 'iterate', 'variant', 'brute', 'force', 'search', 'classical', 'bb', 'search', 'bb', 'search', 'heuristic', 'follow', 'nest', 'loop', 'iterate', 'possible', 'value', 'n', 'parameter', 'set', 'task', 'form', 'generate', 'problem', 'instance', 'task', 'add', 'list', 'task', 'key', 'component', 'task', 'class', 'researcher', 'need', 'provide', 'experiment', 'class', 'look', 'follow', 'l', 'task', 'def', 'l', 'g', 'r', 'e', 'task', 'l', 'g', 'r', 'e', 'def', 'p', 'r', 'e', 'e', 'r', 'l', 'return', 'n', 'c', 'p', 'r', 'e', 'e', 'r', 'l', 'p', 'r', 'e', 'e', 'r', 'return', 'n', 'c', 'p', 'r', 'e', 'e', 'r', 'r', 'p', 'r', 'e', 'p', 'r', 'e', 'e', 'r', 'def', 'p', 'h', 'r', 'p', 'option', 'heuristic', 'p', 'return', 'option', 'cutoff', 'p', 'return', 'return', 'return', 'p', 'h', 'r', 'p', 'n', 'n', 'e', 'def', 'r', 'e', 'l', 'return', 'l', 'g', 'r', 'r', 'l', 'def', 'run', 'return', 'l', 'g', 'r', 'e', 'r', 'c', 'h', 'def', 'g', 'r', 'u', 'p', 'p', 'r', 'e', 'e', 'r', 'l', 'return', 'l', 'e', 'r', 'p', 'r', 'e', 'e', 'r', 'l', 'brief', 'description', 'method', 'follow', 'parametertitle', 'return', 'tuple', 'parameter', 'name', 'appear', 'column', 'title', 'format', 'output', 'example', 'imple', 'mentation', 'consist', 'parameter', 'problem', 'instance', 'number', 'agent', 'number', 'task', 'append', 'rameter', 'search', 'use', '•', 'parameter', 'return', 'tuple', 'parameter', 'value', 'describe', 'task', 'hardnessparameter', 'return', 'subset', 'parameter', 'use', 'deter', 'task', 'default', 'implementation', 'say', 'task', 't1', 'hard', 'hard', 'task', 't2', 'hardness', 'parameter', 'former', 'great', 'equal', 'correspond', 'parameter', 'latter', 'note', 'show', 'code', 'convert', 'param', 'eter', 'search', 'algorithm', 'number', 'adapt', 'default', 'implementation', 'internally', 'hardness', 'task', 'store', 'instance', 'hardness', 'class', 'deﬁne', 'inside', 'abstracttask', 'task', 'class', 'derive', 'abstracttask', 'provide', 'deﬁnition', 'hardness', 'thereby', 'gain', 'full', 'control', 'way', 'hardness', 'task', 'compare', 'resulttitle', 'return', 'tuple', 'name', 'output', 'quantity', 'optimal', 'time', 'execute', 'project', 'time', 'take', 'search', 'actual', 'tuple', 'output', 'quantity', 'return', 'run', 'method', 'describe', 'run', 'execute', 'task', 'run', 'search', 'solve', 'instance', 'implement', 'exam', 'ple', 'suitable', 'method', 'object', 'run', 'otherwise', 'run', 'shell', 'command', 'groupparametertitle', 'return', 'tuple', 'parameter', 'name', 'determine', 'group', 'task', 'explain', 'consider', 'state', 'experiment', 'result', 'problem', 'instance', 'particular', 'setting', 'parameter', 'compute', 'suppose', 'task', 'time', 'point', 'disqualiﬁe', 'remain', 'task', 'hard', 'stand', 'reason', 'result', 'execute', 'task', 'discard', 'average', 'output', 'quantity', 'task', 'low', 'statistical', 'signiﬁcance', 'hand', 'obtain', 'result', 'instance', 'particularly', 'hard', 'task', 'time', 'want', 'keep', 'result', 'setting', 'parameter', 'make', 'decision', 'keep', 'parameter', 'set', 'pergroup', 'basis', 'group', 'consist', 'task', 'value', 'parameter', 'return', 'groupparametertitle', 'method2', 'group', 'keep', 'number', 'solve', 'task', 'group', 'least', 'large', 'optional', 'mingroupsize', 'argument', 'constructor', 'server', 'object', 'show', 'implementation', 'group', 'deﬁne', 'somewhat', 'similar', 'idea', 'group', 'clause', 'parameter', 'problem', 'instance', 'particular', 'setting', 'parameter', 'default', 'value', 'mingroupsize', 'argument', 'mean', 'result', 'keep', 'next', 'section', 'script', 'speciﬁes', 'conﬁguration', 'compute', 'engine', 'pass', 'conﬁguration', 'constructor', 'engine', 'object', 'c', 'g', 'p', 'r', 'g', 'n', 'p', 'r', 'j', 'g', 'n', 'zone', 'e', 'l', '−a', 'e', 'r', 'e', 'r', 'e', 'r', 'e', 'r', '−t', 'e', 'p', 'l', 'e', 'c', 'l', 'e', 'c', 'l', 'e', 'n', '−t', 'e', 'p', 'l', 'e', 'r', 'e', 'r', 'p', 'r', 'e', 'e', 'r', 'example', 'g', 'e', 'g', 'n', 'e', 'g', 'n', 'conﬁguration', 'dictionary', 'following', 'key', 'prefix', 'preﬁx', 'use', 'automatically', 'generate', 'name', 'compute', 'instance', 'several', 'experiment', 'diﬀerent', 'preﬁxe', 'conduct', 'simultaneously', 'project', 'name', 'identify', 'project', 'cloud', 'platform', 'zone', 'zone', 'allocate', 'compute', 'instance', 'pertain', 'current', 'implementation', 'gce', 'engine', 'limit', 'use', 'single', 'zone', 'limitation', 'lift', 'future', 'enable', 'even', 'large', 'scalability', 'serverimage', 'clientimage', 'name', 'machine', 'image', 'e', 'conﬁguration', 'cpu', 'family', 'number', 'amount', 'ram', 'future', 'server', 'client', 'instance', 'respectively', 'inexpensive', 'conﬁguration', 'cpus', 'use', 'server', 'opt', 'cpus', 'instance', 'client', 'expocloud', '’s', 'client', 'make', 'use', 'available', 'cpus', 'automatically', 'rootfolder', 'folder', 'reside', 'compute', 'instance', 'projectfolder', 'folder', 'userprovided', 'script', 'reside', 'folder', 'speciﬁe', 'dotted', 'format', 'show', 'listing3', 'case', 'engine', 'use', 'compute', 'engine', 'gce', 'dictionary', 'key', 'engine', 'diﬀer', 'example', 'zone', 'gce', 'concept', 'suitable', 'key', 'name', 'use', 'extension', 'class', 'platform', 'lastly', 'construct', 'primary', 'server', 'object', 'call', 'run', 'method', 'e', 'r', 'e', 'r', 'e', 'g', 'n', 'e', 'run', 'experiment', 'complete', 'main', 'expocloud', 'folder', 'primary', 'server', 'output', 'folder', 'contain', 'result', 'folder', 'client', 'instance', 'client', 'folder', 'contain', 'ﬁle', 'event', 'send', 'client', 'expocloud', 'provide', 'script', 'convenient', 'viewing', 'result', 'client', 'event', 'relate', 'execution', 'task', 'provide', 'local', 'machine', 'engine', 'run', 'experiment', 'lo', 'cally', 'change', 'script', 'concern', 'construction', 'engine', 'object', 'e', 'g', 'n', 'l', 'e', 'g', 'n', 'example', 'g', 'e', 'g', 'n', 'experiment', 'complete', 'main', 'expocloud', 'folder', 'output', 'folder', 'server', 'well', 'ﬁle', 'stdout', 'stderr', 'client', 'run', 'experiment', 'locally', 'useful', 'small', 'initial', 'exploration', 'also', 'enable', 'rapid', 'development', 'make', 'unnecessary', 'format', 'path', 'speciﬁe', 'use', 'commandline', 'argument', 'copy', 'update', 'version', 'cloud', 'avoid', 'latency', 'associate', 'use', 'cloud', 'describe', 'detail', 'primary', 'server', 'operate', 'primary', 'server', 'ﬁrst', 'describe', 'primary', 'server', 'store', 'task', 'outline', 'working', 'run', 'method', 'high', 'level', 'lastly', 'zoom', 'message', 'handle', 'part', 'primary', 'server', 'tasksrelated', 'list', 'tasksrelated', 'list', 'actual', 'list', 'task', 'auxiliary', 'list', 'use', 'performance', 'fault', 'tolerance', 'describe', 'turn', 'list', 'task', 'call', 'task', 'sort', 'order', 'nondecrease', 'hard', 'ness', 'task', 'order', 'maximize', 'number', 'task', 'attempt', 'result', 'previous', 'task', 'time', 'original', 'order', 'task', 'restore', 'prior', 'printing', 'result', 'list', 'tasksfromfaile', 'consist', 'index', 'task', 'assign', 'client', 'complete', 'failure', 'client', 'instance', 'client', 'request', 'task', 'task', 'tasksfromfaile', 'assign', 'ﬁrst', 'next', 'task', 'task', 'assign', 'tasksfromfaile', 'empty', 'lastly', 'list', 'minhard', 'consist', 'hardness', 'task', 'time', 'server', 'assign', 'task', 'ﬁrst', 'check', 'hardness', 'task', 'equal', 'great', 'element', 'minhard', 'minhard', 'keep', 'small', 'store', 'minimal', 'element', 'run', 'method', 'primary', 'server', 'object', 'run', 'method', 'execute', 'inﬁnite', 'loop', 'iter', 'ation', 'loop', 'perform', 'follow', 'action', 'inform', 'backup', 'server', 'primary', 'server', 'continue', 'function', 'properly', 'refer', 'message', 'health', 'update', 'handle', 'handshake', 'request', 'newly', 'start', 'instance', 'instance', 'backup', 'server', 'client', 'refer', 'instance', 'shake', 'hand', 'primary', 'server', 'active', 'instance', 'response', 'handshake', 'request', 'twoway', 'communication', 'channel', 'instance', 'established4', 'contrast', 'channel', 'queue', 'ac', 'cepte', 'handshake', 'create', 'primary', 'server', 'constructor', 'instance', 'start', 'get', 'ip', 'address', 'primary', 'server', 'port', 'number', 'handshake', 'request', 'command', 'line', 'argument', 'addition', 'instance', 'client', 'folder', 'store', 'client', 'event', 'create', 'handle', 'message', 'client', 'outline', 'message', 'handle', 'next', 'section', 'create', 'backup', 'server', 'new', 'client', 'instance', 'creation', 'backup', 'server', 'take', 'precedence', 'backup', 'server', 'already', 'run', 'researcher', 'opt', 'use', 'backup', 'server', 'experiment', 'new', 'client', 'create', 'compute', 'engine', 'let', 'user', 'create', 'instance', 'quick', 'succession', 'therefore', 'use', 'exponentially', 'increase', 'delay', 'attempt', 'create', 'cloud', 'instance', 'terminate', 'unhealthy', 'instance', 'active', 'instance', 'unhealthy', 'fail', 'send', 'health', 'update', 'server', 'period', 'time', 'speciﬁe', 'healthupdatelimit', 'constant', 'nonactive', 'instance', 'unhealthy', 'fail', 'shake', 'hand', 'primary', 'server', 'period', 'time', 'speciﬁe', 'instancemaxnonactivetime', 'constant', 'output', 'result', 'task', 'assign', 'client', 'client', 'complete', 'task', 'assign', 'server', 'stop', 'result', 'output', 'thus', 'fault', 'tolerance', '4namely', 'instance', 'queue', 'register', 'syncmanager', 'object', 'create', 'correspond', 'queue', 'end', 'syncmanager', 'part', 'multiprocesse', 'module', 'library', 'provide', 'lowlatency', 'commu', 'nication', 'make', 'distribute', 'approach', 'eﬀective', 'even', 'ﬁnegraine', 'task', 'mechanism', 'continue', 'protect', 'result', 'possible', 'primary', 'server', 'instance', 'failure', 'c', 'handling', 'message', 'following', 'outline', 'message', 'arrive', 'primary', 'server', 'backup', 'server', 'client', 'instance', 'healthupdate', 'health', 'update', 'come', 'backup', 'server', 'client', 'primary', 'server', 'simply', 'save', 'timestamp', 'last', 'health', 'update', 'instance', 'requesttask', 'request', 'task', 'client', 'body', 'message', 'speciﬁes', 'number', 'task', 'request', 'remain', 'unassigned', 'task', 'granttask', 'message', 'send', 'response', 'body', 'message', 'contain', 'task', 'assign', 'request', 'client', 'include', 'parameter', 'full', 'representation', 'problem', 'instance', 'solve', 'unassigned', 'task', 'response', 'furthertask', 'message', 'result', 'result', 'execute', 'task', 'primary', 'server', 'store', 'result', 'task', 'object', 'report', 'timed', 'task', 'primary', 'server', 'update', 'minhard', 'list', 'send', 'applydominoeffect', 'message', 'client', 'terminate', 'task', 'hard', 'hard', 'task', 'time', 'log', 'exception', 'report', 'event', 'relate', 'execute', 'task', 'exception', 'respectively', 'send', 'client', 'primary', 'server', 'store', 'event', 'ﬁtte', 'correspond', 'client', 'client', 'mean', 'send', 'primary', 'server', 'result', 'task', 'assign', 'previously', 'receive', 'nofurthertask', 'message', 'primary', 'server', 'terminate', 'client', 'instance', 'researcher', 'incur', 'charge', 'primary', 'server', 'forward', 'copy', 'message', 'client', 'backup', 'server', 'keep', 'backup', 'server', 'uptodate', 'ready', 'take', 'primary', 'server', 'instance', 'fail', 'far', 'detailed', 'section', 'fault', 'tolerance', 'describe', 'operation', 'client', 'client', 'ﬁrst', 'describe', 'main', 'loop', 'client', 'object', 'run', 'method', 'detail', 'worker', 'manage', 'lastly', 'zoom', 'messagehandling', 'part', 'client', 'main', 'loop', 'contrast', 'primary', 'server', 'client', 'main', 'loop', 'inﬁnite', 'stop', 'task', 'assign', 'client', 'task', 'assign', 'primary', 'server', 'nofurthertask', 'message', 'receive', 'iteration', 'main', 'loop', 'perform', 'follow', 'action', 'send', 'health', 'update', 'server', 'process', 'worker', 'detail', 'next', 'section', 'request', 'task', 'primary', 'server', 'subject', 'availability', 'idle', 'cpus', 'nofurthertask', 'message', 'receive', 'note', 'task', 'request', 'previously', 'yet', 'grant', 'take', 'account', 'determine', 'many', 'idle', 'cpus', 'process', 'message', 'primary', 'server', 'detailed', 'separate', 'tion', 'new', 'task', 'grant', 'primary', 'server', 'start', 'worker', 'process', 'execute', 'foe', 'message', 'send', 'primary', 'server', 'client', 'send', 'copy', 'message', 'backup', 'server', 'need', 'explain', 'section', 'fault', 'tolerance', 'section', 'also', 'detail', 'client', 'incoming', 'message', 'backup', 'server', 'main', 'loop', 'exit', 'client', 'send', 'message', 'complete', 'management', 'worker', 'task', 'perform', 'separate', 'worker', 'process', 'client', 'perform', 'action', 'manage', 'worker', 'process', 'message', 'arrive', 'worker', 'worker', 'send', 'message', 'workerstarte', 'workerdone', 'response', 'sage', 'client', 'send', 'log', 'message', 'correspond', 'body', 'server', 'workerdone', 'message', 'result', 'send', 'result', 'message', 'well', 'take', 'accounting', 'worker', 'process', 'long', 'alive', 'either', 'terminate', 'able', 'assign', 'release', 'cpus', 'task', 'terminate', 'process', 'task', 'time', 'client', 'send', 'reporthardtask', 'message', 'server', 'time', 'task', 'handling', 'message', 'primary', 'server', 'following', 'outline', 'message', 'arrive', 'client', 'primary', 'server', 'granttask', 'task', 'assign', 'client', 'task', 'add', 'task', 'list', 'log', 'message', 'send', 'server', 'record', 'event', 'hardness', 'task', 'time', 'report', 'primary', 'server', 'client', 'terminate', 'worker', 'currently', 'form', 'task', 'equal', 'great', 'hardness', 'nofurthertask', 'primary', 'server', 'inform', 'task', 'assign', 'client', 'store', 'information', 'avoid', 'request', 'task', 'exit', 'main', 'loop', 'worker', 'process', 'complete', 'addition', 'message', 'stop', 'resume', 'swap', 'queue', 'message', 'use', 'achieve', 'fault', 'tolerance', 'detail', 'next', 'section', 'fault', 'tolerance', 'standard', 'technique', 'achieve', 'fault', 'tolerance', 'distribute', 'system', 'use', 'redundancy', 'approach', 'follow', 'employ', 'backup', 'server', 'mirror', 'primary', 'one', 'substitute', 'case', 'failure', 'backup', 'server', 'use', 'computation', 'perform', 'use', 'local', 'machine', 'engine', 'mention', 'researcher', 'choose', 'disable', 'use', 'backup', 'server', 'desire', 'short', 'experiment', 'distinguish', 'kind', 'failure', 'client', 'instance', 'failure', 'backup', 'server', 'failure', 'primary', 'server', 'failure', 'client', 'failure', 'require', 'special', 'action', 'register', 'failure', 'reassign', 'task', 'previ', 'ously', 'assign', 'failed', 'client', 'latter', 'achieve', 'maintain', 'tasksfromfaile', 'list', 'describe', 'contrast', 'care', 'need', 'take', 'achieve', 'correctness', 'recovery', 'server', 'failure', 'follow', 'section', 'detail', 'achieve', 'creation', 'backup', 'server', 'primary', 'server', 'create', 'backup', 'server', 'way', 'create', 'client', 'backup', 'server', 'instance', 'yet', 'exist', 'creation', 'take', 'precedence', 'creation', 'new', 'client', 'note', 'backup', 'server', 'maybe', 'create', 'beginning', 'computation', 'server', 'failure5', 'therefore', 'need', 'create', 'backup', 'server', 'assumption', 'distribute', 'computation', 'progress', 'make', 'sure', 'newly', 'create', 'backup', 'server', 'fully', 'synchronize', 'primary', 'server', 'primary', 'server', 'freeze', 'state', 'prior', 'create', '5we', 'see', 'case', 'primary', 'server', 'failure', 'reduce', 'case', 'backup', 'server', 'failure', 'backup', 'server', 'first', 'stop', 'accept', 'handshake', 'request', 'new', 'client', 'instance', 'second', 'send', 'stop', 'message', 'active', 'client', 'cause', 'refrain', 'action', 'result', 'message', 'server', 'exception', 'make', 'health', 'report', 'client', 'continue', 'send', 'next', 'primary', 'server', 'serialize', 'full', 'state', 'ﬁle', 'output', 'folder', 'create', 'new', 'instance', 'compute', 'engine', 'copy', 'output', 'folder', 'start', 'backup', 'server', 'script', 'new', 'instance', 'script', 'unserialize', 'server', 'object', 'run', 'assumebackuprole', 'method', 'name', 'suggest', 'method', 'convert', 'primary', 'server', 'object', 'backup', 'server', 'first', 'disconnect', 'server', 'object', 'client', 'channel', 'communicate', 'primary', 'server', 'connect', 'channel', 'communicate', 'backup', 'server', 'second', 'create', 'twoway', 'channel', 'communicate', 'primary', 'server', 'lastly', 'shake', 'hand', 'primary', 'server', 'twoway', 'communication', 'establish', 'handshake', 'primary', 'server', 'resume', 'accept', 'handshake', 'request', 'new', 'client', 'instance', 'send', 'resume', 'message', 'client', 'resume', 'normal', 'operation', 'finally', 'backup', 'server', 'script', 'start', 'main', 'event', 'loop', 'server', 'object', 'primary', 'backup', 'server', 'coordination', 'new', 'client', 'shake', 'hand', 'primary', 'server', 'latter', 'send', 'newclient', 'message', 'backup', 'server', 'information', 'client', 'response', 'message', 'backup', 'server', 'create', 'client', 'object', 'establish', 'communication', 'similarly', 'primary', 'server', 'detect', 'client', 'failure', 'send', 'clientterminate', 'message', 'backup', 'server', 'destroy', 'correspond', 'client', 'object', 'client', 'send', 'message', 'primary', 'server', 'send', 'copy', 'message', 'backup', 'server', 'thus', 'backup', 'server', 'receive', 'copy', 'message', 'send', 'client', 'copy', 'receive', 'directly', 'client', 'need', 'case', 'primary', 'server', 'fail', 'forward', 'message', 'backup', 'server', 'copy', 'receive', 'primary', 'server', 'need', 'keep', 'server', 'synchronize', 'describe', 'backup', 'server', 'take', 'action', 'base', 'copy', 'message', 'receive', 'primary', 'server', 'simply', 'pop', 'correspond', 'message', 'receive', 'directly', 'client', 'oﬀ', 'queue', 'backup', 'server', 'register', 'failure', 'ready', 'take', 'message', 'receive', 'directly', 'client', 'last', 'message', 'forward', 'primary', 'server', 'backup', 'server', 'process', 'message', 'client', 'exact', 'way', 'primary', 'server', 'also', 'send', 'message', 'client', 'mirror', 'message', 'send', 'primary', 'server', 'mechanism', 'backup', 'server', 'take', 'action', 'base', 'copy', 'message', 'receive', 'primary', 'server', 'take', 'care', 'possible', 'cause', 'desynchronization', 'first', 'client', 'fail', 'send', 'message', 'primary', 'server', 'send', 'copy', 'backup', 'server', 'second', 'race', 'condition', 'possible', 'server', 'handle', 'message', 'diﬀerent', 'client', 'request', 'task', 'diﬀerent', 'order', 'end', 'diﬀerent', 'state', 'similarly', 'backup', 'server', 'process', 'copy', 'message', 'client', 'client', 'process', 'copy', 'message', 'server', 'receive', 'primary', 'server', 'receive', 'backup', 'server', 'client', 'perform', 'action', 'base', 'message', 'receive', 'primary', 'server', 'pop', 'oﬀ', 'queue', 'correspond', 'message', 'receive', 'backup', 'server', 'primary', 'server', 'fail', 'remain', 'message', 'receive', 'backup', 'server', 'treat', 'primary', 'server', 'detailed', 'next', 'section', 'handle', 'server', 'failure', 'response', 'backup', 'server', 'failure', 'primary', 'server', 'simply', 'create', 'new', 'backup', 'server', 'outline', 'last', 'section', 'case', 'primary', 'server', 'failure', 'backup', 'server', 'change', 'role', 'primary', 'server', 'proceed', 'create', 'temporary', 'connec', 'tion', 'client', 'inbound', 'queue', 'communication', 'primary', 'server', 'send', 'swap', 'message', 'response', 'message', 'client', 'swap', 'queue', 'communicate', 'primary', 'server', 'communicat', 'e', 'backup', 'server', 'client', 'ready', 'proceed', 'normally', 'thus', 'case', 'primary', 'server', 'failure', 'reduce', 'case', 'backup', 'server', 'failure', 'discuss', 'special', 'case', 'primary', 'server', 'fail', 'create', 'client', 'instance', 'new', 'client', 'shake', 'hand', 'backup', 'server', 'date', 'case', 'dangle', 'client', 'instance', 'incur', 'charge', 'researcher', 'avoid', 'part', 'backup', 'server', 'assume', 'role', 'primary', 'server', 'request', 'engine', 'list', 'compute', 'instance', 'delete', 'client', 'instance', 'represent', 'exist', 'client', 'object', 'discussion', 'conclusion', 'present', 'expocloud', 'framework', 'distribute', 'compute', 'cloud', 'compute', 'engine', 'exist', 'tool', 'gear', 'business', 'workload', 'speciﬁcally', 'design', 'make', 'easy', 'execute', 'large', 'parameterspace', 'exploration', 'address', 'main', 'concern', 'researcher', 'ease', 'deﬁne', 'workload', 'harnessing', 'much', 'compute', 'power', 'use', 'speed', 'experiment', 'eliminate', 'computation', 'unlikely', 'complete', 'reasonable', 'amount', 'time', 'avoid', 'e', 'unnecessary', 'charge', 'combine', 'mechanism', 'fault', 'tolerance', 'property', 'make', 'expocloud', 'ﬁtte', 'tool', 'many', 'research', 'project', 'require', 'largescale', 'parameterspace', 'exploration', 'future', 'work', 'consider', 'execute', 'workload', 'task', 'dependency', 'integrate', 'expocloud', 'exist', 'tool', 'address', 'security', 'concern', 'acknowledgement', 'access', 'compute', 'engine', 'provide', 'reference', 'page', 'goldenberg', 'expocloud', 'developer', 'documentation', 'url', 'pollack', 'tutorial', 'parallelize', 'python', 'code', 'run', 'c', 'canadian', 'internet', 'work', 'scientiﬁc', 'supercomputer', '17th', 'international', 'symposium', 'high', 'performance', 'computing', 'system', 'application', 'c', 'storm', 'fault', 'tolerance', 'distribute', 'compute', 'viewegteubner', 'ver', 'lag', 'wiesbaden', 'b', 'burn', 'b', 'grant', 'oppenheimer', 'e', 'brewer', 'wilke', 'borg', 'omega', 'kubernete', 'communication', 'acm']"
COOKIEGRAPH: Measuring and Countering First-Party Tracking Cookies,"[{'href': 'http://arxiv.org/abs/2208.12370v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2208.12370v1', 'rel': 'related', 'type': 'application/pdf'}]",2022-08-25 22:56:31,"TMIC: App Inventor Extension for the Deployment of
Image Classification Models Exported from Teachable Machine

Fabiano Pereira de Oliveira
Department of Informatics and Statistics, Federal University of Santa Catarina
Florianópolis/SC, Brazil
fabiano.pereira.oliveira@grad.ufsc.br

Christiane Gresse von Wangenheim
Department of Informatics and Statistics, Federal University of Santa Catarina
Florianópolis/SC, Brazil
c.wangenheim@ufsc.br

Jean C. R. Hauck
Department of Informatics and Statistics, Federal University of Santa Catarina
Florianópolis/SC, Brazil
jean.hauck@ufsc.br

Summary

TMIC is an App Inventor extension for the deployment of ML models for image classification developed with
Google Teachable Machine in educational settings. Google Teachable Machine, is an intuitive visual tool that
provides workflow-oriented support for the development of ML models for image classification. Aiming at the
usage of models developed with Google Teachable Machine, the extension TMIC enables the deployment of the
trained models exported as TensorFlow.js to Google Cloud as part of App Inventor, one of the most popular
block-based programming environments for teaching computing in K-12. The extension was created with the App
Inventor extension framework based on the extension PIC and is available under the BSD 3 license. It can be used
for teaching ML in K-12, in introductory courses in higher education or by anyone interested in creating
intelligent apps with image classification. The extension TMIC is being developed by the initiative Computação
na Escola of the Department of Informatics and Statistics at the Federal University of Santa Catarina/Brazil as part
of a research effort aiming at introducing AI education in K-12.

Keywords: Machine Learning, Image Classification, Google Teachable Machine, App Inventor, Extension

Statement of need

in our daily lives, e.g., as spam filters, recommendation
Nowadays, Machine Learning (ML) is present
mechanisms, chatbots, digital assistants, etc. Considering its inevitable impact
that people
understand Machine Learning not just as a consumer, but also as a creator of this type of innovation (Touretzky et
al., 2019). Therefore, it is important to start teaching ML concepts in K-12 following a trend emerging during the
last few years (Marques et al., 2020).
According to the K-12 Guidelines for Artificial Intelligence by AI4K12 (Touretsky et al., 2019), AI education
encompasses 5 big ideas, including Machine Learning (ML). This includes an understanding of basic ML
concepts as well as the application of these concepts, developing ML applications typically focusing on the task of
image classification. Image classification is the process of taking an input (like a photo or videostream) and
outputting a class (like “plastic garbage”) or a probability that the input is a particular class (“there’s a 90%
probability that this image shows a plastic garbage”). Teaching the application of ML following a human-centric

is essential

it

interactive ML process (Amershi et al., 2019, Gresse von Wangenheim and von Wangenheim, 2021) includes the
development, from requirements analysis to exporting the developed model and its deployment (Figure 1).

Figure 1. Human-centric interactive ML process

The development of ML models is typically taught in K-12 adopting visual tools, such as Google Teachable
Machine. Google Teachable Machine (teachablemachine.withgoogle.com) is a free web-based GUI tool for
creating custom machine learning classification models without specialized technical expertise (Carney et al.,
2020). Google Teachable Machine uses TensorFlow.js, to train and run the users’ models online. It runs within the
browser entirely on the user’s device, maintaining any input data locally, protecting data privacy. Google
Teachable Machine provides an intuitive workflow-oriented interface supporting the upload of the dataset, model
training and evaluation, as well as the prediction of the classes of new data and the export of the trained model
(Figure 2).

Figure 2. Example of ML model development with Google Teachable Machine

Furthermore, it is possible to download a trained model as a TensorFlow.js model and host it on Google Cloud, so
it can be deployed easily into any website or app. In this case Google Teachable Machine generates a URL where
the model is hosted for free and this link can be shared to use the created model. It can also be converted into a
TensorFlow or TensorFlow Lite model and downloaded for local use (Figure 3).

Figure 3. Example of exporting trained model as TensorFlow.js

is important

Metadata, a JSON file indicating the versions of the used libraries, metadata on the user and model

Model, a JSON file specifying the model topology
Weights, a BIN file specifying the weights of the trained model

The exported Tensorflow.js is a zip file including:
●
name, as well as a list of the label names and the size of the images used to train the model
●
●
The exported trained ML model can then be deployed in software systems, such as mobile applications. The
deployment of the trained model
to illustrate the usefulness of ML, not only teaching the
development of ML models, but also the creating of “intelligent” solutions. Such a deployment as part of IA/ML
education in K-12 is typically done within block-based programming environments such as App Inventor (Gresse
von Wangenheim et al., 2021).
MIT App Inventor (appinventor.mit.edu) is a free web platform that allows users to create mobile applications.
Users can design their own applications using drag and drop components and program its behavior using a
blocks-based programming language. The App Inventor core already provides a comprehensive set of
components, methods and commands for diverse kinds of functionality, including sensors, communication, data
storage, etc. It is also possible to further extend App Inventor by providing more components (Patton et al., 2019).
Extensions can also be used to incorporate ML features into App Inventor using the App Inventor extension
framework (http://ai2.appinventor.mit.edu/reference/other/extensions.html). An example of such an App Inventor
extension for integrating custom-trained image classification models is the Personal Image Classifier (PIC)

extension (Tang et al., 2019)(Tang, 2019). Support provided by PIC consists of a web application supporting the
model development and of the extension with new components for running the trained model in App Inventor
apps. However, certain shortcomings regarding the specific web application for the development of the model,
such as a lack of evaluation support in V2.0, performance problems of the trained models, and a lack of flexibility
allowing the deployment of ML models developed on other environments such as Teachable Machine, indicate a
need for further extensions.

TMIC Teachable Machine - Image Classifier Extension

TMIC is an App Inventor extension for the deployment of image classification models developed in Google
Teachable Machine. The extension is based on the PIC extension (Tang et al., 2019)(Tang, 2019), adapting the
PIC extension in order to enable the import of TensorFlow.js models created with Google Teachable Machine and
exported by uploading them on Google Cloud.

The TMIC extension includes the following properties:

URL_Model is the property responsible for containing the URL of the
model trained with the Google Teachable Machine that has been exported
as Tensorflow.js on Google Cloud.

WebViewer is the property that allows the user to assign a Web Browser
component so that
the extension can be used. The Web Browser
component is used in order to visualize the functionality of the extension.

The TMIC extension provides the following blocks:

Blocks of the TMIC extension

Functionality

The ClassifierReady event block is executed when the
extension finishes loading the ML model from the
GTM cloud.

The GotClassification event block is executed when the
extension finishes classifying an image. This event
the
occurs
the
of
ClassifyVideoData
predictions for each category in the model.

execution

returning

of
list

block,

right

after

the

The ClassifyVideoData block starts the classification of
the image captured by the smartphone’s rear-facing
camera video stream, using the WebViewer component.
When the classification is finished, the result is returned
via the GotClassification event block.

The StopWebcam block stops the webcam when
leaving the screen in which the image classification is
done.

The URL_Model adjustment block allows the user to
adjust
the ML model URL to another link of the
exported GTM model in Google Cloud.

TeachableMachineImageClassifier

The
returns a specific instance of the extension.

get

block

It

in which the first

is divided into backend and frontend,

The TMIC extension was developed using as a base the PIC extension code inside of the App Inventor framework
refers to the
for creating extensions.
TeachableMachineImageClassifier.java file, which initializes the extension and its blocks.
Each extension block is defined in the TeachableMachineImageClassifier.java class as a method responsible for
executing the action of this block.
The front end of the TMIC extension is made up of an HTML file along with four other Javascript files. The
extension needs to be rendered in an HTML page to open the camera (asking the user for permission), and display
it to the user. Javascript files are needed to load the model and perform the classification of the image when the
user requests it. The teachable_machine_image_classifier.js file is mainly responsible for performing the task of
communicating with the backend, receiving requests for loading the model, opening the cell phone camera and
classifying the image. This file also notifies the backend when the extension is ready and returns the ranking
results.
The other Javascript files refer to the GTM and TensorFlow.js frameworks, which work together to perform image
classification on the mobile device. Its functions are called within the teachable_machine_image_classifier.js code
and internally between the files. In total, the TMIC extension is made up of six files, one of the Java extension,
one of the HTML and four Javascript extension files.
The main methods of the Java class (TeachableMachineImageClassifier.java) are those that will define the
behavior of the blocks. Most of them need to communicate with the front-end, calling functions and passing
parameters to the file teachable_machine_image_classifier.js, which will process the submitted request.
The teachable_machine_image_classifier.js Javascript file functions are responsible for receive requests from the
TeachableMachineImageClassifier.java class, process them and return the result in cases where it is necessary to
notify that the extension is ready for the usage or prediction results are ready.
The classifyVideoData() function is responsible for loading the Teachable Machine cloud hosted template from a
user-defined URL in the property URL_Model. The classifyVideoData() function captures the URL of the two
JSON files, one containing the model trained and the other with the model metadata, from the URL defined earlier
in the preparation of the extension when it is initialized. After assigning the URL of the JSON files to two
variables, they are passed as parameters to the function tmImage.load(modelURL, metadataURL), belonging to
the Teachable Machine framework file teachablemachine-image.min.js, which will return the model prepared to
be used in image classification.
After the model is prepared, the model.getTotalClasses() function is called, which returns the number of model
classes for the maxPredictions variable. Finally, the function is called model.predict(webcamPredict.canvas),
which calls the classifier passing as a parameter the image captured at the exact moment the classifyVideoData()
function was executed, returning the prediction result in the prediction variable. Finally, after the prediction
variable is already with the classification result, an array with the results is filled in and returned to the Java class,
calling the method reportResult(String result), which will prepare the result and notify the event block
GotClassification.

The TMIC extension is provided with the BSD 3 license (https://opensource.org/licenses/BSD-3-Clause),
included in a LICENSE file. The license is available from the TMIC source code in the GitLab repository hosted

at the Federal University of Santa Catarina. Also along with the code sources, a NOTICE file is available
recognizing that the TMIC was developed by adjusting the PIC code.

Currently the TMIC extension supports only Tensorflow.js models exported to Google Cloud and only allows
capturing images with the rear-facing camera of the smartphone. We are planning to improve the extension as part
of future work.

Usage example

The extension can be used for teaching ML in K-12, in introductory courses in higher education or by anyone who
wants to create “intelligent” apps for image classification. As with any App Inventor extension it can be imported
into App Inventor and then used in order to run trained models as part of intelligent apps.
In order to support its usage the following material is available (currently in Brazilian Portuguese only):

● TMIC extension .aix
● Example app for the classification of recycling trash .aia (wireframe and final version)

● Online tutorial explaining the use of the extension

The extension and material is available online: https://computacaonaescola.ufsc.br/en/tmic/

Acknowledgments

This work is supported by CNPq (National Council for Scientific and Technological Development), a Brazilian
government entity focused on scientific and technological development.

References

Armeshi, S. et al. Software Engineering for Machine Learning: A Case Study. In: Proc. of the 41st International Conference
on Software Engineering: Software Engineering in Practice, IEEE Press, 2019, 291–300.

Carney, M. et al. Teachable Machine: Approachable Web-Based Tool for Exploring Machine Learning Classification. In:
Proc. of Conference on Human Factors in Computing Systems, ACM, 2020.

C. Gresse von Wangenheim, C. Gresse von Wangenheim. Overview on a human-centric interactive ML process for teaching
ML in K-12. Working Paper WP_GQS_01_2021_v10, GQS/INCoD/UFSC, 2021.

Gresse von Wangenheim, C.; Hauck, J. C. R.; Pacheco, F. S.; Bertonceli Bueno, M. F. Visual Tools for Teaching Machine
Learning in K-12: A Ten-Year Systematic Mapping. Education and Information Technologies, 2021.

Marques, L. S., Gresse von Wangenheim, C., Hauck, J. C. R. Teaching Machine Learning in School: A Systematic Mapping
of the State of the Art. Informatics in Education, 19(2), 2020.

Patton E.W., Tissenbaum M., Harunani F. MIT App Inventor: Objectives, Design, and Development. In: Kong SC., Abelson
H. (eds) Computational Thinking Education. Springer, Singapore, 2019.

Tang, D., Utsumi, Y., Lao, N. (2019). PIC: A Personal Image Classification Webtool for High School Students. In: Proc.of the
IJCAI EduAI Workshop, Macao, China, 2019.

Tang, D. (2019). Empowering Novices to Understand and Use Machine Learning With Personalized Image Classification
Models, Intuitive Analysis Tools, and MIT App Inventor, M.Eng thesis, MIT, Cambridge, USA.

Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D. Envisioning AI for k-12: What should every child know about
AI? In Proc. of AAAI Conference on Artificial Intelligence, Honolulu, HI, USA, 2019, 9795–9799.

","TMIC: App Inventor Extension for the Deployment of Image Classification Models Exported from Teachable Machine Fabiano Pereira de Oliveira Department of Informatics and Statistics, Federal University of Santa Catarina Florianópolis/SC, Brazil fabiano.pereira.oliveira@grad.ufsc.br Christiane Gresse von Wangenheim Department of Informatics and Statistics, Federal University of Santa Catarina Florianópolis/SC, Brazil c.wangenheim@ufsc.br Jean C. R. Hauck Department of Informatics and Statistics, Federal University of Santa Catarina Florianópolis/SC, Brazil jean.hauck@ufsc.br Summary TMIC is an App Inventor extension for the deployment of ML models for image classification developed with Google Teachable Machine in educational settings. Google Teachable Machine, is an intuitive visual tool that provides workflow-oriented support for the development of ML models for image classification. Aiming at the usage of models developed with Google Teachable Machine, the extension TMIC enables the deployment of the trained models exported as TensorFlow.js to Google Cloud as part of App Inventor, one of the most popular block-based programming environments for teaching computing in K-12. The extension was created with the App Inventor extension framework based on the extension PIC and is available under the BSD 3 license. It can be used for teaching ML in K-12, in introductory courses in higher education or by anyone interested in creating intelligent apps with image classification. The extension TMIC is being developed by the initiative Computação na Escola of the Department of Informatics and Statistics at the Federal University of Santa Catarina/Brazil as part of a research effort aiming at introducing AI education in K-12. Keywords: Machine Learning, Image Classification, Google Teachable Machine, App Inventor, Extension Statement of need in our daily lives, e.g., as spam filters, recommendation Nowadays, Machine Learning (ML) is present mechanisms, chatbots, digital assistants, etc. Considering its inevitable impact that people understand Machine Learning not just as a consumer, but also as a creator of this type of innovation (Touretzky et al., 2019). Therefore, it is important to start teaching ML concepts in K-12 following a trend emerging during the last few years (Marques et al., 2020). According to the K-12 Guidelines for Artificial Intelligence by AI4K12 (Touretsky et al., 2019), AI education encompasses 5 big ideas, including Machine Learning (ML). This includes an understanding of basic ML concepts as well as the application of these concepts, developing ML applications typically focusing on the task of image classification. Image classification is the process of taking an input (like a photo or videostream) and outputting a class (like “plastic garbage”) or a probability that the input is a particular class (“there’s a 90% probability that this image shows a plastic garbage”). Teaching the application of ML following a human-centric is essential it interactive ML process (Amershi et al., 2019, Gresse von Wangenheim and von Wangenheim, 2021) includes the development, from requirements analysis to exporting the developed model and its deployment (Figure 1). Figure 1. Human-centric interactive ML process The development of ML models is typically taught in K-12 adopting visual tools, such as Google Teachable Machine. Google Teachable Machine (teachablemachine.withgoogle.com) is a free web-based GUI tool for creating custom machine learning classification models without specialized technical expertise (Carney et al., 2020). Google Teachable Machine uses TensorFlow.js, to train and run the users’ models online. It runs within the browser entirely on the user’s device, maintaining any input data locally, protecting data privacy. Google Teachable Machine provides an intuitive workflow-oriented interface supporting the upload of the dataset, model training and evaluation, as well as the prediction of the classes of new data and the export of the trained model (Figure 2). Figure 2. Example of ML model development with Google Teachable Machine Furthermore, it is possible to download a trained model as a TensorFlow.js model and host it on Google Cloud, so it can be deployed easily into any website or app. In this case Google Teachable Machine generates a URL where the model is hosted for free and this link can be shared to use the created model. It can also be converted into a TensorFlow or TensorFlow Lite model and downloaded for local use (Figure 3). Figure 3. Example of exporting trained model as TensorFlow.js is important Metadata, a JSON file indicating the versions of the used libraries, metadata on the user and model Model, a JSON file specifying the model topology Weights, a BIN file specifying the weights of the trained model The exported Tensorflow.js is a zip file including: ● name, as well as a list of the label names and the size of the images used to train the model ● ● The exported trained ML model can then be deployed in software systems, such as mobile applications. The deployment of the trained model to illustrate the usefulness of ML, not only teaching the development of ML models, but also the creating of “intelligent” solutions. Such a deployment as part of IA/ML education in K-12 is typically done within block-based programming environments such as App Inventor (Gresse von Wangenheim et al., 2021). MIT App Inventor (appinventor.mit.edu) is a free web platform that allows users to create mobile applications. Users can design their own applications using drag and drop components and program its behavior using a blocks-based programming language. The App Inventor core already provides a comprehensive set of components, methods and commands for diverse kinds of functionality, including sensors, communication, data storage, etc. It is also possible to further extend App Inventor by providing more components (Patton et al., 2019). Extensions can also be used to incorporate ML features into App Inventor using the App Inventor extension framework (http://ai2.appinventor.mit.edu/reference/other/extensions.html). An example of such an App Inventor extension for integrating custom-trained image classification models is the Personal Image Classifier (PIC) extension (Tang et al., 2019)(Tang, 2019). Support provided by PIC consists of a web application supporting the model development and of the extension with new components for running the trained model in App Inventor apps. However, certain shortcomings regarding the specific web application for the development of the model, such as a lack of evaluation support in V2.0, performance problems of the trained models, and a lack of flexibility allowing the deployment of ML models developed on other environments such as Teachable Machine, indicate a need for further extensions. TMIC Teachable Machine - Image Classifier Extension TMIC is an App Inventor extension for the deployment of image classification models developed in Google Teachable Machine. The extension is based on the PIC extension (Tang et al., 2019)(Tang, 2019), adapting the PIC extension in order to enable the import of TensorFlow.js models created with Google Teachable Machine and exported by uploading them on Google Cloud. The TMIC extension includes the following properties: URL_Model is the property responsible for containing the URL of the model trained with the Google Teachable Machine that has been exported as Tensorflow.js on Google Cloud. WebViewer is the property that allows the user to assign a Web Browser component so that the extension can be used. The Web Browser component is used in order to visualize the functionality of the extension. The TMIC extension provides the following blocks: Blocks of the TMIC extension Functionality The ClassifierReady event block is executed when the extension finishes loading the ML model from the GTM cloud. The GotClassification event block is executed when the extension finishes classifying an image. This event the occurs the of ClassifyVideoData predictions for each category in the model. execution returning of list block, right after the The ClassifyVideoData block starts the classification of the image captured by the smartphone’s rear-facing camera video stream, using the WebViewer component. When the classification is finished, the result is returned via the GotClassification event block. The StopWebcam block stops the webcam when leaving the screen in which the image classification is done. The URL_Model adjustment block allows the user to adjust the ML model URL to another link of the exported GTM model in Google Cloud. TeachableMachineImageClassifier The returns a specific instance of the extension. get block It in which the first is divided into backend and frontend, The TMIC extension was developed using as a base the PIC extension code inside of the App Inventor framework refers to the for creating extensions. TeachableMachineImageClassifier.java file, which initializes the extension and its blocks. Each extension block is defined in the TeachableMachineImageClassifier.java class as a method responsible for executing the action of this block. The front end of the TMIC extension is made up of an HTML file along with four other Javascript files. The extension needs to be rendered in an HTML page to open the camera (asking the user for permission), and display it to the user. Javascript files are needed to load the model and perform the classification of the image when the user requests it. The teachable_machine_image_classifier.js file is mainly responsible for performing the task of communicating with the backend, receiving requests for loading the model, opening the cell phone camera and classifying the image. This file also notifies the backend when the extension is ready and returns the ranking results. The other Javascript files refer to the GTM and TensorFlow.js frameworks, which work together to perform image classification on the mobile device. Its functions are called within the teachable_machine_image_classifier.js code and internally between the files. In total, the TMIC extension is made up of six files, one of the Java extension, one of the HTML and four Javascript extension files. The main methods of the Java class (TeachableMachineImageClassifier.java) are those that will define the behavior of the blocks. Most of them need to communicate with the front-end, calling functions and passing parameters to the file teachable_machine_image_classifier.js, which will process the submitted request. The teachable_machine_image_classifier.js Javascript file functions are responsible for receive requests from the TeachableMachineImageClassifier.java class, process them and return the result in cases where it is necessary to notify that the extension is ready for the usage or prediction results are ready. The classifyVideoData() function is responsible for loading the Teachable Machine cloud hosted template from a user-defined URL in the property URL_Model. The classifyVideoData() function captures the URL of the two JSON files, one containing the model trained and the other with the model metadata, from the URL defined earlier in the preparation of the extension when it is initialized. After assigning the URL of the JSON files to two variables, they are passed as parameters to the function tmImage.load(modelURL, metadataURL), belonging to the Teachable Machine framework file teachablemachine-image.min.js, which will return the model prepared to be used in image classification. After the model is prepared, the model.getTotalClasses() function is called, which returns the number of model classes for the maxPredictions variable. Finally, the function is called model.predict(webcamPredict.canvas), which calls the classifier passing as a parameter the image captured at the exact moment the classifyVideoData() function was executed, returning the prediction result in the prediction variable. Finally, after the prediction variable is already with the classification result, an array with the results is filled in and returned to the Java class, calling the method reportResult(String result), which will prepare the result and notify the event block GotClassification. The TMIC extension is provided with the BSD 3 license (https://opensource.org/licenses/BSD-3-Clause), included in a LICENSE file. The license is available from the TMIC source code in the GitLab repository hosted at the Federal University of Santa Catarina. Also along with the code sources, a NOTICE file is available recognizing that the TMIC was developed by adjusting the PIC code. Currently the TMIC extension supports only Tensorflow.js models exported to Google Cloud and only allows capturing images with the rear-facing camera of the smartphone. We are planning to improve the extension as part of future work. Usage example The extension can be used for teaching ML in K-12, in introductory courses in higher education or by anyone who wants to create “intelligent” apps for image classification. As with any App Inventor extension it can be imported into App Inventor and then used in order to run trained models as part of intelligent apps. In order to support its usage the following material is available (currently in Brazilian Portuguese only): ● TMIC extension .aix ● Example app for the classification of recycling trash .aia (wireframe and final version) ● Online tutorial explaining the use of the extension The extension and material is available online: https://computacaonaescola.ufsc.br/en/tmic/ Acknowledgments This work is supported by CNPq (National Council for Scientific and Technological Development), a Brazilian government entity focused on scientific and technological development. References Armeshi, S. et al. Software Engineering for Machine Learning: A Case Study. In: Proc. of the 41st International Conference on Software Engineering: Software Engineering in Practice, IEEE Press, 2019, 291–300. Carney, M. et al. Teachable Machine: Approachable Web-Based Tool for Exploring Machine Learning Classification. In: Proc. of Conference on Human Factors in Computing Systems, ACM, 2020. C. Gresse von Wangenheim, C. Gresse von Wangenheim. Overview on a human-centric interactive ML process for teaching ML in K-12. Working Paper WP_GQS_01_2021_v10, GQS/INCoD/UFSC, 2021. Gresse von Wangenheim, C.; Hauck, J. C. R.; Pacheco, F. S.; Bertonceli Bueno, M. F. Visual Tools for Teaching Machine Learning in K-12: A Ten-Year Systematic Mapping. Education and Information Technologies, 2021. Marques, L. S., Gresse von Wangenheim, C., Hauck, J. C. R. Teaching Machine Learning in School: A Systematic Mapping of the State of the Art. Informatics in Education, 19(2), 2020. Patton E.W., Tissenbaum M., Harunani F. MIT App Inventor: Objectives, Design, and Development. In: Kong SC., Abelson H. (eds) Computational Thinking Education. Springer, Singapore, 2019. Tang, D., Utsumi, Y., Lao, N. (2019). PIC: A Personal Image Classification Webtool for High School Students. In: Proc.of the IJCAI EduAI Workshop, Macao, China, 2019. Tang, D. (2019). Empowering Novices to Understand and Use Machine Learning With Personalized Image Classification Models, Intuitive Analysis Tools, and MIT App Inventor, M.Eng thesis, MIT, Cambridge, USA. Touretzky, D., Gardner-McCune, C., Martin, F., Seehorn, D. Envisioning AI for k-12: What should every child know about AI? In Proc. of AAAI Conference on Artificial Intelligence, Honolulu, HI, USA, 2019, 9795–9799.","['tmic', 'app', 'inventor', 'extension', 'deployment', 'image', 'classification', 'model', 'export', 'teachable', 'machine', 'fabiano', 'informatic', 'statistic', 'federal', 'fabianopereiraoliveiragradufscbr', 'christiane', 'informatic', 'statistic', 'federal', 'hauck', 'department', 'informatic', 'statistic', 'federal', 'summary', 'tmic', 'app', 'inventor', 'extension', 'deployment', 'model', 'image', 'classification', 'develop', 'teachable', 'machine', 'educational', 'setting', 'teachable', 'machine', 'intuitive', 'visual', 'tool', 'provide', 'workfloworiented', 'support', 'development', 'model', 'image', 'classification', 'aim', 'usage', 'model', 'develop', 'teachable', 'machine', 'extension', 'tmic', 'enable', 'deployment', 'train', 'model', 'export', 'part', 'app', 'inventor', 'popular', 'blockbase', 'programming', 'environment', 'teach', 'computing', 'k12', 'extension', 'create', 'app', 'inventor', 'extension', 'framework', 'base', 'extension', 'pic', 'available', 'bsd', 'license', 'use', 'teach', 'ml', 'k12', 'introductory', 'course', 'high', 'education', 'interested', 'create', 'intelligent', 'app', 'image', 'classification', 'extension', 'tmic', 'develop', 'initiative', 'computação', 'na', 'escola', 'department', 'informatic', 'statistic', 'federal', 'part', 'research', 'effort', 'aim', 'introduce', 'education', 'k12', 'keyword', 'machine', 'learn', 'image', 'classification', 'teachable', 'machine', 'app', 'inventor', 'extension', 'statement', 'need', 'daily', 'life', 'eg', 'spam', 'filter', 'recommendation', 'nowadays', 'machine', 'learning', 'present', 'mechanism', 'chatbot', 'digital', 'assistant', 'consider', 'inevitable', 'impact', 'people', 'understand', 'machine', 'learn', 'consumer', 'also', 'creator', 'type', 'innovation', 'therefore', 'important', 'start', 'teach', 'concept', 'k12', 'follow', 'trend', 'emerge', 'last', 'year', 'marques', 'accord', 'k12', 'guideline', 'artificial', 'intelligence', 'touretsky', 'ai', 'education', 'encompass', 'big', 'idea', 'include', 'machine', 'learn', 'include', 'understanding', 'basic', 'concept', 'well', 'application', 'concept', 'develop', 'ml', 'application', 'typically', 'focus', 'task', 'image', 'classification', 'image', 'classification', 'process', 'take', 'input', 'photo', 'videostream', 'output', 'class', 'plastic', 'garbage', 'probability', 'input', 'particular', 'class', '’', 'probability', 'image', 'show', 'plastic', 'garbage', 'teach', 'application', 'ml', 'follow', 'humancentric', 'essential', 'interactive', 'ml', 'process', 'include', 'development', 'requirement', 'analysis', 'export', 'developed', 'model', 'deployment', 'figure', 'figure', 'humancentric', 'interactive', 'ml', 'process', 'development', 'model', 'typically', 'teach', 'k12', 'adopt', 'visual', 'tool', 'teachable', 'machine', 'teachable', 'machine', 'teachablemachinewithgooglecom', 'free', 'webbase', 'gui', 'tool', 'create', 'custom', 'machine', 'learn', 'classification', 'model', 'specialized', 'technical', 'expertise', 'carney', 'teachable', 'machine', 'use', 'train', 'run', 'user', 'model', 'online', 'run', 'browser', 'entirely', 'user', 'device', 'maintain', 'input', 'datum', 'locally', 'protect', 'datum', 'privacy', 'teachable', 'machine', 'provide', 'intuitive', 'workfloworiented', 'interface', 'support', 'upload', 'dataset', 'model', 'training', 'evaluation', 'well', 'prediction', 'class', 'new', 'datum', 'export', 'train', 'model', 'figure', 'figure', 'example', 'development', 'teachable', 'machine', 'furthermore', 'possible', 'download', 'train', 'model', 'tensorflowjs', 'model', 'host', 'deploy', 'easily', 'website', 'app', 'case', 'teachable', 'machine', 'generate', 'url', 'model', 'host', 'free', 'link', 'share', 'use', 'create', 'model', 'also', 'convert', 'tensorflow', 'tensorflow', 'lite', 'model', 'download', 'local', 'use', 'figure', 'figure', 'example', 'export', 'train', 'model', 'important', 'metadata', 'json', 'file', 'indicate', 'version', 'use', 'library', 'metadata', 'user', 'model', 'model', 'json', 'file', 'specify', 'model', 'topology', 'weight', 'bin', 'file', 'specify', 'weight', 'train', 'model', 'export', 'tensorflowjs', 'zip', 'file', 'include', 'name', 'well', 'list', 'label', 'name', 'size', 'image', 'use', 'train', 'model', 'export', 'train', 'ml', 'model', 'deploy', 'software', 'system', 'mobile', 'application', 'deployment', 'train', 'model', 'illustrate', 'usefulness', 'ml', 'teach', 'development', 'model', 'also', 'creating', 'intelligent', 'solution', 'deployment', 'part', 'iaml', 'education', 'k12', 'typically', 'blockbase', 'programming', 'environment', 'mit', 'app', 'inventor', 'free', 'web', 'platform', 'allow', 'user', 'create', 'mobile', 'application', 'user', 'design', 'application', 'use', 'drag', 'drop', 'component', 'program', 'behavior', 'use', 'blocksbase', 'programming', 'language', 'app', 'inventor', 'core', 'already', 'provide', 'comprehensive', 'set', 'component', 'method', 'command', 'diverse', 'kind', 'functionality', 'include', 'sensor', 'communication', 'datum', 'storage', 'also', 'possible', 'far', 'extend', 'app', 'inventor', 'provide', 'component', 'patton', 'extension', 'also', 'use', 'incorporate', 'ml', 'feature', 'app', 'inventor', 'use', 'inventor', 'extension', 'framework', 'example', 'app', 'inventor', 'extension', 'integrate', 'customtraine', 'image', 'classification', 'model', 'personal', 'image', 'classifier', 'pic', 'extension', 'support', 'provide', 'pic', 'consist', 'web', 'application', 'support', 'model', 'development', 'extension', 'new', 'component', 'run', 'train', 'model', 'app', 'inventor', 'app', 'however', 'certain', 'shortcoming', 'regard', 'specific', 'web', 'application', 'development', 'model', 'lack', 'evaluation', 'support', 'performance', 'problem', 'train', 'model', 'lack', 'flexibility', 'allow', 'deployment', 'model', 'develop', 'environment', 'teachable', 'machine', 'indicate', 'need', 'extension', 'tmic', 'teachable', 'machine', 'image', 'classifier', 'extension', 'tmic', 'app', 'inventor', 'extension', 'deployment', 'image', 'classification', 'model', 'develop', 'teachable', 'machine', 'extension', 'base', 'pic', 'extension', 'adapt', 'pic', 'extension', 'order', 'enable', 'import', 'tensorflowjs', 'model', 'create', 'teachable', 'machine', 'export', 'upload', 'tmic', 'extension', 'include', 'follow', 'property', 'urlmodel', 'property', 'responsible', 'contain', 'url', 'model', 'train', 'teachable', 'machine', 'export', 'tensorflowjs', 'webviewer', 'property', 'allow', 'user', 'assign', 'web', 'browser', 'component', 'extension', 'use', 'web', 'browser', 'component', 'use', 'order', 'visualize', 'functionality', 'extension', 'tmic', 'extension', 'provide', 'follow', 'block', 'block', 'tmic', 'extension', 'functionality', 'classifierready', 'event', 'block', 'execute', 'extension', 'finish', 'load', 'model', 'cloud', 'gotclassification', 'event', 'block', 'execute', 'extension', 'finish', 'classify', 'image', 'event', 'occur', 'classifyvideodata', 'prediction', 'category', 'model', 'execution', 'return', 'list', 'block', 'right', 'classifyvideodata', 'block', 'start', 'classification', 'image', 'capture', 'smartphone', 'rearface', 'camera', 'video', 'stream', 'use', 'webviewer', 'component', 'classification', 'finish', 'result', 'return', 'gotclassification', 'event', 'block', 'stopwebcam', 'block', 'stop', 'webcam', 'leave', 'screen', 'image', 'classification', 'adjustment', 'block', 'allow', 'user', 'adjust', 'link', 'export', 'model', 'teachablemachineimageclassifier', 'return', 'specific', 'instance', 'extension', 'block', 'first', 'divide', 'backend', 'frontend', 'tmic', 'extension', 'develop', 'use', 'base', 'pic', 'extension', 'code', 'inside', 'inventor', 'framework', 'refer', 'create', 'extension', 'teachablemachineimageclassifierjava', 'file', 'initialize', 'extension', 'block', 'extension', 'block', 'define', 'teachablemachineimageclassifierjava', 'class', 'method', 'responsible', 'execute', 'action', 'block', 'front', 'end', 'tmic', 'extension', 'make', 'file', 'javascript', 'file', 'extension', 'need', 'render', 'page', 'open', 'camera', 'ask', 'user', 'permission', 'display', 'user', 'javascript', 'file', 'need', 'load', 'model', 'perform', 'classification', 'image', 'user', 'request', 'teachablemachineimageclassifierjs', 'file', 'mainly', 'responsible', 'perform', 'task', 'communicate', 'backend', 'receiving', 'request', 'load', 'model', 'open', 'cell', 'phone', 'camera', 'classify', 'image', 'file', 'also', 'notify', 'backend', 'extension', 'ready', 'return', 'rank', 'result', 'javascript', 'file', 'refer', 'framework', 'work', 'together', 'perform', 'image', 'classification', 'mobile', 'device', 'function', 'call', 'teachablemachineimageclassifierjs', 'code', 'internally', 'file', 'total', 'tmic', 'extension', 'make', 'file', 'javascript', 'extension', 'file', 'main', 'method', 'class', 'teachablemachineimageclassifierjava', 'define', 'behavior', 'block', 'need', 'communicate', 'frontend', 'call', 'function', 'pass', 'parameter', 'file', 'teachablemachineimageclassifierjs', 'process', 'submit', 'request', 'teachablemachineimageclassifierjs', 'javascript', 'file', 'function', 'responsible', 'receive', 'request', 'teachablemachineimageclassifierjava', 'class', 'process', 'return', 'result', 'case', 'necessary', 'notify', 'extension', 'ready', 'usage', 'prediction', 'result', 'ready', 'classifyvideodata', 'function', 'responsible', 'load', 'teachable', 'machine', 'cloud', 'host', 'template', 'userdefined', 'url', 'property', 'urlmodel', 'classifyvideodata', 'function', 'capture', 'url', 'json', 'file', 'contain', 'model', 'train', 'model', 'metadata', 'url', 'define', 'early', 'preparation', 'extension', 'initialize', 'assign', 'url', 'json', 'file', 'variable', 'pass', 'parameter', 'function', 'tmimageloadmodelurl', 'metadataurl', 'belong', 'teachable', 'machine', 'framework', 'file', 'teachablemachineimageminj', 'return', 'model', 'prepare', 'use', 'image', 'classification', 'model', 'prepare', 'modelgettotalclasse', 'function', 'call', 'return', 'number', 'model', 'class', 'maxprediction', 'variable', 'finally', 'function', 'call', 'modelpredictwebcampredictcanvas', 'call', 'classifier', 'pass', 'parameter', 'image', 'capture', 'exact', 'moment', 'classifyvideodata', 'function', 'execute', 'return', 'prediction', 'result', 'prediction', 'variable', 'finally', 'prediction', 'variable', 'already', 'classification', 'result', 'array', 'result', 'fill', 'return', 'class', 'call', 'method', 'reportresultstre', 'result', 'prepare', 'result', 'notify', 'event', 'block', 'gotclassification', 'tmic', 'extension', 'provide', 'bsd', 'license', 'include', 'license', 'file', 'license', 'available', 'tmic', 'source', 'code', 'repository', 'host', 'federal', 'also', 'along', 'code', 'source', 'notice', 'file', 'available', 'recognize', 'tmic', 'develop', 'adjust', 'pic', 'code', 'currently', 'tmic', 'extension', 'support', 'tensorflowjs', 'model', 'export', 'allow', 'capture', 'image', 'rearface', 'camera', 'smartphone', 'plan', 'improve', 'extension', 'part', 'future', 'work', 'usage', 'example', 'extension', 'use', 'teach', 'ml', 'k12', 'introductory', 'course', 'high', 'education', 'want', 'create', 'intelligent', 'app', 'image', 'classification', 'app', 'inventor', 'extension', 'import', 'app', 'inventor', 'use', 'order', 'run', 'train', 'model', 'part', 'intelligent', 'app', 'order', 'support', 'usage', 'follow', 'material', 'available', 'currently', 'brazilian', 'portuguese', 'tmic', 'extension', 'aix', 'example', 'app', 'classification', 'recycle', 'trash', 'aia', 'wireframe', 'final', 'version', 'online', 'tutorial', 'explain', 'use', 'extension', 'extension', 'material', 'available', 'online', 'acknowledgment', 'work', 'support', 'scientific', 'technological', 'development', 'brazilian', 'government', 'entity', 'focus', 'scientific', 'technological', 'development', 'reference', 'software', 'engineering', 'machine', 'learn', 'case', 'study', 'proc', '41st', 'international', 'conference', 'software', 'engineering', 'software', 'engineering', 'practice', 'ieee', 'press', 'carney', 'teachable', 'machine', 'approachable', 'webbase', 'tool', 'explore', 'machine', 'learn', 'classification', 'proc', 'conference', 'human', 'factor', 'compute', 'system', 'acm', 'c', 'overview', 'humancentric', 'interactive', 'ml', 'process', 'teach', 'ml', 'k12', 'work', 'paper', 'wpgqs012021v10', 'gqsincodufsc', 'hauck', 'r', 'visual', 'tool', 'teach', 'machine', 'learning', 'k12', 'tenyear', 'systematic', 'mapping', 'education', 'information', 'technology', 'marques', 'hauck', 'r', 'teach', 'machine', 'learning', 'school', 'systematic', 'mapping', 'state', 'art', 'informatic', 'education', 'patton', 'ew', 'mit', 'app', 'inventor', 'objective', 'design', 'development', 'ed', 'computational', 'thinking', 'education', 'springer', 'pic', 'personal', 'image', 'classification', 'webtool', 'high', 'school', 'student', 'procof', 'empower', 'novice', 'understand', 'use', 'machine', 'learning', 'personalized', 'image', 'classification', 'model', 'intuitive', 'analysis', 'tool', 'mit', 'app', 'inventor', 'thesis', 'mit', 'envision', 'ai', 'k12', 'child', 'know', 'conference', 'artificial', 'intelligence']"
"ExpoCloud: a Framework for Time and Budget-Effective Parameter Space
  Explorations Using a Cloud Compute Engine","[{'href': 'http://arxiv.org/abs/2208.12195v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2208.12195v2', 'rel': 'related', 'type': 'application/pdf'}]",2022-08-25 16:32:44,"2
2
0
2

g
u
A
5
2

]

R
C
.
s
c
[

1
v
0
7
3
2
1
.
8
0
2
2
:
v
i
X
r
a

COOKIEGRAPH: Measuring and Countering First-Party Tracking Cookies

Shaoor Munir
UC Davis
smunir@ucdavis.edu

Steven Englehardt
Independent Researcher
se@senglehardt.com

Sandra Siby
EPFL
sandra.siby@epﬂ.ch

Umar Iqbal
University of Washington
umar@cs.washington.edu

Zubair Shaﬁq
UC Davis
zubair@ucdavis.edu

Carmela Troncoso
EPFL
carmela.troncoso@epﬂ.ch

Abstract—Recent privacy protections by browser vendors aim
to limit the abuse of third-party cookies for cross-site tracking.
While these countermeasures against third-party cookies are
widely welcome, there are concerns that they will result in
advertisers and trackers abusing ﬁrst-party cookies instead.
We provide the ﬁrst empirical evidence of how ﬁrst-party
cookies are abused by advertisers and trackers by conducting
a differential measurement study on 10K websites with third-
party cookies allowed and blocked. We ﬁnd that advertisers
and trackers implement cross-site tracking despite third-party
cookie blocking by storing identiﬁers, based on probabilistic
and deterministic attributes, in ﬁrst-party cookies. As opposed
to third-party cookies, outright ﬁrst-party cookie blocking is
not practical because it would result in major breakage of
legitimate website functionality.

We propose COOKIEGRAPH, a machine learning approach
that can accurately and robustly detect ﬁrst-party tracking
cookies. COOKIEGRAPH detects ﬁrst-party tracking cook-
ies with 91.06% accuracy, outperforming the state-of-the-art
CookieBlock approach by 10.28%. We show that COOKIE-
GRAPH is fully robust against cookie name manipulation while
CookieBlock’s accuracy drops by 15.68%. We also show that
COOKIEGRAPH does not cause any major breakage while
CookieBlock causes major breakage on 8% of the websites
with SSO logins. Our deployment of COOKIEGRAPH shows
that ﬁrst-party tracking cookies are used on 93.43% of the
10K websites. We also ﬁnd that the most prevalent ﬁrst-party
tracking cookies are set by major advertising entities such as
Google as well as many specialized entities such as Criteo.

1. Introduction

Browser vendors and trackers are engaged in an arms
race. As soon as browser vendors deploy privacy protec-
tions, e.g., third-party cookie blocking [85], [30], trackers
quickly adapt to evade them, e.g., CNAME cloaking [50],
bounce tracking [94] etc. In response, browser vendors have
developed targeted countermeasures against such evasions
[92], [81].

To gain advantage over browser vendors, trackers have
started exploiting browser features that are typically used for
functional purposes, and thus cannot be trivially blocked.
i.e.,
The abuse of JavaScript APIs to build identiﬁers,
browser ﬁngerprinting [39], and the abuse of ﬁrst-party
context to store tracking cookies [75] stand out as two
prominent techniques. Browser vendors have largely strug-
gled against these tracking techniques because preventing
them requires compromising functionality [58], [85].

While these new tracking techniques are difﬁcult
to
counter, they do not offer the same ﬂexibility as third-party
cookies for cross-site tracking. Browser ﬁngerprints enable
cross-site tracking but are not stable over time [83]. On the
other hand, ﬁrst-party cookies are stable but not linkable
across different sites. When combined, however, browser
ﬁngerprints and ﬁrst-party cookies complement each oth-
ers’ shortcomings and enable reliable cross-site tracking.
Speciﬁcally, trackers are able to leverage non-deterministic
ﬁngerprints in the ﬁrst-party context to set deterministic
ﬁrst-party tracking cookies [57].

Prior literature has shown how ﬁrst-party cookies set by
third party scripts are exﬁltrated to tracking endpoints [75],
[44], [56] and how trackers use browser ﬁngerprinting to
respawn ﬁrst-party cookies [57]. While prior work has
demonstrated that ﬁrst-party cookies are indeed abused by
advertisers and trackers, no countermeasure has been pro-
posed to speciﬁcally block ﬁrst-party tracking cookies.

In this paper, we investigate how ﬁrst-party cookies are
abused for cross-site tracking and use our ﬁndings to develop
a machine learning based countermeasure, COOKIEGRAPH,
to block ﬁrst-party tracking cookies.

To this end, we ﬁrst perform a differential measure-
ment study where we compare the ﬁrst- and third-party
cookie usage from two crawls of 10K websites when third-
party cookies are enabled and blocked. We show that third-
party-cookie blocking does not signiﬁcantly impact sharing
of identiﬁers to tracking endpoints because trackers use
(or reactively shift to) ﬁrst-party cookies when third-party
cookies are blocked. Speciﬁcally, we ﬁnd entities such as
Criteo, Lotame, and ID5 that show an increased presence
and reactively move to ﬁrst-party cookies when third-party

 
 
 
 
 
 
cookies are blocked. Our further analysis reveals that they
store identiﬁers in ﬁrst-party cookies, based on probabilistic
and deterministic attributes, which can be then used for
cross-site tracking.

Unlike third-party cookies, blocking all ﬁrst-party cook-
ies is not practical because it would lead to major breakage
of legitimate website functionality. Privacy-enhancing con-
tent blocking tools, which use crowdsourced ﬁlter lists or
machine learning [65], [78], [77], could be an alternative
since blocking requests would also block all cookies set
by the requests (or the requested scripts). However, as we
also ﬁnd in our evaluation, blocking requests would also
lead to breakage since it is likely that many of the blocked
cookies are needed for legitimate website functionality. Re-
searchers have recently started to develop approaches to
detect and block tracking cookies (both ﬁrst and third-party)
[63], [41]. However, these approaches rely on content-based
features such as cookie names and values, which can lead
to high number of false positives (and consequently higher
major website breakage) while also being susceptible to
evasion [77].

Keeping these limitations in mind, we design and im-
plement COOKIEGRAPH, a machine learning approach to
detect ﬁrst-party tracking cookies. Instead of using content-
based features, COOKIEGRAPH captures fundamental track-
ing behaviors exhibited by ﬁrst-party cookies that we
discover in our differential measurement study. COOKIE-
GRAPH is able to detect ﬁrst-party tracking cookies with
91.06% accuracy, outperforming the state-of-the-art Cook-
ieBlock [41] approach by 10.28%. We also show that
COOKIEGRAPH does not cause any major website breakage,
where CookieBlock causes major breakage on 8% of the
websites with SSO logins. Moreover, COOKIEGRAPH is
robust to evasion through cookie name manipulation while
CookieBlock’s accuracy degrades by 15.68%.

Our deployment of COOKIEGRAPH on 10K websites
shows that ﬁrst-party tracking cookies are used on 93.43%
of the websites. While ﬁrst-party tracking cookies are set
by third-party scripts served from a total of 1,588 unique
domains, we show that the most prevalent ﬁrst-party tracking
cookies are set by major advertising entities such as Google,
as well as many specialized entities such as Criteo. We also
show that 41.45% of all ﬁrst-party tracking cookies are set
by scripts served by domains involved in ﬁngerprinting.
In summary, our key contributions are as follows:

1) We conduct a large-scale differential measure-
ment study to understand the effectiveness of third-
party cookie blocking and whether ﬁrst-party cook-
ies are used in lieu of third-party cookies.

2) We design and implement COOKIEGRAPH, a ma-
chine learning based countermeasure to detect
and block ﬁrst-party tracking cookies. COOKIE-
GRAPH captures fundamental tracking behaviors of
ﬁrst-party cookies that we discovered in our mea-
surement study, and outperforms the state-of-the-
art in terms of accuracy, robustness, and breakage
minimization.

3) We deploy COOKIEGRAPH on 10K websites
sampled from the Alexa’s top-100K list to measure
the prevalence of ﬁrst-party tracking cookies. We
detect a total of 1,588 distinct domains that set ﬁrst-
party tracking cookies, including major advertising
entities such as Google, and show that 45 (2.83%)
of these domains are known ﬁngerprinters which
set 41.45% of all ﬁrst-party tracking cookies.

Paper Organization: The rest of this paper is organized
as follows: Section 2 provides an overview of the recent
developments in third-party and ﬁrst-party cookie based
tracking and countermeasures. Section 3 evaluates effec-
tiveness of third-party cookie blocking in reducing tracking
activity and measures the extent of ﬁrst-party cookie abuse
by advertisers and trackers. Section 4 describes the design
and evaluation of COOKIEGRAPH. We discuss limitations
of COOKIEGRAPH in Section 5 and conclude in Section 6.

2. Background & Related Work

2.1. Adoption of third-party cookies for tracking

While cookies were originally designed to recognize
returning users, e.g., to maintain virtual shopping carts [70],
they were quickly adopted by third-parties to track users
across websites, e.g., to serve targeted ads [27]. Early stan-
dardization efforts mostly focused on limiting unintended
cookie sharing across domains [47] and, despite well-known
privacy concerns [21], largely ignored the intentional misuse
of cookies by third-parties for cross-site tracking. Over the
years, the use of third-party cookies for cross-site tracking
has become increasingly prevalent [74], [43], [75], [48].
Prior research has found that the vast majority of third-
party cookies are set by advertising and tracking services
[48] and that the third-party cookies outnumber ﬁrst-party
cookies by a factor of two [43] and up to four when they
contain identiﬁers [75].

2.2. Countermeasures against third-party cookies

2.2.1. Safari. Since its inception in 2003, Safari has blocked
third-party cookies from domains that have not been visited
by the user as full-ﬂedged websites [85]. To strengthen
its cookie blocking, Safari introduced Intelligent Tracking
Prevention (ITP) in 2017. ITP used machine learning to
automatically detect third-party trackers and revoked storage
access from classiﬁed domains if users did not interact with
them on a daily basis (i.e., a 24 hour period) [86]. Since
2017, ITP went through several iterations, i.e., ITP 1.1 [87],
ITP 2.0 [88], ITP 2.1 [89], ITP 2.2 [90] and ITP 2.3 [91],
eventually leading to full third-party cookie blocking [93].

2.2.2. Firefox. Firefox experimented with third-party
cookie blocking in 2013 [52], [53], but did not ship default-
on third-party cookie blocking until the release of Enhanced
Tracking Protection (ETP) in 2018 [71]. ETP blocks third-
party cookies based on a blocklist of trackers provided by

2

Disconnect [26]. As of 2022, Firefox has launched Total
Cookie Protection (TPC) which partitions all third-party
cookie access [6]. Partitioning ensures that cookies set by
a third-party on one site are distinct from those set by the
same third-party on other websites, eliminating the third-
party’s ability to track users across those websites.

2.2.3. Internet Explorer and Microsoft Edge. Amongst
the mainstream browsers that have deployed countermea-
third-party cookies, Internet Explorer (IE)
sures against
and Microsoft Edge have the most permissive protections.
IE blocked third-party cookies from domains that did not
specify their cookie usage policy with P3P response header
[22]. However, website owners often misrepresented their
cookie usage polices, which rendered P3P ineffective [69].
Since 2019, Microsoft Edge blocks access to cookies and
storage in a third-party context from some trackers, based
on Disconnect’s tracking protection list [82], [35], [26].

2.2.4. Chrome. Google Chrome is the only mainstream
browser that does not restrict third-party cookies in any
way in its default mode. In 2020, Google announced plans
to phase out third-party cookies in Chrome by 2022 [76].
However, the plan has been postponed several times and the
latest timeline suggests the phasing out of cookies by late
2024 [59]. Google has also announced plans to implement
privacy-preserving versions of advertising use cases that cur-
rently depend on third-party cookies—including behavioral
ad targeting and ad attribution/measurement [59].

2.3. Adoption of ﬁrst-party cookies for tracking

While third-party cookies are widely considered as the
main mechanism for cross-site tracking, trackers have also
relied on ﬁrst-party cookies for tracking. As early as 2012,
Roesner et al. [74], noted that third-party tracking scripts,
embedded on the main webpage (i.e., in ﬁrst-party context),
set ﬁrst-party cookies. More recently, in 2020 Fouad et al.
[56] found that trackers sync ﬁrst-party cookies to several
third-parties on as many as 67.96% of the websites. In
2021, Chen et al. [44] found that more than 90% of the
websites contain at least one ﬁrst-party cookie that is set
by a third-party script. Similar to Fouad et al., they also
found that at least one ﬁrst-party cookie is exﬁltrated to a
third-party domain on more than half of the tested web-
sites, raising concerns that these cookies might be used for
tracking. These concerns were also echoed by Sanchez et
al. [75], who uncovered several instances where different
third-parties interacted with the same ﬁrst-party cookies.
They conclude, through a large scale measurement study
of top websites and a number of case studies, that even
after blocking third-party cookies, users are still at risk of
tracking through ﬁrst-party cookies.

While prior studies have identiﬁed the use of ﬁrst-party
cookies by trackers, they were not solely focused on study-
ing ﬁrst-party tracking cookies. In fact, their measurement
infrastructure was not designed to capture tracking through
they did not conﬁgure
ﬁrst-party cookies. For example,

their browsers to block third-party cookies, which might not
instigate trackers to use ﬁrst-party cookies for tracking.
Techniques used to set ﬁrst-party cookies. It is non-
trivial to generate ﬁrst-party identiﬁers that are accessible
across websites. Prior research has found that trackers often
leverage browser ﬁngerprinting to generate ﬁrst-party track-
ing cookies [57]. Browser ﬁngerprinting provides unique
identiﬁers that are accessible across websites but drift over
time [67]. However, identiﬁers generated through browser
ﬁngerprinting can be stored in cookies that persist even after
ﬁngerprints change. In addition to browser ﬁngerprinting,
several advertising and tracking services, such as Google
Ad Manager [79], [1] and ID5 [10], specify in their docu-
mentation that they also use publisher provided identiﬁers
(PPIDs), such as email addresses, to set ﬁrst-party cookies.
CNAME cloaking also allows advertisers or trackers to
use ﬁrst-party cookies. In this paper, we do not focus on
CNAME cloaking because ﬁrst-party cookie leaks due to
CNAME cloaking is already extensively studied by prior
work [49], [50].

2.4. Countermeasures against ﬁrst-party cookies

2.4.1. Deployed countermeasures. Safari is the only main-
stream browser that has deployed protections against ﬁrst-
party tracking cookies. Safari’s ITP expires ﬁrst-party cook-
ies and storage set by scripts in 7 days if users do not interact
with the website [85]. For ﬁrst-party cookies, this limit is
lowered to 24 hours if ITP detects link decoration being
used for tracking [85]. However, ﬁrst-party cookie tracking
does not require link decoration to be effective. In cases
where link decoration isn’t used, trackers can still track users
within the 7-day window and beyond if users interact with
the website within the 7-day window.

2.4.2. Countermeasures proposed by prior research.
Recently, researchers have proposed machine learning based
approaches to detect ﬁrst-party and third-party tracking
cookies. Hu et al. [63] developed a machine learning based
approach that uses sub-strings in cookie names (e.g., track,
GDPR) as features to detect ﬁrst-party and third-party track-
ing cookies. Bollinger et al. [41] also developed a machine
learning approach, CookieBlock, that uses several cookie
attributes such as the domain name of the setter, cookie
name, path, value, expiration, etc, as features to detect
ﬁrst-party and third-party tracking cookies. However, rely-
ing on hard-coded content features make these approaches
susceptible to adversarial evasions (as we show later in
Section 4.4.3). Moreover, these approaches mainly rely on
self-disclosed cookie labels as ground truth which are known
to be unreliable [84].

2.4.3. Request blocking approaches. Request blocking
through browser extensions, such as Adblock Plus [23],
and machine learning based tracker detection approaches
proposed by prior research, e.g., [77], can potentially block
ﬁrst-party tracking cookies. However, request blocking is
inherently prone to cause breakage (as we later show in

3

Section 4.4.3) because it blocks access to content or cookies
that might be essential for website functionality.
Focus of this paper. In conclusion, prior work has only
incidentally measured the usage of ﬁrst-party tracking cook-
ies and existing approaches to detect ﬁrst-party cookies are
lacking. In this paper, we ﬁll this void by conducting a large-
scale study to measure the prevalence of ﬁrst-party tracking
cookies and develop an accurate and robust machine learn-
ing approach, called COOKIEGRAPH, that is purpose-built
to detect ﬁrst-party cookies.

3. Measurements

In this section, we present a measurement study to
understand the usage of ﬁrst-party cookies by advertising
and tracking services (ATS) when third-party cookies are
blocked. To this end, we conduct two web crawls (with and
without third-party cookies) and analyze the differences in
the tracking activity (i.e., sharing of identiﬁers to known
adverting and tracking services) observed across these two
crawls to understand the effectiveness of third-party cookie
blocking and whether ﬁrst-party cookies are used in lieu of
third-party cookies.

3.1. Data Collection and Methodology

Data collection. We use OpenWPM [54] to crawl sites from
Alexa’s top-100K list. To ensure that our crawls contain
representative sites of different popularity, we crawl the top
1K sites, and randomly sample another 9K sites from the
long tail of sites ranked 1K-100K. To ensure intra-page
diversity (landing and internal pages [38]) we perform an
interactive crawl. Speciﬁcally, for each site, we crawl its
landing page, and then sample 5-10 anchor tags in this
landing page uniformly at random, and crawl them to get a
sample of internal pages. We conduct two crawls: one with
third-party cookies enabled (3P-Allowed), and one with
third-party cookies blocked (3P-Blocked). We conduct
these crawls simultaneously to minimize temporal variations
in sites across the two crawls1.
Deﬁnition of ﬁrst- and third-party cookies. Cookies are
set in the browser in two ways. They can either be set by
the Set-Cookie HTTP response header or by using docu-
ment.cookie() in JavaScript. Cookies are further classiﬁed as
ﬁrst- or third-party. Cookies set via response header from the
same (or different) domain as the ﬁrst-party are ﬁrst-party
(or third-party) cookies. Classiﬁcation of cookies set by a
script depends on whether the script is embedded in a ﬁrst-
or third-party execution context. The cookies set by third-
party scripts running in a ﬁrst-party context are ﬁrst-party
cookies. The cookies set by third-party scripts running in a
third-party context (e.g., third-party iframes) are third-party
cookies.
Labeling tracking activity. We use EasyList [28] and
EasyPrivacy [29] to label requests as tracking (ATS) or not

Figure 1. Average number of requests per site in 3P-Allowed and
3P-Blocked conﬁgurations:
) Non-ATS requests
(
) ATS requests without identiﬁers
(
) ATS requests with identiﬁers
(

tracking (Non-ATS).2 Since the basic premise of tracking is
to identify users, we are particularly interested in sharing
of identiﬁers in these tracking requests. To this end, in
line with prior work [66], [55], we deﬁne identiﬁers as a
string that is longer than 8 characters and matches the regex
[a − zA − Z0 − 9 = −]. Using this deﬁnition, we look for
identiﬁers in URL query parameters [73] and cookie values
[75], [51], [44], [43].

3.2. Tracking after Blocking Third-Party Cookies

We ﬁrst study whether blocking third-party cookies ef-
fectively eliminates ATS requests. To this end, we compare
the number of requests with and without third-party cookies.
Figure 1 plots the number of requests with and without
third-party cookies. It can be seen from the Figure 1 that
when third-party cookies are blocked, there is only a modest
reduction in the overall number of ATS requests, with just an
18.4% reduction in the number of ATS requests containing
identiﬁers. This is surprising because cookie syncing, which
is widely used for cross-site tracking [56], [72], entails
sharing third-party identiﬁer cookies in query parameters
[51], [44], [43]. With third-party cookies blocked, cookie
syncing between third-parties cannot occur and we would
expect to see a larger drop in identiﬁers shared in ATS
requests. We address this surprising observation in Section
3.3.

Next, we analyze whether third-party cookie blocking
disparately impacts different ATS domains (eTLD+1). Fig-
ure 2 plots the percentage of sites with at least one ATS
request with identiﬁers for the top-10 most prevalent ATS
domains across both crawls. We note that six of the top-10
ATS domains, all owned by Google, show only a negligible

1. The success rate of our crawl is 83.98%. Form the 10K sites visited,

8,398 were successfully crawled.

2. We label a request as tracking (ATS) if its URL matches the rules in
either one of the lists. Otherwise, we label it as not tracking (Non-ATS).

4

s
t
s
e
u
q
e
R

f
o

r
e
b
m
u
N
e
g
a
r
e
v
A

300

250

200

150

100

50

0

18.4% Decrease

8.18% Decrease

1.59% Decrease

3P Cookies Enabled

3P Cookies Blocked

Figure 2. Presence of top-10 tracking domains. The plot shows percentage
of sites where at least one request is sent to a tracking domain. We include
criteo.net due to its peculiar increased presence after blocking third-
party cookies.
(
(

) third-party cookies allowed
) third-party cookies blocked

Figure 4. Comparison of percentage of sites on which ﬁrst party and third-
party identiﬁer cookies are set by ATS domains.
(
(
(

) ﬁrst-party cookies set when third-party cookies are allowed
) ﬁrst-party cookies set when third-party cookies are blocked
) third-party cookies set when third-party cookies are allowed

3.3. Tracking through First-Party Cookies

Figure 1 showed that 82.6% of ATS requests contain
identiﬁers even after third-party cookies are blocked. It is
clear that the identiﬁers in these ATS requests are then likely
originating from some storage mechanism other than third-
party cookies. Since recent prior work has shown that ATSes
are increasingly using ﬁrst-party cookies [75], [44], we next
investigate whether ﬁrst-party cookies are being used in lieu
of third-party cookies.

We ﬁrst compare the average number of ﬁrst-party cook-
ies in 3P-Allowed and 3P-Blocked crawls in Figure 3.
We observe only a minor difference in the average number
of ﬁrst-party cookies set by ATS scripts (or Non-ATS for
that matter).3 However, it is noteworthy that 81% of the
ﬁrst-party cookies are set by ATS scripts and further 82%
of them are identiﬁer cookies. This demonstrates that an
overwhelming number of ﬁrst-party cookies are in fact set
by ATSes.

Next, we compare the setting of ﬁrst- and third-party
identiﬁer cookies by ATS domains (eTLD+1 of the setting
script URL) to understand if ﬁrst-party cookie usage is
equally prevalent across different ATSes. Figure 4 plots
the percentage of sites where at least one ﬁrst-party and/or
third-party identiﬁer cookie is set by top-10 ATS domains
(with Criteo divided into criteo.com and criteo.net). First, we
observe that for the six Google-owned ATS domains, which
showed negligible difference in requests containing identi-
ﬁers after blocking third-party cookies, there is also little
to no change in use of ﬁrst-party identiﬁer cookies across

3. We label scripts as ATS or Non-ATS based on their src URL as in

Section 3.1.

Figure 3. Breakdown of average number of ﬁrst-party cookies per site set
before and after blocking third-party cookies.
(
(
(

) Cookies set by non-tracking sources
) Non-identiﬁer cookies set by tracking sources
) Identiﬁer cookies set by tracking sources.

reduction in the number ATS requests with identiﬁers when
third-party cookies are blocked. In contrast, three other ATS
domains, owned by Pubmatic, Rubicon, and OpenX, show
an almost 50% reduction. Criteo exhibits interesting behav-
ior, where the requests sent to Criteo are divided between
two domains: criteo.com and criteo.net. While criteo.com
shows negligible change across two crawls, criteo.net in-
creases by about one-third. We attempt to better understand
the reason behind this disparate impact across different ATS
domains.

5

70

60

50

40

30

20

10

s
e
t
i

S
f
o
%

0

google.co m
pub m atic.co m
doubleclick.net
googlesyndication.co m
rubiconproject.co m
googletag m anager.co m
google-analytics.co m
googleadservices.co m

openx.net
criteo.co m

criteo.net

s
e
i
k
o
o
C
P
1

f
o

r
e
b
m
u
N
e
g
a
r
e
v
A

50

40

30

20

10

0

0.44% Increase

1.89% Decrease

1.15% Increase

3P Cookies Enabled

3P Cookies Blocked

s
e
t
i

S
f
o
%

70

60

50

40

30

20

10

0

google.co m
pub m atic.co m
doubleclick.net
googlesyndication.co m
rubiconproject.co m
googletag m anager.co m
google-analytics.co m
googleadservices.co m

openx.net
criteo.co m

criteo.net

Table 1. COOKIES SHOWING THE HIGHEST RATIO OF NEW
APPEARANCES AFTER BLOCKING THIRD-PARTY COOKIES.

Cookie
Name

cto bundle
id5id
pbjs-uniﬁedid
pbjs-id5id
s sq

stripe mid
stripe sid
panoramaId
cc id

Script
Domain

New
Appearances

Total
Appearances

Ratio

criteo.com
pubmatic.com
pubmatic.com
pubmatic.com
adobedtm.com
stripe.com
stripe.com
crwdcntrl.net
crwdcntrl.net

132
25
17
24
17
13
13
24
24

632
139
103
164
122
95
95
184
196

0.21
0.18
0.16
0.15
0.14
0.14
0.14
0.13
0.12

are blocked. We can quantify this shift as a ratio be-
tween the number sites where ﬁrst-party cookie is present
in 3P-Allowed crawl and number of new sites where
ﬁrst-party cookie is present in 3P-Blocked crawl. Ta-
ble 1 shows top-10 identiﬁer cookies based on this ra-
is dominated by three well-
tio. We note that
known ad-tech organizations: Criteo (cto_bundle), ID5
(id5id, pbjs-unifiedid, pbjs-id5id), and Lotame
((panoramaID, _cc_id). We further investigate the be-
havior of these cookies using their publicly available docu-
mentation [14], [13], [9], [32], [4] in Appendix A.

the list

3.4. Cross-site Tracking via First-party Cookies

Our analysis of Criteo, Lotame, and ID5 in Appendix
A reveals a common approach to using ﬁrst-party cookies
for cross-site tracking. They build an “identity graph” to

Figure 6. The ﬁgure shows the ﬂow of information and identiﬁers through
an identity Graph for cross-site attribution. Initially, the user visits sites 1,
2, and 3. Trackers on sites 1, 2, and 3 collect and send ﬁngerprints F 1, F 2,
and F 3 to their identity graph. The identity graph returns a U ID−1 for all
the site visits, using a probabilistic matching of ﬁngerprints F 1, F 2, and
F 3 sent on each respective website. A publisher provided ID, P P ID − 1,
is also sent alongside F 3 when visiting site 3. When the user visits site 4,
it sends ﬁngerprint F 4. Because the ﬁngerprint F 4 is different from F 1,
F 2, and F 3, the identity graph cannot create a probabilistic match with the
other sites. On site 4, the website obtains and sends a publisher provided
ID which matches P P ID − 1 provided on site 3. As a result, the identity
graph matches and returns the existing user’s U ID − 1 for site 4 using
deterministic matching. All of these IDs are stored in ﬁrst-party cookies
on the user’s device.

6

Figure 5. Percentage of sites ﬁrst-party cookies show up on before and
after blocking ﬁrst-party cookies.
(
(

) third-party cookies are allowed
) third-party cookies are blocked.

both crawls. These domains do not set a large number of
third-party identiﬁer cookies, which likely explains why they
were not impacted by third-party cookie blocking. Second,
the other set of ATS domains (i.e., Pubmatic, Rubicon, and
OpenX) disproportionately use more third-party identiﬁer
cookies than ﬁrst-party identiﬁer cookies. This observation
explains the drastic drop in number of requests containing
identiﬁers to these other ATS domains after blocking third-
party cookies in Figure 2.

to set cookies:

Finally, we further investigate Criteo which showed
a peculiar behavior in Figure 2. Recall that Criteo uses
criteo.com and criteo.net
the ﬁrst-party
identiﬁer cookies set by the former showed an increase
after blocking third-party cookies while the latter does not
change. In addition to this, criteo.com is also used to set
third-party identiﬁer cookies, while criteo.net sets only ﬁrst-
party identiﬁer cookies. Both of these domains set
the
same cto_bundle cookie. To compare cto_bundle
with identiﬁer cookies set by other ATSes, we plot the
percentage of sites where a cookie with the same name
appears. Figure 5 plots the prevalence of ﬁrst-party cookies
for top-20 cookies. We note that while other cookies witness
a slight drop in their prevalence after blocking third-party
cookies, it does not hold true for cto_bundle. In fact,
cto_bundle’s prevalence increased after blocking third-
party cookies, in accordance with the unexpected increase
in total number of ﬁrst-party identiﬁer cookies set by scripts
belonging to criteo.com.

The aforementioned increased use of ﬁrst-party cookies
represents an interesting scenario where trackers are reac-
tively shifting to ﬁrst-party cookies if third-party cookies

80

60

40

20

s
e
t
i

S
f
o
%

0

ga

gid

gads
fbp
uetvid
gclau
uetsid
bundle
hjT L D Test
P H PS E SSID
cto

cf

utm a
b m

utm c

uid

d
y m
y m

utm b

utm z

utm v
O ptanonC onsent
consentdata

userid

pbjs

Site 1

Site 2

Site 3

Site 4

F1
UI D-1

F2
UI D-1

F3+PPI D-1
UI D-1

F4+PPI D-1
UI D-1

F1

F2

F3 + 
PPI D-1

F4 + 
PPI D-1

identiﬁers to a particular user using ﬁrst-
link different
party information collected from different sites. A node can
represent a user (or device such as web browser) based
on different attributes and edges between the nodes are
formed based on “deterministic” or “probabilistic” match-
ing between attributes of a pair of nodes. For cross-site
tracking, they need to establish edges between different
nodes (that actually represent the same user/device) of the
identity graph. Note that trackers cannot simply use third-
party identiﬁer cookies if they are blocked.

Trackers typically use two types of information to
build their identity graph. They gather information provided
by publishers including both deterministic attributes (e.g.,
email, phone, username, or any other publisher-provided
ID [PPID] that can be directly used for identiﬁcation) and
probabilistic attributes (e.g., zip code, city, age, etc. that can
be used together for non-deterministic identiﬁcation). They
themselves typically also gather probabilistic information
such as IP address and ﬁngerprinting attributes such as
browser and operating system information (e.g., name and
speciﬁc version), device properties (e.g., display resolution,
screen orientation), etc.

To link different nodes in their identity graph (e.g., to
link the same user across different sites or to link different
devices of the same user, an example showing how different
user devices are linked is shown in Appendix B), they use
probabilistic or deterministic matching as shown in more
detail in Figure 6. In probabilistic matching, they measure
the similarity between probabilistic attributes and determine
a match if the similarity is reasonably high (represented as
gray edges in Figure 6). In deterministic matching, they can
exactly match deterministic attributes (represented as black
edges in Figure 6). Once these links are established, trackers
store an identiﬁer in a ﬁrst-party cookie which uniquely
represents that user across different sites (or devices).

3.5. Takeaway

Our differential measurement study reveals that blocking
third-party cookies is insufﬁcient in preventing tracking; as
there is a minimal decrease in the number of ATS requests
sharing identiﬁers when third-party cookies are blocked.
However, the impact of third-party cookie blocking is not
uniform across different ATSes– some ATS domains such as
google-analytics.com and doubleclick.net show no change in
their tracking requests, while others such as pubmatic.com
and rubiconproject.com show a decrease, and yet others
such as criteo.net show an increase. We ﬁnd that ﬁrst-party
cookies are predominantly used by ATSes in lieu of third-
party cookies to perform tracking. Some ATS domains, such
as those owned by Google, only use ﬁrst-party cookies
and are hence not impacted by third-party cookie blocking.
Some other ATS domains that do use third-party cookies
reactively shift to using ﬁrst-party cookies when third-party
cookies are blocked. We ﬁnd that these ATSes rely on a
combination of deterministic and probabilistic attributes to
build an identity graph. Then, they use ﬁrst-party cookies to
store these identiﬁers that are used for cross-site tracking.

Next, we present our approach to accurately and robustly

detect these ﬁrst-party ATS cookies.

4. COOKIEGRAPH: Detecting
Tracking Cookies

First-Party

In this section, we describe COOKIEGRAPH, a graph-
based machine learning approach to detect ﬁrst-party ATS
cookies. COOKIEGRAPH creates a graph representation
of a webpage’s execution based on HTML, network,
JavaScript, and storage information collected by an instru-
mented browser, in which ﬁrst-party cookies are represented
as storage nodes. COOKIEGRAPH extracts distinguishing
features of these cookies and uses a random forest classiﬁer
to detect ﬁrst-party ATS cookies. Figure 7 provides an
overview of COOKIEGRAPH’s pipeline.

4.1. Design and Implementation

Browser instrumentation. COOKIEGRAPH relies on our
extended version of OpenWPM [54] to capture webpage ex-
ecution information across HTML, network, JavaScript, and
the storage4 layers of the web stack. Speciﬁcally, COOKIE-
GRAPH captures HTML elements created by scripts, net-
work requests sent by HTML elements (as they are parsed)
and scripts, responses received by the browser, exﬁltra-
tion/inﬁltration of identiﬁers in network requests/responses,
and read/write operations on browser’s storage mechanisms.
Graph construction. The nodes in COOKIEGRAPH’s graph
represent HTML elements, network requests, scripts, and
storage elements. When localStorage and ﬁrst-party cookie
nodes share the exact same name, COOKIEGRAPH considers
them as one storage node. The edges represent a wide
range of interactions among different types of nodes e.g.,
scripts sending HTTP requests, scripts setting cookies etc.
In addition to interactions considered by prior work [77],
COOKIEGRAPH incorporates edges that capture the tracking
behavior of ﬁrst-party cookies. Informed by our ﬁndings in
Section 3: cookies are typically set with the values inﬁltrated
with HTTP responses and are exﬁltrated via URL parame-
ters and request headers or bodies; COOKIEGRAPH captures
inﬁltrations and exﬁltrations by linking the script-read/write
cookies in the ﬁrst-party execution context to the requests
of reader/writer script that contains those cookie values. In
addition to plain text cookie values, COOKIEGRAPH also
monitors Base64-, MD5-, SHA-1-, and SHA-256- encoded
cookie values in URLs, headers, request and response bod-
ies. As in our measurement study, because of the focus on
identiﬁers, COOKIEGRAPH only captures cookie values that
are at least 8 characters long.

We illustrate the difference between COOKIEGRAPH’s
graph representation and prior work, i.e., WebGraph [77]

4. Our measurements in Section 3 found a signiﬁcant use of localStorage
in addition to cookies. Thus, we use the term “storage” to refer to both
cookies and localStorage. In most cases, the description for cookies is also
applicable to localStorage and vice versa.

7

Figure 7. Overview of COOKIEGRAPH pipeline: (1) Webpage crawl using an instrumented browser; (2) Construction of a graph representation to represent
the instrumented webpage execution information; (3) Feature extraction for graph nodes that represent ﬁrst-party cookies; and (4) Classiﬁer training to
detect ﬁrst-party ATS cookies.

(a) Graph representation of Code 1 in WebGraph

(b) Graph representation of Code 1 in COOKIEGRAPH

Figure 8. Graph representation of Code 1 in WebGraph and COOKIEGRAPH.
represents
storage nodes. Node numbers correspond to the lines in Code 1. In Figure 8(a), dashed (- - -) and dotted (. . .) lines represent the additional edges that
are captured by COOKIEGRAPH and missed by WebGraph. The grey dashed line shows different representations of the same event by both systems.

represents script nodes, and

represents network nodes,

using an example script that involves ﬁrst-party ATS cook-
ies. Code 1 shows a third-party script from tracker1.com
executing in a ﬁrst party context on a webpage. The script
ﬁrst reads infoCookie, which stores tracking information
such as the publisher ID and a user signature. Then, it
sends the content of the cookie to an endpoint via an HTTP
POST request. The endpoint returns a user ID (UID) in the
response body, which is stored in both a ﬁrst-party cookie
and localStorage named IDStore. At a later point, the
script exﬁltrates UID to two other tracking endpoints: to
tracker2.com via a URL parameter and to tracker3.com via
an HTTP header. The HTTP requests and responses that
result from Code 1 are listed in Listing 1.

Figure 8 shows the differences between the graph rep-
resentations of this script created by prior work, WebGraph
(left), and COOKIEGRAPH (right). WebGraph does not cap-
ture the inﬁltration of the UID to the cookie from the
response body and also does not consider inﬁltration and ex-
ﬁltration via localStorage. In contrast, the dotted and dashed
lines in Figure 8(b) show that COOKIEGRAPH captures both
the inﬁltration and the exﬁltration in subsequent network
requests. Moreover, while WebGraph captures exﬁltrations
via URL parameters (shown by grey dashed lines) via edges

from the setting script to the endpoint, COOKIEGRAPH is
able to precisely link this exﬁltration to the ﬁrst-party cookie
via an edge from the cookie node to the endpoint.
Feature extraction. We use COOKIEGRAPH’s representa-
tion to extract structural and information ﬂow features.

Structural features represent relationships between nodes
in the graph, such as ancestry information and connectivity.
These features capture the relationships between the ﬁrst-
party cookie nodes and scripts on the page. For example,
how many scripts interacted with a cookie or whether a
script that interacted with a cookie also interacted with other
cookies.

Flow features represent ﬁrst-party ATS cookie behavior.
We extract three types of ﬂow features. First, we count the
number of times a cookie was read or written. Second,
the number of times a cookie was inﬁltrated
we count
or exﬁltrated via the methods explained in the previous
section. Third, we calculate some features with respect to the
setter of the cookie. Concretely, whether the setter’s domain
also acted as an end-point for other cookie exﬁltrations,
and whether the setter’s domain was involved in redirect
chains (since redirects are commonly used in tracking). The
intuition behind the third category of features is that domains

8

Webpage cr aw l  u si n g 
Open W PM  i n st r u m en t ed 
Fi r ef ox  br ow ser
(t h i r d-par t y cook i es bl ock ed)

Cook i e f eat u r e ex t r act i on
 an d l abel i n g u si n g 
f i l t er  l i st s an d Cook i epedi a

Pr ocess cr aw l  dat a t o bu i l d 
a gr aph  r epr esen t at i on  of  
page ex ecu t i on

Fi r st -par t y cook i e 
cl assf i i cat i on  

ATS

Non -ATS

Script from
tracker1.com

Storage
accesses

2

2

4

Cookie

9, 13

Cookie

10

Local
Storage

14

18

Request to
tracker1.com/sync

Request to
tracker2.com

Request to
tracker3.com

Script from
tracker1.com

Storage
accesses

2

2

4

Cookie

9, 13

Cookie

10

Local
Storage

ID exfiltrations to
other trackers

ID infiltration in
response body

14

18

Request to
tracker1.com/sync

Request to
tracker2.com

Request to
tracker3.com

Table 2. COOKIEGRAPH FEATURES COMPARISON WITH WEBGRAPH.

INDICATES THAT A FEATURE IS PRESENT.

INDICATES THAT FEATURE WAS

EXTENDED IN COOKIEGRAPH. COOKIEGRAPH CALCULATES GRAPH SIZE, DEGREE AND CENTRALITY FEATURES USING BOTH NORMAL AND
SHARED INFORMATION EDGES. THE FORMER COMES UNDER STRUCTURAL FEATURES WHILE THE LATTER COMES UNDER FLOW FEATURES.

Feature

Type

COOKIEGRAPH WebGraph

Graph size (# of nodes, # of edges, and nodes/edge ratio)
Degree (in, out, in+out, and average degree connectivity)
Centrality (closeness centrality, eccentricity)
Ascendant’s attributes
Descendant of a script
Ascendant’s script properties
Parent is an eval script

Local storage access (# of sets, # of gets)
Cookie access (# of sets, # of gets)
Storage access on local storage with same name (# of sets, # of gets)
Requests (sent, received)
Redirects (sent, received, depth in chain)
Common access to the same storage node
Cookie exﬁltration
Cookie inﬁltration
Cookie Setter (# of exﬁltration, # redirects)
Graph size (# of nodes, # of edges, and nodes/edge ratio)
Degree (in, out, in+out, and average degree connectivity)
Centrality (closeness centrality, eccentricity)

Structure
Structure
Structure
Structure
Structure
Structure
Structure

Flow
Flow
Flow
Flow
Flow
Flow
Flow
Flow
Flow
Flow
Flow
Flow

1
2
3
4
5
6

7
8
9
10
11
12
13
14

15
16
17

18
19
20
21
22

<html>

---------------------------------------------------

<script src=’tracker1.com/track.js’>

...
infoCookie = document.cookie;
var idReq = new XMLHTTPRequest();
idReq.open(""POST"", ""tracker1.com/sync"",

true)

idReq.send(infoCookie)
var response = newReq.response
document.cookie = ""IDStore="" + response;
localStorage.setItem(IDStore, response);
...
var exfilReq1 = new XMLHTTPRequest();
idCookie = document.cookie
exfilReq1.open(""GET"", ""tracker2.com?

user_id="" + idCookie);

...
var exfilReq2 = new XMLHTTPRequest();
exfilReq2.setRequestHeader(""ID-header"",

idCookie);

exfilReq2.open(""GET"", ""tracker3.com"");
...

Request 1
URL: tracker1.com/sync
POST data: publisherID=704; signature=xyz
Response 1
Status: 200
Content: UID=abcd
---------------------------------------------------

Request 2
URL: tracker2.com?user_id=abcd
Response 2
Status: 200
---------------------------------------------------

Request 3
Header: ID-header = abcd
URL: tracker3.com
Response 3
Status: 200

</script>
...

</html>

Code 1. Script from third party tracker1.com executing in a ﬁrst party
context. The script obtains a UID from a sync point, stores it, and exﬁltrates
it to tracker2.com and tracker3.com.

involved in setting ﬁrst-party ATS cookies are also involved
in sharing information with other ATSes.

Table 2 shows the differences in features between
COOKIEGRAPH and WebGraph. COOKIEGRAPH adds im-
proved cookie exﬁltration features and also introduces a new
complete new set of inﬁltration and setter features. Unlike
WebGraph, COOKIEGRAPH also considers cases where a
localStorage shares the same name as a cookie (a behavior

Listing 1. HTTP requests and responses initiated from Code 1.

observed in ﬁrst-party ATS cookies). COOKIEGRAPH does
not use content features, e.g., based on cookie name, as they
can be trivially used in detection evasion tactics [77], [66].
COOKIEGRAPH also removes three features because they
are related to classiﬁcation of request nodes in WebGraph
whereas COOKIEGRAPH classiﬁes storage nodes.

4.2. Evaluation

Similar to previous work [65], [77], we use a random
forest classiﬁer to distinguish between ATS and Non-ATS
cookies. We ﬁrst train and test the accuracy of this classiﬁer

9

on a carefully labeled dataset. Then, we deploy it on our 10K
website dataset.

4.2.1. Ground truth labeling. We use two complementary
approaches to construct our ground truth for ﬁrst-party ATS
cookies. We represent each ﬁrst-party cookie as a cookie-
domain pair, since the same cookie name can occur on
multiple sites.
Filter lists. We rely on ﬁlter lists [28], [29] as previous
work has found them to be reasonably reliable in detecting
ATS endpoints [65], [77]. However, ﬁlter lists are designed
to label resource URLs, rather than cookies. We adapt ﬁlter
lists to label cookies by assigning the label of a particular
resource to all the cookies set by that resource. Since both
ATS and Non-ATS cookies can be set by the same resource,
this labeling procedure could result in a non-trivial number
of false positives. To limit the number of false positives in
our ground truth, we only label Non-ATS cookies based on
ﬁlter lists: i.e., if a script that sets a cookie is not marked
by any of the ﬁlter lists, we label these cookies as Non-
ATS. Conservatively, if any one of the ﬁlter lists mark the
cookie’s setter as ATS, we label the cookie as Unknown.
Cookiepedia. Inspired by prior work [41], we use Cook-
iepedia [34] as an additional source of cookie labels. Cook-
iepedia is a database of cookies maintained by a well-known
Consent Management Platform (CMP) called OneTrust [62],
[42]. For each cookie and domain pair, Cookiepedia pro-
vides its purpose, deﬁned primarily through the cookie
integration with OneTrust. Each cookie is assigned one
of four labels: strictly necessary, functional, analytics, and
advertising/tracking. As Cookiepedia-reported purposes are
self-declared, we adopt a conservative approach: we only
label a cookie-domain pair as ATS if a cookie’s purpose is
declared as advertising/tracking or analytics in a particular
domain. If the cookie’s declared purpose is strictly necessary
or functional, we label the cookie as Unknown, as the cookie
might have been, mistakenly or intentionally, mislabeled.

We combine the results of the labeling approaches to
obtain a ﬁnal label for ﬁrst-party cookies. If both approaches
label a cookie as Unknown, its ﬁnal label is Unknown. If
only one of the approaches has a known label, this is the
ﬁnal label. When Cookiepedia marks a cookie as ATS and
ﬁlter lists mark it as Non-ATS, we give precedence to the
Cookiepedia label and assign the ﬁnal label as ATS because
websites are unlikely to self-declare their Non-ATS cookies
as ATS.

Using this labeling process, 20,927 out of 78,560 ﬁrst-
party cookies (26.64%) have a known (ATS or Non-ATS)
label and the rest are labeled as Unknown. We then observe
that cookies set by the same script across two different sites
are often labeled ATS in one instance and Unknown in other
instance because Cookiepedia does not have data for the
latter. As it is unlikely that an ATS script changes purpose
across sites, we propagate the ATS label to all instances
set by the same script. After this label propagation, 51.76%
of the data is now labeled, with 21,875 (53.79%) ATS and
18,786 (46.20%) Non-ATS labels.

10

Figure 9. Feature distribution of cookie exﬁltrations (top) and storage
sets (bottom) for ATS and Non-ATS cookies. ATS cookies are exﬁltrated
and set more than Non-ATS cookies, resulting in ﬂow features based on
exﬁltrations and sets being helpful for the classiﬁer.

4.2.2. Classiﬁcation. We train and test the classiﬁer on the
labeled dataset using standard 10-fold cross validation. We
ensure that there is no overlap in the websites used for
training and test in each fold. Similar to Section 4.1, we limit
the classiﬁer to cookies whose value is at least 8 characters
long. The classiﬁer has 91.87% precision and 90.59% recall,
with an overall accuracy of 91.06%, indicating that the
classiﬁer is successful in detecting ATS cookies.

Feature analysis. We conduct feature analysis to understand
the most inﬂuential features for the classiﬁer. We ﬁnd that
the most inﬂuential features are the ﬂow features, which
capture cookie exﬁltrations, set operations, and redirections
by cookie setters. Figure 9 shows the distributions for the
number of cookie exﬁltrations (top) and the number of times
a cookie is set (bottom), for ATS and Non-ATS cookies. ATS
cookies are much more likely to be exﬁltrated than Non-
ATS cookies: ATS have a median number of 6 exﬁltrations
(mean/std is 11.11/15.95) as compared to a median of 0 for
Non-ATS (mean/std is 0.62/5.29). Also, ATS cookies tend
to be set much more frequently by scripts, with a median of
3 set operations (mean and standard deviation is 4.86±6.99)
as compared to 1 for Non-ATS cookies (mean and standard
deviation is 2.17±6.08). These ﬁndings conﬁrm our conclu-
sions in Section 3: ﬁrst-party ATS cookies are used to store
identiﬁers which are then exﬁltrated to multiple endpoints.

the cookies

Error analysis. We conduct manual analysis of COOKIE-
GRAPH’s false positives and false negatives to understand
why the approach fails.
We ﬁnd that

that were most mis-
classiﬁed as ATS are those whose publicly available
descriptions
indicate they are used to track visitors
on a page (e.g., __attentive_id, messagesUtk,
omnisendAnonymousID) [24], [33], [31]. We also ﬁnd a
few instances of well-known Google Analytics cookies _ga
and _gid that are labeled in ground truth as Non-ATS, but

are classiﬁed by COOKIEGRAPH as ATS. Overall, we ﬁnd
that the false positives are typically not caused by COOK-
IEGRAPH misclassifying non-tracking cookies, but mostly
that the tracking cookies ﬂagged by COOKIEGRAPH were
mislabeled as Non-ATS in the ground truth. In other words,
COOKIEGRAPH has likely correctly classiﬁed these tracking
cookies. We note that even after our procedures to improve
ground truth labels, there may be cookies that did not have
self-disclosed labels or were served from slightly different
scripts (thereby missing our hash-based script matching)
leading to some mistakes in the ground truth. We leave
investigation of further methods of improving the ground
truth labeling to future work.

For

false negatives, a representative case is

the
_pin_unauth cookie. Its value is double-base64-encoded,
that is not included in the list of potential encoding schemes
used by COOKIEGRAPH to detect exﬁltration. These false
negatives can be averted by using a more comprehensive
list of encoding schemes or by performing full-blown infor-
mation ﬂow tracking instead of approximating exﬁltration
ﬂows; however, the latter would come at a performance cost
as we discuss further in Section 4.4. Other false negatives are
because COOKIEGRAPH does not capture sufﬁcient activity
during webpage execution. We further discuss these cases
of false negatives in Section 5.1

Table 3. LIST OF TOP-25 ATS COOKIES DETECTED BY COOKIEGRAPH

Cookie
Name

gid
ga
fbp
gcl au
gpi
ga
gads
gads
uetsid
uetvid
gpi
clck
hjTLDTest
clsk
cto bundle
ym d
ym uid
pin unauth
utma
utmb
utmz
qca
utmc
ttp
hubspotutk

Script
Domain

Org.

Percentage of
Sites

google-analytics.com
google-analytics.com
facebook.net
googletagmanager.com
googlesyndication.com
googletagmanager.com
googlesyndication.com
doubleclick.net
bing.com
bing.com
doubleclick.net
clarity.ms
hotjar.com
clarity.ms
criteo.net
yandex.ru
yandex.ru
pinimg.com
google-analytics.com
google-analytics.com
google-analytics.com
quantserve.com
google-analytics.com
tiktok.com
hs-analytics.net

Google
Google
Facebook
Google
Google
Google
Google
Google
Microsoft
Microsoft
Google
Microsoft
Hotjar
Microsoft
Criteo
Yandex
Yandex
Pinterest
Google
Google
Google
Quantcast
Google
TikTok
HubSpot

77.11%
68.88%
33.22%
14.22%
14.02%
12.79%
12.35%
11.68%
10.22%
10.22%
10.11%
8.81%
8.05%
7.88%
5.98%
4.85%
4.85%
4.57%
4.32%
4.32%
4.32%
4.19%
4.17%
3.75%
3.29%

4.3. Deployment

We deploy COOKIEGRAPH to classify all cookies, in-

cluding Unknown cookies, in our crawl of 10K sites.
Prevalence of ﬁrst-party ATS cookies. Overall, COOKIE-
GRAPH classiﬁes 62.48% of the 74,003 ﬁrst-party cookies
in our dataset as ATS. We ﬁnd that 93.43% of sites deploy at
least one ﬁrst-party ATS cookie. Of these sites, the average
number of ﬁrst-party ATS cookies on a site is 6.29.
Who sets ﬁrst-party ATS cookies? The vast majority
(98.39%) of the ﬁrst-party ATS cookies are in fact set by
third-party embedded scripts served from a total of 1,588
unique domains. This demonstrates that ﬁrst-party ATS
cookies are actually set and used by third-party trackers.
Because this is only possible if the ﬁrst-party allows the
third-party trackers to embed a script in ﬁrst-party con-
text, this suggests that there is intentional or unintentional
collusion between the ﬁrst-party and third-party tracker.
These third-party-set ﬁrst-party cookies enable third-parties
to circumvent blocking-based countermeasures implemented
by browsers.

Next, we analyze the most prevalent ﬁrst-party cookies
and the third-party entities that actually set them. Table 3
lists top-25 out of 5,019 ﬁrst-party ATS cookies5 based on
their prevalence. Two major advertising entities (Google and
Facebook) set ﬁrst-party ATS cookies on approximately a
third of all sites in our dataset. COOKIEGRAPH detects
_gid and _ga cookies by Google Analytics as ATS on
77.11% and 68.88% of the sites. The public documentation

5. We report distinct tuples of cookie name and the setter script’s URL.

acknowledges using these two ﬁrst-party cookies to store
user identiﬁers for tracking [8]. COOKIEGRAPH detects
_fbp cookie by Facebook as ATS on 33.22% of the sites.
Their public documentation acknowledges that Facebook
tracking pixel stores unique identiﬁer in the ﬁrst-party _fbp
cookie [5]. In fact, Facebook made a recent change to
include ﬁrst-party cookie support in its tracking pixel to
avoid third-party cookie countermeasures [20].

TikTok, an emerging social media app that is known
to aggressively harvest sensitive user information [11], also
recently added support for setting ﬁrst-party tracking cook-
ies using TikTok Pixel [19], [17]. TikTok’s ﬁrst-party _ttp
tracking cookie is present on 3.75% percent of sites, which
is considerably lower than Facebook and Google but com-
parable to more specialized entities such as Criteo.
Criteo’s cto_bundle cookie is amongst

the most
prevalent ﬁrst-party ATS cookies. Recall from Section 3.3
that cto_bundle is sometimes purposefully set when
third-party cookies are blocked. Our deployment of COOK-
IEGRAPH shows that Criteo sets this ﬁrst-party ATS cookie
on 5.98% of sites in our dataset. Note that ﬁrst-party ATS
cookies from Lotame, ID5, and Adobe listed in Table 1 are
also detected by COOKIEGRAPH but they do not make the
top-25 list. Despite not being as prevalent as the other ﬁrst-
party ATS cookies, their behavior analysis in Section 3.3
was crucial in discovering prevalent examples discussed in
this section.
Browser ﬁngerprinting. As discussed in Section 3.4, track-
ers that use ﬁrst-party ATS cookies may employ other
invasive tracking techniques such as browser ﬁngerprinting
to implement cross-site tracking. We analyze the ﬁrst-party

11

cookies that are set by the scripts from entities that are
known to engage in browser ﬁngerprinting. We use Dis-
connect’s sublist of ﬁngerprinters [15], [7] from its tracking
protection list [26]. We ﬁnd that Google’s and Facebook’s
ﬁrst-party ATS cookies are predominately set by scripts
served from domains involved in ﬁngerprinting. Lotame’s
cookies (_cc_id, _cc_aud, _cc_cc) are also found to
be set by such scripts.

Overall, we ﬁnd that 45 (2.83%) distinct domains that set
ﬁrst-party cookies are also known ﬁngerprinters. However,
these handful of domains are responsible for setting 41.45%
of all ﬁrst-party ATS cookies. This disproportionately be-
tween domains and number of cookies set is not surprising.
Effective cross-site tracking would require a tracker to be
present on and collect data from a large number of sites.
This presence will allow the tracker to collect extensive
deterministic and probabilistic attributes about the user from
a varied number of source, enhancing its ability to track
users across sites in absence of third-party cookies. Our
case studies in Appendix A and our analysis in Section 3.4
elaborate on how ﬁrst-party ATS cookies are combined with
ﬁngerprinting for cross-site tracking.

4.4. Comparison with Existing Countermeasures

Next, we compare COOKIEGRAPH with state-of-the-
art countermeasures against ATS, CookieBlock [41] and
WebGraph [77], in terms of detection accuracy, website
breakage, and robustness.
CookieBlock is a state-of-the-art approach to classify cook-
ies, including advertising/tracking and analytics. It makes
use of both manually curated allow lists and a machine
learning classiﬁer, which mainly relies on features based
on cookie attributes (cookie names and values).
WebGraph is the state-of-the-art graph-based approach
to classify ATS requests. Since WebGraph is not de-
signed to directly classify cookies, we adapt it to this end
by identifying ATS resources identiﬁed by WebGraph in
3P-Blocked and generating a block list of cookies for
each domain set by those resources. This list is meant to
mimic the effect of blocking these resources on ﬁrst-party
ATS cookies.

4.4.1. Detection Accuracy. Table 4 compares the detec-
tion accuracy of COOKIEGRAPH with CookieBlock and
WebGraph. COOKIEGRAPH outperforms both approaches
in all metrics. The superiority in precision indicates that
existing countermeasures result on many more false posi-
tives than COOKIEGRAPH. These additional false positives
means that previous approaches would block functional ﬁrst-
party cookies potentially affecting user experience. Next, we
investigate the impact of these false positives on website
breakage.

4.4.2. Website Breakage. We manually analyze the break-
age caused by COOKIEGRAPH, CookieBlock and Web-
Graph’s on 50 sites that are sampled from the 10K sites

Table 4. CLASSIFICATION ACCURACY OF COOKIEGRAPH, WEBGRAPH,
AND COOKIEBLOCK

Classiﬁer

Accuracy

Precision

Recall

COOKIEGRAPH
WebGraph
CookieBlock

91.06%
78.74%
80.78%

91.87%
71.59%
69.95%

90.59%
85.49%
72.45%

used in Section 3 (25 sites chosen randomly from top 100
and other 25 from the rest).

We divide our breakage analysis in four categories of
typical website usage: navigation (from one page to an-
other), SSO (initiating and maintaining login state), appear-
ance (visual consistency), and miscellaneous functionality
(chats, search, shopping cart, etc.). We label breakage as
major or minor for each category: major breakage – when
it is not possible to use a functionality on the site included in
either of the aforementioned categories, and minor breakage
– when it is difﬁcult, but not impossible, for the user to make
use of a functionality. To assess website breakage, we com-
pare a vanilla Chrome browser (with no countermeasures
against ﬁrst-party cookies) with browsers enhanced with
an extension which blocks all ﬁrst-party cookies classiﬁed
as ATS by COOKIEGRAPH, enhanced with an extension
which blocks all cookies set by resources labeled as ATS
by WebGraph, and enhanced with the ofﬁcial CookieBlock
extension [3]. We use two reviewers to perform the breakage
analysis to mitigate the impact of biases or subjectivity. Any
disagreements between the reviewers were resolved after
careful discussion.

Out of the 50 sites, COOKIEGRAPH only had minor
breakage on one site where an offer popup kept reappearing
due to deletion of a cookie which stores user preferences.
In contrast, both WebGraph and CookieBlock cause major
breakage in at least one of the four categories on 10% of
the sites. For example, WebGraph causes issues with cart
functionality on darsoo.com, complete website breakage on
espncricinfo.com, and SSO issues on other sites. Most of
the breakage issues of CookieBlock relate to SSO logins
and additional login-dependent functionality (e.g., missing
proﬁle picture). Our results, that CookieBlock causes break-
age on 8% of the sites with SSO logins, are inline with the
7-8% breakage reported by the authors [42].

We also ﬁnd that WebGraph blocks some additional ﬁrst-
party cookies that are important for server-side functionality,
but not directly related to user experience and therefore
not immediately perceptible. For example, WebGraph blocks
essential cookies such as Bm_sz cookie used by Akamai for
bot detection, XSRF-TOKEN cookie used to prevent CSRF
on different sites, and AWSALB cookies used by Amazon
for load balancing. COOKIEGRAPH correctly classiﬁed these
cookies at Non-ATS, and thus does not prevent these mea-
sures from being deployed.

4.4.3. Robustness. We compare the robustness of COOKIE-
GRAPH, CookieBlock, and WebGraph to evasion, i.e., mod-
iﬁcations to cause the misclassiﬁcation of ATS resources
as Non-ATS. Since advertisers and trackers are known to

12

Table 5. WEBSITE BREAKAGE COMPARISON OF ALL THREE

COUNTERMEASURES.(
BREAKAGE, AND (

) SIGNIFIES NO BREAKAGE, (

) MINOR
) MAJOR BREAKAGE. EACH CELL REPRESENTS

THE PERCENTAGE OF SITES ON WHICH BREAKAGE WAS OBSERVED.

Classiﬁer

Navigation

Miscellaneous
Minor Major Minor Major Minor Major Minor Major

Appearance

SSO

COOKIEGRAPH
0%
WebGraph
10%
CookieBlock
2%
Table 6. ROBUSTNESS (DIFFERENCE IN CLASSIFICATION ACCURACY)

2%
4%
0%

0%
6%
8%

0%
0%
0%

0%
4%
0%

0%
2%
0%

0%
2%
2%

0%
0%
0%

Classiﬁer

∆ Accuracy ∆ Precision ∆ Recall

COOKIEGRAPH
WebGraph
CookieBlock

0.00%
0.00%
-15.68%

0.00%
0.00%
-15.08%

0.00%
0.00%
-16.54%

engage in the arms race with privacy-enhancing tools [37],
[64], [61],
to test whether the detection
of ﬁrst-party ATS cookies is brittle in the face of trivial
manipulation attempts such as changing cookie names.

is important

it

We evaluate robustness on a test set of 2,000 sites from
our dataset which also have the required CMP needed by
CookieBlock for data collection and training. This translates
to a total test set of 7,726 ﬁrst-party cookies. We change the
names of the cookies in our test set to randomly generated
strings of lengths between 2 and 15 characters. Table 6
shows the results. We note that both COOKIEGRAPH and
WebGraph are fully robust to manipulation of cookies names
while CookieBlock’s accuracy degrades by more than 15%.
COOKIEGRAPH and WebGraph are robust because they
do not use any content features (features related to the
cookie characteristics, such as cookie name or domain) since
these can be somewhat easily manipulated by an adversary
aiming to evade classiﬁcation [77]. On the contrary, the most
important feature of CookieBlock in fact depends on the
cookie name, i.e., whether the name belongs to the top-500
most common cookie names [40]. Thus, CookieBlock can
be easily bypassed with trivial cookie name modiﬁcations.
COOKIEGRAPH’s implementation of ﬂow features can
be manipulated by an adversary by using a different encod-
ing than it currently considers or by changing the domains of
exﬁltration endpoints. COOKIEGRAPH’s robustness to these
attacks can be improved by more comprehensive informa-
tion ﬂow tracking. However, full-blown information ﬂow
tracking would incur prohibitively high run-time overheads
(up to 100X-1000X [60]) and implementation complexity in
the browser [46], [45], [80], [68].

5. Limitations

5.1. Completeness

COOKIEGRAPH relies on a graph representation of in-
teractions between different elements during webpage exe-
cution. The completeness of the interactions captured in the
graph depends on the intensity and variety of user activity on
a webpage (e.g., scrolling activity, number of internal pages
clicked). In other words, it is possible that COOKIEGRAPH

13

may not detect certain ATS cookies if its graph represen-
tation has not captured the interactions between different
elements due to insufﬁcient user activity.

To study the impact of user activity on COOKIEGRAPH,
we recrawl sites performing two to three times more in-
ternal page clicks than in the original crawl. We speciﬁ-
cally recrawl 238 sites where Criteo’s cto_bundle cookie
was originally classiﬁed as Non-ATS by COOKIEGRAPH.
COOKIEGRAPH’s deployment on the recrawled sites results
in successful detection of Criteo’s cto_bundle cookie
as ATS on 121 of the 238 recrawled sites. We ﬁnd that
the average number of inﬁltrations (exﬁltrations) increase
from 1.54 to 2.95 (1.13 to 4.01) across the original and
recrawled sites. We surmise that while there are cases
where COOKIEGRAPH incorrectly classiﬁes ATS as Non-
ATS due to incompleteness of the graph representation, its
decision reﬂects the behavior of the cookie at the time of
classiﬁcation. As more interaction is captured in the graph,
COOKIEGRAPH is able to correctly switch the label to ATS.
Moreover, COOKIEGRAPH never switch labels from ATS
to Non-ATS due to increased interaction. We observed a
similar trend for other prevalent ﬁrst-party ATS cookies in
our dataset.

5.2. Deployment

COOKIEGRAPH’s implementation is not suitable for run-
time deployment due to the performance overheads asso-
ciated to the browser instrumentation and machine learn-
ing pipeline. We envision COOKIEGRAPH to be used in
an ofﬂine setting: (1) ﬁrst-party ATS cookie-domain pairs
are detected using machine learning classiﬁer and (2) the
detected cookie-domain pairs are added to a cookie ﬁlter
list such as those already supported in privacy-enhancing
browser extensions such as uBlock Origin [18] for run-
time blocking. We argue that a reasonably frequent (e.g.,
once a week) deployment of COOKIEGRAPH on a large
scale would be sufﬁcient in generating and keeping the
ﬁlter list up-to-date. While advertisers and trackers can in
theory change cookie names at a rate faster than COOK-
IEGRAPH’s periodic deployment, updating cookie names
frequently is challenging in practice because setting these
ﬁrst-party ATS cookies across many different sites requires
tight coordination between different entities. To illustrate
the practical issues associated with changing cookie names,
consider the legacy demdex cookie set by Adobe’s em-
bedded script
is then exﬁltrated to the demdex.net
domain. Adobe’s documentation explains that it is difﬁcult
to change the legacy name because “... it is entwined deeply
with Audience Manager, the Adobe Experience Cloud ID
Service, and our installed user base” [25], [36]. If advertisers
or trackers are somehow able to overcome these practi-
cal challenges and change cookie names at a much faster
pace, COOKIEGRAPH’s online implementation for run-time
cookie classiﬁcation would be necessary. Further research is
needed for efﬁcient and effective online implementation of
COOKIEGRAPH.

that

6. Conclusion

We conducted a large scale differential measurement
study to investigate how trackers abuse ﬁrst-party cookies
to circumvent third-party cookie blocking. Our proposed
COOKIEGRAPH was able to accurately and robustly block
ﬁrst-party tracking cookies, and signiﬁcantly outperforming
the state-of-the-art. Using COOKIEGRAPH, we found evi-
dence of widespread abuse of ﬁrst-party cookies on more
than 93% of the tested websites by 1500+ distinct tracking
domains, which included major advertising entities such as
Google as well as many specialized entities such as Criteo.

References

[18] “uBlock Origin: Resources Library,” https://github.com/gorhill/uBloc

k/wiki/Resources-Library#cookie-removerjs-.

[19] “Using cookies with tiktok pixel,” https://web.archive.org/web/

20220610074648/https://ads.tiktok.com/help/article?aid=10007540.

[20] “What

facebook’s

ﬁrst-party

cookie means

for

adtech,”

https://web.archive.org/web/20220729210450/https://clearcode.cc
/blog/facebook-first-party-cookie-adtech/.

[21] “This bug in your pc is a smart cookie,” https://archive.org/details/Fi

nancialTimes1996UKEnglish, 1996.

[22] “Internet privacy with ie6 and p3p: A summary of ﬁnd-
ings,” http://web.archive.org/web/20200731061208/http://www.spyw
arewarrior.com/uiuc/ie6-p3p.htm, 2001.

[23] “Adblock plus,” https://adblockplus.org/, 2022. [Online]. Available:

https://adblockplus.org/

[24] “Attentive

cookie,”

https://docs.attentivemobile.com/p

[1]

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

“About publisher provided identiﬁers,” https://web.archive.org/we
b/20220614165742/https://support.google.com/admanager/answer/
2880055?hl=en.

“Cartographer
20220526085916/https://www.lotame.com/solutions/cartographe
r-identity-graph/.

https://web.archive.org/web/

identity

graph,”

“Cookieblock,” https://github.com/dibollinger/CookieBlock.

Online

“Criteo
20220819071808/https://ﬁlecache.investorroom.com/mr5ir crite
o/977/download/Criteo Online Identification May2020.pdf/.

Identiﬁcation),”

https://web.archive.org/web/

and

“fbp
Parameters,”
20220722220344/https://developers.facebook.com/docs/marketi
ng-api/conversions-api/parameters/fbp-and-fbc/.

https://web.archive.org/web/

fbc

“Firefox rolls out total cookie protection by default to all users world-
wide,” https://blog.mozilla.org/en/products/firefox/firefox-rolls-out-t
otal-cookie-protection-by-default-to-all-users-worldwide/.

“Firefox’s protection against ﬁngerprinting,” https://support.mozilla.
org/en-US/kb/firefox-protection-against-fingerprinting.

“Google Analytics Cookie Usage
//web.archive.org/web/20220812222800/https://developers.googl
e.com/analytics/devguides/collection/gtagjs/cookie-usage.

on Websites),”

https:

“Id5 identity cloud,” https://web.archive.org/web/20220727094611/ht
tps://www.id5.io/identity-cloud/.

[10] “Identity Guide,” https://web.archive.org/web/20220115155115/https:

//yieldbird.com/identity-guide/.

[11] “It’s

their word against

their
https://internet2-0.com/whitepaper/its-their-word-against-their-s
ource-code-tiktok-report/.

source code -

tiktok report,”

[12] “Lotame – Data Collection Guide,” https://web.archive.org/web/
20210730071853/https://my.lotame.com/t/p8hxvnd/data-collection-g
uide.

[13] “Lotame

identity

resolution,”
20220530231410/https://www.lotame.com/solutions/identity-res
olution/.

https://web.archive.org/web/

[14] “Lotame

lightning

tag,”
20220307010702/https://my.lotame.com/t/m1hxv7l/lotame-light
ning-tag.

https://web.archive.org/web/

[15] “Our new approach to address

the

rise of ﬁngerprinting,”

https://blog.disconnect.me/our-new-approach-to-address-the-ris
e-of-fingerprinting/.

[16] “Panorama id,” https://web.archive.org/web/20220327180718/https://

www.lotame.com/panorama/id/.

ages/developer-guides/third-party-integrations/referral-mar
keting-platforms/talkable/,
https://docs.attentivemobile.com/pages/developer-guides/third-p
arty-integrations/referral-marketing-platforms/talkable/

[Online].

2022.

Available:

[25] “Cookies

the

and

ser-
experience
vice,” https://experienceleague.adobe.com/docs/id-service/using/intro
/cookies.html?lang=en, 2022. [Online]. Available: https://experience
league.adobe.com/docs/id-service/using/intro/cookies.html?lang=en

identity

cloud

[26] “Disconnect tracking protection lists,” https://disconnect.me/trackerp
rotection, 2022. [Online]. Available: https://disconnect.me/trackerpro
tection

[27] “Doubleclick,”

https://web.archive.org/web/19970405225532/http:

//www.doubleclick.com/, 2022.

[28] “Easylist,” https://easylist.to/easylist/easylist.txt, 2022.

[29] “Easyprivacy,” https://easylist.to/easylist/easyprivacy.txt, 2022.

[30] “Enhanced tracking protection in ﬁrefox for desktop,” https://support.
mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop,
2022.

[31] “Hubspot cookie,” https://knowledge.hubspot.com/reports/what-coo
kies-does-hubspot-set-in-a-visitor-s-browser, 2022. [Online]. Avail-
able: https://knowledge.hubspot.com/reports/what-cookies-does-hub
spot-set-in-a-visitor-s-browser

[32] “Id5

-

ﬁrst

resolution methods
party
explained,”
https://web.archive.org/web/20220408035339/https:
//id5.io/news/index.php/2022/03/24/ﬁrst-party-ids-and-identity-resol
ution-methods-explained/, 2022.

identity

and

ids

[33] “Omnisend

cookie,”

https://support.omnisend.com/en/articles
[On-
/1933402-explaining-and-managing-tracking-cookies,
line]. Available: https://support.omnisend.com/en/articles/1933402-e
xplaining-and-managing-tracking-cookies

2022.

[34] “One trust. cookiepedia,” https://cookiepedia.co.uk, 2022.

[35] “Tracking prevention in microsoft edge,” https://docs.microsoft.com
/en-us/microsoft-edge/web-platform/tracking-prevention, 2022.

[36] “Understanding

calls

do-
https://experienceleague.adobe.com/docs/audience-manager
main,”
/user-guide/reference/demdex-calls.html?lang=en, 2022.
[Online].
Available: https://experienceleague.adobe.com/docs/audience-manag
er/user-guide/reference/demdex-calls.html?lang=en

demdex

the

to

[37] M. Alrizah, S. Zhu, X. Xing, and G. Wang, “Errors, misunder-
standings, and attacks: Analyzing the crowdsourcing process of ad-
blocking systems,” in Proceedings of the 2019 Internet Measurement
Conference (IMC), 2019.

[17] “Tiktok adds third-party cookies to its pixel – and tries to eat face-
book’s
lunch,” https://web.archive.org/web/20220623232016/https:
//www.adexchanger.com/online-advertising/tiktok-adds-third-party-c
ookies-to-its-pixel-and-tries-to-eat-facebooks-lunch/.

[38] W. Aqeel, B. Chandrasekaran, A. Feldmann, and B. M. Maggs, “On
landing and internal web pages: The strange case of jekyll and hyde in
web performance measurement,” in Proceedings of the ACM Internet
Measurement Conference, 2020.

14

[39] P. N. Bahrami, U. Iqbal, and Z. Shaﬁq, “Fp-radar: Longitudinal
measurement and early detection of browser ﬁngerprinting,” in Pro-
ceedings on Privacy Enhancing Technologies (PETS), 2022.

[40] D. Bollinger, “Analyzing Cookies Compliance with the GDPR,” https:
//www.research-collection.ethz.ch/handle/20.500.11850/477333. The-
sis, ETH Zurich.

[41] D. Bollinger, K. Kubicek, C. Cotrini, and D. Basin, “Automating
cookie consent and GDPR violation detection,” in 31st USENIX
Security Symposium (USENIX Security 22). USENIX Association,
2022.

[42] ——, “Automating cookie consent and gdpr violation detection,” in
31st USENIX Security Symposium (USENIX Security 22), 2022.

[43] A. Cahn, S. Alfeld, P. Barford, and S. Muthukrishnan, “An empirical
study of web cookies,” in Proceedings of the 25th International
Conference on World Wide Web.
International World Wide Web
Conferences Steering Committee, 2016, p. 891–901.

[44] Q. Chen, P. Ilia, M. Polychronakis, and A. Kapravelos, “Cookie swap
party: Abusing ﬁrst-party cookies for web tracking,” in Proceedings
of the Web Conference, 2021.

[45] Q. Chen and A. Kapravelos, “Mystique: Uncovering information
leakage from browser extensions,” in Proceedings of the 2018 ACM
SIGSAC Conference on Computer and Communications Security,
2018, pp. 1687–1700.

[46] A. Chudnov and D. A. Naumann, “Inlined information ﬂow mon-
itoring for javascript,” in Proceedings of the 22nd ACM SIGSAC
Conference on Computer and Communications Security, 2015, pp.
629–643.

[47] L. M. D. Kristol, “Http state management mechanism,” https://datatr

acker.ietf.org/doc/html/rfc2109, 1997.

[48] S. Dambra, I. Sanchez-Rola, L. Bilge, and D. Balzarotti, “When sally
met trackers: Web tracking from the users’ perspective,” in USENIX
Security Symposium, 2022.

[49] H. Dao, J. Mazel, and K. Fukuda, “Cname cloaking-based tracking
on the web: Characterization, detection, and protection,” IEEE Trans-
actions on Network and Service Management, 2021.

[60] D. Hedin, A. Birgisson, L. Bello, and A. Sabelfeld, “Jsﬂow: Tracking
information ﬂow in javascript and its apis,” in Proceedings of the 29th
Annual ACM Symposium on Applied Computing, 2014, pp. 1663–
1671.

[61] L. Hieu, M. Athina, and S. Zubair, “Cv-inspector: Towards automat-
ing detection of adblock circumvention,” in Network and Distributed
System Security Symposium (NDSS), 2021.

[62] M. Hils, D. W. Woods, and R. B¨ohme, “Measuring the emergence
of consent management on the web,” in Proceedings of the ACM
Internet Measurement Conference, 2020.

[63] X. Hu, N. Sastry, and M. Mondal, “Cccc: Corralling cookies into
categories with cookiemonster,” in 13th ACM Web Science Conference
2021. Association for Computing Machinery, 2021, p. 234–242.

[64] U. Iqbal, Z. Shaﬁq, and Z. Qian, “The ad wars: Retrospective mea-
surement and analysis of anti-adblock ﬁlter lists,” in IMC, 2017.

[65] U. Iqbal, P. Snyder, S. Zhu, B. Livshits, Z. Qian, and Z. Shaﬁq,
“Adgraph: A graph-based approach to ad and tracker blocking,” in
IEEE Symposium on Security and Privacy (S&P).

IEEE, 2020.

[66] U. Iqbal, C. Wolfe, C. Nguyen, S. Englehardt, and Z. Shaﬁq,
“Khaleesi: Breaker of advertising and tracking request chains,” in
USENIX Security Symposium (USENIX), 2022.

[67] P. Laperdrix, W. Rudametkin, and B. Baudry, “Beauty and the beast:
Diverting modern web browsers to build unique browser ﬁngerprints,”
in 2016 IEEE Symposium on Security and Privacy (SP), 2016.

[68] S. Lekies, B. Stock, and M. Johns, “25 million ﬂows later: Large-
scale detection of dom-based xss,” in Proceedings of the 2013 ACM
SIGSAC conference on Computer and Communications Security,
2013, pp. 1193–1204.

[69] P. G. Leon, L. F. Cranor, A. M. McDonald, and R. McGuire, “Token
attempt: the misrepresentation of website privacy policies through
the misuse of p3p compact policy tokens,” in Proceedings of the 9th
Annual ACM Workshop on Privacy in the Electronic Society, 2010.

[70] L. Montulli, “The reasoning behind web cookies,” http://montulli.blo

gspot.com/2013/05/the-reasoning-behind-web-cookies.html, 2013.

[50] Y. Dimova, G. Acar, L. Olejnik, W. Joosen, and T. Van Goethem, “The
CNAME of the Game: Large-scale Analysis of DNS-based Tracking
Evasion,” PETS, 2021.

[71] N. Nguyen, “Latest ﬁrefox rolls out enhanced tracking pro-
tection,” https://blog.mozilla.org/en/products/firefox/latest-firefox-rol
ls-out-enhanced-tracking-protection/, 2018.

[51] D´ıaz-Morales and Roberto, “Cross-device tracking: Matching devices
and cookies,” in 2015 IEEE International Conference on Data Mining
Workshop (ICDMW), 2015, pp. 1699–1704.

[52] B. Eich, “C is for cookie,” https://brendaneich.com/2013/05/c-is-for

-cookie/, 2013.

[53] ——, “The cookie clearinghouse,” https://brendaneich.com/2013/06/

the-cookie-clearinghouse/, 2013.

[54] S. Englehardt and A. Narayanan, “Online tracking: A 1-million-site
measurement and analysis,” in Proceedings of ACM CCS 2016, 2016.

[55] S. Englehardt, D. Reisman, C. Eubank, P. Zimmerman, J. Mayer,
A. Narayanan, and E. W. Felten, “Cookies that give you away: The
surveillance implications of web tracking,” in Proceedings of the 24th
International Conference on World Wide Web, 2015.

[56] I. Fouad, N. Bielova, A. Legout, and N. Saraﬁjanovic-Djukic, “Missed
by ﬁlter lists: Detecting unknown third-party trackers with invisible
pixels,” Proceedings on Privacy Enhancing Technologies, vol. 2020,
pp. 499–518, 04 2020.

[57] I. Fouad, C. Santos, A. Legout, and N. Bielova, “My cookie is a
phoenix: detection, measurement, and lawfulness of cookie respawn-
ing with browser ﬁngerprinting,” in Privacy Enhancing Technologies
Symposium (PETS), 2022.

[58] B. Fulgham, “Protecting against hsts abuse,” https://webkit.org/blog/

8146/protecting-against-hsts-abuse/, 2018.

[59] Google, “The privacy sandbox,” https://developer.chrome.com/docs/

privacy-sandbox/.

[72] P. Papadopoulos, N. Kourtellis, and E. P. Markatos, “Cookie syn-
chronization: Everything you always wanted to know but were afraid
to ask,” in Proceedings of the World Wide Web (WWW) Conference,
2019.

[73] A. Randall, P. Snyder, A. Ukani, A. Snoeren, G. Voelker, S. Savage,
and A. Schulman, “Trackers bounce back: Measuring evasion of
partitioned storage in the wild,” 2022.

[74] F. Roesner, T. Kohno, and D. Wetherall, “Detecting and defending
against third-party tracking on the web,” in 9th USENIX Symposium
on Networked Systems Design and Implementation (NSDI 12), 2012,
pp. 155–168.

[75] I. Sanchez-Rola, M. Dell’Amico, , D. Balzarotti, P.-A. Vervier, and
L. Bilge, “Journey to the center of the cookie ecosystem: Unraveling
actors’; roles and relationships,” in S&P 2021, 42nd IEEE Symposium
on Security & Privacy, 23-27 May 2021, San Francisco, CA, USA,
2021.

[76] J. Schuh, “Building a more private web: A path towards making third
party cookies obsolete,” https://blog.chromium.org/2020/01/building
-more-private-web-path-towards.html, 2020.

[77] S. Siby, U. Iqbal, S. Englehardt, Z. Shaﬁq, and C. Troncoso, “Web-
graph: Capturing advertising and tracking information ﬂows for robust
blocking,” in 31st USENIX Security Symposium (USENIX Security
22). USENIX Association, 2022.

[78] A. Sj¨osten, P. Snyder, A. Pastor, P. Papadopoulos, and B. Livshits,
“Filter list generation for underserved regions,” in WWW, 2020.

15

[79] S. Sluis, “Google is building integrations for publisher-speciﬁc identi-
ﬁers,” https://www.adexchanger.com/platforms/google-is-building-int
egrations-for-publisher-speciﬁc-identifiers/, 2021.

[80] B. Stock, S. Lekies, T. Mueller, P. Spiegel, and M. Johns, “Precise
client-side protection against dom-based cross-site scripting,” in 23rd
USENIX Security Symposium (USENIX Security 14), San Diego, CA,
2014, pp. 655–670.

[81] B. P. Team, “Fighting CNAME Trickery,” https://brave.com/privacy-u

pdates/6-cname-trickery/, 2020.

[82] M. E. Team, “Introducing tracking prevention, now available in
microsoft edge preview builds,” https://blogs.windows.com/msedge
dev/2019/06/27/tracking-prevention-microsoft-edge-preview/, 2022.
[Online]. Available: https://blogs.windows.com/msedgedev/2019/06/
27/tracking-prevention-microsoft-edge-preview/

[83] A. Vastel, P. Laperdrix, W. Rudametkin, and R. Rouvoy, “Fp-stalker:
Tracking browser ﬁngerprint evolutions,” in IEEE Symposium on
Security and Privacy (SP), 2018.

[84] A. V. Veen and A. de Vries, “Cookie compliance of dutch hospital

websites,” 2021.

[85] WebKit, “Tracking prevention in webkit,” https://webkit.org/trackin
g-prevention/, 2022. [Online]. Available: https://webkit.org/trackin
g-prevention/

[86] J. Wilander, “Intelligent tracking prevention,” https://webkit.org/blog/

7675/intelligent-tracking-prevention/, 2017.

[87] ——, “Intelligent tracking prevention 1.1,” https://webkit.org/blog/

8142/intelligent-tracking-prevention-1-1//, 2018.

[88] ——, “Intelligent tracking prevention 2.0,” https://webkit.org/blog/

8311/intelligent-tracking-prevention-2-0/, 2018.

[89] ——, “Intelligent tracking prevention 2.1,” https://webkit.org/blog/

8613/intelligent-tracking-prevention-2-1/, 2019.

[90] ——, “Intelligent tracking prevention 2.2,” https://webkit.org/blog/

8828/intelligent-tracking-prevention-2-2/, 2019.

[91] ——, “Intelligent tracking prevention 2.3,” https://webkit.org/blog/

9521/intelligent-tracking-prevention-2-3/, 2019.

[92] ——, “Cname cloaking and bounce tracking defense,” https://we

bkit.org/blog/11338/cname-cloaking-and-bounce-tracking-defense/,
2020.

[93] ——, “Full third-party cookie blocking and more,” https://webkit.org
/blog/10218/full-third-party-cookie-blocking-and-more/, 2020.

[94] ——, “Bounce tracking protection,” https://github.com/privacycg/pro

posals/issues/6, 2022.

Appendix

1. Case Studies

In this section, we look at case studies of ATSes identi-
ﬁed in Section 3.3 which are found to be extensively using
ﬁrst-party cookies for tracking purposes. We analyze the
behavior of these ATS in our crawls, compare the observed
behavior with their documentation, and create a generic
model which all ﬁrst-party-cookie-based ATSes follow in
Section 3.4. We present case studies of three ATSes here:
Lotame, ID5, and Criteo.

1.1. Lotame. Lotame is a data and identity management
solution which claims to provide a single ID to users across
multiple browsers, devices, and platforms. Lotame’s Light-
ning Tag [14] packages the user visit data in a JSON object
and sends it to its servers. Code 2 shows an example payload
sent to Lotame. The payload includes IDs assigned by the
website, third-party identiﬁers present on the site, certain
user behaviors (conﬁgured through collaboration between
the publisher and Lotame), and other custom rules deﬁned
per website [12]. Lotame processes the payload and matches
the data with its Cartographer Identity Graph [2], and sends
back an ID, called panoramaID [16], which is stored as
a ﬁrst-party cookie or in localStorage.

1.2. ID5 Universal ID. ID5 provides identity resolution for
publishers and advertisers through its Identity Cloud [9].
ID5’s script packages a payload that contains several de-
terministic identiﬁers, such as email, usernames, and phone
numbers (if available) and as well as probabilistic identiﬁers
include, such as IP address, user agent, and location of the
user [32]. ID5 then processes the payload and matches the
data with its Identity Cloud and send back an ID, called
universal id, which is stored as a ﬁrst-party cookie and as
well as in local storage. An example payload from ID5 is
shown in Figure 3. We note that ID5 also provides Partner
Graph, a service that enables information sharing among
its partners [9]. Partner Graph allows different
identify
providers to exchange information with each other.

data: {

behaviorIds: [1,2,3],
behaviors: {

int: [’behaviorName’, ’behaviorName2’],
act: [’behaviorName’]

},
ruleBuilder: {

key1: [’value 1a’, ’value 1b’]

},
thirdParty: {

namespace: ’NAMESPACE’,
value: ’TPID_VALUE’

}

}

Code 2. Example of data sent structure sent to Lotame during a user’s ﬁrst
visit.

1
2
3
4
5
6
7
8
9
10
11
12
13
14

16

party cookies and localStorage for storing cto_bundle
cookie. We consider this to be one of the fundamental
behaviors of ﬁrst-party ATS cookies. As described in Sec-
tion 4.1, COOKIEGRAPH’s graph representation abstracts
storage to refer to both Cookies and localStorage. We also
include a count of localStorage accesses in the feature set
computed from the graph representation. Inclusion of these
features help COOKIEGRAPH effectively model ﬁrst-party
ATS cookies behavior.

2. Cross-Device User Attribution

The methodology for cross-site attribution can also be
extended to cross-device attribution. In this slightly more
complex scenario, the user is not only visiting different sites
but also using different devices with different ﬁngerprints.
We show an example of cross-device attribution in Fig-
ure 10. Instead of visiting the sites on the same device, the
user now visits sites 1-3 on device 1, and then visits sites 4-6
on device 2. Fingerprints F1, F2 and F3 are collected on sites
1-3 while using device 1, and F4, F5 and F6 are collected
while using device 2. Sites 3 and 6 ask the user for an
additional P P ID − 1. There is no similarity in ﬁngerprints
between the two devices. However, as sites 3 and 6 collect
the additional P P ID − 1, the tracker is able to identify and
populate its ﬁrst-party cookie on each of those sites with
the correct user ID (U ID1).

1
2
3
4

5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36

37
38
39
40
41
42
43
44
45

{

""created_at"":""2022-02-09T11:42:40.817811Z"",
""id5_consent"":true,
""original_uid"":""ID5*

FnFOGLkYzdJjuoK3KvAecVW2oFpZ7OrZiW7h-M0H
ACAHYuWkxQrEGcpWuOkQUXbHB2OO8Rj0wt94jllT
WHQ6wdkqOwSbnYea8cesuONCF4HZeIoDaB_TwBsy
lKrs3tHB2Y87ZwP0DrpYlGz1OG1Fgdn0YdgqoSGU
SGxzS1gUzsHaMIUBVqf2I08es6aUULEB2n48oyL0
nGnRtstVqtcQQdquS3Aay4Hhgbzh9gIZyYHa_nLT
d5rjbbR0ZXwkXDzB2yU1XUC2dukip1J_clVAgdtt
xC_xaRRBOLi0fnvp9cHbqr_pWihTtaUMS_R6eLuB
2_AMExt1UdhJZBe2mcXZAdwm9lcbeMMvlpg3MBrC
oHcUgzNypi-5xLUqBD8GC4B3KsefcNkiDvI4n9ZL
7OjAdzqB9PD-KczAx63Ck0gEIHdNPfQeEi-f5VaO
OEhf6B3VUqDoL11hqVoIuDhKJbgd2kp0mgXabhwJ
tPO7sgWwHd_vz_uIYYmqQBTbH-JFVB3h1-kI9GQv
dby2PyftDawd596ho3tuOsKtoDOk4S4Her2Uw-_u
BYRxrt6YzVYqB3tRwTVI3Fxm8cGJyjdmYAd88lom
BIpkOeg2Ok4VTNc"",
""universal_uid"":""ID5*

HGH7W7iMpMu3-EPZCXUuqNBB7fFHUUVcbSddSSG
Fu5UHYucsBxMz2jncvKS7rkwlB2MWiiPupapPxa
79eieMAdkTyMQz82s1vIekPr28DEHZbqTCrapj9
Fb9K0x4zjlB2YHOKNDwQY6mZwxk_1mwAdna3wWna
hrpMEUrPxJSnAHaPYB-InS5DXGpQgqbqirB2nHFI
D4j9i9BgCP3k0VygdqdtFHsT7eeDfFYuB8EQ0Ha4
-yV9Ifvbvi5oxmtH7HB2xg-mmmOeyVOPBYGi2tfw
dtREZnUE83cfn_LHvHvu4HbvkLkwEFJiddOEp4PT
ZbB2-de_VPyKHax5JtpO46xwdwZ_0UMgANOsZygV
0SrrMHcZ37qQB-LkCO4tWoTbv_B3KMGCMrebcfLE
TeCn0AEgdzIR1utDJzM6AaiL9KVkAHdPtrAtTv73
ZyDg92Rq-_B3XeRNOOc7b2CEBsilXOlQd2sfmR36
NyW-dsK9CUmd4Hd3vcrlAWzfYEfw01Q5J1B3ibAF
UYrA0XWMl-D9jSlAd5iX1tGA4vPu0wdZkXVOEHek
q2xibOm9XwN2nSdZjbB3v8nOyzGuF9QgwI67pMGQ
d85BszRCJDUkiiu-tv5BQ"",

""signature"":""

ID5_Ab6tnGgmCcjKo-qFGVKszuNpNePqkOHZT
rbCmpuktLLOlNOCALhmY_91AHP8LU0BvfJT2Q
JQWlsUEfynB1hBGZc"",

""link_type"":1,
""cascade_needed"":true,
""privacy"":{

""jurisdiction"":""other"",
""id5_consent"":true

}

}

Code 3. Example of data structure received from ID5 during a user’s ﬁrst
visit.

1.3. Criteo. Criteo provides Criteo Identity Graph for iden-
tity resolution [4]. Criteo Identity Graph is built from four
different sources: (i) data contributed by advertisers, (ii) data
collected from publisher websites by Criteo itself, (iii) data
provided by Criteo partners such as LiveRamp and Oracle,
(iv) and predictions on existing data by Criteo’s machine
learning models. Criteo claims that its identity graph is able
to stitch together identiﬁers from more than 2 billion users
across the world, and that it contains persistent deterministic
identiﬁers for 96% of the users [4]. Similar to other identity
resolution services, Criteo generates an ID, based on identi-
ﬁers, such as hashed emails, mobile device IDs, cookie IDs,
and stores it in ﬁrst-party storage as cto_bundle. Their
documentation shows that Criteo makes use of both ﬁrst-

17

Figure 10. This ﬁgure shows the ﬂow of information and identiﬁers through an identity graph for a cross-device attribution. The user visits sites 1, 2, and
3 via Device 1. The identity graph returns a U ID − 1 for all the site visits, using a probabilistic matching of ﬁngerprints F 1, F 2, and F 3 sent on each
respective website. A Publisher Provided ID P P ID − 1 is also sent alongside F 3 when visiting site 3. The user visits sites 4, 5, and 6 through a new
Device 2. Because the ﬁngerprints F 4 and F 5 are different from F 1, F 2, and F 3, the identity graph returns a new U ID − 2 for these site visits. On
site 6, the website obtains and sends a Publisher Provided ID which matches P P ID − 1 provided on site 3. As a result, the identity graph matches and
returns the existing user’s U ID − 1 for site 6.

18

Site 1

Site 2

Site 3

UID-1

UID-1

UID-1

Device 1

Cookie Stor e

Site 1

Site 2

Site 3

F1
UI D-1

F2
UI D-1

F3+PPI D-1
UI D-1

F1

F4

F2

F3 + 
PPID-1

F6 + 
PPID-1

F5

Site 4

Site 5

Site 6

UID-2

UID-2

UID-1

Cookie Stor e

Device 2

F4
UI D-2

F5
UI D-2

F6 + PPI D-1

UI D-1

Site 4

Site 5

Site 6

","2 2 0 2 g u A 5 2 ] R C . s c [ 1 v 0 7 3 2 1 . 8 0 2 2 : v i X r a COOKIEGRAPH: Measuring and Countering First-Party Tracking Cookies Shaoor Munir UC Davis smunir@ucdavis.edu Steven Englehardt Independent Researcher se@senglehardt.com Sandra Siby EPFL sandra.siby@epﬂ.ch Umar Iqbal University of Washington umar@cs.washington.edu Zubair Shaﬁq UC Davis zubair@ucdavis.edu Carmela Troncoso EPFL carmela.troncoso@epﬂ.ch Abstract—Recent privacy protections by browser vendors aim to limit the abuse of third-party cookies for cross-site tracking. While these countermeasures against third-party cookies are widely welcome, there are concerns that they will result in advertisers and trackers abusing ﬁrst-party cookies instead. We provide the ﬁrst empirical evidence of how ﬁrst-party cookies are abused by advertisers and trackers by conducting a differential measurement study on 10K websites with third- party cookies allowed and blocked. We ﬁnd that advertisers and trackers implement cross-site tracking despite third-party cookie blocking by storing identiﬁers, based on probabilistic and deterministic attributes, in ﬁrst-party cookies. As opposed to third-party cookies, outright ﬁrst-party cookie blocking is not practical because it would result in major breakage of legitimate website functionality. We propose COOKIEGRAPH, a machine learning approach that can accurately and robustly detect ﬁrst-party tracking cookies. COOKIEGRAPH detects ﬁrst-party tracking cook- ies with 91.06% accuracy, outperforming the state-of-the-art CookieBlock approach by 10.28%. We show that COOKIE- GRAPH is fully robust against cookie name manipulation while CookieBlock’s accuracy drops by 15.68%. We also show that COOKIEGRAPH does not cause any major breakage while CookieBlock causes major breakage on 8% of the websites with SSO logins. Our deployment of COOKIEGRAPH shows that ﬁrst-party tracking cookies are used on 93.43% of the 10K websites. We also ﬁnd that the most prevalent ﬁrst-party tracking cookies are set by major advertising entities such as Google as well as many specialized entities such as Criteo. 1. Introduction Browser vendors and trackers are engaged in an arms race. As soon as browser vendors deploy privacy protec- tions, e.g., third-party cookie blocking [85], [30], trackers quickly adapt to evade them, e.g., CNAME cloaking [50], bounce tracking [94] etc. In response, browser vendors have developed targeted countermeasures against such evasions [92], [81]. To gain advantage over browser vendors, trackers have started exploiting browser features that are typically used for functional purposes, and thus cannot be trivially blocked. i.e., The abuse of JavaScript APIs to build identiﬁers, browser ﬁngerprinting [39], and the abuse of ﬁrst-party context to store tracking cookies [75] stand out as two prominent techniques. Browser vendors have largely strug- gled against these tracking techniques because preventing them requires compromising functionality [58], [85]. While these new tracking techniques are difﬁcult to counter, they do not offer the same ﬂexibility as third-party cookies for cross-site tracking. Browser ﬁngerprints enable cross-site tracking but are not stable over time [83]. On the other hand, ﬁrst-party cookies are stable but not linkable across different sites. When combined, however, browser ﬁngerprints and ﬁrst-party cookies complement each oth- ers’ shortcomings and enable reliable cross-site tracking. Speciﬁcally, trackers are able to leverage non-deterministic ﬁngerprints in the ﬁrst-party context to set deterministic ﬁrst-party tracking cookies [57]. Prior literature has shown how ﬁrst-party cookies set by third party scripts are exﬁltrated to tracking endpoints [75], [44], [56] and how trackers use browser ﬁngerprinting to respawn ﬁrst-party cookies [57]. While prior work has demonstrated that ﬁrst-party cookies are indeed abused by advertisers and trackers, no countermeasure has been pro- posed to speciﬁcally block ﬁrst-party tracking cookies. In this paper, we investigate how ﬁrst-party cookies are abused for cross-site tracking and use our ﬁndings to develop a machine learning based countermeasure, COOKIEGRAPH, to block ﬁrst-party tracking cookies. To this end, we ﬁrst perform a differential measure- ment study where we compare the ﬁrst- and third-party cookie usage from two crawls of 10K websites when third- party cookies are enabled and blocked. We show that third- party-cookie blocking does not signiﬁcantly impact sharing of identiﬁers to tracking endpoints because trackers use (or reactively shift to) ﬁrst-party cookies when third-party cookies are blocked. Speciﬁcally, we ﬁnd entities such as Criteo, Lotame, and ID5 that show an increased presence and reactively move to ﬁrst-party cookies when third-party cookies are blocked. Our further analysis reveals that they store identiﬁers in ﬁrst-party cookies, based on probabilistic and deterministic attributes, which can be then used for cross-site tracking. Unlike third-party cookies, blocking all ﬁrst-party cook- ies is not practical because it would lead to major breakage of legitimate website functionality. Privacy-enhancing con- tent blocking tools, which use crowdsourced ﬁlter lists or machine learning [65], [78], [77], could be an alternative since blocking requests would also block all cookies set by the requests (or the requested scripts). However, as we also ﬁnd in our evaluation, blocking requests would also lead to breakage since it is likely that many of the blocked cookies are needed for legitimate website functionality. Re- searchers have recently started to develop approaches to detect and block tracking cookies (both ﬁrst and third-party) [63], [41]. However, these approaches rely on content-based features such as cookie names and values, which can lead to high number of false positives (and consequently higher major website breakage) while also being susceptible to evasion [77]. Keeping these limitations in mind, we design and im- plement COOKIEGRAPH, a machine learning approach to detect ﬁrst-party tracking cookies. Instead of using content- based features, COOKIEGRAPH captures fundamental track- ing behaviors exhibited by ﬁrst-party cookies that we discover in our differential measurement study. COOKIE- GRAPH is able to detect ﬁrst-party tracking cookies with 91.06% accuracy, outperforming the state-of-the-art Cook- ieBlock [41] approach by 10.28%. We also show that COOKIEGRAPH does not cause any major website breakage, where CookieBlock causes major breakage on 8% of the websites with SSO logins. Moreover, COOKIEGRAPH is robust to evasion through cookie name manipulation while CookieBlock’s accuracy degrades by 15.68%. Our deployment of COOKIEGRAPH on 10K websites shows that ﬁrst-party tracking cookies are used on 93.43% of the websites. While ﬁrst-party tracking cookies are set by third-party scripts served from a total of 1,588 unique domains, we show that the most prevalent ﬁrst-party tracking cookies are set by major advertising entities such as Google, as well as many specialized entities such as Criteo. We also show that 41.45% of all ﬁrst-party tracking cookies are set by scripts served by domains involved in ﬁngerprinting. In summary, our key contributions are as follows: 1) We conduct a large-scale differential measure- ment study to understand the effectiveness of third- party cookie blocking and whether ﬁrst-party cook- ies are used in lieu of third-party cookies. 2) We design and implement COOKIEGRAPH, a ma- chine learning based countermeasure to detect and block ﬁrst-party tracking cookies. COOKIE- GRAPH captures fundamental tracking behaviors of ﬁrst-party cookies that we discovered in our mea- surement study, and outperforms the state-of-the- art in terms of accuracy, robustness, and breakage minimization. 3) We deploy COOKIEGRAPH on 10K websites sampled from the Alexa’s top-100K list to measure the prevalence of ﬁrst-party tracking cookies. We detect a total of 1,588 distinct domains that set ﬁrst- party tracking cookies, including major advertising entities such as Google, and show that 45 (2.83%) of these domains are known ﬁngerprinters which set 41.45% of all ﬁrst-party tracking cookies. Paper Organization: The rest of this paper is organized as follows: Section 2 provides an overview of the recent developments in third-party and ﬁrst-party cookie based tracking and countermeasures. Section 3 evaluates effec- tiveness of third-party cookie blocking in reducing tracking activity and measures the extent of ﬁrst-party cookie abuse by advertisers and trackers. Section 4 describes the design and evaluation of COOKIEGRAPH. We discuss limitations of COOKIEGRAPH in Section 5 and conclude in Section 6. 2. Background & Related Work 2.1. Adoption of third-party cookies for tracking While cookies were originally designed to recognize returning users, e.g., to maintain virtual shopping carts [70], they were quickly adopted by third-parties to track users across websites, e.g., to serve targeted ads [27]. Early stan- dardization efforts mostly focused on limiting unintended cookie sharing across domains [47] and, despite well-known privacy concerns [21], largely ignored the intentional misuse of cookies by third-parties for cross-site tracking. Over the years, the use of third-party cookies for cross-site tracking has become increasingly prevalent [74], [43], [75], [48]. Prior research has found that the vast majority of third- party cookies are set by advertising and tracking services [48] and that the third-party cookies outnumber ﬁrst-party cookies by a factor of two [43] and up to four when they contain identiﬁers [75]. 2.2. Countermeasures against third-party cookies 2.2.1. Safari. Since its inception in 2003, Safari has blocked third-party cookies from domains that have not been visited by the user as full-ﬂedged websites [85]. To strengthen its cookie blocking, Safari introduced Intelligent Tracking Prevention (ITP) in 2017. ITP used machine learning to automatically detect third-party trackers and revoked storage access from classiﬁed domains if users did not interact with them on a daily basis (i.e., a 24 hour period) [86]. Since 2017, ITP went through several iterations, i.e., ITP 1.1 [87], ITP 2.0 [88], ITP 2.1 [89], ITP 2.2 [90] and ITP 2.3 [91], eventually leading to full third-party cookie blocking [93]. 2.2.2. Firefox. Firefox experimented with third-party cookie blocking in 2013 [52], [53], but did not ship default- on third-party cookie blocking until the release of Enhanced Tracking Protection (ETP) in 2018 [71]. ETP blocks third- party cookies based on a blocklist of trackers provided by 2 Disconnect [26]. As of 2022, Firefox has launched Total Cookie Protection (TPC) which partitions all third-party cookie access [6]. Partitioning ensures that cookies set by a third-party on one site are distinct from those set by the same third-party on other websites, eliminating the third- party’s ability to track users across those websites. 2.2.3. Internet Explorer and Microsoft Edge. Amongst the mainstream browsers that have deployed countermea- third-party cookies, Internet Explorer (IE) sures against and Microsoft Edge have the most permissive protections. IE blocked third-party cookies from domains that did not specify their cookie usage policy with P3P response header [22]. However, website owners often misrepresented their cookie usage polices, which rendered P3P ineffective [69]. Since 2019, Microsoft Edge blocks access to cookies and storage in a third-party context from some trackers, based on Disconnect’s tracking protection list [82], [35], [26]. 2.2.4. Chrome. Google Chrome is the only mainstream browser that does not restrict third-party cookies in any way in its default mode. In 2020, Google announced plans to phase out third-party cookies in Chrome by 2022 [76]. However, the plan has been postponed several times and the latest timeline suggests the phasing out of cookies by late 2024 [59]. Google has also announced plans to implement privacy-preserving versions of advertising use cases that cur- rently depend on third-party cookies—including behavioral ad targeting and ad attribution/measurement [59]. 2.3. Adoption of ﬁrst-party cookies for tracking While third-party cookies are widely considered as the main mechanism for cross-site tracking, trackers have also relied on ﬁrst-party cookies for tracking. As early as 2012, Roesner et al. [74], noted that third-party tracking scripts, embedded on the main webpage (i.e., in ﬁrst-party context), set ﬁrst-party cookies. More recently, in 2020 Fouad et al. [56] found that trackers sync ﬁrst-party cookies to several third-parties on as many as 67.96% of the websites. In 2021, Chen et al. [44] found that more than 90% of the websites contain at least one ﬁrst-party cookie that is set by a third-party script. Similar to Fouad et al., they also found that at least one ﬁrst-party cookie is exﬁltrated to a third-party domain on more than half of the tested web- sites, raising concerns that these cookies might be used for tracking. These concerns were also echoed by Sanchez et al. [75], who uncovered several instances where different third-parties interacted with the same ﬁrst-party cookies. They conclude, through a large scale measurement study of top websites and a number of case studies, that even after blocking third-party cookies, users are still at risk of tracking through ﬁrst-party cookies. While prior studies have identiﬁed the use of ﬁrst-party cookies by trackers, they were not solely focused on study- ing ﬁrst-party tracking cookies. In fact, their measurement infrastructure was not designed to capture tracking through they did not conﬁgure ﬁrst-party cookies. For example, their browsers to block third-party cookies, which might not instigate trackers to use ﬁrst-party cookies for tracking. Techniques used to set ﬁrst-party cookies. It is non- trivial to generate ﬁrst-party identiﬁers that are accessible across websites. Prior research has found that trackers often leverage browser ﬁngerprinting to generate ﬁrst-party track- ing cookies [57]. Browser ﬁngerprinting provides unique identiﬁers that are accessible across websites but drift over time [67]. However, identiﬁers generated through browser ﬁngerprinting can be stored in cookies that persist even after ﬁngerprints change. In addition to browser ﬁngerprinting, several advertising and tracking services, such as Google Ad Manager [79], [1] and ID5 [10], specify in their docu- mentation that they also use publisher provided identiﬁers (PPIDs), such as email addresses, to set ﬁrst-party cookies. CNAME cloaking also allows advertisers or trackers to use ﬁrst-party cookies. In this paper, we do not focus on CNAME cloaking because ﬁrst-party cookie leaks due to CNAME cloaking is already extensively studied by prior work [49], [50]. 2.4. Countermeasures against ﬁrst-party cookies 2.4.1. Deployed countermeasures. Safari is the only main- stream browser that has deployed protections against ﬁrst- party tracking cookies. Safari’s ITP expires ﬁrst-party cook- ies and storage set by scripts in 7 days if users do not interact with the website [85]. For ﬁrst-party cookies, this limit is lowered to 24 hours if ITP detects link decoration being used for tracking [85]. However, ﬁrst-party cookie tracking does not require link decoration to be effective. In cases where link decoration isn’t used, trackers can still track users within the 7-day window and beyond if users interact with the website within the 7-day window. 2.4.2. Countermeasures proposed by prior research. Recently, researchers have proposed machine learning based approaches to detect ﬁrst-party and third-party tracking cookies. Hu et al. [63] developed a machine learning based approach that uses sub-strings in cookie names (e.g., track, GDPR) as features to detect ﬁrst-party and third-party track- ing cookies. Bollinger et al. [41] also developed a machine learning approach, CookieBlock, that uses several cookie attributes such as the domain name of the setter, cookie name, path, value, expiration, etc, as features to detect ﬁrst-party and third-party tracking cookies. However, rely- ing on hard-coded content features make these approaches susceptible to adversarial evasions (as we show later in Section 4.4.3). Moreover, these approaches mainly rely on self-disclosed cookie labels as ground truth which are known to be unreliable [84]. 2.4.3. Request blocking approaches. Request blocking through browser extensions, such as Adblock Plus [23], and machine learning based tracker detection approaches proposed by prior research, e.g., [77], can potentially block ﬁrst-party tracking cookies. However, request blocking is inherently prone to cause breakage (as we later show in 3 Section 4.4.3) because it blocks access to content or cookies that might be essential for website functionality. Focus of this paper. In conclusion, prior work has only incidentally measured the usage of ﬁrst-party tracking cook- ies and existing approaches to detect ﬁrst-party cookies are lacking. In this paper, we ﬁll this void by conducting a large- scale study to measure the prevalence of ﬁrst-party tracking cookies and develop an accurate and robust machine learn- ing approach, called COOKIEGRAPH, that is purpose-built to detect ﬁrst-party cookies. 3. Measurements In this section, we present a measurement study to understand the usage of ﬁrst-party cookies by advertising and tracking services (ATS) when third-party cookies are blocked. To this end, we conduct two web crawls (with and without third-party cookies) and analyze the differences in the tracking activity (i.e., sharing of identiﬁers to known adverting and tracking services) observed across these two crawls to understand the effectiveness of third-party cookie blocking and whether ﬁrst-party cookies are used in lieu of third-party cookies. 3.1. Data Collection and Methodology Data collection. We use OpenWPM [54] to crawl sites from Alexa’s top-100K list. To ensure that our crawls contain representative sites of different popularity, we crawl the top 1K sites, and randomly sample another 9K sites from the long tail of sites ranked 1K-100K. To ensure intra-page diversity (landing and internal pages [38]) we perform an interactive crawl. Speciﬁcally, for each site, we crawl its landing page, and then sample 5-10 anchor tags in this landing page uniformly at random, and crawl them to get a sample of internal pages. We conduct two crawls: one with third-party cookies enabled (3P-Allowed), and one with third-party cookies blocked (3P-Blocked). We conduct these crawls simultaneously to minimize temporal variations in sites across the two crawls1. Deﬁnition of ﬁrst- and third-party cookies. Cookies are set in the browser in two ways. They can either be set by the Set-Cookie HTTP response header or by using docu- ment.cookie() in JavaScript. Cookies are further classiﬁed as ﬁrst- or third-party. Cookies set via response header from the same (or different) domain as the ﬁrst-party are ﬁrst-party (or third-party) cookies. Classiﬁcation of cookies set by a script depends on whether the script is embedded in a ﬁrst- or third-party execution context. The cookies set by third- party scripts running in a ﬁrst-party context are ﬁrst-party cookies. The cookies set by third-party scripts running in a third-party context (e.g., third-party iframes) are third-party cookies. Labeling tracking activity. We use EasyList [28] and EasyPrivacy [29] to label requests as tracking (ATS) or not Figure 1. Average number of requests per site in 3P-Allowed and 3P-Blocked conﬁgurations: ) Non-ATS requests ( ) ATS requests without identiﬁers ( ) ATS requests with identiﬁers ( tracking (Non-ATS).2 Since the basic premise of tracking is to identify users, we are particularly interested in sharing of identiﬁers in these tracking requests. To this end, in line with prior work [66], [55], we deﬁne identiﬁers as a string that is longer than 8 characters and matches the regex [a − zA − Z0 − 9 = −]. Using this deﬁnition, we look for identiﬁers in URL query parameters [73] and cookie values [75], [51], [44], [43]. 3.2. Tracking after Blocking Third-Party Cookies We ﬁrst study whether blocking third-party cookies ef- fectively eliminates ATS requests. To this end, we compare the number of requests with and without third-party cookies. Figure 1 plots the number of requests with and without third-party cookies. It can be seen from the Figure 1 that when third-party cookies are blocked, there is only a modest reduction in the overall number of ATS requests, with just an 18.4% reduction in the number of ATS requests containing identiﬁers. This is surprising because cookie syncing, which is widely used for cross-site tracking [56], [72], entails sharing third-party identiﬁer cookies in query parameters [51], [44], [43]. With third-party cookies blocked, cookie syncing between third-parties cannot occur and we would expect to see a larger drop in identiﬁers shared in ATS requests. We address this surprising observation in Section 3.3. Next, we analyze whether third-party cookie blocking disparately impacts different ATS domains (eTLD+1). Fig- ure 2 plots the percentage of sites with at least one ATS request with identiﬁers for the top-10 most prevalent ATS domains across both crawls. We note that six of the top-10 ATS domains, all owned by Google, show only a negligible 1. The success rate of our crawl is 83.98%. Form the 10K sites visited, 8,398 were successfully crawled. 2. We label a request as tracking (ATS) if its URL matches the rules in either one of the lists. Otherwise, we label it as not tracking (Non-ATS). 4 s t s e u q e R f o r e b m u N e g a r e v A 300 250 200 150 100 50 0 18.4% Decrease 8.18% Decrease 1.59% Decrease 3P Cookies Enabled 3P Cookies Blocked Figure 2. Presence of top-10 tracking domains. The plot shows percentage of sites where at least one request is sent to a tracking domain. We include criteo.net due to its peculiar increased presence after blocking third- party cookies. ( ( ) third-party cookies allowed ) third-party cookies blocked Figure 4. Comparison of percentage of sites on which ﬁrst party and third- party identiﬁer cookies are set by ATS domains. ( ( ( ) ﬁrst-party cookies set when third-party cookies are allowed ) ﬁrst-party cookies set when third-party cookies are blocked ) third-party cookies set when third-party cookies are allowed 3.3. Tracking through First-Party Cookies Figure 1 showed that 82.6% of ATS requests contain identiﬁers even after third-party cookies are blocked. It is clear that the identiﬁers in these ATS requests are then likely originating from some storage mechanism other than third- party cookies. Since recent prior work has shown that ATSes are increasingly using ﬁrst-party cookies [75], [44], we next investigate whether ﬁrst-party cookies are being used in lieu of third-party cookies. We ﬁrst compare the average number of ﬁrst-party cook- ies in 3P-Allowed and 3P-Blocked crawls in Figure 3. We observe only a minor difference in the average number of ﬁrst-party cookies set by ATS scripts (or Non-ATS for that matter).3 However, it is noteworthy that 81% of the ﬁrst-party cookies are set by ATS scripts and further 82% of them are identiﬁer cookies. This demonstrates that an overwhelming number of ﬁrst-party cookies are in fact set by ATSes. Next, we compare the setting of ﬁrst- and third-party identiﬁer cookies by ATS domains (eTLD+1 of the setting script URL) to understand if ﬁrst-party cookie usage is equally prevalent across different ATSes. Figure 4 plots the percentage of sites where at least one ﬁrst-party and/or third-party identiﬁer cookie is set by top-10 ATS domains (with Criteo divided into criteo.com and criteo.net). First, we observe that for the six Google-owned ATS domains, which showed negligible difference in requests containing identi- ﬁers after blocking third-party cookies, there is also little to no change in use of ﬁrst-party identiﬁer cookies across 3. We label scripts as ATS or Non-ATS based on their src URL as in Section 3.1. Figure 3. Breakdown of average number of ﬁrst-party cookies per site set before and after blocking third-party cookies. ( ( ( ) Cookies set by non-tracking sources ) Non-identiﬁer cookies set by tracking sources ) Identiﬁer cookies set by tracking sources. reduction in the number ATS requests with identiﬁers when third-party cookies are blocked. In contrast, three other ATS domains, owned by Pubmatic, Rubicon, and OpenX, show an almost 50% reduction. Criteo exhibits interesting behav- ior, where the requests sent to Criteo are divided between two domains: criteo.com and criteo.net. While criteo.com shows negligible change across two crawls, criteo.net in- creases by about one-third. We attempt to better understand the reason behind this disparate impact across different ATS domains. 5 70 60 50 40 30 20 10 s e t i S f o % 0 google.co m pub m atic.co m doubleclick.net googlesyndication.co m rubiconproject.co m googletag m anager.co m google-analytics.co m googleadservices.co m openx.net criteo.co m criteo.net s e i k o o C P 1 f o r e b m u N e g a r e v A 50 40 30 20 10 0 0.44% Increase 1.89% Decrease 1.15% Increase 3P Cookies Enabled 3P Cookies Blocked s e t i S f o % 70 60 50 40 30 20 10 0 google.co m pub m atic.co m doubleclick.net googlesyndication.co m rubiconproject.co m googletag m anager.co m google-analytics.co m googleadservices.co m openx.net criteo.co m criteo.net Table 1. COOKIES SHOWING THE HIGHEST RATIO OF NEW APPEARANCES AFTER BLOCKING THIRD-PARTY COOKIES. Cookie Name cto bundle id5id pbjs-uniﬁedid pbjs-id5id s sq stripe mid stripe sid panoramaId cc id Script Domain New Appearances Total Appearances Ratio criteo.com pubmatic.com pubmatic.com pubmatic.com adobedtm.com stripe.com stripe.com crwdcntrl.net crwdcntrl.net 132 25 17 24 17 13 13 24 24 632 139 103 164 122 95 95 184 196 0.21 0.18 0.16 0.15 0.14 0.14 0.14 0.13 0.12 are blocked. We can quantify this shift as a ratio be- tween the number sites where ﬁrst-party cookie is present in 3P-Allowed crawl and number of new sites where ﬁrst-party cookie is present in 3P-Blocked crawl. Ta- ble 1 shows top-10 identiﬁer cookies based on this ra- is dominated by three well- tio. We note that known ad-tech organizations: Criteo (cto_bundle), ID5 (id5id, pbjs-unifiedid, pbjs-id5id), and Lotame ((panoramaID, _cc_id). We further investigate the be- havior of these cookies using their publicly available docu- mentation [14], [13], [9], [32], [4] in Appendix A. the list 3.4. Cross-site Tracking via First-party Cookies Our analysis of Criteo, Lotame, and ID5 in Appendix A reveals a common approach to using ﬁrst-party cookies for cross-site tracking. They build an “identity graph” to Figure 6. The ﬁgure shows the ﬂow of information and identiﬁers through an identity Graph for cross-site attribution. Initially, the user visits sites 1, 2, and 3. Trackers on sites 1, 2, and 3 collect and send ﬁngerprints F 1, F 2, and F 3 to their identity graph. The identity graph returns a U ID−1 for all the site visits, using a probabilistic matching of ﬁngerprints F 1, F 2, and F 3 sent on each respective website. A publisher provided ID, P P ID − 1, is also sent alongside F 3 when visiting site 3. When the user visits site 4, it sends ﬁngerprint F 4. Because the ﬁngerprint F 4 is different from F 1, F 2, and F 3, the identity graph cannot create a probabilistic match with the other sites. On site 4, the website obtains and sends a publisher provided ID which matches P P ID − 1 provided on site 3. As a result, the identity graph matches and returns the existing user’s U ID − 1 for site 4 using deterministic matching. All of these IDs are stored in ﬁrst-party cookies on the user’s device. 6 Figure 5. Percentage of sites ﬁrst-party cookies show up on before and after blocking ﬁrst-party cookies. ( ( ) third-party cookies are allowed ) third-party cookies are blocked. both crawls. These domains do not set a large number of third-party identiﬁer cookies, which likely explains why they were not impacted by third-party cookie blocking. Second, the other set of ATS domains (i.e., Pubmatic, Rubicon, and OpenX) disproportionately use more third-party identiﬁer cookies than ﬁrst-party identiﬁer cookies. This observation explains the drastic drop in number of requests containing identiﬁers to these other ATS domains after blocking third- party cookies in Figure 2. to set cookies: Finally, we further investigate Criteo which showed a peculiar behavior in Figure 2. Recall that Criteo uses criteo.com and criteo.net the ﬁrst-party identiﬁer cookies set by the former showed an increase after blocking third-party cookies while the latter does not change. In addition to this, criteo.com is also used to set third-party identiﬁer cookies, while criteo.net sets only ﬁrst- party identiﬁer cookies. Both of these domains set the same cto_bundle cookie. To compare cto_bundle with identiﬁer cookies set by other ATSes, we plot the percentage of sites where a cookie with the same name appears. Figure 5 plots the prevalence of ﬁrst-party cookies for top-20 cookies. We note that while other cookies witness a slight drop in their prevalence after blocking third-party cookies, it does not hold true for cto_bundle. In fact, cto_bundle’s prevalence increased after blocking third- party cookies, in accordance with the unexpected increase in total number of ﬁrst-party identiﬁer cookies set by scripts belonging to criteo.com. The aforementioned increased use of ﬁrst-party cookies represents an interesting scenario where trackers are reac- tively shifting to ﬁrst-party cookies if third-party cookies 80 60 40 20 s e t i S f o % 0 ga gid gads fbp uetvid gclau uetsid bundle hjT L D Test P H PS E SSID cto cf utm a b m utm c uid d y m y m utm b utm z utm v O ptanonC onsent consentdata userid pbjs Site 1 Site 2 Site 3 Site 4 F1 UI D-1 F2 UI D-1 F3+PPI D-1 UI D-1 F4+PPI D-1 UI D-1 F1 F2 F3 + PPI D-1 F4 + PPI D-1 identiﬁers to a particular user using ﬁrst- link different party information collected from different sites. A node can represent a user (or device such as web browser) based on different attributes and edges between the nodes are formed based on “deterministic” or “probabilistic” match- ing between attributes of a pair of nodes. For cross-site tracking, they need to establish edges between different nodes (that actually represent the same user/device) of the identity graph. Note that trackers cannot simply use third- party identiﬁer cookies if they are blocked. Trackers typically use two types of information to build their identity graph. They gather information provided by publishers including both deterministic attributes (e.g., email, phone, username, or any other publisher-provided ID [PPID] that can be directly used for identiﬁcation) and probabilistic attributes (e.g., zip code, city, age, etc. that can be used together for non-deterministic identiﬁcation). They themselves typically also gather probabilistic information such as IP address and ﬁngerprinting attributes such as browser and operating system information (e.g., name and speciﬁc version), device properties (e.g., display resolution, screen orientation), etc. To link different nodes in their identity graph (e.g., to link the same user across different sites or to link different devices of the same user, an example showing how different user devices are linked is shown in Appendix B), they use probabilistic or deterministic matching as shown in more detail in Figure 6. In probabilistic matching, they measure the similarity between probabilistic attributes and determine a match if the similarity is reasonably high (represented as gray edges in Figure 6). In deterministic matching, they can exactly match deterministic attributes (represented as black edges in Figure 6). Once these links are established, trackers store an identiﬁer in a ﬁrst-party cookie which uniquely represents that user across different sites (or devices). 3.5. Takeaway Our differential measurement study reveals that blocking third-party cookies is insufﬁcient in preventing tracking; as there is a minimal decrease in the number of ATS requests sharing identiﬁers when third-party cookies are blocked. However, the impact of third-party cookie blocking is not uniform across different ATSes– some ATS domains such as google-analytics.com and doubleclick.net show no change in their tracking requests, while others such as pubmatic.com and rubiconproject.com show a decrease, and yet others such as criteo.net show an increase. We ﬁnd that ﬁrst-party cookies are predominantly used by ATSes in lieu of third- party cookies to perform tracking. Some ATS domains, such as those owned by Google, only use ﬁrst-party cookies and are hence not impacted by third-party cookie blocking. Some other ATS domains that do use third-party cookies reactively shift to using ﬁrst-party cookies when third-party cookies are blocked. We ﬁnd that these ATSes rely on a combination of deterministic and probabilistic attributes to build an identity graph. Then, they use ﬁrst-party cookies to store these identiﬁers that are used for cross-site tracking. Next, we present our approach to accurately and robustly detect these ﬁrst-party ATS cookies. 4. COOKIEGRAPH: Detecting Tracking Cookies First-Party In this section, we describe COOKIEGRAPH, a graph- based machine learning approach to detect ﬁrst-party ATS cookies. COOKIEGRAPH creates a graph representation of a webpage’s execution based on HTML, network, JavaScript, and storage information collected by an instru- mented browser, in which ﬁrst-party cookies are represented as storage nodes. COOKIEGRAPH extracts distinguishing features of these cookies and uses a random forest classiﬁer to detect ﬁrst-party ATS cookies. Figure 7 provides an overview of COOKIEGRAPH’s pipeline. 4.1. Design and Implementation Browser instrumentation. COOKIEGRAPH relies on our extended version of OpenWPM [54] to capture webpage ex- ecution information across HTML, network, JavaScript, and the storage4 layers of the web stack. Speciﬁcally, COOKIE- GRAPH captures HTML elements created by scripts, net- work requests sent by HTML elements (as they are parsed) and scripts, responses received by the browser, exﬁltra- tion/inﬁltration of identiﬁers in network requests/responses, and read/write operations on browser’s storage mechanisms. Graph construction. The nodes in COOKIEGRAPH’s graph represent HTML elements, network requests, scripts, and storage elements. When localStorage and ﬁrst-party cookie nodes share the exact same name, COOKIEGRAPH considers them as one storage node. The edges represent a wide range of interactions among different types of nodes e.g., scripts sending HTTP requests, scripts setting cookies etc. In addition to interactions considered by prior work [77], COOKIEGRAPH incorporates edges that capture the tracking behavior of ﬁrst-party cookies. Informed by our ﬁndings in Section 3: cookies are typically set with the values inﬁltrated with HTTP responses and are exﬁltrated via URL parame- ters and request headers or bodies; COOKIEGRAPH captures inﬁltrations and exﬁltrations by linking the script-read/write cookies in the ﬁrst-party execution context to the requests of reader/writer script that contains those cookie values. In addition to plain text cookie values, COOKIEGRAPH also monitors Base64-, MD5-, SHA-1-, and SHA-256- encoded cookie values in URLs, headers, request and response bod- ies. As in our measurement study, because of the focus on identiﬁers, COOKIEGRAPH only captures cookie values that are at least 8 characters long. We illustrate the difference between COOKIEGRAPH’s graph representation and prior work, i.e., WebGraph [77] 4. Our measurements in Section 3 found a signiﬁcant use of localStorage in addition to cookies. Thus, we use the term “storage” to refer to both cookies and localStorage. In most cases, the description for cookies is also applicable to localStorage and vice versa. 7 Figure 7. Overview of COOKIEGRAPH pipeline: (1) Webpage crawl using an instrumented browser; (2) Construction of a graph representation to represent the instrumented webpage execution information; (3) Feature extraction for graph nodes that represent ﬁrst-party cookies; and (4) Classiﬁer training to detect ﬁrst-party ATS cookies. (a) Graph representation of Code 1 in WebGraph (b) Graph representation of Code 1 in COOKIEGRAPH Figure 8. Graph representation of Code 1 in WebGraph and COOKIEGRAPH. represents storage nodes. Node numbers correspond to the lines in Code 1. In Figure 8(a), dashed (- - -) and dotted (. . .) lines represent the additional edges that are captured by COOKIEGRAPH and missed by WebGraph. The grey dashed line shows different representations of the same event by both systems. represents script nodes, and represents network nodes, using an example script that involves ﬁrst-party ATS cook- ies. Code 1 shows a third-party script from tracker1.com executing in a ﬁrst party context on a webpage. The script ﬁrst reads infoCookie, which stores tracking information such as the publisher ID and a user signature. Then, it sends the content of the cookie to an endpoint via an HTTP POST request. The endpoint returns a user ID (UID) in the response body, which is stored in both a ﬁrst-party cookie and localStorage named IDStore. At a later point, the script exﬁltrates UID to two other tracking endpoints: to tracker2.com via a URL parameter and to tracker3.com via an HTTP header. The HTTP requests and responses that result from Code 1 are listed in Listing 1. Figure 8 shows the differences between the graph rep- resentations of this script created by prior work, WebGraph (left), and COOKIEGRAPH (right). WebGraph does not cap- ture the inﬁltration of the UID to the cookie from the response body and also does not consider inﬁltration and ex- ﬁltration via localStorage. In contrast, the dotted and dashed lines in Figure 8(b) show that COOKIEGRAPH captures both the inﬁltration and the exﬁltration in subsequent network requests. Moreover, while WebGraph captures exﬁltrations via URL parameters (shown by grey dashed lines) via edges from the setting script to the endpoint, COOKIEGRAPH is able to precisely link this exﬁltration to the ﬁrst-party cookie via an edge from the cookie node to the endpoint. Feature extraction. We use COOKIEGRAPH’s representa- tion to extract structural and information ﬂow features. Structural features represent relationships between nodes in the graph, such as ancestry information and connectivity. These features capture the relationships between the ﬁrst- party cookie nodes and scripts on the page. For example, how many scripts interacted with a cookie or whether a script that interacted with a cookie also interacted with other cookies. Flow features represent ﬁrst-party ATS cookie behavior. We extract three types of ﬂow features. First, we count the number of times a cookie was read or written. Second, the number of times a cookie was inﬁltrated we count or exﬁltrated via the methods explained in the previous section. Third, we calculate some features with respect to the setter of the cookie. Concretely, whether the setter’s domain also acted as an end-point for other cookie exﬁltrations, and whether the setter’s domain was involved in redirect chains (since redirects are commonly used in tracking). The intuition behind the third category of features is that domains 8 Webpage cr aw l u si n g Open W PM i n st r u m en t ed Fi r ef ox br ow ser (t h i r d-par t y cook i es bl ock ed) Cook i e f eat u r e ex t r act i on an d l abel i n g u si n g f i l t er l i st s an d Cook i epedi a Pr ocess cr aw l dat a t o bu i l d a gr aph r epr esen t at i on of page ex ecu t i on Fi r st -par t y cook i e cl assf i i cat i on ATS Non -ATS Script from tracker1.com Storage accesses 2 2 4 Cookie 9, 13 Cookie 10 Local Storage 14 18 Request to tracker1.com/sync Request to tracker2.com Request to tracker3.com Script from tracker1.com Storage accesses 2 2 4 Cookie 9, 13 Cookie 10 Local Storage ID exfiltrations to other trackers ID infiltration in response body 14 18 Request to tracker1.com/sync Request to tracker2.com Request to tracker3.com Table 2. COOKIEGRAPH FEATURES COMPARISON WITH WEBGRAPH. INDICATES THAT A FEATURE IS PRESENT. INDICATES THAT FEATURE WAS EXTENDED IN COOKIEGRAPH. COOKIEGRAPH CALCULATES GRAPH SIZE, DEGREE AND CENTRALITY FEATURES USING BOTH NORMAL AND SHARED INFORMATION EDGES. THE FORMER COMES UNDER STRUCTURAL FEATURES WHILE THE LATTER COMES UNDER FLOW FEATURES. Feature Type COOKIEGRAPH WebGraph Graph size (# of nodes, # of edges, and nodes/edge ratio) Degree (in, out, in+out, and average degree connectivity) Centrality (closeness centrality, eccentricity) Ascendant’s attributes Descendant of a script Ascendant’s script properties Parent is an eval script Local storage access (# of sets, # of gets) Cookie access (# of sets, # of gets) Storage access on local storage with same name (# of sets, # of gets) Requests (sent, received) Redirects (sent, received, depth in chain) Common access to the same storage node Cookie exﬁltration Cookie inﬁltration Cookie Setter (# of exﬁltration, # redirects) Graph size (# of nodes, # of edges, and nodes/edge ratio) Degree (in, out, in+out, and average degree connectivity) Centrality (closeness centrality, eccentricity) Structure Structure Structure Structure Structure Structure Structure Flow Flow Flow Flow Flow Flow Flow Flow Flow Flow Flow Flow 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 <html> --------------------------------------------------- <script src=’tracker1.com/track.js’> ... infoCookie = document.cookie; var idReq = new XMLHTTPRequest(); idReq.open(""POST"", ""tracker1.com/sync"", true) idReq.send(infoCookie) var response = newReq.response document.cookie = ""IDStore="" + response; localStorage.setItem(IDStore, response); ... var exfilReq1 = new XMLHTTPRequest(); idCookie = document.cookie exfilReq1.open(""GET"", ""tracker2.com? user_id="" + idCookie); ... var exfilReq2 = new XMLHTTPRequest(); exfilReq2.setRequestHeader(""ID-header"", idCookie); exfilReq2.open(""GET"", ""tracker3.com""); ... Request 1 URL: tracker1.com/sync POST data: publisherID=704; signature=xyz Response 1 Status: 200 Content: UID=abcd --------------------------------------------------- Request 2 URL: tracker2.com?user_id=abcd Response 2 Status: 200 --------------------------------------------------- Request 3 Header: ID-header = abcd URL: tracker3.com Response 3 Status: 200 </script> ... </html> Code 1. Script from third party tracker1.com executing in a ﬁrst party context. The script obtains a UID from a sync point, stores it, and exﬁltrates it to tracker2.com and tracker3.com. involved in setting ﬁrst-party ATS cookies are also involved in sharing information with other ATSes. Table 2 shows the differences in features between COOKIEGRAPH and WebGraph. COOKIEGRAPH adds im- proved cookie exﬁltration features and also introduces a new complete new set of inﬁltration and setter features. Unlike WebGraph, COOKIEGRAPH also considers cases where a localStorage shares the same name as a cookie (a behavior Listing 1. HTTP requests and responses initiated from Code 1. observed in ﬁrst-party ATS cookies). COOKIEGRAPH does not use content features, e.g., based on cookie name, as they can be trivially used in detection evasion tactics [77], [66]. COOKIEGRAPH also removes three features because they are related to classiﬁcation of request nodes in WebGraph whereas COOKIEGRAPH classiﬁes storage nodes. 4.2. Evaluation Similar to previous work [65], [77], we use a random forest classiﬁer to distinguish between ATS and Non-ATS cookies. We ﬁrst train and test the accuracy of this classiﬁer 9 on a carefully labeled dataset. Then, we deploy it on our 10K website dataset. 4.2.1. Ground truth labeling. We use two complementary approaches to construct our ground truth for ﬁrst-party ATS cookies. We represent each ﬁrst-party cookie as a cookie- domain pair, since the same cookie name can occur on multiple sites. Filter lists. We rely on ﬁlter lists [28], [29] as previous work has found them to be reasonably reliable in detecting ATS endpoints [65], [77]. However, ﬁlter lists are designed to label resource URLs, rather than cookies. We adapt ﬁlter lists to label cookies by assigning the label of a particular resource to all the cookies set by that resource. Since both ATS and Non-ATS cookies can be set by the same resource, this labeling procedure could result in a non-trivial number of false positives. To limit the number of false positives in our ground truth, we only label Non-ATS cookies based on ﬁlter lists: i.e., if a script that sets a cookie is not marked by any of the ﬁlter lists, we label these cookies as Non- ATS. Conservatively, if any one of the ﬁlter lists mark the cookie’s setter as ATS, we label the cookie as Unknown. Cookiepedia. Inspired by prior work [41], we use Cook- iepedia [34] as an additional source of cookie labels. Cook- iepedia is a database of cookies maintained by a well-known Consent Management Platform (CMP) called OneTrust [62], [42]. For each cookie and domain pair, Cookiepedia pro- vides its purpose, deﬁned primarily through the cookie integration with OneTrust. Each cookie is assigned one of four labels: strictly necessary, functional, analytics, and advertising/tracking. As Cookiepedia-reported purposes are self-declared, we adopt a conservative approach: we only label a cookie-domain pair as ATS if a cookie’s purpose is declared as advertising/tracking or analytics in a particular domain. If the cookie’s declared purpose is strictly necessary or functional, we label the cookie as Unknown, as the cookie might have been, mistakenly or intentionally, mislabeled. We combine the results of the labeling approaches to obtain a ﬁnal label for ﬁrst-party cookies. If both approaches label a cookie as Unknown, its ﬁnal label is Unknown. If only one of the approaches has a known label, this is the ﬁnal label. When Cookiepedia marks a cookie as ATS and ﬁlter lists mark it as Non-ATS, we give precedence to the Cookiepedia label and assign the ﬁnal label as ATS because websites are unlikely to self-declare their Non-ATS cookies as ATS. Using this labeling process, 20,927 out of 78,560 ﬁrst- party cookies (26.64%) have a known (ATS or Non-ATS) label and the rest are labeled as Unknown. We then observe that cookies set by the same script across two different sites are often labeled ATS in one instance and Unknown in other instance because Cookiepedia does not have data for the latter. As it is unlikely that an ATS script changes purpose across sites, we propagate the ATS label to all instances set by the same script. After this label propagation, 51.76% of the data is now labeled, with 21,875 (53.79%) ATS and 18,786 (46.20%) Non-ATS labels. 10 Figure 9. Feature distribution of cookie exﬁltrations (top) and storage sets (bottom) for ATS and Non-ATS cookies. ATS cookies are exﬁltrated and set more than Non-ATS cookies, resulting in ﬂow features based on exﬁltrations and sets being helpful for the classiﬁer. 4.2.2. Classiﬁcation. We train and test the classiﬁer on the labeled dataset using standard 10-fold cross validation. We ensure that there is no overlap in the websites used for training and test in each fold. Similar to Section 4.1, we limit the classiﬁer to cookies whose value is at least 8 characters long. The classiﬁer has 91.87% precision and 90.59% recall, with an overall accuracy of 91.06%, indicating that the classiﬁer is successful in detecting ATS cookies. Feature analysis. We conduct feature analysis to understand the most inﬂuential features for the classiﬁer. We ﬁnd that the most inﬂuential features are the ﬂow features, which capture cookie exﬁltrations, set operations, and redirections by cookie setters. Figure 9 shows the distributions for the number of cookie exﬁltrations (top) and the number of times a cookie is set (bottom), for ATS and Non-ATS cookies. ATS cookies are much more likely to be exﬁltrated than Non- ATS cookies: ATS have a median number of 6 exﬁltrations (mean/std is 11.11/15.95) as compared to a median of 0 for Non-ATS (mean/std is 0.62/5.29). Also, ATS cookies tend to be set much more frequently by scripts, with a median of 3 set operations (mean and standard deviation is 4.86±6.99) as compared to 1 for Non-ATS cookies (mean and standard deviation is 2.17±6.08). These ﬁndings conﬁrm our conclu- sions in Section 3: ﬁrst-party ATS cookies are used to store identiﬁers which are then exﬁltrated to multiple endpoints. the cookies Error analysis. We conduct manual analysis of COOKIE- GRAPH’s false positives and false negatives to understand why the approach fails. We ﬁnd that that were most mis- classiﬁed as ATS are those whose publicly available descriptions indicate they are used to track visitors on a page (e.g., __attentive_id, messagesUtk, omnisendAnonymousID) [24], [33], [31]. We also ﬁnd a few instances of well-known Google Analytics cookies _ga and _gid that are labeled in ground truth as Non-ATS, but are classiﬁed by COOKIEGRAPH as ATS. Overall, we ﬁnd that the false positives are typically not caused by COOK- IEGRAPH misclassifying non-tracking cookies, but mostly that the tracking cookies ﬂagged by COOKIEGRAPH were mislabeled as Non-ATS in the ground truth. In other words, COOKIEGRAPH has likely correctly classiﬁed these tracking cookies. We note that even after our procedures to improve ground truth labels, there may be cookies that did not have self-disclosed labels or were served from slightly different scripts (thereby missing our hash-based script matching) leading to some mistakes in the ground truth. We leave investigation of further methods of improving the ground truth labeling to future work. For false negatives, a representative case is the _pin_unauth cookie. Its value is double-base64-encoded, that is not included in the list of potential encoding schemes used by COOKIEGRAPH to detect exﬁltration. These false negatives can be averted by using a more comprehensive list of encoding schemes or by performing full-blown infor- mation ﬂow tracking instead of approximating exﬁltration ﬂows; however, the latter would come at a performance cost as we discuss further in Section 4.4. Other false negatives are because COOKIEGRAPH does not capture sufﬁcient activity during webpage execution. We further discuss these cases of false negatives in Section 5.1 Table 3. LIST OF TOP-25 ATS COOKIES DETECTED BY COOKIEGRAPH Cookie Name gid ga fbp gcl au gpi ga gads gads uetsid uetvid gpi clck hjTLDTest clsk cto bundle ym d ym uid pin unauth utma utmb utmz qca utmc ttp hubspotutk Script Domain Org. Percentage of Sites google-analytics.com google-analytics.com facebook.net googletagmanager.com googlesyndication.com googletagmanager.com googlesyndication.com doubleclick.net bing.com bing.com doubleclick.net clarity.ms hotjar.com clarity.ms criteo.net yandex.ru yandex.ru pinimg.com google-analytics.com google-analytics.com google-analytics.com quantserve.com google-analytics.com tiktok.com hs-analytics.net Google Google Facebook Google Google Google Google Google Microsoft Microsoft Google Microsoft Hotjar Microsoft Criteo Yandex Yandex Pinterest Google Google Google Quantcast Google TikTok HubSpot 77.11% 68.88% 33.22% 14.22% 14.02% 12.79% 12.35% 11.68% 10.22% 10.22% 10.11% 8.81% 8.05% 7.88% 5.98% 4.85% 4.85% 4.57% 4.32% 4.32% 4.32% 4.19% 4.17% 3.75% 3.29% 4.3. Deployment We deploy COOKIEGRAPH to classify all cookies, in- cluding Unknown cookies, in our crawl of 10K sites. Prevalence of ﬁrst-party ATS cookies. Overall, COOKIE- GRAPH classiﬁes 62.48% of the 74,003 ﬁrst-party cookies in our dataset as ATS. We ﬁnd that 93.43% of sites deploy at least one ﬁrst-party ATS cookie. Of these sites, the average number of ﬁrst-party ATS cookies on a site is 6.29. Who sets ﬁrst-party ATS cookies? The vast majority (98.39%) of the ﬁrst-party ATS cookies are in fact set by third-party embedded scripts served from a total of 1,588 unique domains. This demonstrates that ﬁrst-party ATS cookies are actually set and used by third-party trackers. Because this is only possible if the ﬁrst-party allows the third-party trackers to embed a script in ﬁrst-party con- text, this suggests that there is intentional or unintentional collusion between the ﬁrst-party and third-party tracker. These third-party-set ﬁrst-party cookies enable third-parties to circumvent blocking-based countermeasures implemented by browsers. Next, we analyze the most prevalent ﬁrst-party cookies and the third-party entities that actually set them. Table 3 lists top-25 out of 5,019 ﬁrst-party ATS cookies5 based on their prevalence. Two major advertising entities (Google and Facebook) set ﬁrst-party ATS cookies on approximately a third of all sites in our dataset. COOKIEGRAPH detects _gid and _ga cookies by Google Analytics as ATS on 77.11% and 68.88% of the sites. The public documentation 5. We report distinct tuples of cookie name and the setter script’s URL. acknowledges using these two ﬁrst-party cookies to store user identiﬁers for tracking [8]. COOKIEGRAPH detects _fbp cookie by Facebook as ATS on 33.22% of the sites. Their public documentation acknowledges that Facebook tracking pixel stores unique identiﬁer in the ﬁrst-party _fbp cookie [5]. In fact, Facebook made a recent change to include ﬁrst-party cookie support in its tracking pixel to avoid third-party cookie countermeasures [20]. TikTok, an emerging social media app that is known to aggressively harvest sensitive user information [11], also recently added support for setting ﬁrst-party tracking cook- ies using TikTok Pixel [19], [17]. TikTok’s ﬁrst-party _ttp tracking cookie is present on 3.75% percent of sites, which is considerably lower than Facebook and Google but com- parable to more specialized entities such as Criteo. Criteo’s cto_bundle cookie is amongst the most prevalent ﬁrst-party ATS cookies. Recall from Section 3.3 that cto_bundle is sometimes purposefully set when third-party cookies are blocked. Our deployment of COOK- IEGRAPH shows that Criteo sets this ﬁrst-party ATS cookie on 5.98% of sites in our dataset. Note that ﬁrst-party ATS cookies from Lotame, ID5, and Adobe listed in Table 1 are also detected by COOKIEGRAPH but they do not make the top-25 list. Despite not being as prevalent as the other ﬁrst- party ATS cookies, their behavior analysis in Section 3.3 was crucial in discovering prevalent examples discussed in this section. Browser ﬁngerprinting. As discussed in Section 3.4, track- ers that use ﬁrst-party ATS cookies may employ other invasive tracking techniques such as browser ﬁngerprinting to implement cross-site tracking. We analyze the ﬁrst-party 11 cookies that are set by the scripts from entities that are known to engage in browser ﬁngerprinting. We use Dis- connect’s sublist of ﬁngerprinters [15], [7] from its tracking protection list [26]. We ﬁnd that Google’s and Facebook’s ﬁrst-party ATS cookies are predominately set by scripts served from domains involved in ﬁngerprinting. Lotame’s cookies (_cc_id, _cc_aud, _cc_cc) are also found to be set by such scripts. Overall, we ﬁnd that 45 (2.83%) distinct domains that set ﬁrst-party cookies are also known ﬁngerprinters. However, these handful of domains are responsible for setting 41.45% of all ﬁrst-party ATS cookies. This disproportionately be- tween domains and number of cookies set is not surprising. Effective cross-site tracking would require a tracker to be present on and collect data from a large number of sites. This presence will allow the tracker to collect extensive deterministic and probabilistic attributes about the user from a varied number of source, enhancing its ability to track users across sites in absence of third-party cookies. Our case studies in Appendix A and our analysis in Section 3.4 elaborate on how ﬁrst-party ATS cookies are combined with ﬁngerprinting for cross-site tracking. 4.4. Comparison with Existing Countermeasures Next, we compare COOKIEGRAPH with state-of-the- art countermeasures against ATS, CookieBlock [41] and WebGraph [77], in terms of detection accuracy, website breakage, and robustness. CookieBlock is a state-of-the-art approach to classify cook- ies, including advertising/tracking and analytics. It makes use of both manually curated allow lists and a machine learning classiﬁer, which mainly relies on features based on cookie attributes (cookie names and values). WebGraph is the state-of-the-art graph-based approach to classify ATS requests. Since WebGraph is not de- signed to directly classify cookies, we adapt it to this end by identifying ATS resources identiﬁed by WebGraph in 3P-Blocked and generating a block list of cookies for each domain set by those resources. This list is meant to mimic the effect of blocking these resources on ﬁrst-party ATS cookies. 4.4.1. Detection Accuracy. Table 4 compares the detec- tion accuracy of COOKIEGRAPH with CookieBlock and WebGraph. COOKIEGRAPH outperforms both approaches in all metrics. The superiority in precision indicates that existing countermeasures result on many more false posi- tives than COOKIEGRAPH. These additional false positives means that previous approaches would block functional ﬁrst- party cookies potentially affecting user experience. Next, we investigate the impact of these false positives on website breakage. 4.4.2. Website Breakage. We manually analyze the break- age caused by COOKIEGRAPH, CookieBlock and Web- Graph’s on 50 sites that are sampled from the 10K sites Table 4. CLASSIFICATION ACCURACY OF COOKIEGRAPH, WEBGRAPH, AND COOKIEBLOCK Classiﬁer Accuracy Precision Recall COOKIEGRAPH WebGraph CookieBlock 91.06% 78.74% 80.78% 91.87% 71.59% 69.95% 90.59% 85.49% 72.45% used in Section 3 (25 sites chosen randomly from top 100 and other 25 from the rest). We divide our breakage analysis in four categories of typical website usage: navigation (from one page to an- other), SSO (initiating and maintaining login state), appear- ance (visual consistency), and miscellaneous functionality (chats, search, shopping cart, etc.). We label breakage as major or minor for each category: major breakage – when it is not possible to use a functionality on the site included in either of the aforementioned categories, and minor breakage – when it is difﬁcult, but not impossible, for the user to make use of a functionality. To assess website breakage, we com- pare a vanilla Chrome browser (with no countermeasures against ﬁrst-party cookies) with browsers enhanced with an extension which blocks all ﬁrst-party cookies classiﬁed as ATS by COOKIEGRAPH, enhanced with an extension which blocks all cookies set by resources labeled as ATS by WebGraph, and enhanced with the ofﬁcial CookieBlock extension [3]. We use two reviewers to perform the breakage analysis to mitigate the impact of biases or subjectivity. Any disagreements between the reviewers were resolved after careful discussion. Out of the 50 sites, COOKIEGRAPH only had minor breakage on one site where an offer popup kept reappearing due to deletion of a cookie which stores user preferences. In contrast, both WebGraph and CookieBlock cause major breakage in at least one of the four categories on 10% of the sites. For example, WebGraph causes issues with cart functionality on darsoo.com, complete website breakage on espncricinfo.com, and SSO issues on other sites. Most of the breakage issues of CookieBlock relate to SSO logins and additional login-dependent functionality (e.g., missing proﬁle picture). Our results, that CookieBlock causes break- age on 8% of the sites with SSO logins, are inline with the 7-8% breakage reported by the authors [42]. We also ﬁnd that WebGraph blocks some additional ﬁrst- party cookies that are important for server-side functionality, but not directly related to user experience and therefore not immediately perceptible. For example, WebGraph blocks essential cookies such as Bm_sz cookie used by Akamai for bot detection, XSRF-TOKEN cookie used to prevent CSRF on different sites, and AWSALB cookies used by Amazon for load balancing. COOKIEGRAPH correctly classiﬁed these cookies at Non-ATS, and thus does not prevent these mea- sures from being deployed. 4.4.3. Robustness. We compare the robustness of COOKIE- GRAPH, CookieBlock, and WebGraph to evasion, i.e., mod- iﬁcations to cause the misclassiﬁcation of ATS resources as Non-ATS. Since advertisers and trackers are known to 12 Table 5. WEBSITE BREAKAGE COMPARISON OF ALL THREE COUNTERMEASURES.( BREAKAGE, AND ( ) SIGNIFIES NO BREAKAGE, ( ) MINOR ) MAJOR BREAKAGE. EACH CELL REPRESENTS THE PERCENTAGE OF SITES ON WHICH BREAKAGE WAS OBSERVED. Classiﬁer Navigation Miscellaneous Minor Major Minor Major Minor Major Minor Major Appearance SSO COOKIEGRAPH 0% WebGraph 10% CookieBlock 2% Table 6. ROBUSTNESS (DIFFERENCE IN CLASSIFICATION ACCURACY) 2% 4% 0% 0% 6% 8% 0% 0% 0% 0% 4% 0% 0% 2% 0% 0% 2% 2% 0% 0% 0% Classiﬁer ∆ Accuracy ∆ Precision ∆ Recall COOKIEGRAPH WebGraph CookieBlock 0.00% 0.00% -15.68% 0.00% 0.00% -15.08% 0.00% 0.00% -16.54% engage in the arms race with privacy-enhancing tools [37], [64], [61], to test whether the detection of ﬁrst-party ATS cookies is brittle in the face of trivial manipulation attempts such as changing cookie names. is important it We evaluate robustness on a test set of 2,000 sites from our dataset which also have the required CMP needed by CookieBlock for data collection and training. This translates to a total test set of 7,726 ﬁrst-party cookies. We change the names of the cookies in our test set to randomly generated strings of lengths between 2 and 15 characters. Table 6 shows the results. We note that both COOKIEGRAPH and WebGraph are fully robust to manipulation of cookies names while CookieBlock’s accuracy degrades by more than 15%. COOKIEGRAPH and WebGraph are robust because they do not use any content features (features related to the cookie characteristics, such as cookie name or domain) since these can be somewhat easily manipulated by an adversary aiming to evade classiﬁcation [77]. On the contrary, the most important feature of CookieBlock in fact depends on the cookie name, i.e., whether the name belongs to the top-500 most common cookie names [40]. Thus, CookieBlock can be easily bypassed with trivial cookie name modiﬁcations. COOKIEGRAPH’s implementation of ﬂow features can be manipulated by an adversary by using a different encod- ing than it currently considers or by changing the domains of exﬁltration endpoints. COOKIEGRAPH’s robustness to these attacks can be improved by more comprehensive informa- tion ﬂow tracking. However, full-blown information ﬂow tracking would incur prohibitively high run-time overheads (up to 100X-1000X [60]) and implementation complexity in the browser [46], [45], [80], [68]. 5. Limitations 5.1. Completeness COOKIEGRAPH relies on a graph representation of in- teractions between different elements during webpage exe- cution. The completeness of the interactions captured in the graph depends on the intensity and variety of user activity on a webpage (e.g., scrolling activity, number of internal pages clicked). In other words, it is possible that COOKIEGRAPH 13 may not detect certain ATS cookies if its graph represen- tation has not captured the interactions between different elements due to insufﬁcient user activity. To study the impact of user activity on COOKIEGRAPH, we recrawl sites performing two to three times more in- ternal page clicks than in the original crawl. We speciﬁ- cally recrawl 238 sites where Criteo’s cto_bundle cookie was originally classiﬁed as Non-ATS by COOKIEGRAPH. COOKIEGRAPH’s deployment on the recrawled sites results in successful detection of Criteo’s cto_bundle cookie as ATS on 121 of the 238 recrawled sites. We ﬁnd that the average number of inﬁltrations (exﬁltrations) increase from 1.54 to 2.95 (1.13 to 4.01) across the original and recrawled sites. We surmise that while there are cases where COOKIEGRAPH incorrectly classiﬁes ATS as Non- ATS due to incompleteness of the graph representation, its decision reﬂects the behavior of the cookie at the time of classiﬁcation. As more interaction is captured in the graph, COOKIEGRAPH is able to correctly switch the label to ATS. Moreover, COOKIEGRAPH never switch labels from ATS to Non-ATS due to increased interaction. We observed a similar trend for other prevalent ﬁrst-party ATS cookies in our dataset. 5.2. Deployment COOKIEGRAPH’s implementation is not suitable for run- time deployment due to the performance overheads asso- ciated to the browser instrumentation and machine learn- ing pipeline. We envision COOKIEGRAPH to be used in an ofﬂine setting: (1) ﬁrst-party ATS cookie-domain pairs are detected using machine learning classiﬁer and (2) the detected cookie-domain pairs are added to a cookie ﬁlter list such as those already supported in privacy-enhancing browser extensions such as uBlock Origin [18] for run- time blocking. We argue that a reasonably frequent (e.g., once a week) deployment of COOKIEGRAPH on a large scale would be sufﬁcient in generating and keeping the ﬁlter list up-to-date. While advertisers and trackers can in theory change cookie names at a rate faster than COOK- IEGRAPH’s periodic deployment, updating cookie names frequently is challenging in practice because setting these ﬁrst-party ATS cookies across many different sites requires tight coordination between different entities. To illustrate the practical issues associated with changing cookie names, consider the legacy demdex cookie set by Adobe’s em- bedded script is then exﬁltrated to the demdex.net domain. Adobe’s documentation explains that it is difﬁcult to change the legacy name because “... it is entwined deeply with Audience Manager, the Adobe Experience Cloud ID Service, and our installed user base” [25], [36]. If advertisers or trackers are somehow able to overcome these practi- cal challenges and change cookie names at a much faster pace, COOKIEGRAPH’s online implementation for run-time cookie classiﬁcation would be necessary. Further research is needed for efﬁcient and effective online implementation of COOKIEGRAPH. that 6. Conclusion We conducted a large scale differential measurement study to investigate how trackers abuse ﬁrst-party cookies to circumvent third-party cookie blocking. Our proposed COOKIEGRAPH was able to accurately and robustly block ﬁrst-party tracking cookies, and signiﬁcantly outperforming the state-of-the-art. Using COOKIEGRAPH, we found evi- dence of widespread abuse of ﬁrst-party cookies on more than 93% of the tested websites by 1500+ distinct tracking domains, which included major advertising entities such as Google as well as many specialized entities such as Criteo. References [18] “uBlock Origin: Resources Library,” https://github.com/gorhill/uBloc k/wiki/Resources-Library#cookie-removerjs-. [19] “Using cookies with tiktok pixel,” https://web.archive.org/web/ 20220610074648/https://ads.tiktok.com/help/article?aid=10007540. [20] “What facebook’s ﬁrst-party cookie means for adtech,” https://web.archive.org/web/20220729210450/https://clearcode.cc /blog/facebook-first-party-cookie-adtech/. [21] “This bug in your pc is a smart cookie,” https://archive.org/details/Fi nancialTimes1996UKEnglish, 1996. [22] “Internet privacy with ie6 and p3p: A summary of ﬁnd- ings,” http://web.archive.org/web/20200731061208/http://www.spyw arewarrior.com/uiuc/ie6-p3p.htm, 2001. [23] “Adblock plus,” https://adblockplus.org/, 2022. [Online]. Available: https://adblockplus.org/ [24] “Attentive cookie,” https://docs.attentivemobile.com/p [1] [2] [3] [4] [5] [6] [7] [8] [9] “About publisher provided identiﬁers,” https://web.archive.org/we b/20220614165742/https://support.google.com/admanager/answer/ 2880055?hl=en. “Cartographer 20220526085916/https://www.lotame.com/solutions/cartographe r-identity-graph/. https://web.archive.org/web/ identity graph,” “Cookieblock,” https://github.com/dibollinger/CookieBlock. Online “Criteo 20220819071808/https://ﬁlecache.investorroom.com/mr5ir crite o/977/download/Criteo Online Identification May2020.pdf/. Identiﬁcation),” https://web.archive.org/web/ and “fbp Parameters,” 20220722220344/https://developers.facebook.com/docs/marketi ng-api/conversions-api/parameters/fbp-and-fbc/. https://web.archive.org/web/ fbc “Firefox rolls out total cookie protection by default to all users world- wide,” https://blog.mozilla.org/en/products/firefox/firefox-rolls-out-t otal-cookie-protection-by-default-to-all-users-worldwide/. “Firefox’s protection against ﬁngerprinting,” https://support.mozilla. org/en-US/kb/firefox-protection-against-fingerprinting. “Google Analytics Cookie Usage //web.archive.org/web/20220812222800/https://developers.googl e.com/analytics/devguides/collection/gtagjs/cookie-usage. on Websites),” https: “Id5 identity cloud,” https://web.archive.org/web/20220727094611/ht tps://www.id5.io/identity-cloud/. [10] “Identity Guide,” https://web.archive.org/web/20220115155115/https: //yieldbird.com/identity-guide/. [11] “It’s their word against their https://internet2-0.com/whitepaper/its-their-word-against-their-s ource-code-tiktok-report/. source code - tiktok report,” [12] “Lotame – Data Collection Guide,” https://web.archive.org/web/ 20210730071853/https://my.lotame.com/t/p8hxvnd/data-collection-g uide. [13] “Lotame identity resolution,” 20220530231410/https://www.lotame.com/solutions/identity-res olution/. https://web.archive.org/web/ [14] “Lotame lightning tag,” 20220307010702/https://my.lotame.com/t/m1hxv7l/lotame-light ning-tag. https://web.archive.org/web/ [15] “Our new approach to address the rise of ﬁngerprinting,” https://blog.disconnect.me/our-new-approach-to-address-the-ris e-of-fingerprinting/. [16] “Panorama id,” https://web.archive.org/web/20220327180718/https:// www.lotame.com/panorama/id/. ages/developer-guides/third-party-integrations/referral-mar keting-platforms/talkable/, https://docs.attentivemobile.com/pages/developer-guides/third-p arty-integrations/referral-marketing-platforms/talkable/ [Online]. 2022. Available: [25] “Cookies the and ser- experience vice,” https://experienceleague.adobe.com/docs/id-service/using/intro /cookies.html?lang=en, 2022. [Online]. Available: https://experience league.adobe.com/docs/id-service/using/intro/cookies.html?lang=en identity cloud [26] “Disconnect tracking protection lists,” https://disconnect.me/trackerp rotection, 2022. [Online]. Available: https://disconnect.me/trackerpro tection [27] “Doubleclick,” https://web.archive.org/web/19970405225532/http: //www.doubleclick.com/, 2022. [28] “Easylist,” https://easylist.to/easylist/easylist.txt, 2022. [29] “Easyprivacy,” https://easylist.to/easylist/easyprivacy.txt, 2022. [30] “Enhanced tracking protection in ﬁrefox for desktop,” https://support. mozilla.org/en-US/kb/enhanced-tracking-protection-firefox-desktop, 2022. [31] “Hubspot cookie,” https://knowledge.hubspot.com/reports/what-coo kies-does-hubspot-set-in-a-visitor-s-browser, 2022. [Online]. Avail- able: https://knowledge.hubspot.com/reports/what-cookies-does-hub spot-set-in-a-visitor-s-browser [32] “Id5 - ﬁrst resolution methods party explained,” https://web.archive.org/web/20220408035339/https: //id5.io/news/index.php/2022/03/24/ﬁrst-party-ids-and-identity-resol ution-methods-explained/, 2022. identity and ids [33] “Omnisend cookie,” https://support.omnisend.com/en/articles [On- /1933402-explaining-and-managing-tracking-cookies, line]. Available: https://support.omnisend.com/en/articles/1933402-e xplaining-and-managing-tracking-cookies 2022. [34] “One trust. cookiepedia,” https://cookiepedia.co.uk, 2022. [35] “Tracking prevention in microsoft edge,” https://docs.microsoft.com /en-us/microsoft-edge/web-platform/tracking-prevention, 2022. [36] “Understanding calls do- https://experienceleague.adobe.com/docs/audience-manager main,” /user-guide/reference/demdex-calls.html?lang=en, 2022. [Online]. Available: https://experienceleague.adobe.com/docs/audience-manag er/user-guide/reference/demdex-calls.html?lang=en demdex the to [37] M. Alrizah, S. Zhu, X. Xing, and G. Wang, “Errors, misunder- standings, and attacks: Analyzing the crowdsourcing process of ad- blocking systems,” in Proceedings of the 2019 Internet Measurement Conference (IMC), 2019. [17] “Tiktok adds third-party cookies to its pixel – and tries to eat face- book’s lunch,” https://web.archive.org/web/20220623232016/https: //www.adexchanger.com/online-advertising/tiktok-adds-third-party-c ookies-to-its-pixel-and-tries-to-eat-facebooks-lunch/. [38] W. Aqeel, B. Chandrasekaran, A. Feldmann, and B. M. Maggs, “On landing and internal web pages: The strange case of jekyll and hyde in web performance measurement,” in Proceedings of the ACM Internet Measurement Conference, 2020. 14 [39] P. N. Bahrami, U. Iqbal, and Z. Shaﬁq, “Fp-radar: Longitudinal measurement and early detection of browser ﬁngerprinting,” in Pro- ceedings on Privacy Enhancing Technologies (PETS), 2022. [40] D. Bollinger, “Analyzing Cookies Compliance with the GDPR,” https: //www.research-collection.ethz.ch/handle/20.500.11850/477333. The- sis, ETH Zurich. [41] D. Bollinger, K. Kubicek, C. Cotrini, and D. Basin, “Automating cookie consent and GDPR violation detection,” in 31st USENIX Security Symposium (USENIX Security 22). USENIX Association, 2022. [42] ——, “Automating cookie consent and gdpr violation detection,” in 31st USENIX Security Symposium (USENIX Security 22), 2022. [43] A. Cahn, S. Alfeld, P. Barford, and S. Muthukrishnan, “An empirical study of web cookies,” in Proceedings of the 25th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, 2016, p. 891–901. [44] Q. Chen, P. Ilia, M. Polychronakis, and A. Kapravelos, “Cookie swap party: Abusing ﬁrst-party cookies for web tracking,” in Proceedings of the Web Conference, 2021. [45] Q. Chen and A. Kapravelos, “Mystique: Uncovering information leakage from browser extensions,” in Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, 2018, pp. 1687–1700. [46] A. Chudnov and D. A. Naumann, “Inlined information ﬂow mon- itoring for javascript,” in Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security, 2015, pp. 629–643. [47] L. M. D. Kristol, “Http state management mechanism,” https://datatr acker.ietf.org/doc/html/rfc2109, 1997. [48] S. Dambra, I. Sanchez-Rola, L. Bilge, and D. Balzarotti, “When sally met trackers: Web tracking from the users’ perspective,” in USENIX Security Symposium, 2022. [49] H. Dao, J. Mazel, and K. Fukuda, “Cname cloaking-based tracking on the web: Characterization, detection, and protection,” IEEE Trans- actions on Network and Service Management, 2021. [60] D. Hedin, A. Birgisson, L. Bello, and A. Sabelfeld, “Jsﬂow: Tracking information ﬂow in javascript and its apis,” in Proceedings of the 29th Annual ACM Symposium on Applied Computing, 2014, pp. 1663– 1671. [61] L. Hieu, M. Athina, and S. Zubair, “Cv-inspector: Towards automat- ing detection of adblock circumvention,” in Network and Distributed System Security Symposium (NDSS), 2021. [62] M. Hils, D. W. Woods, and R. B¨ohme, “Measuring the emergence of consent management on the web,” in Proceedings of the ACM Internet Measurement Conference, 2020. [63] X. Hu, N. Sastry, and M. Mondal, “Cccc: Corralling cookies into categories with cookiemonster,” in 13th ACM Web Science Conference 2021. Association for Computing Machinery, 2021, p. 234–242. [64] U. Iqbal, Z. Shaﬁq, and Z. Qian, “The ad wars: Retrospective mea- surement and analysis of anti-adblock ﬁlter lists,” in IMC, 2017. [65] U. Iqbal, P. Snyder, S. Zhu, B. Livshits, Z. Qian, and Z. Shaﬁq, “Adgraph: A graph-based approach to ad and tracker blocking,” in IEEE Symposium on Security and Privacy (S&P). IEEE, 2020. [66] U. Iqbal, C. Wolfe, C. Nguyen, S. Englehardt, and Z. Shaﬁq, “Khaleesi: Breaker of advertising and tracking request chains,” in USENIX Security Symposium (USENIX), 2022. [67] P. Laperdrix, W. Rudametkin, and B. Baudry, “Beauty and the beast: Diverting modern web browsers to build unique browser ﬁngerprints,” in 2016 IEEE Symposium on Security and Privacy (SP), 2016. [68] S. Lekies, B. Stock, and M. Johns, “25 million ﬂows later: Large- scale detection of dom-based xss,” in Proceedings of the 2013 ACM SIGSAC conference on Computer and Communications Security, 2013, pp. 1193–1204. [69] P. G. Leon, L. F. Cranor, A. M. McDonald, and R. McGuire, “Token attempt: the misrepresentation of website privacy policies through the misuse of p3p compact policy tokens,” in Proceedings of the 9th Annual ACM Workshop on Privacy in the Electronic Society, 2010. [70] L. Montulli, “The reasoning behind web cookies,” http://montulli.blo gspot.com/2013/05/the-reasoning-behind-web-cookies.html, 2013. [50] Y. Dimova, G. Acar, L. Olejnik, W. Joosen, and T. Van Goethem, “The CNAME of the Game: Large-scale Analysis of DNS-based Tracking Evasion,” PETS, 2021. [71] N. Nguyen, “Latest ﬁrefox rolls out enhanced tracking pro- tection,” https://blog.mozilla.org/en/products/firefox/latest-firefox-rol ls-out-enhanced-tracking-protection/, 2018. [51] D´ıaz-Morales and Roberto, “Cross-device tracking: Matching devices and cookies,” in 2015 IEEE International Conference on Data Mining Workshop (ICDMW), 2015, pp. 1699–1704. [52] B. Eich, “C is for cookie,” https://brendaneich.com/2013/05/c-is-for -cookie/, 2013. [53] ——, “The cookie clearinghouse,” https://brendaneich.com/2013/06/ the-cookie-clearinghouse/, 2013. [54] S. Englehardt and A. Narayanan, “Online tracking: A 1-million-site measurement and analysis,” in Proceedings of ACM CCS 2016, 2016. [55] S. Englehardt, D. Reisman, C. Eubank, P. Zimmerman, J. Mayer, A. Narayanan, and E. W. Felten, “Cookies that give you away: The surveillance implications of web tracking,” in Proceedings of the 24th International Conference on World Wide Web, 2015. [56] I. Fouad, N. Bielova, A. Legout, and N. Saraﬁjanovic-Djukic, “Missed by ﬁlter lists: Detecting unknown third-party trackers with invisible pixels,” Proceedings on Privacy Enhancing Technologies, vol. 2020, pp. 499–518, 04 2020. [57] I. Fouad, C. Santos, A. Legout, and N. Bielova, “My cookie is a phoenix: detection, measurement, and lawfulness of cookie respawn- ing with browser ﬁngerprinting,” in Privacy Enhancing Technologies Symposium (PETS), 2022. [58] B. Fulgham, “Protecting against hsts abuse,” https://webkit.org/blog/ 8146/protecting-against-hsts-abuse/, 2018. [59] Google, “The privacy sandbox,” https://developer.chrome.com/docs/ privacy-sandbox/. [72] P. Papadopoulos, N. Kourtellis, and E. P. Markatos, “Cookie syn- chronization: Everything you always wanted to know but were afraid to ask,” in Proceedings of the World Wide Web (WWW) Conference, 2019. [73] A. Randall, P. Snyder, A. Ukani, A. Snoeren, G. Voelker, S. Savage, and A. Schulman, “Trackers bounce back: Measuring evasion of partitioned storage in the wild,” 2022. [74] F. Roesner, T. Kohno, and D. Wetherall, “Detecting and defending against third-party tracking on the web,” in 9th USENIX Symposium on Networked Systems Design and Implementation (NSDI 12), 2012, pp. 155–168. [75] I. Sanchez-Rola, M. Dell’Amico, , D. Balzarotti, P.-A. Vervier, and L. Bilge, “Journey to the center of the cookie ecosystem: Unraveling actors’; roles and relationships,” in S&P 2021, 42nd IEEE Symposium on Security & Privacy, 23-27 May 2021, San Francisco, CA, USA, 2021. [76] J. Schuh, “Building a more private web: A path towards making third party cookies obsolete,” https://blog.chromium.org/2020/01/building -more-private-web-path-towards.html, 2020. [77] S. Siby, U. Iqbal, S. Englehardt, Z. Shaﬁq, and C. Troncoso, “Web- graph: Capturing advertising and tracking information ﬂows for robust blocking,” in 31st USENIX Security Symposium (USENIX Security 22). USENIX Association, 2022. [78] A. Sj¨osten, P. Snyder, A. Pastor, P. Papadopoulos, and B. Livshits, “Filter list generation for underserved regions,” in WWW, 2020. 15 [79] S. Sluis, “Google is building integrations for publisher-speciﬁc identi- ﬁers,” https://www.adexchanger.com/platforms/google-is-building-int egrations-for-publisher-speciﬁc-identifiers/, 2021. [80] B. Stock, S. Lekies, T. Mueller, P. Spiegel, and M. Johns, “Precise client-side protection against dom-based cross-site scripting,” in 23rd USENIX Security Symposium (USENIX Security 14), San Diego, CA, 2014, pp. 655–670. [81] B. P. Team, “Fighting CNAME Trickery,” https://brave.com/privacy-u pdates/6-cname-trickery/, 2020. [82] M. E. Team, “Introducing tracking prevention, now available in microsoft edge preview builds,” https://blogs.windows.com/msedge dev/2019/06/27/tracking-prevention-microsoft-edge-preview/, 2022. [Online]. Available: https://blogs.windows.com/msedgedev/2019/06/ 27/tracking-prevention-microsoft-edge-preview/ [83] A. Vastel, P. Laperdrix, W. Rudametkin, and R. Rouvoy, “Fp-stalker: Tracking browser ﬁngerprint evolutions,” in IEEE Symposium on Security and Privacy (SP), 2018. [84] A. V. Veen and A. de Vries, “Cookie compliance of dutch hospital websites,” 2021. [85] WebKit, “Tracking prevention in webkit,” https://webkit.org/trackin g-prevention/, 2022. [Online]. Available: https://webkit.org/trackin g-prevention/ [86] J. Wilander, “Intelligent tracking prevention,” https://webkit.org/blog/ 7675/intelligent-tracking-prevention/, 2017. [87] ——, “Intelligent tracking prevention 1.1,” https://webkit.org/blog/ 8142/intelligent-tracking-prevention-1-1//, 2018. [88] ——, “Intelligent tracking prevention 2.0,” https://webkit.org/blog/ 8311/intelligent-tracking-prevention-2-0/, 2018. [89] ——, “Intelligent tracking prevention 2.1,” https://webkit.org/blog/ 8613/intelligent-tracking-prevention-2-1/, 2019. [90] ——, “Intelligent tracking prevention 2.2,” https://webkit.org/blog/ 8828/intelligent-tracking-prevention-2-2/, 2019. [91] ——, “Intelligent tracking prevention 2.3,” https://webkit.org/blog/ 9521/intelligent-tracking-prevention-2-3/, 2019. [92] ——, “Cname cloaking and bounce tracking defense,” https://we bkit.org/blog/11338/cname-cloaking-and-bounce-tracking-defense/, 2020. [93] ——, “Full third-party cookie blocking and more,” https://webkit.org /blog/10218/full-third-party-cookie-blocking-and-more/, 2020. [94] ——, “Bounce tracking protection,” https://github.com/privacycg/pro posals/issues/6, 2022. Appendix 1. Case Studies In this section, we look at case studies of ATSes identi- ﬁed in Section 3.3 which are found to be extensively using ﬁrst-party cookies for tracking purposes. We analyze the behavior of these ATS in our crawls, compare the observed behavior with their documentation, and create a generic model which all ﬁrst-party-cookie-based ATSes follow in Section 3.4. We present case studies of three ATSes here: Lotame, ID5, and Criteo. 1.1. Lotame. Lotame is a data and identity management solution which claims to provide a single ID to users across multiple browsers, devices, and platforms. Lotame’s Light- ning Tag [14] packages the user visit data in a JSON object and sends it to its servers. Code 2 shows an example payload sent to Lotame. The payload includes IDs assigned by the website, third-party identiﬁers present on the site, certain user behaviors (conﬁgured through collaboration between the publisher and Lotame), and other custom rules deﬁned per website [12]. Lotame processes the payload and matches the data with its Cartographer Identity Graph [2], and sends back an ID, called panoramaID [16], which is stored as a ﬁrst-party cookie or in localStorage. 1.2. ID5 Universal ID. ID5 provides identity resolution for publishers and advertisers through its Identity Cloud [9]. ID5’s script packages a payload that contains several de- terministic identiﬁers, such as email, usernames, and phone numbers (if available) and as well as probabilistic identiﬁers include, such as IP address, user agent, and location of the user [32]. ID5 then processes the payload and matches the data with its Identity Cloud and send back an ID, called universal id, which is stored as a ﬁrst-party cookie and as well as in local storage. An example payload from ID5 is shown in Figure 3. We note that ID5 also provides Partner Graph, a service that enables information sharing among its partners [9]. Partner Graph allows different identify providers to exchange information with each other. data: { behaviorIds: [1,2,3], behaviors: { int: [’behaviorName’, ’behaviorName2’], act: [’behaviorName’] }, ruleBuilder: { key1: [’value 1a’, ’value 1b’] }, thirdParty: { namespace: ’NAMESPACE’, value: ’TPID_VALUE’ } } Code 2. Example of data sent structure sent to Lotame during a user’s ﬁrst visit. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 party cookies and localStorage for storing cto_bundle cookie. We consider this to be one of the fundamental behaviors of ﬁrst-party ATS cookies. As described in Sec- tion 4.1, COOKIEGRAPH’s graph representation abstracts storage to refer to both Cookies and localStorage. We also include a count of localStorage accesses in the feature set computed from the graph representation. Inclusion of these features help COOKIEGRAPH effectively model ﬁrst-party ATS cookies behavior. 2. Cross-Device User Attribution The methodology for cross-site attribution can also be extended to cross-device attribution. In this slightly more complex scenario, the user is not only visiting different sites but also using different devices with different ﬁngerprints. We show an example of cross-device attribution in Fig- ure 10. Instead of visiting the sites on the same device, the user now visits sites 1-3 on device 1, and then visits sites 4-6 on device 2. Fingerprints F1, F2 and F3 are collected on sites 1-3 while using device 1, and F4, F5 and F6 are collected while using device 2. Sites 3 and 6 ask the user for an additional P P ID − 1. There is no similarity in ﬁngerprints between the two devices. However, as sites 3 and 6 collect the additional P P ID − 1, the tracker is able to identify and populate its ﬁrst-party cookie on each of those sites with the correct user ID (U ID1). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 { ""created_at"":""2022-02-09T11:42:40.817811Z"", ""id5_consent"":true, ""original_uid"":""ID5* FnFOGLkYzdJjuoK3KvAecVW2oFpZ7OrZiW7h-M0H ACAHYuWkxQrEGcpWuOkQUXbHB2OO8Rj0wt94jllT WHQ6wdkqOwSbnYea8cesuONCF4HZeIoDaB_TwBsy lKrs3tHB2Y87ZwP0DrpYlGz1OG1Fgdn0YdgqoSGU SGxzS1gUzsHaMIUBVqf2I08es6aUULEB2n48oyL0 nGnRtstVqtcQQdquS3Aay4Hhgbzh9gIZyYHa_nLT d5rjbbR0ZXwkXDzB2yU1XUC2dukip1J_clVAgdtt xC_xaRRBOLi0fnvp9cHbqr_pWihTtaUMS_R6eLuB 2_AMExt1UdhJZBe2mcXZAdwm9lcbeMMvlpg3MBrC oHcUgzNypi-5xLUqBD8GC4B3KsefcNkiDvI4n9ZL 7OjAdzqB9PD-KczAx63Ck0gEIHdNPfQeEi-f5VaO OEhf6B3VUqDoL11hqVoIuDhKJbgd2kp0mgXabhwJ tPO7sgWwHd_vz_uIYYmqQBTbH-JFVB3h1-kI9GQv dby2PyftDawd596ho3tuOsKtoDOk4S4Her2Uw-_u BYRxrt6YzVYqB3tRwTVI3Fxm8cGJyjdmYAd88lom BIpkOeg2Ok4VTNc"", ""universal_uid"":""ID5* HGH7W7iMpMu3-EPZCXUuqNBB7fFHUUVcbSddSSG Fu5UHYucsBxMz2jncvKS7rkwlB2MWiiPupapPxa 79eieMAdkTyMQz82s1vIekPr28DEHZbqTCrapj9 Fb9K0x4zjlB2YHOKNDwQY6mZwxk_1mwAdna3wWna hrpMEUrPxJSnAHaPYB-InS5DXGpQgqbqirB2nHFI D4j9i9BgCP3k0VygdqdtFHsT7eeDfFYuB8EQ0Ha4 -yV9Ifvbvi5oxmtH7HB2xg-mmmOeyVOPBYGi2tfw dtREZnUE83cfn_LHvHvu4HbvkLkwEFJiddOEp4PT ZbB2-de_VPyKHax5JtpO46xwdwZ_0UMgANOsZygV 0SrrMHcZ37qQB-LkCO4tWoTbv_B3KMGCMrebcfLE TeCn0AEgdzIR1utDJzM6AaiL9KVkAHdPtrAtTv73 ZyDg92Rq-_B3XeRNOOc7b2CEBsilXOlQd2sfmR36 NyW-dsK9CUmd4Hd3vcrlAWzfYEfw01Q5J1B3ibAF UYrA0XWMl-D9jSlAd5iX1tGA4vPu0wdZkXVOEHek q2xibOm9XwN2nSdZjbB3v8nOyzGuF9QgwI67pMGQ d85BszRCJDUkiiu-tv5BQ"", ""signature"":"" ID5_Ab6tnGgmCcjKo-qFGVKszuNpNePqkOHZT rbCmpuktLLOlNOCALhmY_91AHP8LU0BvfJT2Q JQWlsUEfynB1hBGZc"", ""link_type"":1, ""cascade_needed"":true, ""privacy"":{ ""jurisdiction"":""other"", ""id5_consent"":true } } Code 3. Example of data structure received from ID5 during a user’s ﬁrst visit. 1.3. Criteo. Criteo provides Criteo Identity Graph for iden- tity resolution [4]. Criteo Identity Graph is built from four different sources: (i) data contributed by advertisers, (ii) data collected from publisher websites by Criteo itself, (iii) data provided by Criteo partners such as LiveRamp and Oracle, (iv) and predictions on existing data by Criteo’s machine learning models. Criteo claims that its identity graph is able to stitch together identiﬁers from more than 2 billion users across the world, and that it contains persistent deterministic identiﬁers for 96% of the users [4]. Similar to other identity resolution services, Criteo generates an ID, based on identi- ﬁers, such as hashed emails, mobile device IDs, cookie IDs, and stores it in ﬁrst-party storage as cto_bundle. Their documentation shows that Criteo makes use of both ﬁrst- 17 Figure 10. This ﬁgure shows the ﬂow of information and identiﬁers through an identity graph for a cross-device attribution. The user visits sites 1, 2, and 3 via Device 1. The identity graph returns a U ID − 1 for all the site visits, using a probabilistic matching of ﬁngerprints F 1, F 2, and F 3 sent on each respective website. A Publisher Provided ID P P ID − 1 is also sent alongside F 3 when visiting site 3. The user visits sites 4, 5, and 6 through a new Device 2. Because the ﬁngerprints F 4 and F 5 are different from F 1, F 2, and F 3, the identity graph returns a new U ID − 2 for these site visits. On site 6, the website obtains and sends a Publisher Provided ID which matches P P ID − 1 provided on site 3. As a result, the identity graph matches and returns the existing user’s U ID − 1 for site 6. 18 Site 1 Site 2 Site 3 UID-1 UID-1 UID-1 Device 1 Cookie Stor e Site 1 Site 2 Site 3 F1 UI D-1 F2 UI D-1 F3+PPI D-1 UI D-1 F1 F4 F2 F3 + PPID-1 F6 + PPID-1 F5 Site 4 Site 5 Site 6 UID-2 UID-2 UID-1 Cookie Stor e Device 2 F4 UI D-2 F5 UI D-2 F6 + PPI D-1 UI D-1 Site 4 Site 5 Site 6","['g', 'u', 'cookiegraph', 'measuring', 'counter', 'firstparty', 'track', 'cookie', 'shaoor', 'englehardt', 'independent', 'researcher', 'sesenglehardtcom', 'shaﬁq', 'abstract', 'recent', 'privacy', 'protection', 'browser', 'vendor', 'aim', 'limit', 'abuse', 'thirdparty', 'cookie', 'crosssite', 'tracking', 'countermeasure', 'thirdparty', 'cookie', 'widely', 'welcome', 'concern', 'result', 'advertiser', 'tracker', 'abuse', 'ﬁrstparty', 'cookie', 'instead', 'provide', 'ﬁrst', 'empirical', 'evidence', 'ﬁrstparty', 'cookie', 'abuse', 'advertiser', 'tracker', 'conduct', 'differential', 'measurement', 'study', 'website', 'third', 'party', 'cookie', 'allow', 'block', 'advertiser', 'tracker', 'implement', 'crosssite', 'tracking', 'blocking', 'store', 'identiﬁer', 'base', 'probabilistic', 'deterministic', 'attribute', 'ﬁrstparty', 'cookie', 'oppose', 'thirdparty', 'cookie', 'cookie', 'blocking', 'practical', 'result', 'major', 'breakage', 'legitimate', 'website', 'functionality', 'propose', 'machine', 'learning', 'approach', 'accurately', 'robustly', 'detect', 'ﬁrstparty', 'tracking', 'cookie', 'cookiegraph', 'detect', 'ﬁrstparty', 'track', 'cook', 'ie', 'accuracy', 'outperform', 'stateoftheart', 'cookieblock', 'approach', 'show', 'cookie', 'graph', 'fully', 'robust', 'cookie', 'name', 'manipulation', 'cookieblock', 'accuracy', 'drop', 'also', 'show', 'cookiegraph', 'cause', 'major', 'breakage', 'cookieblock', 'cause', 'major', 'breakage', 'website', 'sso', 'login', 'deployment', 'cookiegraph', 'show', 'ﬁrstparty', 'tracking', 'cookie', 'use', 'website', 'also', 'prevalent', 'ﬁrstparty', 'tracking', 'cookie', 'set', 'major', 'advertising', 'entity', 'well', 'many', 'specialized', 'entity', 'criteo', 'introduction', 'browser', 'vendor', 'tracker', 'engage', 'arm', 'race', 'soon', 'browser', 'vendor', 'deploy', 'privacy', 'protec', 'tion', 'block', 'tracker', 'quickly', 'adapt', 'evade', 'cname', 'cloak', 'bounce', 'track', 'response', 'browser', 'vendor', 'develop', 'target', 'countermeasure', 'evasion', 'gain', 'advantage', 'browser', 'vendor', 'tracker', 'start', 'exploit', 'browser', 'feature', 'typically', 'use', 'functional', 'purpose', 'thus', 'trivially', 'block', 'abuse', 'javascript', 'build', 'identiﬁer', 'browser', 'ﬁngerprinte', 'abuse', 'ﬁrstparty', 'context', 'store', 'tracking', 'cookie', 'stand', 'prominent', 'technique', 'browser', 'vendor', 'largely', 'strug', 'gle', 'tracking', 'technique', 'prevent', 'require', 'compromise', 'functionality', 'new', 'tracking', 'technique', 'difﬁcult', 'counter', 'offer', 'ﬂexibility', 'thirdparty', 'cookie', 'crosssite', 'tracking', 'browser', 'ﬁngerprint', 'enable', 'crosssite', 'tracking', 'stable', 'time', 'hand', 'ﬁrstparty', 'cookie', 'stable', 'linkable', 'different', 'site', 'combine', 'however', 'browser', 'ﬁngerprint', 'ﬁrstparty', 'cookie', 'complement', 'er', 'shortcoming', 'enable', 'reliable', 'crosssite', 'tracking', 'speciﬁcally', 'tracker', 'able', 'leverage', 'nondeterministic', 'ﬁngerprint', 'ﬁrstparty', 'context', 'set', 'deterministic', 'ﬁrstparty', 'tracking', 'cookie', 'prior', 'literature', 'show', 'ﬁrstparty', 'cookie', 'set', 'third', 'party', 'script', 'exﬁltrate', 'track', 'endpoint', 'tracker', 'use', 'browser', 'ﬁngerprinte', 'respawn', 'ﬁrstparty', 'cookie', 'prior', 'work', 'demonstrate', 'ﬁrstparty', 'cookie', 'indeed', 'abuse', 'advertiser', 'tracker', 'countermeasure', 'pro', 'pose', 'speciﬁcally', 'block', 'ﬁrstparty', 'tracking', 'cookie', 'paper', 'investigate', 'ﬁrstparty', 'cookie', 'abuse', 'crosssite', 'tracking', 'use', 'ﬁnding', 'develop', 'machine', 'learn', 'base', 'countermeasure', 'cookiegraph', 'block', 'ﬁrstparty', 'tracking', 'cookie', 'end', 'ﬁrst', 'perform', 'differential', 'measure', 'ment', 'study', 'compare', 'ﬁrst', 'cookie', 'usage', 'crawl', 'website', 'third', 'party', 'cookie', 'enable', 'block', 'show', 'third', 'partycookie', 'blocking', 'signiﬁcantly', 'impact', 'sharing', 'identiﬁer', 'track', 'endpoint', 'tracker', 'use', 'reactively', 'shift', 'ﬁrstparty', 'cookie', 'cookie', 'block', 'speciﬁcally', 'entity', 'criteo', 'show', 'increase', 'presence', 'reactively', 'move', 'ﬁrstparty', 'cookie', 'cookie', 'block', 'analysis', 'reveal', 'store', 'identiﬁer', 'ﬁrstparty', 'cookie', 'base', 'probabilistic', 'deterministic', 'attribute', 'use', 'crosssite', 'tracking', 'thirdparty', 'cookie', 'block', 'ﬁrstparty', 'cook', 'ie', 'practical', 'lead', 'major', 'breakage', 'legitimate', 'website', 'functionality', 'privacyenhance', 'tent', 'blocking', 'tool', 'use', 'crowdsourced', 'ﬁlter', 'list', 'machine', 'learn', 'alternative', 'block', 'request', 'also', 'block', 'cookie', 'set', 'request', 'request', 'script', 'however', 'also', 'ﬁnd', 'evaluation', 'blocking', 'request', 'also', 'lead', 'breakage', 'likely', 'many', 'block', 'cookie', 'need', 'legitimate', 'website', 'functionality', 'searcher', 'recently', 'start', 'develop', 'approach', 'detect', 'block', 'tracking', 'cookie', 'ﬁrst', 'thirdparty', 'however', 'approach', 'rely', 'contentbase', 'feature', 'cookie', 'name', 'value', 'lead', 'high', 'number', 'false', 'positive', 'consequently', 'high', 'major', 'website', 'breakage', 'also', 'susceptible', 'evasion', 'keep', 'limitation', 'mind', 'design', 'plement', 'cookiegraph', 'machine', 'learn', 'approach', 'detect', 'ﬁrstparty', 'tracking', 'cookie', 'instead', 'use', 'content', 'base', 'feature', 'cookiegraph', 'capture', 'fundamental', 'track', 'e', 'behavior', 'exhibit', 'ﬁrstparty', 'cookie', 'discover', 'differential', 'measurement', 'study', 'cookie', 'graph', 'able', 'detect', 'ﬁrstparty', 'tracking', 'cookie', 'accuracy', 'outperform', 'stateoftheart', 'cook', 'approach', 'also', 'show', 'cookiegraph', 'cause', 'major', 'website', 'breakage', 'cookieblock', 'cause', 'major', 'breakage', 'website', 'sso', 'login', 'moreover', 'cookiegraph', 'robust', 'evasion', 'cookie', 'name', 'manipulation', 'cookieblock', 'accuracy', 'degrade', 'deployment', 'cookiegraph', 'website', 'show', 'ﬁrstparty', 'tracking', 'cookie', 'use', 'website', 'ﬁrstparty', 'track', 'cookie', 'set', 'thirdparty', 'script', 'serve', 'total', 'unique', 'domain', 'show', 'prevalent', 'ﬁrstparty', 'tracking', 'cookie', 'set', 'major', 'advertising', 'entity', 'well', 'many', 'specialized', 'entity', 'criteo', 'also', 'show', 'ﬁrstparty', 'tracking', 'cookie', 'set', 'script', 'serve', 'domain', 'involve', 'ﬁngerprinte', 'summary', 'key', 'contribution', 'follow', 'conduct', 'largescale', 'differential', 'measure', 'ment', 'study', 'understand', 'effectiveness', 'third', 'party', 'cookie', 'blocking', 'ﬁrstparty', 'cook', 'ie', 'use', 'lieu', 'thirdparty', 'cookie', 'design', 'implement', 'cookiegraph', 'learning', 'base', 'countermeasure', 'detect', 'block', 'ﬁrstparty', 'tracking', 'cookie', 'cookie', 'graph', 'capture', 'fundamental', 'tracking', 'behavior', 'ﬁrstparty', 'cookie', 'discover', 'mea', 'surement', 'study', 'outperform', 'stateofthe', 'art', 'term', 'accuracy', 'robustness', 'breakage', 'minimization', 'deploy', 'cookiegraph', 'website', 'sample', 'alexa', 'list', 'measure', 'prevalence', 'ﬁrstparty', 'tracking', 'cookie', 'detect', 'total', 'distinct', 'domain', 'set', 'party', 'tracking', 'cookie', 'include', 'major', 'advertising', 'entity', 'show', 'domain', 'know', 'ﬁngerprinter', 'set', 'ﬁrstparty', 'track', 'cookie', 'paper', 'organization', 'rest', 'paper', 'organize', 'follow', 'section', 'provide', 'overview', 'recent', 'development', 'thirdparty', 'ﬁrstparty', 'cookie', 'base', 'tracking', 'countermeasure', 'section', 'evaluate', 'effec', 'tiveness', 'blocking', 'reduce', 'tracking', 'activity', 'measure', 'extent', 'ﬁrstparty', 'cookie', 'abuse', 'advertiser', 'tracker', 'section', 'describe', 'design', 'evaluation', 'cookiegraph', 'discuss', 'limitation', 'cookiegraph', 'section', 'conclude', 'section', 'background', 'relate', 'work', 'adoption', 'thirdparty', 'cookie', 'tracking', 'cookie', 'originally', 'design', 'recognize', 'return', 'user', 'eg', 'maintain', 'virtual', 'shopping', 'cart', 'quickly', 'adopt', 'thirdpartie', 'track', 'user', 'website', 'eg', 'serve', 'target', 'ad', 'early', 'dardization', 'effort', 'mostly', 'focus', 'limit', 'unintended', 'cookie', 'sharing', 'domain', 'wellknown', 'privacy', 'concern', 'largely', 'ignore', 'intentional', 'misuse', 'cookie', 'thirdpartie', 'crosssite', 'tracking', 'year', 'use', 'thirdparty', 'cookie', 'crosssite', 'tracking', 'become', 'increasingly', 'prevalent', 'prior', 'research', 'find', 'vast', 'majority', 'third', 'party', 'cookie', 'set', 'advertising', 'tracking', 'service', 'thirdparty', 'cookie', 'ﬁrstparty', 'cookie', 'factor', 'contain', 'identiﬁer', 'countermeasure', 'cookie', 'inception', 'block', 'thirdparty', 'cookie', 'domain', 'visit', 'user', 'fullﬂedge', 'website', 'strengthen', 'cookie', 'block', 'introduce', 'intelligent', 'tracking', 'prevention', 'itp', 'use', 'machine', 'learning', 'automatically', 'detect', 'thirdparty', 'tracker', 'revoke', 'storage', 'access', 'domain', 'user', 'interact', 'daily', 'basis', 'hour', 'period', 'go', 'several', 'iteration', 'itp', 'itp', 'itp', 'itp', 'eventually', 'lead', 'full', 'cookie', 'block', 'firefox', 'experiment', 'blocking', 'ship', 'default', 'blocking', 'release', 'enhanced', 'tracking', 'protection', 'etp', 'etp', 'block', 'party', 'cookie', 'base', 'blocklist', 'tracker', 'provide', 'disconnect', 'firefox', 'launch', 'total', 'cookie', 'protection', 'tpc', 'partition', 'cookie', 'access', 'partition', 'ensure', 'cookie', 'set', 'thirdparty', 'site', 'distinct', 'set', 'thirdparty', 'website', 'eliminate', 'third', 'party', 'ability', 'track', 'user', 'website', 'internet', 'explorer', 'microsoft', 'edge', 'mainstream', 'browser', 'deploy', 'countermea', 'thirdparty', 'cookie', 'internet', 'sure', 'edge', 'permissive', 'protection', 'block', 'thirdparty', 'cookie', 'domain', 'specify', 'cookie', 'usage', 'policy', 'response', 'header', 'however', 'website', 'owner', 'often', 'misrepresent', 'cookie', 'usage', 'police', 'render', 'p3p', 'ineffective', 'edge', 'block', 'access', 'cookie', 'storage', 'thirdparty', 'context', 'tracker', 'base', 'disconnect', 'track', 'protection', 'list', 'chrome', 'chrome', 'mainstream', 'browser', 'restrict', 'thirdparty', 'cookie', 'way', 'default', 'mode', 'announce', 'plan', 'phase', 'thirdparty', 'cookie', 'chrome', 'however', 'plan', 'postpone', 'several', 'time', 'late', 'timeline', 'suggest', 'phasing', 'cookie', 'late', 'google', 'also', 'announce', 'plan', 'implement', 'privacypreserving', 'version', 'advertising', 'use', 'case', 'cur', 'rently', 'depend', 'cookie', 'include', 'behavioral', 'ad', 'targeting', 'ad', 'attributionmeasurement', 'adoption', 'ﬁrstparty', 'cookie', 'tracking', 'thirdparty', 'cookie', 'widely', 'consider', 'main', 'mechanism', 'crosssite', 'tracking', 'tracker', 'also', 'rely', 'ﬁrstparty', 'cookie', 'tracking', 'early', 'roesner', 'note', 'thirdparty', 'track', 'script', 'embed', 'main', 'webpage', 'ie', 'ﬁrstparty', 'context', 'set', 'ﬁrstparty', 'cookie', 'recently', 'fouad', 'find', 'tracker', 'sync', 'ﬁrstparty', 'cookie', 'several', 'thirdpartie', 'many', 'website', 'find', 'website', 'contain', 'least', 'ﬁrstparty', 'cookie', 'set', 'thirdparty', 'script', 'similar', 'fouad', 'also', 'find', 'least', 'ﬁrstparty', 'cookie', 'exﬁltrate', 'thirdparty', 'domain', 'half', 'test', 'web', 'site', 'raise', 'concern', 'cookie', 'use', 'track', 'concern', 'also', 'echo', 'sanchez', 'uncover', 'several', 'instance', 'different', 'thirdpartie', 'interact', 'ﬁrstparty', 'cookie', 'conclude', 'large', 'scale', 'measurement', 'study', 'top', 'website', 'number', 'case', 'study', 'even', 'block', 'thirdparty', 'cookie', 'user', 'still', 'risk', 'track', 'ﬁrstparty', 'cookie', 'prior', 'study', 'identiﬁe', 'use', 'ﬁrstparty', 'cookie', 'tracker', 'solely', 'focus', 'study', 'e', 'ﬁrstparty', 'track', 'cookie', 'fact', 'measurement', 'infrastructure', 'design', 'capture', 'track', 'conﬁgure', 'ﬁrstparty', 'cookie', 'example', 'browser', 'block', 'thirdparty', 'cookie', 'instigate', 'tracker', 'use', 'ﬁrstparty', 'cookie', 'track', 'technique', 'use', 'set', 'ﬁrstparty', 'cookie', 'non', 'trivial', 'generate', 'ﬁrstparty', 'identiﬁer', 'accessible', 'website', 'prior', 'research', 'find', 'tracker', 'often', 'leverage', 'browser', 'ﬁngerprinte', 'generate', 'ﬁrstparty', 'track', 'ing', 'cookie', 'browser', 'ﬁngerprinting', 'provide', 'unique', 'identiﬁer', 'accessible', 'website', 'drift', 'time', 'however', 'identiﬁer', 'generate', 'browser', 'ﬁngerprinting', 'store', 'cookie', 'persist', 'even', 'ﬁngerprint', 'change', 'addition', 'browser', 'ﬁngerprinte', 'several', 'advertising', 'tracking', 'service', 'ad', 'manager', 'specify', 'docu', 'mentation', 'also', 'use', 'publisher', 'provide', 'identiﬁer', 'ppid', 'email', 'address', 'set', 'ﬁrstparty', 'cookie', 'cname', 'cloaking', 'also', 'allow', 'advertiser', 'tracker', 'use', 'ﬁrstparty', 'cookie', 'paper', 'focus', 'cname', 'cloaking', 'leak', 'cname', 'cloaking', 'already', 'extensively', 'study', 'prior', 'work', 'countermeasure', 'ﬁrstparty', 'cookie', 'deploy', 'countermeasure', 'main', 'stream', 'browser', 'deploy', 'protection', 'party', 'track', 'itp', 'expire', 'ﬁrstparty', 'cook', 'ie', 'storage', 'set', 'script', 'day', 'user', 'interact', 'website', 'ﬁrstparty', 'cookie', 'limit', 'lower', 'hour', 'detect', 'link', 'decoration', 'use', 'track', 'however', 'cookie', 'tracking', 'require', 'link', 'decoration', 'effective', 'case', 'link', 'decoration', 'use', 'tracker', 'still', 'track', 'user', 'window', 'user', 'interact', 'website', 'window', 'countermeasure', 'propose', 'prior', 'research', 'recently', 'researcher', 'propose', 'machine', 'learning', 'base', 'approach', 'detect', 'ﬁrstparty', 'thirdparty', 'tracking', 'cookie', 'develop', 'machine', 'learning', 'base', 'approach', 'use', 'substring', 'cookie', 'name', 'track', 'gdpr', 'feature', 'detect', 'ﬁrstparty', 'thirdparty', 'track', 'ing', 'cookie', 'bolling', 'also', 'develop', 'machine', 'learning', 'approach', 'cookieblock', 'use', 'several', 'cookie', 'attribute', 'domain', 'name', 'name', 'path', 'value', 'expiration', 'feature', 'detect', 'ﬁrstparty', 'thirdparty', 'track', 'cookie', 'however', 'rely', 'e', 'hardcoded', 'content', 'feature', 'make', 'approach', 'susceptible', 'adversarial', 'evasion', 'show', 'later', 'section', 'moreover', 'approach', 'mainly', 'rely', 'selfdisclose', 'cookie', 'label', 'ground', 'truth', 'know', 'unreliable', 'request', 'block', 'approach', 'request', 'block', 'browser', 'extension', 'adblock', 'machine', 'learning', 'base', 'tracker', 'detection', 'approach', 'propose', 'prior', 'research', 'potentially', 'block', 'ﬁrstparty', 'tracking', 'cookie', 'however', 'request', 'blocking', 'inherently', 'prone', 'cause', 'breakage', 'later', 'show', 'section', 'block', 'access', 'content', 'cookie', 'essential', 'website', 'functionality', 'focus', 'paper', 'conclusion', 'prior', 'work', 'incidentally', 'measure', 'usage', 'ﬁrstparty', 'tracking', 'cook', 'ie', 'exist', 'approach', 'detect', 'ﬁrstparty', 'cookie', 'lack', 'paper', 'ﬁll', 'void', 'conduct', 'large', 'scale', 'study', 'measure', 'prevalence', 'ﬁrstparty', 'track', 'cookie', 'develop', 'accurate', 'robust', 'machine', 'learn', 'e', 'approach', 'call', 'cookiegraph', 'purposebuilt', 'detect', 'ﬁrstparty', 'cookie', 'measurement', 'section', 'present', 'measurement', 'study', 'understand', 'usage', 'ﬁrstparty', 'cookie', 'advertising', 'tracking', 'service', 'cookie', 'block', 'end', 'conduct', 'web', 'crawl', 'thirdparty', 'cookie', 'analyze', 'difference', 'tracking', 'activity', 'sharing', 'identiﬁer', 'known', 'adverting', 'tracking', 'service', 'observe', 'crawl', 'understand', 'effectiveness', 'blocking', 'ﬁrstparty', 'cookie', 'use', 'lieu', 'datum', 'collection', 'methodology', 'datum', 'collection', 'use', 'openwpm', 'crawl', 'site', 'list', 'ensure', 'crawl', 'contain', 'representative', 'site', 'different', 'popularity', 'crawl', 'top', 'site', 'randomly', 'sample', 'site', 'long', 'tail', 'site', 'rank', 'ensure', 'intrapage', 'diversity', 'landing', 'internal', 'page', 'perform', 'interactive', 'crawl', 'speciﬁcally', 'site', 'crawl', 'landing', 'page', 'sample', 'anchor', 'tag', 'landing', 'page', 'uniformly', 'random', 'crawl', 'get', 'sample', 'internal', 'page', 'conduct', 'crawl', 'thirdparty', 'cookie', 'enable', 'thirdparty', 'cookie', 'block', 'conduct', 'crawl', 'simultaneously', 'minimize', 'temporal', 'variation', 'site', 'crawls1', 'deﬁnition', 'ﬁrst', 'cookie', 'cookie', 'set', 'browser', 'way', 'set', 'header', 'use', 'javascript', 'cookie', 'far', 'classiﬁe', 'thirdparty', 'cookie', 'set', 'response', 'header', 'different', 'domain', 'ﬁrstparty', 'ﬁrstparty', 'thirdparty', 'cookie', 'classiﬁcation', 'cookie', 'set', 'script', 'depend', 'script', 'embed', 'ﬁrst', 'thirdparty', 'execution', 'context', 'cookie', 'set', 'third', 'party', 'script', 'run', 'ﬁrstparty', 'context', 'ﬁrstparty', 'cookie', 'cookie', 'set', 'thirdparty', 'script', 'run', 'thirdparty', 'context', 'thirdparty', 'iframe', 'thirdparty', 'cookie', 'label', 'tracking', 'activity', 'use', 'easylist', 'easyprivacy', 'label', 'request', 'track', 'figure', 'average', 'number', 'request', 'site', 'conﬁguration', 'nonat', 'request', 'request', 'identiﬁer', 'request', 'identiﬁer', 'tracking', 'nonats2', 'basic', 'premise', 'tracking', 'identify', 'user', 'particularly', 'interested', 'sharing', 'identiﬁer', 'tracking', 'request', 'end', 'line', 'prior', 'work', 'deﬁne', 'identiﬁer', 'string', 'long', 'character', 'match', 'regex', '−', '−', 'z0', '−', 'use', 'deﬁnition', 'look', 'identiﬁer', 'url', 'query', 'parameter', 'cookie', 'value', 'tracking', 'block', 'thirdparty', 'cookie', 'ﬁrst', 'study', 'block', 'thirdparty', 'cookie', 'fectively', 'eliminate', 'request', 'end', 'compare', 'number', 'request', 'cookie', 'figure', 'plot', 'number', 'request', 'thirdparty', 'cookie', 'see', 'figure', 'cookie', 'block', 'modest', 'reduction', 'overall', 'number', 'request', 'reduction', 'number', 'request', 'contain', 'identiﬁer', 'surprising', 'cookie', 'syncing', 'widely', 'use', 'crosssite', 'tracking', 'entail', 'share', 'thirdparty', 'cookie', 'query', 'parameter', 'thirdparty', 'cookie', 'block', 'cookie', 'sync', 'thirdpartie', 'occur', 'expect', 'see', 'large', 'drop', 'identiﬁer', 'share', 'request', 'address', 'surprising', 'observation', 'section', 'next', 'analyze', 'block', 'disparately', 'impact', 'different', 'domain', 'etld1', 'fig', 'ure', 'plot', 'percentage', 'site', 'least', 'request', 'identiﬁer', 'prevalent', 'domain', 'crawl', 'note', 'domain', 'negligible', 'success', 'rate', 'crawl', 'form', '10k', 'site', 'visit', 'successfully', 'crawl', 'label', 'request', 'track', 'url', 'match', 'rule', 'list', 'otherwise', 'label', 'track', 'nonat', 'e', 'q', 'e', 'r', 'r', 'e', 'u', 'n', 'e', 'g', 'r', 'e', 'decrease', 'decrease', 'decrease', 'cookie', 'enable', 'cookie', 'block', 'figure', 'presence', 'tracking', 'domain', 'plot', 'show', 'percentage', 'site', 'least', 'request', 'send', 'tracking', 'domain', 'include', 'criteonet', 'peculiar', 'increase', 'presence', 'block', 'third', 'party', 'cookie', 'thirdparty', 'cookie', 'allow', 'thirdparty', 'cookie', 'block', 'figure', 'comparison', 'percentage', 'site', 'third', 'party', 'identiﬁer', 'cookie', 'set', 'domain', 'ﬁrstparty', 'cookie', 'set', 'cookie', 'allow', 'ﬁrstparty', 'cookie', 'set', 'cookie', 'block', 'thirdparty', 'cookie', 'set', 'cookie', 'allow', 'tracking', 'firstparty', 'cookie', 'figure', 'show', 'request', 'contain', 'identiﬁer', 'even', 'thirdparty', 'cookie', 'block', 'clear', 'identiﬁer', 'request', 'likely', 'originate', 'storage', 'mechanism', 'third', 'party', 'cookie', 'recent', 'prior', 'work', 'show', 'atse', 'increasingly', 'use', 'ﬁrstparty', 'cookie', 'next', 'investigate', 'ﬁrstparty', 'cookie', 'use', 'lieu', 'thirdparty', 'cookie', 'ﬁrst', 'compare', 'average', 'number', 'ﬁrstparty', 'cook', 'ie', 'crawl', 'figure', 'observe', 'minor', 'difference', 'average', 'number', 'ﬁrstparty', 'cookie', 'set', 'script', 'nonat', 'matter3', 'however', 'noteworthy', 'ﬁrstparty', 'cookie', 'set', 'script', 'far', 'cookie', 'demonstrate', 'overwhelming', 'number', 'ﬁrstparty', 'cookie', 'fact', 'set', 'atse', 'next', 'compare', 'setting', 'ﬁrst', 'thirdparty', 'cookie', 'domain', 'etld1', 'setting', 'script', 'understand', 'ﬁrstparty', 'cookie', 'usage', 'equally', 'prevalent', 'different', 'atse', 'figure', 'plot', 'percentage', 'site', 'least', 'ﬁrstparty', 'set', 'domain', 'criteo', 'divide', 'criteonet', 'first', 'observe', 'googleowne', 'domain', 'show', 'negligible', 'difference', 'request', 'contain', 'identi', 'ﬁer', 'block', 'thirdparty', 'cookie', 'also', 'little', 'change', 'use', 'ﬁrstparty', 'cookie', 'label', 'script', 'nonat', 'base', 'src', 'url', 'section', 'figure', 'breakdown', 'average', 'number', 'ﬁrstparty', 'cookie', 'site', 'set', 'block', 'thirdparty', 'cookie', 'cookie', 'set', 'nontracke', 'source', 'nonidentiﬁer', 'cookie', 'set', 'track', 'source', 'identiﬁer', 'cookie', 'set', 'track', 'source', 'reduction', 'number', 'request', 'identiﬁer', 'cookie', 'block', 'contrast', 'domain', 'pubmatic', 'rubicon', 'show', 'almost', 'reduction', 'criteo', 'exhibit', 'interesting', 'behav', 'ior', 'request', 'send', 'criteo', 'divide', 'domain', 'criteonet', 'show', 'negligible', 'change', 'crawl', 'criteonet', 'crease', 'attempt', 'well', 'understand', 'reason', 'disparate', 'impact', 'different', 'domain', 'e', 'googleco', 'googletag', 'e', 'c', 'p', 'r', 'e', 'u', 'n', 'e', 'g', 'r', 'e', 'increase', 'decrease', 'increase', 'cookie', 'enable', 'cookie', 'block', 'e', 'googleco', 'googletag', 'criteonet', 'table', 'cookie', 'show', 'high', 'ratio', 'new', 'appearance', 'block', 'name', 'sq', 'stripe', 'stripe', 'sid', 'script', 'domain', 'new', 'appearance', 'total', 'appearance', 'ratio', 'criteocom', 'crwdcntrlnet', 'block', 'quantify', 'shift', 'ratio', 'tween', 'number', 'site', 'ﬁrstparty', 'cookie', 'present', '3pallowe', 'crawl', 'number', 'new', 'site', 'ﬁrstparty', 'cookie', 'present', 'crawl', 'ble', 'show', 'identiﬁer', 'cookie', 'base', 'dominate', 'note', 'know', 'adtech', 'organization', 'criteo', 'ctobundle', 'pbjsunifiedid', 'pbjsid5id', 'panoramaid', 'ccid', 'far', 'investigate', 'havior', 'cookie', 'use', 'publicly', 'available', 'docu', 'mentation', 'list', 'crosssite', 'tracking', 'firstparty', 'cookie', 'analysis', 'criteo', 'reveal', 'common', 'approach', 'use', 'ﬁrstparty', 'cookie', 'crosssite', 'tracking', 'build', 'identity', 'graph', 'figure', 'ﬁgure', 'show', 'ﬂow', 'information', 'identiﬁer', 'identity', 'graph', 'crosssite', 'attribution', 'initially', 'user', 'visit', 'site', 'tracker', 'site', 'collect', 'send', 'ﬁngerprint', 'identity', 'graph', 'identity', 'graph', 'return', 'u', 'site', 'visit', 'use', 'probabilistic', 'matching', 'ﬁngerprint', 'send', 'respective', 'website', 'publisher', 'provide', 'p', 'also', 'send', 'visit', 'site', 'user', 'visit', 'site', 'send', 'ﬁngerprint', 'ﬁngerprint', 'different', 'identity', 'graph', 'create', 'probabilistic', 'match', 'site', 'site', 'website', 'obtain', 'send', 'publisher', 'provide', 'match', 'p', 'p', 'provide', 'site', 'result', 'identity', 'graph', 'match', 'return', 'exist', 'user', 'site', 'use', 'deterministic', 'matching', 'id', 'store', 'ﬁrstparty', 'cookie', 'user', 'device', 'figure', 'percentage', 'site', 'ﬁrstparty', 'cookie', 'show', 'block', 'ﬁrstparty', 'cookie', 'cookie', 'allow', 'thirdparty', 'cookie', 'block', 'crawl', 'domain', 'set', 'large', 'number', 'thirdparty', 'cookie', 'likely', 'explain', 'impact', 'block', 'second', 'set', 'domain', 'pubmatic', 'rubicon', 'openx', 'disproportionately', 'use', 'thirdparty', 'identiﬁer', 'cookie', 'ﬁrstparty', 'cookie', 'observation', 'explain', 'drastic', 'drop', 'number', 'request', 'contain', 'identiﬁer', 'domain', 'block', 'third', 'party', 'cookie', 'figure', 'set', 'cookie', 'finally', 'far', 'investigate', 'criteo', 'show', 'peculiar', 'behavior', 'figure', 'recall', 'criteo', 'use', 'criteonet', 'ﬁrstparty', 'cookie', 'set', 'former', 'show', 'increase', 'block', 'thirdparty', 'cookie', 'latter', 'change', 'addition', 'criteocom', 'also', 'use', 'set', 'thirdparty', 'cookie', 'criteonet', 'set', 'cookie', 'domain', 'set', 'ctobundle', 'cookie', 'compare', 'ctobundle', 'cookie', 'set', 'atse', 'plot', 'percentage', 'site', 'cookie', 'name', 'appear', 'figure', 'plot', 'prevalence', 'ﬁrstparty', 'cookie', 'cookie', 'note', 'cookie', 'witness', 'slight', 'drop', 'prevalence', 'block', 'thirdparty', 'cookie', 'hold', 'true', 'ctobundle', 'fact', 'ctobundle', '’s', 'prevalence', 'increase', 'block', 'third', 'party', 'cookie', 'accordance', 'unexpected', 'increase', 'total', 'number', 'ﬁrstparty', 'cookie', 'set', 'script', 'belong', 'aforementioned', 'increase', 'use', 'ﬁrstparty', 'cookie', 'represent', 'interesting', 'scenario', 'tracker', 'reac', 'tively', 'shift', 'ﬁrstparty', 'cookie', 'cookie', 'e', 'ga', 'gad', 'fbp', 'uetsid', 'test', 'p', 'ps', 'cto', 'cf', 'utm', 'b', 'uid', 'utm', 'ptanonc', 'onsent', 'consentdata', 'userid', 'pbjs', 'site', 'site', 'site', 'site', 'f1', 'ui', 'd1', 'd1', 'd1', 'd1', 'd1', 'd1', 'ppi', 'd1', 'ppi', 'd1', 'identiﬁer', 'particular', 'user', 'use', 'different', 'party', 'information', 'collect', 'different', 'site', 'node', 'represent', 'user', 'device', 'web', 'browser', 'base', 'different', 'attribute', 'edge', 'node', 'form', 'base', 'deterministic', 'probabilistic', 'match', 'ing', 'attribute', 'pair', 'node', 'crosssite', 'tracking', 'need', 'establish', 'edge', 'different', 'node', 'actually', 'represent', 'userdevice', 'identity', 'graph', 'note', 'tracker', 'simply', 'use', 'third', 'party', 'identiﬁer', 'cookie', 'block', 'tracker', 'typically', 'use', 'type', 'information', 'build', 'identity', 'graph', 'gather', 'information', 'provide', 'publisher', 'include', 'deterministic', 'attribute', 'eg', 'email', 'phone', 'username', 'publisherprovided', 'ppid', 'directly', 'use', 'identiﬁcation', 'probabilistic', 'attribute', 'zip', 'code', 'city', 'age', 'use', 'together', 'nondeterministic', 'identiﬁcation', 'typically', 'also', 'gather', 'probabilistic', 'information', 'ip', 'address', 'ﬁngerprinting', 'attribute', 'browser', 'operating', 'system', 'information', 'eg', 'name', 'speciﬁc', 'version', 'device', 'property', 'eg', 'display', 'resolution', 'screen', 'orientation', 'link', 'different', 'node', 'identity', 'graph', 'eg', 'link', 'user', 'different', 'site', 'link', 'different', 'device', 'user', 'example', 'show', 'different', 'user', 'device', 'link', 'show', 'b', 'use', 'probabilistic', 'deterministic', 'matching', 'show', 'detail', 'figure', 'probabilistic', 'matching', 'measure', 'similarity', 'probabilistic', 'attribute', 'determine', 'match', 'similarity', 'reasonably', 'high', 'represent', 'gray', 'edge', 'figure', 'deterministic', 'matching', 'exactly', 'match', 'deterministic', 'attribute', 'represent', 'black', 'edge', 'figure', 'link', 'establish', 'tracker', 'store', 'identiﬁer', 'ﬁrstparty', 'cookie', 'uniquely', 'represent', 'user', 'different', 'site', 'device', 'differential', 'measurement', 'study', 'reveal', 'block', 'thirdparty', 'cookie', 'insufﬁcient', 'prevent', 'tracking', 'minimal', 'decrease', 'number', 'request', 'share', 'identiﬁer', 'cookie', 'block', 'however', 'impact', 'blocking', 'uniform', 'different', 'atse', 'domain', 'googleanalyticscom', 'doubleclicknet', 'show', 'change', 'tracking', 'request', 'show', 'decrease', 'yet', 'criteonet', 'show', 'increase', 'ﬁnd', 'ﬁrstparty', 'cookie', 'predominantly', 'use', 'atse', 'lieu', 'third', 'party', 'cookie', 'perform', 'track', 'domain', 'use', 'ﬁrstparty', 'cookie', 'hence', 'impact', 'block', 'domain', 'use', 'thirdparty', 'cookie', 'reactively', 'shift', 'use', 'ﬁrstparty', 'cookie', 'cookie', 'block', 'atse', 'rely', 'combination', 'deterministic', 'probabilistic', 'attribute', 'build', 'identity', 'graph', 'use', 'ﬁrstparty', 'cookie', 'store', 'identiﬁer', 'use', 'crosssite', 'tracking', 'next', 'present', 'approach', 'accurately', 'robustly', 'detect', 'ﬁrstparty', 'cookie', 'cookiegraph', 'detect', 'track', 'cookie', 'firstparty', 'section', 'describe', 'cookiegraph', 'graph', 'base', 'machine', 'learning', 'approach', 'detect', 'ﬁrstparty', 'cookie', 'cookiegraph', 'create', 'graph', 'representation', 'webpage', '’s', 'execution', 'base', 'javascript', 'storage', 'information', 'collect', 'instru', 'mente', 'browser', 'ﬁrstparty', 'cookie', 'represent', 'storage', 'node', 'cookiegraph', 'extract', 'distinguish', 'feature', 'cookie', 'use', 'random', 'forest', 'classiﬁer', 'detect', 'ﬁrstparty', 'cookie', 'figure', 'provide', 'overview', 'pipeline', 'design', 'implementation', 'browser', 'instrumentation', 'cookiegraph', 'rely', 'extended', 'version', 'openwpm', 'capture', 'webpage', 'ex', 'ecution', 'information', 'javascript', 'storage4', 'layer', 'web', 'stack', 'speciﬁcally', 'cookie', 'graph', 'capture', 'element', 'create', 'script', 'net', 'work', 'request', 'send', 'element', 'parse', 'script', 'response', 'receive', 'identiﬁer', 'network', 'requestsresponse', 'readwrite', 'operation', 'storage', 'mechanism', 'graph', 'construction', 'node', 'graph', 'represent', 'element', 'network', 'request', 'script', 'storage', 'element', 'localstorage', 'ﬁrstparty', 'cookie', 'node', 'share', 'exact', 'name', 'cookiegraph', 'consider', 'storage', 'node', 'edge', 'represent', 'wide', 'range', 'interaction', 'different', 'type', 'node', 'eg', 'script', 'send', 'http', 'request', 'script', 'set', 'cookie', 'addition', 'interaction', 'consider', 'prior', 'work', 'cookiegraph', 'incorporate', 'edge', 'capture', 'tracking', 'behavior', 'ﬁrstparty', 'cookie', 'inform', 'ﬁnding', 'section', 'cookie', 'typically', 'set', 'value', 'inﬁltrate', 'http', 'response', 'exﬁltrate', 'parame', 'ter', 'request', 'header', 'body', 'cookiegraph', 'capture', 'inﬁltration', 'exﬁltration', 'link', 'scriptreadwrite', 'cookie', 'ﬁrstparty', 'execution', 'context', 'request', 'readerwriter', 'script', 'contain', 'cookie', 'value', 'addition', 'plain', 'text', 'cookie', 'value', 'cookiegraph', 'also', 'monitor', 'base64', 'md5', 'sha1', 'encode', 'cookie', 'value', 'header', 'request', 'response', 'bod', 'ie', 'measurement', 'study', 'focus', 'identiﬁer', 'cookiegraph', 'capture', 'cookie', 'value', 'least', 'character', 'long', 'illustrate', 'difference', 'graph', 'representation', 'prior', 'work', 'measurement', 'section', 'find', 'signiﬁcant', 'use', 'localstorage', 'addition', 'cookie', 'thus', 'use', 'term', 'storage', 'refer', 'cookie', 'localstorage', 'case', 'description', 'cookie', 'also', 'applicable', 'localstorage', 'vice', 'versa', 'figure', 'overview', 'cookiegraph', 'pipeline', 'webpage', 'crawl', 'use', 'instrumented', 'browser', 'construction', 'graph', 'representation', 'represent', 'instrumented', 'webpage', 'execution', 'information', 'feature', 'extraction', 'graph', 'node', 'represent', 'ﬁrstparty', 'cookie', 'classiﬁer', 'training', 'detect', 'ﬁrstparty', 'cookie', 'graph', 'representation', 'code', 'webgraph', 'graph', 'representation', 'code', 'cookiegraph', 'figure', 'graph', 'representation', 'code', 'webgraph', 'cookiegraph', 'represent', 'node', 'node', 'number', 'correspond', 'line', 'code', 'figure', 'dash', 'dot', 'line', 'represent', 'additional', 'edge', 'capture', 'cookiegraph', 'miss', 'webgraph', 'grey', 'dash', 'line', 'show', 'different', 'representation', 'event', 'system', 'represent', 'script', 'node', 'represent', 'network', 'node', 'use', 'example', 'script', 'involve', 'ﬁrstparty', 'cook', 'ie', 'code', 'show', 'thirdparty', 'script', 'execute', 'party', 'context', 'webpage', 'script', 'read', 'infocookie', 'store', 'track', 'information', 'publisher', 'user', 'signature', 'send', 'content', 'cookie', 'endpoint', 'http', 'post', 'request', 'endpoint', 'return', 'user', 'response', 'body', 'store', 'ﬁrstparty', 'cookie', 'localstorage', 'name', 'idstore', 'late', 'point', 'script', 'exﬁltrate', 'uid', 'tracking', 'endpoint', 'url', 'parameter', 'http', 'header', 'request', 'response', 'result', 'code', 'list', 'list', 'figure', 'show', 'difference', 'graph', 'rep', 'resentation', 'script', 'create', 'prior', 'work', 'webgraph', 'leave', 'cookiegraph', 'right', 'webgraph', 'cap', 'ture', 'inﬁltration', 'uid', 'cookie', 'response', 'body', 'also', 'consider', 'inﬁltration', 'ﬁltration', 'localstorage', 'contrast', 'dotted', 'dash', 'line', 'figure', 'show', 'cookiegraph', 'capture', 'inﬁltration', 'exﬁltration', 'subsequent', 'network', 'request', 'moreover', 'webgraph', 'capture', 'exﬁltration', 'url', 'parameter', 'show', 'dash', 'line', 'edge', 'setting', 'script', 'endpoint', 'cookiegraph', 'able', 'precisely', 'link', 'exﬁltration', 'ﬁrstparty', 'cookie', 'edge', 'cookie', 'node', 'endpoint', 'feature', 'extraction', 'use', 'tion', 'extract', 'structural', 'information', 'ﬂow', 'feature', 'structural', 'feature', 'represent', 'relationship', 'node', 'graph', 'ancestry', 'information', 'connectivity', 'feature', 'capture', 'relationship', 'cookie', 'node', 'script', 'page', 'example', 'many', 'script', 'interact', 'cookie', 'script', 'interact', 'cookie', 'also', 'interact', 'cookie', 'flow', 'feature', 'represent', 'cookie', 'behavior', 'extract', 'type', 'feature', 'first', 'count', 'number', 'time', 'cookie', 'read', 'write', 'second', 'number', 'time', 'cookie', 'inﬁltrate', 'count', 'exﬁltrate', 'method', 'explain', 'previous', 'section', 'third', 'calculate', 'feature', 'respect', 'setter', 'cookie', 'concretely', 'setter', 'domain', 'also', 'act', 'endpoint', 'cookie', 'exﬁltration', 'setter', 'domain', 'involve', 'redirect', 'chain', 'redirect', 'commonly', 'use', 'track', 'intuition', 'third', 'category', 'feature', 'domain', 'webpage', 'l', 'u', 'n', 'g', 'open', 'pm', 'r', 'h', 'r', 'dpar', 'ock', 'e', 'eat', 'r', 'e', 'r', 'act', 'g', 'u', 'si', 'l', 'cook', 'epedi', 'pr', 'ocess', 'l', 'aph', 'esen', 'page', 'ex', 'ecu', 'e', 'cl', 'cat', 'script', 'storage', 'access', 'cookie', 'cookie', 'local', 'storage', 'request', 'tracker1comsync', 'request', 'request', 'script', 'storage', 'access', 'cookie', 'cookie', 'local', 'storage', 'exfiltration', 'tracker', 'infiltration', 'response', 'body', 'request', 'tracker1comsync', 'request', 'request', 'table', 'cookiegraph', 'feature', 'comparison', 'indicate', 'feature', 'present', 'indicate', 'feature', 'extend', 'cookiegraph', 'cookiegraph', 'calculate', 'graph', 'size', 'degree', 'centrality', 'feature', 'use', 'normal', 'share', 'information', 'edge', 'former', 'come', 'structural', 'feature', 'latter', 'come', 'flow', 'feature', 'feature', 'type', 'cookiegraph', 'webgraph', 'graph', 'size', 'node', 'edge', 'nodesedge', 'ratio', 'degree', 'inout', 'average', 'degree', 'connectivity', 'centrality', 'closeness', 'centrality', 'eccentricity', 'attribute', 'descendant', 'script', 'ascendant', '’s', 'script', 'property', 'parent', 'script', 'local', 'storage', 'access', 'set', 'get', 'cookie', 'access', 'set', 'get', 'storage', 'access', 'local', 'storage', 'name', 'set', 'get', 'request', 'send', 'receive', 'redirect', 'send', 'receive', 'depth', 'chain', 'common', 'access', 'storage', 'inﬁltration', 'setter', 'exﬁltration', 'redirect', 'graph', 'size', 'node', 'edge', 'nodesedge', 'ratio', 'degree', 'inout', 'average', 'degree', 'connectivity', 'centrality', 'closeness', 'centrality', 'eccentricity', 'structure', 'structure', 'structure', 'structure', 'structure', 'structure', 'structure', 'flow', 'flow', 'flow', 'flow', 'flow', 'flow', 'flow', 'flow', 'flow', 'flow', 'flow', 'flow', 'script', 'true', 'idstore', 'response', 'response', 'var', 'exfilreq1openget', 'var', 'exfilreq2openget', 'request', 'url', 'datum', 'signaturexyz', 'response', 'status', 'content', 'request', 'url', 'tracker2comuseridabcd', 'response', 'status', 'request', 'header', 'idheader', 'abcd', 'url', 'response', 'status', 'script', 'code', 'script', 'third', 'execute', 'party', 'context', 'script', 'obtain', 'uid', 'sync', 'point', 'store', 'exﬁltrate', 'involve', 'set', 'ﬁrstparty', 'cookie', 'also', 'involve', 'share', 'information', 'atse', 'table', 'show', 'difference', 'feature', 'cookiegraph', 'webgraph', 'cookiegraph', 'add', 'prove', 'cookie', 'exﬁltration', 'feature', 'also', 'introduce', 'new', 'complete', 'new', 'set', 'inﬁltration', 'setter', 'feature', 'cookiegraph', 'also', 'consider', 'case', 'localstorage', 'share', 'name', 'cookie', 'behavior', 'list', 'http', 'request', 'response', 'initiate', 'code', 'observe', 'ﬁrstparty', 'cookie', 'cookiegraph', 'use', 'content', 'feature', 'eg', 'base', 'cookie', 'name', 'trivially', 'use', 'detection', 'evasion', 'tactic', 'cookiegraph', 'also', 'remove', 'feature', 'relate', 'classiﬁcation', 'request', 'node', 'webgraph', 'cookiegraph', 'classiﬁes', 'storage', 'node', 'evaluation', 'similar', 'previous', 'work', 'use', 'random', 'forest', 'classiﬁer', 'distinguish', 'nonat', 'cookie', 'ﬁrst', 'train', 'test', 'accuracy', 'classiﬁer', 'carefully', 'label', 'dataset', 'deploy', 'website', 'dataset', 'ground', 'truth', 'labeling', 'use', 'complementary', 'approach', 'construct', 'ground', 'truth', 'ﬁrstparty', 'cookie', 'represent', 'ﬁrstparty', 'cookie', 'cookie', 'domain', 'pair', 'cookie', 'name', 'occur', 'multiple', 'site', 'filter', 'list', 'rely', 'ﬁlter', 'list', 'previous', 'work', 'find', 'reasonably', 'reliable', 'detect', 'endpoint', 'however', 'ﬁlter', 'list', 'design', 'label', 'resource', 'url', 'rather', 'cookie', 'adapt', 'ﬁlter', 'list', 'label', 'cookie', 'assign', 'label', 'particular', 'resource', 'cookie', 'set', 'resource', 'nonat', 'cookie', 'set', 'resource', 'labeling', 'procedure', 'result', 'nontrivial', 'number', 'false', 'positive', 'limit', 'number', 'false', 'positive', 'ground', 'truth', 'nonat', 'cookie', 'base', 'ﬁlter', 'list', 'ie', 'script', 'set', 'cookie', 'mark', 'ﬁlter', 'list', 'label', 'cookie', 'non', 'conservatively', 'ﬁlter', 'list', 'mark', 'setter', 'label', 'cookie', 'unknown', 'cookiepedia', 'inspire', 'prior', 'work', 'use', 'cook', 'additional', 'source', 'cookie', 'label', 'cook', 'database', 'cookie', 'maintain', 'wellknown', 'consent', 'management', 'platform', 'call', 'onetrust', 'cookie', 'domain', 'pair', 'cookiepedia', 'vide', 'purpose', 'deﬁne', 'primarily', 'cookie', 'integration', 'onetrust', 'cookie', 'assign', 'label', 'strictly', 'necessary', 'functional', 'analytic', 'advertisingtracke', 'cookiepediareported', 'purpose', 'selfdeclare', 'adopt', 'conservative', 'approach', 'label', 'cookiedomain', 'pair', 'cookie', 'purpose', 'declare', 'advertisingtracking', 'analytic', 'particular', 'domain', 'cookie', '’s', 'declare', 'purpose', 'strictly', 'necessary', 'functional', 'label', 'cookie', 'unknown', 'cookie', 'mistakenly', 'intentionally', 'mislabele', 'combine', 'result', 'labeling', 'approach', 'obtain', 'ﬁnal', 'label', 'ﬁrstparty', 'cookie', 'approach', 'label', 'cookie', 'unknown', 'ﬁnal', 'label', 'unknown', 'approach', 'know', 'label', 'ﬁnal', 'label', 'mark', 'cookie', 'ﬁlter', 'list', 'mark', 'nonat', 'give', 'precedence', 'cookiepedia', 'label', 'assign', 'ﬁnal', 'label', 'website', 'unlikely', 'selfdeclare', 'nonat', 'cookie', 'use', 'labeling', 'process', 'party', 'cookie', 'know', 'nonat', 'label', 'rest', 'label', 'unknown', 'observe', 'cookie', 'set', 'script', 'different', 'site', 'often', 'label', 'instance', 'unknown', 'instance', 'datum', 'latter', 'unlikely', 'script', 'change', 'purpose', 'site', 'propagate', 'label', 'instance', 'set', 'script', 'label', 'propagation', 'datum', 'label', 'nonat', 'label', 'figure', 'feature', 'distribution', 'cookie', 'exﬁltration', 'top', 'storage', 'set', 'bottom', 'nonat', 'cookie', 'cookie', 'exﬁltrate', 'set', 'cookie', 'result', 'feature', 'base', 'exﬁltration', 'set', 'helpful', 'classiﬁer', 'classiﬁcation', 'train', 'test', 'classiﬁer', 'label', 'dataset', 'use', 'standard', 'cross', 'validation', 'ensure', 'overlap', 'website', 'use', 'training', 'test', 'fold', 'similar', 'section', 'limit', 'classiﬁer', 'cookie', 'value', 'least', 'character', 'long', 'classiﬁer', 'precision', 'recall', 'overall', 'accuracy', 'indicate', 'classiﬁer', 'successful', 'detect', 'cookie', 'feature', 'analysis', 'conduct', 'feature', 'analysis', 'understand', 'inﬂuential', 'feature', 'classiﬁer', 'ﬁnd', 'inﬂuential', 'feature', 'ﬂow', 'feature', 'capture', 'cookie', 'exﬁltration', 'set', 'operation', 'redirection', 'cookie', 'setter', 'figure', 'show', 'distribution', 'number', 'cookie', 'exﬁltration', 'top', 'number', 'time', 'cookie', 'set', 'bottom', 'nonat', 'cookie', 'cookie', 'much', 'likely', 'exﬁltrate', 'cookie', 'median', 'number', 'exﬁltration', 'meanstd', 'compare', 'median', 'nonat', 'meanstd', 'also', 'cookie', 'tend', 'set', 'much', 'frequently', 'script', 'median', 'set', 'operation', 'mean', 'standard', 'deviation', '486±699', 'compare', 'nonat', 'cookie', 'mean', 'standard', 'deviation', '217±608', 'ﬁnding', 'conﬁrm', 'conclu', 'sion', 'section', 'ﬁrstparty', 'cookie', 'use', 'store', 'identiﬁer', 'exﬁltrate', 'multiple', 'endpoint', 'cookie', 'error', 'analysis', 'conduct', 'manual', 'analysis', 'graph', 'false', 'positive', 'false', 'negative', 'understand', 'approach', 'fail', 'ﬁnd', 'mis', 'classiﬁed', 'publicly', 'available', 'description', 'indicate', 'use', 'track', 'visitor', 'page', 'attentiveid', 'messagesutk', 'omnisendanonymousid', 'also', 'instance', 'wellknown', 'analytic', 'cookie', 'ga', 'gid', 'label', 'ground', 'truth', 'nonat', 'classiﬁe', 'cookiegraph', 'overall', 'false', 'positive', 'typically', 'cause', 'misclassifying', 'nontracke', 'cookie', 'mostly', 'tracking', 'cookie', 'ﬂagge', 'cookiegraph', 'mislabele', 'nonat', 'ground', 'truth', 'word', 'cookiegraph', 'likely', 'correctly', 'classiﬁe', 'tracking', 'cookie', 'note', 'even', 'procedure', 'improve', 'ground', 'truth', 'label', 'cookie', 'selfdisclose', 'label', 'serve', 'slightly', 'different', 'script', 'thereby', 'miss', 'hashbase', 'script', 'matching', 'lead', 'mistake', 'ground', 'truth', 'leave', 'investigation', 'method', 'improve', 'ground', 'truth', 'label', 'future', 'work', 'false', 'negative', 'representative', 'case', 'pinunauth', 'cookie', 'value', 'doublebase64encode', 'include', 'list', 'potential', 'encoding', 'scheme', 'use', 'cookiegraph', 'detect', 'exﬁltration', 'false', 'negative', 'avert', 'use', 'comprehensive', 'list', 'encoding', 'scheme', 'perform', 'fullblown', 'mation', 'ﬂow', 'track', 'instead', 'approximating', 'exﬁltration', 'ﬂow', 'however', 'latter', 'come', 'performance', 'cost', 'discuss', 'far', 'section', 'false', 'negative', 'capture', 'sufﬁcient', 'activity', 'webpage', 'execution', 'far', 'discuss', 'case', 'false', 'negative', 'section', 'table', 'list', 'cookie', 'detect', 'name', 'gad', 'uetsid', 'uetvid', 'hjtldt', 'clsk', 'cto', 'bundle', 'uid', 'pin', 'unauth', 'utma', 'utmb', 'utmz', 'script', 'org', 'percentage', 'site', 'googleanalyticscom', 'googleanalyticscom', 'googleanalyticscom', 'googleanalyticscom', 'hotjar', 'criteo', 'yandex', 'tiktok', 'hubspot', 'deployment', 'deploy', 'cookiegraph', 'cookie', 'clude', 'unknown', 'cookie', 'crawl', 'site', 'prevalence', 'ﬁrstparty', 'cookie', 'overall', 'cookie', 'graph', 'classiﬁes', 'ﬁrstparty', 'cookie', 'dataset', 'ﬁnd', 'site', 'deploy', 'least', 'ﬁrstparty', 'site', 'average', 'number', 'ﬁrstparty', 'cookie', 'site', 'set', 'ﬁrstparty', 'cookie', 'vast', 'majority', 'ﬁrstparty', 'cookie', 'fact', 'set', 'thirdparty', 'embed', 'script', 'serve', 'total', 'unique', 'domain', 'demonstrate', 'ﬁrstparty', 'cookie', 'actually', 'set', 'use', 'thirdparty', 'tracker', 'possible', 'ﬁrstparty', 'allow', 'thirdparty', 'tracker', 'embed', 'script', 'ﬁrstparty', 'con', 'text', 'suggest', 'intentional', 'unintentional', 'collusion', 'ﬁrstparty', 'thirdparty', 'tracker', 'thirdpartyset', 'ﬁrstparty', 'cookie', 'enable', 'thirdpartie', 'circumvent', 'blockingbase', 'countermeasure', 'implement', 'browser', 'next', 'analyze', 'prevalent', 'ﬁrstparty', 'cookie', 'thirdparty', 'entity', 'actually', 'set', 'table', 'list', 'top25', 'ﬁrstparty', 'cookies5', 'base', 'prevalence', 'major', 'advertising', 'entity', 'facebook', 'set', 'ﬁrstparty', 'cookie', 'approximately', 'third', 'site', 'dataset', 'cookiegraph', 'detect', 'gid', 'ga', 'cookie', 'analytic', 'site', 'public', 'documentation', 'report', 'distinct', 'tuple', 'cookie', 'name', 'acknowledge', 'use', 'ﬁrstparty', 'cookie', 'store', 'user', 'identiﬁer', 'track', 'cookiegraph', 'detect', 'site', 'public', 'documentation', 'acknowledge', 'facebook', 'track', 'pixel', 'store', 'unique', 'identiﬁer', 'fact', 'facebook', 'make', 'recent', 'change', 'include', 'ﬁrstparty', 'cookie', 'support', 'tracking', 'pixel', 'avoid', 'countermeasure', 'tiktok', 'emerge', 'social', 'medium', 'app', 'know', 'aggressively', 'harvest', 'sensitive', 'user', 'information', 'also', 'recently', 'add', 'support', 'set', 'ﬁrstparty', 'tracking', 'cook', 'ie', 'use', 'tiktok', 'pixel', 'tiktok', 'tracking', 'cookie', 'present', 'percent', 'site', 'considerably', 'low', 'com', 'parable', 'specialized', 'entity', 'criteo', 'cookie', 'prevalent', 'ﬁrstparty', 'cookie', 'recall', 'section', 'ctobundle', 'sometimes', 'purposefully', 'set', 'cookie', 'block', 'deployment', 'show', 'criteo', 'set', 'ﬁrstparty', 'cookie', 'site', 'dataset', 'note', 'ﬁrstparty', 'cookie', 'adobe', 'list', 'table', 'also', 'detect', 'cookiegraph', 'make', 'list', 'prevalent', 'cookie', 'behavior', 'analysis', 'section', 'crucial', 'discover', 'prevalent', 'example', 'discuss', 'section', 'browser', 'ﬁngerprinte', 'discuss', 'section', 'track', 'er', 'use', 'ﬁrstparty', 'cookie', 'employ', 'invasive', 'tracking', 'technique', 'browser', 'ﬁngerprinte', 'implement', 'crosssite', 'tracking', 'analyze', 'ﬁrstparty', 'cookie', 'set', 'script', 'entity', 'know', 'engage', 'browser', 'ﬁngerprinte', 'use', 'connect', 'sublist', 'ﬁngerprinter', 'tracking', 'protection', 'list', 'cookie', 'predominately', 'set', 'script', 'serve', 'domain', 'involve', 'ﬁngerprinting', 'ccaud', 'cccc', 'also', 'find', 'set', 'script', 'overall', 'distinct', 'domain', 'set', 'ﬁrstparty', 'cookie', 'also', 'know', 'ﬁngerprinter', 'however', 'handful', 'domain', 'responsible', 'set', 'ﬁrstparty', 'cookie', 'disproportionately', 'tween', 'domain', 'number', 'cookie', 'set', 'surprising', 'effective', 'crosssite', 'tracking', 'require', 'tracker', 'present', 'collect', 'datum', 'large', 'number', 'site', 'presence', 'allow', 'tracker', 'collect', 'extensive', 'deterministic', 'probabilistic', 'attribute', 'user', 'varied', 'number', 'source', 'enhance', 'ability', 'track', 'user', 'site', 'absence', 'thirdparty', 'cookie', 'case', 'study', 'analysis', 'section', 'elaborate', 'ﬁrstparty', 'cookie', 'combine', 'ﬁngerprinte', 'crosssite', 'tracking', 'comparison', 'exist', 'countermeasure', 'next', 'compare', 'cookiegraph', 'art', 'countermeasure', 'cookieblock', 'webgraph', 'term', 'detection', 'accuracy', 'website', 'breakage', 'robustness', 'cookieblock', 'stateoftheart', 'approach', 'classify', 'cook', 'ie', 'include', 'advertisingtracking', 'analytic', 'make', 'use', 'manually', 'curate', 'allow', 'list', 'machine', 'learning', 'classiﬁer', 'mainly', 'rely', 'feature', 'base', 'attribute', 'cookie', 'name', 'value', 'webgraph', 'stateoftheart', 'graphbased', 'approach', 'classify', 'request', 'de', 'sign', 'directly', 'classify', 'cookie', 'adapt', 'end', 'identify', 'resource', 'identiﬁe', 'webgraph', 'generate', 'block', 'list', 'cookie', 'domain', 'set', 'resource', 'list', 'mean', 'mimic', 'effect', 'block', 'resource', 'ﬁrstparty', 'cookie', 'detection', 'accuracy', 'table', 'compare', 'detec', 'tion', 'accuracy', 'cookiegraph', 'cookieblock', 'webgraph', 'cookiegraph', 'outperform', 'approach', 'metric', 'superiority', 'precision', 'indicate', 'exist', 'countermeasure', 'result', 'many', 'false', 'posi', 'tive', 'cookiegraph', 'additional', 'false', 'positive', 'mean', 'previous', 'approach', 'block', 'functional', 'party', 'cookie', 'potentially', 'affect', 'user', 'experience', 'next', 'investigate', 'impact', 'false', 'positive', 'website', 'breakage', 'website', 'breakage', 'manually', 'analyze', 'break', 'age', 'cause', 'cookiegraph', 'cookieblock', 'web', 'graph', '’s', 'site', 'sample', '10k', 'site', 'table', 'classification', 'accuracy', 'cookiegraph', 'webgraph', 'cookieblock', 'accuracy', 'precision', 'recall', 'use', 'section', 'site', 'choose', 'randomly', 'top', 'rest', 'divide', 'breakage', 'analysis', 'category', 'typical', 'website', 'usage', 'navigation', 'page', 'sso', 'initiate', 'maintain', 'login', 'state', 'appear', 'ance', 'visual', 'consistency', 'miscellaneous', 'functionality', 'chat', 'search', 'shopping', 'cart', 'label', 'breakage', 'major', 'minor', 'category', 'major', 'breakage', 'possible', 'use', 'functionality', 'site', 'include', 'aforementioned', 'category', 'minor', 'breakage', 'difﬁcult', 'impossible', 'user', 'make', 'use', 'functionality', 'assess', 'website', 'breakage', 'com', 'pare', 'vanilla', 'chrome', 'browser', 'countermeasure', 'ﬁrstparty', 'cookie', 'browser', 'enhance', 'extension', 'block', 'ﬁrstparty', 'cookie', 'classiﬁe', 'cookiegraph', 'enhance', 'extension', 'block', 'cookie', 'set', 'resource', 'label', 'webgraph', 'enhance', 'ofﬁcial', 'cookieblock', 'extension', 'use', 'reviewer', 'perform', 'breakage', 'analysis', 'mitigate', 'impact', 'bias', 'subjectivity', 'disagreement', 'reviewer', 'resolve', 'careful', 'discussion', 'site', 'cookiegraph', 'minor', 'breakage', 'site', 'offer', 'popup', 'keep', 'reappear', 'deletion', 'cookie', 'store', 'user', 'preference', 'contrast', 'webgraph', 'cookieblock', 'cause', 'major', 'breakage', 'least', 'category', 'site', 'example', 'webgraph', 'cause', 'issue', 'cart', 'functionality', 'complete', 'website', 'breakage', 'espncricinfocom', 'sso', 'issue', 'site', 'breakage', 'issue', 'cookieblock', 'relate', 'sso', 'login', 'additional', 'logindependent', 'functionality', 'eg', 'miss', 'proﬁle', 'picture', 'result', 'cookieblock', 'cause', 'break', 'age', 'site', 'sso', 'login', 'inline', 'breakage', 'report', 'author', 'also', 'webgraph', 'block', 'additional', 'party', 'cookie', 'important', 'serverside', 'functionality', 'directly', 'relate', 'user', 'experience', 'therefore', 'immediately', 'perceptible', 'example', 'webgraph', 'block', 'essential', 'cookie', 'use', 'use', 'prevent', 'csrf', 'different', 'site', 'awsalb', 'cookie', 'use', 'amazon', 'load', 'balance', 'cookiegraph', 'correctly', 'classiﬁe', 'cookie', 'nonat', 'thus', 'prevent', 'mea', 'sure', 'deploy', 'robustness', 'compare', 'robustness', 'cookie', 'graph', 'cookieblock', 'webgraph', 'evasion', 'mod', 'iﬁcation', 'cause', 'misclassiﬁcation', 'resource', 'nonat', 'advertiser', 'tracker', 'know', 'table', 'website', 'breakage', 'comparison', 'countermeasure', 'breakage', 'signify', 'breakage', 'minor', 'major', 'breakage', 'cell', 'represent', 'percentage', 'site', 'breakage', 'observe', 'classiﬁer', 'navigation', 'miscellaneous', 'minor', 'major', 'minor', 'major', 'minor', 'major', 'minor', 'major', 'appearance', 'cookieblock', 'table', 'robustness', 'difference', 'classification', 'accuracy', 'classiﬁer', 'accuracy', 'precision', 'recall', 'engage', 'arm', 'race', 'privacyenhance', 'tool', 'test', 'detection', 'ﬁrstparty', 'cookie', 'brittle', 'face', 'trivial', 'manipulation', 'attempt', 'change', 'cookie', 'name', 'important', 'evaluate', 'robustness', 'test', 'set', 'site', 'dataset', 'also', 'require', 'need', 'cookieblock', 'data', 'collection', 'training', 'translate', 'total', 'test', 'set', 'ﬁrstparty', 'cookie', 'change', 'name', 'cookie', 'test', 'set', 'randomly', 'generate', 'string', 'length', 'character', 'table', 'show', 'result', 'note', 'cookiegraph', 'webgraph', 'fully', 'robust', 'manipulation', 'cookie', 'name', 'cookieblock', 'accuracy', 'degrade', 'cookiegraph', 'webgraph', 'robust', 'use', 'content', 'feature', 'feature', 'relate', 'cookie', 'characteristic', 'cookie', 'name', 'domain', 'somewhat', 'easily', 'manipulate', 'adversary', 'aim', 'evade', 'classiﬁcation', 'contrary', 'important', 'feature', 'cookieblock', 'fact', 'depend', 'cookie', 'name', 'ie', 'name', 'belong', 'common', 'cookie', 'name', 'thus', 'cookieblock', 'easily', 'bypass', 'trivial', 'cookie', 'name', 'modiﬁcation', 'cookiegraph', 'implementation', 'feature', 'manipulate', 'adversary', 'use', 'different', 'encod', 'ing', 'currently', 'consider', 'change', 'domain', 'exﬁltration', 'endpoint', 'robustness', 'attack', 'improve', 'comprehensive', 'ﬂow', 'track', 'however', 'fullblown', 'information', 'tracking', 'incur', 'prohibitively', 'high', 'runtime', 'overhead', 'implementation', 'complexity', 'browser', 'limitation', 'completeness', 'cookiegraph', 'rely', 'graph', 'representation', 'teraction', 'different', 'element', 'webpage', 'exe', 'cution', 'completeness', 'interaction', 'capture', 'graph', 'depend', 'intensity', 'variety', 'user', 'activity', 'webpage', 'scroll', 'activity', 'number', 'internal', 'page', 'click', 'word', 'possible', 'cookiegraph', 'detect', 'certain', 'cookie', 'graph', 'represen', 'tation', 'capture', 'interaction', 'different', 'element', 'insufﬁcient', 'user', 'activity', 'study', 'impact', 'user', 'activity', 'cookiegraph', 'recrawl', 'site', 'perform', 'time', 'ternal', 'page', 'click', 'original', 'crawl', 'speciﬁ', 'cally', 'recrawl', 'site', 'criteo', 'originally', 'classiﬁe', 'nonat', 'deployment', 'recrawle', 'site', 'result', 'successful', 'detection', 'criteo', 'ctobundle', 'cookie', 'recrawle', 'site', 'ﬁnd', 'average', 'number', 'inﬁltration', 'exﬁltration', 'increase', 'original', 'recrawle', 'site', 'surmise', 'case', 'cookiegraph', 'incorrectly', 'classiﬁes', 'non', 'due', 'incompleteness', 'graph', 'representation', 'decision', 'reﬂect', 'behavior', 'cookie', 'time', 'classiﬁcation', 'interaction', 'capture', 'graph', 'cookiegraph', 'able', 'correctly', 'switch', 'label', 'moreover', 'cookiegraph', 'never', 'switch', 'label', 'nonat', 'due', 'increase', 'interaction', 'observe', 'similar', 'trend', 'prevalent', 'ﬁrstparty', 'cookie', 'dataset', 'deployment', 'cookiegraph', '’s', 'implementation', 'suitable', 'run', 'time', 'deployment', 'performance', 'overhead', 'asso', 'ciate', 'browser', 'instrumentation', 'machine', 'learn', 'e', 'pipeline', 'envision', 'cookiegraph', 'use', 'ofﬂine', 'set', 'ﬁrstparty', 'cookiedomain', 'pair', 'detect', 'use', 'machine', 'learning', 'classiﬁer', 'detect', 'cookiedomain', 'pair', 'add', 'cookie', 'ﬁlter', 'list', 'already', 'support', 'privacyenhance', 'browser', 'extension', 'ublock', 'origin', 'run', 'time', 'block', 'argue', 'reasonably', 'frequent', 'eg', 'week', 'deployment', 'cookiegraph', 'large', 'scale', 'sufﬁcient', 'generate', 'keep', 'ﬁlter', 'list', 'uptodate', 'advertiser', 'tracker', 'theory', 'change', 'cookie', 'name', 'rate', 'fast', 'periodic', 'deployment', 'updating', 'cookie', 'name', 'frequently', 'challenge', 'practice', 'set', 'ﬁrstparty', 'cookie', 'many', 'different', 'site', 'require', 'tight', 'coordination', 'different', 'entity', 'illustrate', 'practical', 'issue', 'associate', 'change', 'cookie', 'name', 'consider', 'legacy', 'demdex', 'cookie', 'set', 'bed', 'script', 'exﬁltrate', 'demdexnet', 'domain', 'adobe', 'documentation', 'explain', 'difﬁcult', 'change', 'legacy', 'name', 'entwine', 'deeply', 'audience', 'manager', 'adobe', 'experience', 'cloud', 'service', 'instal', 'user', 'advertiser', 'tracker', 'somehow', 'able', 'overcome', 'practi', 'cal', 'challenge', 'change', 'cookie', 'name', 'much', 'fast', 'pace', 'cookiegraph', 'online', 'implementation', 'runtime', 'cookie', 'classiﬁcation', 'necessary', 'research', 'need', 'efﬁcient', 'effective', 'online', 'implementation', 'cookiegraph', 'conclusion', 'conduct', 'large', 'scale', 'differential', 'measurement', 'study', 'investigate', 'tracker', 'abuse', 'ﬁrstparty', 'cookie', 'circumvent', 'thirdparty', 'cookie', 'block', 'propose', 'cookiegraph', 'able', 'accurately', 'robustly', 'block', 'ﬁrstparty', 'tracking', 'cookie', 'signiﬁcantly', 'outperform', 'stateoftheart', 'use', 'cookiegraph', 'find', 'evi', 'dence', 'widespread', 'abuse', 'ﬁrstparty', 'cookie', 'test', 'website', 'distinct', 'tracking', 'domain', 'include', 'major', 'advertising', 'entity', 'well', 'many', 'specialized', 'entity', 'criteo', 'reference', 'ublock', 'origin', 'resource', 'library', 'use', 'cookie', 'tiktok', 'pixel', 'mean', 'blogfacebookfirstpartycookieadtech', 'bug', 'pc', 'smart', 'cookie', 'internet', 'privacy', 'p3p', 'summary', 'ing', 'adblock', 'online', 'available', 'attentive', 'cookie', 'publisher', 'provide', 'identiﬁer', 'cartographer', 'ridentitygraph', 'identity', 'graph', 'cookieblock', 'online', 'criteo', 'crite', 'o977downloadcriteo', 'online', 'identification', 'identiﬁcation', 'parameter', 'fbc', 'roll', 'total', 'cookie', 'protection', 'default', 'user', 'world', 'wide', 'otalcookieprotectionbydefaulttoallusersworldwide', 'protection', 'ﬁngerprinte', 'orgenuskbfirefoxprotectionagainstfingerprinting', 'cookie', 'usage', 'ecomanalyticsdevguidescollectiongtagjscookieusage', 'website', 'identity', 'cloud', 'tpswwwid5ioidentitycloud', 'identity', 'guide', 'yieldbirdcomidentityguide', '’', 'word', 'ourcecodetiktokreport', 'source', 'code', 'tiktok', 'report', 'lotame', 'data', 'collection', 'guide', 'lotame', 'identity', 'resolution', 'olution', 'lotame', 'lightning', 'tag', 'ningtag', 'new', 'approach', 'address', 'rise', 'ﬁngerprinte', 'eoffingerprinte', 'panorama', 'artyintegrationsreferralmarketingplatformstalkable', 'online', 'available', 'cookie', 'ser', 'experience', 'vice', 'cookieshtmllangen', 'online', 'available', 'leagueadobecomdocsidserviceusingintrocookieshtmllangen', 'identity', 'cloud', 'disconnect', 'track', 'protection', 'list', 'rotection', 'online', 'available', 'tection', 'doubleclick', 'wwwdoubleclickcom', 'easylist', 'easyprivacy', 'enhance', 'tracking', 'protection', 'ﬁrefox', 'desktop', 'mozillaorgenuskbenhancedtrackingprotectionfirefoxdesktop', 'online', 'avail', 'able', 'spotsetinavisitorsbrowser', 'resolution', 'method', 'party', 'explain', 'id5ionewsindexphp20220324ﬁrstpartyidsandidentityresol', 'utionmethodsexplaine', 'identity', 'omnisend', 'cookie', '1933402explainingandmanagingtrackingcookie', 'line', 'available', 'xplainingandmanagingtrackingcookie', 'trust', 'cookiepedia', 'tracking', 'prevention', 'edge', 'enusmicrosoftedgewebplatformtrackingprevention', 'understanding', 'call', 'main', 'userguidereferencedemdexcallshtmllangen', 'online', 'available', 'eruserguidereferencedemdexcallshtmllangen', 'demdex', 'error', 'misunder', 'standing', 'attack', 'analyze', 'crowdsourcing', 'process', 'ad', 'blocking', 'system', 'proceeding', 'internet', 'measurement', 'tiktok', 'add', 'cookie', 'pixel', 'try', 'eat', 'lunch', 'wwwadexchangercomonlineadvertisingtiktokaddsthirdpartyc', 'ookiestoitspixelandtriestoeatfacebookslunch', 'w', 'aqeel', 'b', 'chandrasekaran', 'feldmann', 'maggs', 'landing', 'internal', 'web', 'page', 'strange', 'case', 'jekyll', 'web', 'performance', 'measurement', 'proceeding', 'acm', 'internet', 'measurement', 'conference', 'p', 'shaﬁq', 'fpradar', 'longitudinal', 'measurement', 'early', 'detection', 'browser', 'ﬁngerprinte', 'pro', 'ceeding', 'privacy', 'enhance', 'technology', 'pet', 'bollinger', 'analyze', 'cookie', 'compliance', 'gdpr', 'https', 'sis', 'bolling', 'basin', 'automate', 'cookie', 'consent', 'gdpr', 'violation', 'detection', '31st', 'usenix', 'security', 'symposium', 'usenix', 'security', 'automate', 'cookie', 'consent', 'gdpr', 'violation', 'detection', '31st', 'usenix', 'security', 'symposium', 'usenix', 'security', 'cahn', 'alfeld', 'p', 'barford', 'empirical', 'study', 'web', 'cookie', 'proceeding', '25th', 'international', 'conference', 'world', 'wide', 'web', 'international', 'world', 'wide', 'web', 'conference', 'steering', 'committee', 'p', 'q', 'polychronaki', 'swap', 'party', 'abuse', 'ﬁrstparty', 'cookie', 'web', 'tracking', 'proceeding', 'web', 'conference', 'q', 'kapravelos', 'mystique', 'uncover', 'information', 'leakage', 'browser', 'extension', 'proceeding', 'acm', 'sigsac', 'conference', 'computer', 'communication', 'security', 'chudnov', 'naumann', 'inline', 'information', 'ﬂow', 'itore', 'javascript', 'proceeding', '22nd', 'acm', 'sigsac', 'conference', 'computer', 'communication', 'security', 'l', 'kristol', 'state', 'management', 'mechanism', 'l', 'bilge', 'meet', 'tracker', 'web', 'tracking', 'user', 'perspective', 'usenix', 'security', 'symposium', 'h', 'dao', 'mazel', 'fukuda', 'cname', 'cloakingbase', 'tracking', 'web', 'characterization', 'detection', 'protection', 'ieee', 'tran', 'action', 'network', 'service', 'management', 'birgisson', 'l', 'bello', 'sabelfeld', 'jsﬂow', 'track', 'information', 'ﬂow', 'javascript', 'apis', 'proceeding', '29th', 'annual', 'acm', 'symposium', 'apply', 'computing', 'l', 'hieu', 'zubair', 'cvinspector', 'automat', 'e', 'detection', 'adblock', 'circumvention', 'network', 'distribute', 'system', 'security', 'symposium', 'ndss', 'hil', 'wood', 'r', 'b¨ohme', 'measure', 'emergence', 'consent', 'management', 'web', 'proceeding', 'acm', 'internet', 'measurement', 'conference', 'sastry', 'mondal', 'cccc', 'corral', 'cookie', 'category', 'cookiemonster', '13th', 'acm', 'web', 'science', 'conference', 'association', 'compute', 'machinery', 'p', 'u', 'shaﬁq', 'qian', 'ad', 'war', 'retrospective', 'mea', 'surement', 'analysis', 'antiadblock', 'ﬁlter', 'list', 'snyder', 'livshit', 'qian', 'shaﬁq', 'adgraph', 'graphbased', 'approach', 'ad', 'tracker', 'blocking', 'ieee', 'symposium', 'security', 'privacy', 'sp', 'ieee', 'nguyen', 'englehardt', 'shaﬁq', 'khaleesi', 'breaker', 'advertising', 'tracking', 'request', 'chain', 'usenix', 'security', 'symposium', 'usenix', 'p', 'laperdrix', 'w', 'rudametkin', 'baudry', 'beauty', 'beast', 'divert', 'modern', 'web', 'browser', 'build', 'unique', 'browser', 'ﬁngerprint', 'ieee', 'symposium', 'security', 'privacy', 'sp', 'lekie', 'stock', 'ﬂow', 'later', 'large', 'scale', 'detection', 'dombase', 'xss', 'proceeding', 'acm', 'sigsac', 'conference', 'computer', 'communication', 'security', 'pp', 'p', 'g', 'cranor', 'mcdonald', 'r', 'mcguire', 'token', 'attempt', 'misrepresentation', 'website', 'privacy', 'policy', 'misuse', 'p3p', 'compact', 'policy', 'token', 'proceeding', '9th', 'annual', 'acm', 'workshop', 'privacy', 'electronic', 'society', 'l', 'reasoning', 'web', 'cookie', 'cname', 'game', 'largescale', 'analysis', 'dnsbased', 'tracking', 'evasion', 'pet', 'nguyen', 'late', 'ﬁrefox', 'roll', 'enhanced', 'track', 'pro', 'tection', 'lsoutenhancedtrackingprotection', 'd´ıazmorale', 'crossdevice', 'tracking', 'matching', 'device', 'cookie', 'ieee', 'international', 'conference', 'datum', 'mining', 'workshop', 'pp', 'b', 'cookie', 'cookie', 'clearinghouse', 'thecookieclearinghouse', 'englehardt', 'online', 'track', 'measurement', 'analysis', 'proceeding', 'englehardt', 'eubank', 'p', 'zimmerman', 'narayanan', 'felten', 'cookie', 'give', 'away', 'surveillance', 'implication', 'web', 'tracking', 'proceeding', '24th', 'international', 'conference', 'world', 'wide', 'web', 'fouad', 'legout', 'saraﬁjanovicdjukic', 'miss', 'ﬁlter', 'list', 'detect', 'unknown', 'thirdparty', 'tracker', 'invisible', 'pixel', 'proceeding', 'privacy', 'enhance', 'technology', 'vol', 'fouad', 'santo', 'legout', 'cookie', 'phoenix', 'detection', 'measurement', 'lawfulness', 'cookie', 'respawn', 'e', 'browser', 'ﬁngerprinte', 'privacy', 'enhance', 'technology', 'symposium', 'pet', 'b', 'fulgham', 'protect', 'hst', 'abuse', '8146protectingagainsthstsabuse', 'google', 'privacy', 'sandbox', 'privacysandbox', 'p', 'papadopoulo', 'e', 'p', 'markato', 'cookie', 'syn', 'chronization', 'always', 'want', 'know', 'afraid', 'ask', 'proceeding', 'world', 'wide', 'web', 'www', 'conference', 'randall', 'p', 'snyder', 'ukani', 'snoeren', 'savage', 'schulman', 'tracker', 'bounce', 'measure', 'evasion', 'partitioned', 'storage', 'wild', 'roesner', 'kohno', 'wetherall', 'detect', 'defend', 'thirdparty', 'tracking', 'web', '9th', 'usenix', 'symposium', 'networked', 'system', 'design', 'implementation', 'nsdi', 'sanchezrola', 'l', 'bilge', 'center', 'cookie', 'ecosystem', 'unravel', 'actor', 'role', 'relationship', 'sp', '42nd', 'ieee', 'symposium', 'security', 'privacy', 'usa', 'j', 'schuh', 'build', 'private', 'web', 'path', 'make', 'third', 'party', 'cookie', 'moreprivatewebpathtowardshtml', 'englehardt', 'z', 'shaﬁq', 'c', 'troncoso', 'web', 'graph', 'capture', 'advertising', 'track', 'information', 'ﬂow', 'robust', 'blocking', '31st', 'usenix', 'security', 'symposium', 'usenix', 'security', 'sj¨osten', 'p', 'snyder', 'pastor', 'p', 'papadopoulo', 'b', 'livshit', 'filter', 'list', 'generation', 'underserved', 'region', 'sluis', 'build', 'integration', 'publisherspeciﬁc', 'ﬁer', 'egrationsforpublisherspeciﬁcidentifier', 'b', 'stock', 'lekie', 'mueller', 'p', 'spiegel', 'clientside', 'protection', 'dombased', 'crosssite', 'scripting', '23rd', 'security', 'symposium', 'usenix', 'security', 'diego', 'ca', 'b', 'p', 'team', 'fight', 'cname', 'trickery', 'pdates6cnametrickery', 'e', 'team', 'introduce', 'track', 'prevention', 'available', 'edge', 'preview', 'build', 'dev20190627trackingpreventionmicrosoftedgepreview', 'online', 'available', 'vastel', 'p', 'laperdrix', 'w', 'rudametkin', 'r', 'rouvoy', 'fpstalker', 'track', 'browser', 'ﬁngerprint', 'evolution', 'ieee', 'symposium', 'security', 'privacy', 'sp', 'v', 'veen', 'cookie', 'compliance', 'dutch', 'hospital', 'website', 'webkit', 'tracking', 'prevention', 'gprevention', 'online', 'available', 'gprevention', 'j', 'wilander', 'intelligent', 'tracking', 'prevention', 'intelligent', 'tracking', 'prevention', 'intelligent', 'tracking', 'prevention', 'intelligent', 'tracking', 'prevention', 'intelligent', 'tracking', 'prevention', 'intelligent', 'tracking', 'prevention', 'cname', 'cloaking', 'bounce', 'track', 'defense', 'bkitorgblog11338cnamecloakingandbouncetrackingdefense', 'full', 'cookie', 'blocking', 'blog10218fullthirdpartycookieblockingandmore', 'bounce', 'track', 'protection', 'posalsissues6', 'appendix', 'case', 'study', 'section', 'look', 'case', 'study', 'atse', 'section', 'find', 'extensively', 'use', 'ﬁrstparty', 'cookie', 'track', 'purpose', 'analyze', 'behavior', 'crawl', 'compare', 'observed', 'behavior', 'documentation', 'create', 'generic', 'model', 'ﬁrstpartycookiebase', 'atse', 'follow', 'section', 'present', 'case', 'study', 'atse', 'lotame', 'criteo', 'lotame', 'lotame', 'datum', 'identity', 'management', 'solution', 'claim', 'provide', 'single', 'user', 'multiple', 'browser', 'device', 'platform', 'lotame', 'light', 'ning', 'tag', 'package', 'user', 'visit', 'datum', 'json', 'object', 'send', 'server', 'code', 'show', 'example', 'payload', 'send', 'lotame', 'payload', 'include', 'assign', 'website', 'thirdparty', 'identiﬁer', 'present', 'site', 'certain', 'user', 'behavior', 'conﬁgure', 'collaboration', 'publisher', 'lotame', 'custom', 'rule', 'deﬁne', 'website', 'lotame', 'process', 'payload', 'match', 'datum', 'cartograph', 'identity', 'graph', 'send', 'call', 'store', 'ﬁrstparty', 'cookie', 'localstorage', 'provide', 'identity', 'resolution', 'publisher', 'advertiser', 'identity', 'cloud', 'script', 'package', 'payload', 'contain', 'several', 'terministic', 'identiﬁer', 'email', 'username', 'phone', 'number', 'available', 'well', 'probabilistic', 'identiﬁer', 'include', 'ip', 'address', 'user', 'agent', 'location', 'user', 'process', 'payload', 'match', 'datum', 'identity', 'cloud', 'send', 'back', 'call', 'universal', 'store', 'ﬁrstparty', 'cookie', 'well', 'local', 'storage', 'example', 'payload', 'show', 'figure', 'note', 'also', 'provide', 'partner', 'graph', 'service', 'enable', 'information', 'share', 'partner', 'partner', 'graph', 'allow', 'different', 'identify', 'provider', 'exchange', 'information', 'datum', 'behaviorids', 'behavior', 'int', 'value', 'value', 'value', 'tpidvalue', 'code', 'example', 'datum', 'send', 'structure', 'send', 'lotame', 'user', 'ﬁrst', 'visit', 'party', 'cookie', 'localstorage', 'store', 'ctobundle', 'cookie', 'consider', 'fundamental', 'behavior', 'ﬁrstparty', 'cookie', 'describe', 'cookiegraph', '’s', 'graph', 'representation', 'abstract', 'storage', 'refer', 'cookie', 'localstorage', 'also', 'include', 'count', 'localstorage', 'access', 'feature', 'set', 'compute', 'graph', 'representation', 'inclusion', 'feature', 'help', 'cookiegraph', 'effectively', 'model', 'ﬁrstparty', 'cookie', 'behavior', 'crossdevice', 'user', 'attribution', 'methodology', 'crosssite', 'attribution', 'also', 'extend', 'crossdevice', 'attribution', 'slightly', 'complex', 'scenario', 'user', 'visit', 'different', 'site', 'also', 'use', 'different', 'device', 'different', 'ﬁngerprint', 'show', 'example', 'crossdevice', 'attribution', 'fig', 'instead', 'visit', 'site', 'device', 'user', 'visit', 'site', 'device', 'visit', 'site', 'device', 'fingerprint', 'f3', 'collect', 'site', 'use', 'device', 'f5', 'collect', 'use', 'device', 'site', 'ask', 'user', 'additional', 'p', 'p', 'similarity', 'ﬁngerprint', 'device', 'however', 'site', 'collect', 'additional', 'p', 'p', 'tracker', 'able', 'identify', 'populate', 'ﬁrstparty', 'cookie', 'site', 'correct', 'user', 'id1', 'createdat20220209t114240817811z', 'originaluidid5', 'fnfoglkyzdjjuok3kvaecvw2ofpz7orziw7hm0h', 'd5rjbbr0zxwkxdzb2yu1xuc2dukip1jclvagdtt', 'dby2pyftdawd596ho3tuosktodok4s4her2uwu', 'bipkoeg2ok4vtnc', 'universaluidid5', 'hgh7w7impmu3epzcxuuqnbb7ffhuuvcbsddssg', 'fb9k0x4zjlb2yhokndwqy6mzwxk1mwadna3wwna', 'd4j9i9bgcp3k0vygdqdtfhst7eedffyub8eq0ha4', 'yv9ifvbvi5oxmth7hb2xgmmmoeyvopbygi2tfw', '0srrmhcz37qqblkco4twotbvb3kmgcmrebcfle', 'signature', 'linktype1', 'privacy', 'code', 'example', 'datum', 'structure', 'receive', 'user', 'visit', 'criteo', 'criteo', 'provide', 'criteo', 'identity', 'graph', 'resolution', 'criteo', 'identity', 'graph', 'build', 'different', 'source', 'datum', 'contribute', 'advertiser', 'datum', 'collect', 'publisher', 'website', 'criteo', 'datum', 'provide', 'criteo', 'partner', 'liveramp', 'oracle', 'iv', 'prediction', 'exist', 'datum', 'criteo', 'machine', 'learning', 'model', 'criteo', 'claim', 'identity', 'graph', 'able', 'stitch', 'together', 'identiﬁer', 'user', 'world', 'contain', 'persistent', 'deterministic', 'identiﬁer', 'user', 'similar', 'identity', 'resolution', 'service', 'criteo', 'generate', 'base', 'ﬁer', 'hashed', 'email', 'mobile', 'device', 'store', 'ﬁrstparty', 'storage', 'ctobundle', 'documentation', 'show', 'criteo', 'make', 'use', 'figure', 'ﬁgure', 'show', 'ﬂow', 'information', 'identiﬁer', 'identity', 'graph', 'crossdevice', 'attribution', 'user', 'visit', 'site', 'device', 'identity', 'graph', 'return', 'u', 'site', 'visit', 'use', 'probabilistic', 'matching', 'ﬁngerprint', 'send', 'respective', 'website', 'publisher', 'provide', 'p', 'also', 'send', 'visit', 'site', 'user', 'visit', 'site', 'new', 'device', 'ﬁngerprint', 'different', 'identity', 'graph', 'return', 'new', 'u', 'site', 'visit', 'site', 'website', 'obtain', 'send', 'publisher', 'provide', 'match', 'p', 'p', 'provide', 'site', 'result', 'identity', 'graph', 'match', 'return', 'exist', 'user', 'site', 'site', 'site', 'site', 'uid1', 'uid1', 'uid1', 'device', 'cookie', 'stor', 'e', 'site', 'site', 'site', 'f1', 'ui', 'd1', 'd1', 'd1', 'd1', 'ppid1', 'ppid1', 'site', 'site', 'site', 'uid2', 'uid2', 'cookie', 'stor', 'e', 'device', 'd1', 'd1', 'site', 'site', 'site']"
"TMIC: App Inventor Extension for the Deployment of Image Classification
  Models Exported from Teachable Machine","[{'href': 'http://arxiv.org/abs/2208.12637v2', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2208.12637v2', 'rel': 'related', 'type': 'application/pdf'}]",2022-08-24 17:34:47,"Dynamic Memory-based Curiosity: A Bootstrap Approach for Exploration

Zijian Gao1, Kele Xu1*, YiYing Li2, Yuanzhao Zhai1,
Dawei Feng1, Bo Ding1, XinJun Mao1, Huaimin Wang1
1 National University of Defense Technology, Changsha, China
2 Artiﬁcial Intelligence Research Center, DII, Beijing, China
kelele.xu@gmail.com

2
2
0
2

g
u
A
4
2

]
I

A
.
s
c
[

1
v
9
4
3
1
1
.
8
0
2
2
:
v
i
X
r
a

Abstract

The sparsity of extrinsic rewards poses a serious chal-
lenge for reinforcement learning (RL). Currently, many
efforts have been made on curiosity which can pro-
vide a representative intrinsic reward for effective ex-
ploration. However, the challenge is still far from be-
ing solved. In this paper, we present a novel curiosity
for RL, named DyMeCu, which stands for Dynamic
Memory-based Curiosity. Inspired by human curiosity
and information theory, DyMeCu consists of a dynamic
memory and dual online learners. The curiosity arouses
if memorized information can not deal with the current
state, and the information gap between dual learners can
be formulated as the intrinsic reward for agents, and
then such state information can be consolidated into the
dynamic memory. Compared with previous curiosity
methods, DyMeCu can better mimic human curiosity
with dynamic memory, and the memory module can be
dynamically grown based on a bootstrap paradigm with
dual learners. On multiple benchmarks including Deep-
Mind Control Suite and Atari Suite, large-scale empir-
ical experiments are conducted and the results demon-
strate that DyMeCu outperforms competitive curiosity-
based methods with or without extrinsic rewards. We
will release the code to enhance reproducibility.

Introduction

Despite the success of reinforcement
learning (RL) on
sequential decision-making tasks (Bellemare et al. 2013;
Tesauro et al. 1995; Mnih et al. 2015), many current methods
struggle with sparse extrinsic rewards. To cope with the spar-
sity, curiosity provides a representative intrinsic reward that
can encourage agents to explore new states. Designing algo-
rithms to efﬁciently construct curiosity can be a key compo-
nent in RL systems. Previous research has shown that intrin-
sic rewards can help alleviate the issues resulting from the
lacking of dense extrinsic rewards (Liu and Abbeel 2021b;
Tao, Franc¸ois-Lavet, and Pineau 2020; Yang et al. 2021).

For human learning, curiosity motivates people to seek
and retain more information through exploration in the envi-
ronment (Burda et al. 2018; Ryan and Deci 2000; Smith and
Gasser 2005). The process of arousing and satisfying curios-
ity can be summed up as one cycle: when a person encoun-

ters a problem, he/she will ﬁrst try to solve it by retrieving
information from memory. If retrieval from memory fails,
he/she realizes that the current memorized information is in-
sufﬁcient solve the problem. A conscious awareness of in-
formation discrepancy then sparks curiosity about the prob-
lem, and curiosity stimulates the search for new informa-
tion. Once the information discrepancy is eliminated, people
may have no further curiosity to learn more about the cur-
rent problem until another problem is encountered (Rotgans
and Schmidt 2017; Silvia 2017). Human curiosity is con-
stantly consolidated based on the dynamic memory, which
consists of the encoding, storing, and retrieving information
stage (Hayes et al. 2021). As the curiosity fades, additional
information is consolidated into the memory. The consolida-
tion results in the forming of new dynamic memories, which
depends on the hippocampus (O’Reilly and Rudy 2001).

Many attempts have been made to build curiosity in
RL, which fall into two main categories: count-based and
prediction-based. However, such curiosity is very different
from human curiosity, and the problem is far from solved.
Taking the Random Network Distillation (RND) (Burda
et al. 2019) method as an example, RND initializes a ran-
dom ﬁxed target network with state embeddings, and trains
another prediction network to ﬁt the output of the target net-
work. A random ﬁxed target network can be regarded as a
random ﬁxed memory, so that RND cannot retain contextual
knowledge about the environment (Yang et al. 2021). With-
out dynamically incorporating contextual information into
memory, random features may not be sufﬁcient to interpret
dynamic environments. Therefore, this kind of curiosity is
evaluated in a non-developmental way, which severely lim-
its the performance of curiosity in RL.

In this work, to mimic human curiosity, we formalize and
investigate a Dynamic Memory-based Curiosity mechanism,
named DyMeCu. Inspired by the bootstrap paradigm (Guo
et al. 2020; Grill et al. 2020; Flennerhag et al. 2021), we
construct dual online learners to learn the latent state to
formulate dynamic memory model (Figure 1). On the one
hand, state information can be consolidated to the memory
via the exponential moving average (EMA) (Haynes, Corns,
and Venayagamoorthy 2012; Klinker 2011; Grebenkov and
Serror 2014) of dual learners’ parameters. The bootstrap

The term bootstrap is used in this text in its colloquial meaning

*Corresponding author: Kele Xu

rather than its statistical connotation.

 
 
 
 
 
 
Figure 1: DyMeCu employs a novel learning framework to build the intrinsic reward for RL, which consists of a dynamic
memory and dual online learners. The information discrepancy of the current state compared with the retrieved information
from the memory makes curiosity arouse. We get the curiosity-based intrinsic reward for agent learning by calculating the
information gap between dual online learners. Then the state information can be dynamically consolidated into the memory in
the bootstrap paradigm for curiosity fading.

paradigm, on the other hand, utilizes supervised signals from
memory to improve dual learners’ encoding ability. Further-
more, the curiosity is measured by the information gap be-
tween the dual learners, which is essentially an uncertainty
estimation of given state based on dynamic memory (Mai,
Mani, and Paull 2022; Liu et al. 2020; Abdar et al. 2021).

In brief, our contribution in this paper is:

• We ﬁrstly analyze the shortcomings of previous
curiosity-based intrinsic reward methods, and suggest to
mimic human curiosity leveraging a dynamic memory in-
stead of a ﬁxed one, based on the information theory.
• We propose a novel and practicable intrinsic reward
method for RL agents, named DyMeCu (Dynamic
Memory-based Curiosity), which consists of a dynamic
memory and dual online learners, and thus can measure
the curiosity and consolidate the information in a feasi-
ble way. Meanwhile, different strategies are explored to
further improve the performance of DyMeCu.

• On multiple benchmarks including DeepMind Con-
trol Suite (DMC) (Tunyasuvunakool et al. 2020) and
Atari Suite (Bellemare et al. 2013), large-scale empiri-
cal experiments demonstrate that DyMeCu outperforms
the other competitive curiosity-based methods and pre-
training strategies.

Related Work
Curiosity-Based Intrinsic Reward
In RL, the exploration issue is a long standing challenge.
Previous attempts suggest that: if there is no additional re-
ward, exploration can be regarded as a hunt for informa-
tion theoretically, which also can be viewed as the curios-
ity (Berlyne 1950; Schmidhuber 1991; Kidd and Hayden

2015; de Abril and Kanai 2018; Jaegle, Mehrpour, and Rust
2019; Friston et al. 2016; Peterson and Verstynen 2021). One
intuitive formulation of curiosity is the count-based meth-
ods, where the less visited state has more state novelty for
exploration. But it can not scale to large-scale or continu-
ous state spaces (Kearns and Singh 2002; Charikar 2002).
Inspired by count-based methods, RND calculates the state
novelty by distilling a random ﬁxed network (target net-
work) into another prediction network (predictor network).
The predictor network is trained to minimize the prediction
error for each state and take the prediction error as the in-
trinsic reward. Apart from count-based methods, prediction-
based methods also show competitive or better performance
by modeling the environment dynamics (Pathak et al. 2017;
Pathak, Gandhi, and Gupta 2019; Kim et al. 2020; Burda
et al. 2018). With the assumption that more visited state-
action pairs will result in more accurate prediction, the in-
trinsic reward can be applied as the variance of predic-
tions of ensembles or the distance between prediction states
and true states, such as the Disagreement method (Pathak,
Gandhi, and Gupta 2019) and ICM (Pathak et al. 2017)
method. There have been few attempts to design a curios-
ity that contains memory and effectively uses information
consolidated in memory, which however is the main goal of
this paper.

Uncertainty Estimation
Our work is also related to the uncertainty estimation, as
uncertainty is crucial which allows an agent to discern
when to exploit and when to explore its environment in
RL (Szepesv´ari 2009). Previous intrinsic rewards can also
be interpreted from the perspective of uncertainty estima-
tion, which can evaluate curiosity by estimating the deep
learning model’s uncertainty (conﬁdence). Take Disagree-

Curiosity Arouses 

Curiosity-based Learning & Curiosity Fades

Novel State
𝑆𝑡

Encode

Latent
State

Retrieve
Information

State 𝑠𝑡

Information
Discrepancy

Memory
Model
𝜔

Output

Retrieved
Information

Online
Learner
𝜃1
EMA

Memory
Model
𝜔

EMA

Online
Learner
𝜃2

𝜃1
𝑧𝑡
loss

𝜔
𝑧𝑡

loss

𝜃2
𝑧𝑡

Stop-
gradient

𝑖𝑛𝑡
𝑟𝑡

𝑠𝑡

State

𝜋

Policy

𝑎𝑡
Action

𝑠𝑡+1

Next State

Algorithm 1: Dynamic Memory-based Curiosity
Initialization: policy network πφ; dual online learner net-
works fθ1, fθ2; memory network Mω; coefﬁcients of intrin-
sic and extrinsic reward ζ, β.
1: while Training do
2:
3:
4:
5:

Receive state st from environment
at ← πφ(a|s) based on policy network πφ
Take action at, receive state st+1 and extrinsic re-
ext from environment
ward rt
Collect step data into replay buffer
st ← st+1

for t = 1, · · · , T do

end for
Sample batch data as {(si, ai, ri
replay buffer
for each i = 1, · · · , N do

ext, si+1)}N

i=1from

Generate latent state vectors zθ1
fθ2 (si), zω
i = Mω(si)
Calculate intrinsic reward rint
Calculate total reward ri

total = ζri

i = (cid:107)zθ1

i − zθ2
i (cid:107)2
int + βrext
i

i = fθ1 (si), zθ2

i =

end for
Update θ1 and θ2 with sampled data by minimizing
loss with equation (3)
Update ω with equation (7)
Update φ with sampled data by maximizing rtotal us-
ing RL algorithm

6:
7:
8:
9:

10:
11:

12:
13:
14:
15:

16:
17:

18: end while

ment as an example, instead of comparing the prediction to
the ground-truth, they suggest to evaluate the uncertainty of
multiple prediction models using the deep ensemble (Diet-
terich 2000), despite incurring additional computation. RND
also claims that the distillation error can be viewed as a
quantiﬁcation of the uncertainty. Unlike RND, in our work,
we evaluate the uncertainty of given states though measur-
ing the information gap between dual learners which rely on
dynamic memory instead of a random ﬁxed network.

Methodology
In general, if an agent encounters a state with the informa-
tion value E compared to its memory, then this state is worth
exploring and such information value is worth consolidat-
ing to its memory dynamically (Rotgans and Schmidt 2017;
Silvia 2017). In detail, the concept of information value E
necessitates the formation of the dynamic memory M and a
way g to consolidate information to the memory. For deep
neural networks, the memory M can be embedded in the la-
tent space and g can by the function that maps state s into
memory (Peterson and Verstynen 2021). This kind of con-
solidating information is denoted by:
g(s; M ) → M (cid:48).

(1)

With the memory M which has been learned by g over
historical states, we can measure the information value E
of the next state st+1. According to the information the-
ory (Ishii, Yoshida, and Yoshimoto 2002; Reddy, Celani, and
Vergassola 2016; Gray 2011) and the concepts proposed in

Peterson and Verstynen (2021), the information value E of a
state should (1) only depend on the memory and what can be
immediately learned (i.e., M , s and g); (2) be non-negative
because E is for exploring the environment; (3) decelerate
in the ﬁnite time for the same state. Thus we deﬁne E as:

E = (cid:107)g(st+1; M ) − M (cid:107) .

(2)

We can get from the deﬁnition of E as :
(1) If one state has been completely explored, or cannot
be learned, then no more information gain can be added into
the current memory, and E = 0. Such state is no longer
worth exploring.

(2) If E > 0, then the larger the value of E, the more
information gain can be consolidated into the memory. In
other words, the larger the value of E, the memory M is less
aware of the current state, such state is more worth explor-
ing. It is such information deﬁciency of memory that sparks
the curiosity of agents.

In this paper, we will focus on how to obtain and lever-
age the information value E for agents exploration, and the
information consolidation method g in details.

Dynamic Memory-based Curiosity

In our framework, if the information in current memory
cannot handle the encountered state, then the curiosity is
aroused. We model the memory as a learnable neural net-
work, but there is a dilemma that we do not have a “bench-
mark” encoded network in the parameter space to encode the
encountered state accurately, since not enough supervised
signal provided here. Thus it is difﬁcult and not sound to di-
rectly deﬁne the curiosity by comparing a random encoded
state with the output latent state from a dynamic memory
network. We instead introduce dual online learners for state
encode representations. These dual learners have the same
network architecture as the memory network but with each
own different parameters. In their network parameter space,
the dual networks are supervised by the memory encoding
ability. And then our curiosity can be deﬁned by the gap
of the encodings of the same state output by dual learners’
networks. The intuition of our dual learners is: if the state
information has been squeezed out by the memory, then the
memory can completely know and resolve the state, and the
dual learners which can be seen as the two imitators to the
memory are easier to get the similar encodings to the current
state. In other words, if one state is little known by the mem-
ory, then the dual learners may produce quite different en-
codings to it, which represents the larger information value
E and thus stimulates the agent to explore this state. Here,
for the uniform description, we refer the encoded states and
encodings to the latent states, which reﬂect the cognition of
states by the memory and learner networks.

In our implementation, such kind of latent gap E will
spark the curiosity as the intrinsic reward for agents explo-
ration. After the RL agents learning, such information will
be consolidated to the memory for memory better growing.
In terms of the consolidation method g, it is externalized as
updating the memory parameters via the exponential mov-
ing average (EMA) (Haynes, Corns, and Venayagamoorthy

Figure 2: Performance of different methods in the ﬁne-tuning phase on DeepMind Control Suite.

2012; Klinker 2011; Grebenkov and Serror 2014) of the dual
learners’ parameters.

From such analysis, we see the dual learners ﬁrst learn
based on the memory network for measure the information
value for exploration, and then the memory network consol-
idate information gain based on dual learners in the EMA
way. The memory is actually seeking for the appropriate po-
sition in the parameter space dynamically, in order that its
network can better characterize the memory and cognition
ability of the seen states in environments. In a word, our dy-
namic memory is updated in a bootstrap (Grill et al. 2020)
way. Figure 1 and algorithm 1 present the whole framework
and pseudo-code of DyMeCu.

• Learning of Dual Learners:
Dual online learner models fθ1 and fθ2 are deﬁned by a
set of weights θ1 and θ2 with the same architecture as the
memory network Mω. The memory provides the regression
targets for the learning of dual learners fθ1 and fθ2. Given
a current state st, the learners transform it into the latent
(cid:44) fθ1 (st) and zθ2
states zθ1
(cid:44) fθ2 (st) respectively, and the
t
t
(cid:44) Mω (st). The mean squared
memory network outputs zω
t
error (MSE) between them is:
(cid:13)
(cid:13)zθ1
(cid:13)
(cid:13)
(cid:13)zθ2
(cid:13)
Based on Lθ1 and Lθ2 , the dual learners are updated as :
(cid:26)θ1 ← optim (θ1, ∇θ1Lθ1 , η) ,
θ2 ← optim (θ2, ∇θ2Lθ1 , η) ,
where optim and η represent the optimizer and learning rate.

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
2
(cid:13)
(cid:13)

t − zω
t

t − zω
t




Lθ2

Lθ1

(3)

(4)



(cid:44)

(cid:44)

,

.

• Intrinsic Reward based on Curiosity:

The curiosity relies on the information value of current
state. In our method, such information value can be mea-
sured by the information gap between dual learners. This
information gap can also be considered following the δ-
Progress (Achiam and Sastry 2017; Graves et al. 2017) to

form the curiosity. We obtain the intrinsic reward to agents
based on the curiosity from the information value:

(5)

t (cid:107)2.

t − zω

t − zθ2

t ) − (zθ2

t )(cid:107)2 = (cid:107)zθ1

t = (cid:107)(zθ1
t − zω
rint
From another point of view, the dual-learner mechanism
can be regarded as the variant of ensemble (Mai, Mani, and
Paull 2022) for uncertainty estimation. Compared with pre-
vious attempts which requires heavily ensembling (such as
the Disagreement), our lightweight solution can previous
better performance while retaining computation efﬁciency.
Overall, we can get the optimization goal for the agent:

max
φ

Eπφ(st)

(cid:104)(cid:88)

γt(ζrint

t + βrext

t

(cid:105)

)

,

(6)

where γ is the discount factor and φ represents parameters of
policy π; ζ and β are the coefﬁcients of the intrinsic reward
and extrinsic reward respectively.

• Consolidating Information into Memory:

The memory model is updated in an EMA way for sake of
its stability to the old state information and the plasticity to
the current new state information. In other words, the mem-
ory is dynamically growing taking the contextual environ-
ment information into account. Speciﬁcally, given a decay
rate α ∈ [0, 1] and after each training step, the memory Mω
can be updated as:

θ1 + θ2
2
• Intuitions on DyMeCu’s behavior:

ω ← αω + (1 − α)

.

(7)

The dynamic memory-based curiosity is closer to human
curiosity mechanism. It is the cognitive difference compared
to the memory that stimulates our curiosity to explore the
world, and then we will consolidate the cognition infor-
mation to the memory dynamically. In addition, from the
knowledge distillation view, such memory can also be re-
garded as the teacher model in Mean Teacher-based ap-
proach (Tarvainen and Valpola 2017). The memory is essen-
tially a self-ensemble of the intermediate models of learners.

Table 1: Performance comparison with different pre-training methods on DeepMind Control Suite. The best results are in bold
font in each task, and the second best results are underlined.

Domain

Walker

Task
Flip
Run
Stand
Walk
Average Performance
Jump
Run
Stand
Walk
Average Performance

Quadruped

Jaco

Reach bottom left
Reach bottom right
Reach top left
Reach top right

Average Performance

ICM
398±18
216±35
928±18
696±162
560±59
112±4
91±29
184±100
99±46
122±45
102±47
75±27
105±29
93±19
94±31

Disagreement
407±75
291±81
680±107
595±153
494±104
383±265
389±61
628±114
384±28
446±117
117±17
142±3
121±17
131±10
128±12

RND
465±62
352±29
901±8
814±116
633±54
580±72
385±47
800±54
392±39
540±53
103±17
101±26
146±46
99±25
113±29

APT
477±16
344±28
914±8
759±35
624±22
462±48
339±40
622±57
434±64
465±52
88±12
115±12
112±11
136±5
113±10

ProtoRL
480±23
200±15
870±23
777±33
582±24
425±63
316±36
560±71
403±91
426±66
121±22
113±16
124±20
135±19
124±20

SMM DIAYN
381±17
505±26
242±11
430±26
860±26
877±34
661±26
821±36
536±20
659±31
578±46
298±39
415±28
220±37
706±48
367±42
406±64
184±26
527±47
268±36
17±5
40±9
31±4
50±9
11±3
50±7
19±4
37±8
20±4
44±9

APS
461±24
257±27
835±64
711±68
566±46
529±42
465±37
714±50
602±86
578±43
96±13
93±9
65±10
81±11
84±11

Ours
630±37
588±25
965±5
934±16
780±21
694±15
479±6
921±14
833±44
732±20
155±13
146±16
166±14
152±4
155±12

The paradigm we proposed is one type of replay mechanism
that is thought to play an important role in memory forma-
tion, retrieval, and consolidation (Hayes et al. 2021). More-
over, we consider our way to form the memory can also be
used in the continual learning to address the issue of catas-
trophic forgetting (Arani, Sarfraz, and Zonooz 2021).

Experiments and Analysis

Experimental Settings
We evaluate our method in both pre-training and traditional
RL situations utilizing two widely used benchmarks: Deep-
Mind Control Suite (DMC) (Tunyasuvunakool et al. 2020)
and Atari Suite (Bellemare et al. 2013). We follow the
RND (Burda et al. 2019) experimental settings for Atari
Suite and settings of URLB (Laskin et al. 2021) which is the
pre-training benchmark for DeepMind Control Suite. We ap-
ply PPO algorithm (Schulman et al. 2017) to train the agent.
The hyper-parameter α was set as 0.99 in all experiments,
and the implementation details and hyper-parameters can be
found in the appendix.

DeepMind Control Suite
Many well-performing approaches like URLB (Laskin et al.
2021) use the pre-training and ﬁne-tuning paradigm to im-
prove sample efﬁciency for RL, especially in the experiment
benchmark like DMC containing various domains and com-
plex tasks. We evaluate DyMeCu on all three domains of
DMC, namely Walker, Quadruped, and Jaco Arm (from eas-
iest to hardest), and each of them has four tasks. During the
pre-training phase, the agents are trained for 2 million steps
with only intrinsic rewards produced by the curiosity. Dur-
ing the ﬁne-tuning phase, the agents are trained for 100k
steps with only extrinsic rewards.

Table 1 reports the ﬁnal scores and standard deviations
of DyMeCu and other competitive methods. We compare
DyMeCu with both intrinsic reward-based methods (ICM,
Disagreement, RND, APT (Liu and Abbeel 2021b)) and
other pre-training strategies (ProtoRL (Yarats et al. 2021),
SMM (Lee et al. 2019), DIAYN (Eysenbach et al. 2018),

APS (Liu and Abbeel 2021a)). DyMeCu improves average
performance by 18.3%, 26.6%, and 21.0% on these three
domains respectively. From the quantitative results, we can
see our DyMeCu achieve the new state-of-the-art across
all 12 tasks, demonstrating DyMeCu’s ability to improve
the model performance and robustness through pre-training
paradigm. Figure 2 plots 6 learning curves (ﬁne-tuning
phase) of DyMeCu and three competitive curiosity-based
methods. All learning curves can be found in the appendix.
DyMeCu shows a superior convergence speed than other
methods. Meanwhile, the convergence result of DyMeCu
also surpasses others signiﬁcantly. DyMeCu’s speed in-
crease may sbe mainly due to the contextual state infor-
mation being consolidated into memory dynamically, rather
than a random ﬁxed setting like the RND. Based on the dy-
namic memory, the exploration of agents can be much more
efﬁcient.

Atari Suite

For the Atari suite, we ﬁrst record the performance of agents
with both intrinsic and extrinsic rewards. The experiments
conducts 100M running steps - equivalent to 400M frames
and the intrinsic and extrinsic rewards coefﬁcients are set
to ζ = 1 and β = 2 respectively for all methods, follow-
ing the setup of the previous curiosity-based methods. Ta-
ble 2 lists the aggregate metrics and scores of three meth-
ods trained with both intrinsic and extrinsic rewards on the
Atari 26 games. Human and random scores are adopted
from Hessel et al. (2018). As done in previous works (Liu
and Abbeel 2021b; Yarats, Kostrikov, and Fergus 2020;
Schwarzer et al. 2020), we normalize the episode reward
as human-normalized scores (HNS) by expert human scores
to account for different score scales in each game. #SOTA
denotes the number of games that the current method ex-
ceeds other methods and mean HNS is calculated as the
average of (agent score − random score)/(human score −
random score) of all games. From Table 2, DyMeCu dis-
plays the superiority over Disagreement and ICM with its
highest mean HNS and #SOTA.

Figure 3 displays the learning curves using both intrin-

Figure 3: Performance comparison on Atari games subsets using both intrinsic rewards and extrinsic rewards.

Table 2: Performance comparison of curiosity-based meth-
ods using both intrinsic and extrinsic rewards on 26 Atari
games subset. The bold font indicates the best value.

Game
Alien
Amidar
Assault
Asterix
Bank Heist
BattleZone
Boxing
Breakout
ChopperCommand
Crazy Climber
Demon Attack
Freeway
Frostbite
Gopher
Hero
Jamesbond
Kangaroo
Krull
Kung Fu Master
Ms Pacman
Pong
Private Eye
Qbert
Road Runner
Seaquest
Up N Down
Mean HNS
#SOTA

Random
227.8
5.8
222.4
210.0
14.2
2360.0
0.1
1.7
811.0
10780.5
107805.0
0.0
65.2
257.6
1027.0
29.0
52.0
1598.0
258.5
307.3
-20.7
24.9
163.9
11.5
68.4
533.4
0.0
N/A

Human
7127.7
1719.5
742.0
8503.3
753.1
37187.5
12.1
30.5
7387.8
23829.4
35829.4
29.6
4334.7
2412.5
30826.4
302.8
3035.0
2665.6
22736.3
6951.6
14.6
69571.3
13455.0
7845.0
42054.7
11693.2
1.0
N/A

ICM
1524.7
763.0
1365.5
2103.4
1359.4
51459.1
98.9
247.6
9456.5
135003.3
4679.2
33.8
309.4
14619.4
13482.2
680.8
12922.7
10027.1
40157.7
2787.0
20.1
96.0
16388.9
56273.7
16178.1
46152.9
2.861
7

Disagreement Ours
1304.7
506.6
1544.6
1616.2
1343.4
65387.4
99.3
177.8
10286.9
132614.0
6606.0
33.9
295.1
14202.4
13488.0
726.5
14621.8
11402.7
32607.2
6287.8
20.6
98.0
22474.5
55359.3
2733.1
18235.5
2.767
9

2589.2
470.1
4539.3
4576
1529.5
58220.0
99.6
119.7
9521.0
106682.0
8417.0
30.7
1750.0
9750.3
12728.5
5052.5
10760.0
6447.0
44604.9
2752.4
15.3
100.0
14770.2
32271.0
3910.9
18067.6
3.019
10

sic and extrinsic rewards. We compare DyMeCu with three
widely-used baselines, including Disagreement, ICM and
RND, on 6 random chosen Atari games. DyMeCu shows
evident advantages in most games on the performance and
learning speed. For example, on Jamesbond, the conver-
gence plot reward of DyMeCu is more than three times
that of other methods. Moreover, we also compare the per-
formance of agents trained with only intrinsic rewards. As
shown in Figure 4, of the 6 environments, DyMeCu out-
performs Disagreement baseline in all environments, out-
performs ICM and RND baselines both in 4 environments.
Overall,
the results in Atari Suite show that DyMeCu
outperforms other curiosity-based methods, demonstrating
DyMeCu’s ability to generate more accurate intrinsic re-
wards and provide more useful information for better ex-
ploration.

Figure 5: Performance comparison among two kinds of de-
ployments and baselines with both intrinsic and extrinsic re-
wards.

Further Analysis on DyMeCu
Further analysis including ablation studies on DyMeCu are
presented to give an intuition of its behavior and perfor-
mance. We run the experiments across 3 random seeds and
all following experiments conducts 50M running steps -
equivalent to 200M frames.

• Dual learners:

Here we explore to design the curiosity under the naive
setting, that is, using one encoding network to learn to en-
code the latent space, and thus the curiosity-based intrinsic
reward can be deﬁned as the gap with the memory network:

t (cid:107)2.

t − zω

t = (cid:107)zθ
rint

(8)
The memory is updated with ω ← αω + (1 − α)θ. As
shown in Figure 5, one-learner mechanism does not show
signiﬁcant advantages over other methods, whereas our
dual-learner mechanism performs much better with more ac-
curate curiosity and corresponding intrinsic rewards.

• Update of memory network:

The memory network in DyMeCu is updated with
dual learners, we additionally evaluate the performance of
DyMeCu when the memory is updated using only one of the

Figure 4: Performance comparison on Atari games suite subsets using only intrinsic rewards.

Table 3: Performance comparison of baselines and DyMeCu
under different settings with only intrinsic rewards. The re-
sults represent the average episode reward at the end of train-
ing. The Ave. in the last column shows the average result
among the three tasks.

Game

Method

Alien Kangaroo MsPacman

Ave.

Disagreement
ICM
RND
DyMeCu (ours)
DyMeCu update with one learner
DyMeCu with additional module

316.6
374.2
206.1
492.0
521.7
390.6

514.0
557.0
412.0
739.0
782.0
645.2

291.0
412.7
607.2
602.4
500.6
644.4

373.9
447.9
408.4
611.1
601.4
560.1

learner’s parameters. The results in Table 3 indicate that both
learners can consolidate state information into the memory
well. Combined with Figure 5, it is useful and necessary to
assign and train dual learners, and then we can update the
memory with dual or one-learner, while dual-learner update
mechanism shows a little superior performance.

• Structure of learners:

The bootstrap idea has been explored and used in some
previous researches. The most similar one to ours is
BYOL (Grill et al. 2020), which uses the bootstrap method
for self-supervised learning in computer vision. Further-
more, Grill et al. add another predictor module to the on-
line network, and compare the output of predictor to the tar-
get network, and it is the key to generating well-performed
representations (Chen and He 2021). Similarly, in this ab-
lation study, we also design the controlled trials, in which
additional two convolution layers are added to each of dual
learners. In Table 3, we can ﬁnd that such learnable addi-
tional module does not lead to signiﬁcant improvement. Un-
der our analysis, unlike previous work using the bootstrap
method, we aim to generate the intrinsic reward by calcu-
lating the information value (i.e., information gap between
dual learners) as accurate as possible, instead of better rep-
resentations for downstream tasks.

• Robustness to hyper-parameter α:

There is a concern of the updating speed of memory net-

Figure 6: Performance comparison with different values of
α with only intrinsic rewards.

work in the EMA way. It is about how much and how fast
to accept and consolidate the new environment informa-
tion. Therefore, to further analyze the updating effect of the
hyper-parameter α, we evaluate DyMeCu with different val-
ues of α in a rational interval, and we assess the agents’
performance in three different Atari games: Alien, Kan-
garoo, and Krull. For more direct and visual comparison,
we normalize the episode reward of DyMeCu as baseline-
normalized scores (BNS) which is calculated as the aver-
age of (DyMeCu score − random score)/(baseline score −
random score) where the baseline score is the average score
of baselines. As illustrated in Figure 6, all values of the
hyper-parameter α between 0.99 and 0.9999 yield satisﬁed
performance, generally greater than twice that of the base-
line average. DyMeCu shows acceptable robustness to the
updating hyper-parameter.

Conclusion

To address the challenge of extrinsic rewards sparsity in RL,
we propose DyMeCu to mimic human curiosity in this pa-
per. Speciﬁcally, DyMeCu consists of a dynamic memory
and dual online learners. The information gap between dual
learners sparks the agent’s curiosity and then formulates the
intrinsic reward, and the state information can then be con-
solidated into the dynamic memory. Large-scale empirical
experiments are conducted on multiple benchmarks, and the
experimental results show that DyMeCu outperforms com-
peting curiosity-based methods under different settings.

References
Abdar, M.; Pourpanah, F.; Hussain, S.; Rezazadegan, D.;
Liu, L.; Ghavamzadeh, M.; Fieguth, P.; Cao, X.; Khosravi,
A.; Acharya, U. R.; et al. 2021. A review of uncertainty
quantiﬁcation in deep learning: Techniques, applications and
challenges. Information Fusion, 76: 243–297.
Achiam, J.; and Sastry, S. 2017. Surprise-based intrinsic
motivation for deep reinforcement learning. arXiv preprint
arXiv:1703.01732.
Arani, E.; Sarfraz, F.; and Zonooz, B. 2021. Learning
Fast, Learning Slow: A General Continual Learning Method
based on Complementary Learning System. In International
Conference on Learning Representations.
Bellemare, M. G.; Naddaf, Y.; Veness, J.; and Bowling, M.
2013. The arcade learning environment: An evaluation plat-
form for general agents. Journal of Artiﬁcial Intelligence
Research, 47: 253–279.
Berlyne, D. E. 1950. Novelty and curiosity as determinants
of exploratory behaviour. British journal of psychology,
41(1): 68.
Burda, Y.; Edwards, H.; Pathak, D.; Storkey, A.; Darrell,
T.; and Efros, A. A. 2018. Large-Scale Study of Curiosity-
Driven Learning. In International Conference on Learning
Representations.
Burda, Y.; Edwards, H.; Storkey, A.; and Klimov, O. 2019.
Exploration by random network distillation. In International
Conference on Learning Representations.
Charikar, M. S. 2002. Similarity estimation techniques from
rounding algorithms. In Proceedings of the thiry-fourth an-
nual ACM symposium on Theory of computing, 380–388.
Chen, X.; and He, K. 2021. Exploring simple siamese repre-
sentation learning. In Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition, 15750–
15758.
de Abril, I. M.; and Kanai, R. 2018. Curiosity-driven rein-
forcement learning with homeostatic regulation. In 2018 in-
ternational joint conference on neural networks (ijcnn), 1–6.
IEEE.
Dietterich, T. G. 2000. Ensemble methods in machine learn-
In International workshop on multiple classiﬁer sys-
ing.
tems, 1–15. Springer.
Eysenbach, B.; Gupta, A.; Ibarz, J.; and Levine, S. 2018.
Diversity is all you need: Learning skills without a reward
function. arXiv preprint arXiv:1802.06070.
Flennerhag, S.; Schroecker, Y.; Zahavy, T.; van Hasselt, H.;
Silver, D.; and Singh, S. 2021. Bootstrapped meta-learning.
arXiv preprint arXiv:2109.04504.
Friston, K.; FitzGerald, T.; Rigoli, F.; Schwartenbeck, P.;
Pezzulo, G.; et al. 2016. Active inference and learning. Neu-
roscience & Biobehavioral Reviews, 68: 862–879.
Graves, A.; Bellemare, M. G.; Menick, J.; Munos, R.; and
Kavukcuoglu, K. 2017. Automated curriculum learning for
neural networks. In Proceedings of the 34th International
Conference on Machine Learning-Volume 70, 1311–1320.
Gray, R. M. 2011. Entropy and information theory. Springer
Science & Business Media.

Grebenkov, D. S.; and Serror, J. 2014. Following a trend
with an exponential moving average: Analytical results for
a Gaussian model. Physica A: Statistical Mechanics and its
Applications, 394: 288–303.
Grill, J.-B.; Strub, F.; Altch´e, F.; Tallec, C.; Richemond,
P.; Buchatskaya, E.; Doersch, C.; Avila Pires, B.; Guo, Z.;
Gheshlaghi Azar, M.; et al. 2020. Bootstrap your own latent-
a new approach to self-supervised learning. Advances in
Neural Information Processing Systems, 33: 21271–21284.
Guo, Z. D.; Pires, B. A.; Piot, B.; Grill, J.-B.; Altch´e,
F.; Munos, R.; and Azar, M. G. 2020. Bootstrap latent-
predictive representations for multitask reinforcement learn-
In International Conference on Machine Learning,
ing.
3875–3886. PMLR.

Hayes, T. L.; Krishnan, G. P.; Bazhenov, M.; Siegelmann,
H. T.; Sejnowski, T. J.; and Kanan, C. 2021. Replay in
deep learning: Current approaches and missing biological
elements. Neural Computation, 33(11): 2908–2950.
Haynes, D.; Corns, S.; and Venayagamoorthy, G. K. 2012.
In 2012 IEEE
An exponential moving average algorithm.
Congress on Evolutionary Computation, 1–8. IEEE.
Hessel, M.; Modayil, J.; Van Hasselt, H.; Schaul, T.; Os-
trovski, G.; Dabney, W.; Horgan, D.; Piot, B.; Azar, M.; and
Silver, D. 2018. Rainbow: Combining improvements in deep
reinforcement learning. In Thirty-second AAAI conference
on artiﬁcial intelligence.
Ishii, S.; Yoshida, W.; and Yoshimoto, J. 2002. Control of
exploitation–exploration meta-parameter in reinforcement
learning. Neural networks, 15(4-6): 665–687.
Jaegle, A.; Mehrpour, V.; and Rust, N. 2019. Visual novelty,
curiosity, and intrinsic reward in machine learning and the
brain. Current opinion in neurobiology, 58: 167–174.
Kearns, M.; and Singh, S. 2002. Near-optimal reinforcement
learning in polynomial time. Machine learning, 49(2): 209–
232.

Kidd, C.; and Hayden, B. Y. 2015. The psychology and neu-
roscience of curiosity. Neuron, 88(3): 449–460.
Kim, K.; Sano, M.; De Freitas, J.; Haber, N.; and Yamins,
D. 2020. Active world model learning with progress cu-
In International conference on machine learning,
riosity.
5306–5315. PMLR.

Klinker, F. 2011. Exponential moving average versus mov-
ing exponential average. Mathematische Semesterberichte,
58(1): 97–107.

Laskin, M.; Yarats, D.; Liu, H.; Lee, K.; Zhan, A.; Lu, K.;
Cang, C.; Pinto, L.; and Abbeel, P. 2021. URLB: Unsu-
pervised Reinforcement Learning Benchmark. In Deep RL
Workshop NeurIPS 2021.
Lee, L.; Eysenbach, B.; Parisotto, E.; Xing, E.; Levine, S.;
and Salakhutdinov, R. 2019. Efﬁcient exploration via state
marginal matching. arXiv preprint arXiv:1906.05274.
Liu, H.; and Abbeel, P. 2021a. Aps: Active pretraining with
successor features. In International Conference on Machine
Learning, 6736–6747. PMLR.

Szepesv´ari, C. 2009. Synthesis Lectures on Artiﬁcial Intelli-
gence and Machine Learning. Synthesis lectures on artiﬁcial
intelligence and machine learning.
Tao, R. Y.; Franc¸ois-Lavet, V.; and Pineau, J. 2020. Novelty
search in representational space for sample efﬁcient explo-
ration. Advances in Neural Information Processing Systems,
33: 8114–8126.
Tarvainen, A.; and Valpola, H. 2017. Mean teachers are
better role models: Weight-averaged consistency targets im-
prove semi-supervised deep learning results. Advances in
neural information processing systems, 30.
Tesauro, G.; et al. 1995. Temporal difference learning and
TD-Gammon. Communications of the ACM, 38(3): 58–68.
Tunyasuvunakool, S.; Muldal, A.; Doron, Y.; Liu, S.; Bohez,
S.; Merel, J.; Erez, T.; Lillicrap, T.; Heess, N.; and Tassa, Y.
2020. dm control: Software and tasks for continuous con-
trol. Software Impacts, 6: 100022.
Yang, T.; Tang, H.; Bai, C.; Liu, J.; Hao, J.; Meng, Z.; and
Liu, P. 2021. Exploration in deep reinforcement learning: a
comprehensive survey. arXiv preprint arXiv:2109.06668.
Yarats, D.; Fergus, R.; Lazaric, A.; and Pinto, L. 2021.
Reinforcement learning with prototypical representations.
In International Conference on Machine Learning, 11920–
11931. PMLR.
Yarats, D.; Kostrikov, I.; and Fergus, R. 2020. Image aug-
mentation is all you need: Regularizing deep reinforcement
learning from pixels. In International Conference on Learn-
ing Representations.

Liu, H.; and Abbeel, P. 2021b. Behavior from the void: Un-
supervised active pre-training. Advances in Neural Informa-
tion Processing Systems, 34.
Liu, J.; Lin, Z.; Padhy, S.; Tran, D.; Bedrax Weiss, T.; and
Lakshminarayanan, B. 2020. Simple and principled uncer-
tainty estimation with deterministic deep learning via dis-
tance awareness. Advances in Neural Information Process-
ing Systems, 33: 7498–7512.
Mai, V.; Mani, K.; and Paull, L. 2022. Sample Efﬁcient Deep
Reinforcement Learning via Uncertainty Estimation. arXiv
preprint arXiv:2201.01666.
Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Ve-
ness, J.; Bellemare, M. G.; Graves, A.; Riedmiller, M.; Fidje-
land, A. K.; Ostrovski, G.; et al. 2015. Human-level control
through deep reinforcement learning. nature, 518(7540):
529–533.
O’Reilly, R. C.; and Rudy, J. W. 2001. Conjunctive repre-
sentations in learning and memory: principles of cortical and
hippocampal function. Psychological review, 108(2): 311.
Pathak, D.; Agrawal, P.; Efros, A. A.; and Darrell, T. 2017.
Curiosity-driven exploration by self-supervised prediction.
In International Conference on Machine Learning, 2778–
2787. PMLR.
Pathak, D.; Gandhi, D.; and Gupta, A. 2019. Self-supervised
exploration via disagreement. In International Conference
on Machine Learning, 5062–5071. PMLR.
Peterson, E. J.; and Verstynen, T. D. 2021. Curiosity
eliminates the exploration-exploitation dilemma. bioRxiv,
671362.
Reddy, G.; Celani, A.; and Vergassola, M. 2016. Infomax
strategies for an optimal balance between exploration and
exploitation. Journal of Statistical Physics, 163(6): 1454–
1476.
Rotgans, J. I.; and Schmidt, H. G. 2017. The role of interest
in learning: knowledge acquisition at the intersection of sit-
uational and individual interest. In The science of interest,
69–93. Springer.
Ryan, R. M.; and Deci, E. L. 2000. Intrinsic and extrinsic
motivations: Classic deﬁnitions and new directions. Con-
temporary educational psychology, 25(1): 54–67.
Schmidhuber, J. 1991. A possibility for implementing cu-
riosity and boredom in model-building neural controllers. In
Proc. of the international conference on simulation of adap-
tive behavior: From animals to animats, 222–227.
Schulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; and
Klimov, O. 2017. Proximal policy optimization algorithms.
arXiv preprint arXiv:1707.06347.
Schwarzer, M.; Anand, A.; Goel, R.; Hjelm, R. D.;
Courville, A.; and Bachman, P. 2020. Data-Efﬁcient Re-
inforcement Learning with Self-Predictive Representations.
In International Conference on Learning Representations.
Silvia, P. J. 2017. Curiosity. In The science of interest, 97–
107. Springer.
Smith, L.; and Gasser, M. 2005. The development of em-
bodied cognition: Six lessons from babies. Artiﬁcial life,
11(1-2): 13–29.

","Dynamic Memory-based Curiosity: A Bootstrap Approach for Exploration Zijian Gao1, Kele Xu1*, YiYing Li2, Yuanzhao Zhai1, Dawei Feng1, Bo Ding1, XinJun Mao1, Huaimin Wang1 1 National University of Defense Technology, Changsha, China 2 Artiﬁcial Intelligence Research Center, DII, Beijing, China kelele.xu@gmail.com 2 2 0 2 g u A 4 2 ] I A . s c [ 1 v 9 4 3 1 1 . 8 0 2 2 : v i X r a Abstract The sparsity of extrinsic rewards poses a serious chal- lenge for reinforcement learning (RL). Currently, many efforts have been made on curiosity which can pro- vide a representative intrinsic reward for effective ex- ploration. However, the challenge is still far from be- ing solved. In this paper, we present a novel curiosity for RL, named DyMeCu, which stands for Dynamic Memory-based Curiosity. Inspired by human curiosity and information theory, DyMeCu consists of a dynamic memory and dual online learners. The curiosity arouses if memorized information can not deal with the current state, and the information gap between dual learners can be formulated as the intrinsic reward for agents, and then such state information can be consolidated into the dynamic memory. Compared with previous curiosity methods, DyMeCu can better mimic human curiosity with dynamic memory, and the memory module can be dynamically grown based on a bootstrap paradigm with dual learners. On multiple benchmarks including Deep- Mind Control Suite and Atari Suite, large-scale empir- ical experiments are conducted and the results demon- strate that DyMeCu outperforms competitive curiosity- based methods with or without extrinsic rewards. We will release the code to enhance reproducibility. Introduction Despite the success of reinforcement learning (RL) on sequential decision-making tasks (Bellemare et al. 2013; Tesauro et al. 1995; Mnih et al. 2015), many current methods struggle with sparse extrinsic rewards. To cope with the spar- sity, curiosity provides a representative intrinsic reward that can encourage agents to explore new states. Designing algo- rithms to efﬁciently construct curiosity can be a key compo- nent in RL systems. Previous research has shown that intrin- sic rewards can help alleviate the issues resulting from the lacking of dense extrinsic rewards (Liu and Abbeel 2021b; Tao, Franc¸ois-Lavet, and Pineau 2020; Yang et al. 2021). For human learning, curiosity motivates people to seek and retain more information through exploration in the envi- ronment (Burda et al. 2018; Ryan and Deci 2000; Smith and Gasser 2005). The process of arousing and satisfying curios- ity can be summed up as one cycle: when a person encoun- ters a problem, he/she will ﬁrst try to solve it by retrieving information from memory. If retrieval from memory fails, he/she realizes that the current memorized information is in- sufﬁcient solve the problem. A conscious awareness of in- formation discrepancy then sparks curiosity about the prob- lem, and curiosity stimulates the search for new informa- tion. Once the information discrepancy is eliminated, people may have no further curiosity to learn more about the cur- rent problem until another problem is encountered (Rotgans and Schmidt 2017; Silvia 2017). Human curiosity is con- stantly consolidated based on the dynamic memory, which consists of the encoding, storing, and retrieving information stage (Hayes et al. 2021). As the curiosity fades, additional information is consolidated into the memory. The consolida- tion results in the forming of new dynamic memories, which depends on the hippocampus (O’Reilly and Rudy 2001). Many attempts have been made to build curiosity in RL, which fall into two main categories: count-based and prediction-based. However, such curiosity is very different from human curiosity, and the problem is far from solved. Taking the Random Network Distillation (RND) (Burda et al. 2019) method as an example, RND initializes a ran- dom ﬁxed target network with state embeddings, and trains another prediction network to ﬁt the output of the target net- work. A random ﬁxed target network can be regarded as a random ﬁxed memory, so that RND cannot retain contextual knowledge about the environment (Yang et al. 2021). With- out dynamically incorporating contextual information into memory, random features may not be sufﬁcient to interpret dynamic environments. Therefore, this kind of curiosity is evaluated in a non-developmental way, which severely lim- its the performance of curiosity in RL. In this work, to mimic human curiosity, we formalize and investigate a Dynamic Memory-based Curiosity mechanism, named DyMeCu. Inspired by the bootstrap paradigm (Guo et al. 2020; Grill et al. 2020; Flennerhag et al. 2021), we construct dual online learners to learn the latent state to formulate dynamic memory model (Figure 1). On the one hand, state information can be consolidated to the memory via the exponential moving average (EMA) (Haynes, Corns, and Venayagamoorthy 2012; Klinker 2011; Grebenkov and Serror 2014) of dual learners’ parameters. The bootstrap The term bootstrap is used in this text in its colloquial meaning *Corresponding author: Kele Xu rather than its statistical connotation. Figure 1: DyMeCu employs a novel learning framework to build the intrinsic reward for RL, which consists of a dynamic memory and dual online learners. The information discrepancy of the current state compared with the retrieved information from the memory makes curiosity arouse. We get the curiosity-based intrinsic reward for agent learning by calculating the information gap between dual online learners. Then the state information can be dynamically consolidated into the memory in the bootstrap paradigm for curiosity fading. paradigm, on the other hand, utilizes supervised signals from memory to improve dual learners’ encoding ability. Further- more, the curiosity is measured by the information gap be- tween the dual learners, which is essentially an uncertainty estimation of given state based on dynamic memory (Mai, Mani, and Paull 2022; Liu et al. 2020; Abdar et al. 2021). In brief, our contribution in this paper is: • We ﬁrstly analyze the shortcomings of previous curiosity-based intrinsic reward methods, and suggest to mimic human curiosity leveraging a dynamic memory in- stead of a ﬁxed one, based on the information theory. • We propose a novel and practicable intrinsic reward method for RL agents, named DyMeCu (Dynamic Memory-based Curiosity), which consists of a dynamic memory and dual online learners, and thus can measure the curiosity and consolidate the information in a feasi- ble way. Meanwhile, different strategies are explored to further improve the performance of DyMeCu. • On multiple benchmarks including DeepMind Con- trol Suite (DMC) (Tunyasuvunakool et al. 2020) and Atari Suite (Bellemare et al. 2013), large-scale empiri- cal experiments demonstrate that DyMeCu outperforms the other competitive curiosity-based methods and pre- training strategies. Related Work Curiosity-Based Intrinsic Reward In RL, the exploration issue is a long standing challenge. Previous attempts suggest that: if there is no additional re- ward, exploration can be regarded as a hunt for informa- tion theoretically, which also can be viewed as the curios- ity (Berlyne 1950; Schmidhuber 1991; Kidd and Hayden 2015; de Abril and Kanai 2018; Jaegle, Mehrpour, and Rust 2019; Friston et al. 2016; Peterson and Verstynen 2021). One intuitive formulation of curiosity is the count-based meth- ods, where the less visited state has more state novelty for exploration. But it can not scale to large-scale or continu- ous state spaces (Kearns and Singh 2002; Charikar 2002). Inspired by count-based methods, RND calculates the state novelty by distilling a random ﬁxed network (target net- work) into another prediction network (predictor network). The predictor network is trained to minimize the prediction error for each state and take the prediction error as the in- trinsic reward. Apart from count-based methods, prediction- based methods also show competitive or better performance by modeling the environment dynamics (Pathak et al. 2017; Pathak, Gandhi, and Gupta 2019; Kim et al. 2020; Burda et al. 2018). With the assumption that more visited state- action pairs will result in more accurate prediction, the in- trinsic reward can be applied as the variance of predic- tions of ensembles or the distance between prediction states and true states, such as the Disagreement method (Pathak, Gandhi, and Gupta 2019) and ICM (Pathak et al. 2017) method. There have been few attempts to design a curios- ity that contains memory and effectively uses information consolidated in memory, which however is the main goal of this paper. Uncertainty Estimation Our work is also related to the uncertainty estimation, as uncertainty is crucial which allows an agent to discern when to exploit and when to explore its environment in RL (Szepesv´ari 2009). Previous intrinsic rewards can also be interpreted from the perspective of uncertainty estima- tion, which can evaluate curiosity by estimating the deep learning model’s uncertainty (conﬁdence). Take Disagree- Curiosity Arouses Curiosity-based Learning & Curiosity Fades Novel State 𝑆𝑡 Encode Latent State Retrieve Information State 𝑠𝑡 Information Discrepancy Memory Model 𝜔 Output Retrieved Information Online Learner 𝜃1 EMA Memory Model 𝜔 EMA Online Learner 𝜃2 𝜃1 𝑧𝑡 loss 𝜔 𝑧𝑡 loss 𝜃2 𝑧𝑡 Stop- gradient 𝑖𝑛𝑡 𝑟𝑡 𝑠𝑡 State 𝜋 Policy 𝑎𝑡 Action 𝑠𝑡+1 Next State Algorithm 1: Dynamic Memory-based Curiosity Initialization: policy network πφ; dual online learner net- works fθ1, fθ2; memory network Mω; coefﬁcients of intrin- sic and extrinsic reward ζ, β. 1: while Training do 2: 3: 4: 5: Receive state st from environment at ← πφ(a|s) based on policy network πφ Take action at, receive state st+1 and extrinsic re- ext from environment ward rt Collect step data into replay buffer st ← st+1 for t = 1, · · · , T do end for Sample batch data as {(si, ai, ri replay buffer for each i = 1, · · · , N do ext, si+1)}N i=1from Generate latent state vectors zθ1 fθ2 (si), zω i = Mω(si) Calculate intrinsic reward rint Calculate total reward ri total = ζri i = (cid:107)zθ1 i − zθ2 i (cid:107)2 int + βrext i i = fθ1 (si), zθ2 i = end for Update θ1 and θ2 with sampled data by minimizing loss with equation (3) Update ω with equation (7) Update φ with sampled data by maximizing rtotal us- ing RL algorithm 6: 7: 8: 9: 10: 11: 12: 13: 14: 15: 16: 17: 18: end while ment as an example, instead of comparing the prediction to the ground-truth, they suggest to evaluate the uncertainty of multiple prediction models using the deep ensemble (Diet- terich 2000), despite incurring additional computation. RND also claims that the distillation error can be viewed as a quantiﬁcation of the uncertainty. Unlike RND, in our work, we evaluate the uncertainty of given states though measur- ing the information gap between dual learners which rely on dynamic memory instead of a random ﬁxed network. Methodology In general, if an agent encounters a state with the informa- tion value E compared to its memory, then this state is worth exploring and such information value is worth consolidat- ing to its memory dynamically (Rotgans and Schmidt 2017; Silvia 2017). In detail, the concept of information value E necessitates the formation of the dynamic memory M and a way g to consolidate information to the memory. For deep neural networks, the memory M can be embedded in the la- tent space and g can by the function that maps state s into memory (Peterson and Verstynen 2021). This kind of con- solidating information is denoted by: g(s; M ) → M (cid:48). (1) With the memory M which has been learned by g over historical states, we can measure the information value E of the next state st+1. According to the information the- ory (Ishii, Yoshida, and Yoshimoto 2002; Reddy, Celani, and Vergassola 2016; Gray 2011) and the concepts proposed in Peterson and Verstynen (2021), the information value E of a state should (1) only depend on the memory and what can be immediately learned (i.e., M , s and g); (2) be non-negative because E is for exploring the environment; (3) decelerate in the ﬁnite time for the same state. Thus we deﬁne E as: E = (cid:107)g(st+1; M ) − M (cid:107) . (2) We can get from the deﬁnition of E as : (1) If one state has been completely explored, or cannot be learned, then no more information gain can be added into the current memory, and E = 0. Such state is no longer worth exploring. (2) If E > 0, then the larger the value of E, the more information gain can be consolidated into the memory. In other words, the larger the value of E, the memory M is less aware of the current state, such state is more worth explor- ing. It is such information deﬁciency of memory that sparks the curiosity of agents. In this paper, we will focus on how to obtain and lever- age the information value E for agents exploration, and the information consolidation method g in details. Dynamic Memory-based Curiosity In our framework, if the information in current memory cannot handle the encountered state, then the curiosity is aroused. We model the memory as a learnable neural net- work, but there is a dilemma that we do not have a “bench- mark” encoded network in the parameter space to encode the encountered state accurately, since not enough supervised signal provided here. Thus it is difﬁcult and not sound to di- rectly deﬁne the curiosity by comparing a random encoded state with the output latent state from a dynamic memory network. We instead introduce dual online learners for state encode representations. These dual learners have the same network architecture as the memory network but with each own different parameters. In their network parameter space, the dual networks are supervised by the memory encoding ability. And then our curiosity can be deﬁned by the gap of the encodings of the same state output by dual learners’ networks. The intuition of our dual learners is: if the state information has been squeezed out by the memory, then the memory can completely know and resolve the state, and the dual learners which can be seen as the two imitators to the memory are easier to get the similar encodings to the current state. In other words, if one state is little known by the mem- ory, then the dual learners may produce quite different en- codings to it, which represents the larger information value E and thus stimulates the agent to explore this state. Here, for the uniform description, we refer the encoded states and encodings to the latent states, which reﬂect the cognition of states by the memory and learner networks. In our implementation, such kind of latent gap E will spark the curiosity as the intrinsic reward for agents explo- ration. After the RL agents learning, such information will be consolidated to the memory for memory better growing. In terms of the consolidation method g, it is externalized as updating the memory parameters via the exponential mov- ing average (EMA) (Haynes, Corns, and Venayagamoorthy Figure 2: Performance of different methods in the ﬁne-tuning phase on DeepMind Control Suite. 2012; Klinker 2011; Grebenkov and Serror 2014) of the dual learners’ parameters. From such analysis, we see the dual learners ﬁrst learn based on the memory network for measure the information value for exploration, and then the memory network consol- idate information gain based on dual learners in the EMA way. The memory is actually seeking for the appropriate po- sition in the parameter space dynamically, in order that its network can better characterize the memory and cognition ability of the seen states in environments. In a word, our dy- namic memory is updated in a bootstrap (Grill et al. 2020) way. Figure 1 and algorithm 1 present the whole framework and pseudo-code of DyMeCu. • Learning of Dual Learners: Dual online learner models fθ1 and fθ2 are deﬁned by a set of weights θ1 and θ2 with the same architecture as the memory network Mω. The memory provides the regression targets for the learning of dual learners fθ1 and fθ2. Given a current state st, the learners transform it into the latent (cid:44) fθ1 (st) and zθ2 states zθ1 (cid:44) fθ2 (st) respectively, and the t t (cid:44) Mω (st). The mean squared memory network outputs zω t error (MSE) between them is: (cid:13) (cid:13)zθ1 (cid:13) (cid:13) (cid:13)zθ2 (cid:13) Based on Lθ1 and Lθ2 , the dual learners are updated as : (cid:26)θ1 ← optim (θ1, ∇θ1Lθ1 , η) , θ2 ← optim (θ2, ∇θ2Lθ1 , η) , where optim and η represent the optimizer and learning rate. (cid:13) 2 (cid:13) (cid:13) (cid:13) 2 (cid:13) (cid:13) t − zω t t − zω t   Lθ2 Lθ1 (3) (4)  (cid:44) (cid:44) , . • Intrinsic Reward based on Curiosity: The curiosity relies on the information value of current state. In our method, such information value can be mea- sured by the information gap between dual learners. This information gap can also be considered following the δ- Progress (Achiam and Sastry 2017; Graves et al. 2017) to form the curiosity. We obtain the intrinsic reward to agents based on the curiosity from the information value: (5) t (cid:107)2. t − zω t − zθ2 t ) − (zθ2 t )(cid:107)2 = (cid:107)zθ1 t = (cid:107)(zθ1 t − zω rint From another point of view, the dual-learner mechanism can be regarded as the variant of ensemble (Mai, Mani, and Paull 2022) for uncertainty estimation. Compared with pre- vious attempts which requires heavily ensembling (such as the Disagreement), our lightweight solution can previous better performance while retaining computation efﬁciency. Overall, we can get the optimization goal for the agent: max φ Eπφ(st) (cid:104)(cid:88) γt(ζrint t + βrext t (cid:105) ) , (6) where γ is the discount factor and φ represents parameters of policy π; ζ and β are the coefﬁcients of the intrinsic reward and extrinsic reward respectively. • Consolidating Information into Memory: The memory model is updated in an EMA way for sake of its stability to the old state information and the plasticity to the current new state information. In other words, the mem- ory is dynamically growing taking the contextual environ- ment information into account. Speciﬁcally, given a decay rate α ∈ [0, 1] and after each training step, the memory Mω can be updated as: θ1 + θ2 2 • Intuitions on DyMeCu’s behavior: ω ← αω + (1 − α) . (7) The dynamic memory-based curiosity is closer to human curiosity mechanism. It is the cognitive difference compared to the memory that stimulates our curiosity to explore the world, and then we will consolidate the cognition infor- mation to the memory dynamically. In addition, from the knowledge distillation view, such memory can also be re- garded as the teacher model in Mean Teacher-based ap- proach (Tarvainen and Valpola 2017). The memory is essen- tially a self-ensemble of the intermediate models of learners. Table 1: Performance comparison with different pre-training methods on DeepMind Control Suite. The best results are in bold font in each task, and the second best results are underlined. Domain Walker Task Flip Run Stand Walk Average Performance Jump Run Stand Walk Average Performance Quadruped Jaco Reach bottom left Reach bottom right Reach top left Reach top right Average Performance ICM 398±18 216±35 928±18 696±162 560±59 112±4 91±29 184±100 99±46 122±45 102±47 75±27 105±29 93±19 94±31 Disagreement 407±75 291±81 680±107 595±153 494±104 383±265 389±61 628±114 384±28 446±117 117±17 142±3 121±17 131±10 128±12 RND 465±62 352±29 901±8 814±116 633±54 580±72 385±47 800±54 392±39 540±53 103±17 101±26 146±46 99±25 113±29 APT 477±16 344±28 914±8 759±35 624±22 462±48 339±40 622±57 434±64 465±52 88±12 115±12 112±11 136±5 113±10 ProtoRL 480±23 200±15 870±23 777±33 582±24 425±63 316±36 560±71 403±91 426±66 121±22 113±16 124±20 135±19 124±20 SMM DIAYN 381±17 505±26 242±11 430±26 860±26 877±34 661±26 821±36 536±20 659±31 578±46 298±39 415±28 220±37 706±48 367±42 406±64 184±26 527±47 268±36 17±5 40±9 31±4 50±9 11±3 50±7 19±4 37±8 20±4 44±9 APS 461±24 257±27 835±64 711±68 566±46 529±42 465±37 714±50 602±86 578±43 96±13 93±9 65±10 81±11 84±11 Ours 630±37 588±25 965±5 934±16 780±21 694±15 479±6 921±14 833±44 732±20 155±13 146±16 166±14 152±4 155±12 The paradigm we proposed is one type of replay mechanism that is thought to play an important role in memory forma- tion, retrieval, and consolidation (Hayes et al. 2021). More- over, we consider our way to form the memory can also be used in the continual learning to address the issue of catas- trophic forgetting (Arani, Sarfraz, and Zonooz 2021). Experiments and Analysis Experimental Settings We evaluate our method in both pre-training and traditional RL situations utilizing two widely used benchmarks: Deep- Mind Control Suite (DMC) (Tunyasuvunakool et al. 2020) and Atari Suite (Bellemare et al. 2013). We follow the RND (Burda et al. 2019) experimental settings for Atari Suite and settings of URLB (Laskin et al. 2021) which is the pre-training benchmark for DeepMind Control Suite. We ap- ply PPO algorithm (Schulman et al. 2017) to train the agent. The hyper-parameter α was set as 0.99 in all experiments, and the implementation details and hyper-parameters can be found in the appendix. DeepMind Control Suite Many well-performing approaches like URLB (Laskin et al. 2021) use the pre-training and ﬁne-tuning paradigm to im- prove sample efﬁciency for RL, especially in the experiment benchmark like DMC containing various domains and com- plex tasks. We evaluate DyMeCu on all three domains of DMC, namely Walker, Quadruped, and Jaco Arm (from eas- iest to hardest), and each of them has four tasks. During the pre-training phase, the agents are trained for 2 million steps with only intrinsic rewards produced by the curiosity. Dur- ing the ﬁne-tuning phase, the agents are trained for 100k steps with only extrinsic rewards. Table 1 reports the ﬁnal scores and standard deviations of DyMeCu and other competitive methods. We compare DyMeCu with both intrinsic reward-based methods (ICM, Disagreement, RND, APT (Liu and Abbeel 2021b)) and other pre-training strategies (ProtoRL (Yarats et al. 2021), SMM (Lee et al. 2019), DIAYN (Eysenbach et al. 2018), APS (Liu and Abbeel 2021a)). DyMeCu improves average performance by 18.3%, 26.6%, and 21.0% on these three domains respectively. From the quantitative results, we can see our DyMeCu achieve the new state-of-the-art across all 12 tasks, demonstrating DyMeCu’s ability to improve the model performance and robustness through pre-training paradigm. Figure 2 plots 6 learning curves (ﬁne-tuning phase) of DyMeCu and three competitive curiosity-based methods. All learning curves can be found in the appendix. DyMeCu shows a superior convergence speed than other methods. Meanwhile, the convergence result of DyMeCu also surpasses others signiﬁcantly. DyMeCu’s speed in- crease may sbe mainly due to the contextual state infor- mation being consolidated into memory dynamically, rather than a random ﬁxed setting like the RND. Based on the dy- namic memory, the exploration of agents can be much more efﬁcient. Atari Suite For the Atari suite, we ﬁrst record the performance of agents with both intrinsic and extrinsic rewards. The experiments conducts 100M running steps - equivalent to 400M frames and the intrinsic and extrinsic rewards coefﬁcients are set to ζ = 1 and β = 2 respectively for all methods, follow- ing the setup of the previous curiosity-based methods. Ta- ble 2 lists the aggregate metrics and scores of three meth- ods trained with both intrinsic and extrinsic rewards on the Atari 26 games. Human and random scores are adopted from Hessel et al. (2018). As done in previous works (Liu and Abbeel 2021b; Yarats, Kostrikov, and Fergus 2020; Schwarzer et al. 2020), we normalize the episode reward as human-normalized scores (HNS) by expert human scores to account for different score scales in each game. #SOTA denotes the number of games that the current method ex- ceeds other methods and mean HNS is calculated as the average of (agent score − random score)/(human score − random score) of all games. From Table 2, DyMeCu dis- plays the superiority over Disagreement and ICM with its highest mean HNS and #SOTA. Figure 3 displays the learning curves using both intrin- Figure 3: Performance comparison on Atari games subsets using both intrinsic rewards and extrinsic rewards. Table 2: Performance comparison of curiosity-based meth- ods using both intrinsic and extrinsic rewards on 26 Atari games subset. The bold font indicates the best value. Game Alien Amidar Assault Asterix Bank Heist BattleZone Boxing Breakout ChopperCommand Crazy Climber Demon Attack Freeway Frostbite Gopher Hero Jamesbond Kangaroo Krull Kung Fu Master Ms Pacman Pong Private Eye Qbert Road Runner Seaquest Up N Down Mean HNS #SOTA Random 227.8 5.8 222.4 210.0 14.2 2360.0 0.1 1.7 811.0 10780.5 107805.0 0.0 65.2 257.6 1027.0 29.0 52.0 1598.0 258.5 307.3 -20.7 24.9 163.9 11.5 68.4 533.4 0.0 N/A Human 7127.7 1719.5 742.0 8503.3 753.1 37187.5 12.1 30.5 7387.8 23829.4 35829.4 29.6 4334.7 2412.5 30826.4 302.8 3035.0 2665.6 22736.3 6951.6 14.6 69571.3 13455.0 7845.0 42054.7 11693.2 1.0 N/A ICM 1524.7 763.0 1365.5 2103.4 1359.4 51459.1 98.9 247.6 9456.5 135003.3 4679.2 33.8 309.4 14619.4 13482.2 680.8 12922.7 10027.1 40157.7 2787.0 20.1 96.0 16388.9 56273.7 16178.1 46152.9 2.861 7 Disagreement Ours 1304.7 506.6 1544.6 1616.2 1343.4 65387.4 99.3 177.8 10286.9 132614.0 6606.0 33.9 295.1 14202.4 13488.0 726.5 14621.8 11402.7 32607.2 6287.8 20.6 98.0 22474.5 55359.3 2733.1 18235.5 2.767 9 2589.2 470.1 4539.3 4576 1529.5 58220.0 99.6 119.7 9521.0 106682.0 8417.0 30.7 1750.0 9750.3 12728.5 5052.5 10760.0 6447.0 44604.9 2752.4 15.3 100.0 14770.2 32271.0 3910.9 18067.6 3.019 10 sic and extrinsic rewards. We compare DyMeCu with three widely-used baselines, including Disagreement, ICM and RND, on 6 random chosen Atari games. DyMeCu shows evident advantages in most games on the performance and learning speed. For example, on Jamesbond, the conver- gence plot reward of DyMeCu is more than three times that of other methods. Moreover, we also compare the per- formance of agents trained with only intrinsic rewards. As shown in Figure 4, of the 6 environments, DyMeCu out- performs Disagreement baseline in all environments, out- performs ICM and RND baselines both in 4 environments. Overall, the results in Atari Suite show that DyMeCu outperforms other curiosity-based methods, demonstrating DyMeCu’s ability to generate more accurate intrinsic re- wards and provide more useful information for better ex- ploration. Figure 5: Performance comparison among two kinds of de- ployments and baselines with both intrinsic and extrinsic re- wards. Further Analysis on DyMeCu Further analysis including ablation studies on DyMeCu are presented to give an intuition of its behavior and perfor- mance. We run the experiments across 3 random seeds and all following experiments conducts 50M running steps - equivalent to 200M frames. • Dual learners: Here we explore to design the curiosity under the naive setting, that is, using one encoding network to learn to en- code the latent space, and thus the curiosity-based intrinsic reward can be deﬁned as the gap with the memory network: t (cid:107)2. t − zω t = (cid:107)zθ rint (8) The memory is updated with ω ← αω + (1 − α)θ. As shown in Figure 5, one-learner mechanism does not show signiﬁcant advantages over other methods, whereas our dual-learner mechanism performs much better with more ac- curate curiosity and corresponding intrinsic rewards. • Update of memory network: The memory network in DyMeCu is updated with dual learners, we additionally evaluate the performance of DyMeCu when the memory is updated using only one of the Figure 4: Performance comparison on Atari games suite subsets using only intrinsic rewards. Table 3: Performance comparison of baselines and DyMeCu under different settings with only intrinsic rewards. The re- sults represent the average episode reward at the end of train- ing. The Ave. in the last column shows the average result among the three tasks. Game Method Alien Kangaroo MsPacman Ave. Disagreement ICM RND DyMeCu (ours) DyMeCu update with one learner DyMeCu with additional module 316.6 374.2 206.1 492.0 521.7 390.6 514.0 557.0 412.0 739.0 782.0 645.2 291.0 412.7 607.2 602.4 500.6 644.4 373.9 447.9 408.4 611.1 601.4 560.1 learner’s parameters. The results in Table 3 indicate that both learners can consolidate state information into the memory well. Combined with Figure 5, it is useful and necessary to assign and train dual learners, and then we can update the memory with dual or one-learner, while dual-learner update mechanism shows a little superior performance. • Structure of learners: The bootstrap idea has been explored and used in some previous researches. The most similar one to ours is BYOL (Grill et al. 2020), which uses the bootstrap method for self-supervised learning in computer vision. Further- more, Grill et al. add another predictor module to the on- line network, and compare the output of predictor to the tar- get network, and it is the key to generating well-performed representations (Chen and He 2021). Similarly, in this ab- lation study, we also design the controlled trials, in which additional two convolution layers are added to each of dual learners. In Table 3, we can ﬁnd that such learnable addi- tional module does not lead to signiﬁcant improvement. Un- der our analysis, unlike previous work using the bootstrap method, we aim to generate the intrinsic reward by calcu- lating the information value (i.e., information gap between dual learners) as accurate as possible, instead of better rep- resentations for downstream tasks. • Robustness to hyper-parameter α: There is a concern of the updating speed of memory net- Figure 6: Performance comparison with different values of α with only intrinsic rewards. work in the EMA way. It is about how much and how fast to accept and consolidate the new environment informa- tion. Therefore, to further analyze the updating effect of the hyper-parameter α, we evaluate DyMeCu with different val- ues of α in a rational interval, and we assess the agents’ performance in three different Atari games: Alien, Kan- garoo, and Krull. For more direct and visual comparison, we normalize the episode reward of DyMeCu as baseline- normalized scores (BNS) which is calculated as the aver- age of (DyMeCu score − random score)/(baseline score − random score) where the baseline score is the average score of baselines. As illustrated in Figure 6, all values of the hyper-parameter α between 0.99 and 0.9999 yield satisﬁed performance, generally greater than twice that of the base- line average. DyMeCu shows acceptable robustness to the updating hyper-parameter. Conclusion To address the challenge of extrinsic rewards sparsity in RL, we propose DyMeCu to mimic human curiosity in this pa- per. Speciﬁcally, DyMeCu consists of a dynamic memory and dual online learners. The information gap between dual learners sparks the agent’s curiosity and then formulates the intrinsic reward, and the state information can then be con- solidated into the dynamic memory. Large-scale empirical experiments are conducted on multiple benchmarks, and the experimental results show that DyMeCu outperforms com- peting curiosity-based methods under different settings. References Abdar, M.; Pourpanah, F.; Hussain, S.; Rezazadegan, D.; Liu, L.; Ghavamzadeh, M.; Fieguth, P.; Cao, X.; Khosravi, A.; Acharya, U. R.; et al. 2021. A review of uncertainty quantiﬁcation in deep learning: Techniques, applications and challenges. Information Fusion, 76: 243–297. Achiam, J.; and Sastry, S. 2017. Surprise-based intrinsic motivation for deep reinforcement learning. arXiv preprint arXiv:1703.01732. Arani, E.; Sarfraz, F.; and Zonooz, B. 2021. Learning Fast, Learning Slow: A General Continual Learning Method based on Complementary Learning System. In International Conference on Learning Representations. Bellemare, M. G.; Naddaf, Y.; Veness, J.; and Bowling, M. 2013. The arcade learning environment: An evaluation plat- form for general agents. Journal of Artiﬁcial Intelligence Research, 47: 253–279. Berlyne, D. E. 1950. Novelty and curiosity as determinants of exploratory behaviour. British journal of psychology, 41(1): 68. Burda, Y.; Edwards, H.; Pathak, D.; Storkey, A.; Darrell, T.; and Efros, A. A. 2018. Large-Scale Study of Curiosity- Driven Learning. In International Conference on Learning Representations. Burda, Y.; Edwards, H.; Storkey, A.; and Klimov, O. 2019. Exploration by random network distillation. In International Conference on Learning Representations. Charikar, M. S. 2002. Similarity estimation techniques from rounding algorithms. In Proceedings of the thiry-fourth an- nual ACM symposium on Theory of computing, 380–388. Chen, X.; and He, K. 2021. Exploring simple siamese repre- sentation learning. In Proceedings of the IEEE/CVF Confer- ence on Computer Vision and Pattern Recognition, 15750– 15758. de Abril, I. M.; and Kanai, R. 2018. Curiosity-driven rein- forcement learning with homeostatic regulation. In 2018 in- ternational joint conference on neural networks (ijcnn), 1–6. IEEE. Dietterich, T. G. 2000. Ensemble methods in machine learn- In International workshop on multiple classiﬁer sys- ing. tems, 1–15. Springer. Eysenbach, B.; Gupta, A.; Ibarz, J.; and Levine, S. 2018. Diversity is all you need: Learning skills without a reward function. arXiv preprint arXiv:1802.06070. Flennerhag, S.; Schroecker, Y.; Zahavy, T.; van Hasselt, H.; Silver, D.; and Singh, S. 2021. Bootstrapped meta-learning. arXiv preprint arXiv:2109.04504. Friston, K.; FitzGerald, T.; Rigoli, F.; Schwartenbeck, P.; Pezzulo, G.; et al. 2016. Active inference and learning. Neu- roscience & Biobehavioral Reviews, 68: 862–879. Graves, A.; Bellemare, M. G.; Menick, J.; Munos, R.; and Kavukcuoglu, K. 2017. Automated curriculum learning for neural networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, 1311–1320. Gray, R. M. 2011. Entropy and information theory. Springer Science & Business Media. Grebenkov, D. S.; and Serror, J. 2014. Following a trend with an exponential moving average: Analytical results for a Gaussian model. Physica A: Statistical Mechanics and its Applications, 394: 288–303. Grill, J.-B.; Strub, F.; Altch´e, F.; Tallec, C.; Richemond, P.; Buchatskaya, E.; Doersch, C.; Avila Pires, B.; Guo, Z.; Gheshlaghi Azar, M.; et al. 2020. Bootstrap your own latent- a new approach to self-supervised learning. Advances in Neural Information Processing Systems, 33: 21271–21284. Guo, Z. D.; Pires, B. A.; Piot, B.; Grill, J.-B.; Altch´e, F.; Munos, R.; and Azar, M. G. 2020. Bootstrap latent- predictive representations for multitask reinforcement learn- In International Conference on Machine Learning, ing. 3875–3886. PMLR. Hayes, T. L.; Krishnan, G. P.; Bazhenov, M.; Siegelmann, H. T.; Sejnowski, T. J.; and Kanan, C. 2021. Replay in deep learning: Current approaches and missing biological elements. Neural Computation, 33(11): 2908–2950. Haynes, D.; Corns, S.; and Venayagamoorthy, G. K. 2012. In 2012 IEEE An exponential moving average algorithm. Congress on Evolutionary Computation, 1–8. IEEE. Hessel, M.; Modayil, J.; Van Hasselt, H.; Schaul, T.; Os- trovski, G.; Dabney, W.; Horgan, D.; Piot, B.; Azar, M.; and Silver, D. 2018. Rainbow: Combining improvements in deep reinforcement learning. In Thirty-second AAAI conference on artiﬁcial intelligence. Ishii, S.; Yoshida, W.; and Yoshimoto, J. 2002. Control of exploitation–exploration meta-parameter in reinforcement learning. Neural networks, 15(4-6): 665–687. Jaegle, A.; Mehrpour, V.; and Rust, N. 2019. Visual novelty, curiosity, and intrinsic reward in machine learning and the brain. Current opinion in neurobiology, 58: 167–174. Kearns, M.; and Singh, S. 2002. Near-optimal reinforcement learning in polynomial time. Machine learning, 49(2): 209– 232. Kidd, C.; and Hayden, B. Y. 2015. The psychology and neu- roscience of curiosity. Neuron, 88(3): 449–460. Kim, K.; Sano, M.; De Freitas, J.; Haber, N.; and Yamins, D. 2020. Active world model learning with progress cu- In International conference on machine learning, riosity. 5306–5315. PMLR. Klinker, F. 2011. Exponential moving average versus mov- ing exponential average. Mathematische Semesterberichte, 58(1): 97–107. Laskin, M.; Yarats, D.; Liu, H.; Lee, K.; Zhan, A.; Lu, K.; Cang, C.; Pinto, L.; and Abbeel, P. 2021. URLB: Unsu- pervised Reinforcement Learning Benchmark. In Deep RL Workshop NeurIPS 2021. Lee, L.; Eysenbach, B.; Parisotto, E.; Xing, E.; Levine, S.; and Salakhutdinov, R. 2019. Efﬁcient exploration via state marginal matching. arXiv preprint arXiv:1906.05274. Liu, H.; and Abbeel, P. 2021a. Aps: Active pretraining with successor features. In International Conference on Machine Learning, 6736–6747. PMLR. Szepesv´ari, C. 2009. Synthesis Lectures on Artiﬁcial Intelli- gence and Machine Learning. Synthesis lectures on artiﬁcial intelligence and machine learning. Tao, R. Y.; Franc¸ois-Lavet, V.; and Pineau, J. 2020. Novelty search in representational space for sample efﬁcient explo- ration. Advances in Neural Information Processing Systems, 33: 8114–8126. Tarvainen, A.; and Valpola, H. 2017. Mean teachers are better role models: Weight-averaged consistency targets im- prove semi-supervised deep learning results. Advances in neural information processing systems, 30. Tesauro, G.; et al. 1995. Temporal difference learning and TD-Gammon. Communications of the ACM, 38(3): 58–68. Tunyasuvunakool, S.; Muldal, A.; Doron, Y.; Liu, S.; Bohez, S.; Merel, J.; Erez, T.; Lillicrap, T.; Heess, N.; and Tassa, Y. 2020. dm control: Software and tasks for continuous con- trol. Software Impacts, 6: 100022. Yang, T.; Tang, H.; Bai, C.; Liu, J.; Hao, J.; Meng, Z.; and Liu, P. 2021. Exploration in deep reinforcement learning: a comprehensive survey. arXiv preprint arXiv:2109.06668. Yarats, D.; Fergus, R.; Lazaric, A.; and Pinto, L. 2021. Reinforcement learning with prototypical representations. In International Conference on Machine Learning, 11920– 11931. PMLR. Yarats, D.; Kostrikov, I.; and Fergus, R. 2020. Image aug- mentation is all you need: Regularizing deep reinforcement learning from pixels. In International Conference on Learn- ing Representations. Liu, H.; and Abbeel, P. 2021b. Behavior from the void: Un- supervised active pre-training. Advances in Neural Informa- tion Processing Systems, 34. Liu, J.; Lin, Z.; Padhy, S.; Tran, D.; Bedrax Weiss, T.; and Lakshminarayanan, B. 2020. Simple and principled uncer- tainty estimation with deterministic deep learning via dis- tance awareness. Advances in Neural Information Process- ing Systems, 33: 7498–7512. Mai, V.; Mani, K.; and Paull, L. 2022. Sample Efﬁcient Deep Reinforcement Learning via Uncertainty Estimation. arXiv preprint arXiv:2201.01666. Mnih, V.; Kavukcuoglu, K.; Silver, D.; Rusu, A. A.; Ve- ness, J.; Bellemare, M. G.; Graves, A.; Riedmiller, M.; Fidje- land, A. K.; Ostrovski, G.; et al. 2015. Human-level control through deep reinforcement learning. nature, 518(7540): 529–533. O’Reilly, R. C.; and Rudy, J. W. 2001. Conjunctive repre- sentations in learning and memory: principles of cortical and hippocampal function. Psychological review, 108(2): 311. Pathak, D.; Agrawal, P.; Efros, A. A.; and Darrell, T. 2017. Curiosity-driven exploration by self-supervised prediction. In International Conference on Machine Learning, 2778– 2787. PMLR. Pathak, D.; Gandhi, D.; and Gupta, A. 2019. Self-supervised exploration via disagreement. In International Conference on Machine Learning, 5062–5071. PMLR. Peterson, E. J.; and Verstynen, T. D. 2021. Curiosity eliminates the exploration-exploitation dilemma. bioRxiv, 671362. Reddy, G.; Celani, A.; and Vergassola, M. 2016. Infomax strategies for an optimal balance between exploration and exploitation. Journal of Statistical Physics, 163(6): 1454– 1476. Rotgans, J. I.; and Schmidt, H. G. 2017. The role of interest in learning: knowledge acquisition at the intersection of sit- uational and individual interest. In The science of interest, 69–93. Springer. Ryan, R. M.; and Deci, E. L. 2000. Intrinsic and extrinsic motivations: Classic deﬁnitions and new directions. Con- temporary educational psychology, 25(1): 54–67. Schmidhuber, J. 1991. A possibility for implementing cu- riosity and boredom in model-building neural controllers. In Proc. of the international conference on simulation of adap- tive behavior: From animals to animats, 222–227. Schulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; and Klimov, O. 2017. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347. Schwarzer, M.; Anand, A.; Goel, R.; Hjelm, R. D.; Courville, A.; and Bachman, P. 2020. Data-Efﬁcient Re- inforcement Learning with Self-Predictive Representations. In International Conference on Learning Representations. Silvia, P. J. 2017. Curiosity. In The science of interest, 97– 107. Springer. Smith, L.; and Gasser, M. 2005. The development of em- bodied cognition: Six lessons from babies. Artiﬁcial life, 11(1-2): 13–29.","['memorybase', 'curiosity', 'bootstrap', 'approach', 'exploration', 'huaimin', 'artiﬁcial', 'intelligence', 'research', 'center', 'dii', 'g', 'u', 'x', 'abstract', 'sparsity', 'extrinsic', 'reward', 'pose', 'serious', 'chal', 'lenge', 'reinforcement', 'learn', 'currently', 'many', 'effort', 'make', 'curiosity', 'pro', 'vide', 'representative', 'intrinsic', 'reward', 'effective', 'ex', 'ploration', 'however', 'challenge', 'still', 'far', 'e', 'solve', 'paper', 'present', 'novel', 'curiosity', 'rl', 'name', 'dymecu', 'stand', 'dynamic', 'memorybase', 'curiosity', 'inspire', 'human', 'curiosity', 'information', 'theory', 'dymecu', 'consist', 'dynamic', 'memory', 'dual', 'online', 'learner', 'curiosity', 'arouse', 'memorized', 'information', 'deal', 'current', 'state', 'information', 'gap', 'dual', 'learner', 'formulate', 'intrinsic', 'reward', 'agent', 'state', 'information', 'consolidate', 'dynamic', 'memory', 'compare', 'previous', 'curiosity', 'method', 'dymecu', 'well', 'mimic', 'human', 'curiosity', 'dynamic', 'memory', 'memory', 'module', 'dynamically', 'grow', 'base', 'bootstrap', 'paradigm', 'dual', 'learner', 'multiple', 'benchmark', 'include', 'deep', 'mind', 'control', 'suite', 'ical', 'experiment', 'conduct', 'result', 'demon', 'strate', 'outperform', 'competitive', 'curiosity', 'base', 'method', 'extrinsic', 'reward', 'release', 'code', 'enhance', 'reproducibility', 'introduction', 'success', 'reinforcement', 'learn', 'rl', 'sequential', 'decisionmake', 'task', 'bellemare', 'tesauro', 'et', 'many', 'current', 'method', 'struggle', 'sparse', 'extrinsic', 'reward', 'cope', 'spar', 'sity', 'curiosity', 'provide', 'representative', 'intrinsic', 'reward', 'encourage', 'agent', 'explore', 'new', 'state', 'design', 'algo', 'rithm', 'efﬁciently', 'construct', 'curiosity', 'key', 'compo', 'nent', 'system', 'previous', 'research', 'show', 'intrin', 'sic', 'reward', 'help', 'alleviate', 'issue', 'result', 'lacking', 'dense', 'extrinsic', 'reward', 'abbeel', 'franc¸oislavet', 'human', 'learning', 'curiosity', 'motivate', 'people', 'seek', 'retain', 'information', 'exploration', 'envi', 'ronment', 'ryan', 'deci', 'gasser', 'process', 'arouse', 'satisfy', 'curio', 'ity', 'sum', 'cycle', 'person', 'encoun', 'ter', 'problem', 'heshe', 'ﬁrst', 'try', 'solve', 'retrieve', 'information', 'memory', 'retrieval', 'memory', 'fail', 'realize', 'current', 'memorized', 'information', 'sufﬁcient', 'solve', 'problem', 'conscious', 'awareness', 'formation', 'discrepancy', 'spark', 'curiosity', 'prob', 'lem', 'curiosity', 'stimulate', 'search', 'new', 'tion', 'information', 'discrepancy', 'eliminate', 'people', 'curiosity', 'learn', 'cur', 'rent', 'problem', 'problem', 'encounter', 'rotgan', 'schmidt', 'human', 'curiosity', 'stantly', 'consolidate', 'base', 'dynamic', 'memory', 'consist', 'encoding', 'store', 'retrieve', 'information', 'stage', 'hayes', 'curiosity', 'fade', 'additional', 'information', 'consolidate', 'memory', 'tion', 'result', 'forming', 'new', 'dynamic', 'memory', 'depend', 'o’reilly', 'rudy', 'many', 'attempt', 'make', 'build', 'curiosity', 'fall', 'main', 'category', 'countbase', 'predictionbase', 'however', 'curiosity', 'different', 'human', 'curiosity', 'problem', 'far', 'solve', 'take', 'random', 'network', 'distillation', 'method', 'example', 'initialize', 'ran', 'dom', 'ﬁxed', 'target', 'network', 'state', 'embedding', 'train', 'prediction', 'network', 'ﬁt', 'output', 'target', 'net', 'work', 'random', 'ﬁxed', 'target', 'network', 'regard', 'random', 'ﬁxed', 'memory', 'retain', 'contextual', 'knowledge', 'environment', 'dynamically', 'incorporate', 'contextual', 'information', 'memory', 'random', 'feature', 'sufﬁcient', 'interpret', 'dynamic', 'environment', 'therefore', 'kind', 'curiosity', 'evaluate', 'nondevelopmental', 'way', 'severely', 'lim', 'performance', 'curiosity', 'work', 'mimic', 'human', 'curiosity', 'formalize', 'investigate', 'dynamic', 'memorybase', 'curiosity', 'mechanism', 'name', 'dymecu', 'inspire', 'bootstrap', 'paradigm', 'guo', 'grill', 'flennerhag', 'construct', 'dual', 'online', 'learner', 'learn', 'latent', 'state', 'formulate', 'dynamic', 'memory', 'model', 'figure', 'hand', 'state', 'information', 'consolidate', 'memory', 'exponential', 'move', 'average', 'hayne', 'corn', 'venayagamoorthy', 'klinker', 'grebenkov', 'serror', 'dual', 'learner', 'parameter', 'bootstrap', 'term', 'bootstrap', 'use', 'text', 'colloquial', 'meaning', 'correspond', 'author', 'rather', 'statistical', 'connotation', 'figure', 'dymecu', 'employ', 'novel', 'learn', 'framework', 'build', 'intrinsic', 'reward', 'consist', 'dynamic', 'memory', 'dual', 'online', 'learner', 'information', 'discrepancy', 'current', 'state', 'compare', 'retrieve', 'information', 'memory', 'make', 'curiosity', 'arouse', 'get', 'curiositybase', 'intrinsic', 'reward', 'agent', 'learning', 'calculate', 'information', 'gap', 'dual', 'online', 'learner', 'state', 'information', 'dynamically', 'consolidate', 'memory', 'bootstrap', 'paradigm', 'curiosity', 'fade', 'paradigm', 'hand', 'utilize', 'supervised', 'signal', 'memory', 'improve', 'dual', 'learner', 'encoding', 'ability', 'far', 'curiosity', 'measure', 'information', 'gap', 'tween', 'dual', 'learner', 'essentially', 'uncertainty', 'estimation', 'give', 'state', 'base', 'dynamic', 'memory', 'mai', 'paull', 'abdar', 'brief', 'contribution', 'paper', 'ﬁrstly', 'analyze', 'shortcoming', 'previous', 'curiositybase', 'intrinsic', 'reward', 'method', 'suggest', 'mimic', 'human', 'curiosity', 'leverage', 'dynamic', 'memory', 'stead', 'ﬁxed', 'one', 'base', 'information', 'theory', 'propose', 'novel', 'practicable', 'intrinsic', 'reward', 'method', 'agent', 'name', 'memorybase', 'curiosity', 'consist', 'dynamic', 'memory', 'dual', 'online', 'learner', 'thus', 'measure', 'curiosity', 'consolidate', 'information', 'feasi', 'ble', 'way', 'meanwhile', 'different', 'strategy', 'explore', 'far', 'improve', 'performance', '•', 'multiple', 'benchmark', 'include', 'deepmind', 'tunyasuvunakool', 'atari', 'suite', 'bellemare', 'largescale', 'empiri', 'cal', 'experiment', 'demonstrate', 'outperform', 'competitive', 'curiositybase', 'method', 'pre', 'training', 'strategy', 'related', 'work', 'curiositybase', 'intrinsic', 'reward', 'exploration', 'issue', 'long', 'standing', 'challenge', 'previous', 'attempt', 'suggest', 'additional', 'ward', 'exploration', 'regard', 'hunt', 'theoretically', 'also', 'view', 'curio', 'ity', 'berlyne', 'schmidhuber', 'kidd', 'hayden', 'abril', 'kanai', 'rust', 'friston', 'peterson', 'verstynen', 'intuitive', 'formulation', 'curiosity', 'countbase', 'meth', 'od', 'less', 'visited', 'state', 'state', 'novelty', 'exploration', 'scale', 'largescale', 'continu', 'ous', 'state', 'space', 'kearn', 'singh', 'charikar', 'inspire', 'countbase', 'method', 'calculate', 'state', 'novelty', 'distil', 'random', 'ﬁxed', 'network', 'target', 'net', 'work', 'prediction', 'network', 'predictor', 'network', 'predictor', 'network', 'train', 'minimize', 'prediction', 'error', 'state', 'take', 'prediction', 'error', 'trinsic', 'reward', 'apart', 'countbase', 'method', 'prediction', 'base', 'method', 'also', 'show', 'competitive', 'well', 'performance', 'model', 'environment', 'dynamic', 'pathak', 'assumption', 'visit', 'state', 'action', 'pair', 'result', 'accurate', 'prediction', 'trinsic', 'reward', 'apply', 'variance', 'predic', 'tion', 'ensemble', 'distance', 'prediction', 'state', 'true', 'state', 'disagreement', 'method', 'method', 'attempt', 'design', 'curio', 'ity', 'contain', 'memory', 'effectively', 'use', 'information', 'consolidate', 'memory', 'however', 'main', 'goal', 'paper', 'uncertainty', 'estimation', 'work', 'also', 'relate', 'uncertainty', 'estimation', 'uncertainty', 'crucial', 'allow', 'agent', 'discern', 'exploit', 'explore', 'environment', 'previous', 'intrinsic', 'reward', 'also', 'interpret', 'perspective', 'uncertainty', 'estima', 'tion', 'evaluate', 'curiosity', 'estimate', 'deep', 'learning', 'model', 'uncertainty', 'conﬁdence', 'take', 'disagree', 'curiosity', 'arouse', 'curiositybase', 'learn', 'curiosity', 'fade', 'novel', 'state', 'encode', 'latent', 'state', 'retrieve', 'information', 'state', 'information', 'discrepancy', 'memory', 'model', '𝜔', 'output', 'retrieve', 'information', 'online', 'learner', '𝜃1', 'memory', 'model', 'online', 'learner', 'loss', 'loss', 'stop', 'policy', '𝑎𝑡', 'action', '𝑠𝑡1', 'next', 'state', 'dynamic', 'memorybase', 'curiosity', 'initialization', 'policy', 'network', 'dual', 'online', 'learner', 'net', 'work', 'fθ1', 'memory', 'network', 'coefﬁcient', 'intrin', 'sic', 'extrinsic', 'reward', 'ζ', 'training', 'receive', 'state', 'environment', 'base', 'policy', 'network', 'πφ', 'take', 'action', 'receive', 'state', 'st1', 'extrinsic', 'ext', 'environment', 'collect', 'step', 'datum', 'replay', 'buffer', 'end', 'sample', 'batch', 'datum', 'replay', 'buffer', 'generate', 'latent', 'state', 'vector', 'mωsi', 'calculate', 'intrinsic', 'reward', 'rint', 'calculate', 'total', 'reward', 'total', 'ζri', 'cid1072', 'int', 'βrext', 'fθ1', 'si', 'end', 'update', 'sample', 'datum', 'minimize', 'loss', 'equation', 'update', 'ω', 'equation', 'update', 'sample', 'datum', 'maximize', 'rtotal', 'e', 'end', 'ment', 'example', 'instead', 'compare', 'prediction', 'groundtruth', 'suggest', 'evaluate', 'uncertainty', 'multiple', 'prediction', 'model', 'use', 'deep', 'ensemble', 'diet', 'terich', 'incur', 'additional', 'computation', 'also', 'claim', 'distillation', 'error', 'view', 'quantiﬁcation', 'uncertainty', 'work', 'evaluate', 'uncertainty', 'give', 'state', 'e', 'information', 'gap', 'dual', 'learner', 'rely', 'dynamic', 'memory', 'instead', 'random', 'ﬁxed', 'network', 'methodology', 'general', 'agent', 'encounter', 'state', 'tion', 'value', 'e', 'compare', 'memory', 'state', 'worth', 'explore', 'information', 'value', 'worth', 'consolidat', 'ing', 'memory', 'dynamically', 'rotgan', 'schmidt', 'detail', 'concept', 'information', 'value', 'e', 'necessitate', 'formation', 'dynamic', 'memory', 'way', 'g', 'consolidate', 'information', 'memory', 'deep', 'neural', 'network', 'memory', 'embed', 'tent', 'space', 'g', 'function', 'map', 'state', 'memory', 'peterson', 'verstynen', 'kind', 'con', 'solidate', 'information', 'denote', 'memory', 'learn', 'g', 'historical', 'state', 'measure', 'information', 'value', 'e', 'next', 'state', 'st1', 'accord', 'information', 'ory', 'reddy', 'vergassola', 'gray', 'concept', 'propose', 'peterson', 'verstynen', 'information', 'value', 'e', 'state', 'depend', 'memory', 'immediately', 'learn', 'g', 'nonnegative', 'e', 'explore', 'environment', 'decelerate', 'ﬁnite', 'time', 'state', 'thus', 'deﬁne', 'e', 'cid107gst1', '−', 'get', 'deﬁnition', 'e', 'state', 'completely', 'explore', 'learn', 'information', 'gain', 'add', 'current', 'memory', 'state', 'long', 'worth', 'explore', 'large', 'value', 'e', 'information', 'gain', 'consolidate', 'memory', 'word', 'large', 'value', 'e', 'memory', 'less', 'aware', 'current', 'state', 'state', 'worth', 'explor', 'e', 'information', 'deﬁciency', 'memory', 'spark', 'curiosity', 'agent', 'paper', 'focus', 'obtain', 'lever', 'age', 'information', 'value', 'e', 'agent', 'exploration', 'information', 'consolidation', 'method', 'g', 'detail', 'dynamic', 'memorybase', 'curiosity', 'framework', 'information', 'current', 'memory', 'handle', 'encounter', 'state', 'curiosity', 'arouse', 'model', 'memory', 'learnable', 'neural', 'net', 'work', 'dilemma', 'bench', 'mark', 'encode', 'network', 'parameter', 'space', 'encode', 'encounter', 'state', 'accurately', 'enough', 'supervised', 'signal', 'provide', 'thus', 'difﬁcult', 'sound', 'di', 'rectly', 'deﬁne', 'curiosity', 'compare', 'random', 'encode', 'state', 'output', 'latent', 'state', 'dynamic', 'memory', 'network', 'instead', 'introduce', 'dual', 'online', 'learner', 'state', 'encode', 'representation', 'dual', 'learner', 'network', 'architecture', 'memory', 'network', 'different', 'parameter', 'network', 'parameter', 'space', 'dual', 'network', 'supervise', 'memory', 'encoding', 'ability', 'curiosity', 'deﬁne', 'gap', 'encoding', 'state', 'output', 'dual', 'learner', 'network', 'intuition', 'dual', 'learner', 'state', 'information', 'squeeze', 'memory', 'memory', 'completely', 'know', 'resolve', 'state', 'dual', 'learner', 'see', 'imitator', 'memory', 'easy', 'get', 'similar', 'encoding', 'current', 'state', 'word', 'state', 'little', 'know', 'ory', 'dual', 'learner', 'produce', 'quite', 'different', 'coding', 'represent', 'large', 'information', 'value', 'e', 'thus', 'stimulate', 'agent', 'explore', 'state', 'uniform', 'description', 'refer', 'encode', 'state', 'encoding', 'latent', 'state', 'reﬂect', 'cognition', 'state', 'memory', 'learner', 'network', 'implementation', 'kind', 'latent', 'gap', 'e', 'spark', 'curiosity', 'intrinsic', 'reward', 'agent', 'explo', 'ration', 'agent', 'learn', 'information', 'consolidate', 'memory', 'memory', 'well', 'grow', 'term', 'consolidation', 'method', 'g', 'externalize', 'update', 'memory', 'parameter', 'exponential', 'mov', 'e', 'average', 'hayne', 'corn', 'venayagamoorthy', 'figure', 'performance', 'different', 'method', 'ﬁnetune', 'phase', 'control', 'grebenkov', 'serror', 'dual', 'learner', 'parameter', 'analysis', 'see', 'dual', 'learner', 'ﬁrst', 'learn', 'base', 'memory', 'network', 'measure', 'information', 'value', 'exploration', 'memory', 'network', 'consol', 'idate', 'information', 'gain', 'base', 'dual', 'learner', 'ema', 'way', 'memory', 'actually', 'seek', 'appropriate', 'po', 'sition', 'parameter', 'space', 'dynamically', 'order', 'network', 'well', 'characterize', 'memory', 'cognition', 'ability', 'see', 'state', 'environment', 'word', 'dy', 'namic', 'memory', 'update', 'bootstrap', 'grill', 'way', 'figure', 'present', 'whole', 'framework', 'pseudocode', 'learning', 'dual', 'learner', 'dual', 'online', 'learner', 'model', 'fθ2', 'deﬁne', 'set', 'weight', 'architecture', 'memory', 'network', 'mω', 'memory', 'provide', 'regression', 'target', 'learning', 'dual', 'learner', 'fθ1', 'fθ2', 'give', 'current', 'state', 'learner', 'transform', 'latent', 'state', 'respectively', 'mean', 'squared', 'memory', 'network', 'output', 'error', 'mse', 'cid13zθ1', 'cid13zθ2', 'base', 'dual', 'learner', 'update', 'optim', 'represent', 'optimizer', 'learning', 'rate', 'lθ2', 'lθ1', '\uf8f4\uf8f3', 'intrinsic', 'reward', 'base', 'curiosity', 'curiosity', 'rely', 'information', 'value', 'current', 'state', 'method', 'information', 'value', 'mea', 'sure', 'information', 'gap', 'dual', 'learner', 'information', 'gap', 'also', 'consider', 'follow', 'progress', 'sastry', 'grave', 'form', 'curiosity', 'obtain', 'intrinsic', 'reward', 'agent', 'base', 'curiosity', 'information', 'value', 'cid1072', 'cid1072', 'rint', 'point', 'view', 'duallearner', 'mechanism', 'regard', 'variant', 'ensemble', 'paull', 'uncertainty', 'estimation', 'compare', 'pre', 'vious', 'attempt', 'require', 'heavily', 'ensemble', 'disagreement', 'lightweight', 'solution', 'previous', 'well', 'performance', 'retain', 'computation', 'efﬁciency', 'overall', 'get', 'optimization', 'goal', 'agent', 'max', 'γtζrint', 'βrext', 'discount', 'factor', 'represent', 'parameter', 'policy', 'π', 'ζ', 'β', 'coefﬁcient', 'intrinsic', 'reward', 'extrinsic', 'reward', 'respectively', 'consolidate', 'information', 'memory', 'memory', 'model', 'update', 'ema', 'way', 'sake', 'stability', 'old', 'state', 'information', 'plasticity', 'current', 'new', 'state', 'information', 'word', 'ory', 'dynamically', 'grow', 'take', 'contextual', 'environ', 'ment', 'information', 'account', 'speciﬁcally', 'give', 'decay', 'rate', 'training', 'step', 'memory', 'update', 'intuition', 'dynamic', 'memorybase', 'curiosity', 'close', 'human', 'curiosity', 'mechanism', 'cognitive', 'difference', 'compare', 'memory', 'stimulate', 'curiosity', 'explore', 'world', 'consolidate', 'cognition', 'infor', 'mation', 'memory', 'dynamically', 'addition', 'knowledge', 'distillation', 'view', 'memory', 'also', 'garde', 'teacher', 'model', 'mean', 'teacherbased', 'proach', 'tarvainen', 'valpola', 'memory', 'essen', 'tially', 'selfensemble', 'intermediate', 'model', 'learner', 'table', 'performance', 'comparison', 'different', 'pretraine', 'method', 'control', 'suite', 'good', 'result', 'bold', 'font', 'task', 'second', 'good', 'result', 'underline', 'domain', 'walker', 'task', 'flip', 'run', 'stand', 'walk', 'average', 'performance', 'jump', 'run', 'stand', 'walk', 'average', 'performance', 'quadrupe', 'bottom', 'leave', 'reach', 'bottom', 'right', 'reach', 'top', 'leave', 'reach', 'top', 'right', 'average', 'performance', 'icm', '398±18', '696±162', '91±29', '184±100', '99±46', '102±47', '75±27', 'disagreement', '680±107', '628±114', '446±117', '814±116', '385±47', '540±53', '622±57', 'protorl', '200±15', 'smm', '821±36', '536±20', '17±5', '50±9', '20±4', 'ap', '711±68', '93±9', '65±10', '81±11', '588±25', '934±16', '780±21', '694±15', 'paradigm', 'propose', 'type', 'replay', 'mechanism', 'think', 'play', 'important', 'role', 'memory', 'retrieval', 'consolidation', 'hayes', 'consider', 'way', 'form', 'memory', 'also', 'use', 'continual', 'learning', 'address', 'issue', 'cata', 'trophic', 'forget', 'arani', 'sarfraz', 'zonooz', 'experiment', 'analysis', 'experimental', 'setting', 'evaluate', 'method', 'pretraine', 'traditional', 'rl', 'situation', 'utilize', 'widely', 'use', 'benchmark', 'deep', 'mind', 'control', 'tunyasuvunakool', 'atari', 'suite', 'bellemare', 'follow', 'experimental', 'setting', 'atari', 'suite', 'setting', 'urlb', 'laskin', 'pretraine', 'benchmark', 'control', 'suite', 'ply', 'schulman', 'train', 'agent', 'hyperparameter', 'set', 'experiment', 'implementation', 'detail', 'hyperparameter', 'find', 'deepmind', 'control', 'suite', 'many', 'wellperforming', 'approach', 'urlb', 'laskin', 'use', 'pretraine', 'ﬁnetune', 'paradigm', 'prove', 'sample', 'efﬁciency', 'especially', 'experiment', 'benchmark', 'contain', 'various', 'domain', 'com', 'plex', 'task', 'evaluate', 'dymecu', 'domain', 'namely', 'quadrupe', 'arm', 'iest', 'hard', 'task', 'pretraine', 'phase', 'agent', 'train', 'step', 'intrinsic', 'reward', 'produce', 'curiosity', 'dur', 'e', 'ﬁnetune', 'phase', 'agent', 'train', 'step', 'extrinsic', 'reward', 'table', 'report', 'ﬁnal', 'score', 'standard', 'deviation', 'dymecu', 'competitive', 'method', 'compare', 'dymecu', 'intrinsic', 'rewardbase', 'method', 'icm', 'disagreement', 'abbeel', 'pretraine', 'strategy', 'protorl', 'yarat', 'eysenbach', 'ap', 'abbeel', 'dymecu', 'improve', 'average', 'performance', 'domain', 'respectively', 'quantitative', 'result', 'see', 'dymecu', 'achieve', 'new', 'stateoftheart', 'task', 'demonstrate', 'dymecu', 'ability', 'improve', 'model', 'performance', 'robustness', 'pretraine', 'paradigm', 'figure', 'plot', 'learn', 'curve', 'ﬁnetune', 'phase', 'dymecu', 'competitive', 'curiositybase', 'method', 'learn', 'curve', 'find', 'appendix', 'dymecu', 'show', 'superior', 'convergence', 'speed', 'method', 'meanwhile', 'convergence', 'result', 'also', 'surpass', 'signiﬁcantly', 'dymecu', '’s', 'speed', 'crease', 'sbe', 'mainly', 'contextual', 'state', 'infor', 'mation', 'consolidate', 'memory', 'dynamically', 'rather', 'random', 'ﬁxed', 'setting', 'base', 'dy', 'namic', 'memory', 'exploration', 'agent', 'much', 'efﬁcient', 'atari', 'suite', 'suite', 'ﬁrst', 'record', 'performance', 'agent', 'intrinsic', 'extrinsic', 'reward', 'experiment', 'conduct', 'run', 'step', 'equivalent', 'frame', 'intrinsic', 'extrinsic', 'reward', 'coefﬁcient', 'set', 'respectively', 'method', 'follow', 'e', 'setup', 'previous', 'curiositybase', 'method', 'ble', 'list', 'aggregate', 'metric', 'score', 'od', 'train', 'intrinsic', 'extrinsic', 'reward', 'game', 'human', 'random', 'score', 'adopt', 'previous', 'work', 'abbeel', 'yarat', 'fergus', 'schwarzer', 'normalize', 'episode', 'reward', 'humannormalize', 'score', 'hns', 'expert', 'human', 'score', 'account', 'different', 'score', 'scale', 'game', 'sota', 'denote', 'number', 'game', 'current', 'method', 'ex', 'ceed', 'method', 'mean', 'hns', 'calculate', 'average', 'agent', 'score', '−', 'random', 'scorehuman', 'score', '−', 'random', 'score', 'game', 'table', 'dymecu', 'play', 'superiority', 'disagreement', 'icm', 'high', 'mean', 'hns', 'sota', 'figure', 'display', 'learn', 'curve', 'use', 'intrin', 'figure', 'performance', 'comparison', 'atari', 'game', 'subset', 'use', 'intrinsic', 'reward', 'extrinsic', 'reward', 'table', 'performance', 'comparison', 'curiositybase', 'od', 'use', 'intrinsic', 'extrinsic', 'reward', 'atari', 'game', 'subset', 'bold', 'font', 'indicate', 'good', 'value', 'game', 'heist', 'battlezone', 'box', 'breakout', 'choppercommand', 'crazy', 'freeway', 'frostbite', 'gopher', 'hero', 'private', 'eye', 'qbert', 'road', 'runner', 'seaquest', 'mean', 'random', 'human', 'na', 'icm', 'disagreement', 'sic', 'extrinsic', 'reward', 'compare', 'dymecu', 'widelyused', 'baseline', 'include', 'disagreement', 'icm', 'rnd', 'random', 'choose', 'atari', 'game', 'show', 'evident', 'advantage', 'game', 'performance', 'learn', 'speed', 'example', 'jamesbond', 'conver', 'gence', 'plot', 'reward', 'time', 'method', 'moreover', 'also', 'compare', 'per', 'formance', 'agent', 'train', 'intrinsic', 'reward', 'show', 'figure', 'environment', 'dymecu', 'perform', 'disagreement', 'baseline', 'environment', 'perform', 'icm', 'baseline', 'environment', 'overall', 'result', 'show', 'outperform', 'curiositybase', 'method', 'demonstrate', 'dymecu', '’s', 'ability', 'generate', 'accurate', 'intrinsic', 'ward', 'provide', 'useful', 'information', 'well', 'ex', 'ploration', 'figure', 'performance', 'comparison', 'kind', 'ployment', 'baseline', 'intrinsic', 'extrinsic', 'ward', 'analysis', 'analysis', 'include', 'ablation', 'study', 'present', 'give', 'intuition', 'behavior', 'perfor', 'mance', 'run', 'experiment', 'random', 'seed', 'follow', 'experiment', 'conduct', 'run', 'step', 'equivalent', 'frame', 'dual', 'learner', 'explore', 'design', 'curiosity', 'naive', 'setting', 'use', 'encoding', 'network', 'learn', 'code', 'latent', 'space', 'thus', 'curiositybase', 'intrinsic', 'reward', 'deﬁne', 'gap', 'memory', 'network', 'cid1072', 'rint', 'memory', 'update', '−', 'αθ', 'show', 'figure', 'onelearner', 'mechanism', 'show', 'signiﬁcant', 'advantage', 'method', 'duallearner', 'mechanism', 'perform', 'much', 'well', 'ac', 'curate', 'curiosity', 'correspond', 'intrinsic', 'reward', 'update', 'memory', 'network', 'memory', 'network', 'update', 'dual', 'learner', 'additionally', 'evaluate', 'performance', 'memory', 'update', 'use', 'figure', 'performance', 'comparison', 'game', 'suite', 'subset', 'use', 'intrinsic', 'reward', 'table', 'performance', 'comparison', 'baseline', 'dymecu', 'different', 'setting', 'intrinsic', 'reward', 'sult', 'represent', 'average', 'episode', 'reward', 'end', 'train', 'e', 'ave', 'last', 'column', 'show', 'average', 'result', 'task', 'game', 'method', 'disagreement', 'icm', 'dymecu', 'dymecu', 'update', 'learner', 'dymecu', 'additional', 'module', 'learner', 'parameter', 'result', 'table', 'indicate', 'learner', 'consolidate', 'state', 'information', 'memory', 'well', 'combine', 'figure', 'useful', 'necessary', 'assign', 'train', 'dual', 'learner', 'update', 'memory', 'dual', 'onelearner', 'duallearner', 'update', 'mechanism', 'show', 'little', 'superior', 'performance', 'structure', 'learner', 'bootstrap', 'idea', 'explore', 'use', 'previous', 'research', 'similar', 'one', 'byol', 'grill', 'use', 'bootstrap', 'method', 'selfsupervised', 'learning', 'computer', 'vision', 'far', 'grill', 'add', 'predictor', 'module', 'line', 'network', 'compare', 'output', 'predictor', 'tar', 'get', 'network', 'key', 'generate', 'wellperforme', 'representation', 'similarly', 'lation', 'study', 'also', 'design', 'control', 'trial', 'additional', 'convolution', 'layer', 'add', 'dual', 'learner', 'table', 'learnable', 'tional', 'module', 'lead', 'signiﬁcant', 'improvement', 'der', 'analysis', 'previous', 'work', 'use', 'bootstrap', 'method', 'aim', 'generate', 'intrinsic', 'reward', 'calcu', 'late', 'information', 'value', 'information', 'gap', 'dual', 'learner', 'accurate', 'possible', 'instead', 'well', 'rep', 'resentation', 'downstream', 'task', 'robustness', 'hyperparameter', 'concern', 'update', 'speed', 'memory', 'net', 'figure', 'performance', 'comparison', 'different', 'value', 'α', 'intrinsic', 'reward', 'work', 'ema', 'way', 'much', 'fast', 'accept', 'consolidate', 'new', 'environment', 'tion', 'therefore', 'far', 'analyze', 'update', 'effect', 'hyperparameter', 'α', 'evaluate', 'dymecu', 'different', 'val', 'ue', 'α', 'rational', 'interval', 'assess', 'agent', 'performance', 'different', 'atari', 'game', 'alien', 'krull', 'direct', 'visual', 'comparison', 'normalize', 'episode', 'reward', 'normalize', 'score', 'bns', 'calculate', 'aver', 'age', 'dymecu', 'score', '−', 'random', 'scorebaseline', 'score', '−', 'random', 'score', 'baseline', 'score', 'average', 'score', 'baseline', 'illustrate', 'figure', 'value', 'hyperparameter', 'yield', 'satisﬁed', 'performance', 'generally', 'great', 'base', 'line', 'average', 'dymecu', 'show', 'acceptable', 'robustness', 'update', 'hyperparameter', 'conclusion', 'address', 'challenge', 'extrinsic', 'reward', 'sparsity', 'propose', 'dymecu', 'mimic', 'human', 'curiosity', 'speciﬁcally', 'dymecu', 'consist', 'dynamic', 'memory', 'dual', 'online', 'learner', 'information', 'gap', 'dual', 'learner', 'spark', 'agent', 'curiosity', 'formulate', 'intrinsic', 'reward', 'state', 'information', 'con', 'solidate', 'dynamic', 'memory', 'largescale', 'empirical', 'experiment', 'conduct', 'multiple', 'benchmark', 'experimental', 'result', 'show', 'dymecu', 'outperform', 'com', 'pet', 'curiositybased', 'method', 'different', 'setting', 'reference', 'abdar', 'hussain', 'fieguth', 'p', 'khosravi', 'acharya', 'u', 'r', 'review', 'uncertainty', 'quantiﬁcation', 'deep', 'learning', 'technique', 'application', 'challenge', 'information', 'fusion', 'sastry', 'surprisebase', 'intrinsic', 'motivation', 'deep', 'reinforcement', 'learn', 'preprint', 'zonooz', 'learn', 'fast', 'learning', 'slow', 'general', 'continual', 'learning', 'method', 'base', 'complementary', 'learning', 'system', 'international', 'conference', 'learn', 'representation', 'bellemare', 'bowling', 'arcade', 'learning', 'environment', 'evaluation', 'plat', 'form', 'general', 'agent', 'journal', 'artiﬁcial', 'intelligence', 'research', 'berlyne', 'e', 'novelty', 'curiosity', 'determinant', 'exploratory', 'behaviour', 'british', 'journal', 'psychology', 'storkey', 'darrell', 'efro', 'largescale', 'study', 'curiosity', 'drive', 'learning', 'international', 'conference', 'learn', 'representation', 'storkey', 'klimov', 'exploration', 'random', 'network', 'distillation', 'international', 'conference', 'learn', 'representation', 'similarity', 'estimation', 'technique', 'round', 'algorithm', 'proceeding', 'thiryfourth', 'nual', 'acm', 'symposium', 'theory', 'compute', 'explore', 'simple', 'siamese', 'repre', 'sentation', 'learn', 'proceeding', 'ieeecvf', 'confer', 'ence', 'computer', 'vision', 'pattern', 'recognition', 'kanai', 'r', 'curiositydriven', 'rein', 'forcement', 'learn', 'homeostatic', 'regulation', 'ternational', 'joint', 'conference', 'neural', 'network', 'ijcnn', 'ieee', 'dietterich', 'g', 'ensemble', 'method', 'machine', 'learn', 'international', 'workshop', 'multiple', 'sy', 'ing', 'tem', 'springer', 'diversity', 'need', 'learning', 'skill', 'reward', 'function', 'preprint', 'schroecker', 'h', 'silver', 'bootstrappe', 'metalearning', 'arxiv', 'preprint', 'schwartenbeck', 'p', 'pezzulo', 'active', 'inference', 'learn', 'neu', 'roscience', 'biobehavioral', 'review', 'grave', 'bellemare', 'g', 'menick', 'muno', 'r', 'automate', 'curriculum', 'learn', 'neural', 'network', 'proceeding', '34th', 'international', 'conference', 'machine', 'learningvolume', 'gray', 'r', 'information', 'theory', 'springer', 'science', 'business', 'medium', 'grebenkov', 'serror', 'follow', 'trend', 'exponential', 'move', 'average', 'analytical', 'result', 'gaussian', 'model', 'statistical', 'mechanic', 'application', 'grill', 'richemond', 'p', 'buchatskaya', 'e', 'pire', 'gheshlaghi', 'azar', 'bootstrap', 'latent', 'new', 'approach', 'selfsupervise', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'guo', 'pire', 'piot', 'b', 'grill', 'muno', 'bootstrap', 'latent', 'predictive', 'representation', 'multitask', 'reinforcement', 'learn', 'international', 'conference', 'machine', 'learning', 'e', 'pmlr', 'haye', 'l', 'g', 'p', 'bazhenov', 'replay', 'deep', 'learn', 'current', 'approach', 'miss', 'biological', 'element', 'neural', 'computation', 'hayne', 'corn', 'venayagamoorthy', 'ieee', 'exponential', 'move', 'average', 'evolutionary', 'computation', 'ieee', 'hessel', 'schaul', 'os', 'trovski', 'silver', 'rainbow', 'combine', 'improvement', 'deep', 'reinforcement', 'learning', 'conference', 'artiﬁcial', 'intelligence', 'control', 'exploitation', 'exploration', 'metaparameter', 'reinforcement', 'learn', 'neural', 'network', 'mehrpour', 'v', 'rust', 'n', 'visual', 'novelty', 'curiosity', 'intrinsic', 'reward', 'machine', 'learning', 'brain', 'current', 'opinion', 'neurobiology', 'kearn', 'nearoptimal', 'reinforcement', 'learning', 'polynomial', 'time', 'machine', 'learn', 'kidd', 'hayden', 'b', 'psychology', 'neu', 'roscience', 'curiosity', 'yamin', 'active', 'world', 'model', 'learn', 'progress', 'cu', 'international', 'conference', 'machine', 'learning', 'riosity', 'pmlr', 'klinker', 'exponential', 'move', 'average', 'mov', 'e', 'exponential', 'average', 'mathematische', 'laskin', 'yarat', 'abbeel', 'p', 'urlb', 'pervise', 'reinforcement', 'learning', 'benchmark', 'deep', 'rl', 'workshop', 'neurip', 'parisotto', 'e', 'salakhutdinov', 'r', 'efﬁcient', 'exploration', 'state', 'preprint', 'abbeel', 'p', 'ap', 'active', 'pretraining', 'successor', 'feature', 'international', 'conference', 'machine', 'learn', 'pmlr', 'synthesis', 'lecture', 'artiﬁcial', 'intelli', 'gence', 'machine', 'learn', 'synthesis', 'lecture', 'artiﬁcial', 'intelligence', 'machine', 'learn', 'r', 'franc¸oislavet', 'v', 'novelty', 'search', 'representational', 'space', 'sample', 'efﬁcient', 'explo', 'ration', 'advance', 'neural', 'information', 'processing', 'system', 'tarvainen', 'valpola', 'h', 'mean', 'teacher', 'well', 'role', 'model', 'weightaverage', 'consistency', 'target', 'prove', 'semisupervised', 'deep', 'learning', 'result', 'advance', 'neural', 'information', 'processing', 'system', 'tesauro', 'temporal', 'difference', 'learning', 'tdgammon', 'communication', 'acm', 'tunyasuvunakool', 'muldal', 'doron', 'heess', 'n', 'tassa', 'dm', 'control', 'software', 'task', 'continuous', 'software', 'impact', 'exploration', 'deep', 'reinforcement', 'learn', 'comprehensive', 'survey', 'arxiv', 'preprint', 'yarat', 'fergus', 'r', 'lazaric', 'reinforcement', 'learn', 'prototypical', 'representation', 'international', 'conference', 'machine', 'learning', 'pmlr', 'yarat', 'fergus', 'r', 'image', 'aug', 'mentation', 'need', 'regularize', 'deep', 'reinforcement', 'learn', 'pixel', 'international', 'conference', 'learn', 'e', 'representation', 'abbeel', 'p', 'behavior', 'void', 'supervise', 'active', 'pretraine', 'advance', 'processing', 'system', 'b', 'simple', 'principled', 'uncer', 'tainty', 'estimation', 'deterministic', 'deep', 'learning', 'awareness', 'advance', 'neural', 'information', 'process', 'ing', 'system', 'mai', 'paull', 'sample', 'efﬁcient', 'deep', 'reinforcement', 'learning', 'uncertainty', 'estimation', 'preprint', 'mnih', 'rusu', 'ness', 'bellemare', 'g', 'grave', 'riedmiller', 'k', 'ostrovski', 'g', 'humanlevel', 'control', 'deep', 'reinforcement', 'learn', 'nature', 'o’reilly', 'r', 'c', 'rudy', 'conjunctive', 'repre', 'sentation', 'learning', 'memory', 'principle', 'cortical', 'hippocampal', 'function', 'psychological', 'review', 'pathak', 'efro', 'curiositydriven', 'exploration', 'selfsupervise', 'prediction', 'international', 'conference', 'machine', 'learning', 'pmlr', 'pathak', 'selfsupervise', 'exploration', 'disagreement', 'international', 'conference', 'machine', 'learn', 'pmlr', 'peterson', 'verstynen', 'curiosity', 'eliminate', 'explorationexploitation', 'dilemma', 'reddy', 'vergassola', 'infomax', 'strategy', 'optimal', 'balance', 'exploration', 'exploitation', 'journal', 'statistical', 'physics', 'rotgan', 'schmidt', 'h', 'role', 'interest', 'learn', 'knowledge', 'acquisition', 'intersection', 'sit', 'uational', 'individual', 'interest', 'science', 'interest', 'springer', 'ryan', 'r', 'deci', 'intrinsic', 'extrinsic', 'motivation', 'classic', 'deﬁnition', 'new', 'direction', 'temporary', 'educational', 'psychology', 'schmidhuber', 'j', 'possibility', 'implement', 'cu', 'riosity', 'boredom', 'modelbuilde', 'neural', 'controller', 'proc', 'international', 'conference', 'simulation', 'tive', 'behavior', 'animal', 'animat', 'schulman', 'radford', 'klimov', 'proximal', 'policy', 'optimization', 'preprint', 'schwarzer', 'anand', 'goel', 'r', 'hjelm', 'r', 'bachman', 'p', 'dataefﬁcient', 'inforcement', 'learning', 'selfpredictive', 'representation', 'international', 'conference', 'learn', 'representation', 'curiosity', 'science', 'interest', 'springer', 'gasser', 'development', 'bodied', 'cognition', 'lesson', 'baby', 'artiﬁcial', 'life']"
