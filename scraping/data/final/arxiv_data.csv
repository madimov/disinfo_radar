title,url,date,text,cleaning,tokens
"Country-Scale Cropland Mapping in Data-Scarce Settings Using Deep
  Learning: A Case Study of Nigeria","[{'href': 'http://arxiv.org/abs/2312.10872v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2312.10872v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-12-18 01:23:22,"3
2
0
2
c
e
D
8
1

]

V
C
.
s
c
[

1
v
2
7
8
0
1
.
2
1
3
2
:
v
i
X
r
a

COUNTRY-SCALE CROPLAND MAPPING IN DATA-SCARCE
SETTINGS USING DEEP LEARNING: A CASE STUDY OF NIGERIA

Joaquin Gajardo1,4,*, Michele Volpi2, Daniel Onwude1, and Thijs Defraeye1,3

1Empa, Swiss Federal Laboratories for Material Science and Technology. Laboratory for Biomimetic Membranes and
Textiles. Lerchenfeldstrasse 5, CH-9014 St. Gallen, Switzerland
2SDSC, Swiss Data Science Center, ETH Zurich and EPFL, Switzerland
3Food Quality and Design, Wageningen University & Research, P.O. Box 17, 6700 AA Wageningen, the Netherlands
4Institute of Agricultural Sciences, ETH Zurich, Universitätstrasse 2, Zurich, 8092, Switzerland
*Corresponding author. Now at ETH Zurich. Email: jgajardo@ethz.ch

ABSTRACT

Cropland maps are a core and critical component of remote-sensing-based agricultural monitoring.
These maps can provide dense and up-to-date information about agricultural development without
requiring regular field surveys, which are particularly challenging to execute in regions with limited
accessibility. Machine learning is an effective tool for large-scale agricultural mapping, but relies
on geo-referenced ground-truth data for model training and testing, which can be scarce or time-
consuming to obtain. In this study, we explore the usefulness of combining a global cropland dataset
and a hand-labeled dataset to train machine learning models for generating a new cropland map for
Nigeria in 2020 at 10 m resolution. We provide the models with pixel-wise time series input data
from remote sensing sources such as Sentinel-1 and 2, ERA5 climate data, and DEM data, in addition
to binary labels indicating cropland presence. We manually labeled 1827 evenly distributed pixels
across Nigeria, splitting them into 50% training, 25% validation, and 25% test sets used to fit the
models and test our output map. We evaluate and compare the performance of single- and multi-
headed Long Short-Term Memory (LSTM) neural network classifiers, a Random Forest classifier,
and three existing 10 m resolution global land cover maps (Google’s Dynamic World, ESRI’s Land
Cover, and ESA’s WorldCover) on our proposed test set. Given the regional variations in cropland
appearance, we additionally experimented with excluding or sub-setting the global crowd-sourced
Geowiki cropland dataset, to empirically assess the trade-off between data quantity and data quality in
terms of the similarity to the target data distribution of Nigeria. We find that the existing WorldCover
map performs the best with an F1-score of 0.825 and accuracy of 0.870 on the test set, followed by a
single-headed LSTM model trained with our hand-labeled training samples and the Geowiki data
points in Nigeria, with a F1-score of 0.814 and accuracy of 0.842. The code, data and output map
generated with the best LSTM model are made available to the public to support research aiming to
improve climate mitigation strategies, agricultural monitoring, and food security assessments.

Keywords Deep Learning, Agriculture, Satellite Images, Time Series, Transfer Learning, Large-scale mapping,
Sentinel

1

Introduction

Agricultural maps are relevant for a variety of downstream applications ranging from policy making, early-warning
systems for food security, and agricultural extension services [1]. The availability of free, granular, and high-cadence
data from remote sensing sources like Sentinel-1 and 2 satellites has enabled the creation of detailed land cover and
crop maps on a global scale [2]. Machine Learning (ML) is a widely employed methodology for generating these maps,
given its capacity to process and extract useful information from large and diverse amounts of data, thereby aiding
decision-making in agriculture [3].

 
 
 
 
 
 
Supervised machine learning, which requires high quality ground-truth data, has been applied extensively for generating
crop maps all over the world [4, 5, 6]. Governments in High-Income Countries (HIC) regularly collect detailed
information from farmers, including farm boundaries and crop types. This wealth of data has fueled research on
generating accurate and high-resolution cropland, crop type and crop yield maps in regions like USA and Europe
[4, 5, 7]. However, generating maps in countries where ground truth data is limited poses significant challenges. This
data is time- and resource-consuming to collect, yet it is essential for validating the generated maps and for training the
models to create them. As a mitigation strategy, one could attempt to leverage existing geo-referenced data related
to cropland or crop type presence from other regions our countries to enhance the models performance. However,
cropland data from different regions may present severe data distribution shifts associated with climate conditions,
diverse agricultural practices, and the types of crops planted. Therefore, leveraging globally distributed data to generate
agricultural maps in specific regions is not straight-forward and requires the use of different transfer learning strategies.
Studies such as [6, 8] created cropland maps for Togo and Kenya leveraging global and local hand-labelled cropland
samples by using a multi-task learning approach with an LSTM model. Other works have attempted to tackle the
problem from a meta-learning approach [9, 10] or from a representation learning perspective using transformer models
[11].

In this study, we focus on cropland mapping, framing it as a crop versus non-crop binary classification problem. We
train ML models to provide a probability score of a given pixel being crop (positive class) given a multi-temporal array
of pixel-wise data from different sensors (e.g. satellites images). Acquiring cropland ground-truth data, although a
time-consuming endeavour that demands specialized expertise, can be achieved remotely by labeling high-resolution
satellite or airborne image pixels through photo-interpretation [6]. Therefore, it is feasible to collect a minimal validation
data set that allows for the creation and validation of cropland maps in new regions. In this work, we specifically
aim to produce a cropland map for Nigeria using Sentinel data at a 10 m resolution for the year 2020, in order to
support agricultural applications in the region. Nigeria stands as one of the leading food producers in Africa, with a
population that accounts for about half of West-African population [12]. However, it currently lacks a cropland map at
this level of spatial resolution. Given its significant agricultural importance for the region, we generate a small dataset
of hand-labelled data for Nigeria to validate newly produced maps and to complement the training of different models
to generate them. To this end, we investigate the usefulness of the global crowd-sourced Geowiki cropland dataset
[13] together with our Nigeria dataset, by assessing and comparing an LSTM model and a Random Forest baseline.
We provide the models with multi-temporal input data from Sentinel-1 and Sentinel-2 missions, complemented by
local climate and topographic information (details in Section 2.1). For the LSTM, we explore standard and multi-task
learning settings [6, 8]. Furthermore, we explore different dataset configurations such as sub-setting Geowiki to points
within Nigeria or in neighbouring countries and compare our results to three 10 m resolution global land cover maps of
the same year, which are briefly described in Section 3.2.

2 Data

2.1 Remote sensing data

Sentinel-1 and Sentinel-2 satellites from ESA’s Copernicus program provide data at ground sample distance (GSD)
ranging from 10 to 60 m with frequent revisit time of 5 days world-wide, which is the best resolution freely available.
Sentinel-2 captures multispectral data on bands ranging from visible and near-infrared (GSD of 10 m) to short-wave
infrared (20 m to 60 m GSD), which are useful for vegetation monitoring and crop detection, by measuring how plants
reflect different wavelengths [14]. On the other hand, Sentinel-1 contains a Synthetic Aperture Radar (SAR) sensor,
which measures actively emitted radio wave signals in two polarization modes, as reflected by the surface. This data
is useful for detecting traits related to surface roughness such as crop height, growth stage and soil moisture content
[15]. We also include pixel-wise data of monthly total precipitation, monthly average temperature at 2 metres above
the ground from ERA5 Climate Reanalysis Meteorological data [16], as well as elevation and slope derived from the
Shuttle Radar Topography Mission’s (SRTM) Digital Elevation Model (DEM) [17].

The data was collected using the CropHarvest Python package [18] and Google Earth Engine [19] to produce a monthly
per-pixel data array (i.e. each pixels is characterised by 12 values for each parameter considered) for a requested year.
All Sentinel-2 bands are used and up-sampled to 10 m resolution except the B1 and B10, which have a coarse 60 m
resolution and are predominantly meant for coastal aerosols and cirrus detection. Least-cloudy monthly composites
of Sentinel-2 Level-1C images are obtained using an algorithm from [20]. Additionally, the Normalized Difference
Vegetation Index (NDVI = N IR−R
N IR+R ), derived from Sentinel-2 red (B4) and near-infrared (B8) bands, is also added
given its value for assessing vegetation health and growth [21]. Thus, the output datasets contain modified Copernicus
Sentinel data, ERA5, and SRTM data as processed by [18], yielding samples that are 18-dimensional arrays of features

2

at 12 different monthly time steps, counting backwards from the respective label collection date. The 18 considered
features are summarized on Table 1.

Table 1: Data features used in this study. All features were collected using the CropHarvest Python package [18].

Feature group

Feature descriptions

Feature count Data Type

Source

Sentinel-1

Sentinel-2

VV polarization mode
VH polarization mode

Visible bands (RGB)
Visible and Near Infrared bands (VNIR)
Short Wave Infrared bands (SWIR)
NDVI

Climate

Monthly average precipitation
Monthly average temperature

Topological

Elevation
Slope

1
1

3
5
3
1

1
1

1
1

Dynamic
Dynamic

Dynamic
Dynamic
Dynamic
Dynamic

Dynamic
Dynamic

Static
Static

Sentinel-1
Sentinel-1

Sentinel-2
Sentinel-2
Sentinel-2
Sentinel-2

ERA5 [16]
ERA5 [16]

SRTM [17]
SRTM [17]

2.2 Cropland labels

These data refers to manually annotated ground-truth spatial coordinates indicating the presence (or absence) of visible
cropland at a specific time. Each data point includes latitude and longitude coordinates, a reference date, and a label
indicating whether it represents cropland (1) or non-cropland (0). These coordinates and the reference date are used to
retrieve the corresponding remote sensing data.

2.2.1 Geowiki dataset

The Geowiki dataset consists of crowd-sourced points of cropland and non-cropland points sampled around the world
[13]. The original dataset consists of roughly 36,000 points, each associated with a cropland probability score, which is
the average of the labels provided by several human annotators. The Geowiki dataset is also readily available with the
CropHavest package [18]. The data arrays cover September 2016 to September 2017, and match the labels’ collection
date, to avoid mismatches due to possible land cover changes. The average label is transformed into 0 (non-cropland)
or 1 (cropland) using a crop probability threshold of 0.5. In addition, we experiment with two subsets of this dataset:
Geowiki Nigeria and Geowiki Neighbours. The number of points and class distribution for the full dataset and its
subsets are described below:

• Geowiki World: contains all Geowiki dataset samples available in the CropHarvest package. The total number
of collected samples are only 24761, presumably due to the input data availability, and out of which 13980 are
labelled as cropland and 10781 labelled as non-cropland.

• Geowiki Nigeria: this subset includes all Geowiki samples available in the CropHarvest package that
fall within Nigeria boundaries. They amount to 452 samples, out of which 312 are cropland and 140 are
non-cropland samples.

• Geowiki Neighbours: this subset includes Geowiki Nigeria and all Geowiki samples available in the CropHar-
vest package that fall within the boundaries of the following countries close to Nigeria: Ghana, Togo, Benin,
and Cameroon. This choice of countries was due to data availability and sharing of agro-ecological zones.
Together they amount to 790 samples, from which 460 are cropland and 330 are non-cropland.

The Geowiki datasets described above are randomly split into 80 % training and 20 % validation data for the models.

2.2.2 Nigeria dataset

A dataset of evenly distributed points within Nigeria was generated and labelled as cropland or non-cropland via
photo-interpretation. Spatial coordinates were randomly sampled within the country, until 2000 points spaced by least
15 km were obtained. Each point was examined using very high-resolution Google Satellite Imagery Basemap (which
is mostly derived from Maxar’s 30 cm GSD mosaics) from 2020 in Google Earth Pro and labelled by an expert as
cropland (1) or non-cropland (0) using QGIS. We consider cropland as arable land (cultivated or fallow) and areas
where permanent (perennial) crops are grown, including orchards [22]. 1827 points were labelled and the remaining
discarded as the class could not be determined by the human annotator from the available reference imagery. We note

3

Figure 1: Geographical distribution of the 1827 points of the generated Nigeria dataset and its assigned splits for model
training and evaluation. Nigeria state boundaries are taken from [23].

that given our constraint on the number of annotators and the remote labeling process, some labels may contain errors,
particularly in regions affected by water scarcity, where distinguishing between fallow or wasteland was challenging.
The dataset was then split into 50% train, 25% validation and 25% test sets using a stratified random sampling strategy,
whereby each point within the validation and test sets were at least 30 km apart from each other. Using a stratified
random splits covering the whole country is important to guarantee the quality of the output map at identifying cropland
under the different climate and vegetation types found in the country, in a spatially homogeneous manner. The resulting
splits are depicted in Figure 1. The coordinates of these points were used to query the respective pixel-wise data arrays
from March 2019 - March 2020 using the CropHarvest package. The final dataset consists of 1822 data samples with a
class distribution per split described in Table 2.

Table 2: Class distribution of Nigeria dataset. The cropland ratio refers to the proportion of points labelled as cropland
in each data split.

Data split

Points

Cropland ratio

Train
Validation
Test

Total

913
454
455

1822

0.417
0.399
0.402

0.409

2.3 Dataset combination

We experiment with various combinations of the Geowiki dataset subsets, as described in Section 2.2.1, and considered
both including and excluding the Nigeria dataset for training. To normalize the data, we initially calculated per-channel
means and standard deviations independently using their training and validation samples. When merging datasets,
as in [6], we combined all samples of the respective splits and calculated weighted per-channel means and standard

4

14

12

10

e
d
u
t
i
t
a
L

8

6

4

Nigeria states
1: Abia
2: Adamawa
3: Akwa Ibom
4: Anambra
5: Bauchi
6: Bayelsa
7: Benue
8: Borno
9: Cross River
10: Delta
11: Ebonyi
12: Edo
13: Ekiti
14: Enugu
15: Fed. Capital Territory
16: Gombe
17: Imo
18: Jigawa
19: Kaduna
20: Kano
21: Katsina
22: Kebbi
23: Kogi
24: Kwara
25: Lagos
26: Nasarawa
27: Niger
28: Ogun
29: Ondo
30: Osun
31: Oyo
32: Plateau
33: Rivers
34: Sokoto
35: Taraba
36: Yobe
37: Zamfara

0

2

4

34

37

22

27

13

23

29

24

30

31

28

25

21

19

18

36

20

8

5

16

32

2

15

26

35

7

9

train
validation
test

10

12

14

12

10

14

4

11

17

1

6

33

3

6

8
Longitude

deviations based on the number of samples in each dataset relative to the total combined samples. Subsequently, we
applied this per-channel mean and standard deviation normalization to all samples in any data split.

3 Methods

3.1 Models

We followed [6, 8] and experimented with two LSTM neural network architectures: a standard one [24] and a multi-task
(multi-head) implementation [6]. LSTM networks, which are a type of Recurrent Neural Network (RNN), excel in
processing sequential data such as text or time series data. This makes them well-suited for crop classification tasks,
as they can effectively capture temporal patterns and dependencies in remote sensing data [4]. The model is trained
for binary classification of individual pixels. Each pixel in the input data is represented as a regularly sampled time
series X = [x1, x2, ..., x12] of 12 time steps of 18 dimensions each, i.e. xt ∈ R1×18. The model can have either one or
two identical classification heads each consisting of a Multilayer Perceptron (MLP) and a sigmoid activation function
to normalize the last activation between 0 and 1. This value can be interpreted as a posterior probability of cropland
presence. When using the two classification heads, they both share the same LSTM backbone, but the global head
classifies all the samples that are outside the boundaries of Nigeria and the local head classifies all samples that fall
within Nigeria. This multi-headed architecture follows a multi-task learning approach [9]. In this setup, classifying
global and local samples are treated as separate tasks handled by a dedicated head, but whereby they can leverage
shared patterns learned by the LSTM backbone. The local head can then be used as a specialized classifier specialized
for the region of interest.

This architecture is trained by minimizing the loss function of Eq. (1) [6], where Llocal and Lglobal are Binary Cross-
Entropy (BCE) loss functions of the local and global classification heads respectively. W
α is a weighting term, where W
is the proportion of global to local labels in each batch and α is a weighting hyper-parameter. This weighting term
reduces the impact of the global head in the overall loss function and thus its influence over the parameters updates of
the shared LSTM backbone, effectively giving more relevance to the local classification task in the overall architecture.
When using only one head, all the samples are treated equally (no weighting).

For this work, both Llocal and Lglobal BCE loss terms are additionally weighted according to the class distributions,
as in Eq. (2), to better account for class imbalance. In here, w(1) and w(0) respectively represent the inverse of the
cropland and non-cropland instances proportion from the total amount of local or global labels, y is the label and ˆy is
the model prediction.

L =

W
α

Lglobal + Llocal

Li = −(w(1) · y · log(ˆy) + w(0) · (1 − y) · log(1 − ˆy))

(1)

(2)

All hyper-parameters were kept to default values from [6]. These include one hidden layer size of 64 units for the LSTM
backbone, two classification layers on the MLPs, dropout of 0.2 between LSTM state updates and an α of 10. We
trained all models using the Adam optimizer [25], with a learning rate of 0.001, and a batch size of 64, for a maximum
of 100 epochs and early stopping with patience of 10 epochs on the validation set loss. A grid-search of {32, 64, 128}
hidden units and {1, 2} LSTM hidden layers on the validation set confirmed that these are robust hyper-parameters for
our datasets. We refer the reader to [6] for further details and a schematic diagram of the model architecture. The deep
learning models are implemented in PyTorch [26]. We also included a Random Forest baseline model from scikit-learn
[27] default implementation (100 trees with bootstrapping on the full dataset), due to its robustness and widespread use
for crop and land cover classification [28].

3.2 Land cover maps

We additionally compare our models to three global land cover maps of 2020 at 10 m resolution. These maps are
Google’s Dynamic World [29], ESRI’s 2020 Land Cover [30] and ESA’s WorldCover 2020 [31]. Dynamic World
and ESRI Land Cover are two global land cover map produced with deep learning models, which were both trained
using a dataset of 5 billion densely annotated patches of Sentinel-2 imagery distributed all over the world by experts
and non-experts [2]. On the other hand, the global WorldCover map was produced with a Catboost model trained on
pixels from 100 by 100 m patches of 141,000 locations around the world, which were labeled by experts [31, 2]. Both
WorldCover and ESRI LandCover maps are produced yearly and have only discrete pixel assignments to classes, while
Dynamic World is updated in near-real time (as new Sentinel-2 scenes become available approximately every 5 days)

5

and also provides the probability for each pixel belonging to each of the possible classes. Another key difference is that
WorldCover additionally uses Sentinel-1, together with Sentinel-2 and other auxiliary data, as well as being digitized
with a smaller Minimum Mapping Distance (MMU) of 100 m2, compared to 250 m2 of the other two maps. While all
maps are multi-class, we focus on the cropland class (named ""crops"" in ESRI and Dynamic World maps), and converted
the maps to a binary version by assigning all non-cropland pixel values to the negative class and all cropland pixels to
the positive class. This was done in order to be able to evaluate the maps performance on our Nigeria test set. We note
that the cropland class in these maps do not consider tree plantations, which are categorized under a ""trees"" class for all
three maps.

3.3 Evaluation metrics

We evaluated the models as well as the binarized land cover maps quantitatively by computing different performance
metrics of their predictions on the Nigeria test set. The different metrics used are precision (proportion of correct
predictions), recall (proportion of correctly identified samples or ""probability of detection""), F1-score (harmonic mean
between precision and recall and thus a symmetric measure of both), total accuracy (global proportion of correctly
classified samples), and the Area Under the Receiver Operating Characteristic Curve (AUC ROC). These metrics are all
typically used in classification settings and AUC ROC is exclusively used in binary classification for evaluating the
ability of a classifier to correctly distinguish between the positive and negative classes. For all metrics a higher value
is better, however since achieving a perfect recall and precision simultaneously is not possible in practice, a higher
F1-score reflects a better trade-off between the two. The equations for precision, recall, F1-score and total accuracy
are given in Eqs. (3), where TP, FP, FN, and TN are true positives, false positives, false negatives, and true negatives
predictions, respectively. Note that for calculating the precision, recall, F1-score and total accuracy metrics, model
prediction probabilities first need to be converted to binary predictions (0 or 1) by applying a threshold value. On
the other hand, the AUC ROC score is calculated by computing the True Positive Rate (TPR = recall) and the False
Positive Rate (FPR = FP
FP+TN , or ""probability of false alarm"") at different thresholds values to build the ROC and then
calculating the area under this curve. The scikit-learn Python package was used for calculating all metrics [27].

Precision =

Recall =

F1-score =

Total Accuracy =

TP
TP + FP
TP
TP + FN
2 × Precision × Recall
Precision + Recall

TP + TN
TP + FP + FN + TN

(3)

In this study, a threshold of 0.5 was used as in [6], which is a sensible choice given there is no clear preference
for a higher TPR or FPR in our cropland mapping use case (also note that this threshold is only required for model
performance evaluation and is not used in any way during model training). Alternatively, this threshold could be
optimized on a held-out validation set, or according to a desired confidence on model predictions, but we did not
consider this setting.

4 Results

4.1 Main experiments

In this section we present the experimental results of the different models on the Nigeria test set, considering the
different dataset configurations discussed in Section 2.3. We also compared our results to the global land cover maps
introduced in Section 3.2 as benchmarks. The results are summarized on Table 3.

We can observe that the WorldCover map performs exceptionally well, particularly in terms of F1-score and total
accuracy, compared to any of the models or other land cover maps. However, we also note that its recall is overall
lower than those of the models, highlighting the need for careful consideration of the metric based on specific use cases.
Among the implemented models, the single-headed LSTM model when using the Nigeria dataset and the Geowiki
Nigeria subset achieves the best performance. Overall, all models show substantial improvement when the Nigeria
dataset is included for training. It can also be observed that the Geowiki dataset is also beneficial in this case, but only
when one of its subsets its used rather than the full Geowiki World dataset.

6

Table 3: Results on the test set. A threshold of 0.5 was applied on the predicted probability to binarize into labels. Best
results per metric are in bold and second best are underlined.

Map / Model

Geowiki dataset Nigeria dataset AUC ROC Precision Recall

F1-score Accuracy

ESA WorldCover 2020
ESRI 2020
Dynamic World 2020

-
-
-

Random Forest

Single-headed LSTM

Multi-headed LSTM

×
Nigeria
Neighbours
World
Nigeria
Neighbours
World

×
Nigeria
Neighbours
World
Nigeria
Neighbours
World

Neighbours
World
Neighbours
World

-
-
-

✓
✓
✓
✓
×
×
×
✓
✓
✓
✓
×
×
×
✓
✓
×
×

-
-
-

0.911
0.915
0.916
0.796
0.755
0.842
0.755

0.908
0.907
0.906
0.884
0.756
0.874
0.854

0.889
0.893
0.772
0.819

0.903
0.867
0.491

0.774
0.782
0.791
0.569
0.495
0.695
0.522

0.772
0.771
0.788
0.671
0.561
0.688
0.575

0.737
0.917
0.638
0.721

0.760
0.213
0.448

0.787
0.825
0.765
0.858
0.891
0.798
0.836

0.776
0.863
0.831
0.847
0.749
0.831
0.902

0.874
0.541
0.694
0.650

0.825
0.342
0.469

0.780
0.803
0.778
0.684
0.637
0.743
0.643

0.774
0.814
0.809
0.749
0.642
0.752
0.702

0.800
0.680
0.665
0.684

0.870
0.670
0.591

0.822
0.837
0.824
0.681
0.591
0.778
0.626

0.818
0.842
0.842
0.771
0.664
0.780
0.692

0.824
0.796
0.719
0.758

We can also observe that the best-performing Random Forest model is competitive to the best single-headed LSTM
model and outperforms the multi-headed LSTM model. Nevertheless, the multi-headed LSTM model performs better
than the Random Forest model when using the same Geowiki subset for training. Furthermore, the AUC ROC metric
offer insights into model performance under different thresholds values, and we also depict the ROC curves for the
two best models of each type (based on total accuracy) in Figure 2. In here, we can see how the Random Forest model
performs better at lower thresholds (middle-right side of the curves), which can explain its higher AUC ROC scores
compared to the other models.

4.2 Ablation experiments

We conducted supplementary experiments by exclusively using the Sentinel-2 bands and by using only a regular
BCE loss function for the LSTM models. The results for these experiments are presented on Table S1 and Table S2,
respectively, in the Supplementary Material. Including additional data from Sentinel-1, climate and topography helps to
significantly improve the results for all models under any dataset combination. However, it is interesting to note how
the performance drop is most pronounced whenever Geowiki data is included, which might suggest that this additional
features provide essential information for the models to identify the data distribution shifts. Furthermore, we also
confirm that using a weighted BCE loss function improves the results from the single-headed LSTM models. However,
its impact is particularly significant under dataset configurations that have a more pronounced class imbalance, such as
when using the Geowiki Nigeria subset.

4.3 Nigeria cropland maps

We use our best model, the single-headed LSTM trained with the Geowiki Nigeria subset the Nigeria dataset, to generate
both binary and probabilistic cropland maps covering the entire extent of Nigeria for the year 2020. The maps are
presented on Figure 3. The cropland probability map offers additional valuable insights that are not available with the
discrete WorldCover land cover map.

5 Discussion

From our quantitative results we see that with the given remote sensing data and labels, the Random Forest and LSTM
models do not achieve better performance on our cropland test set of Nigeria compared to the WorldCover land cover

7

Figure 2: Receiving Operator Curve on the test set for two best models (regarding accuracy) of each type. All models
represented here use the Nigeria hand-labelled data.

map. The three land cover maps evaluated also present drastic differences in performance. While WorldCover achieves
an accuracy of 0.825 and F1-score of 0.870, both ESRI and Dynamic World maps lag several percentage points behind.
In [2] a comparative analysis about these three maps was performed for all land cover classes and they suggest that
WorldCover is better suited for resolving smaller and more complex agricultural landscapes. They argue this might
be due to its lower MMU of 100 m2 compared to 250 m2 of the other two maps, and that it was likely trained for
pixel-wise classification rather than for semantic segmentation. Therefore, this map may be specially well suited for
detecting cropland in regions where smallholder farming is predominant, which also implies identifying isolated pixels
representing small plots of cropland.

Among our assessed models, the best performing was the single-headed LSTM trained with the Geowiki Nigeria and
Nigeria datasets, which achieved a total accuracy of 0.842 and an F1-score of 0.814, and was used for creating our
Nigeria cropland maps. This performance is on pair with a Kenya cropland map (0.86 total accuracy and 0.84 F1-score)
[8] and a Togo cropland map (0.83 total accuracy and 0.74 F1-score) [6], that were recently generated with a similar
approach. Regarding the other models, we observe interesting results under the different combinations of datasets used
for training. We learn that while including our local labels improves performance in all cases, it is also possible to
train a good classifier using only labels from Geowiki, notably when using the Geowiki Neighbours subset. For this
configuration, the single-headed LSTM model achieves a F1-score and accuracy greater than 0.75. Additionally, the
multi-headed LSTM model is the only model where, when excluding the Nigeria dataset for training, using all of the
Geowiki samples actually improves performance compared to using only a subset of Geowiki. This suggests that at
least under certain cases, such as the absence of local labels for training, clever transfer learning techniques can indeed
yield better results, compared to just combining all available data. The latter approach may in fact cause the resulting
training data distribution to diverge significantly from that of the target country and dataset.

The advent of Sentinel satellite data has allowed for the creation of land cover, cropland and even crop yield maps at 10
m resolution, thus enabling the detection of smallholder farming and facilitating comprehensive agricultural monitoring
at national scales [32]. In light of this progress, our study examines cropland mapping in Nigeria, comparing custom
machine learning models trained for this task and recent global land cover maps at 10 m resolution. While we found
that having enough local training data leads to improved results for custom models, the WorldCover land cover map
is a robust choice for cropland mapping in Nigeria. Therefore, although there has been recent work in evaluating the
accuracy of land cover maps for mapping agricultural land [33], there is a need for a systematic comparative assessment
between these maps and those produced with custom, country-specific models for cropland classification such as those
evaluated in this work. Further research could help practitioners and local governments to discern when relying on

8

e
t
a
r

e
v
i
t
i
s
o
p

e
u
r
T

1.0

0.8

0.6

0.4

0.2

0.0

Single-headed LSTM (Geowiki Nigeria)
Single-headed LSTM (Geowiki neighbours)
Multi-headed LSTM (Geowiki neighbours)
Multi-headed LSTM (Geowiki world)
Random Forest (Geowiki Nigeria)
Random Forest (Geowiki neighbours)
random

0.0

0.2

0.4
0.6
False positive rate

0.8

1.0

 
 
Figure 3: Binary (with a threshold of 0.5) and probability cropland maps for Nigeria in 2020 (A and B, respectively),
generated with our the best model (single-headed LSTM model trained with Nigeria dataset and Geowiki Nigeria subset
dataset). Figure 1 for the state names. Missing data within the country is shown in white.

9

14

A

Nigeria 2020 cropland binary map

N

12

10

e
d
u
t
i
t
a
L

8

6

4

200 km

4

6

cropland
non-cropland

8
Longitude

10

12

14

Nigeria 2020 cropland probability map

14

B

N

12

10

e
d
u
t
i
t
a
L

8

6

4

200 km

4

6

8
Longitude

10

12

14

y
t
i
l
i

b
a
b
o
r
p

l

d
n
a
p
o
r
C

0.8

0.6

0.4

0.2

0.0

 
existing land cover maps suffices for their agricultural needs and when it is judicious to allocate resources for data
collection and the development of croplands maps tailored to their specific requirements.

6 Conclusion

Up-to-date and accurate cropland maps provide fundamental information for many agricultural applications and are
a critical tool for rapidly assessing the effects of climate change on food security at large-scales. In this work we
developed two cropland maps for Nigeria in 2020 at 10 m resolution using deep learning and time series of remote
sensing data. To this end, we created a dataset of uniformly-distributed points around the country and labelled them as
cropland or non-cropland via photo-interpretation. We used this dataset for training and validation of a single- and
multi-headed LSTM network and compared them to a random forest model and three global land cover maps. We
investigated the benefit of combining our training data with different subsets of the Geowiki dataset, a large global
dataset of cropland points. We found that the WorldCover land cover map has the best performance on our test set
compared to all other maps and models. The best performing model was the single-headed LSTM model, obtained
when combining our new training labels with the subset of points of the Geowiki dataset contained within Nigeria’s
border. We observed that except in cases where the local manually labeled data were not provided to the model, using
all of Geowiki labels is always detrimental for the model unless we use a dedicated transfer learning architecture
such as a multi-headed LSTM classifier. However, we find that including training labels from Geowiki on countries
close to the target country may complement and boost the performance of the model compared to using only labels
from the country. Although collecting more training labels, either on-site or remotely, would generally lead to better
results, the WorldCover land cover map proves to be a robust alternative for identifying cropland in Nigeria. This result
is particularly relevant in cases where there is a lack of training labels available in the target region and insufficient
resources for their collection. Nevertheless, land cover maps are generally static in time, whereas cropland maps can be
generated by researchers or governments at any time, thus we consider that studying how to best leverage the available
ground-truth data to be an important research topic for providing timely and accurate cropland extent information.

Data and code availability

The source code, as well as the links to download the data and output maps, are publicly available in the following
repository: https://github.com/Joaquin-Gajardo/nigeria-crop-mask.

The maps can be visualized interactively with the following Google Earth Engine script (account needed): https:
//code.earthengine.google.com/df4bf4a222269289e982de7a48fb68fc

Acknowledgments

This work was funded partially by the data.org Inclusive Growth and Recovery Challenge grant “Your Virtual Cold
Chain Assistant”, supported by The Rockefeller Foundation and the Mastercard Center for Inclusive Growth, as well
as by the project “Scaling up Your Virtual Cold Chain Assistant” commissioned by the German Federal Ministry
for Economic Cooperation and Development and being implemented by BASE and Empa on behalf of the German
Agency for International Cooperation (GIZ). The funders were not involved in the study design, collection, analysis,
interpretation of data, the writing of this article, or the decision to submit it for publication.

References

[1] Inbal Becker-Reshef, Brian Barker, Alyssa Whitcraft, Patricia Oliva, Kara Mobley, Christina Justice, and Ritvik
Sahajpal. Crop Type Maps for Operational Global Agricultural Monitoring. Scientific Data, 10(1):172, March
2023.

[2] Zander S. Venter, David N. Barton, Tirthankar Chakraborty, Trond Simensen, and Geethen Singh. Global 10 m
land use land cover datasets: A comparison of dynamic world, world cover and esri land cover. Remote Sensing,
14(16), 2022.

[3] Dashuai Wang, Wujing Cao, Fan Zhang, Zhuolin Li, Sheng Xu, and Xinyu Wu. A Review of Deep Learning in

Multiscale Agricultural Sensing. Remote Sensing, 14(3):559, January 2022.

[4] Marc RuBwurm and Marco Korner. Temporal Vegetation Modelling Using Long Short-Term Memory Networks
for Crop Identification from Medium-Resolution Multi-spectral Satellite Images. In 2017 IEEE Conference on

10

Computer Vision and Pattern Recognition Workshops (CVPRW), pages 1496–1504, Honolulu, HI, USA, July 2017.
IEEE.

[5] Mehmet Ozgur Turkoglu, Stefano D’Aronco, Gregor Perich, Frank Liebisch, Constantin Streit, Konrad Schindler,
and Jan Dirk Wegner. Crop mapping from image time series: Deep learning with multi-scale label hierarchies.
Remote Sensing of Environment, 264:112603, October 2021.

[6] Hannah Kerner, Gabriel Tseng, Inbal Becker-Reshef, Catherine Nakalembe, Brian Barker, Blake Munshell,

Madhava Paliyam, and Mehdi Hosseini. Rapid response crop maps in data sparse regions, 2020.

[7] Gregor Perich, Mehmet Ozgur Turkoglu, Lukas Valentin Graf, Jan Dirk Wegner, Helge Aasen, Achim Walter,
and Frank Liebisch. Pixel-based yield mapping and prediction from sentinel-2 using spectral indices and neural
networks. Field Crops Research, 292:108824, 2023.

[8] Tseng, Gabriel, Kerner, Hannah, Nakalembe, Catherine, and Becker-Reshef, Inbal. Annual and in-season mapping

of cropland at field scale with sparse labels, November 2020. Type: dataset.

[9] Gabriel Tseng, Hannah Kerner, Catherine Nakalembe, and Inbal Becker-Reshef. Learning to predict crop type
from heterogeneous sparse labels using meta-learning. In 2021 IEEE/CVF Conference on Computer Vision and
Pattern Recognition Workshops (CVPRW), pages 1111–1120, Nashville, TN, USA, June 2021. IEEE.

[10] Gabriel Tseng, Hannah Kerner, and David Rolnick. Timl: Task-informed meta-learning for agriculture, 2022.

[11] Gabriel Tseng, Ivan Zvonkov, Mirali Purohit, David Rolnick, and Hannah Kerner. Lightweight, pre-trained

transformers for remote sensing timeseries, 2023.

[12] Daniel Onwude, Thomas Motmans, Kanaha Shoji, Roberta Evangelista, Joaquin Gajardo, Divinefavor Odion,
Nnaemeka Ikegwuonu, Olubayo Adekanmbi, Soufiane Hourri, and Thijs Defraeye. Bottlenecks in nigeria’s fresh
food supply chain: What is the way forward? Trends in Food Science & Technology, 137:55–62, 2023.

[13] Juan Carlos Laso Bayas, Myroslava Lesiv, François Waldner, Anne Schucknecht, Martina Duerauer, Linda See,
Steffen Fritz, Dilek Fraisl, Inian Moorthy, Ian McCallum, Christoph Perger, Olha Danylo, Pierre Defourny, Javier
Gallego, Sven Gilliams, Ibrar ul Hassan Akhtar, Swarup Jyoti Baishya, Mrinal Baruah, Khangsembou Bungnamei,
Alfredo Campos, Trishna Changkakati, Anna Cipriani, Krishna Das, Keemee Das, Inamani Das, Kyle Frankel
Davis, Purabi Hazarika, Brian Alan Johnson, Ziga Malek, Monia Elisa Molinari, Kripal Panging, Chandra Kant
Pawe, Ana Pérez-Hoyos, Parag Kumar Sahariah, Dhrubajyoti Sahariah, Anup Saikia, Meghna Saikia, Peter
Schlesinger, Elena Seidacaru, Kuleswar Singha, and John W Wilson. A global reference database of crowdsourced
cropland data collected using the Geo-Wiki platform. Scientific Data, 4(1):170136, September 2017.

[14] Francesco Vuolo, Martin Neuwirth, Markus Immitzer, Clement Atzberger, and Wai-Tim Ng. How much does multi-
temporal sentinel-2 data improve crop type classification? International Journal of Applied Earth Observation
and Geoinformation, 72:122–130, 2018.

[15] Zheng Sun, Di Wang, and Geji Zhong. A review of crop classification using satellite-based polarimetric sar
imagery. In 2018 7th International Conference on Agro-geoinformatics (Agro-geoinformatics), pages 1–5, 2018.

[16] Hans Hersbach, Bill Bell, Paul Berrisford, Shoji Hirahara, András Horányi, Joaquín Muñoz-Sabater, Julien Nicolas,
Carole Peubey, Raluca Radu, Dinand Schepers, Adrian Simmons, Cornel Soci, Saleh Abdalla, Xavier Abellan,
Gianpaolo Balsamo, Peter Bechtold, Gionata Biavati, Jean Bidlot, Massimo Bonavita, Giovanna De Chiara,
Per Dahlgren, Dick Dee, Michail Diamantakis, Rossana Dragani, Johannes Flemming, Richard Forbes, Manuel
Fuentes, Alan Geer, Leo Haimberger, Sean Healy, Robin J. Hogan, Elías Hólm, Marta Janisková, Sarah Keeley,
Patrick Laloyaux, Philippe Lopez, Cristina Lupu, Gabor Radnoti, Patricia de Rosnay, Iryna Rozum, Freja
Vamborg, Sebastien Villaume, and Jean-Noël Thépaut. The era5 global reanalysis. Quarterly Journal of the Royal
Meteorological Society, 146(730):1999–2049, 2020.

[17] Tom G. Farr, Paul A. Rosen, Edward Caro, Robert Crippen, Riley Duren, Scott Hensley, Michael Kobrick, Mimi
Paller, Ernesto Rodriguez, Ladislav Roth, David Seal, Scott Shaffer, Joanne Shimada, Jeffrey Umland, Marian
Werner, Michael Oskin, Douglas Burbank, and Douglas Alsdorf. The shuttle radar topography mission. Reviews
of Geophysics, 45(2), 2007.

[18] Gabriel Tseng, Ivan Zvonkov, Catherine Lilian Nakalembe, and Hannah Kerner. Cropharvest: A global dataset
for crop-type classification. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and
Benchmarks Track (Round 2), 2021.

[19] Noel Gorelick, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. Google earth
engine: Planetary-scale geospatial analysis for everyone. Remote Sensing of Environment, 202:18–27, 2017. Big
Remotely Sensed Data: tools, applications and experiences.

11

[20] M. Schmitt, L. H. Hughes, C. Qiu, and X. X. Zhu. AGGREGATING CLOUD-FREE SENTINEL-2 IMAGES
WITH GOOGLE EARTH ENGINE. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Informa-
tion Sciences, IV-2/W7:145–152, September 2019.

[21] Rei Sonobe, Yuki Yamaya, Hiroshi Tani, Xiufeng Wang, Nobuyuki Kobayashi, and Kan ichiro Mochizuki. Crop
classification from Sentinel-2-derived vegetation indices using ensemble learning. Journal of Applied Remote
Sensing, 12(2):026019, 2018.

[22] A Markandya. Water and the Rural Poor: Interventions for Improving Livelihoods in sub-Saharan Africa. FAO,

2008.

[23] The Humanitarian Data Exchange (HDX). Nigeria - administrative boundaries. https://datacatalog.

worldbank.org/search/dataset/0039368, 2017. Accessed: 2023-10-01.

[24] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural Computation, 9(8):1735–1780, 1997.
[25] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.
[26] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito,
Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala.
In Advances in Neural Information
Pytorch: An imperative style, high-performance deep learning library.
Processing Systems 32, pages 8024–8035. Curran Associates, Inc., 2019.

[27] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss,
V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn:
Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830, 2011.

[28] Charlotte Pelletier, Silvia Valero, Jordi Inglada, Nicolas Champion, and Gérard Dedieu. Assessing the robustness
of random forests to map land cover with high resolution satellite image time series over large areas. Remote
Sensing of Environment, 187:156–168, 2016.

[29] Christopher F. Brown, Steven P. Brumby, Brookie Guzder-Williams, Tanya Birch, Samantha Brooks Hyde, Joseph
Mazzariello, Wanda Czerwinski, Valerie J. Pasquarella, Robert Haertel, Simon Ilyushchenko, Kurt Schwehr,
Mikaela Weisse, Fred Stolle, Craig Hanson, Oliver Guinan, Rebecca Moore, and Alexander M. Tait. Dynamic
World, Near real-time global 10 m land use land cover mapping. Scientific Data, 9(1):251, June 2022.

[30] Krishna Karra, Caitlin Kontgis, Zoe Statman-Weil, Joseph C. Mazzariello, Mark Mathis, and Steven P. Brumby.
Global land use / land cover with Sentinel 2 and deep learning. In 2021 IEEE International Geoscience and
Remote Sensing Symposium IGARSS, pages 4704–4707, Brussels, Belgium, July 2021. IEEE.

[31] Daniele Zanaga, Ruben Van De Kerchove, Wanda De Keersmaecker, Niels Souverijns, Carsten Brockmann, Ralf
Quast, Jan Wevers, Alex Grosu, Audrey Paccini, Sylvain Vergnaud, Oliver Cartus, Maurizio Santoro, Steffen Fritz,
Ivelina Georgieva, Myroslava Lesiv, Sarah Carter, Martin Herold, Linlin Li, Nandin-Erdene Tsendbazar, Fabrizio
Ramoino, and Olivier Arino. Esa worldcover 10 m 2020 v100, October 2021.

[32] Zhenong Jin, George Azzari, Calum You, Stefania Di Tommaso, Stephen Aston, Marshall Burke, and David B.
Lobell. Smallholder maize area and yield mapping at national scales with google earth engine. Remote Sensing of
Environment, 228:115–128, 2019.

[33] Hannah Kerner, Catherine Nakalembe, Adam Yang, Ivan Zvonkov, Ryan McWeeny, Gabriel Tseng, and Inbal

Becker-Reshef. How accurate are existing land cover maps for agriculture in sub-saharan africa?, 2023.

12

7 Supplementary Material

Table S1: Results comparison on the test set with only using Sentinel-2 bands and NDVI for training. A threshold of
0.5 was applied on the predicted probability to binarize into labels. Best results per metric are in bold and second best
are underlined.

Model

Geowiki dataset Nigeria dataset AUC ROC Precision Recall

F1-score Accuracy

Random Forest

Single-headed LSTM

Multi-headed LSTM

×
Nigeria
Neighbours
World
Nigeria
Neighbours
World

×
Nigeria
Neighbours
World
Nigeria
Neighbours
World

Neighbours
World
Neighbours
World

✓
✓
✓
✓
×
×
×
✓
✓
✓
✓
×
×
×
✓
✓
×
×

0.880
0.887
0.887
0.722
0.606
0.778
0.691

0.886
0.869
0.870
0.750
0.658
0.810
0.804

0.884
0.847
0.808
0.600

0.749
0.755
0.764
0.587
0.471
0.723
0.530

0.730
0.781
0.733
0.584
0.667
0.681
0.608

0.810
0.780
0.702
0.600

0.765
0.809
0.743
0.667
0.574
0.470
0.732

0.814
0.645
0.689
0.683
0.284
0.607
0.863

0.650
0.601
0.475
0.050

0.757
0.781
0.753
0.624
0.517
0.570
0.615

0.770
0.707
0.710
0.630
0.398
0.642
0.713

0.721
0.679
0.567
0.091

0.802
0.818
0.804
0.677
0.569
0.714
0.631

0.804
0.785
0.774
0.677
0.655
0.727
0.721

0.798
0.771
0.708
0.604

Table S2: Results of LSTM model on test set without using a weighted BCE loss. A threshold of 0.5 was applied on
the predicted probability to binarize into labels. Best results per metric are in bold and second best are underlined.

Model

Geowiki dataset Nigeria dataset AUC ROC Precision Recall

F1-score Accuracy

Single-headed LSTM

Multi-headed LSTM

×
Nigeria
Neighbours
World
Nigeria
Neighbours
World

Neighbours
World
Neighbours
World

✓
✓
✓
✓
×
×
×
✓
✓
×
×

0.907
0.907
0.905
0.868
0.785
0.872
0.846

0.890
0.892
0.827
0.814

0.797
0.764
0.791
0.704
0.497
0.632
0.538

0.743
0.920
0.591
0.723

0.749
0.847
0.809
0.792
0.874
0.918
0.929

0.869
0.437
0.831
0.628

0.772
0.803
0.800
0.746
0.633
0.748
0.681

0.801
0.593
0.691
0.673

0.822
0.833
0.837
0.782
0.593
0.752
0.651

0.826
0.758
0.701
0.754

13

","3 2 0 2 c e D 8 1 ] V C . s c [ 1 v 2 7 8 0 1 . 2 1 3 2 : v i X r a COUNTRY-SCALE CROPLAND MAPPING IN DATA-SCARCE SETTINGS USING DEEP LEARNING : A CASE STUDY OF NIGERIA Joaquin Gajardo1,4 , * , Michele Volpi2 , Daniel Onwude1 , and Thijs Defraeye1,3 1Empa , Swiss Federal Laboratories for Material Science and Technology . Laboratory for Biomimetic Membranes and Textiles . Lerchenfeldstrasse 5 , CH-9014 St. Gallen , Switzerland 2SDSC , Swiss Data Science Center , ETH Zurich and EPFL , Switzerland 3Food Quality and Design , Wageningen University & Research , P.O . Box 17 , 6700 AA Wageningen , the Netherlands 4Institute of Agricultural Sciences , ETH Zurich , Universitätstrasse 2 , Zurich , 8092 , Switzerland * Corresponding author . Now at ETH Zurich . Email : jgajardo @ ethz.ch ABSTRACT Cropland maps are a core and critical component of remote-sensing-based agricultural monitoring . These maps can provide dense and up-to-date information about agricultural development without requiring regular field surveys , which are particularly challenging to execute in regions with limited accessibility . Machine learning is an effective tool for large-scale agricultural mapping , but relies on geo-referenced ground-truth data for model training and testing , which can be scarce or time- consuming to obtain . In this study , we explore the usefulness of combining a global cropland dataset and a hand-labeled dataset to train machine learning models for generating a new cropland map for Nigeria in 2020 at 10 m resolution . We provide the models with pixel-wise time series input data from remote sensing sources such as Sentinel-1 and 2 , ERA5 climate data , and DEM data , in addition to binary labels indicating cropland presence . We manually labeled 1827 evenly distributed pixels across Nigeria , splitting them into 50 % training , 25 % validation , and 25 % test sets used to fit the models and test our output map . We evaluate and compare the performance of single- and multi- headed Long Short-Term Memory ( LSTM ) neural network classifiers , a Random Forest classifier , and three existing 10 m resolution global land cover maps ( Google ’ s Dynamic World , ESRI ’ s Land Cover , and ESA ’ s WorldCover ) on our proposed test set . Given the regional variations in cropland appearance , we additionally experimented with excluding or sub-setting the global crowd-sourced Geowiki cropland dataset , to empirically assess the trade-off between data quantity and data quality in terms of the similarity to the target data distribution of Nigeria . We find that the existing WorldCover map performs the best with an F1-score of 0.825 and accuracy of 0.870 on the test set , followed by a single-headed LSTM model trained with our hand-labeled training samples and the Geowiki data points in Nigeria , with a F1-score of 0.814 and accuracy of 0.842 . The code , data and output map generated with the best LSTM model are made available to the public to support research aiming to improve climate mitigation strategies , agricultural monitoring , and food security assessments . Keywords Deep Learning , Agriculture , Satellite Images , Time Series , Transfer Learning , Large-scale mapping , Sentinel 1 Introduction Agricultural maps are relevant for a variety of downstream applications ranging from policy making , early-warning systems for food security , and agricultural extension services [ 1 ] . The availability of free , granular , and high-cadence data from remote sensing sources like Sentinel-1 and 2 satellites has enabled the creation of detailed land cover and crop maps on a global scale [ 2 ] . Machine Learning ( ML ) is a widely employed methodology for generating these maps , given its capacity to process and extract useful information from large and diverse amounts of data , thereby aiding decision-making in agriculture [ 3 ] . Supervised machine learning , which requires high quality ground-truth data , has been applied extensively for generating crop maps all over the world [ 4 , 5 , 6 ] . Governments in High-Income Countries ( HIC ) regularly collect detailed information from farmers , including farm boundaries and crop types . This wealth of data has fueled research on generating accurate and high-resolution cropland , crop type and crop yield maps in regions like USA and Europe [ 4 , 5 , 7 ] . However , generating maps in countries where ground truth data is limited poses significant challenges . This data is time- and resource-consuming to collect , yet it is essential for validating the generated maps and for training the models to create them . As a mitigation strategy , one could attempt to leverage existing geo-referenced data related to cropland or crop type presence from other regions our countries to enhance the models performance . However , cropland data from different regions may present severe data distribution shifts associated with climate conditions , diverse agricultural practices , and the types of crops planted . Therefore , leveraging globally distributed data to generate agricultural maps in specific regions is not straight-forward and requires the use of different transfer learning strategies . Studies such as [ 6 , 8 ] created cropland maps for Togo and Kenya leveraging global and local hand-labelled cropland samples by using a multi-task learning approach with an LSTM model . Other works have attempted to tackle the problem from a meta-learning approach [ 9 , 10 ] or from a representation learning perspective using transformer models [ 11 ] . In this study , we focus on cropland mapping , framing it as a crop versus non-crop binary classification problem . We train ML models to provide a probability score of a given pixel being crop ( positive class ) given a multi-temporal array of pixel-wise data from different sensors ( e.g . satellites images ) . Acquiring cropland ground-truth data , although a time-consuming endeavour that demands specialized expertise , can be achieved remotely by labeling high-resolution satellite or airborne image pixels through photo-interpretation [ 6 ] . Therefore , it is feasible to collect a minimal validation data set that allows for the creation and validation of cropland maps in new regions . In this work , we specifically aim to produce a cropland map for Nigeria using Sentinel data at a 10 m resolution for the year 2020 , in order to support agricultural applications in the region . Nigeria stands as one of the leading food producers in Africa , with a population that accounts for about half of West-African population [ 12 ] . However , it currently lacks a cropland map at this level of spatial resolution . Given its significant agricultural importance for the region , we generate a small dataset of hand-labelled data for Nigeria to validate newly produced maps and to complement the training of different models to generate them . To this end , we investigate the usefulness of the global crowd-sourced Geowiki cropland dataset [ 13 ] together with our Nigeria dataset , by assessing and comparing an LSTM model and a Random Forest baseline . We provide the models with multi-temporal input data from Sentinel-1 and Sentinel-2 missions , complemented by local climate and topographic information ( details in Section 2.1 ) . For the LSTM , we explore standard and multi-task learning settings [ 6 , 8 ] . Furthermore , we explore different dataset configurations such as sub-setting Geowiki to points within Nigeria or in neighbouring countries and compare our results to three 10 m resolution global land cover maps of the same year , which are briefly described in Section 3.2 . 2 Data 2.1 Remote sensing data Sentinel-1 and Sentinel-2 satellites from ESA ’ s Copernicus program provide data at ground sample distance ( GSD ) ranging from 10 to 60 m with frequent revisit time of 5 days world-wide , which is the best resolution freely available . Sentinel-2 captures multispectral data on bands ranging from visible and near-infrared ( GSD of 10 m ) to short-wave infrared ( 20 m to 60 m GSD ) , which are useful for vegetation monitoring and crop detection , by measuring how plants reflect different wavelengths [ 14 ] . On the other hand , Sentinel-1 contains a Synthetic Aperture Radar ( SAR ) sensor , which measures actively emitted radio wave signals in two polarization modes , as reflected by the surface . This data is useful for detecting traits related to surface roughness such as crop height , growth stage and soil moisture content [ 15 ] . We also include pixel-wise data of monthly total precipitation , monthly average temperature at 2 metres above the ground from ERA5 Climate Reanalysis Meteorological data [ 16 ] , as well as elevation and slope derived from the Shuttle Radar Topography Mission ’ s ( SRTM ) Digital Elevation Model ( DEM ) [ 17 ] . The data was collected using the CropHarvest Python package [ 18 ] and Google Earth Engine [ 19 ] to produce a monthly per-pixel data array ( i.e . each pixels is characterised by 12 values for each parameter considered ) for a requested year . All Sentinel-2 bands are used and up-sampled to 10 m resolution except the B1 and B10 , which have a coarse 60 m resolution and are predominantly meant for coastal aerosols and cirrus detection . Least-cloudy monthly composites of Sentinel-2 Level-1C images are obtained using an algorithm from [ 20 ] . Additionally , the Normalized Difference Vegetation Index ( NDVI = N IR−R N IR+R ) , derived from Sentinel-2 red ( B4 ) and near-infrared ( B8 ) bands , is also added given its value for assessing vegetation health and growth [ 21 ] . Thus , the output datasets contain modified Copernicus Sentinel data , ERA5 , and SRTM data as processed by [ 18 ] , yielding samples that are 18-dimensional arrays of features 2 at 12 different monthly time steps , counting backwards from the respective label collection date . The 18 considered features are summarized on Table 1 . Table 1 : Data features used in this study . All features were collected using the CropHarvest Python package [ 18 ] . Feature group Feature descriptions Feature count Data Type Source Sentinel-1 Sentinel-2 VV polarization mode VH polarization mode Visible bands ( RGB ) Visible and Near Infrared bands ( VNIR ) Short Wave Infrared bands ( SWIR ) NDVI Climate Monthly average precipitation Monthly average temperature Topological Elevation Slope 1 1 3 5 3 1 1 1 1 1 Dynamic Dynamic Dynamic Dynamic Dynamic Dynamic Dynamic Dynamic Static Static Sentinel-1 Sentinel-1 Sentinel-2 Sentinel-2 Sentinel-2 Sentinel-2 ERA5 [ 16 ] ERA5 [ 16 ] SRTM [ 17 ] SRTM [ 17 ] 2.2 Cropland labels These data refers to manually annotated ground-truth spatial coordinates indicating the presence ( or absence ) of visible cropland at a specific time . Each data point includes latitude and longitude coordinates , a reference date , and a label indicating whether it represents cropland ( 1 ) or non-cropland ( 0 ) . These coordinates and the reference date are used to retrieve the corresponding remote sensing data . 2.2.1 Geowiki dataset The Geowiki dataset consists of crowd-sourced points of cropland and non-cropland points sampled around the world [ 13 ] . The original dataset consists of roughly 36,000 points , each associated with a cropland probability score , which is the average of the labels provided by several human annotators . The Geowiki dataset is also readily available with the CropHavest package [ 18 ] . The data arrays cover September 2016 to September 2017 , and match the labels ’ collection date , to avoid mismatches due to possible land cover changes . The average label is transformed into 0 ( non-cropland ) or 1 ( cropland ) using a crop probability threshold of 0.5 . In addition , we experiment with two subsets of this dataset : Geowiki Nigeria and Geowiki Neighbours . The number of points and class distribution for the full dataset and its subsets are described below : • Geowiki World : contains all Geowiki dataset samples available in the CropHarvest package . The total number of collected samples are only 24761 , presumably due to the input data availability , and out of which 13980 are labelled as cropland and 10781 labelled as non-cropland . • Geowiki Nigeria : this subset includes all Geowiki samples available in the CropHarvest package that fall within Nigeria boundaries . They amount to 452 samples , out of which 312 are cropland and 140 are non-cropland samples . • Geowiki Neighbours : this subset includes Geowiki Nigeria and all Geowiki samples available in the CropHar- vest package that fall within the boundaries of the following countries close to Nigeria : Ghana , Togo , Benin , and Cameroon . This choice of countries was due to data availability and sharing of agro-ecological zones . Together they amount to 790 samples , from which 460 are cropland and 330 are non-cropland . The Geowiki datasets described above are randomly split into 80 % training and 20 % validation data for the models . 2.2.2 Nigeria dataset A dataset of evenly distributed points within Nigeria was generated and labelled as cropland or non-cropland via photo-interpretation . Spatial coordinates were randomly sampled within the country , until 2000 points spaced by least 15 km were obtained . Each point was examined using very high-resolution Google Satellite Imagery Basemap ( which is mostly derived from Maxar ’ s 30 cm GSD mosaics ) from 2020 in Google Earth Pro and labelled by an expert as cropland ( 1 ) or non-cropland ( 0 ) using QGIS . We consider cropland as arable land ( cultivated or fallow ) and areas where permanent ( perennial ) crops are grown , including orchards [ 22 ] . 1827 points were labelled and the remaining discarded as the class could not be determined by the human annotator from the available reference imagery . We note 3 Figure 1 : Geographical distribution of the 1827 points of the generated Nigeria dataset and its assigned splits for model training and evaluation . Nigeria state boundaries are taken from [ 23 ] . that given our constraint on the number of annotators and the remote labeling process , some labels may contain errors , particularly in regions affected by water scarcity , where distinguishing between fallow or wasteland was challenging . The dataset was then split into 50 % train , 25 % validation and 25 % test sets using a stratified random sampling strategy , whereby each point within the validation and test sets were at least 30 km apart from each other . Using a stratified random splits covering the whole country is important to guarantee the quality of the output map at identifying cropland under the different climate and vegetation types found in the country , in a spatially homogeneous manner . The resulting splits are depicted in Figure 1 . The coordinates of these points were used to query the respective pixel-wise data arrays from March 2019 - March 2020 using the CropHarvest package . The final dataset consists of 1822 data samples with a class distribution per split described in Table 2 . Table 2 : Class distribution of Nigeria dataset . The cropland ratio refers to the proportion of points labelled as cropland in each data split . Data split Points Cropland ratio Train Validation Test Total 913 454 455 1822 0.417 0.399 0.402 0.409 2.3 Dataset combination We experiment with various combinations of the Geowiki dataset subsets , as described in Section 2.2.1 , and considered both including and excluding the Nigeria dataset for training . To normalize the data , we initially calculated per-channel means and standard deviations independently using their training and validation samples . When merging datasets , as in [ 6 ] , we combined all samples of the respective splits and calculated weighted per-channel means and standard 4 14 12 10 e d u t i t a L 8 6 4 Nigeria states 1 : Abia 2 : Adamawa 3 : Akwa Ibom 4 : Anambra 5 : Bauchi 6 : Bayelsa 7 : Benue 8 : Borno 9 : Cross River 10 : Delta 11 : Ebonyi 12 : Edo 13 : Ekiti 14 : Enugu 15 : Fed . Capital Territory 16 : Gombe 17 : Imo 18 : Jigawa 19 : Kaduna 20 : Kano 21 : Katsina 22 : Kebbi 23 : Kogi 24 : Kwara 25 : Lagos 26 : Nasarawa 27 : Niger 28 : Ogun 29 : Ondo 30 : Osun 31 : Oyo 32 : Plateau 33 : Rivers 34 : Sokoto 35 : Taraba 36 : Yobe 37 : Zamfara 0 2 4 34 37 22 27 13 23 29 24 30 31 28 25 21 19 18 36 20 8 5 16 32 2 15 26 35 7 9 train validation test 10 12 14 12 10 14 4 11 17 1 6 33 3 6 8 Longitude deviations based on the number of samples in each dataset relative to the total combined samples . Subsequently , we applied this per-channel mean and standard deviation normalization to all samples in any data split . 3 Methods 3.1 Models We followed [ 6 , 8 ] and experimented with two LSTM neural network architectures : a standard one [ 24 ] and a multi-task ( multi-head ) implementation [ 6 ] . LSTM networks , which are a type of Recurrent Neural Network ( RNN ) , excel in processing sequential data such as text or time series data . This makes them well-suited for crop classification tasks , as they can effectively capture temporal patterns and dependencies in remote sensing data [ 4 ] . The model is trained for binary classification of individual pixels . Each pixel in the input data is represented as a regularly sampled time series X = [ x1 , x2 , ... , x12 ] of 12 time steps of 18 dimensions each , i.e . xt ∈ R1×18 . The model can have either one or two identical classification heads each consisting of a Multilayer Perceptron ( MLP ) and a sigmoid activation function to normalize the last activation between 0 and 1 . This value can be interpreted as a posterior probability of cropland presence . When using the two classification heads , they both share the same LSTM backbone , but the global head classifies all the samples that are outside the boundaries of Nigeria and the local head classifies all samples that fall within Nigeria . This multi-headed architecture follows a multi-task learning approach [ 9 ] . In this setup , classifying global and local samples are treated as separate tasks handled by a dedicated head , but whereby they can leverage shared patterns learned by the LSTM backbone . The local head can then be used as a specialized classifier specialized for the region of interest . This architecture is trained by minimizing the loss function of Eq . ( 1 ) [ 6 ] , where Llocal and Lglobal are Binary Cross- Entropy ( BCE ) loss functions of the local and global classification heads respectively . W α is a weighting term , where W is the proportion of global to local labels in each batch and α is a weighting hyper-parameter . This weighting term reduces the impact of the global head in the overall loss function and thus its influence over the parameters updates of the shared LSTM backbone , effectively giving more relevance to the local classification task in the overall architecture . When using only one head , all the samples are treated equally ( no weighting ) . For this work , both Llocal and Lglobal BCE loss terms are additionally weighted according to the class distributions , as in Eq . ( 2 ) , to better account for class imbalance . In here , w ( 1 ) and w ( 0 ) respectively represent the inverse of the cropland and non-cropland instances proportion from the total amount of local or global labels , y is the label and ˆy is the model prediction . L = W α Lglobal + Llocal Li = − ( w ( 1 ) · y · log ( ˆy ) + w ( 0 ) · ( 1 − y ) · log ( 1 − ˆy ) ) ( 1 ) ( 2 ) All hyper-parameters were kept to default values from [ 6 ] . These include one hidden layer size of 64 units for the LSTM backbone , two classification layers on the MLPs , dropout of 0.2 between LSTM state updates and an α of 10 . We trained all models using the Adam optimizer [ 25 ] , with a learning rate of 0.001 , and a batch size of 64 , for a maximum of 100 epochs and early stopping with patience of 10 epochs on the validation set loss . A grid-search of { 32 , 64 , 128 } hidden units and { 1 , 2 } LSTM hidden layers on the validation set confirmed that these are robust hyper-parameters for our datasets . We refer the reader to [ 6 ] for further details and a schematic diagram of the model architecture . The deep learning models are implemented in PyTorch [ 26 ] . We also included a Random Forest baseline model from scikit-learn [ 27 ] default implementation ( 100 trees with bootstrapping on the full dataset ) , due to its robustness and widespread use for crop and land cover classification [ 28 ] . 3.2 Land cover maps We additionally compare our models to three global land cover maps of 2020 at 10 m resolution . These maps are Google ’ s Dynamic World [ 29 ] , ESRI ’ s 2020 Land Cover [ 30 ] and ESA ’ s WorldCover 2020 [ 31 ] . Dynamic World and ESRI Land Cover are two global land cover map produced with deep learning models , which were both trained using a dataset of 5 billion densely annotated patches of Sentinel-2 imagery distributed all over the world by experts and non-experts [ 2 ] . On the other hand , the global WorldCover map was produced with a Catboost model trained on pixels from 100 by 100 m patches of 141,000 locations around the world , which were labeled by experts [ 31 , 2 ] . Both WorldCover and ESRI LandCover maps are produced yearly and have only discrete pixel assignments to classes , while Dynamic World is updated in near-real time ( as new Sentinel-2 scenes become available approximately every 5 days ) 5 and also provides the probability for each pixel belonging to each of the possible classes . Another key difference is that WorldCover additionally uses Sentinel-1 , together with Sentinel-2 and other auxiliary data , as well as being digitized with a smaller Minimum Mapping Distance ( MMU ) of 100 m2 , compared to 250 m2 of the other two maps . While all maps are multi-class , we focus on the cropland class ( named `` crops '' in ESRI and Dynamic World maps ) , and converted the maps to a binary version by assigning all non-cropland pixel values to the negative class and all cropland pixels to the positive class . This was done in order to be able to evaluate the maps performance on our Nigeria test set . We note that the cropland class in these maps do not consider tree plantations , which are categorized under a `` trees '' class for all three maps . 3.3 Evaluation metrics We evaluated the models as well as the binarized land cover maps quantitatively by computing different performance metrics of their predictions on the Nigeria test set . The different metrics used are precision ( proportion of correct predictions ) , recall ( proportion of correctly identified samples or `` probability of detection '' ) , F1-score ( harmonic mean between precision and recall and thus a symmetric measure of both ) , total accuracy ( global proportion of correctly classified samples ) , and the Area Under the Receiver Operating Characteristic Curve ( AUC ROC ) . These metrics are all typically used in classification settings and AUC ROC is exclusively used in binary classification for evaluating the ability of a classifier to correctly distinguish between the positive and negative classes . For all metrics a higher value is better , however since achieving a perfect recall and precision simultaneously is not possible in practice , a higher F1-score reflects a better trade-off between the two . The equations for precision , recall , F1-score and total accuracy are given in Eqs . ( 3 ) , where TP , FP , FN , and TN are true positives , false positives , false negatives , and true negatives predictions , respectively . Note that for calculating the precision , recall , F1-score and total accuracy metrics , model prediction probabilities first need to be converted to binary predictions ( 0 or 1 ) by applying a threshold value . On the other hand , the AUC ROC score is calculated by computing the True Positive Rate ( TPR = recall ) and the False Positive Rate ( FPR = FP FP+TN , or `` probability of false alarm '' ) at different thresholds values to build the ROC and then calculating the area under this curve . The scikit-learn Python package was used for calculating all metrics [ 27 ] . Precision = Recall = F1-score = Total Accuracy = TP TP + FP TP TP + FN 2 × Precision × Recall Precision + Recall TP + TN TP + FP + FN + TN ( 3 ) In this study , a threshold of 0.5 was used as in [ 6 ] , which is a sensible choice given there is no clear preference for a higher TPR or FPR in our cropland mapping use case ( also note that this threshold is only required for model performance evaluation and is not used in any way during model training ) . Alternatively , this threshold could be optimized on a held-out validation set , or according to a desired confidence on model predictions , but we did not consider this setting . 4 Results 4.1 Main experiments In this section we present the experimental results of the different models on the Nigeria test set , considering the different dataset configurations discussed in Section 2.3 . We also compared our results to the global land cover maps introduced in Section 3.2 as benchmarks . The results are summarized on Table 3 . We can observe that the WorldCover map performs exceptionally well , particularly in terms of F1-score and total accuracy , compared to any of the models or other land cover maps . However , we also note that its recall is overall lower than those of the models , highlighting the need for careful consideration of the metric based on specific use cases . Among the implemented models , the single-headed LSTM model when using the Nigeria dataset and the Geowiki Nigeria subset achieves the best performance . Overall , all models show substantial improvement when the Nigeria dataset is included for training . It can also be observed that the Geowiki dataset is also beneficial in this case , but only when one of its subsets its used rather than the full Geowiki World dataset . 6 Table 3 : Results on the test set . A threshold of 0.5 was applied on the predicted probability to binarize into labels . Best results per metric are in bold and second best are underlined . Map / Model Geowiki dataset Nigeria dataset AUC ROC Precision Recall F1-score Accuracy ESA WorldCover 2020 ESRI 2020 Dynamic World 2020 - - - Random Forest Single-headed LSTM Multi-headed LSTM × Nigeria Neighbours World Nigeria Neighbours World × Nigeria Neighbours World Nigeria Neighbours World Neighbours World Neighbours World - - - ✓ ✓ ✓ ✓ × × × ✓ ✓ ✓ ✓ × × × ✓ ✓ × × - - - 0.911 0.915 0.916 0.796 0.755 0.842 0.755 0.908 0.907 0.906 0.884 0.756 0.874 0.854 0.889 0.893 0.772 0.819 0.903 0.867 0.491 0.774 0.782 0.791 0.569 0.495 0.695 0.522 0.772 0.771 0.788 0.671 0.561 0.688 0.575 0.737 0.917 0.638 0.721 0.760 0.213 0.448 0.787 0.825 0.765 0.858 0.891 0.798 0.836 0.776 0.863 0.831 0.847 0.749 0.831 0.902 0.874 0.541 0.694 0.650 0.825 0.342 0.469 0.780 0.803 0.778 0.684 0.637 0.743 0.643 0.774 0.814 0.809 0.749 0.642 0.752 0.702 0.800 0.680 0.665 0.684 0.870 0.670 0.591 0.822 0.837 0.824 0.681 0.591 0.778 0.626 0.818 0.842 0.842 0.771 0.664 0.780 0.692 0.824 0.796 0.719 0.758 We can also observe that the best-performing Random Forest model is competitive to the best single-headed LSTM model and outperforms the multi-headed LSTM model . Nevertheless , the multi-headed LSTM model performs better than the Random Forest model when using the same Geowiki subset for training . Furthermore , the AUC ROC metric offer insights into model performance under different thresholds values , and we also depict the ROC curves for the two best models of each type ( based on total accuracy ) in Figure 2 . In here , we can see how the Random Forest model performs better at lower thresholds ( middle-right side of the curves ) , which can explain its higher AUC ROC scores compared to the other models . 4.2 Ablation experiments We conducted supplementary experiments by exclusively using the Sentinel-2 bands and by using only a regular BCE loss function for the LSTM models . The results for these experiments are presented on Table S1 and Table S2 , respectively , in the Supplementary Material . Including additional data from Sentinel-1 , climate and topography helps to significantly improve the results for all models under any dataset combination . However , it is interesting to note how the performance drop is most pronounced whenever Geowiki data is included , which might suggest that this additional features provide essential information for the models to identify the data distribution shifts . Furthermore , we also confirm that using a weighted BCE loss function improves the results from the single-headed LSTM models . However , its impact is particularly significant under dataset configurations that have a more pronounced class imbalance , such as when using the Geowiki Nigeria subset . 4.3 Nigeria cropland maps We use our best model , the single-headed LSTM trained with the Geowiki Nigeria subset the Nigeria dataset , to generate both binary and probabilistic cropland maps covering the entire extent of Nigeria for the year 2020 . The maps are presented on Figure 3 . The cropland probability map offers additional valuable insights that are not available with the discrete WorldCover land cover map . 5 Discussion From our quantitative results we see that with the given remote sensing data and labels , the Random Forest and LSTM models do not achieve better performance on our cropland test set of Nigeria compared to the WorldCover land cover 7 Figure 2 : Receiving Operator Curve on the test set for two best models ( regarding accuracy ) of each type . All models represented here use the Nigeria hand-labelled data . map . The three land cover maps evaluated also present drastic differences in performance . While WorldCover achieves an accuracy of 0.825 and F1-score of 0.870 , both ESRI and Dynamic World maps lag several percentage points behind . In [ 2 ] a comparative analysis about these three maps was performed for all land cover classes and they suggest that WorldCover is better suited for resolving smaller and more complex agricultural landscapes . They argue this might be due to its lower MMU of 100 m2 compared to 250 m2 of the other two maps , and that it was likely trained for pixel-wise classification rather than for semantic segmentation . Therefore , this map may be specially well suited for detecting cropland in regions where smallholder farming is predominant , which also implies identifying isolated pixels representing small plots of cropland . Among our assessed models , the best performing was the single-headed LSTM trained with the Geowiki Nigeria and Nigeria datasets , which achieved a total accuracy of 0.842 and an F1-score of 0.814 , and was used for creating our Nigeria cropland maps . This performance is on pair with a Kenya cropland map ( 0.86 total accuracy and 0.84 F1-score ) [ 8 ] and a Togo cropland map ( 0.83 total accuracy and 0.74 F1-score ) [ 6 ] , that were recently generated with a similar approach . Regarding the other models , we observe interesting results under the different combinations of datasets used for training . We learn that while including our local labels improves performance in all cases , it is also possible to train a good classifier using only labels from Geowiki , notably when using the Geowiki Neighbours subset . For this configuration , the single-headed LSTM model achieves a F1-score and accuracy greater than 0.75 . Additionally , the multi-headed LSTM model is the only model where , when excluding the Nigeria dataset for training , using all of the Geowiki samples actually improves performance compared to using only a subset of Geowiki . This suggests that at least under certain cases , such as the absence of local labels for training , clever transfer learning techniques can indeed yield better results , compared to just combining all available data . The latter approach may in fact cause the resulting training data distribution to diverge significantly from that of the target country and dataset . The advent of Sentinel satellite data has allowed for the creation of land cover , cropland and even crop yield maps at 10 m resolution , thus enabling the detection of smallholder farming and facilitating comprehensive agricultural monitoring at national scales [ 32 ] . In light of this progress , our study examines cropland mapping in Nigeria , comparing custom machine learning models trained for this task and recent global land cover maps at 10 m resolution . While we found that having enough local training data leads to improved results for custom models , the WorldCover land cover map is a robust choice for cropland mapping in Nigeria . Therefore , although there has been recent work in evaluating the accuracy of land cover maps for mapping agricultural land [ 33 ] , there is a need for a systematic comparative assessment between these maps and those produced with custom , country-specific models for cropland classification such as those evaluated in this work . Further research could help practitioners and local governments to discern when relying on 8 e t a r e v i t i s o p e u r T 1.0 0.8 0.6 0.4 0.2 0.0 Single-headed LSTM ( Geowiki Nigeria ) Single-headed LSTM ( Geowiki neighbours ) Multi-headed LSTM ( Geowiki neighbours ) Multi-headed LSTM ( Geowiki world ) Random Forest ( Geowiki Nigeria ) Random Forest ( Geowiki neighbours ) random 0.0 0.2 0.4 0.6 False positive rate 0.8 1.0 Figure 3 : Binary ( with a threshold of 0.5 ) and probability cropland maps for Nigeria in 2020 ( A and B , respectively ) , generated with our the best model ( single-headed LSTM model trained with Nigeria dataset and Geowiki Nigeria subset dataset ) . Figure 1 for the state names . Missing data within the country is shown in white . 9 14 A Nigeria 2020 cropland binary map N 12 10 e d u t i t a L 8 6 4 200 km 4 6 cropland non-cropland 8 Longitude 10 12 14 Nigeria 2020 cropland probability map 14 B N 12 10 e d u t i t a L 8 6 4 200 km 4 6 8 Longitude 10 12 14 y t i l i b a b o r p l d n a p o r C 0.8 0.6 0.4 0.2 0.0 existing land cover maps suffices for their agricultural needs and when it is judicious to allocate resources for data collection and the development of croplands maps tailored to their specific requirements . 6 Conclusion Up-to-date and accurate cropland maps provide fundamental information for many agricultural applications and are a critical tool for rapidly assessing the effects of climate change on food security at large-scales . In this work we developed two cropland maps for Nigeria in 2020 at 10 m resolution using deep learning and time series of remote sensing data . To this end , we created a dataset of uniformly-distributed points around the country and labelled them as cropland or non-cropland via photo-interpretation . We used this dataset for training and validation of a single- and multi-headed LSTM network and compared them to a random forest model and three global land cover maps . We investigated the benefit of combining our training data with different subsets of the Geowiki dataset , a large global dataset of cropland points . We found that the WorldCover land cover map has the best performance on our test set compared to all other maps and models . The best performing model was the single-headed LSTM model , obtained when combining our new training labels with the subset of points of the Geowiki dataset contained within Nigeria ’ s border . We observed that except in cases where the local manually labeled data were not provided to the model , using all of Geowiki labels is always detrimental for the model unless we use a dedicated transfer learning architecture such as a multi-headed LSTM classifier . However , we find that including training labels from Geowiki on countries close to the target country may complement and boost the performance of the model compared to using only labels from the country . Although collecting more training labels , either on-site or remotely , would generally lead to better results , the WorldCover land cover map proves to be a robust alternative for identifying cropland in Nigeria . This result is particularly relevant in cases where there is a lack of training labels available in the target region and insufficient resources for their collection . Nevertheless , land cover maps are generally static in time , whereas cropland maps can be generated by researchers or governments at any time , thus we consider that studying how to best leverage the available ground-truth data to be an important research topic for providing timely and accurate cropland extent information . Data and code availability The source code , as well as the links to download the data and output maps , are publicly available in the following repository : https : . The maps can be visualized interactively with the following Google Earth Engine script ( account needed ) : https : Acknowledgments This work was funded partially by the data.org Inclusive Growth and Recovery Challenge grant “ Your Virtual Cold Chain Assistant ” , supported by The Rockefeller Foundation and the Mastercard Center for Inclusive Growth , as well as by the project “ Scaling up Your Virtual Cold Chain Assistant ” commissioned by the German Federal Ministry for Economic Cooperation and Development and being implemented by BASE and Empa on behalf of the German Agency for International Cooperation ( GIZ ) . The funders were not involved in the study design , collection , analysis , interpretation of data , the writing of this article , or the decision to submit it for publication . References [ 1 ] Inbal Becker-Reshef , Brian Barker , Alyssa Whitcraft , Patricia Oliva , Kara Mobley , Christina Justice , and Ritvik Sahajpal . Crop Type Maps for Operational Global Agricultural Monitoring . Scientific Data , 10 ( 1 ) :172 , March 2023 . [ 2 ] Zander S. Venter , David N. Barton , Tirthankar Chakraborty , Trond Simensen , and Geethen Singh . Global 10 m land use land cover datasets : A comparison of dynamic world , world cover and esri land cover . Remote Sensing , 14 ( 16 ) , 2022 . [ 3 ] Dashuai Wang , Wujing Cao , Fan Zhang , Zhuolin Li , Sheng Xu , and Xinyu Wu . A Review of Deep Learning in Multiscale Agricultural Sensing . Remote Sensing , 14 ( 3 ) :559 , January 2022 . [ 4 ] Marc RuBwurm and Marco Korner . Temporal Vegetation Modelling Using Long Short-Term Memory Networks for Crop Identification from Medium-Resolution Multi-spectral Satellite Images . In 2017 IEEE Conference on 10 Computer Vision and Pattern Recognition Workshops ( CVPRW ) , pages 1496–1504 , Honolulu , HI , USA , July 2017 . IEEE . [ 5 ] Mehmet Ozgur Turkoglu , Stefano D ’ Aronco , Gregor Perich , Frank Liebisch , Constantin Streit , Konrad Schindler , and Jan Dirk Wegner . Crop mapping from image time series : Deep learning with multi-scale label hierarchies . Remote Sensing of Environment , 264:112603 , October 2021 . [ 6 ] Hannah Kerner , Gabriel Tseng , Inbal Becker-Reshef , Catherine Nakalembe , Brian Barker , Blake Munshell , Madhava Paliyam , and Mehdi Hosseini . Rapid response crop maps in data sparse regions , 2020 . [ 7 ] Gregor Perich , Mehmet Ozgur Turkoglu , Lukas Valentin Graf , Jan Dirk Wegner , Helge Aasen , Achim Walter , and Frank Liebisch . Pixel-based yield mapping and prediction from sentinel-2 using spectral indices and neural networks . Field Crops Research , 292:108824 , 2023 . [ 8 ] Tseng , Gabriel , Kerner , Hannah , Nakalembe , Catherine , and Becker-Reshef , Inbal . Annual and in-season mapping of cropland at field scale with sparse labels , November 2020 . Type : dataset . [ 9 ] Gabriel Tseng , Hannah Kerner , Catherine Nakalembe , and Inbal Becker-Reshef . Learning to predict crop type from heterogeneous sparse labels using meta-learning . In 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops ( CVPRW ) , pages 1111–1120 , Nashville , TN , USA , June 2021 . IEEE . [ 10 ] Gabriel Tseng , Hannah Kerner , and David Rolnick . Timl : Task-informed meta-learning for agriculture , 2022 . [ 11 ] Gabriel Tseng , Ivan Zvonkov , Mirali Purohit , David Rolnick , and Hannah Kerner . Lightweight , pre-trained transformers for remote sensing timeseries , 2023 . [ 12 ] Daniel Onwude , Thomas Motmans , Kanaha Shoji , Roberta Evangelista , Joaquin Gajardo , Divinefavor Odion , Nnaemeka Ikegwuonu , Olubayo Adekanmbi , Soufiane Hourri , and Thijs Defraeye . Bottlenecks in nigeria ’ s fresh food supply chain : What is the way forward ? Trends in Food Science & Technology , 137:55–62 , 2023 . [ 13 ] Juan Carlos Laso Bayas , Myroslava Lesiv , François Waldner , Anne Schucknecht , Martina Duerauer , Linda See , Steffen Fritz , Dilek Fraisl , Inian Moorthy , Ian McCallum , Christoph Perger , Olha Danylo , Pierre Defourny , Javier Gallego , Sven Gilliams , Ibrar ul Hassan Akhtar , Swarup Jyoti Baishya , Mrinal Baruah , Khangsembou Bungnamei , Alfredo Campos , Trishna Changkakati , Anna Cipriani , Krishna Das , Keemee Das , Inamani Das , Kyle Frankel Davis , Purabi Hazarika , Brian Alan Johnson , Ziga Malek , Monia Elisa Molinari , Kripal Panging , Chandra Kant Pawe , Ana Pérez-Hoyos , Parag Kumar Sahariah , Dhrubajyoti Sahariah , Anup Saikia , Meghna Saikia , Peter Schlesinger , Elena Seidacaru , Kuleswar Singha , and John W Wilson . A global reference database of crowdsourced cropland data collected using the Geo-Wiki platform . Scientific Data , 4 ( 1 ) :170136 , September 2017 . [ 14 ] Francesco Vuolo , Martin Neuwirth , Markus Immitzer , Clement Atzberger , and Wai-Tim Ng . How much does multi- temporal sentinel-2 data improve crop type classification ? International Journal of Applied Earth Observation and Geoinformation , 72:122–130 , 2018 . [ 15 ] Zheng Sun , Di Wang , and Geji Zhong . A review of crop classification using satellite-based polarimetric sar imagery . In 2018 7th International Conference on Agro-geoinformatics ( Agro-geoinformatics ) , pages 1–5 , 2018 . [ 16 ] Hans Hersbach , Bill Bell , Paul Berrisford , Shoji Hirahara , András Horányi , Joaquín Muñoz-Sabater , Julien Nicolas , Carole Peubey , Raluca Radu , Dinand Schepers , Adrian Simmons , Cornel Soci , Saleh Abdalla , Xavier Abellan , Gianpaolo Balsamo , Peter Bechtold , Gionata Biavati , Jean Bidlot , Massimo Bonavita , Giovanna De Chiara , Per Dahlgren , Dick Dee , Michail Diamantakis , Rossana Dragani , Johannes Flemming , Richard Forbes , Manuel Fuentes , Alan Geer , Leo Haimberger , Sean Healy , Robin J. Hogan , Elías Hólm , Marta Janisková , Sarah Keeley , Patrick Laloyaux , Philippe Lopez , Cristina Lupu , Gabor Radnoti , Patricia de Rosnay , Iryna Rozum , Freja Vamborg , Sebastien Villaume , and Jean-Noël Thépaut . The era5 global reanalysis . Quarterly Journal of the Royal Meteorological Society , 146 ( 730 ) :1999–2049 , 2020 . [ 17 ] Tom G. Farr , Paul A. Rosen , Edward Caro , Robert Crippen , Riley Duren , Scott Hensley , Michael Kobrick , Mimi Paller , Ernesto Rodriguez , Ladislav Roth , David Seal , Scott Shaffer , Joanne Shimada , Jeffrey Umland , Marian Werner , Michael Oskin , Douglas Burbank , and Douglas Alsdorf . The shuttle radar topography mission . Reviews of Geophysics , 45 ( 2 ) , 2007 . [ 18 ] Gabriel Tseng , Ivan Zvonkov , Catherine Lilian Nakalembe , and Hannah Kerner . Cropharvest : A global dataset for crop-type classification . In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track ( Round 2 ) , 2021 . [ 19 ] Noel Gorelick , Matt Hancher , Mike Dixon , Simon Ilyushchenko , David Thau , and Rebecca Moore . Google earth engine : Planetary-scale geospatial analysis for everyone . Remote Sensing of Environment , 202:18–27 , 2017 . Big Remotely Sensed Data : tools , applications and experiences . 11 [ 20 ] M. Schmitt , L. H. Hughes , C. Qiu , and X. X. Zhu . AGGREGATING CLOUD-FREE SENTINEL-2 IMAGES WITH GOOGLE EARTH ENGINE . ISPRS Annals of the Photogrammetry , Remote Sensing and Spatial Informa- tion Sciences , IV-2/W7:145–152 , September 2019 . [ 21 ] Rei Sonobe , Yuki Yamaya , Hiroshi Tani , Xiufeng Wang , Nobuyuki Kobayashi , and Kan ichiro Mochizuki . Crop classification from Sentinel-2-derived vegetation indices using ensemble learning . Journal of Applied Remote Sensing , 12 ( 2 ) :026019 , 2018 . [ 22 ] A Markandya . Water and the Rural Poor : Interventions for Improving Livelihoods in sub-Saharan Africa . FAO , 2008 . [ 23 ] The Humanitarian Data Exchange ( HDX ) . Nigeria - administrative boundaries . https : //datacatalog . , 2017 . Accessed : 2023-10-01 . [ 24 ] Sepp Hochreiter and Jürgen Schmidhuber . Long short-term memory . Neural Computation , 9 ( 8 ) :1735–1780 , 1997 . [ 25 ] Diederik P. Kingma and Jimmy Ba . Adam : A method for stochastic optimization , 2017 . [ 26 ] Adam Paszke , Sam Gross , Francisco Massa , Adam Lerer , James Bradbury , Gregory Chanan , Trevor Killeen , Zeming Lin , Natalia Gimelshein , Luca Antiga , Alban Desmaison , Andreas Kopf , Edward Yang , Zachary DeVito , Martin Raison , Alykhan Tejani , Sasank Chilamkurthy , Benoit Steiner , Lu Fang , Junjie Bai , and Soumith Chintala . In Advances in Neural Information Pytorch : An imperative style , high-performance deep learning library . Processing Systems 32 , pages 8024–8035 . Curran Associates , Inc. , 2019 . [ 27 ] F. Pedregosa , G. Varoquaux , A. Gramfort , V. Michel , B. Thirion , O. Grisel , M. Blondel , P. Prettenhofer , R. Weiss , V. Dubourg , J. Vanderplas , A. Passos , D. Cournapeau , M. Brucher , M. Perrot , and E. Duchesnay . Scikit-learn : Machine learning in Python . Journal of Machine Learning Research , 12:2825–2830 , 2011 . [ 28 ] Charlotte Pelletier , Silvia Valero , Jordi Inglada , Nicolas Champion , and Gérard Dedieu . Assessing the robustness of random forests to map land cover with high resolution satellite image time series over large areas . Remote Sensing of Environment , 187:156–168 , 2016 . [ 29 ] Christopher F. Brown , Steven P. Brumby , Brookie Guzder-Williams , Tanya Birch , Samantha Brooks Hyde , Joseph Mazzariello , Wanda Czerwinski , Valerie J. Pasquarella , Robert Haertel , Simon Ilyushchenko , Kurt Schwehr , Mikaela Weisse , Fred Stolle , Craig Hanson , Oliver Guinan , Rebecca Moore , and Alexander M. Tait . Dynamic World , Near real-time global 10 m land use land cover mapping . Scientific Data , 9 ( 1 ) :251 , June 2022 . [ 30 ] Krishna Karra , Caitlin Kontgis , Zoe Statman-Weil , Joseph C. Mazzariello , Mark Mathis , and Steven P. Brumby . Global land use / land cover with Sentinel 2 and deep learning . In 2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS , pages 4704–4707 , Brussels , Belgium , July 2021 . IEEE . [ 31 ] Daniele Zanaga , Ruben Van De Kerchove , Wanda De Keersmaecker , Niels Souverijns , Carsten Brockmann , Ralf Quast , Jan Wevers , Alex Grosu , Audrey Paccini , Sylvain Vergnaud , Oliver Cartus , Maurizio Santoro , Steffen Fritz , Ivelina Georgieva , Myroslava Lesiv , Sarah Carter , Martin Herold , Linlin Li , Nandin-Erdene Tsendbazar , Fabrizio Ramoino , and Olivier Arino . Esa worldcover 10 m 2020 v100 , October 2021 . [ 32 ] Zhenong Jin , George Azzari , Calum You , Stefania Di Tommaso , Stephen Aston , Marshall Burke , and David B. Lobell . Smallholder maize area and yield mapping at national scales with google earth engine . Remote Sensing of Environment , 228:115–128 , 2019 . [ 33 ] Hannah Kerner , Catherine Nakalembe , Adam Yang , Ivan Zvonkov , Ryan McWeeny , Gabriel Tseng , and Inbal Becker-Reshef . How accurate are existing land cover maps for agriculture in sub-saharan africa ? , 2023 . 12 7 Supplementary Material Table S1 : Results comparison on the test set with only using Sentinel-2 bands and NDVI for training . A threshold of 0.5 was applied on the predicted probability to binarize into labels . Best results per metric are in bold and second best are underlined . Model Geowiki dataset Nigeria dataset AUC ROC Precision Recall F1-score Accuracy Random Forest Single-headed LSTM Multi-headed LSTM × Nigeria Neighbours World Nigeria Neighbours World × Nigeria Neighbours World Nigeria Neighbours World Neighbours World Neighbours World ✓ ✓ ✓ ✓ × × × ✓ ✓ ✓ ✓ × × × ✓ ✓ × × 0.880 0.887 0.887 0.722 0.606 0.778 0.691 0.886 0.869 0.870 0.750 0.658 0.810 0.804 0.884 0.847 0.808 0.600 0.749 0.755 0.764 0.587 0.471 0.723 0.530 0.730 0.781 0.733 0.584 0.667 0.681 0.608 0.810 0.780 0.702 0.600 0.765 0.809 0.743 0.667 0.574 0.470 0.732 0.814 0.645 0.689 0.683 0.284 0.607 0.863 0.650 0.601 0.475 0.050 0.757 0.781 0.753 0.624 0.517 0.570 0.615 0.770 0.707 0.710 0.630 0.398 0.642 0.713 0.721 0.679 0.567 0.091 0.802 0.818 0.804 0.677 0.569 0.714 0.631 0.804 0.785 0.774 0.677 0.655 0.727 0.721 0.798 0.771 0.708 0.604 Table S2 : Results of LSTM model on test set without using a weighted BCE loss . A threshold of 0.5 was applied on the predicted probability to binarize into labels . Best results per metric are in bold and second best are underlined . Model Geowiki dataset Nigeria dataset AUC ROC Precision Recall F1-score Accuracy Single-headed LSTM Multi-headed LSTM × Nigeria Neighbours World Nigeria Neighbours World Neighbours World Neighbours World ✓ ✓ ✓ ✓ × × × ✓ ✓ × × 0.907 0.907 0.905 0.868 0.785 0.872 0.846 0.890 0.892 0.827 0.814 0.797 0.764 0.791 0.704 0.497 0.632 0.538 0.743 0.920 0.591 0.723 0.749 0.847 0.809 0.792 0.874 0.918 0.929 0.869 0.437 0.831 0.628 0.772 0.803 0.800 0.746 0.633 0.748 0.681 0.801 0.593 0.691 0.673 0.822 0.833 0.837 0.782 0.593 0.752 0.651 0.826 0.758 0.701 0.754 13","['c', 'e', 'v', 'c', 'c', 'v', 'r', 'countryscale', 'cropland', 'mapping', 'datascarce', 'setting', 'use', 'deep', 'learning', 'case', 'study', 'onwude1', 'defraeye13', 'swiss', 'federal', 'laboratory', 'material', 'science', 'technology', 'laboratory', 'biomimetic', 'membrane', 'textile', 'switzerland', 'swiss', 'data', 'science', 'center', 'epfl', 'switzerland', 'quality', 'design', 'university', 'research', 'aa', 'agricultural', 'science', 'universitätstrasse', 'switzerland', 'corresponding', 'author', 'email', 'map', 'core', 'critical', 'component', 'remotesensingbase', 'agricultural', 'monitoring', 'map', 'provide', 'dense', 'uptodate', 'information', 'agricultural', 'development', 'require', 'regular', 'field', 'survey', 'particularly', 'challenge', 'execute', 'region', 'limited', 'accessibility', 'machine', 'learning', 'effective', 'tool', 'largescale', 'agricultural', 'mapping', 'rely', 'georeference', 'groundtruth', 'datum', 'model', 'training', 'testing', 'scarce', 'time', 'consume', 'obtain', 'study', 'explore', 'usefulness', 'combine', 'global', 'cropland', 'dataset', 'handlabele', 'dataset', 'train', 'machine', 'learning', 'model', 'generate', 'new', 'cropland', 'map', 'resolution', 'provide', 'model', 'pixelwise', 'time', 'series', 'input', 'datum', 'remote', 'sense', 'source', 'sentinel1', 'climate', 'datum', 'dem', 'datum', 'addition', 'binary', 'label', 'indicate', 'presence', 'manually', 'label', 'evenly', 'distribute', 'pixel', 'split', 'training', 'validation', 'test', 'set', 'use', 'fit', 'model', 'test', 'output', 'map', 'evaluate', 'compare', 'performance', 'single', 'head', 'long', 'memory', 'lstm', 'neural', 'network', 'classifier', 'random', 'forest', 'classifier', 'exist', 'resolution', 'global', 'land', 'cover', 'map', 'dynamic', 'world', 'esri', 'land', 'cover', 'worldcover', 'propose', 'test', 'set', 'give', 'regional', 'variation', 'appearance', 'additionally', 'experiment', 'exclude', 'subsette', 'global', 'crowdsource', 'dataset', 'empirically', 'assess', 'tradeoff', 'datum', 'quantity', 'datum', 'quality', 'term', 'similarity', 'target', 'data', 'distribution', 'find', 'exist', 'worldcover', 'map', 'perform', 'good', 'f1score', 'accuracy', 'test', 'set', 'follow', 'singleheaded', 'lstm', 'model', 'train', 'handlabele', 'training', 'sample', 'geowiki', 'datum', 'point', 'f1score', 'accuracy', 'code', 'datum', 'output', 'map', 'generate', 'good', 'lstm', 'model', 'make', 'available', 'public', 'support', 'research', 'aim', 'improve', 'climate', 'mitigation', 'strategy', 'agricultural', 'monitoring', 'food', 'security', 'assessment', 'keyword', 'deep', 'learn', 'agriculture', 'satellite', 'image', 'time', 'series', 'transfer', 'learn', 'largescale', 'mapping', 'sentinel', 'introduction', 'agricultural', 'map', 'relevant', 'variety', 'downstream', 'application', 'range', 'policy', 'making', 'earlywarne', 'system', 'food', 'security', 'agricultural', 'extension', 'service', 'availability', 'free', 'granular', 'highcadence', 'datum', 'remote', 'sense', 'source', 'sentinel1', 'satellite', 'enable', 'creation', 'detailed', 'land', 'cover', 'crop', 'map', 'global', 'scale', 'machine', 'learning', 'widely', 'employ', 'methodology', 'generate', 'map', 'give', 'capacity', 'process', 'extract', 'useful', 'information', 'large', 'diverse', 'amount', 'datum', 'thereby', 'aid', 'decisionmake', 'agriculture', 'supervise', 'machine', 'learning', 'require', 'high', 'quality', 'groundtruth', 'datum', 'apply', 'extensively', 'generate', 'crop', 'map', 'world', 'government', 'highincome', 'country', 'regularly', 'collect', 'detailed', 'information', 'farmer', 'include', 'farm', 'boundary', 'crop', 'type', 'wealth', 'datum', 'fuel', 'research', 'generate', 'accurate', 'highresolution', 'cropland', 'crop', 'type', 'crop', 'yield', 'map', 'region', 'however', 'generate', 'map', 'country', 'ground', 'truth', 'datum', 'limited', 'pose', 'significant', 'challenge', 'datum', 'time', 'resourceconsume', 'collect', 'yet', 'essential', 'validate', 'generate', 'map', 'train', 'model', 'create', 'mitigation', 'strategy', 'attempt', 'leverage', 'exist', 'georeference', 'datum', 'relate', 'cropland', 'crop', 'type', 'presence', 'region', 'country', 'enhance', 'model', 'performance', 'however', 'datum', 'different', 'region', 'present', 'severe', 'data', 'distribution', 'shift', 'associate', 'climate', 'condition', 'diverse', 'agricultural', 'practice', 'type', 'crop', 'plant', 'therefore', 'leverage', 'globally', 'distribute', 'datum', 'generate', 'agricultural', 'map', 'specific', 'region', 'straightforward', 'require', 'use', 'different', 'transfer', 'learning', 'strategy', 'study', 'create', 'cropland', 'map', 'leverage', 'global', 'local', 'handlabelled', 'cropland', 'sample', 'use', 'multitask', 'learn', 'approach', 'lstm', 'model', 'work', 'attempt', 'tackle', 'problem', 'metalearning', 'approach', 'representation', 'learning', 'perspective', 'use', 'transformer', 'model', 'study', 'focus', 'mapping', 'frame', 'crop', 'binary', 'classification', 'problem', 'train', 'ml', 'model', 'provide', 'probability', 'score', 'give', 'pixel', 'crop', 'positive', 'class', 'give', 'multitemporal', 'array', 'pixelwise', 'datum', 'different', 'sensor', 'satellite', 'image', 'acquire', 'groundtruth', 'datum', 'timeconsuming', 'endeavour', 'demand', 'specialized', 'expertise', 'achieve', 'remotely', 'label', 'highresolution', 'satellite', 'airborne', 'image', 'pixel', 'photointerpretation', 'therefore', 'feasible', 'collect', 'minimal', 'validation', 'datum', 'set', 'allow', 'creation', 'validation', 'map', 'new', 'region', 'work', 'specifically', 'aim', 'produce', 'cropland', 'map', 'nigeria', 'use', 'sentinel', 'datum', 'resolution', 'year', 'order', 'support', 'agricultural', 'application', 'region', 'stand', 'lead', 'food', 'producer', 'population', 'account', 'half', 'westafrican', 'population', 'however', 'currently', 'lack', 'cropland', 'map', 'level', 'spatial', 'resolution', 'give', 'significant', 'agricultural', 'importance', 'region', 'generate', 'small', 'dataset', 'handlabelled', 'datum', 'validate', 'newly', 'produce', 'map', 'complement', 'training', 'different', 'model', 'generate', 'end', 'investigate', 'usefulness', 'global', 'crowdsource', 'dataset', 'together', 'dataset', 'assess', 'compare', 'lstm', 'model', 'random', 'forest', 'baseline', 'provide', 'model', 'multitemporal', 'input', 'datum', 'sentinel1', 'sentinel2', 'mission', 'complement', 'local', 'climate', 'topographic', 'information', 'detail', 'section', 'lstm', 'explore', 'standard', 'multitask', 'learn', 'setting', 'furthermore', 'explore', 'different', 'dataset', 'configuration', 'subsette', 'geowiki', 'point', 'neighbouring', 'country', 'compare', 'result', 'resolution', 'global', 'land', 'cover', 'map', 'year', 'briefly', 'describe', 'section', 'datum', 'remote', 'sense', 'datum', 'sentinel1', 'sentinel2', 'satellite', 'copernicus', 'program', 'provide', 'datum', 'ground', 'sample', 'distance', 'gsd', 'range', 'frequent', 'revisit', 'time', 'day', 'worldwide', 'good', 'resolution', 'freely', 'available', 'sentinel2', 'capture', 'multispectral', 'datum', 'band', 'range', 'visible', 'nearinfrare', 'gsd', 'shortwave', 'infrare', 'gsd', 'useful', 'vegetation', 'monitoring', 'crop', 'detection', 'measure', 'plant', 'reflect', 'different', 'wavelength', 'hand', 'sentinel1', 'contain', 'synthetic', 'aperture', 'radar', 'sar', 'sensor', 'measure', 'actively', 'emit', 'radio', 'wave', 'signal', 'polarization', 'mode', 'reflect', 'surface', 'datum', 'useful', 'detect', 'trait', 'relate', 'surface', 'roughness', 'crop', 'height', 'growth', 'stage', 'soil', 'moisture', 'content', 'also', 'include', 'pixelwise', 'datum', 'monthly', 'total', 'precipitation', 'monthly', 'average', 'temperature', 'metre', 'ground', 'climate', 'reanalysis', 'meteorological', 'datum', 'well', 'elevation', 'slope', 'derive', 'shuttle', 'radar', 'topography', 'mission', 'srtm', 'digital', 'elevation', 'model', 'dem', 'datum', 'collect', 'use', 'cropharv', 'python', 'package', 'earth', 'engine', 'produce', 'monthly', 'perpixel', 'datum', 'array', 'pixel', 'characterise', 'value', 'parameter', 'consider', 'request', 'year', 'sentinel2', 'band', 'use', 'upsampled', 'resolution', 'b1', 'b10', 'coarse', 'resolution', 'predominantly', 'mean', 'coastal', 'aerosol', 'cirrus', 'detection', 'leastcloudy', 'monthly', 'composite', 'sentinel2', 'level1c', 'image', 'obtain', 'use', 'additionally', 'normalize', 'difference', 'vegetation', 'index', 'ir−r', 'irr', 'derive', 'sentinel2', 'red', 'b4', 'nearinfrare', 'band', 'also', 'add', 'give', 'value', 'assess', 'vegetation', 'health', 'growth', 'thus', 'output', 'dataset', 'contain', 'modify', 'copernicus', 'srtm', 'datum', 'process', 'yield', 'sample', 'array', 'feature', 'different', 'monthly', 'time', 'step', 'counting', 'backwards', 'respective', 'label', 'collection', 'date', 'consider', 'feature', 'summarize', 'table', 'table', 'datum', 'feature', 'use', 'study', 'feature', 'collect', 'use', 'cropharv', 'python', 'package', 'feature', 'group', 'feature', 'description', 'feature', 'count', 'datum', 'type', 'source', 'sentinel1', 'sentinel2', 'polarization', 'mode', 'vh', 'polarization', 'mode', 'visible', 'band', 'visible', 'infrared', 'band', 'vnir', 'short', 'wave', 'infrare', 'band', 'climate', 'monthly', 'average', 'precipitation', 'monthly', 'average', 'temperature', 'topological', 'elevation', 'slope', 'dynamic', 'dynamic', 'dynamic', 'dynamic', 'dynamic', 'dynamic', 'dynamic', 'dynamic', 'static', 'static', 'sentinel1', 'srtm', 'srtm', 'cropland', 'label', 'datum', 'refer', 'manually', 'annotate', 'groundtruth', 'spatial', 'coordinate', 'indicate', 'presence', 'absence', 'visible', 'cropland', 'specific', 'time', 'datum', 'point', 'include', 'latitude', 'longitude', 'coordinate', 'reference', 'date', 'label', 'indicate', 'represent', 'coordinate', 'reference', 'date', 'use', 'retrieve', 'corresponding', 'remote', 'sense', 'datum', 'geowiki', 'dataset', 'geowiki', 'dataset', 'consist', 'crowdsource', 'point', 'point', 'sample', 'world', 'original', 'dataset', 'consist', 'roughly', 'point', 'associate', 'cropland', 'probability', 'score', 'average', 'label', 'provide', 'several', 'human', 'annotator', 'geowiki', 'dataset', 'also', 'readily', 'available', 'crophav', 'package', 'datum', 'array', 'cover', 'match', 'label', 'collection', 'date', 'avoid', 'mismatch', 'possible', 'land', 'cover', 'change', 'average', 'label', 'transform', 'cropland', 'use', 'crop', 'probability', 'threshold', 'addition', 'experiment', 'subset', 'dataset', 'geowiki', 'geowiki', 'neighbour', 'number', 'point', 'class', 'distribution', 'full', 'dataset', 'subset', 'describe', 'geowiki', 'world', 'contain', 'geowiki', 'dataset', 'sample', 'available', 'cropharv', 'package', 'total', 'number', 'collect', 'sample', 'presumably', 'input', 'data', 'availability', 'label', 'label', 'subset', 'include', 'geowiki', 'sample', 'available', 'cropharv', 'package', 'fall', 'boundary', 'amount', 'sample', 'cropland', 'sample', 'geowiki', 'neighbour', 'subset', 'include', 'geowiki', 'sample', 'available', 'crophar', 'vest', 'package', 'fall', 'boundary', 'follow', 'country', 'close', 'benin', 'cameroon', 'choice', 'country', 'due', 'data', 'availability', 'sharing', 'agroecological', 'zone', 'together', 'amount', 'sample', 'cropland', 'geowiki', 'dataset', 'describe', 'randomly', 'split', 'training', 'validation', 'datum', 'model', 'nigeria', 'dataset', 'dataset', 'evenly', 'distribute', 'point', 'generate', 'label', 'photointerpretation', 'spatial', 'coordinate', 'randomly', 'sample', 'country', 'point', 'space', 'least', 'km', 'obtain', 'point', 'examine', 'use', 'highresolution', 'satellite', 'imagery', 'mostly', 'derive', 'cm', 'gsd', 'mosaic', 'pro', 'label', 'expert', 'use', 'qgis', 'consider', 'cropland', 'arable', 'land', 'cultivate', 'fallow', 'area', 'permanent', 'perennial', 'crop', 'grow', 'include', 'orchard', 'point', 'label', 'remain', 'discard', 'class', 'determine', 'human', 'annotator', 'available', 'reference', 'imagery', 'note', 'figure', 'geographical', 'distribution', 'point', 'generated', 'dataset', 'assign', 'split', 'model', 'training', 'evaluation', 'state', 'boundary', 'take', 'give', 'constraint', 'number', 'annotator', 'remote', 'labeling', 'process', 'label', 'contain', 'error', 'particularly', 'region', 'affect', 'water', 'scarcity', 'distinguish', 'fallow', 'wasteland', 'challenge', 'dataset', 'split', 'train', 'validation', 'test', 'set', 'use', 'stratified', 'random', 'sampling', 'strategy', 'point', 'validation', 'test', 'set', 'least', 'km', 'apart', 'use', 'stratified', 'random', 'split', 'cover', 'whole', 'country', 'important', 'guarantee', 'quality', 'output', 'map', 'identify', 'cropland', 'different', 'climate', 'vegetation', 'type', 'find', 'country', 'spatially', 'homogeneous', 'manner', 'result', 'split', 'depict', 'figure', 'coordinate', 'point', 'use', 'query', 'respective', 'pixelwise', 'datum', 'array', 'use', 'cropharv', 'package', 'final', 'dataset', 'consist', 'datum', 'sample', 'class', 'distribution', 'split', 'describe', 'table', 'table', 'class', 'distribution', 'dataset', 'cropland', 'ratio', 'refer', 'proportion', 'point', 'label', 'datum', 'split', 'datum', 'split', 'point', 'ratio', 'train', 'validation', 'test', 'total', 'dataset', 'combination', 'experiment', 'various', 'combination', 'geowiki', 'dataset', 'subset', 'describe', 'section', 'consider', 'include', 'exclude', 'dataset', 'training', 'normalize', 'datum', 'initially', 'calculate', 'perchannel', 'mean', 'standard', 'deviation', 'independently', 'use', 'training', 'validation', 'sample', 'merge', 'dataset', 'combine', 'sample', 'respective', 'split', 'calculate', 'weight', 'perchannel', 'mean', 'standard', 'e', 'u', 'l', 'nigeria', 'state', 'abia', 'ibom', 'anambra', 'bauchi', 'bayelsa', 'benue', 'borno', 'delta', 'enugu', 'feed', 'capital', 'territory', 'gombe', 'imo', 'kano', 'lago', 'niger', 'ogun', 'ondo', 'osun', 'oyo', 'plateau', 'river', 'sokoto', 'taraba', 'yobe', 'train', 'validation', 'test', 'longitude', 'deviation', 'base', 'number', 'sample', 'dataset', 'relative', 'total', 'combine', 'sample', 'subsequently', 'apply', 'perchannel', 'mean', 'standard', 'deviation', 'normalization', 'sample', 'datum', 'split', 'method', 'model', 'follow', 'experiment', 'neural', 'architecture', 'standard', 'multitask', 'multihead', 'implementation', 'lstm', 'network', 'type', 'recurrent', 'neural', 'network', 'excel', 'process', 'sequential', 'datum', 'text', 'time', 'series', 'datum', 'make', 'wellsuite', 'crop', 'classification', 'task', 'effectively', 'capture', 'temporal', 'pattern', 'dependency', 'remote', 'sense', 'datum', 'model', 'train', 'binary', 'classification', 'individual', 'pixel', 'pixel', 'input', 'datum', 'represent', 'regularly', 'sample', 'time', 'series', 'x12', 'time', 'step', 'dimension', 'model', 'identical', 'classification', 'head', 'consist', 'multilayer', 'mlp', 'sigmoid', 'activation', 'function', 'normalize', 'last', 'activation', 'value', 'interpret', 'posterior', 'probability', 'presence', 'use', 'classification', 'head', 'share', 'lstm', 'backbone', 'global', 'head', 'classify', 'sample', 'boundary', 'local', 'head', 'classifie', 'sample', 'fall', 'multiheade', 'architecture', 'follow', 'multitask', 'learn', 'approach', 'setup', 'classify', 'global', 'local', 'sample', 'treat', 'separate', 'task', 'handle', 'dedicated', 'head', 'leverage', 'share', 'pattern', 'learn', 'lstm', 'backbone', 'local', 'head', 'use', 'specialized', 'classifier', 'region', 'interest', 'architecture', 'train', 'minimize', 'loss', 'function', 'llocal', 'lglobal', 'bce', 'loss', 'function', 'local', 'global', 'classification', 'head', 'respectively', 'w', 'weighting', 'term', 'proportion', 'global', 'local', 'label', 'batch', 'weighting', 'hyperparameter', 'weighting', 'term', 'reduce', 'impact', 'global', 'head', 'overall', 'loss', 'function', 'thus', 'influence', 'parameter', 'update', 'share', 'lstm', 'backbone', 'effectively', 'give', 'relevance', 'local', 'classification', 'task', 'overall', 'architecture', 'use', 'head', 'sample', 'treat', 'equally', 'weighting', 'work', 'llocal', 'lglobal', 'bce', 'loss', 'term', 'additionally', 'weight', 'accord', 'class', 'distribution', 'well', 'account', 'class', 'imbalance', 'w', 'respectively', 'represent', 'inverse', 'instance', 'proportion', 'total', 'amount', 'local', 'global', 'label', 'label', 'ˆy', 'model', 'prediction', 'l', 'w', 'lglobal', 'llocal', 'w', 'log', 'ˆy', 'w', 'log', 'ˆy', 'hyperparameter', 'keep', 'default', 'value', 'include', 'hide', 'layer', 'size', 'unit', 'lstm', 'backbone', 'classification', 'layer', 'mlp', 'dropout', 'lstm', 'state', 'update', 'α', 'train', 'model', 'use', 'optimizer', 'learning', 'rate', 'batch', 'size', 'maximum', 'epoch', 'early', 'stop', 'patience', 'epoch', 'validation', 'set', 'loss', 'gridsearch', 'hide', 'unit', 'lstm', 'hide', 'layer', 'validation', 'set', 'confirm', 'robust', 'hyperparameter', 'dataset', 'refer', 'reader', 'detail', 'schematic', 'diagram', 'model', 'architecture', 'deep', 'learning', 'model', 'implement', 'pytorch', 'also', 'include', 'random', 'forest', 'baseline', 'model', 'scikitlearn', 'default', 'implementation', 'tree', 'bootstrappe', 'full', 'dataset', 'robustness', 'widespread', 'use', 'crop', 'land', 'cover', 'classification', 'land', 'cover', 'map', 'additionally', 'compare', 'model', 'global', 'land', 'cover', 'map', 'resolution', 'map', 'dynamic', 'world', 'esri', 'land', 'cover', 'worldcover', 'dynamic', 'world', 'esri', 'land', 'cover', 'global', 'land', 'cover', 'map', 'produce', 'deep', 'learning', 'model', 'train', 'use', 'dataset', 'densely', 'annotate', 'patch', 'sentinel2', 'imagery', 'distribute', 'world', 'expert', 'nonexpert', 'hand', 'global', 'worldcover', 'map', 'produce', 'catboost', 'model', 'train', 'pixel', 'patch', 'location', 'world', 'label', 'expert', 'worldcover', 'esri', 'landcover', 'map', 'produce', 'yearly', 'discrete', 'pixel', 'assignment', 'class', 'dynamic', 'world', 'update', 'nearreal', 'time', 'new', 'sentinel2', 'scene', 'become', 'available', 'approximately', 'day', 'also', 'provide', 'probability', 'belong', 'possible', 'class', 'key', 'difference', 'worldcover', 'additionally', 'use', 'sentinel1', 'together', 'sentinel2', 'auxiliary', 'datum', 'well', 'digitize', 'small', 'minimum', 'mapping', 'distance', 'mmu', 'compare', 'map', 'map', 'multiclass', 'focus', 'class', 'name', 'crop', 'esri', 'dynamic', 'world', 'map', 'convert', 'map', 'binary', 'version', 'assign', 'value', 'negative', 'class', 'cropland', 'pixel', 'positive', 'class', 'order', 'able', 'evaluate', 'map', 'performance', 'test', 'set', 'note', 'class', 'map', 'consider', 'tree', 'plantation', 'categorize', 'tree', 'class', 'map', 'evaluation', 'metric', 'evaluate', 'model', 'well', 'binarize', 'land', 'cover', 'map', 'quantitatively', 'compute', 'different', 'performance', 'metric', 'prediction', 'test', 'set', 'different', 'metric', 'use', 'precision', 'proportion', 'correct', 'prediction', 'recall', 'proportion', 'correctly', 'identify', 'sample', 'probability', 'detection', 'f1score', 'harmonic', 'mean', 'precision', 'recall', 'thus', 'symmetric', 'measure', 'total', 'accuracy', 'global', 'proportion', 'correctly', 'classify', 'sample', 'area', 'receiver', 'operate', 'characteristic', 'curve', 'auc', 'metric', 'typically', 'use', 'classification', 'setting', 'auc', 'exclusively', 'use', 'binary', 'classification', 'evaluate', 'ability', 'classifier', 'correctly', 'distinguish', 'positive', 'negative', 'class', 'metric', 'high', 'value', 'well', 'however', 'achieve', 'perfect', 'recall', 'precision', 'simultaneously', 'possible', 'practice', 'high', 'f1score', 'reflect', 'well', 'tradeoff', 'equation', 'precision', 'recall', 'f1score', 'total', 'accuracy', 'give', 'eq', 'fn', 'true', 'positive', 'false', 'positive', 'false', 'negative', 'true', 'negative', 'prediction', 'respectively', 'note', 'calculate', 'precision', 'recall', 'f1score', 'total', 'accuracy', 'metric', 'model', 'prediction', 'probability', 'first', 'need', 'convert', 'binary', 'prediction', 'apply', 'threshold', 'value', 'hand', 'auc', 'score', 'calculate', 'compute', 'true', 'positive', 'rate', 'tpr', 'recall', 'false', 'positive', 'rate', 'fpr', 'fp', 'fptn', 'probability', 'false', 'alarm', 'different', 'threshold', 'value', 'build', 'calculate', 'area', 'curve', 'scikitlearn', 'package', 'use', 'calculate', 'metric', 'precision', 'recall', 'f1score', 'total', 'accuracy', 'tp', 'tp', 'tp', 'tp', 'fn', '×', 'precision', 'tp', 'fn', 'tn', 'study', 'threshold', 'use', 'sensible', 'choice', 'give', 'clear', 'preference', 'high', 'tpr', 'fpr', 'mapping', 'use', 'case', 'also', 'note', 'threshold', 'require', 'model', 'performance', 'evaluation', 'use', 'way', 'model', 'training', 'alternatively', 'threshold', 'optimize', 'heldout', 'validation', 'set', 'accord', 'desire', 'confidence', 'model', 'prediction', 'consider', 'set', 'result', 'main', 'experiment', 'section', 'present', 'experimental', 'result', 'different', 'model', 'test', 'set', 'consider', 'different', 'dataset', 'configuration', 'discuss', 'section', 'also', 'compare', 'result', 'global', 'land', 'cover', 'map', 'introduce', 'section', 'benchmark', 'result', 'summarize', 'table', 'observe', 'worldcover', 'map', 'perform', 'exceptionally', 'well', 'particularly', 'term', 'f1score', 'total', 'accuracy', 'compare', 'model', 'land', 'cover', 'map', 'however', 'also', 'note', 'recall', 'overall', 'low', 'model', 'highlight', 'need', 'careful', 'consideration', 'metric', 'base', 'specific', 'use', 'case', 'implement', 'model', 'singleheaded', 'lstm', 'model', 'use', 'dataset', 'subset', 'achieve', 'good', 'performance', 'overall', 'model', 'show', 'substantial', 'improvement', 'dataset', 'include', 'training', 'also', 'observe', 'geowiki', 'dataset', 'also', 'beneficial', 'case', 'subset', 'use', 'rather', 'full', 'geowiki', 'world', 'dataset', 'table', 'result', 'test', 'set', 'threshold', 'apply', 'predict', 'probability', 'binarize', 'label', 'good', 'result', 'metric', 'bold', 'second', 'good', 'underline', 'map', 'model', 'dataset', 'auc', 'precision', 'worldcover', 'esri', 'dynamic', 'world', 'random', 'forest', 'singleheaded', 'world', 'world', '✓', '✓', '✓', '✓', '×', '✓', '✓', '✓', '×', '✓', '×', 'also', 'observe', 'bestperforme', 'random', 'forest', 'model', 'competitive', 'well', 'singleheaded', 'lstm', 'model', 'outperform', 'multiheaded', 'model', 'nevertheless', 'model', 'perform', 'well', 'random', 'forest', 'model', 'use', 'geowiki', 'subset', 'training', 'furthermore', 'auc', 'metric', 'offer', 'insight', 'model', 'performance', 'different', 'threshold', 'value', 'also', 'depict', 'curve', 'good', 'model', 'type', 'base', 'total', 'accuracy', 'figure', 'see', 'random', 'forest', 'model', 'perform', 'well', 'low', 'threshold', 'middleright', 'side', 'curve', 'explain', 'high', 'auc', 'score', 'compare', 'model', 'ablation', 'experiment', 'conduct', 'supplementary', 'experiment', 'exclusively', 'use', 'sentinel2', 'band', 'use', 'regular', 'bce', 'loss', 'function', 'lstm', 'model', 'result', 'experiment', 'present', 'table', 's1', 'table', 'respectively', 'supplementary', 'material', 'include', 'additional', 'datum', 'sentinel1', 'climate', 'topography', 'help', 'significantly', 'improve', 'result', 'model', 'dataset', 'combination', 'however', 'interesting', 'note', 'performance', 'drop', 'pronounce', 'geowiki', 'datum', 'include', 'suggest', 'additional', 'feature', 'provide', 'essential', 'information', 'model', 'identify', 'data', 'distribution', 'shift', 'furthermore', 'also', 'confirm', 'use', 'weight', 'bce', 'loss', 'function', 'improve', 'result', 'singleheaded', 'lstm', 'model', 'however', 'impact', 'particularly', 'significant', 'dataset', 'configuration', 'pronounced', 'class', 'imbalance', 'use', 'subset', 'nigeria', 'map', 'use', 'good', 'model', 'singleheaded', 'lstm', 'train', 'subset', 'dataset', 'generate', 'binary', 'probabilistic', 'map', 'cover', 'entire', 'extent', 'year', 'map', 'present', 'figure', 'probability', 'map', 'offer', 'additional', 'valuable', 'insight', 'available', 'discrete', 'worldcover', 'land', 'cover', 'map', 'discussion', 'quantitative', 'result', 'see', 'give', 'remote', 'sense', 'datum', 'label', 'random', 'forest', 'lstm', 'model', 'achieve', 'well', 'performance', 'cropland', 'test', 'set', 'compare', 'worldcover', 'land', 'cover', 'figure', 'receive', 'operator', 'curve', 'test', 'set', 'good', 'model', 'regard', 'accuracy', 'type', 'model', 'represent', 'use', 'handlabelled', 'datum', 'map', 'land', 'cover', 'map', 'evaluate', 'also', 'present', 'drastic', 'difference', 'performance', 'worldcover', 'achieve', 'accuracy', 'f1score', 'esri', 'dynamic', 'world', 'map', 'lag', 'several', 'percentage', 'point', 'comparative', 'analysis', 'map', 'perform', 'land', 'cover', 'class', 'suggest', 'worldcover', 'well', 'suit', 'resolve', 'small', 'complex', 'agricultural', 'landscape', 'argue', 'due', 'low', 'mmu', 'compare', 'map', 'likely', 'train', 'pixelwise', 'classification', 'rather', 'semantic', 'segmentation', 'therefore', 'map', 'specially', 'well', 'suited', 'detect', 'cropland', 'region', 'smallholder', 'farming', 'predominant', 'also', 'imply', 'identify', 'isolated', 'pixel', 'represent', 'small', 'plot', 'assess', 'model', 'well', 'performing', 'singleheaded', 'lstm', 'train', 'dataset', 'achieve', 'total', 'accuracy', 'f1score', 'use', 'create', 'map', 'performance', 'pair', 'map', 'total', 'accuracy', 'f1score', 'total', 'accuracy', 'f1score', 'recently', 'generate', 'similar', 'approach', 'regard', 'model', 'observe', 'interesting', 'result', 'different', 'combination', 'dataset', 'use', 'training', 'learn', 'include', 'local', 'label', 'improve', 'performance', 'case', 'also', 'possible', 'train', 'good', 'classifier', 'use', 'label', 'notably', 'use', 'geowiki', 'subset', 'configuration', 'singleheaded', 'lstm', 'model', 'achieve', 'f1score', 'accuracy', 'great', 'additionally', 'model', 'model', 'exclude', 'dataset', 'training', 'use', 'geowiki', 'sample', 'actually', 'improve', 'performance', 'compare', 'use', 'subset', 'geowiki', 'suggest', 'least', 'certain', 'case', 'absence', 'local', 'label', 'training', 'clever', 'transfer', 'learn', 'technique', 'indeed', 'yield', 'well', 'result', 'compare', 'combine', 'available', 'datum', 'latter', 'approach', 'fact', 'cause', 'result', 'training', 'datum', 'distribution', 'diverge', 'significantly', 'target', 'country', 'dataset', 'advent', 'satellite', 'datum', 'allow', 'creation', 'land', 'cover', 'cropland', 'even', 'crop', 'yield', 'map', 'resolution', 'thus', 'enable', 'detection', 'smallholder', 'farming', 'facilitate', 'comprehensive', 'agricultural', 'monitoring', 'national', 'scale', 'light', 'progress', 'study', 'examine', 'cropland', 'mapping', 'compare', 'custom', 'machine', 'learning', 'model', 'train', 'task', 'recent', 'global', 'land', 'cover', 'map', 'resolution', 'find', 'enough', 'local', 'training', 'datum', 'lead', 'improved', 'result', 'custom', 'model', 'worldcover', 'land', 'cover', 'map', 'robust', 'choice', 'cropland', 'mapping', 'therefore', 'recent', 'work', 'evaluate', 'accuracy', 'land', 'cover', 'map', 'mapping', 'agricultural', 'land', 'need', 'systematic', 'comparative', 'assessment', 'map', 'produce', 'custom', 'countryspecific', 'model', 'cropland', 'classification', 'evaluate', 'work', 'research', 'help', 'practitioner', 'local', 'government', 'discern', 'rely', 'e', 'r', 'e', 'e', 'r', 'singleheaded', 'lstm', 'singleheaded', 'lstm', 'neighbour', 'multiheade', 'neighbour', 'multiheade', 'world', 'random', 'forest', 'geowiki', 'random', 'forest', 'geowiki', 'neighbour', 'random', 'false', 'positive', 'rate', 'figure', 'binary', 'threshold', 'probability', 'map', 'b', 'respectively', 'generate', 'good', 'model', 'singleheaded', 'lstm', 'model', 'train', 'dataset', 'subset', 'dataset', 'figure', 'state', 'name', 'miss', 'datum', 'country', 'show', 'white', 'binary', 'map', 'e', 'u', 'l', 'km', 'longitude', 'probability', 'map', 'e', 'u', 'l', 'km', 'longitude', 'l', 'b', 'r', 'p', 'l', 'n', 'p', 'r', 'c', 'exist', 'land', 'cover', 'map', 'suffice', 'agricultural', 'need', 'judicious', 'allocate', 'resource', 'datum', 'collection', 'development', 'cropland', 'map', 'tailor', 'specific', 'requirement', 'conclusion', 'uptodate', 'accurate', 'map', 'provide', 'fundamental', 'information', 'many', 'agricultural', 'application', 'critical', 'tool', 'rapidly', 'assess', 'effect', 'climate', 'change', 'food', 'security', 'largescale', 'work', 'develop', 'cropland', 'map', 'resolution', 'use', 'deep', 'learning', 'time', 'series', 'remote', 'sense', 'datum', 'end', 'create', 'dataset', 'uniformlydistributed', 'point', 'country', 'label', 'photointerpretation', 'use', 'dataset', 'training', 'validation', 'single', 'multiheaded', 'compare', 'random', 'forest', 'model', 'global', 'land', 'cover', 'map', 'investigate', 'benefit', 'combine', 'training', 'datum', 'different', 'subset', 'geowiki', 'dataset', 'large', 'global', 'dataset', 'point', 'find', 'worldcover', 'land', 'cover', 'map', 'good', 'performance', 'test', 'set', 'compare', 'map', 'model', 'good', 'performing', 'model', 'singleheaded', 'lstm', 'model', 'obtain', 'combine', 'new', 'training', 'label', 'subset', 'point', 'geowiki', 'dataset', 'contain', 'border', 'observe', 'case', 'local', 'manually', 'label', 'datum', 'provide', 'model', 'use', 'geowiki', 'label', 'always', 'detrimental', 'model', 'use', 'dedicated', 'transfer', 'learning', 'architecture', 'multiheaded', 'lstm', 'classifier', 'however', 'find', 'include', 'training', 'label', 'country', 'close', 'target', 'country', 'complement', 'boost', 'performance', 'model', 'compare', 'use', 'label', 'country', 'collect', 'training', 'label', 'onsite', 'remotely', 'generally', 'lead', 'well', 'result', 'worldcover', 'land', 'cover', 'map', 'prove', 'robust', 'alternative', 'identify', 'result', 'particularly', 'relevant', 'case', 'lack', 'training', 'label', 'available', 'target', 'region', 'insufficient', 'resource', 'collection', 'nevertheless', 'land', 'cover', 'map', 'generally', 'static', 'time', 'cropland', 'map', 'generate', 'researcher', 'government', 'time', 'thus', 'consider', 'study', 'good', 'leverage', 'available', 'groundtruth', 'datum', 'important', 'research', 'topic', 'provide', 'timely', 'accurate', 'extent', 'information', 'datum', 'code', 'availability', 'source', 'code', 'well', 'link', 'download', 'datum', 'output', 'map', 'publicly', 'available', 'follow', 'repository', 'https', 'map', 'visualize', 'interactively', 'follow', 'earth', 'engine', 'script', 'account', 'need', 'https', 'acknowledgment', 'work', 'fund', 'partially', 'dataorg', 'inclusive', 'growth', 'recovery', 'challenge', 'grant', 'virtual', 'cold', 'chain', 'assistant', 'support', 'mastercard', 'center', 'inclusive', 'growth', 'well', 'project', 'scale', 'virtual', 'cold', 'chain', 'assistant', 'commission', 'german', 'federal', 'economic', 'cooperation', 'development', 'implement', 'base', 'empa', 'behalf', 'german', 'agency', 'international', 'cooperation', 'giz', 'funder', 'involve', 'study', 'design', 'collection', 'analysis', 'interpretation', 'datum', 'writing', 'article', 'decision', 'submit', 'publication', 'reference', 'inbal', 'ritvik', 'sahajpal', 'crop', 'type', 'map', 'operational', 'global', 'agricultural', 'monitoring', 'scientific', 'datum', 'zander', 'chakraborty', 'trond', 'simensen', 'geethen', 'global', 'land', 'use', 'land', 'cover', 'dataset', 'comparison', 'dynamic', 'world', 'world', 'cover', 'esri', 'land', 'cover', 'remote', 'sensing', 'review', 'deep', 'learning', 'multiscale', 'agricultural', 'sensing', 'remote', 'sensing', 'korner', 'temporal', 'vegetation', 'modelling', 'use', 'long', 'shortterm', 'memory', 'network', 'crop', 'identification', 'mediumresolution', 'multispectral', 'satellite', 'image', 'ieee', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'workshop', 'cvprw', 'page', 'ieee', 'mehmet', 'streit', 'wegner', 'crop', 'mapping', 'image', 'time', 'series', 'deep', 'learning', 'multiscale', 'label', 'hierarchy', 'remote', 'sensing', 'environment', 'kerner', 'madhava', 'paliyam', 'mehdi', 'hosseini', 'rapid', 'response', 'crop', 'map', 'datum', 'sparse', 'region', 'mehmet', 'aasen', 'walter', 'pixelbase', 'yield', 'mapping', 'prediction', 'sentinel2', 'use', 'spectral', 'index', 'neural', 'network', 'field', 'crop', 'research', 'kerner', 'nakalembe', 'catherine', 'inbal', 'annual', 'inseason', 'mapping', 'cropland', 'field', 'scale', 'label', 'type', 'dataset', 'kerner', 'beckerreshef', 'learn', 'predict', 'crop', 'type', 'heterogeneous', 'sparse', 'label', 'use', 'metalearning', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'workshop', 'cvprw', 'page', 'nashville', 'ieee', 'kerner', 'timl', 'taskinforme', 'metalearning', 'agriculture', 'mirali', 'kerner', 'pretraine', 'transformer', 'remote', 'sensing', 'timeserie', 'onwude', 'divinefavor', 'odion', 'ikegwuonu', 'soufiane', 'hourri', 'thijs', 'defraeye', 'bottleneck', 'fresh', 'food', 'supply', 'chain', 'way', 'forward', 'trend', 'food', 'science', 'technology', '13755–62', 'françois', 'waldner', 'see', 'fritz', 'inian', 'moorthy', 'ian', 'olha', 'defourny', 'sven', 'gilliam', 'ibrar', 'swarup', 'mrinal', 'kripal', 'pange', 'kant', 'meghna', 'saikia', 'schlesinger', 'singha', 'global', 'reference', 'database', 'crowdsource', 'datum', 'collect', 'use', 'geowiki', 'platform', 'scientific', 'datum', 'francesco', 'immitzer', 'clement', 'atzberger', 'much', 'multi', 'temporal', 'sentinel2', 'datum', 'improve', 'crop', 'type', 'classification', 'international', 'journal', 'applied', 'earth', 'observation', 'geoinformation', '72122–130', 'review', 'crop', 'classification', 'use', 'satellitebase', 'polarimetric', 'sar', 'imagery', '7th', 'international', 'conference', 'agrogeoinformatic', 'agrogeoinformatic', 'page', 'han', 'andrás', 'peubey', 'raluca', 'radu', 'dinand', 'scheper', 'adrian', 'simmon', 'cornel', 'saleh', 'bechtold', 'gionata', 'bidlot', 'michail', 'diamantaki', 'johanne', 'flemme', 'manuel', 'robin', 'elía', 'rosnay', 'vamborg', 'sebastien', 'villaume', 'global', 'reanalysis', 'quarterly', 'journal', 'meteorological', 'society', 'riley', 'paller', 'marian', 'werner', 'burbank', 'shuttle', 'radar', 'topography', 'mission', 'review', 'geophysic', 'nakalembe', 'kerner', 'global', 'dataset', 'croptype', 'classification', 'thirtyfifth', 'conference', 'neural', 'information', 'processing', 'system', 'dataset', 'benchmark', 'track', 'round', 'moore', 'earth', 'engine', 'planetaryscale', 'geospatial', 'analysis', 'remote', 'sensing', 'environment', 'big', 'remotely', 'sense', 'datum', 'tool', 'application', 'experience', 'schmitt', 'l', 'h', 'hughe', 'aggregate', 'cloudfree', 'sentinel2', 'image', 'earth', 'engine', 'isprs', 'annal', 'photogrammetry', 'remote', 'sensing', 'spatial', 'informa', 'mochizuki', 'crop', 'classification', 'sentinel2derived', 'vegetation', 'index', 'use', 'ensemble', 'learning', 'journal', 'applied', 'remote', 'sensing', 'markandya', 'water', 'rural', 'poor', 'intervention', 'improve', 'livelihood', 'fao', 'humanitarian', 'exchange', 'administrative', 'boundary', 'https', 'datacatalog', 'access', 'schmidhuber', 'long', 'memory', 'neural', 'computation', 'method', 'stochastic', 'optimization', 'gross', 'massa', 'trevor', 'killeen', 'zeme', 'antiga', 'desmaison', 'sasank', 'chilamkurthy', 'benoit', 'advance', 'neural', 'information', 'pytorch', 'imperative', 'style', 'highperformance', 'deep', 'learn', 'library', 'processing', 'system', 'page', 'gramfort', 'thirion', 'grisel', 'p', 'prettenhofer', 'r', 'weiss', 'passos', 'cournapeau', 'perrot', 'e', 'duchesnay', 'scikitlearn', 'machine', 'learning', 'journal', 'machine', 'learn', 'research', 'pelletier', 'champion', 'gérard', 'dedieu', 'assess', 'robustness', 'random', 'forest', 'map', 'land', 'cover', 'high', 'resolution', 'satellite', 'image', 'time', 'series', 'large', 'area', 'remote', 'sensing', 'environment', '187156–168', 'christopher', 'brookie', 'guzderwilliam', 'samantha', 'schwehr', 'fred', 'rebecca', 'moore', 'tait', 'dynamic', 'world', 'land', 'use', 'land', 'cover', 'mapping', 'scientific', 'datum', 'zoe', 'mazzariello', 'mark', 'steven', 'global', 'land', 'use', 'land', 'cover', 'deep', 'learning', 'ieee', 'international', 'geoscience', 'remote', 'sense', 'symposium', 'igarss', 'page', 'ieee', 'souverijn', 'carsten', 'quast', 'wever', 'audrey', 'paccini', 'sylvain', 'vergnaud', 'cartus', 'nandinerdene', 'ramoino', 'olivi', 'arino', 'worldcover', 'zhenong', 'calum', 'area', 'yield', 'mapping', 'national', 'scale', 'earth', 'engine', 'remote', 'sensing', 'environment', 'kerner', 'beckerreshef', 'accurate', 'exist', 'land', 'cover', 'map', 'agriculture', 'supplementary', 'material', 'table', 's1', 'result', 'comparison', 'test', 'set', 'use', 'sentinel2', 'band', 'ndvi', 'train', 'threshold', 'apply', 'predict', 'probability', 'binarize', 'label', 'good', 'result', 'metric', 'bold', 'second', 'good', 'underline', 'model', 'dataset', 'auc', 'precision', 'accuracy', 'random', 'forest', 'singleheaded', 'world', 'neighbour', 'world', '✓', '✓', '✓', '✓', '×', '✓', '✓', '✓', '×', '✓', '×', 'table', 'result', 'lstm', 'model', 'test', 'set', 'use', 'weight', 'bce', 'loss', 'threshold', 'apply', 'predict', 'probability', 'binarize', 'label', 'good', 'result', 'metric', 'bold', 'second', 'good', 'underline', 'model', 'dataset', 'auc', 'precision', 'accuracy', 'singleheaded', 'neighbour', 'world', '✓', '✓', '✓', '✓', '×', '✓', '×']"
"From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the
  Generative Artificial Intelligence (AI) Research Landscape","[{'href': 'http://arxiv.org/abs/2312.10868v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2312.10868v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-12-18 01:11:39,"JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

1

From Google Gemini to OpenAI Q* (Q-Star): A
Survey of Reshaping the Generative Artiﬁcial
Intelligence (AI) Research Landscape

Timothy R. McIntosh, Teo Susnjak, Tong Liu, Paul Watters, Senior Member, IEEE, and Malka N. Halgamuge,
Senior Member, IEEE

3
2
0
2
c
e
D
8
1

]
I

A
.
s
c
[

1
v
8
6
8
0
1
.
2
1
3
2
:
v
i
X
r
a

Abstract—This comprehensive survey explored the evolving
landscape of generative Artiﬁcial Intelligence (AI), with a speciﬁc
focus on the transformative impacts of Mixture of Experts (MoE),
multimodal learning, and the speculated advancements towards
Artiﬁcial General Intelligence (AGI). It critically examined the
current state and future trajectory of generative Artiﬁcial In-
telligence (AI), exploring how innovations like Google’s Gemini
and the anticipated OpenAI Q* project are reshaping research
priorities and applications across various domains,
including
an impact analysis on the generative AI research taxonomy.
It assessed the computational challenges, scalability, and real-
world implications of these technologies while highlighting their
potential in driving signiﬁcant progress in ﬁelds like healthcare,
ﬁnance, and education. It also addressed the emerging academic
challenges posed by the proliferation of both AI-themed and AI-
generated preprints, examining their impact on the peer-review
process and scholarly communication. The study highlighted the
importance of incorporating ethical and human-centric methods
in AI development, ensuring alignment with societal norms
and welfare, and outlined a strategy for future AI research
that focuses on a balanced and conscientious use of MoE,
multimodality, and AGI in generative AI.

Index Terms—AI Ethics, Artiﬁcial General Intelligence (AGI),
Artiﬁcial Intelligence (AI), Gemini, Generative AI, Mixture of
Experts (MoE), Multimodality, Q* (Q-star), Research Impact
Analysis.

I. INTRODUCTION

T HE historical context of AI, tracing back to Alan Turing’s

“Imitation Game” [1], early computational theories [2],
[3], and the development of the ﬁrst neural networks and
machine learning [4], [5], [6], has set the foundation for to-
day’s advanced models. This evolution, accentuated by crucial
moments such as the rise of deep learning and reinforcement
learning, has been vital in shaping the contemporary trends
in AI, including the sophisticated Mixture of Experts (MoE)
models and multimodal AI systems, illustrating the ﬁeld’s
dynamic and continuously evolving character. These advance-
ments are a testament to the dynamic and ever-evolving nature
of AI technology. The evolution of Artiﬁcial Intelligence

Manuscript received December 19, 2023. (Corresponding author: Timothy

R. McIntosh.)

Timothy McIntosh is with Academies Australasia Polytechnic, Melbourne,

VIC 3000, Australia (e-mail: t.mcintosh@aapoly.edu.au).

Teo Susnjak and Tong Liu are with Massey University, Auckland 0632,

New Zealand (e-mail: t.liu@massey.ac.nz; t.susnjak@massey.ac.nz).

Paul Watters is with Cyberstronomy Pty Ltd, Ballarat, VIC 3350, Australia

(e-mail: ceo@cyberstronomy.com).

Malka N. Halgamuge is with RMIT University, Melbourne, VIC 3000,

Australia (e-mail: malka.halgamuge@rmit.edu.au).

(AI) has witnessed a crucial turn with the advent of Large
Language Models (LLMs), notably ChatGPT, developed by
OpenAI, and the recent unveiling of Google’s Gemini [7], [8].
This technology has not only revolutionized the industry and
academia, but has also reignited critical discussions concerning
AI consciousness and its potential threats to humanity [9],
[10], [11]. The development of such advanced AI systems,
including notable competitors like Anthropic’s Claude, and
now Gemini, which demonstrates several advances over pre-
vious models like GPT-3 and Google’s own LaMDA, has
reshaped the research landscape. Gemini’s ability to learn
from two-way conversations and its “spike-and-slab” attention
method, which allows it to focus on relevant parts of the
context during multi-turn conversations, represents a signiﬁ-
cant leap in developing models that are better equipped for
multidomain conversational applications1. These innovations
in LLMs, including the mixture-of-experts methods employed
by Gemini, signal a move towards models that can handle a
diversity of inputs and foster multimodal approaches. Amidst
this backdrop, speculations of an OpenAI project known as
Q* (Q-Star) have surfaced, allegedly combining the power of
LLMs with sophisticated algorithms such as Q-learning and
A* (A-Star algorithm), further contributing to the dynamic
research environment2.

A. Changing AI Research Popularity

As the ﬁeld of LLMs continues to evolve, exempliﬁed by
innovations such as Gemini and Q*, a multitude of stud-
ies have surfaced with the aim of charting future research
paths, which have varied from identifying emerging trends to
highlighting areas poised for swift progress. The dichotomy
of established methods and early adoption is evident, with
“hot topics” in LLM research increasingly shifting towards
multimodal capabilities and conversation-driven learning, as
demonstrated by Gemini. The propagation of preprints has
expedited knowledge sharing, but also brings the risk of re-
duced academic scrutiny. Issues like inherent biases, noted by
Retraction Watch, along with concerns about plagiarism and
forgery, present substantial hurdles [12]. The academic world,
therefore, stands at an intersection, necessitating a uniﬁed drive

1https://deepmind.google/technologies/gemini/
2https://www.forbes.com/sites/lanceeliot/2023/11/26/about-that-mysterious-
ai-breakthrough-known-as-q-by-openai-that-allegedly-attains-true-ai-or-is-on-
the-path-toward-artiﬁcial-general-intelligence-agi

 
 
 
 
 
 
JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

2

to reﬁne research directions in light of the fast-paced evolution
of the ﬁeld, which appears to be partly traced through the
changing popularity of various research keywords over time.
The release of generative models like GPT and the widespread
commercial success of ChatGPT have been inﬂuential. As
depicted in Figure 1, the rise and fall of certain keywords
appear to have correlated with signiﬁcant industry milestones,
such as the release of the “Transformer” model in 2017 [13],
the GPT model in 2018 [14], and the commercial ChatGPT-3.5
in December 2022. For instance, the spike in searches related
to “Deep Learning” coincides with the breakthroughs in neural
network applications, while the interest in “Natural Language
Processing” surges as models like GPT and LLaMA redeﬁne
what’s possible in language understanding and generation. The
enduring attention to “Ethics / Ethical” in AI research, despite
some ﬂuctuations, reﬂects the continuous and deep-rooted
concern for the moral dimensions of AI, underscoring that
ethical considerations are not merely a reactionary measure,
but an integral and persistent dialogue within the AI discussion
[15].
It

is academically intriguing to postulate whether these
trends signify a causal relationship, where technological ad-
vancements drive research focus, or if the burgeoning research
itself propels technological development. This paper also
explores the profound societal and economic impacts of AI
advancements. We examine how AI technologies are reshap-
ing various industries, altering employment landscapes, and
inﬂuencing socio-economic structures. This analysis highlights
both the opportunities and challenges posed by AI in the
modern world, emphasizing its role in driving innovation and
economic growth, while also considering the ethical implica-
tions and potential for societal disruption. Future studies could
yield more deﬁnitive insights, yet the synchronous interplay
between innovation and academic curiosity remains a hallmark
of AI’s progress.
Meanwhile,

increase in the number of
preprints posted on arXiv under the Computer Science > Ar-
tiﬁcial Intelligence (cs.AI) category, as illustrated in Figure 2,
appears to signify a paradigm shift in research dissemination
within the AI community. While the rapid distribution of
ﬁndings enables swift knowledge exchange,
it also raises
concerns regarding the validation of information. The surge
in preprints may lead to the propagation of unvalidated or
biased information, as these studies do not undergo the rigor-
ous scrutiny and potential retraction typical of peer-reviewed
publications [16], [17]. This trend underlines the need for
careful consideration and critique in the academic community,
especially given the potential for such unvetted studies to be
cited and their ﬁndings propagated.

the exponential

B. Objectives

The impetus for this investigation is the ofﬁcial unveiling of
Gemini and the speculative discourse surrounding Q* project,
which prompts a timely examination of the prevailing currents

3The legend entries correspond to the keywords used in the search query,
which is constructed as: “(AI OR artiﬁcial OR (machine learning) OR (neural
network) OR computer OR software) AND ([speciﬁc keyword])”.

in generative AI research. This paper speciﬁcally contributes
to the understanding of how MoE, multimodality, and Artiﬁ-
cial General Intelligence (AGI) are impacting generative AI
models, offering detailed analysis and future directions for
each of these three key areas. This study does not aim to
perpetuate conjecture about the unrevealed Q-Star initiative,
but rather to critically appraise the potential for obsolescence
or insigniﬁcance in extant research themes, whilst concur-
rently delving into burgeoning prospects within the rapidly
transforming LLM panorama. This inquiry is reminiscent
of the obsolete nature of encryption-centric or ﬁle-entropy-
based ransomware detection methodologies, which have been
eclipsed by the transition of ransomware collectives towards
data theft strategies utilizing varied attack vectors, relegating
contemporary studies on crypto-ransomware to the status of
latecomers [18], [19]. Advances in AI are anticipated to not
only enhance capabilities in language analysis and knowledge
synthesis but also to pioneer in areas like Mixture of Experts
(MoE) [20], [21], [22], [23], [24], [25], multimodality [26],
[27], [28], [29], [30], and Artiﬁcial General Intelligence (AGI)
[31], [32], [10], [11], and has already heralded the obso-
lescence of conventional, statistics-driven natural
language
processing techniques in many domains [8]. Nonetheless,
the perennial imperative for AI to align with human ethics
and values persists as a fundamental tenet [33], [34], [35],
and the conjectural Q-Star initiative offers an unprecedented
opportunity to instigate discourse on how such advancements
might reconﬁgure the LLM research topography. Within this
milieu, insights from Dr. Jim Fan (senior research scientist &
lead of AI agents at NVIDIA) on Q*, particularly concerning
the amalgamation of learning and search algorithms, furnish
an invaluable perspective on the prospective technical con-
struct and proﬁciencies of such an undertaking4. Our research
methodology involved a structured literature search using key
terms like ‘Large Language Models’ and ‘Generative AI’. We
utilized ﬁlters across several academic databases such as IEEE
Xplore, Scopus, ACM Digital Library, ScienceDirect, Web of
Science, and ProQuest Central, tailored to identify relevant
articles published in the timeframe from 2017 (the release
of the “Transformer” model) to 2023 (the writing time of
this manuscript). This paper aspires to dissect the technical
ramiﬁcations of Gemini and Q*, probing how they (and
similar technologies whose emergence is now inevitable) may
transﬁgure research trajectories and disclose new vistas in the
domain of AI. In doing so, we have pinpointed three nascent
research domains—MoE, multimodality, and AGI—that stand
to reshape the generative AI research landscape profoundly.
This investigation adopts a survey-style approach, systemat-
ically mapping out a research roadmap that synthesizes and
analyzes the current and emergent trends in generative AI.
The major contributions of this study is as follows:

1) Detailed examination of the evolving landscape in genera-
tive AI, emphasizing the advancements and innovations in
technologies like Gemini and Q*, and their wide-ranging
implications within the AI domain.

4https://twitter.com/DrJimFan/status/1728100123862004105

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

3

700k

600k

500k

400k

300k

200k

100k

s
t
l
u
s
e
r

h
c
r
a
e
s

f
o

r
e
b
m
u
N

2011

2012

2013

2014

Deep Learning
Convolutional Neural Network(s)
Unsupervised Learning
Fine(-)tuning

2018

2015

2016

2017
Year
Transfer Learning
Explainable AI
Reinforcement Learning
Ethics / Ethical

2019

2020

2021

2022

2023

Supervised Learning
Natural Language Processing
Generative Adversarial Networks
Language Model(s)

Figure 1: Number of search results on Google Scholar with different keywords by year 3

s
t
n
i
r
p
e
r
P

f
o

r
e
b
m
u
N

25,000

20,000

15,000

10,000

5,000

0

cs.AI Preprints on arXiv

2011

2012

2013

2014

2015

2016

2017

2018

2019

2020

2021

2022

2023

Year

Figure 2: Annual number of preprints posted under the cs.AI
category on arXiv.org

2) Analysis of the transformative effect of advanced gener-
ative AI systems on academic research, exploring how
these developments are altering research methodologies,
setting new trends, and potentially leading to the obso-
lescence of traditional approaches.

3) Thorough assessment of the ethical, societal, and tech-
nical challenges arising from the integration of genera-
tive AI in academia, underscoring the crucial need for

aligning these technologies with ethical norms, ensuring
data privacy, and developing comprehensive governance
frameworks.

The rest of this paper is organized as follows: Section
II explores the historical development of Generative AI.
Section III presents a taxonomy of current Generative AI
research. Section IV explores the Mixture of Experts (MoE)
model architecture, its innovative features, and its impact on
transformer-based language models. Section V discusses the
speculated capabilities of the Q* project. Section VI discusses
the projected capabilities of AGI. Section VII examines the
impact of recent advancements on the Generative AI research
taxonomy. Section VIII identiﬁes emerging research priorities
in Generative AI. Section X discusses the academic challenges
of the rapid surge of preprints in AI. The paper concludes in
Section XI, summarizing the overall effects of these develop-
ments in generative AI.

II. BACKGROUND: EVOLUTION OF GENERATIVE AI

The ascent of Generative AI has been marked by signiﬁcant
milestones, with each new model paving the way for the next
evolutionary leap. From single-purpose algorithms to LLMs
like OpenAI’s ChatGPT and the latest multimodal systems,
the AI landscape has been transformed, while countless other
ﬁelds have been disrupted.

A. The Evolution of Language Models

Language models have undergone a transformative journey
(Fig. 3), evolving from rudimentary statistical methods to the

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

4

1980s: Statistical Models (n-grams)

1990s: Adoption in NLP, n-gram Usage

1997: Introduction of LSTMs

2000s: LSTMs in Text/Voice Processing

2010s: Deep Learning Era, GPT, BERT

2020s: LLaMA, Gemini; ChatGPT Launch

Figure 3: Timeline of Key Developments in Language Model
Evolution

complex neural network architectures that underpin today’s
LLMs [36], [37]. This evolution has been driven by a relentless
quest for models that more accurately reﬂect the nuances of
human language, as well as the desire to push the boundaries
of what machines can understand and generate [36], [38], [37].
However, this rapid advancement has not been without its
challenges. As language models have grown in capability, so
too have the ethical and safety concerns surrounding their use,
prompting a reevaluation of how these models are developed
and the purposes for which they are employed [36], [39], [40].

1) Language Models as Precursors: The inception of lan-
guage modeling can be traced to the statistical approaches of
the late 1980s, a period marked by a transition from rule-based
to machine learning algorithms in Natural Language Process-
ing (NLP) [41], [42], [43], [44], [45]. Early models, primarily
n-gram based, calculated the probability of word sequences
in a corpus, thus providing a rudimentary understanding of
language structure [41]. Those models, simplistic yet ground-
breaking, laid the groundwork for future advances in language
understanding. With the increase of computational power, the
late 1980s witnessed a revolution in NLP, pivoting towards
statistical models capable of ‘soft’ probabilistic decisions, as
opposed to the rigid, ‘handwritten’ rule-based systems that
dominated early NLP systems [43]. IBM’s development of
complicated statistical models throughout this period signiﬁed
the growing importance and success of these approaches.
In the subsequent decade, the popularity and applicability
of statistical models surged, proving invaluable in managing
the ﬂourishing ﬂow of digital text. The 1990s saw statistical
methods ﬁrmly established in NLP research, with n-grams
becoming instrumental in numerically capturing linguistic pat-
terns. The introduction of Long Short-Term Memory (LSTM)
networks in 1997 [46], and their application to voice and
text processing a decade later [47], [48], [49], marked a
signiﬁcant milestone, leading to the current era where neural
network models represent the cutting edge of NLP research
and development.

2) Large Language Models: Technical Advancement and
Commercial Success: The advent of deep learning has revolu-
tionized the ﬁeld of NLP, leading to the development of LLMs
like GPT, BERT, and notably, OpenAI’s ChatGPT. Recent
models such as GPT-4 and LLaMA have pushed the bound-
aries by integrating sophisticated techniques like transformer
architectures and advanced natural language understanding,
illustrating the rapid evolution in this ﬁeld [37]. These models
represent a signiﬁcant leap in NLP capabilities, leveraging
vast computational resources and extensive datasets to achieve
new heights in language understanding and generation [37],
[50]. ChatGPT has shown impressive conversational skills
and contextual understanding with a broad spectrum of func-
tional uses in many areas, as evidenced by its technical and
commercial success, including rapid adoption by over 100
million users shortly after launch, which underscores a robust
market demand for natural language AI and has catalyzed
interdisciplinary research into its applications in sectors like
education, healthcare, and commerce [8], [50], [51], [52],
[53]. In education, ChatGPT offers innovative approaches
to personalized learning and interactive teaching [54], [51],
[55], [56], while in commerce,
it revolutionizes customer
service and content creation [57], [58]. The widespread use
of ChatGPT, Google Bard, Anthropic Claude and similar
commercial LLMs has reignited important debates in the ﬁeld
of AI, particularly concerning AI consciousness and safety, as
its human-like interaction capabilities raise signiﬁcant ethical
questions and highlight the need for robust governance and
safety measures in AI development [59], [31], [32], [11]. Such
inﬂuence appears to extend beyond its technical achievements,
shaping cultural and societal discussions about the role and
future of AI in our world.

The advancements in LLMs, including the development of
models like GPT and BERT, have paved the way for the
conceptualization of Q*. Speciﬁcally, the scalable architecture
and extensive training data that characterize these models
are foundational
to the proposed capabilities of Q*. The
success of ChatGPT in contextual understanding and con-
versational AI, for example, informs the design principles
of Q*, suggesting a trajectory towards more sophisticated,
context-aware, and adaptive language processing capabilities.
Similarly, the emergence of multimodal systems like Gemini,
capable of integrating text, images, audio, and video, reﬂects
an evolutionary path that Q* could extend, combining the
versatility of LLMs with advanced learning and pathﬁnding
algorithms for a more holistic AI solution.

3) Fine-tuning, Hallucination Reduction, and Alignment
in LLMs: The advancement of LLMs has underlined the
signiﬁcance of ﬁne-tuning [60], [61], [62], [63], hallucination
reduction [64], [65], [66], [67], and alignment [68], [69],
[70], [71], [72]. These aspects are crucial in enhancing the
functionality and reliability of LLMs. Fine-tuning, which
involves adapting pre-trained models to speciﬁc tasks, has
seen signiﬁcant progress: techniques like prompt-based and
few-shot learning [73], [74], [75], [76], alongside supervised
ﬁne-tuning on specialized datasets [60], [77], [78], [79], have
enhanced the adaptability of LLMs in various contexts, but
challenges remain, particularly in bias mitigation and the

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

5

generalization of models across diverse tasks [60], [80], [72].
Hallucination reduction is a persistent challenge in LLMs,
characterized by the generation of conﬁdent but factually in-
correct information [36]. Strategies such as conﬁdence penalty
regularization during ﬁne-tuning have been implemented to
mitigate overconﬁdence and improve accuracy [81], [82], [83].
Despite these efforts, the complexity of human language and
the breadth of topics make completely eradicating hallucina-
tions a daunting task, especially in culturally sensitive contexts
[36], [9]. Alignment, ensuring LLM outputs are congruent
with human values and ethics, is an area of ongoing research.
Innovative approaches, from constrained optimization [84],
[85], [86], [87], [88], to different types of reward modeling
[89], [90], [91], [92], aim to embed human preferences within
AI systems. While advancements in ﬁne-tuning, hallucination
reduction, and alignment have propelled LLMs forward, these
areas still present considerable challenges. The complexity of
aligning AI with the diverse spectrum of human ethics and the
persistence of hallucinations, particularly on culturally sensi-
tive topics, highlight the need for continued interdisciplinary
research in the development and application of LLMs [9].

4) Mixture of Experts: A Paradigm Shift: The adoption
of the MoE architecture in LLMs marks a critical evolution
in AI technology. This innovative approach, exempliﬁed by
advanced models like Google’s Switch Transformer5 and
MistralAI s Mixtral-8x7B6, leverages multiple transformer-
based expert modules for dynamic token routing, enhancing
modeling efﬁciency and scalability. The primary advantage of
MoE lies in its ability to handle vast parameter scales, reduc-
ing memory footprint and computational costs signiﬁcantly
[93], [94], [95], [96], [97]. This is achieved through model
parallelism across specialized experts, allowing the training
of models with trillions of parameters, and its specialization
in handling diverse data distributions enhances its capability
in few-shot learning and other complex tasks [94], [95]. To
illustrate the practicality of MoE, consider its application in
healthcare. For example, an MoE-based system could be used
for personalized medicine, where different ‘expert’ modules
specialize in various aspects of patient data analysis, including
genomics, medical imaging, and electronic health records. This
approach could signiﬁcantly enhance diagnostic accuracy and
treatment personalization. Similarly, in ﬁnance, MoE models
can be deployed for risk assessment, where experts analyze
trends, and regulatory
distinct ﬁnancial
compliance factors.

indicators, market

Despite its beneﬁts, MoE confronts challenges in dynamic
routing complexity [98], [99], [100], [101], [102], expert
imbalance [103], [104], [105], [106], and probability dilu-
tion [107], and such technical hurdles demand sophisticated
solutions to fully harness MoE’s potential. Moreover, while
MoE may offer performance gains, it does not inherently
solve ethical alignment issues in AI [108], [109], [110]. The
complexity and specialization of MoE models can obscure the
decision-making processes, complicating efforts to ensure ethi-
cal compliance and alignment with human values [108], [111].

Although the paradigm shift to MoE signiﬁes a major leap in
LLM development, offering signiﬁcant scalability and special-
ization advantages, ensuring the safety, ethical alignment, and
transparency of these models remains a paramount concern.
The MoE architecture, while technologically advanced, entails
continued interdisciplinary research and governance to align
AI with broader societal values and ethical standards.

B. Multimodal AI and the Future of Interaction

The advent of multimodal AI marks a transformative era
in AI development, revolutionizing how machines interpret
and interact with a diverse array of human sensory inputs and
contextual data.

1) Gemini: Redeﬁning Benchmarks in Multimodality: Gem-
ini, a pioneering multimodal conversational system, marks a
signiﬁcant shift in AI technology by surpassing traditional
text-based LLMs like GPT-3 and even its multimodal coun-
terpart, ChatGPT-4. Gemini’s architecture has been designed
to incorporate the processing of diverse data types such
as text, images, audio, and video, a feat facilitated by its
unique multimodal encoder, cross-modal attention network,
and multimodal decoder [112]. The architectural core of
Gemini is its dual-encoder structure, with separate encoders
for visual and textual data, enabling sophisticated multimodal
contextualization [112]. This architecture is believed to surpass
the capabilities of single-encoder systems, allowing Gemini
to associate textual concepts with image regions and achieve
a compositional understanding of scenes [112]. Furthermore,
Gemini integrates structured knowledge and employs special-
ized training paradigms for cross-modal intelligence, setting
new benchmarks in AI [112]. In [112], Google has claimed and
demonstrated that Gemini distinguishes itself from ChatGPT-4
through several key features:

• Breadth of Modalities: Unlike ChatGPT-4, which pri-
marily focuses on text, documents, images, and code,
Gemini handles a wider range of modalities including
audio, and video. This extensive range allows Gemini to
tackle complex tasks and understand real-world contexts
more effectively.

• Performance: Gemini Ultra excels in key multimodality
benchmarks, notably in massive multitask language un-
derstanding (MMLU) which encompasses a diverse array
of domains like science, law, and medicine, outperform-
ing ChatGPT-4.

• Scalability and Accessibility: Gemini is available in three
tailored versions – Ultra, Pro, and Nano – catering to a
range of applications from data centers to on-device tasks,
a level of ﬂexibility not yet seen in ChatGPT-4.

• Code Generation: Gemini’s proﬁciency in understanding
and generating code across various programming lan-
guages is more advanced, offering practical applications
beyond ChatGPT-4’s capabilities.

• Transparency and Explainability: A focus on explainabil-
ity sets Gemini apart, as it provides justiﬁcations for its
outputs, enhancing user trust and understanding of the
AI’s reasoning process.

5https://huggingface.co/google/switch-c-2048
6https://huggingface.co/mistralai/Mixtral-8x7B-v0.1

Despite these advancements, Gemini’s real-world perfor-
mance in complex reasoning tasks that require integration

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

6

of commonsense knowledge across modalities remains to be
thoroughly evaluated.

2) Technical Challenges in Multimodal Systems: The devel-
opment of multimodal AI systems faces several technical hur-
dles, including creating robust and diverse datasets, managing
scalability, and enhancing user trust and system interpretability
[113], [114], [115]. Challenges like data skew and bias are
prevalent due to data acquisition and annotation issues, which
requires effective dataset management by employing strate-
gies such as data augmentation, active learning, and transfer
learning [113], [116], [80], [115]. A signiﬁcant challenge is
the computational demands of processing various data streams
simultaneously, requiring powerful hardware and optimized
model architectures for multiple encoders [117], [118]. Ad-
vanced algorithms and multimodal attention mechanisms are
needed to balance attention across different input media and
resolve conﬂicts between modalities, especially when they pro-
vide contradictory information [119], [120], [118]. Scalability
issues, due to the extensive computational resources needed,
are exacerbated by limited high-performance hardware avail-
ability [121], [122]. There is also a pressing need for calibrated
multimodal encoders for compositional scene understanding
and data integration [120]. Reﬁning evaluation metrics for
these systems is necessary to accurately assess performance
in real-world tasks, calling for comprehensive datasets and
uniﬁed benchmarks, and for enhancing user trust and system
interpretability through explainable AI in multimodal contexts.
Addressing these challenges is vital for the advancement of
multimodal AI systems, enabling seamless and intelligent
interaction aligned with human expectations.

3) Multimodal AI: Beyond Text in Ethical and Social Con-
texts: The expansion of multimodal AI systems introduces
both beneﬁts and complex ethical and social challenges that
extend beyond those faced by text-based AI. In commerce,
multimodal AI can transform customer engagement by inte-
grating visual, textual, and auditory data [123], [124], [125].
For autonomous vehicles, multimodality can enhance safety
and navigation by synthesizing data from various sensors,
including visual, radar, and Light Detection and Ranging
(LIDAR) [126], [125], [127]. Still, DeepFake technology’s
ability to generate convincingly realistic videos, audio, and
images is a critical concern in multimodality, as it poses risks
of misinformation and manipulation that signiﬁcantly impact
public opinion, political landscapes, and personal reputations,
thereby compromising the authenticity of digital media and
raising issues in social engineering and digital forensics where
distinguishing genuine from AI-generated content becomes
increasingly challenging [128], [129]. Privacy concerns are
ampliﬁed in multimodal AI due to its ability to process
and correlate diverse data sources, potentially leading to
intrusive surveillance and proﬁling, which raises questions
about the consent and rights of individuals, especially when
personal media is used without permission for AI training or
content creation [113], [130], [131]. Moreover, multimodal
AI can propagate and amplify biases and stereotypes across
different modalities, and if unchecked, this can perpetuate
discrimination and social inequities, making it imperative to
address algorithmic bias effectively [132], [133], [134]. The

ethical development of multimodal AI systems requires robust
governance frameworks focusing on transparency, consent,
data handling protocols, and public awareness, when ethical
guidelines must evolve to address the unique challenges posed
by these technologies, including setting standards for data
usage and safeguarding against the nonconsensual exploita-
tion of personal information [135], [136]. Additionally, the
development of AI literacy programs will be crucial in helping
society understand and responsibly interact with multimodal
AI technologies [113], [135]. As the ﬁeld progresses, interdis-
ciplinary collaboration will be key in ensuring these systems
are developed and deployed in a manner that aligns with
societal values and ethical principles [113].

C. Speculative Advances and Chronological Trends

In the dynamic landscape of AI, the speculative capabilities
of the Q* project, blending LLMs, Q-learning, and A* (A-
Star algorithm), embodies a signiﬁcant leap forward. This
section explores the evolutionary trajectory from game-centric
AI systems to the broad applications anticipated with Q*.

1) From AlphaGo’s Groundtruth to Q-Star’s Exploration:
The journey from AlphaGo, a game-centric AI, to the con-
ceptual Q-Star project represents a signiﬁcant paradigm shift
in AI. AlphaGo’s mastery in the game of Go highlighted
the effectiveness of deep learning and tree search algorithms
within well-deﬁned rule-based environments, underscoring the
potential of AI in complex strategy and decision-making [137],
[138]. Q-Star, however, is speculated to move beyond these
conﬁnes, aiming to amalgamate the strengths of reinforcement
learning (as seen in AlphaGo), with the knowledge, NLG,
creativity and versatility of LLMs, and the strategic efﬁ-
ciency of pathﬁnding algorithms like A*. This blend, merging
pathﬁnding algorithms and LLMs, could enable AI systems
to transcend board game conﬁnes and, with Q-Star’s natural
language processing, interact with human language, enabling
nuanced interactions and marking a leap towards AI adept in
both structured tasks and complex human-like communication
and reasoning. Moreover, the incorporation of Q-learning and
A* algorithms would enable Q-Star to optimize decision paths
and learn from its interactions, making it more adaptable and
intelligent over time. The combination of these technologies
could lead to AI that is not only more efﬁcient in problem-
solving but also creative and insightful in its approach. This
speculative advancement from the game-focused power of Al-
phaGo to the comprehensive potential of Q-Star illustrates the
dynamic and ever-evolving nature of AI research, and opens
up possibilities for AI applications that are more integrated
with human life and capable of handling a broader range of
tasks with greater autonomy and sophistication.

2) Bridging Structured Learning with Creativity: The antic-
ipated Q* project, blending Q-learning and A* algorithms with
the creativity of LLMs, embodies a groundbreaking step in
AI, potentially surpassing recent innovations like Gemini. The
fusion suggested in Q* points to an integration of structured,
goal-oriented learning with generative, creative capabilities, a
combination that could transcend the existing achievements
leap in
of Gemini. While Gemini represents a signiﬁcant

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

7

multimodal AI, combining various forms of data inputs such
as text, images, audio, and video, Q* is speculated to bring a
more profound integration of creative reasoning and structured
problem-solving. This would be achieved by merging the
precision and efﬁciency of algorithms like A* with the learning
adaptability of Q-learning, and the complex understanding
of human language and context offered by LLMs. Such an
integration could enable AI systems to not only process and
analyze complex multimodal data but also to autonomously
navigate through structured tasks while engaging in creative
problem-solving and knowledge generation, mirroring the
multifaceted nature of human cognition. The implications of
this potential advancement are vast, suggesting applications
that span beyond the capabilities of current multimodal sys-
tems like Gemini. By aligning the deterministic aspects of
traditional AI algorithms with the creative and generative
potential of LLMs, Q* could offer a more holistic approach
to AI development. This could bridge the gap between the
logical, rule-based processing of AI and the creative, abstract
thinking characteristic of human intelligence. The anticipated
unveiling of Q*, merging structured learning techniques and
creative problem-solving in a singular, advanced framework,
holds the promise of not only extending but also signiﬁcantly
surpassing the multimodal capabilities of systems like Gemini,
thus heralding another game-changing era in the domain of
generative AI, showcasing its potential as a crucial develop-
ment eagerly awaited in the ongoing evolution of AI.

III. THE CURRENT GENERATIVE AI RESEARCH
TAXONOMY

The ﬁeld of Generative AI is evolving rapidly, which
necessitates a comprehensive taxonomy that encompasses the
breadth and depth of research within this domain. Detailed in
Table I, this taxonomy categorizes the key areas of inquiry
and innovation in generative AI, and serves as a foundational
framework to understand the current state of the ﬁeld, guiding
through the complexities of evolving model architectures,
advanced training methodologies, diverse application domains,
ethical implications, and the frontiers of emerging technolo-
gies.

A. Model Architectures

• Recurrent Neural Networks (RNNs): RNNs excel in the
realm of sequence modeling, making them particularly
effective for tasks involving language and temporal data,
as their architecture is speciﬁcally designed to process
sequences of data, such as text, enabling them to capture
the context and order of the input effectively [150],
[151], [152], [153], [154]. This proﬁciency in handling
sequential
information renders them indispensable in
applications that require a deep understanding of the
temporal dynamics within data, such as natural language
tasks and time-series analysis [155], [156]. RNNs’ ability
to maintain a sense of continuity over sequences is a
critical asset in the broader ﬁeld of AI, especially in
scenarios where context and historical data play crucial
roles [157].

• Mixture of Experts (MoE): MoE models can signiﬁ-
cantly enhance efﬁciency by deploying model parallelism
across multiple specialized expert modules, which en-
ables these models to leverage transformer-based modules
for dynamic token routing, and to scale to trillions of
parameters, thereby reducing both memory footprint and
computational costs [94], [98]. MoE models stand out for
their ability to divide computational loads among various
experts, each specializing in different aspects of the data,
which allows for handling vast scales of parameters more
effectively, leading to a more efﬁcient and specialized
handling of complex tasks [94], [21].

• Multimodal Models: Multimodal models, which inte-
grate a variety of sensory inputs such as text, vision,
and audio, are crucial
in achieving a comprehensive
understanding of complex data sets, particularly trans-
formative in ﬁelds like medical imaging [113], [112],
[115]. These models facilitate accurate and data-efﬁcient
analysis by employing multi-view pipelines and cross-
attention blocks [158], [159]. This integration of diverse
sensory inputs allows for a more nuanced and detailed
interpretation of data, enhancing the model’s ability to
accurately analyze and understand various types of infor-
mation [160]. The combination of different data types,
processed concurrently, enables these models to provide a
holistic view, making them especially effective in applica-
tions that require a deep and multifaceted understanding
of complex scenarios [113], [161], [162], [160].

Generative AI model architectures have seen signiﬁcant

developments, with four key domains standing out:

B. Training Techniques

• Transformer Models: Transformer models have signiﬁ-
cantly revolutionized the ﬁeld of AI, especially in NLP,
due to their higher efﬁciency and scalability [139], [140],
[141]. They employ advanced attention mechanisms to
achieve enhanced contextual processing, allowing for
more subtle understanding and interaction [142], [143],
[144]. These models have also made notable strides in
computer vision, as evidenced by the development of
vision transformers like EfﬁcientViT [145], [146] and
YOLOv8 [147], [148], [149]. These innovations symbol-
ize the extended capabilities of transformer models in
areas such as object detection, offering not only improved
performance but also increased computational efﬁciency.

The training of generative AI models leverages four key

techniques, each contributing uniquely to the ﬁeld:

• Supervised Learning: Supervised learning, a founda-
tional approach in AI, uses labeled datasets to guide
models towards accurate predictions, and it has been
integral to various applications, including image recogni-
tion and NLP [163], [164], [165]. Recent advancements
have focused on developing sophisticated loss functions
and regularization techniques, aimed at enhancing the
performance and generalization capabilities of supervised
learning models, ensuring they remain robust and effec-
tive across a wide range of tasks and data types [166],
[167], [168].

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

8

Table I: Comprehensive Taxonomy of Current Generative AI and LLM Research

Subdomain
Transformer Models

Key Focus
Efﬁciency, Scalability

Description
Optimizing network structures for faster processing and larger datasets.

Domain
Model Architec-
ture

Training
Techniques

Application Do-
mains

Compliance and
Ethical Consider-
ations

Advanced Learn-
ing

Neural

Recurrent
Networks
Mixture of Experts

Multimodal Models
Supervised Learning

Unsupervised Learn-
ing
Reinforcement Learn-
ing
Transfer Learning

Language

Natural
Understanding
Natural
Generation
Conversational AI

Language

Creative AI

Bias Mitigation

Data Security

AI Ethics

Privacy Preservation

Self-supervised
Learning
Meta-learning
Fine Tuning

Human Value Align-
ment

Emerging Trends Multimodal Learning

Interactive and Coop-
erative AI

AGI Development

AGI Containment

Sequence Processing

Handling sequences of data, like text, for improved contextual understanding.

Specialization,
Efﬁciency
Sensory Integration
Data Labeling, Accu-
racy
Pattern Discovery

Adaptability,
Optimization
Versatility,
Generalization
Comprehension, Con-
textualization
Creativity, Coherence

Interaction, Natural-
ness
Innovation, Artistic
Generation
Fairness, Representa-
tion

Data Protection, Con-
ﬁdentiality
Fairness,
Accountability
Privacy Compliance,
Anonymization
Autonomy, Efﬁciency

Tuning,

Integration,

Rapid Adaptation
Domain-
Speciﬁc
Personalization
Ethical
Societal Alignment
Integration with Vi-
sion, Audio
Collaboration,
Human-AI
Interaction
Holistic Understand-
ing
Safety
Protocols,
Control Mechanisms

Leveraging multiple expert modules for enhanced efﬁciency and task-speciﬁc
performance.
Integrating text, vision, and audio inputs for comprehensive understanding.
Using labeled datasets to train models for precise predictions.

Finding patterns and structures from unlabeled data.

Training models through feedback mechanisms for optimal decision-making.

Applying knowledge gained in one task to different but related tasks.

Enhancing the ability to understand and interpret human language in context.

Generating coherent and contextually relevant text responses.

Developing systems for natural and contextually relevant human-computer
conversations.
Generating creative content, including text, art, and music.

Addressing and reducing biases in AI outputs.

Ensuring data conﬁdentiality, integrity and availability security in AI models
and outputs.
Addressing ethical
systems.
Protecting data privacy in model training and outputs.

issues such as bias, fairness, and accountability in AI

Utilizing unlabeled data for model training, enhancing learning efﬁciency.

Enabling AI models to quickly adapt to new tasks with minimal data.
Adapting models to speciﬁc domains or user preferences for enhanced relevance
and accuracy.

Aligning AI outputs with human ethics and societal norms, ensuring decisions
are ethically and socially responsible.
Combining language models with other sensory data types for richer under-
standing.
Enhancing AI’s ability to work alongside humans in collaborative tasks.

Pursuing the development of AI systems with comprehensive, human-like
understanding.
Developing methods to contain and control AGI systems to prevent unintended
consequences.

• Unsupervised Learning: Unsupervised learning is es-
sential in AI for uncovering patterns within unlabeled
to tasks like feature learning
data, a process central
and clustering [169], [170]. This method has seen sig-
niﬁcant advancements with the introduction of autoen-
coders [171], [172] and Generative Adversarial Networks
(GANs) [173], [174], [175], which have notably expanded
unsupervised learning’s applicability, enabling more so-
phisticated data generation and representation learning
capabilities. Such innovations are crucial for understand-
ing and leveraging the complex structures often inherent
in unstructured datasets, highlighting the growing versa-
tility and depth of unsupervised learning techniques.
• Reinforcement Learning: Reinforcement learning, char-
acterized by its adaptability and optimization capabilities,
has become increasingly vital in decision-making and

autonomous systems [176], [177]. This training technique
has undergone signiﬁcant advancements, particularly with
the development of Deep Q-Networks (DQN) [178],
[179], [180] and Proximal Policy Optimization (PPO)
algorithms [181], [182], [183]. These enhancements have
been crucial in improving the efﬁcacy and applicability
of reinforcement learning, especially in complex and
dynamic environments. By optimizing decisions and poli-
cies through interactive feedback loops, reinforcement
learning has established itself as a crucial tool for training
AI systems in scenarios that demand a high degree
of adaptability and precision in decision-making [184],
[185].

• Transfer Learning: Transfer learning emphasizes ver-
satility and efﬁciency in AI training, allowing models
to apply knowledge acquired from one task to different

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

9

yet related tasks, which signiﬁcantly reduces the need
for large labeled datasets [186], [187]. Transfer learning,
through the use of pre-trained networks, streamlines the
training process by allowing models to be efﬁciently
ﬁne-tuned for speciﬁc applications, thereby enhancing
adaptability and performance across diverse tasks, and
proving particularly beneﬁcial in scenarios where acquir-
ing extensive labeled data is impractical or unfeasible
[188], [189].

C. Application Domains

The application domains of Generative AI are remarkably
diverse and evolving, encompassing both established and
emerging areas of research and application. These domains
have been signiﬁcantly inﬂuenced by recent advancements in
AI technology and the expanding scope of AI applications.

• Natural Language Understanding (NLU): NLU is cen-
tral to enhancing the comprehension and contextualiza-
tion of human language in AI systems, and involves
key capabilities such as semantic analysis, named en-
tity recognition, sentiment analysis, textual entailment,
and machine reading comprehension [190], [191], [192],
[193]. Advances in NLU have been crucial in improving
AI’s proﬁciency in interpreting and analyzing language
across a spectrum of contexts, ranging from straightfor-
ward conversational exchanges to intricate textual data
[190], [192], [193]. NLU is fundamental in applications
like sentiment analysis, language translation, information
extraction, and more [194], [195], [196]. Recent advance-
ments have prominently featured large transformer-based
models like BERT and GPT-3, which have signiﬁcantly
advanced the ﬁeld by enabling a deeper and more com-
plex understanding of language subtleties [197], [198].
• Natural Language Generation (NLG): NLG em-
phasizes the training of models to generate coherent,
contextually-relevant, and creative text responses, a crit-
ical component in chatbots, virtual assistants, and auto-
mated content creation tools [199], [36], [200], [201].
NLG encompasses challenges such as topic model-
ing, discourse planning, concept-to-text generation, style
transfer, and controllable text generation [36], [202].
The recent surge in NLG capabilities, exempliﬁed by
advanced models like GPT-3, has signiﬁcantly enhanced
the sophistication and nuance of text generation, which
enable AI systems to produce text that closely mirrors
human writing styles, thereby broadening the scope and
applicability of NLG in various interactive and creative
contexts [203], [55], [51].

• Conversational AI: This subdomain is dedicated to
developing AI systems capable of smooth, natural, and
context-aware human-computer interactions, by focusing
on dialogue modeling, question answering, user intent
recognition, and multi-turn context tracking [204], [205],
[206], [207]. In ﬁnance and cybersecurity, AI’s predictive
analytics have transformed risk assessment and fraud
detection, leading to more secure and efﬁcient operations
[205], [19]. The advancements in this area, demonstrated

by large pre-trained models like Meena7 and BlenderBot8,
have signiﬁcantly enhanced the empathetic and respon-
sive capabilities of AI interactions. These systems not
only improve user engagement and satisfaction, but also
maintain the ﬂow of conversation over multiple turns,
providing coherent, contextually relevant, and engaging
experiences [208], [209].

• Creative AI: This emerging subdomain spans across text,
art, music, and more, pushing the boundaries of AI’s
creative and innovative potential across various modalities
including images, audio, and video, by engaging in the
generation of artistic content, encompassing applications
in idea generation, storytelling, poetry, music composi-
tion, visual arts, and creative writing, and has resulted in
commercial success like MidJourney and DALL-E [210],
[211], [212]. The challenges in this ﬁeld involve ﬁnding
suitable data representations, algorithms, and evaluation
metrics to effectively assess and foster creativity [212],
[213]. Creative AI serves not only as a tool for automating
and enhancing artistic processes, but also as a medium for
exploring new forms of artistic expression, enabling the
creation of novel and diverse creative outputs [212]. This
domain represents a signiﬁcant leap in AI’s capability to
engage in and contribute to creative endeavors, redeﬁning
the intersection of technology and art.

D. Compliance and Ethical Considerations

As AI technologies rapidly evolve and become more in-
tegrated into various sectors, ethical considerations and legal
compliance have become increasingly crucial, which requires a
focus on developing ‘Ethical AI Frameworks’, a new category
in our taxonomy reﬂecting the trend towards responsible AI
development in generative AI [214], [215], [15], [216], [217].
Such frameworks are crucial in ensuring AI systems are built
with a core emphasis on ethical considerations, fairness, and
transparency, as they address critical aspects such as bias
mitigation for fairness, privacy and security concerns for data
protection, and AI ethics for accountability, thus responding
to the evolving landscape where accountability in AI is of
paramount importance [214], [15]. The need for rigorous
approaches to uphold ethical integrity and legal conformity
has never been more pressing, reﬂecting the complexity and
multifaceted challenges introduced by the adoption of these
technologies [15].

• Bias Mitigation: Bias Mitigation in AI systems is a
critical endeavor to ensure fairness and representation,
which involves not only balanced data collection to
avoid skewed perspectives but also involves implementing
algorithmic adjustments and regularization techniques to
minimize biases [218], [219]. Continuous monitoring and
bias testing are essential
to identify and address any
biases that may emerge from AI’s predictive patterns
[220], [219]. A signiﬁcant challenge in this area is
dealing with intersectional biases [221], [222], [223] and

7https://neptune.ai/blog/transformer-nlp-models-meena-lamda-chatbots
8https://blenderbot.ai

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

10

understanding the causal interactions that may contribute
to these biases [224], [225], [226], [227].

• Data Security: In AI data security, key requirements and
challenges include ensuring data conﬁdentiality, adhering
to consent norms, and safeguarding against vulnerabilities
like membership inference attacks [228], [229]. Compli-
ance with stringent legal standards within applicable juris-
dictions, such as the General Data Protection Regulation
(GDPR) and California Consumer Privacy Act (CCPA),
is essential, necessitating purpose limitation and data
minimization [230], [231], [232]. Additionally, issues of
data sovereignty and copyright emphasize the need for
robust encryption, access control, and continuous security
assessments [233], [234]. These efforts are critical for
maintaining the integrity of AI systems and protecting
user privacy in an evolving digital landscape.

• AI Ethics: The ﬁeld of AI ethics focuses on fairness,
accountability, and societal impact, addresses the surge in
ethical challenges posed by AI’s increasing complexity
and potential misalignment with human values, and re-
quires ethical governance frameworks, multidisciplinary
collaborations, and technological solutions [214], [235],
[15], [236]. Furthermore, AI Ethics involves ensuring
traceability, auditability, and transparency throughout the
model development lifecycle, employing practices such as
algorithmic auditing, establishing ethics boards, and ad-
hering to documentation standards and model cards [237],
[236]. However, the adoption of these initiatives remains
uneven, highlighting the ongoing need for comprehensive
and consistent ethical practices in AI development and
deployment [214].

• Privacy Preservation: This domain focuses on maintain-
ing data conﬁdentiality and integrity, employing strategies
like anonymization and federated learning to minimize
direct data exposure, especially when the rise of genera-
tive AI poses risks of user proﬁling [238], [239]. Despite
these efforts, challenges such as achieving true anonymity
against correlation attacks highlight the complexities in
effectively protecting against intrusive surveillance [240],
[241]. Ensuring compliance with privacy laws and im-
plementing secure data handling practices are crucial in
this context, demonstrating the continuous need for robust
privacy preservation mechanisms.

E. Advanced Learning

Advanced learning techniques,

including self-supervised
learning, meta-learning, and ﬁne-tuning, are at the forefront
of AI research, enhancing the autonomy, efﬁciency, and ver-
satility of AI models.

• Self-supervised Learning: This method emphasizes au-
tonomous model training using unlabeled data, reducing
manual labeling efforts and model biases [242], [165],
[243]. It incorporates generative models like autoencoders
and GANs for data distribution learning and original
input reconstruction [244], [245], [246], and also includes
contrastive methods such as SimCLR [247] and MoCo
[248], designed to differentiate between positive and

negative sample pairs. Further, it employs self-prediction
strategies, inspired by NLP, using techniques like mask-
ing for input reconstruction, signiﬁcantly enhanced by
recent Vision Transformers developments [249], [250],
[165]. This integration of varied methods highlights self-
supervised learning’s role in advancing AI’s autonomous
training capabilities.

• Meta-learning: Meta-learning, or ‘learning to learn’,
centers on equipping AI models with the ability to
rapidly adapt to new tasks and domains using limited data
samples [251], [252]. This technique involves mastering
the optimization process and is critical in situations with
limited data availability, to ensure models can quickly
adapt and perform across diverse tasks, essential in the
current data-driven landscape [253], [254]. It focuses on
few-shot generalization, enabling AI to handle a wide
range of tasks with minimal data, underlining its impor-
tance in developing versatile and adaptable AI systems
[255], [256], [254], [257].

• Fine Tuning: Involves customizing pre-trained models to
speciﬁc domains or user preferences, enhancing accuracy
and relevance for niche applications [60], [258], [259].
Its two primary approaches are end-to-end ﬁne-tuning,
which adjusts all weights of the encoder and classiﬁer
[260], [261], and feature-extraction ﬁne-tuning, where
the encoder weights are frozen to extract features for
a downstream classiﬁer [262], [263], [264]. This tech-
nique ensures that generative models are more effectively
adapted to speciﬁc user needs or domain requirements,
making them more versatile and applicable across various
contexts.

• Human Value Alignment: This emerging aspect con-
centrates on harmonizing AI models with human ethics
and values to ensure that their decisions and actions
mirror societal norms and ethical standards, involving
the integration of ethical decision-making processes and
the adaptation of AI outputs to conform with human
moral values [265], [89], [266]. This is increasingly
important in scenarios where AI interacts closely with
humans, such as in healthcare, ﬁnance, and personal
assistants, to ensure that AI systems make decisions that
are not only technically sound, but also ethically and
socially responsible, which means human value alignment
is becoming crucial in developing AI systems that are
trusted and accepted by society [89], [267].

F. Emerging Trends

Emerging trends in generative AI research are shaping the
future of technology and human interaction, and they indicate
a dynamic shift
interactive, and
towards more integrated,
intelligent AI systems, driving forward the boundaries of what
is possible in the realm of AI. Key developments in this area
include:

• Multimodal Learning: Multimodal Learning in AI, a
rapidly evolving subdomain, focuses on combining lan-
guage understanding with computer vision and audio
processing to achieve a richer, multi-sensory context

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

11

awareness [114], [268]. Recent developments like Gem-
ini model have set new benchmarks by demonstrating
state-of-the-art performance in various multimodal tasks,
including natural image, audio, and video understanding,
and mathematical reasoning [112]. Gemini’s inherently
multimodal design exempliﬁes the seamless integration
and operation across different information types [112].
Despite the advancements, the ﬁeld of multimodal learn-
ing still confronts ongoing challenges, such as reﬁning
the architectures to handle diverse data types more ef-
fectively [269], [270], developing comprehensive datasets
that accurately represent multifaceted information [269],
[271], and establishing benchmarks for evaluating the
performance of these complex systems [272], [273].
• Interactive and Cooperative AI: This subdomain aims
to enhance the capabilities of AI models to collaborate ef-
fectively with humans in complex tasks [274], [35]. This
trend focuses on developing AI systems that can work
alongside humans, thereby improving user experience and
efﬁciency across various applications, including produc-
tivity and healthcare [275], [276], [277]. Core aspects of
this subdomain involve advancing AI in areas such as
explainability [278], understanding human intentions and
behavior (theory of mind) [279], [280], and scalable coor-
dination between AI systems and humans, a collaborative
approach crucial in creating more intuitive and interactive
AI systems, capable of assisting and augmenting human
capabilities in diverse contexts [281], [35].

• AGI Development: AGI, representing the visionary goal
of crafting AI systems that emulate the comprehensive
and multifaceted aspects of human cognition, is a sub-
domain focused on developing AI with the capability
for holistic understanding and complex reasoning that
closely aligns with the depth and breadth of human
cognitive abilities [282], [283], [32]. AGI is not just about
replicating human intelligence, but also involves crafting
systems that can autonomously perform a variety of tasks,
demonstrating adaptability and learning capabilities akin
to those of humans [282], [283]. The pursuit of AGI is a
long-term aspiration, continually pushing the boundaries
of AI research and development.

• AGI Containment: AGI Safety and Containment ac-
knowledges the potential risks associated with highly
advanced AI systems, focused on ensuring that these ad-
vanced systems are not only technically proﬁcient but also
ethically aligned with human values and societal norms
[15], [32], [11]. As we progress towards developing
superintelligent systems, it becomes crucial to establish
rigorous safety protocols and control mechanisms [11].
Key areas of concern include mitigating representational
biases, addressing distribution shifts, and correcting spu-
rious correlations within AI models [11], [284]. The
objective is to prevent unintended societal consequences
by aligning AI development with responsible and ethical
standards.

Training
Efﬁciency

Load
Balancing

Core Concept

Parallelism
Techniques

Future
Directions

Figure 4: Conceptual Diagram of MoE’s Innovation

IV. INNOVATIVE HORIZON OF MOE

The MoE model architecture represents a pioneering ad-
vancement in transformer-based language models, offering
unparalleled scalability and efﬁciency (Fig. 4). As evidenced
by recent models like the 1.6 trillion parameter Switch Trans-
former [285] and the 8x7B parameter Mixtra [286], MoE-
based designs are rapidly redeﬁning the frontiers of model
scale and performance across diverse language tasks.

A. Core Concept and Structure

MoE models represent a signiﬁcant innovation in neural
network design, offering enhanced scalability and efﬁciency in
training and inference [287], [288], [110]. At their core, MoE
models utilize a sparsity-driven architecture by replacing dense
layers with sparse MoE layers comprising multiple expert
networks, where each expert is dedicated to a speciﬁc subset
of the training data or task, and a trainable gating mechanism
dynamically allocates input tokens to these experts, thereby
optimizing computational resources and effectively adapting to
the task’s complexity [94], [21], [110]. MoE models demon-
strate a substantial advantage in terms of pretraining speed,
outperforming dense models [94], [287]. However, they face
challenges in ﬁne-tuning and require substantial memory for
inference due to the necessity of loading all experts into Video
Random Access Memory (VRAM) [289], [290], [110]. The
structure of MoE involves alternating transformer layers with
router layers containing gating networks for expert routing,
leading to an architecture that allows signiﬁcant parameter
scaling and advanced specialization in problem-solving [291],
[21].

A distinguishing characteristic of MoE models is their ﬂexi-
bility in managing large datasets, capable of amplifying model
capacity by over a thousand times while only experiencing
minor reductions in computational efﬁciency [289], [292]. The
Sparsely-Gated Mixture-of-Experts Layer, a key component
of these models, comprises numerous simple feed-forward
expert networks and a trainable gating network responsible for
expert selection, which can facilitate the dynamic and sparse
activation of experts for each input instance, maintaining high
computational efﬁciency [293], [294], [110].

Recent advancements in MoE models, such as those in the
Switch Transformer, have highlighted the signiﬁcant beneﬁts
of intelligent routing, when the router’s ability to intelligently

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

12

route tokens to appropriate experts confers considerable ad-
vantages to MoE models, allowing them to scale up model
sizes while keeping compute time constant [295], [296], [297].
Experimental evidence suggests that routers learn to route
inputs according to data clusters, demonstrating their potential
in real-world applications [295], [289]. The core concept
and structure of MoE models lie in their dynamic routing
and specialization capabilities, offering promising avenues for
scaling up neural networks and enhancing their efﬁciency and
adaptability in various tasks, but the robustness of the router
must be protected against adversarial attacks [289], [298].

B. Training and Inference Efﬁciency

MoE models, notably Mixtral 8x7B, are renowned for their
superior pretraining speed compared to dense models, yet they
face hurdles in ﬁne-tuning and demand considerable VRAM
for inference, owing to the requirement of loading all experts
[289], [290], [110]. Recent advancements in MoE architecture
have resulted in notable training cost efﬁciencies, especially in
encoder-decoder models, with evidence showing cost savings
of up to ﬁvefold in certain contexts when compared to dense
models [21], [289], [298], [287]. Innovations like DeepSpeed-
MoE [287] offered new architectural designs and model com-
pression, decreasing the MoE model size by approximately
3.7x and optimizing inference to achieve up to 7.3x better
latency and cost efﬁciency. The progression in distributed
MoE training and inference, notably with innovations like
Lina [299], has effectively tackled the all-to-all communication
bottleneck by enhancing tensor partitioning, which not only
improves all-to-all communication and training step time, but
also optimizes resource scheduling during inference, leading
to a substantial reduction in training step time by up to 1.73
times and lowering the 95th percentile inference time by an
average of 1.63 times compared to existing systems. These
developments have marked a crucial shift in the large model
landscape, from dense to sparse MoE models, expanding the
potential applications of AI by training higher-quality models
with fewer resources.

C. Load Balancing and Router Optimization

Effective load balancing is essential in MoE models to
guarantee a uniform distribution of computational load among
experts, with the router network in MoE layers, responsible for
selecting the appropriate experts for processing speciﬁc tokens,
playing a pivotal role in achieving this balance, which is funda-
mental to the stability and overall performance of MoE models
[293], [289], [288], [300], [110]. Developments in router Z-
loss regularization techniques plays a crucial role in addressing
expert imbalance in MoE models by ﬁne-tuning the gating
mechanism, ensuring a more equitable workload distribution
across experts and fostering a stable training environment,
thereby enhancing model performance and reducing training
time and computational overhead [301], [302]. Concurrently,
the integration of expert capacity management strategies,
emerges as a crucial approach in MoE models to regulate the
processing abilities of individual experts by setting thresholds
on the number of tokens each can handle, effectively averting

bottlenecks and ensuring a more efﬁcient and streamlined
model operation, leading to improved training processes and
heightened performance during complex computational tasks
[293], [303], [289].

D. Parallelism and Serving Techniques

Recent developments in MoE models highlighted their ef-
ﬁciency in parallelism and serving techniques, signiﬁcantly
inﬂuencing large-scale neural networks. DeepSpeed-MoE, for
instance, introduces advanced parallelism modes like data par-
allelism, tensor-slicing for non-expert parameters, and expert
parallelism for expert parameters, enhancing model efﬁciency,
as their approach optimizes both latency and throughput in
MoE model inference, offering scalable solutions in produc-
tion environments using multiple Graphics Processing Unit
(GPU) devices [287]. MoE models, versatile in applications
like multilingual tasks and coding, demonstrated impressive
capabilities in handling complex tasks due to their ensemble-
like structure within a single framework [304], [305], [306].
Notably, models like Mixtral and Switch Transformer, with
over 1.6 trillion parameters, achieved computational efﬁciency
equivalent to a 10 billion-parameter dense model, because
they beneﬁted from the sublinear scaling of MoE compute
versus model size, leading to substantial accuracy gains within
ﬁxed compute budgets [21], [289], [287], [110]. Moreover,
DeepSpeed-MoE included model compression techniques, re-
ducing model size by up to 3.7x while maintaining accuracy,
and an end-to-end MoE training and inference solution, part
of the DeepSpeed library, which was instrumental in serv-
ing large-scale MoE models with enhanced speed and cost-
efﬁciency [287]. These innovations open new directions in AI,
shifting from dense to sparse MoE models, where training and
deploying higher-quality models with fewer resources become
more widely achievable.

E. Future Directions and Applications

Emerging research on MoE architectures could focus on
advancing sparse ﬁne-tuning techniques, exploring instruction
tuning methods, and improving routing algorithms to fully
utilize performance and efﬁciency gains. As models scale
over one billion parameters, MoE represents a paradigm shift
for vastly expanding capabilities across scientiﬁc, medical,
creative, and real-world applications. Frontier work could also
aim to reﬁne auto-tuning of hyperparameters during ﬁne-
tuning to optimize accuracy, calibration, and safety. MoE re-
search continues to push model scale limits while maintaining
specialization for transfer learning. Adaptive sparse access
allows coordinating thousands of experts to cooperate on tasks
ranging from reasoning to open domain dialogue. Continued
analysis of routing mechanisms seeks to balance load across
experts and minimize redundant computation. As the AI
community further investigates MoE methods at scale, these
models hold promise for new breakthroughs in language, code
generation, reasoning, and multimodal applications. There
is great interest in evaluating implications across education,
healthcare, ﬁnancial analysis, and other ﬁelds. Outcomes may
yield insights not only into model optimization but also for
understanding principles behind combinatorial generalization.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

13

Human-Level
Understanding

Self-
Learning and
Exploration

General
Intelligence

Real-World
Knowledge
Integration

Common
Sense
Reasoning

Figure 5: Conceptual Diagram of Speculated Q* Capabilities

V. SPECULATED CAPABILITIES OF Q*

In the burgeoning realm of AI, the anticipated Q* project
stands as a beacon of potential breakthroughs, heralding ad-
vancements that could redeﬁne the landscape of AI capabilities
(Fig. 5).

A. Enhanced General Intelligence

Q*’s development in the arena of general intelligence rep-
resents a paradigm shift from specialized to holistic AI, indi-
cating a broadening of the model’s cognitive abilities akin to
human intelligence. This advanced form of general intelligence
involves integrating diverse neural network architectures and
machine learning techniques, enabling the AI to process and
synthesize multifaceted information seamlessly. The universal
adapter approach, mirroring models like T0, could endow
Q* with the capability to rapidly assimilate knowledge from
various domains. This method allows Q* to learn adaptable
module plugins, enhancing its ability to tackle new data
types while preserving existing skills, leading to an AI model
that combines narrow specializations into a comprehensive,
adaptive, and versatile reasoning system. The corresponding
quasi-mathematical formulation can be expressed as:

n

EGI(Q∗) =

(N Ni ⊙ M LTi)

M
i=1

(1)

Where:
• EGI: “Enhanced General Intelligence”
• N Ni: a diverse set of neural network architectures.
• M LTi: various machine learning techniques.
• L: the integration of these components.
• ⊙: a functional interaction between neural networks and

machine learning techniques.

Such advancements in AI suggest the emergence of an intel-
ligence that not only parallels but potentially exceeds human
cognitive ﬂexibility, with far-reaching implications in facil-
itating cross-disciplinary innovations and complex problem-
solving. The speculated capabilities of Q* bring forth com-
plex ethical implications and governance challenges. As AI
systems approach higher levels of autonomy and decision-
making, it is crucial to establish robust ethical frameworks and
governance structures to ensure responsible and transparent AI
development. This involves mitigating potential risks associ-
ated with advanced AI capabilities, emphasizing the need for

comprehensive and dynamic ethical guidelines that evolve in
tandem with AI advancements.

B. Advanced Self-Learning and Exploration

In the realm of advanced AI development, Q* is antici-
pated to represent a signiﬁcant evolution in self-learning and
exploration capabilities. It is speculated to utilize sophisticated
Policy Neural Networks (NNs), similar to those in AlphaGo,
but with substantial enhancements to handle the complexities
of language and reasoning tasks. These networks are expected
to employ advanced reinforcement learning techniques like
Proximal Policy Optimization (PPO), which stabilizes policy
updates and improves sample efﬁciency, a crucial factor in
autonomous learning. The integration of these NNs with
cutting-edge search algorithms, potentially including novel
iterations of Tree or Graph of Thought, is predicted to en-
able Q* to autonomously navigate and assimilate complex
information. This approach might be augmented with graph
neural networks to bolster meta-learning capacities, allowing
Q* to rapidly adapt to new tasks and environments while
retaining previously acquired knowledge. The corresponding
quasi-mathematical formulation can be represented as:

ASLE(Q∗) = RL(P N N, SA) × GN N

(2)

Where:
• ASLE: “Advanced Self-Learning and Exploration”
• RL: to reinforcement learning algorithms, particularly

Proximal Policy Optimization (PPO).

• P N N : Policy Neural Networks, adapted for language

and reasoning tasks.

• SA: sophisticated search algorithms, like Tree or Graph

of Thought.

• GN N : the incorporation of Graph Neural Networks for

meta-learning.

• ×: the cross-functional enhancement of RL with GNN.
Such capabilities indicate a model not limited to understand-
ing existing data but equipped to actively seek and synthesize
new knowledge, effectively adapting to evolving scenarios
without the need for frequent retraining. This signiﬁes a leap
beyond current AI models, embedding a level of autonomy
and efﬁciency previously unattained.

C. Superior Human-Level Understanding

Q*’s aspiration to achieve superior human-level under-
standing is speculated to hinge on an advanced integration
of multiple neural networks, including a Value Neural Net-
work (VNN), paralleling the evaluative components found in
systems like AlphaGo. This network would extend beyond
assessing accuracy and relevance in language and reasoning
processes, delving into the subtleties of human communica-
tion. The model’s deep comprehension capabilities may be
enhanced by advanced natural language processing algorithms
and techniques, such as those found in transformer architec-
tures like DeBERTa. These algorithms would empower Q* to
interpret not just the text but also the nuanced socio-emotional
aspects such as intent, emotion, and underlying meanings.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

14

Incorporating sentiment analysis and natural language infer-
ence, Q* could navigate layers of socio-emotional insights,
including empathy, sarcasm, and attitude. The corresponding
quasi-mathematical formulation can be expressed as:

SHLU (Q∗) = X

(V N N ⊕ alg)

(3)

alg∈N LP

Where:
• SHLU : “Superior Human-Level Understanding”.
• V N N : the Value Neural Network, similar to evaluative

components in systems like AlphaGo.
• N LP : a set of advanced NLP algorithms.
• ⊕: the combination of VNN evaluation with NLP algo-

rithms.

• alg: individual algorithms within the NLP set.
This level of understanding, surpassing current language
models, would position Q* to excel in empathetic, context-
aware interactions, thus enabling a new echelon of personal-
ization and user engagement in AI applications.

D. Advanced Common Sense Reasoning

Q*’s anticipated development in advanced common sense
reasoning is predicted to integrate sophisticated logic and
decision-making algorithms, potentially combining elements
of symbolic AI and probabilistic reasoning. This integration
aims to endow Q* with an intuitive grasp of everyday logic and
an understanding akin to human common sense, thus bridging
a signiﬁcant gap between artiﬁcial and natural intelligence.
Enhancements in Q*’s reasoning abilities might involve graph-
structured world knowledge, incorporating physics and social
engines similar to those in models like CogSKR. This ap-
proach, grounded in physical reality, is expected to capture
and interpret the everyday logic often absent in contemporary
AI systems. By leveraging large-scale knowledge bases and
semantic networks, Q* could effectively navigate and respond
to complex social and practical scenarios, aligning its infer-
ences and decisions more closely with human experiences and
expectations. The corresponding quasi-mathematical formula-
tion can be represented as:

ACSR(Q∗) = LogicAI ⊙ P robAI ⊙ W orldK (4)

Where:
• ACSR: “Advanced Common Sense Reasoning”.
• LogicAI and P robAI: symbolic AI and probabilistic

reasoning components, respectively.

• W orldK:

the integration of graph-structured world

knowledge.

• ⊙: the integrated operation of these elements for common

sense reasoning.

E. Extensive Real-World Knowledge Integration

Q*’s approach to integrating extensive real-world knowl-
edge is speculated to involve the use of advanced formal
veriﬁcation systems, which would provide a robust basis for
validating its logical and factual reasoning. This method, when

Understanding
and
Interaction

Autonomous
Learning

Cognitive
Abilities

Knowledge
Integration

Common
Sense
Reasoning

Figure 6: Conceptual Diagram of Projected AGI Capabilities

coupled with sophisticated neural network architectures and
dynamic learning algorithms, would enable Q* to engage
deeply with the complexities of the real world, transcending
conventional AI limitations. Additionally, Q* might employ
mathematical theorem proving techniques for validation, en-
suring that its reasoning and outputs are not only accurate but
also ethically grounded. The incorporation of Ethics classiﬁers
in this process further strengthens its capacity to deliver
reliable and responsible understanding and interaction with
real-world scenarios. The corresponding quasi-mathematical
formulation can be represented as:

ERW KI(Q∗) = F V S ⊗ N N ⊗ LT P ⊗ EC

(5)

Where:
• ERW KI: “Extensive Real-World Knowledge Integra-

tion”.

• F V S: Formal Veriﬁcation Systems.
• N N : neural network architectures.
• LT P : mathematical
factual validation.

theorem proving for logical and

• EC: the incorporation of Ethics classiﬁers.
• ⊗: the comprehensive integration for knowledge synthesis

and ethical alignment.

Furthermore, the speculated capabilities of Q* have the
potential to signiﬁcantly reshape the job market and labor
dynamics. With its advanced functionalities, Q* could auto-
mate complex tasks, leading to a shift in job requirements and
the emergence of new skill demands. This necessitates a re-
evaluation of workforce strategies and educational paradigms,
aligning them with the evolving technological landscape and
ensuring that the workforce is equipped to interact with and
complement these advanced AI systems.

VI. PROJECTED CAPABILITIES OF AGI

AGI stands as a transformative leap in AI, endeavoring
to mirror human cognitive abilities in a software paradigm
(Fig. 6). AGI’s evolution is marked by advanced self-learning
capabilities, utilizing policy neural networks and sophisticated
reinforcement learning techniques for autonomous adaptation.
The integration of algorithms like Tree/Graph of Thought with
these networks suggests a future where AGI can independently
acquire and apply knowledge across diverse domains.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

15

A. Revolution in Autonomous Learning

F. Challenges and Opportunities in AGI Development

AGI is anticipated to revolutionize self-learning and ex-
ploration [282], [307], [283], [32]. By incorporating methods
like PPO, AGI models are positioned to achieve a level of
autonomous learning and problem-solving that exceeds the
current AI models’ dependence on training data, indicating a
potential paradigm shift towards reducing the need for frequent
retraining and facilitating dynamic adaptation in response to
evolving scenarios [181], [308].

B. Broadening of Cognitive Abilities

Envisaged to integrate various architectures, AGI could
promise a level of general intelligence that replicates the multi-
faceted nature of human cognition [282], [309]. The universal
adapter approach, mirroring models like GPT and BERT, could
facilitate rapid assimilation of diverse information, positioning
AGI as a system capable of performing tasks across multiple
domains with an adaptability akin to human intellect [282],
[310]. While AGI’s full capabilities remain speculative, current
trends suggest its potential application in advanced healthcare
diagnostics, which is evidenced by recent breakthroughs in AI-
driven predictive medicine models, indicating AGI’s potential
to revolutionize medical diagnosis and treatment.

C. Elevating Understanding and Interaction

AGI is projected to achieve an unparalleled understanding
of human language and socio-emotional subtleties, leverag-
ing algorithms like those in transformer architectures, which
would enable AGI to engage in complex, empathetic, and con-
textually aware interactions, suggesting potential applications
that revolutionize how AI systems communicate and interact
[282], [307], [311].

The development of AGI encompasses both challenges
and opportunities. While AGI promises productivity boosts
in creative ﬁelds and innovations in cross-modal generation
techniques, substantial challenges like data bias, computational
efﬁciency, and ethical implications persist [15], [32]. These
challenges necessitate a balanced approach in AGI develop-
ment, focusing on data curation, efﬁcient systems, and societal
impacts [309].

In the context of AGI development, experts from various
domains caution against overestimating current AI capabilities
and highlight the gap between the theoretical framework of
AGI and the practical realities of today’s AI [314], [32]. The
envisioned autonomy and cognitive abilities of AGI separate it
from current AI models, suggesting a future where AI systems
could perform tasks across various domains without human
intervention [282]. This development trajectory underscores
the importance of ethical considerations and technological
breakthroughs in AGI’s journey towards becoming a transfor-
mative force in society [15], [32]. While projecting the time-
line for achieving true AGI remains speculative, recognizing
potential roadblocks is crucial, such as the current limitations
in computational power, and the complexity of replicating
human-like cognitive abilities. These emphasize the need for
sustained research and ethical considerations in the pursuit of
AGI, ensuring responsible and conscientious development.

VII. IMPACT ANALYSIS ON GENERATIVE AI RESEARCH
TAXONOMY

With the advent of advanced AI developments such as
MoE, multimodality, and AGI, the landscape of Generative
AI research is undergoing a signiﬁcant transformation. This
section analyzes how these developments are reshaping the
research taxonomy in generative AI.

D. Advanced Common Sense Reasoning

A. Criteria for Impact Analysis

Symbolic AI and probabilistic reasoning, integrated into
AGI, could imbue these systems with an innate grasp of
common sense, to bridge the gap between artiﬁcial and natural
intelligence, enabling AGI to navigate and respond effectively
to real-world scenarios with reasoning aligned closely with
human thought processes [282], [312], [313].

E. Holistic Integration of Knowledge

AGI’s potential in integrating extensive real-world knowl-
edge, guided by formal veriﬁcation systems, hints at future
capabilities where AGI’s outputs are not only accurate but
ethically grounded, suggesting AGI’s ability for responsible
interaction with real-world complexities [282], [311]. The
projected capabilities of AGI extend to addressing signiﬁcant
global challenges, such as climate change, in which AGI’s
advanced data analysis and predictive modeling can play a
better and more crucial role in environmental monitoring, fore-
casting climate patterns, and devising sustainable solutions,
contributing signiﬁcantly to global ecological efforts [282],
[283], [32].

The continuously evolving landscape of Generative AI,
which instigates transformative changes across various re-
search domains, necessitates a systematic evaluation of these
advancements’ inﬂuence, for which we have established a set
of criteria detailed in Table II, serving as analytical lenses
to quantify and categorize the impact, deeply rooted in the
dynamic interplay between technological progress and the
evolving paradigms of research focus areas. Our analysis
framework has been constructed on a gradient scale ranging
from emergent to obsolete, reﬂecting the extent to which
areas of Generative AI research are being reshaped. The
categorization into ﬁve distinct classes allows for a complex
assessment, acknowledging that not all areas will be uniformly
affected. This multi-tiered approach is informed by historical
patterns of technological disruption and the adaptability of
scientiﬁc inquiry.

At the apex of our evaluative hierarchy, ‘Emerging Direc-
tion’ encapsulates the advent of uncharted research vistas,
propelled by ongoing AI breakthroughs, which is predicated
not on conjecture, but on a historical continuum of AI evo-
lution, where each surge in technological power unfurls new

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

16

Table II: Criteria for Analyzing Impact on Generative AI Research

Symbol
ր

֒→

↔

ց

△

Criteria
Emerging Direc-
tion
Requiring Redi-
rection

Still Relevant

to

Likely
Become
Redundant
Inherently Unre-
solvable

Score
5

4

3

2

1

Deﬁnition
New research areas expected to arise as a
direct consequence of AI advancements.
Areas that need to shift focus or methodol-
ogy to stay relevant with new AI develop-
ments.
Areas where the advancements have mini-
mal or no impact, maintaining their current
status and methodologies.
Areas that may lose relevance or become
obsolete with the advent of new AI tech-
nologies.
Challenges that may remain unresolved due
to complexities like subjective human per-
spectives and diverse cultural values.

Justiﬁcation
Emphasizes novel research domains emerging from AI break-
throughs [315], [316].
Technological shifts necessitate reevaluation and redirection
in AI research [315], [317].

Observes the persistence of certain AI research areas despite
technological advancements [317].

Discusses rapid obsolescence in AI methodologies due to new
technologies [318].

Inherent difﬁculties in issues such as aligning AI with diverse
human values and ethics [319], [320].

scientiﬁc enigmas and avenues [315], [316]. ‘Areas Requiring
Redirection’ denote research spheres that, though established,
ﬁnd themselves at an inﬂection point, necessitating a strategic
pivot to assimilate emergent AI paradigms and an overhaul
of traditional methodologies, akin to the transition from rule-
based expert systems to adaptive machine learning frameworks
[315], [317]. The ‘Still Relevant’ classiﬁcation afﬁrms the
tenacity of select research domains that, by addressing persis-
tent scientiﬁc inquiries or through their inherent malleability,
remain impervious to the tides of AI innovation [317]. In
contrast, domains categorized as ‘Likely to Become Redun-
dant’ confront potential obsolescence, inviting strategic fore-
sight and resource reallocation to forestall scientiﬁc stagnation
[318]. Lastly, ‘Inherently Unresolvable’ challenges serve as
a sobering reminder of the perpetual dilemmas within AI
research that defy resolution, rooted in the complex web of
human ethics and cultural diversity, thus anchoring the pursuit
of AI within the intractable tapestry of human values and
societal imperatives [319], [320].

B. Overview of Impact Analysis

This subsection offers a detailed overview of the impact
analysis carried out on the research taxonomy within the realm
of generative AI, with a speciﬁc focus on recent progress
in MoE, multimodality, and AGI, aiming to evaluate the
impact of these innovative developments on various facets
of generative AI research, ranging from model architecture
to sophisticated learning methodologies, and includes both
quantitative and qualitative assessments across a multitude of
domains and subdomains in LLM research, shedding light on
the extent to which each area is inﬂuenced by these techno-
logical advancements. This evaluation considered factors such
as the emergence of new research directions, the necessity for
redirection in existing research areas, the continued relevance
of certain methodologies, and the potential redundancy of
others, and has encapsulated in Table III.

1) Impact On Model Architecture: Transformer Models
have been scored with a redirection requirement (֒→) of 4 in
both MoE and AGI, and a relevance (↔) of 3 in multimodality,
leading to an overall score of 11. These models, forming the
backbone of many current AI architectures, continue to be
relevant for handling complex input sequences. However, the
emergence of MoE and AGI indicates a shift towards more

dynamic and specialized architectures. While transformers re-
main essential, there is a need for them to evolve and integrate
with these advanced systems for enhanced performance and
adaptability.

Recurrent Neural Networks (RNNs) are facing a potential
decline in relevance, as indicated by their scores: likely to
become redundant (ց) 2 in both MoE and AGI contexts
and still relevant (↔) 3 in multimodality, totaling a score
of 7. Although effective for sequence processing, RNNs are
challenged by their limitations in handling long-range depen-
dencies and lower efﬁciency compared to newer models like
transformers. They may retain some relevance in multimodal
tasks involving sequential data but are generally overshadowed
by more advanced architectures.

The MoE models have scored a consistent relevance (↔)
of 3 in their own development and a score of 5 (ր) in
multimodality, combined with a redirection score (֒→) of 4
in the context of AGI, amounting to an overall score of 12.
MoE models are at the forefront of emerging research in
multimodality due to their ability to handle diverse data types.
For AGI, these models will require adjustments to effectively
integrate into systems exhibiting general intelligence, espe-
cially in areas beyond their initial specialization.

Multimodal Models have received high scores for emerging
research directions (ր) of 5 in both MoE and AGI contexts,
alongside a score of 3 (↔) for current relevance in multi-
modality, culminating in an overall score of 13. The integration
of MoE and the pursuit of AGI are opening new pathways
for research in multimodal models. These developments are
crucial for enhancing the ability to process and synthesize
information from multiple modalities, a key aspect for both
specialized and generalized AI systems.

2) Impact On Training Techniques: Supervised Learning
has been assigned a redirection score (֒→) of 4, a relevance
score (↔) of 3 in multimodality, and a score indicating poten-
tial redundancy (ց) of 2 in the context of AGI, culminating
in an overall score of 9. While supervised learning requires
adaptation to ﬁt the MoE framework, it remains relevant for
multimodal AI models that depend on labeled data. However,
with the shift towards more autonomous learning methods in
AGI, the dependence on extensive labeled datasets typically
associated with supervised learning may diminish, leading to
its potential decrease in signiﬁcance.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

17

Table III: Impact of MoE, Multimodality, and AGI on Generative AI Research

Domain
Model Architecture

Training Techniques

Application Domains

Compliance and Ethical Considerations

Advanced Learning

Emerging Trends

Subdomain
Transformer Models
Recurrent Neural Networks
Mixture of Experts
Multimodal Models
Supervised Learning
Unsupervised Learning
Reinforcement Learning
Transfer Learning
Natural Language Understanding
Natural Language Generation
Conversational AI
Creative AI
Bias Mitigation
Data Security
AI Ethics
Privacy Preservation
Self-supervised Learning
Meta-learning
Fine Tuning
Human Value Alignment
Multimodal Learning
Interactive and Cooperative AI
AGI Development
AGI Containment

MoE Multimodality
֒→ (4)
ց (2)
↔ (3)
ր (5)
֒→ (4)
֒→ (4)
↔ (3)
↔ (3)
↔ (3)
↔ (3)
֒→ (4)
֒→ (4)
֒→ (4)
↔ (3)
֒→ (4)
֒→ (4)
֒→ (4)
↔ (3)
↔ (3)
△ (1)
ր (5)
֒→ (4)
֒→ (4)
△ (1)

↔ (3)
↔ (3)
ր (5)
↔ (3)
↔ (3)
↔ (3)
֒→ (4)
ր (5)
↔ (3)
֒→ (4)
ր (5)
ր (5)
֒→ (4)
↔ (3)
֒→ (4)
֒→ (4)
ր (5)
↔ (3)
↔ (3)
△ (1)
↔ (3)
↔ (3)
֒→ (4)
△ (1)

AGI
֒→ (4)
ց (2)
֒→ (4)
ր (5)
ց (2)
֒→ (4)
ր (5)
֒→ (4)
ր (5)
ր (5)
ր (5)
ր (5)
ր (5)
↔ (3)
△ (1)
֒→ (4)
↔ (3)
ր (5)
ց (2)
△ (1)
ր (5)
ր (5)
↔ (3)
ր (5)

Overall Score
11
7
12
13
9
11
12
12
11
12
14
14
13
9
9
12
12
11
8
3
13
12
11
7

Unsupervised Learning scores a redirection requirement
(֒→) of 4 in both MoE and AGI contexts and maintains its
relevance (↔) with a score of 3 in multimodality, resulting in a
total score of 11. In the MoE architecture, unsupervised learn-
ing methods may need adjustments, particularly in managing
dynamic task allocation. It remains crucial for understanding
unlabeled data across various modalities. In AGI, unsupervised
learning is expected to evolve beyond traditional techniques,
focusing on more advanced self-discovery and intrinsic learn-
ing mechanisms.

Reinforcement Learning is rated as still relevant (↔) with
a score of 3 in MoE, requiring redirection (֒→) with a
score of 4 in multimodality, and identiﬁed as an emerging
research area (ր) with a score of 5 in AGI, giving it a total
score of 12. This technique continues to play a signiﬁcant
role in optimizing MoE model structures. In the realm of
multimodality, it necessitates a strategic shift to effectively
manage complex interactions between different modalities. As
for AGI, reinforcement learning is emerging as a crucial area,
particularly in the development of autonomous systems that
learn from their environment.

Transfer Learning receives a consistent relevance score (↔)
of 3 in MoE, a high score for emerging research directions
(ր) of 5 in multimodality, and a redirection requirement
(֒→) of 4 in AGI, accumulating to an overall score of 12.
It remains important in the MoE framework for leveraging
knowledge across different experts. In multimodal contexts,
transfer learning is becoming increasingly crucial as it facili-
tates the transfer of learning between different modalities. With
the evolution of AGI, this technique is expected to undergo
signiﬁcant changes to cater to broader and more generalized
knowledge applications.

3) Impact On Application Domains: Natural Language
Understanding holds steady relevance (↔) with a score of 3 in
both MoE and multimodality, and an emerging direction (ր)
score of 5 in AGI, totaling an overall score of 11. MoE models
support the relevance of NLU by enhancing its precision and
depth through their ability to handle large, diverse datasets.
In multimodal AI, NLU remains a critical component for
comprehending language in diverse data formats. With AGI’s
progress, NLU is expected to undergo signiﬁcant expansion,
moving towards more advanced, human-like comprehension
and interpretation capabilities.

Natural Language Generation maintains relevance (↔) with
a score of 3 in MoE, requires redirection (֒→) with a score of
4 in multimodality, and is identiﬁed as an emerging research
area (ր) with a score of 5 in AGI, resulting in a total score of
12. MoE’s scalability is crucial for enhancing NLG, while in
multimodal contexts, NLG may need strategic adjustments to
align effectively with other modalities. As AGI evolves, NLG
is anticipated to venture into new research domains, especially
that reﬂects human-like creativity and
in creating content
adaptability.

Conversational AI is marked for redirection (֒→) with a
score of 4 in MoE, emerging research directions (ր) with
a score of 5 in both multimodality and AGI, accumulating
an overall score of 14. While MoE enhances conversational
AI, it may require strategic changes to fully utilize MoE’s
distributed expertise. The integration of multiple modalities
opens new avenues for conversational AI, expanding its scope
to include various sensory data. The development of AGI is
set to bring revolutionary advancements in this domain, paving
the way for more autonomous, context-aware, and human-like
interactions.

Creative AI scores a redirection requirement (֒→) of 4 in

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

18

MoE, and high scores for emerging research directions (ր) of
5 in both multimodality and AGI, leading to a total score of 14.
In the context of MoE, Creative AI may need to be realigned
to capitalize on MoE’s capacity for generating novel content.
The combination of different modalities in creative AI presents
exciting new research opportunities, enabling the creation of
more intricate and diverse outputs. As AGI progresses, it is
expected to signiﬁcantly broaden the capabilities of creative
AI, potentially surpassing existing boundaries and exploring
new realms of creativity.

4) Impact On Compliance and Ethical Considerations:
Bias Mitigation in the context of MoE, multimodality, and
AGI scores a redirection requirement (֒→) of 4 in both MoE
and multimodality, and an emerging research direction (ր)
with a score of 5 in AGI, resulting in an overall score of 13.
MoE architectures demand a new approach in bias mitigation
due to the diversity of expert networks, which could other-
wise amplify biases. In multimodal systems, bias mitigation
requires novel strategies to address biases in various data
types, including non-textual forms like images and audio. With
AGI’s broad cognitive capabilities, a comprehensive approach
towards understanding and addressing biases across diverse
domains is emerging as a critical research area.

Data Security maintains a consistent relevance (↔) with
a score of 3 across MoE, multimodality, and AGI, leading
to a total score of 9. The fundamental principles of data
security remain crucial despite the advancements in MoE,
which may necessitate tailored strategies for its distributed
nature. In multimodal AI, the secure handling of diverse data
types continues to be of paramount importance. The core
tenets of data security are sustained even with the advancement
of AGI, though the complexity and scope of security measures
are likely to increase.

AI Ethics is marked for redirection (֒→) with a score
of 4 in both MoE and multimodality, and faces inherently
unresolvable challenges (△) with a score of 1 in AGI, accu-
mulating a total score of 9. The decision-making processes
and transparency of MoE models necessitate a reevaluation
of ethical considerations. In multimodal AI, ethical concerns,
particularly in the interpretation and use of multimodal data,
require new approaches. The ethical challenges in AGI are
expected to be complex and involve deep philosophical and
societal implications that might be difﬁcult to fully resolve.

Privacy Preservation scores a redirection need (֒→) of 4
across MoE, multimodality, and AGI, leading to an overall
score of 12. The distributed nature of MoE systems requires a
reassessment of privacy preservation techniques to handle data
processed by multiple experts. Multimodal AI systems, espe-
cially those handling sensitive data such as images and sounds,
necessitate tailored privacy strategies. With the extensive data
processing capabilities of AGI, advanced and potentially new
approaches to privacy preservation are called for.

5) Impact On Advanced Learning: In the context of MoE,
self-supervised learning requires redirection (֒→) with a score
of 4, signaling the need to adapt to the evolving architecture.
Emerging research directions (ր) with a score of 5 are iden-
tiﬁed in multimodality, suggesting the integration of various
autonomous data types like text, image, and audio. For AGI,

self-supervised learning remains relevant (↔) with a score
of 3, contributing to the system’s autonomy and adaptability,
though likely to be integrated with more complex strategies.
The overall impact score is 12.

Meta-learning maintains consistent relevance (↔) with a
score of 3 across MoE and multimodality, aligning well with
the dynamic nature of MoE and aiding quick adaptation to
varying data types and tasks in multimodal contexts. In AGI,
it is marked as an emerging research direction (ր) with a
score of 5, suggesting novel research in achieving human-like
adaptability and learning efﬁciency. The total score for meta-
learning is 11.

Fine tuning continues to be relevant (↔) with a score
of 3 in both MoE and multimodality, being essential for
adapting pre-trained models to speciﬁc tasks and tailoring
multimodal models. However, in AGI, it is likely to become
redundant (ց) with a score of 2, as AGI aims to develop
systems that autonomously understand and learn across a
broad range of domains, reducing the need for traditional ﬁne-
tuning processes. The overall impact score for ﬁne tuning is
8.

Aligning AI with human values poses inherently unresolv-
able challenges (△) in all contexts—MoE, multimodality, and
AGI—with a score of 1. This reﬂects the complexity and
diversity of tasks MoE models handle,
the integration of
various data types in multimodal AI, and the broad range
of cognitive abilities encompassed by AGI. These factors
contribute to the signiﬁcant ongoing challenges in aligning
AI with human values, resulting in a total score of 3.

6) Impact On Emerging Trends: Multimodal learning is
marked as an emerging research direction (ր) with a score
of 5 in both MoE and AGI contexts, reﬂecting its capacity to
integrate various data types such as text, images, and audio.
This integration is crucial for specialized tasks in MoE and
processing diverse forms of data in AGI. In the realm of
multimodality, it remains a core aspect (↔) with a score of 3,
being essential for ongoing multimodal AI development. The
overall impact score is 13.

Interactive and Cooperative AI requires redirection (֒→) in
MoE with a score of 4, as MoE models adapt to include more
interactive elements for broader applications. In multimodality,
interaction and cooperation continue to be central (↔) with
a score of 3, especially in ﬁelds like robotics and virtual
assistants. AGI’s evolution includes signiﬁcant advancements
in interactive AI, marking it as an emerging research area (ր)
with a score of 5. The total score for this trend is 12.

The development of AGI necessitates redirection (֒→) in
both MoE and multimodality, each with a score of 4, indicating
the need for more integrated and complex systems. AGI
remains at the forefront of its own ﬁeld (↔) with a score
of 3, with each breakthrough directly inﬂuencing its progress.
The overall impact score for AGI development is 11.

AGI containment is identiﬁed as a challenge not required to
be solved (△) in both MoE and multimodality, with a score
of 1, as these areas are not expected to reach the levels of
autonomy and complexity associated with AGI. However, as
AGI progresses, the emerging need for effective containment
strategies is marked (ր) with a score of 5, highlighting the

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

19

importance of ensuring safe and controlled AI deployment.
The total impact score is 7.

effectively engage with and leverage the advancements in
AI, equipping them with the necessary skills to navigate its
complexities and innovations.

VIII. EMERGENT RESEARCH PRIORITIES IN GENERATIVE
AI

As we are likely to approach the precipice of a new
era marked by the advent of Q*, nudging us closer to the
realization of usable AGI, the research landscape in generative
AI is undergoing a crucial transformation.

A. Emergent Research Priorities in MoE

The MoE domain is increasingly focusing on two critical

areas:

• Multimodal Models in Model Architecture: The in-
tegration of MoE and AGI is opening new pathways
for research in multimodal models. These developments
are enhancing the capability to process and synthesize
information from multiple modalities, which is crucial
for both specialized and generalized AI systems.

• Multimodal Learning in Emerging Trends: MoE is at
the forefront of multimodal learning, integrating diverse
data types like text, images, and audio for specialized
tasks. This trend is directly impacting the enhancement
of the ﬁeld.

Furthermore, an analysis of funding trends and investment
patterns in AI research could indicate a substantial shift
towards areas like multimodal models in MoE. This trend,
characterized by increased capital ﬂow into ﬁelds involving
complex data processing and autonomous systems, is shaping
the direction of future research priorities. It underscores the
growing interest and investment in the potential of generative
AI, inﬂuencing both academic and industry-led initiatives.

B. Emergent Research Priorities in Multimodality

In the realm of multimodality, several areas are identiﬁed

as emerging research priorities:

• MoE in Model Architecture: MoE models are becoming
increasingly relevant for handling diverse data types in
multimodal contexts.

• Transfer Learning in Training Techniques: Transfer
learning is emerging as a key research direction, espe-
cially for learning between different modalities.

• Conversational AI and Creative AI in Application
Domains: Both conversational AI and creative AI are
expanding in multimodal contexts, encompassing visual,
auditory, and other sensory data integration.

• Self-Supervised Learning in Advanced Learning: New
research directions in self-supervised learning are emerg-
ing, focusing on the integration of various data types
autonomously.

Additionally, the rise of generative AI, particularly in multi-
modal contexts, can signiﬁcantly impact educational curricula
and skill development. There is a growing need to update
academic programs to include comprehensive AI literacy,
with a focus on multimodal AI technologies. This evolution
in education is aimed at preparing future professionals to

C. Emergent Research Priorities in AGI

The AGI domain is witnessing a surge in research priorities

across multiple areas:

• Multimodal Models in Model Architecture: Similar to
MoE, multimodal models are crucial in AGI, enabling
deeper and more nuanced understanding.

• Reinforcement Learning in Training Techniques:
Emerging as a key area in AGI, reinforcement learning
focuses on developing autonomous systems learning from
their environment.

• Application Domains: AGI is extending the boundaries
of natural language understanding and generation, conver-
sational AI, and creative AI, with a focus on human-like
comprehension and creativity.

• Bias Mitigation in Compliance and Ethical Consid-
erations: New directions in bias mitigation are focusing
on a comprehensive approach to addressing biases across
diverse domains in AGI.

• Meta-Learning in Advanced Learning: AGI’s pursuit
of human-like adaptability is leading to novel research in
meta-learning.

• Emerging Trends: Multimodal learning, interactive and
cooperative AI, and AGI containment strategies are be-
coming crucial research areas as AGI progresses.

In line with these developments in AGI, a noticeable trend in
AI research funding and investment patterns is evident. There
is a signiﬁcant inclination towards supporting projects and
studies in AGI, particularly in areas such as natural language
understanding and generation, and autonomous systems. This
funding trend not only mirrors the escalating interest in the
capabilities of AGI but also directs the trajectory of future
research, shaping both academic exploration and industry-
driven projects.

IX. PRACTICAL IMPLICATIONS AND LIMITATIONS OF
GENERATIVE AI TECHNOLOGIES

Generative AI technologies, encompassing MoE, multi-
modality, and AGI, present unique computational challenges.
This section explores the processing power requirements,
memory usage, and scalability concerns inherent
in these
advanced AI models.

A. Computational Complexity and Real-world Applications of
Generative AI Technologies

1) Computational Complexity: Generative AI technologies,
encompassing MoE, multimodality, and AGI, present unique
computational challenges. This section explores the processing
power requirements, memory usage, and scalability concerns
inherent in these advanced AI models.

• Processing Power Requirements: Advanced generative
AI models, including MoE architectures and AGI sys-
tems, require signiﬁcant processing power [321]. The

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

20

demand for GPUs and TPUs is accentuated, particularly
when handling complex computations and large datasets
typical in multimodal AI applications.

2) Existing Industry Solutions: Generative AI is reshaping
various industries by offering innovative solutions and altering
market dynamics.

• Memory Usage in AI Modeling: A critical challenge in
training and deploying large-scale AI models, particularly
in multimodal and AGI systems executed on GPUs,
lies in the substantial GPU and VRAM requirements.
Unlike computer RAM, VRAM often cannot be expanded
easily on many platforms, posing signiﬁcant constraints.
Developing strategies for GPU and VRAM optimization
and efﬁcient model scaling is thus crucial for the practical
deployment of these AI technologies.

• Scalability and Efﬁciency in AI Deployment: Address-
ing scalability challenges in generative AI, especially in
MoE and AGI contexts, involves optimizing load man-
agement and parallel processing techniques. This is vital
for their practical application in ﬁelds like healthcare,
ﬁnance, and education.

2) Real-world Application Examples of Generative AI Tech-
nologies: The application of generative AI models in real-
world scenarios demonstrates their transformative potential
and challenges in various sectors.

• Healthcare: In healthcare, generative AI facilitates ad-
vancements in diagnostic imaging and personalized
medicine, but also raises signiﬁcant concerns regarding
data privacy and the potential for misuse of sensitive
health information [322].

• Finance: The use of AI for fraud detection and al-
gorithmic trading in ﬁnance underlines its efﬁciency
and accuracy, while at the same time, it raises ethical
concerns, particularly in automated decision-making pro-
cesses, which may lack transparency and accountability
[323].

• Education: Generative AI’s role in creating personalized
learning experiences offers immense beneﬁts in terms of
educational accessibility and tailored instruction. How-
ever, it poses challenges in equitable access to technology,
potential biases in AI-Generated Content (AIGC), and
could reduce demand for human educators. Addition-
ally, there’s a growing concern about educators who are
against the use of AIGC, fearing it may undermine tradi-
tional teaching methodologies and the role of educators.

B. Commercial Viability and Industry Solutions in Generative
AI Technologies

1) Market Readiness: Assessing the market readiness of
generative AI technologies involves analyzing cost, accessi-
bility, deployment challenges, and user adoption trends.

• Cost Analysis: The ﬁnancial aspects of deploying gen-
erative AI, including MoE, multimodality, and AGI, are
crucial for market adoption.

• Accessibility and Deployment: Integration of these tech-
nologies into existing systems and the technical expertise
required are key factors inﬂuencing their adoption.

• User Adoption Trends: Understanding current adoption
patterns provides insights into market acceptance and the
role of user trust and perceived beneﬁts.

• Sector-Wise Deployment: The diverse applications of
generative AI, from digital content creation to process
streamlining, also raise questions about originality and
intellectual property rights.

• Impact on Market Dynamics: The effect of AI solutions
on traditional industry structures and the introduction of
novel business models are signiﬁcant considerations.
• Challenges and Constraints: Addressing limitations
such as scalability, data management complexity, privacy
concerns, and ethical implications is essential for robust
governance frameworks.

C. Limitations and Future Directions in Generative AI Tech-
nologies

1) Technical Limitations: Identifying and addressing tech-
nical limitations in generative AI models is crucial for their
advancement and reliability.

• Contextual Understanding: Enhancing AI’s ability to
understand and interpret context, especially in natural
language processing and image recognition, is a key area
for improvement.

• Handling Ambiguous Data: Developing better algo-
rithms for processing ambiguous or incomplete data sets
is essential for decision-making accuracy and reliability.
• Navigating Human Judgment: Despite generative AI’s
accuracy in interpreting policies and procedures, its im-
pact is limited in replacing human judgment. This is
especially true in legal and political contexts where
decision-makers might selectively use AIGC, leading to
biased outcomes. Thus, the effectiveness of generative AI
in such scenarios should be realistically assessed.

2) Future Research Directions to Enhance the Practicality
of Generative AI: Future research in generative AI should
focus on addressing current
limitations and expanding its
practical applications.

• Improved Contextual Understanding: Research should
aim at developing models with better contextual aware-
ness, particularly in complex natural language and image
processing tasks.

• Robust Handling of Ambiguous Data: Investigating
techniques for effective processing of ambiguous data is
vital for advancing the decision-making capabilities of AI
models.

• Ethical Integration of AIGC in Legal and Political
Arenas: Future research should focus on the ethical
integration of AI-generated content into legal and political
decision-making processes, which involves developing
frameworks that utilize AIGC in a supportive role, en-
suring it enhances human judgment and contributes to
transparency and fairness [324]. Importantly, researchers
should consider the biases and limitations inherent in AI
[324], alongside the potential for human fallibility, ethical
complexities, and possible corruption in these domains.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

21

s
t
n
i
r
p
e
r
P

f
o

r
e
b
m
u
N

100k

80k

60k

40k

20k

0

physics
math
stat
cs.AI
cs

2011

2012

2013

2014

2015

2016

2017

2018

2019

2020

2021

2022

2023

Year

Figure 7: Annual preprint submissions to different categories
on arXiv.org

X. IMPACT OF GENERATIVE AI ON PREPRINTS ACROSS
DISCIPLINES

The challenges detailed in this section are not directly
related to the knowledge domains within generative AI, but
are fueled by the success of Generative AI, particularly the
commercialization of ChatGPT. The proliferation of preprints
in the ﬁeld of AI (Fig. 7), especially in the cs.AI category
on platforms like arXiv, has introduced a set of academic
challenges that merit careful consideration and strategic re-
sponse. The rapid commercialization and adoption of tools
such as ChatGPT, as evidenced by over 55,700 entries on
Google Scholar mentioning “ChatGPT” within just one year
of its commercialization, exemplify the accelerated pace at
which the ﬁeld is advancing. This rapid development is not
mirrored in the traditional peer-review process, which is con-
siderably slower. The peer-review process now appears to be
overwhelmed with manuscripts that are either generated with
ChatGPT (or other LLMs), or whose writing processes have
been signiﬁcantly accelerated by such LLMs, contributing
to a bottleneck in scholarly communication [325], [326].
This situation is further compounded by the fact that many
journals in disciplines outside of computer science are also
experiencing longer review times and higher rates of desk re-
jections. Additionally, the ﬂourishing trend of manuscripts and
preprints, either generated by or signiﬁcantly expedited using
tools like ChatGPT, extends beyond computer science into
diverse academic disciplines. This trend presents a looming
challenge, potentially overwhelming both the traditional peer-
review process and the ﬂourishing preprint ecosystem with a
volume of work that may not always adhere to established
academic standards.

The sheer volume of preprints has made the task of se-
lecting and scrutinizing research exceedingly demanding. In
the current research era, the exploration of scientiﬁc literature
has become increasingly complex, as knowledge has continued
to expand and disseminate exponentially, while concurrently,
integrative research efforts attempting to distill these vast liter-

ature, attempt to identify and understand a smaller sets of core
contributions [327]. Thus, the rapid expansion of academic
literature across various ﬁelds presents a signiﬁcant challenge
for researchers seeking to perform evidence syntheses over the
increasingly vast body of available knowledge [328]. Further-
more, this explosion in publication volume poses a distinct
challenge for literature reviews and surveys, where the human
capacity for manually selecting, understanding, and critically
evaluating articles is increasingly strained, potentially leading
to gaps in synthesizing comprehensive knowledge landscapes.
Although reproduction of results is a theoretical possibility,
practical constraints such as the lack of technical expertise,
computational resources, or access to proprietary datasets hin-
der rigorous evaluation. This is concerning, as the inability to
thoroughly assess preprint research undermines the foundation
of scientiﬁc reliability and validity. Furthermore, the peer-
review system, a cornerstone of academic rigour, is under the
threat of being further overwhelmed [325], [329]. The potential
consequences are signiﬁcant, with unvetted preprints possibly
perpetuating biases or errors within the scientiﬁc community
and beyond. The absence of established retraction mechanisms
for preprints, akin to those for published articles, exacerbates
the risk of persistent dissemination of ﬂawed research.

The academic community is at a crossroads, necessitating
an urgent and thoughtful discourse on navigating this emerging
“mess” — a situation that risks spiraling out of control if left
unaddressed. In this context, the role of peer review becomes
increasingly crucial, as it serves as a critical checkpoint for
quality and validity, ensuring that the rapid production of
AI research is rigorously studied for scientiﬁc accuracy and
relevance. However, the current modus operandi of traditional
peer review does not appear to be sustainable, primarily due
to its inability to keep pace with the exponential growth in
AI-themed research and Generative-AI-accelerated research
submissions, and the increasingly specialized nature of emerg-
ing AI topics [325], [326]. This situation is compounded
by a ﬁnite pool of qualiﬁed reviewers, leading to delays,
potential biases, and a burden on the scholarly community.
This reality demands an exploration of new paradigms for peer
review and dissemination of research that can keep pace with
swift advancements in AI. Innovative models for community-
driven vetting processes, enhanced reproducibility checks,
and dynamic frameworks for post-publication scrutiny and
correction may be necessary. Efforts to incorporate automated
tools and AI-assisted review processes could also be explored
to alleviate the strain on human reviewers.

In this rapidly evolving landscape, envision a convergence
between the traditional peer review system and the ﬂour-
ishing preprint ecosystem, which could involve creating hy-
brid models (Fig. 8), where preprints undergo a preliminary
community-based review, harnessing the collective expertise
and rapid feedback of the academic community, similar to
product review websites and Twitter [330]. This approach
could provide an initial layer of validation, offering addi-
tional insights on issues that may be overlooked by a lim-
ited number of peer reviewers. The Editors-in-Chief (EICs)
could consider the major criticisms and suggestions of an
article from the community-based review, ensuring a more

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

22

Preprint
Submission

Rapid Feedback
(Similar to Product
Review Sites)

Community-
Based Review

Initial
Validation

In-depth
Academic
Assessment

Formal Peer
Review

Rigor and
Quality
Assurance

Final Publication

Figure 8: Possible Convergence Between Traditional Peer Review and the Preprint Ecosystem

thorough and diverse evaluation. Subsequent, more formal
peer review processes could then reﬁne and endorse these
preprints for academic rigor and quality assurance. This hybrid
model would require robust technological support, possibly
leveraging AI and machine learning tools to assist in initial
screening and identiﬁcation of suitable reviewers. The aim
would be to establish a seamless continuum from rapid dis-
semination to validated publication, ensuring both the speed
of preprints and the credibility of peer-reviewed research. A
balanced approach must be struck to harness the beneﬁts of
preprints—such as rapid dissemination of ﬁndings and open
access—while mitigating their drawbacks. The development of
new infrastructure and norms could be instrumental in steering
the academic community towards a sustainable model that
upholds the integrity and trustworthiness of scientiﬁc research
in the age of Generative AI.

XI. CONCLUSIONS

This roadmap survey has embarked on an exploration of the
transformative trends in generative AI research, particularly
focusing on speculated advancements like Q* and the pro-
gressive strides towards AGI. Our analysis highlights a crucial
paradigm shift, driven by innovations such as MoE, multi-
modal learning, and the pursuit of AGI. These advancements
signal a future where AI systems could signiﬁcantly extend
their capabilities in reasoning, contextual understanding, and
creative problem-solving. This study reﬂects on AI’s dual
potential
to either contribute to or impede global equity
and justice. The equitable distribution of AI beneﬁts and
its role in decision-making processes raise crucial questions
about fairness and inclusivity. It is imperative to thoughtfully
integrate AI into societal structures to enhance justice and
reduce disparities. Despite these advancements, several open
questions and research gaps remain. These include ensuring
the ethical alignment of advanced AI systems with human
values and societal norms, a challenge compounded by their
increasing autonomy. The safety and robustness of AGI sys-
tems in diverse environments also remain a signiﬁcant research
gap. Addressing these challenges requires a multidisciplinary
approach, incorporating ethical, social, and philosophical per-
spectives.

Our survey has highlighted key areas for future inter-
disciplinary research in AI, emphasizing the integration of
ethical, sociological, and technical perspectives. This approach
will foster collaborative research, bridging the gap between
technological advancement and societal needs, ensuring that
AI development is aligned with human values and global
welfare. The roles of MoE, multimodal, and AGI in reshaping

generative AI have been identiﬁed as signiﬁcant, as their
advancements can enhance model performance and versatility,
and pave the way for future research in areas like ethical AI
alignment and AGI. As we forge ahead, the balance between
AI advancements and human creativity is not just a goal
but a necessity, ensuring AI’s role as a complementary force
that ampliﬁes our capacity to innovate and solve complex
challenges. Our responsibility is to guide these advancements
towards enriching the human experience, aligning technolog-
ical progress with ethical standards and societal well-being.

DISCLAIMER

The authors hereby declare no conﬂict of interest.

ABBREVIATIONS

Artiﬁcial General Intelligence
AGI
Artiﬁcial Intelligence
AI
AI-generated content
AIGC
Bidirectional Encoder Representations from Transformers
BERT
California Consumer Privacy Act
CCPA
Deep Q-Networks
DQN
European Union
EU
Generative Adversarial Network
GAN
General Data Protection Regulation
GDPR
Generative Pre-trained Transformers
GPT
Graphics Processing Unit
GPU
Light Detection and Ranging
LIDAR
Large Language Model
LLM
Long Short-Term Memory
LSTM
Monte Carlo Tree Search
MCTS
Machine Learning
ML
Mixture of Experts
MoE
Natural Language Generation
NLG
Natural Language Processing
NLP
Natural Language Understanding
NLU
Neural Network
NN
Proximal Policy Optimization
PPO
Recurrent Neural Networks
RNNs
Value Neural Network
VNN
VRAM Video Random Access Memory

REFERENCES

[1] A. Turing, “Computing machinery and intelligence,” Mind, vol. 59, no.

236, p. 433, 1950.

[2] D. McDermott, “Artiﬁcial intelligence meets natural stupidity,” Acm

Sigart Bulletin, no. 57, pp. 4–9, 1976.

[3] M. Minsky, “Steps toward artiﬁcial intelligence,” Proceedings of the

IRE, vol. 49, no. 1, pp. 8–30, 1961.

[4] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” nature, vol. 521,

no. 7553, pp. 436–444, 2015.

[5] M. Minsky and S. Papert, “An introduction to computational geometry,”

Cambridge tiass., HIT, vol. 479, no. 480, p. 104, 1969.

[6] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learning repre-
sentations by back-propagating errors,” nature, vol. 323, no. 6088, pp.
533–536, 1986.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

23

[7] G.-G. Lee, L. Shi, E. Latif, Y. Gao, A. Bewersdorf, M. Nyaaba, S. Guo,
Z. Wu, Z. Liu, H. Wang et al., “Multimodality of ai for education: To-
wards artiﬁcial general intelligence,” arXiv preprint arXiv:2312.06037,
2023.

[8] P. Maddigan and T. Susnjak, “Chat2vis: Generating data visualisations
via natural language using chatgpt, codex and gpt-3 large language
models,” IEEE Access, 2023.

[9] T. R. McIntosh, T. Liu, T. Susnjak, P. Watters, A. Ng, and M. N.
Halgamuge, “A culturally sensitive test to evaluate nuanced gpt hallu-
cination,” IEEE Transactions on Artiﬁcial Intelligence, vol. 1, no. 01,
pp. 1–13, 2023.

[10] M. R. Morris, J. Sohl-dickstein, N. Fiedel, T. Warkentin, A. Dafoe,
A. Faust, C. Farabet, and S. Legg, “Levels of agi: Operationalizing
progress on the path to agi,” arXiv preprint arXiv:2311.02462, 2023.
[11] J. Schuett, N. Dreksler, M. Anderljung, D. McCaffary, L. Heim,
E. Bluemke, and B. Garﬁnkel, “Towards best practices in agi
safety and governance: A survey of expert opinion,” arXiv preprint
arXiv:2305.07153, 2023.

[12] X. Shuai, J. Rollins,

I. Moulinier, T. Custis, M. Edmunds, and
F. Schilder, “A multidimensional investigation of the effects of pub-
lication retraction on scholarly impact,” Journal of the Association for
Information Science and Technology, vol. 68, no. 9, pp. 2225–2236,
2017.

[13] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.
Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,”
Advances in neural information processing systems, vol. 30, 2017.
[14] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever et al., “Improving

language understanding by generative pre-training,” 2018.

[15] C. Huang, Z. Zhang, B. Mao, and X. Yao, “An overview of artiﬁcial
intelligence ethics,” IEEE Transactions on Artiﬁcial Intelligence, 2022.
[16] L. Besanc¸on, N. Peiffer-Smadja, C. Segalas, H. Jiang, P. Masuzzo,
C. Smout, E. Billy, M. Deforet, and C. Leyrat, “Open science saves
lives: lessons from the covid-19 pandemic,” BMC Medical Research
Methodology, vol. 21, no. 1, pp. 1–18, 2021.

[17] C. R. Triggle, R. MacDonald, D. J. Triggle, and D. Grierson, “Requiem
for impact factors and high publication charges,” Accountability in
Research, vol. 29, no. 3, pp. 133–164, 2022.

[18] T. McIntosh, A. Kayes, Y.-P. P. Chen, A. Ng, and P. Watters, “Ran-
somware mitigation in the modern era: A comprehensive review,
research challenges, and future directions,” ACM Computing Surveys
(CSUR), vol. 54, no. 9, pp. 1–36, 2021.

[19] T. McIntosh, T. Liu, T. Susnjak, H. Alavizadeh, A. Ng, R. Nowrozy,
and P. Watters, “Harnessing gpt-4 for generation of cybersecurity grc
policies: A focus on ransomware attack mitigation,” Computers &
Security, vol. 134, p. 103424, 2023.

[20] H. Bao, W. Wang, L. Dong, Q. Liu, O. K. Mohammed, K. Aggarwal,
S. Som, S. Piao, and F. Wei, “Vlmo: Uniﬁed vision-language pre-
training with mixture-of-modality-experts,” Advances in Neural Infor-
mation Processing Systems, vol. 35, pp. 32 897–32 912, 2022.

[21] N. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, M. Krikun,
Y. Zhou, A. W. Yu, O. Firat et al., “Glam: Efﬁcient scaling of
language models with mixture-of-experts,” in International Conference
on Machine Learning. PMLR, 2022, pp. 5547–5569.

[22] S. Masoudnia and R. Ebrahimpour, “Mixture of experts: a literature
survey,” Artiﬁcial Intelligence Review, vol. 42, pp. 275–293, 2014.
[23] C. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton,
A. Susano Pinto, D. Keysers, and N. Houlsby, “Scaling vision with
sparse mixture of experts,” Advances in Neural Information Processing
Systems, vol. 34, pp. 8583–8595, 2021.

[24] S. E. Yuksel, J. N. Wilson, and P. D. Gader, “Twenty years of mixture of
experts,” IEEE transactions on neural networks and learning systems,
vol. 23, no. 8, pp. 1177–1193, 2012.

[25] L. Zhang, S. Huang, W. Liu, and D. Tao, “Learning a mixture of
granularity-speciﬁc experts for ﬁne-grained categorization,” in Proceed-
ings of the IEEE/CVF International Conference on Computer Vision,
2019, pp. 8331–8340.

[26] D. Martin, S. Malpica, D. Gutierrez, B. Masia, and A. Serrano,
“Multimodality in vr: A survey,” ACM Computing Surveys (CSUR),
vol. 54, no. 10s, pp. 1–36, 2022.

[27] Q. Sun, Q. Yu, Y. Cui, F. Zhang, X. Zhang, Y. Wang, H. Gao, J. Liu,
T. Huang, and X. Wang, “Generative pretraining in multimodality,”
arXiv preprint arXiv:2307.05222, 2023.

[28] L. Wei, L. Xie, W. Zhou, H. Li, and Q. Tian, “Mvp: Multimodality-
guided visual pre-training,” in European Conference on Computer
Vision. Springer, 2022, pp. 337–353.

[29] J. Wu, W. Zhou, X. Qian, J. Lei, L. Yu, and T. Luo, “Menet:
Lightweight multimodality enhancement network for detecting salient

objects in rgb-thermal images,” Neurocomputing, vol. 527, pp. 119–
129, 2023.

[30] Q. Ye, H. Xu, G. Xu, J. Ye, M. Yan, Y. Zhou, J. Wang, A. Hu, P. Shi,
Y. Shi et al., “mplug-owl: Modularization empowers large language
models with multimodality,” arXiv preprint arXiv:2304.14178, 2023.
[31] K. LaGrandeur, “How safe is our reliance on ai, and should we regulate

it?” AI and Ethics, vol. 1, pp. 93–99, 2021.

[32] S. McLean, G. J. Read, J. Thompson, C. Baber, N. A. Stanton, and
P. M. Salmon, “The risks associated with artiﬁcial general intelligence:
A systematic review,” Journal of Experimental & Theoretical Artiﬁcial
Intelligence, vol. 35, no. 5, pp. 649–663, 2023.

[33] Y. K. Dwivedi, L. Hughes, E. Ismagilova, G. Aarts, C. Coombs,
T. Crick, Y. Duan, R. Dwivedi, J. Edwards, A. Eirug, V. Galanos,
P. V. Ilavarasan, M. Janssen, P. Jones, A. K. Kar, H. Kizgin, B. Kro-
nemann, B. Lal, B. Lucini, R. Medaglia, K. Le Meunier-FitzHugh,
L. C. Le Meunier-FitzHugh, S. Misra, E. Mogaji, S. K. Sharma,
J. B. Singh, V. Raghavan, R. Raman, N. P. Rana, S. Samothrakis,
J. Spencer, K. Tamilmani, A. Tubadji, P. Walton, and M. D. Williams,
“Artiﬁcial intelligence (ai): Multidisciplinary perspectives on emerging
challenges, opportunities, and agenda for research, practice and policy,”
International Journal of Information Management, vol. 57, p. 101994,
2021.

[34] I. Gabriel, “Artiﬁcial intelligence, values, and alignment,” Minds and

Machines, vol. 30, pp. 411–437, 2020.

[35] A. Shaban-Nejad, M. Michalowski, S. Bianco, J. S. Brownstein,
D. L. Buckeridge, and R. L. Davis, “Applied artiﬁcial intelligence in
healthcare: Listening to the winds of change in a post-covid-19 world,”
pp. 1969–1971, 2022.

[36] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y. Xu, E. Ishii, Y. J. Bang,
A. Madotto, and P. Fung, “Survey of hallucination in natural language
generation,” ACM Computing Surveys, vol. 55, no. 12, pp. 1–38, 2023.
[37] B. Min, H. Ross, E. Sulem, A. P. B. Veyseh, T. H. Nguyen, O. Sainz,
E. Agirre, I. Heintz, and D. Roth, “Recent advances in natural language
processing via large pre-trained language models: A survey,” ACM
Computing Surveys, vol. 56, no. 2, pp. 1–40, 2023.

[38] J. Li, X. Cheng, W. X. Zhao, J.-Y. Nie, and J.-R. Wen, “Halueval:
A large-scale hallucination evaluation benchmark for large language
models,” in Proceedings of the 2023 Conference on Empirical Methods
in Natural Language Processing, 2023, pp. 6449–6464.

[39] L. Weidinger, J. Mellor, M. Rauh, C. Grifﬁn, J. Uesato, P.-S. Huang,
M. Cheng, M. Glaese, B. Balle, A. Kasirzadeh et al., “Ethical and social
risks of harm from language models,” arXiv preprint arXiv:2112.04359,
2021.

[40] X. Zhiheng, Z. Rui, and G. Tao, “Safety and ethical concerns of large
language models,” in Proceedings of the 22nd Chinese National Con-
ference on Computational Linguistics (Volume 4: Tutorial Abstracts),
2023, pp. 9–16.

[41] P. F. Brown, V. J. Della Pietra, P. V. Desouza, J. C. Lai, and R. L. Mer-
cer, “Class-based n-gram models of natural language,” Computational
linguistics, vol. 18, no. 4, pp. 467–480, 1992.

[42] S. Katz, “Estimation of probabilities from sparse data for the language
model component of a speech recognizer,” IEEE transactions on
acoustics, speech, and signal processing, vol. 35, no. 3, pp. 400–401,
1987.

[43] R. Kneser and H. Ney, “Improved backing-off for m-gram language
modeling,” in 1995 international conference on acoustics, speech, and
signal processing, vol. 1.

IEEE, 1995, pp. 181–184.

[44] R. Kuhn and R. De Mori, “A cache-based natural language model
for speech recognition,” IEEE transactions on pattern analysis and
machine intelligence, vol. 12, no. 6, pp. 570–583, 1990.

[45] H. Ney, U. Essen, and R. Kneser, “On structuring probabilistic de-
pendences in stochastic language modelling,” Computer Speech &
Language, vol. 8, no. 1, pp. 1–38, 1994.

[46] S. Hochreiter and J. Schmidhuber, “Long short-term memory,” Neural

computation, vol. 9, no. 8, pp. 1735–1780, 1997.

[47] M. K. Nammous and K. Saeed, “Natural language processing: speaker,
language, and gender identiﬁcation with lstm,” Advanced Computing
and Systems for Security: Volume Eight, pp. 143–156, 2019.

[48] D. Wei, B. Wang, G. Lin, D. Liu, Z. Dong, H. Liu, and Y. Liu, “Re-
search on unstructured text data mining and fault classiﬁcation based on
rnn-lstm with malfunction inspection report,” Energies, vol. 10, no. 3,
p. 406, 2017.

[49] L. Yao and Y. Guan, “An improved lstm structure for natural language
processing,” in 2018 IEEE International Conference of Safety Produce
Informatization (IICSPI).

IEEE, 2018, pp. 565–569.

[50] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin,
C. Zhang, S. Agarwal, K. Slama, A. Ray et al., “Training language

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

24

models to follow instructions with human feedback,” Advances in
Neural Information Processing Systems, vol. 35, pp. 27 730–27 744,
2022.

[51] T. Susnjak, “Beyond predictive learning analytics modelling and onto
explainable artiﬁcial intelligence with prescriptive analytics and chat-
gpt,” International Journal of Artiﬁcial Intelligence in Education, pp.
1–31, 2023.

[52] T. Susnjak, E. Grifﬁn, M. McCutcheon, and K. Potter, “Towards clinical
prediction with transparency: An explainable ai approach to survival
modelling in residential aged care,” arXiv preprint arXiv:2312.00271,
2023.

[53] R. Yang, T. F. Tan, W. Lu, A. J. Thirunavukarasu, D. S. W. Ting,
and N. Liu, “Large language models in health care: Development,
applications, and challenges,” Health Care Science, vol. 2, no. 4, pp.
255–263, 2023.

[54] D. Baidoo-Anu and L. O. Ansah, “Education in the era of generative
artiﬁcial intelligence (ai): Understanding the potential beneﬁts of chat-
gpt in promoting teaching and learning,” Journal of AI, vol. 7, no. 1,
pp. 52–62, 2023.

[55] T. Susnjak, “Chatgpt: The end of online exam integrity?” arXiv preprint

arXiv:2212.09292, 2022.

[56] A. Tlili, B. Shehata, M. A. Adarkwah, A. Bozkurt, D. T. Hickey,
R. Huang, and B. Agyemang, “What if the devil is my guardian angel:
Chatgpt as a case study of using chatbots in education,” Smart Learning
Environments, vol. 10, no. 1, p. 15, 2023.

[57] M. A. AlAfnan, S. Dishari, M. Jovic, and K. Lomidze, “Chatgpt as an
educational tool: Opportunities, challenges, and recommendations for
communication, business writing, and composition courses,” Journal of
Artiﬁcial Intelligence and Technology, vol. 3, no. 2, pp. 60–68, 2023.
[58] A. S. George and A. H. George, “A review of chatgpt ai’s impact on
several business sectors,” Partners Universal International Innovation
Journal, vol. 1, no. 1, pp. 9–23, 2023.

[59] G. K. Hadﬁeld and J. Clark, “Regulatory markets: The future of ai

governance,” arXiv preprint arXiv:2304.04914, 2023.

[60] M. Bakker, M. Chadwick, H. Sheahan, M. Tessler, L. Campbell-
Gillingham, J. Balaguer, N. McAleese, A. Glaese, J. Aslanides,
M. Botvinick et al., “Fine-tuning language models to ﬁnd agreement
among humans with diverse preferences,” Advances in Neural Infor-
mation Processing Systems, vol. 35, pp. 38 176–38 189, 2022.

[61] Z. Hu, Y. Lan, L. Wang, W. Xu, E.-P. Lim, R. K.-W. Lee, L. Bing, and
S. Poria, “Llm-adapters: An adapter family for parameter-efﬁcient ﬁne-
tuning of large language models,” arXiv preprint arXiv:2304.01933,
2023.

[62] H. Liu, D. Tam, M. Muqeeth, J. Mohta, T. Huang, M. Bansal, and C. A.
Raffel, “Few-shot parameter-efﬁcient ﬁne-tuning is better and cheaper
than in-context learning,” Advances in Neural Information Processing
Systems, vol. 35, pp. 1950–1965, 2022.

[63] H. Zheng, L. Shen, A. Tang, Y. Luo, H. Hu, B. Du, and D. Tao,
“Learn from model beyond ﬁne-tuning: A survey,” arXiv preprint
arXiv:2310.08184, 2023.

[64] P. Manakul, A. Liusie, and M. J. Gales, “Selfcheckgpt: Zero-resource
black-box hallucination detection for generative large language mod-
els,” arXiv preprint arXiv:2303.08896, 2023.

[65] A. Martino, M. Iannelli, and C. Truong, “Knowledge injection to
counter large language model (llm) hallucination,” in European Se-
mantic Web Conference. Springer, 2023, pp. 182–185.

[66] J.-Y. Yao, K.-P. Ning, Z.-H. Liu, M.-N. Ning, and L. Yuan, “Llm
lies: Hallucinations are not bugs, but features as adversarial examples,”
arXiv preprint arXiv:2310.01469, 2023.

[67] Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,
Y. Zhang, Y. Chen et al., “Siren’s song in the ai ocean: A survey on hal-
lucination in large language models,” arXiv preprint arXiv:2309.01219,
2023.

[68] J. Ji, M. Liu, J. Dai, X. Pan, C. Zhang, C. Bian, R. Sun, Y. Wang, and
Y. Yang, “Beavertails: Towards improved safety alignment of llm via
a human-preference dataset,” arXiv preprint arXiv:2307.04657, 2023.
[69] Y. Liu, Y. Yao, J.-F. Ton, X. Zhang, R. G. H. Cheng, Y. Klochkov,
M. F. Tauﬁq, and H. Li, “Trustworthy llms: a survey and guideline
for evaluating large language models’ alignment,” arXiv preprint
arXiv:2308.05374, 2023.

[70] Y. Wang, W. Zhong, L. Li, F. Mi, X. Zeng, W. Huang, L. Shang,
X. Jiang, and Q. Liu, “Aligning large language models with human: A
survey,” arXiv preprint arXiv:2307.12966, 2023.

[71] Z. Sun, Y. Shen, Q. Zhou, H. Zhang, Z. Chen, D. Cox, Y. Yang,
and C. Gan, “Principle-driven self-alignment of
language mod-
els from scratch with minimal human supervision,” arXiv preprint
arXiv:2305.03047, 2023.

[72] Y. Wolf, N. Wies, Y. Levine, and A. Shashua, “Fundamental

lim-
in large language models,” arXiv preprint

itations of alignment
arXiv:2304.11082, 2023.

[73] H. Dang, L. Mecke, F. Lehmann, S. Goller, and D. Buschek, “How
to prompt? opportunities and challenges of zero-and few-shot learning
for human-ai interaction in creative applications of generative models,”
arXiv preprint arXiv:2209.01390, 2022.

[74] R. Ma, X. Zhou, T. Gui, Y. Tan, L. Li, Q. Zhang, and X. Huang,
few-shot ner,” arXiv preprint

tuning for

“Template-free prompt
arXiv:2109.13532, 2021.

[75] C. Qin and S. Joty, “Lfpt5: A uniﬁed framework for lifelong few-
shot language learning based on prompt tuning of t5,” arXiv preprint
arXiv:2110.07298, 2021.

[76] S. Wang, L. Tang, A. Majety, J. F. Rousseau, G. Shih, Y. Ding,
and Y. Peng, “Trustworthy assertion classiﬁcation through prompting,”
Journal of biomedical informatics, vol. 132, p. 104139, 2022.
[77] Y. Fan, F. Jiang, P. Li, and H. Li, “Grammargpt: Exploring open-source
llms for native chinese grammatical error correction with supervised
ﬁne-tuning,” in CCF International Conference on Natural Language
Processing and Chinese Computing. Springer, 2023, pp. 69–80.
[78] D. Liga and L. Robaldo, “Fine-tuning gpt-3 for legal rule classiﬁca-

tion,” Computer Law & Security Review, vol. 51, p. 105864, 2023.

[79] Y. Liu, A. Singh, C. D. Freeman, J. D. Co-Reyes, and P. J. Liu, “Im-
proving large language model ﬁne-tuning for solving math problems,”
arXiv preprint arXiv:2310.10047, 2023.

[80] Z. Talat, A. N´ev´eol, S. Biderman, M. Clinciu, M. Dey, S. Longpre,
S. Luccioni, M. Masoud, M. Mitchell, D. Radev et al., “You reap
what you sow: On the challenges of bias evaluation under multilingual
settings,” in Proceedings of BigScience Episode# 5–Workshop on
Challenges & Perspectives in Creating Large Language Models, 2022,
pp. 26–41.

[81] Y. Liu, S. Yu, and T. Lin, “Hessian regularization of deep neural
networks: A novel approach based on stochastic estimators of hessian
trace,” Neurocomputing, vol. 536, pp. 13–20, 2023.

[82] Y. Lu, Y. Bo, and W. He, “Conﬁdence adaptive regularization for deep

learning with noisy labels,” arXiv preprint arXiv:2108.08212, 2021.

[83] G. Pereyra, G. Tucker, J. Chorowski, Ł. Kaiser, and G. Hinton, “Regu-
larizing neural networks by penalizing conﬁdent output distributions,”
arXiv preprint arXiv:1701.06548, 2017.

[84] E. Chen, Z.-W. Hong, J. Pajarinen, and P. Agrawal, “Redeeming
intrinsic rewards via constrained optimization,” Advances in Neural
Information Processing Systems, vol. 35, pp. 4996–5008, 2022.
[85] Y. Jiang, Z. Li, M. Tan, S. Wei, G. Zhang, Z. Guan, and B. Han,
“A stable block adjustment method without ground control points
using bound constrained optimization,” International Journal of Remote
Sensing, vol. 43, no. 12, pp. 4708–4722, 2022.

[86] M. Kachuee and S. Lee, “Constrained policy optimization for con-
trolled self-learning in conversational ai systems,” arXiv preprint
arXiv:2209.08429, 2022.

[87] Z. Song, H. Wang, and Y. Jin, “A surrogate-assisted evolutionary
framework with regions of interests-based data selection for expensive
constrained optimization,” IEEE Transactions on Systems, Man, and
Cybernetics: Systems, 2023.

[88] J. Yu, T. Xu, Y. Rong, J. Huang, and R. He, “Structure-aware condi-
tional variational auto-encoder for constrained molecule optimization,”
Pattern Recognition, vol. 126, p. 108581, 2022.

[89] P. Butlin, “Ai alignment and human reward,” in Proceedings of the 2021
AAAI/ACM Conference on AI, Ethics, and Society, 2021, pp. 437–445.
[90] F. Faal, K. Schmitt, and J. Y. Yu, “Reward modeling for mitigating
toxicity in transformer-based language models,” Applied Intelligence,
vol. 53, no. 7, pp. 8421–8435, 2023.

[91] J. Leike, D. Krueger, T. Everitt, M. Martic, V. Maini, and S. Legg,
“Scalable agent alignment via reward modeling: a research direction,”
arXiv preprint arXiv:1811.07871, 2018.

[92] L. Li, Y. Chai, S. Wang, Y. Sun, H. Tian, N. Zhang, and H. Wu, “Tool-
augmented reward modeling,” arXiv preprint arXiv:2310.01045, 2023.
[93] F. Barreto, L. Moharkar, M. Shirodkar, V. Sarode, S. Gonsalves,
and A. Johns, “Generative artiﬁcial
intelligence: Opportunities and
challenges of large language models,” in International Conference on
Intelligent Computing and Networking. Springer, 2023, pp. 545–553.
[94] Z. Chen, Z. Wang, Z. Wang, H. Liu, Z. Yin, S. Liu, L. Sheng,
W. Ouyang, Y. Qiao, and J. Shao, “Octavius: Mitigating task inter-
ference in mllms via moe,” arXiv preprint arXiv:2311.02684, 2023.

[95] C. Dun, M. D. C. H. Garcia, G. Zheng, A. H. Awadallah, A. Kyrillidis,
and R. Sim, “Sweeping heterogeneity with smart mops: Mixture of
prompts for llm task adaptation,” arXiv preprint arXiv:2310.02842,
2023.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

25

[96] H. Naveed, A. U. Khan, S. Qiu, M. Saqib, S. Anwar, M. Usman,
N. Barnes, and A. Mian, “A comprehensive overview of large language
models,” arXiv preprint arXiv:2307.06435, 2023.

[97] F. Xue, Y. Fu, W. Zhou, Z. Zheng, and Y. You, “To repeat or not to
repeat: Insights from scaling llm under token-crisis,” arXiv preprint
arXiv:2305.13230, 2023.

[98] M. Nowaz Rabbani Chowdhury, S. Zhang, M. Wang, S. Liu, and P.-Y.
Chen, “Patch-level routing in mixture-of-experts is provably sample-
efﬁcient for convolutional neural networks,” arXiv e-prints, pp. arXiv–
2306, 2023.

[99] J. Peng, K. Zhou, R. Zhou, T. Hartvigsen, Y. Zhang, Z. Wang, and
T. Chen, “Sparse moe as a new treatment: Addressing forgetting, ﬁtting,
learning issues in multi-modal multi-task learning,” in Conference on
Parsimony and Learning (Recent Spotlight Track), 2023.

[100] C. N. d. Santos, J. Lee-Thorp, I. Noble, C.-C. Chang, and D. Uthus,
“Memory augmented language models through mixture of word ex-
perts,” arXiv preprint arXiv:2311.10768, 2023.

[101] W. Wang, G. Ma, Y. Li, and B. Du, “Language-routing mixture of
experts for multilingual and code-switching speech recognition,” arXiv
preprint arXiv:2307.05956, 2023.

[102] X. Zhao, X. Chen, Y. Cheng, and T. Chen, “Sparse moe with language
guided routing for multilingual machine translation,” in Conference on
Parsimony and Learning (Recent Spotlight Track), 2023.

[103] W. Huang, H. Zhang, P. Peng, and H. Wang, “Multi-gate mixture-
of-expert combined with synthetic minority over-sampling technique
for multimode imbalanced fault diagnosis,” in 2023 26th International
Conference on Computer Supported Cooperative Work in Design
(CSCWD).

IEEE, 2023, pp. 456–461.

[104] B. Liu, L. Ding, L. Shen, K. Peng, Y. Cao, D. Cheng, and D. Tao,
“Diversifying the mixture-of-experts representation for language mod-
els with orthogonal optimizer,” arXiv preprint arXiv:2310.09762, 2023.
[105] W. Wang, Z. Lai, S. Li, W. Liu, K. Ge, Y. Liu, A. Shen, and D. Li,
“Prophet: Fine-grained load balancing for parallel training of large-
scale moe models,” in 2023 IEEE International Conference on Cluster
Computing (CLUSTER).

IEEE, 2023, pp. 82–94.

[106] X. Yao, S. Liang, S. Han, and H. Huang, “Enhancing molecular
property prediction via mixture of collaborative experts,” arXiv preprint
arXiv:2312.03292, 2023.

[107] Z. Xiao, Y. Jiang, G. Tang, L. Liu, S. Xu, Y. Xiao, and W. Yan, “Ad-
versarial mixture of experts with category hierarchy soft constraint,”
in 2021 IEEE 37th International Conference on Data Engineering
(ICDE).

IEEE, 2021, pp. 2453–2463.

[108] M. Agbese, R. Mohanani, A. Khan, and P. Abrahamsson, “Implement-
ing ai ethics: Making sense of the ethical requirements,” in Proceedings
of the 27th International Conference on Evaluation and Assessment in
Software Engineering, 2023, pp. 62–71.

[109] Z. Chen, Y. Deng, Y. Wu, Q. Gu, and Y. Li, “Towards understanding
the mixture-of-experts layer in deep learning,” Advances in neural
information processing systems, vol. 35, pp. 23 049–23 062, 2022.

[110] Y. Zhou, T. Lei, H. Liu, N. Du, Y. Huang, V. Zhao, A. M. Dai, Q. V.
Le, J. Laudon et al., “Mixture-of-experts with expert choice routing,”
Advances in Neural Information Processing Systems, vol. 35, pp. 7103–
7114, 2022.

[111] N. Guha, C. Lawrence, L. A. Gailmard, K. Rodolfa, F. Surani,
R. Bommasani, I. Raji, M.-F. Cu´ellar, C. Honigsberg, P. Liang et al.,
“Ai regulation has its own alignment problem: The technical and insti-
tutional feasibility of disclosure, registration, licensing, and auditing,”
George Washington Law Review, Forthcoming, 2023.

Team,

[112] Gemini
of
accessed:
https://storage.googleapis.com/deepmind-media/gemini/gemini 1 report.pdf

family
2023,
Available:

multimodal
2023.

December

“Gemini:

[Online].

models,”

Google,

capable

highly

17

A

[113] J. N. Acosta, G. J. Falcone, P. Rajpurkar, and E. J. Topol, “Multimodal
biomedical ai,” Nature Medicine, vol. 28, no. 9, pp. 1773–1784, 2022.
[114] S. Qi, Z. Cao, J. Rao, L. Wang, J. Xiao, and X. Wang, “What is
the limitation of multimodal
llms? a deeper look into multimodal
llms through prompt probing,” Information Processing & Management,
vol. 60, no. 6, p. 103510, 2023.

[115] B. Xu, D. Kocyigit, R. Grimm, B. P. Grifﬁn, and F. Cheng, “Applica-
tions of artiﬁcial intelligence in multimodality cardiovascular imaging:
a state-of-the-art review,” Progress in cardiovascular diseases, vol. 63,
no. 3, pp. 367–376, 2020.

[116] A. Birhane, V. U. Prabhu, and E. Kahembwe, “Multimodal datasets:
misogyny, pornography, and malignant stereotypes,” arXiv preprint
arXiv:2110.01963, 2021.

[117] Y. Li, W. Li, N. Li, X. Qiu, and K. B. Manokaran, “Multimodal infor-
mation interaction and fusion for the parallel computing system using

ai techniques,” International Journal of High Performance Systems
Architecture, vol. 10, no. 3-4, pp. 185–196, 2021.

[118] C. Zhang, Z. Yang, X. He, and L. Deng, “Multimodal intelligence:
Representation learning, information fusion, and applications,” IEEE
Journal of Selected Topics in Signal Processing, vol. 14, no. 3, pp.
478–493, 2020.

[119] H. Qiao, V. Liu, and L. Chilton, “Initial images: using image prompts
to improve subject representation in multimodal ai generated art,” in
Proceedings of the 14th Conference on Creativity and Cognition, 2022,
pp. 15–28.

[120] A. E. Stewart, Z. Keirn, and S. K. D’Mello, “Multimodal modeling
of collaborative problem-solving facets in triads,” User Modeling and
User-Adapted Interaction, pp. 1–39, 2021.

[121] L. Xue, N. Yu, S. Zhang, J. Li, R. Mart´ın-Mart´ın, J. Wu, C. Xiong,
R. Xu, J. C. Niebles, and S. Savarese, “Ulip-2: Towards scal-
able multimodal pre-training for 3d understanding,” arXiv preprint
arXiv:2305.08275, 2023.

[122] L. Yan, L. Zhao, D. Gasevic, and R. Martinez-Maldonado, “Scalability,
sustainability, and ethicality of multimodal
learning analytics,” in
LAK22: 12th international learning analytics and knowledge confer-
ence, 2022, pp. 13–23.

[123] Y. Liu-Thompkins, S. Okazaki, and H. Li, “Artiﬁcial empathy in
marketing interactions: Bridging the human-ai gap in affective and
social customer experience,” Journal of the Academy of Marketing
Science, vol. 50, no. 6, pp. 1198–1218, 2022.

[124] M. S. Rahman, S. Bag, M. A. Hossain, F. A. M. A. Fattah, M. O.
Gani, and N. P. Rana, “The new wave of ai-powered luxury brands
online shopping experience: The role of digital multisensory cues and
customers’ engagement,” Journal of Retailing and Consumer Services,
vol. 72, p. 103273, 2023.

[125] E. Sachdeva, N. Agarwal, S. Chundi, S. Roelofs, J. Li, B. Dariush,
C. Choi, and M. Kochenderfer, “Rank2tell: A multimodal driving
dataset for joint importance ranking and reasoning,” arXiv preprint
arXiv:2309.06597, 2023.

[126] C. Cui, Y. Ma, X. Cao, W. Ye, Y. Zhou, K. Liang, J. Chen, J. Lu,
Z. Yang, K.-D. Liao et al., “A survey on multimodal large language
models for autonomous driving,” arXiv preprint arXiv:2311.12320,
2023.

[127] A. B. Temsamani, A. K. Chavali, W. Vervoort, T. Tuytelaars, G. Rade-
vski, H. Van Hamme, K. Mets, M. Hutsebaut-Buysse, T. De Schepper,
and S. Latr´e, “A multimodal ai approach for intuitively instructable
autonomous systems: a case study of an autonomous off-highway
vehicle,” in The Eighteenth International Conference on Autonomic
and Autonomous Systems, ICAS 2022, May 22-26, 2022, Venice, Italy,
2022, pp. 31–39.

[128] J. Lee and S. Y. Shin, “Something that they never said: Multimodal
disinformation and source vividness in understanding the power of ai-
enabled deepfake news,” Media Psychology, vol. 25, no. 4, pp. 531–
546, 2022.

[129] S. Muppalla, S. Jia, and S. Lyu, “Integrating audio-visual features
for multimodal deepfake detection,” arXiv preprint arXiv:2310.03827,
2023.

[130] S. Kumar, M. K. Chaube, S. N. Nenavath, S. K. Gupta, and S. K.
Tetarave, “Privacy preservation and security challenges: a new frontier
multimodal machine learning research,” International Journal of Sensor
Networks, vol. 39, no. 4, pp. 227–245, 2022.

[131] J. Marchang and A. Di Nuovo, “Assistive multimodal robotic system
(amrsys): security and privacy issues, challenges, and possible solu-
tions,” Applied Sciences, vol. 12, no. 4, p. 2174, 2022.

[132] A. Pe˜na, I. Serna, A. Morales, J. Fierrez, A. Ortega, A. Herrarte, M. Al-
cantara, and J. Ortega-Garcia, “Human-centric multimodal machine
learning: Recent advances and testbed on ai-based recruitment,” SN
Computer Science, vol. 4, no. 5, p. 434, 2023.

[133] R. Wolfe and A. Caliskan, “American== white in multimodal language-
and-image ai,” in Proceedings of the 2022 AAAI/ACM Conference on
AI, Ethics, and Society, 2022, pp. 800–812.

[134] R. Wolfe, Y. Yang, B. Howe, and A. Caliskan, “Contrastive language-
vision ai models pretrained on web-scraped multimodal data exhibit
sexual objectiﬁcation bias,” in Proceedings of the 2023 ACM Confer-
ence on Fairness, Accountability, and Transparency, 2023, pp. 1174–
1185.

[135] M. Afshar, B. Sharma, D. Dligach, M. Oguss, R. Brown, N. Chhabra,
H. M. Thompson, T. Markossian, C. Joyce, M. M. Churpek et al.,
“Development and multimodal validation of a substance misuse algo-
rithm for referral to treatment using artiﬁcial intelligence (smart-ai): a
retrospective deep learning study,” The Lancet Digital Health, vol. 4,
no. 6, pp. e426–e435, 2022.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

26

[136] H. Alwahaby, M. Cukurova, Z. Papamitsiou, and M. Giannakos, “The
evidence of impact and ethical considerations of multimodal learning
analytics: A systematic literature review,” The Multimodal Learning
Analytics Handbook, pp. 289–325, 2022.

[137] Q. Miao, W. Zheng, Y. Lv, M. Huang, W. Ding, and F.-Y. Wang,
“Dao to hanoi via desci: Ai paradigm shifts from alphago to chatgpt,”
IEEE/CAA Journal of Automatica Sinica, vol. 10, no. 4, pp. 877–897,
2023.

[138] Y. Rong, “Roadmap of alphago to alphastar: Problems and challenges,”
in 2nd International Conference on Artiﬁcial Intelligence, Automation,
and High-Performance Computing (AIAHPC 2022), vol. 12348. SPIE,
2022, pp. 904–914.

[139] Y. Gao, M. Zhou, D. Liu, Z. Yan, S. Zhang, and D. N. Metaxas, “A
data-scalable transformer for medical image segmentation: architecture,
model efﬁciency, and benchmark,” arXiv preprint arXiv:2203.00131,
2022.

[140] W. Peebles and S. Xie, “Scalable diffusion models with transformers,”
in Proceedings of the IEEE/CVF International Conference on Com-
puter Vision, 2023, pp. 4195–4205.

[141] R. Pope, S. Douglas, A. Chowdhery, J. Devlin, J. Bradbury, J. Heek,
K. Xiao, S. Agrawal, and J. Dean, “Efﬁciently scaling transformer
inference,” Proceedings of Machine Learning and Systems, vol. 5,
2023.

[142] Y. Ding and M. Jia, “Convolutional transformer: An enhanced atten-
tion mechanism architecture for remaining useful life estimation of
bearings,” IEEE Transactions on Instrumentation and Measurement,
vol. 71, pp. 1–10, 2022.

[143] Y. Ding, M. Jia, Q. Miao, and Y. Cao, “A novel

time–frequency
transformer based on self–attention mechanism and its application in
fault diagnosis of rolling bearings,” Mechanical Systems and Signal
Processing, vol. 168, p. 108616, 2022.

[144] G. Wang, Y. Zhao, C. Tang, C. Luo, and W. Zeng, “When shift
operation meets vision transformer: An extremely simple alternative
to attention mechanism,” in Proceedings of the AAAI Conference on
Artiﬁcial Intelligence, vol. 36, no. 2, 2022, pp. 2423–2430.

[145] H. Cai, J. Li, M. Hu, C. Gan, and S. Han, “Efﬁcientvit: Lightweight
multi-scale attention for high-resolution dense prediction,” in Proceed-
ings of the IEEE/CVF International Conference on Computer Vision,
2023, pp. 17 302–17 313.

[146] X. Liu, H. Peng, N. Zheng, Y. Yang, H. Hu, and Y. Yuan, “Efﬁcientvit:
Memory efﬁcient vision transformer with cascaded group attention,”
in Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, 2023, pp. 14 420–14 430.

[147] Y. Li, Q. Fan, H. Huang, Z. Han, and Q. Gu, “A modiﬁed yolov8
detection network for uav aerial image recognition,” Drones, vol. 7,
no. 5, p. 304, 2023.

[148] F. M. Talaat and H. ZainEldin, “An improved ﬁre detection approach
based on yolo-v8 for smart cities,” Neural Computing and Applications,
vol. 35, no. 28, pp. 20 939–20 954, 2023.

[149] S. Tamang, B. Sen, A. Pradhan, K. Sharma, and V. K. Singh, “Enhanc-
ing covid-19 safety: Exploring yolov8 object detection for accurate face
mask classiﬁcation,” International Journal of Intelligent Systems and
Applications in Engineering, vol. 11, no. 2, pp. 892–897, 2023.
[150] J. Lu, R. Xiong, J. Tian, C. Wang, C.-W. Hsu, N.-T. Tsou, F. Sun,
and J. Li, “Battery degradation prediction against uncertain future con-
ditions with recurrent neural network enabled deep learning,” Energy
Storage Materials, vol. 50, pp. 139–151, 2022.

[151] A. Onan, “Bidirectional convolutional recurrent neural network archi-
tecture with group-wise enhancement mechanism for text sentiment
classiﬁcation,” Journal of King Saud University-Computer and Infor-
mation Sciences, vol. 34, no. 5, pp. 2098–2117, 2022.

[152] F. Shan, X. He, D. J. Armaghani, P. Zhang, and D. Sheng, “Success
and challenges in predicting tbm penetration rate using recurrent neural
networks,” Tunnelling and Underground Space Technology, vol. 130,
p. 104728, 2022.

[153] C. Sridhar, P. K. Pareek, R. Kalidoss, S. S. Jamal, P. K. Shukla, S. J.
Nuagah et al., “Optimal medical image size reduction model creation
using recurrent neural network and genpsowvq,” Journal of Healthcare
Engineering, vol. 2022, 2022.

[154] J. Zhu, Q. Jiang, Y. Shen, C. Qian, F. Xu, and Q. Zhu, “Application
of recurrent neural network to mechanical fault diagnosis: A review,”
Journal of Mechanical Science and Technology, vol. 36, no. 2, pp.
527–542, 2022.

[156] Z. Wei, X. Zhang, and M. Sun, “Extracting weighted ﬁnite automata
from recurrent neural networks for natural languages,” in International
Conference on Formal Engineering Methods.
Springer, 2022, pp.
370–385.

[157] F. Bonassi, M. Farina, J. Xie, and R. Scattolini, “On recurrent neural
networks for learning-based control: recent results and ideas for future
developments,” Journal of Process Control, vol. 114, pp. 92–104, 2022.
[158] Z. Guo, Y. Tang, R. Zhang, D. Wang, Z. Wang, B. Zhao, and
X. Li, “Viewrefer: Grasp the multi-view knowledge for 3d visual
grounding,” in Proceedings of the IEEE/CVF International Conference
on Computer Vision, 2023, pp. 15 372–15 383.

[159] C. Pan, Y. He, J. Peng, Q. Zhang, W. Sui, and Z. Zhang, “Baeformer:
Bi-directional and early interaction transformers for bird’s eye view
semantic segmentation,” in Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, 2023, pp. 9590–9599.

[160] P. Xu, X. Zhu, and D. A. Clifton, “Multimodal learning with transform-
ers: A survey,” IEEE Transactions on Pattern Analysis and Machine
Intelligence, 2023.

[161] I. Molenaar, S. de Mooij, R. Azevedo, M. Bannert, S. J¨arvel¨a, and
D. Gaˇsevi´c, “Measuring self-regulated learning and the role of ai: Five
years of research using multimodal multichannel data,” Computers in
Human Behavior, vol. 139, p. 107540, 2023.

[162] S. Steyaert, M. Pizurica, D. Nagaraj, P. Khandelwal, T. Hernandez-
Boussard, A. J. Gentles, and O. Gevaert, “Multimodal data fusion
for cancer biomarker discovery with deep learning,” Nature Machine
Intelligence, vol. 5, no. 4, pp. 351–362, 2023.

[163] V. Rani, S. T. Nabi, M. Kumar, A. Mittal, and K. Kumar, “Self-
supervised learning: A succinct review,” Archives of Computational
Methods in Engineering, vol. 30, no. 4, pp. 2761–2775, 2023.
[164] M. C. Schiappa, Y. S. Rawat, and M. Shah, “Self-supervised learning
for videos: A survey,” ACM Computing Surveys, vol. 55, no. 13s, pp.
1–37, 2023.

[165] J. Yu, H. Yin, X. Xia, T. Chen, J. Li, and Z. Huang, “Self-supervised
learning for recommender systems: A survey,” IEEE Transactions on
Knowledge and Data Engineering, 2023.

[166] V. Bharti, A. Kumar, V. Purohit, R. Singh, A. K. Singh, and S. K.
Singh, “A label efﬁcient semi self-supervised learning framework for
iot devices in industrial process,” IEEE Transactions on Industrial
Informatics, 2023.

[167] D. Sam and J. Z. Kolter, “Losses over labels: Weakly supervised
loss construction,” in Proceedings of the AAAI
learning via direct
Conference on Artiﬁcial Intelligence, vol. 37, no. 8, 2023, pp. 9695–
9703.

[168] M. Wang, P. Xie, Y. Du, and X. Hu, “T5-based model for abstractive
summarization: A semi-supervised learning approach with consistency
loss functions,” Applied Sciences, vol. 13, no. 12, p. 7111, 2023.
[169] Q. Li, X. Peng, Y. Qiao, and Q. Hao, “Unsupervised person re-
identiﬁcation with multi-label learning guided self-paced clustering,”
Pattern Recognition, vol. 125, p. 108521, 2022.

[170] P. Nancy, H. Pallathadka, M. Naved, K. Kaliyaperumal, K. Arumugam,
and V. Garchar, “Deep learning and machine learning based efﬁcient
framework for image based plant disease classiﬁcation and detection,”
in 2022 International Conference on Advanced Computing Technolo-
gies and Applications (ICACTA).

IEEE, 2022, pp. 1–6.

[171] P. An, Z. Wang, and C. Zhang, “Ensemble unsupervised autoencoders
and gaussian mixture model for cyberattack detection,” Information
Processing & Management, vol. 59, no. 2, p. 102844, 2022.

[172] S. Yan, H. Shao, Y. Xiao, B. Liu, and J. Wan, “Hybrid robust convo-
lutional autoencoder for unsupervised anomaly detection of machine
tools under noises,” Robotics and Computer-Integrated Manufacturing,
vol. 79, p. 102441, 2023.

[173] E. Ayanoglu, K. Davaslioglu, and Y. E. Sagduyu, “Machine learning
in nextg networks via generative adversarial networks,” IEEE Trans-
actions on Cognitive Communications and Networking, vol. 8, no. 2,
pp. 480–501, 2022.

[174] K. Yan, X. Chen, X. Zhou, Z. Yan, and J. Ma, “Physical model
informed fault detection and diagnosis of air handling units based
on transformer generative adversarial network,” IEEE Transactions on
Industrial Informatics, vol. 19, no. 2, pp. 2192–2199, 2022.

[175] N.-R. Zhou, T.-F. Zhang, X.-W. Xie, and J.-Y. Wu, “Hybrid quantum–
classical generative adversarial networks for image generation via
learning discrete distribution,” Signal Processing: Image Communica-
tion, vol. 110, p. 116891, 2023.

[155] S. Lin, W. Lin, W. Wu, F. Zhao, R. Mo, and H. Zhang, “Segrnn: Seg-
ment recurrent neural network for long-term time series forecasting,”
arXiv preprint arXiv:2308.11200, 2023.

[176] P. Ladosz, L. Weng, M. Kim, and H. Oh, “Exploration in deep
reinforcement learning: A survey,” Information Fusion, vol. 85, pp.
1–22, 2022.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

27

[177] Y. Matsuo, Y. LeCun, M. Sahani, D. Precup, D. Silver, M. Sugiyama,
E. Uchibe, and J. Morimoto, “Deep learning, reinforcement learning,
and world models,” Neural Networks, vol. 152, pp. 267–275, 2022.

[178] D. Bertoin, A. Zouitine, M. Zouitine, and E. Rachelson, “Look where
you look! saliency-guided q-networks for generalization in visual
reinforcement learning,” Advances in Neural Information Processing
Systems, vol. 35, pp. 30 693–30 706, 2022.

[179] A. Haﬁz, “A survey of deep q-networks used for reinforcement
learning: State of the art,” Intelligent Communication Technologies and
Virtual Mobile Networks: Proceedings of ICICV 2022, pp. 393–402,
2022.

[180] A. Haﬁz, M. Hassaballah, A. Alqahtani, S. Alsubai, and M. A. Hameed,
“Reinforcement learning with an ensemble of binary action deep q-
networks.” Computer Systems Science & Engineering, vol. 46, no. 3,
2023.

[181] A. Alagha, S. Singh, R. Mizouni, J. Bentahar, and H. Otrok, “Target
localization using multi-agent deep reinforcement learning with prox-
imal policy optimization,” Future Generation Computer Systems, vol.
136, pp. 342–357, 2022.

[182] S. S. Hassan, Y. M. Park, Y. K. Tun, W. Saad, Z. Han, and C. S. Hong,
“3to: Thz-enabled throughput and trajectory optimization of uavs in 6g
networks by proximal policy optimization deep reinforcement learn-
ing,” in ICC 2022-IEEE International Conference on Communications.
IEEE, 2022, pp. 5712–5718.

[183] A. K. Jayant and S. Bhatnagar, “Model-based safe deep reinforcement
learning via a constrained proximal policy optimization algorithm,”
Advances in Neural Information Processing Systems, vol. 35, pp.
24 432–24 445, 2022.

[184] B. Lin, “Reinforcement learning and bandits for speech and language
processing: Tutorial, review and outlook,” Expert Systems with Appli-
cations, p. 122254, 2023.

[185] B. Luo, Z. Wu, F. Zhou, and B.-C. Wang, “Human-in-the-loop rein-
forcement learning in continuous-action space,” IEEE Transactions on
Neural Networks and Learning Systems, 2023.

[186] A. Raza, K. P. Tran, L. Koehl, and S. Li, “Designing ecg monitoring
healthcare system with federated transfer learning and explainable ai,”
Knowledge-Based Systems, vol. 236, p. 107763, 2022.

[187] S. Siahpour, X. Li, and J. Lee, “A novel transfer learning approach
life prediction for incomplete dataset,” IEEE
in remaining useful
Transactions on Instrumentation and Measurement, vol. 71, pp. 1–11,
2022.

[188] Z. Guo, K. Lin, X. Chen, and C.-Y. Chit, “Transfer learning for angle
of arrivals estimation in massive mimo system,” in 2022 IEEE/CIC
International Conference on Communications in China (ICCC).
IEEE,
2022, pp. 506–511.

[189] S. Liu, Y. Lu, P. Zheng, H. Shen, and J. Bao, “Adaptive reconstruction
of digital twins for machining systems: A transfer learning approach,”
Robotics and Computer-Integrated Manufacturing, vol. 78, p. 102390,
2022.

[190] H. Liu, J. Liu, L. Cui, Z. Teng, N. Duan, M. Zhou, and Y. Zhang,
“Logiqa 2.0—an improved dataset for logical reasoning in natural
language understanding,” IEEE/ACM Transactions on Audio, Speech,
and Language Processing, 2023.

[191] Y. Meng, J. Huang, Y. Zhang, and J. Han, “Generating training data
with language models: Towards zero-shot language understanding,”
Advances in Neural Information Processing Systems, vol. 35, pp. 462–
477, 2022.

[192] R. M. Samant, M. R. Bachute, S. Gite, and K. Kotecha, “Framework
for deep learning-based language models using multi-task learning in
natural
language understanding: A systematic literature review and
future directions,” IEEE Access, vol. 10, pp. 17 078–17 097, 2022.

[193] H. Weld, X. Huang, S. Long, J. Poon, and S. C. Han, “A survey
of joint intent detection and slot ﬁlling models in natural language
understanding,” ACM Computing Surveys, vol. 55, no. 8, pp. 1–38,
2022.

[194] S. Ajmal, A. A. I. Ahmed, and C. Jalota, “Natural language process-
ing in improving information retrieval and knowledge discovery in
healthcare conversational agents,” Journal of Artiﬁcial Intelligence and
Machine Learning in Management, vol. 7, no. 1, pp. 34–47, 2023.

[195] A. Montejo-R´aez and S. M. Jim´enez-Zafra, “Current approaches and
applications in natural language processing,” Applied Sciences, vol. 12,
no. 10, p. 4859, 2022.

[196] K. Vijayan, O. Anand, and A. Sahaj, “Language-agnostic text process-
ing for information extraction,” in CS & IT Conference Proceedings,
vol. 12, no. 23. CS & IT Conference Proceedings, 2022.

[197] C. D. Manning, “Human language understanding & reasoning,”

Daedalus, vol. 151, no. 2, pp. 127–138, 2022.

[198] W. Peng, D. Xu, T. Xu, J. Zhang, and E. Chen, “Are gpt embeddings
useful for ads and recommendation?” in International Conference on
Knowledge Science, Engineering and Management.
Springer, 2023,
pp. 151–162.

[199] E. Erdem, M. Kuyu, S. Yagcioglu, A. Frank, L. Parcalabescu, B. Plank,
A. Babii, O. Turuta, A. Erdem, I. Calixto et al., “Neural natural
language generation: A survey on multilinguality, multimodality, con-
trollability and learning,” Journal of Artiﬁcial Intelligence Research,
vol. 73, pp. 1131–1207, 2022.

[200] J. Qian, L. Dong, Y. Shen, F. Wei, and W. Chen, “Controllable
natural language generation with contrastive preﬁxes,” arXiv preprint
arXiv:2202.13257, 2022.

[201] H. Rashkin, V. Nikolaev, M. Lamm, L. Aroyo, M. Collins, D. Das,
S. Petrov, G. S. Tomar, I. Turc, and D. Reitter, “Measuring attribution
in natural language generation models,” Computational Linguistics, pp.
1–64, 2023.

[202] A. K. Pandey and S. S. Roy, “Natural

language generation using
sequential models: A survey,” Neural Processing Letters, pp. 1–34,
2023.

[203] J. Y. Khan and G. Uddin, “Automatic code documentation generation
the 37th IEEE/ACM International

using gpt-3,” in Proceedings of
Conference on Automated Software Engineering, 2022, pp. 1–6.
[204] Y. K. Dwivedi, N. Kshetri, L. Hughes, E. L. Slade, A. Jeyaraj, A. K.
Kar, A. M. Baabdullah, A. Koohang, V. Raghavan, M. Ahuja et al.,
““so what if chatgpt wrote it?” multidisciplinary perspectives on op-
portunities, challenges and implications of generative conversational ai
for research, practice and policy,” International Journal of Information
Management, vol. 71, p. 102642, 2023.

[205] T. Fu, S. Gao, X. Zhao, J.-r. Wen, and R. Yan, “Learning towards
conversational ai: A survey,” AI Open, vol. 3, pp. 14–28, 2022.
[206] H. Ji, I. Han, and Y. Ko, “A systematic review of conversational
ai in language education: Focusing on the collaboration with human
teachers,” Journal of Research on Technology in Education, vol. 55,
no. 1, pp. 48–63, 2023.

[207] Y. Wan, W. Wang, P. He, J. Gu, H. Bai, and M. R. Lyu, “Biasasker:
Measuring the bias in conversational ai system,” in Proceedings of
the 31st ACM Joint European Software Engineering Conference and
Symposium on the Foundations of Software Engineering, 2023, pp.
515–527.

[208] S. Kusal, S. Patil, J. Choudrie, K. Kotecha, S. Mishra, and A. Abraham,
“Ai-based conversational agents: A scoping review from technologies
to future directions,” IEEE Access, 2022.

[209] Z. Xiao, “Seeing us through machines: designing and building con-
versational ai to understand humans,” Ph.D. dissertation, University of
Illinois at Urbana-Champaign, 2023.

[210] H.-K. Ko, G. Park, H. Jeon, J. Jo, J. Kim, and J. Seo, “Large-scale
text-to-image generation models for visual artists’ creative works,” in
Proceedings of the 28th International Conference on Intelligent User
Interfaces, 2023, pp. 919–933.

[211] A. Pearson, “The rise of crealtives: Using ai to enable and speed up
the creative process,” Journal of AI, Robotics & Workplace Automation,
vol. 2, no. 2, pp. 101–114, 2023.

[212] J. Rezwana and M. L. Maher, “Designing creative ai partners with
coﬁ: A framework for modeling interaction in human-ai co-creative
systems,” ACM Transactions on Computer-Human Interaction, vol. 30,
no. 5, pp. 1–28, 2023.

[213] S. Sharma and S. Bvuma, “Generative adversarial networks (gans) for
creative applications: Exploring art and music generation,” Interna-
tional Journal of Multidisciplinary Innovation and Research Method-
ology, ISSN: 2960-2068, vol. 2, no. 4, pp. 29–33, 2023.

[214] B. Attard-Frost, A. De los R´ıos, and D. R. Walters, “The ethics of ai
business practices: a review of 47 ai ethics guidelines,” AI and Ethics,
vol. 3, no. 2, pp. 389–406, 2023.

[215] A. Gardner, A. L. Smith, A. Steventon, E. Coughlan, and M. Oldﬁeld,
“Ethical funding for trustworthy ai: proposals to address the respon-
sibilities of funders to ensure that projects adhere to trustworthy ai
practice,” AI and Ethics, pp. 1–15, 2022.

[216] J. Schuett, “Three lines of defense against risks from ai,” AI &

SOCIETY, pp. 1–15, 2023.

[217] M. Sloane and J. Zakrzewski, “German ai start-ups and “ai ethics”:
Using a social practice lens for assessing and implementing socio-
technical innovation,” in Proceedings of the 2022 ACM Conference on
Fairness, Accountability, and Transparency, 2022, pp. 935–947.
[218] M. Vasconcelos, C. Cardonha, and B. Gonc¸alves, “Modeling epistemo-
logical principles for bias mitigation in ai systems: an illustration in
hiring decisions,” in Proceedings of the 2018 AAAI/ACM Conference
on AI, Ethics, and Society, 2018, pp. 323–329.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

28

[219] Y. Yang, A. Gupta, J. Feng, P. Singhal, V. Yadav, Y. Wu, P. Natarajan,
V. Hedau, and J. Joo, “Enhancing fairness in face detection in computer
vision systems by demographic bias mitigation,” in Proceedings of the
2022 AAAI/ACM Conference on AI, Ethics, and Society, 2022, pp. 813–
822.

[220] R. Schwartz, A. Vassilev, K. Greene, L. Perine, A. Burt, P. Hall et al.,
“Towards a standard for identifying and managing bias in artiﬁcial
intelligence,” NIST special publication, vol. 1270, no. 10.6028, 2022.
[221] W. Guo and A. Caliskan, “Detecting emergent intersectional biases:
Contextualized word embeddings contain a distribution of human-like
biases,” in Proceedings of the 2021 AAAI/ACM Conference on AI,
Ethics, and Society, 2021, pp. 122–133.

[222] Y. Kong, “Are “intersectionally fair” ai algorithms really fair to women
of color? a philosophical analysis,” in Proceedings of the 2022 ACM
Conference on Fairness, Accountability, and Transparency, 2022, pp.
485–494.

[223] Y. C. Tan and L. E. Celis, “Assessing social and intersectional biases in
contextualized word representations,” Advances in neural information
processing systems, vol. 32, 2019.

[224] L. Cheng, A. Mosallanezhad, P. Sheth, and H. Liu, “Causal learning

for socially responsible ai,” arXiv preprint arXiv:2104.12278, 2021.

[225] J. D. Correa, J. Tian, and E. Bareinboim, “Identiﬁcation of causal
effects in the presence of selection bias,” in Proceedings of the AAAI
Conference on Artiﬁcial Intelligence, vol. 33, no. 01, 2019, pp. 2744–
2751.

[226] B. Ghai and K. Mueller, “D-bias: a causality-based human-in-the-
loop system for tackling algorithmic bias,” IEEE Transactions on
Visualization and Computer Graphics, vol. 29, no. 1, pp. 473–482,
2022.

[227] J. N. Yan, Z. Gu, H. Lin, and J. M. Rzeszotarski, “Silva: Interactively
assessing machine learning fairness using causality,” in Proceedings of
the 2020 chi conference on human factors in computing systems, 2020,
pp. 1–13.

[228] E. Bertino, M. Kantarcioglu, C. G. Akcora, S. Samtani, S. Mittal,
and M. Gupta, “Ai for security and security for ai,” in Proceedings
of the Eleventh ACM Conference on Data and Application Security
and Privacy, 2021, pp. 333–334.

[229] H. Susanto, L. F. Yie, D. Rosiyadi, A. I. Basuki, and D. Setiana, “Data
security for connected governments and organisations: Managing au-
tomation and artiﬁcial intelligence,” in Web 2.0 and cloud technologies
for implementing connected government.
IGI Global, 2021, pp. 229–
251.

[230] S. Dilmaghani, M. R. Brust, G. Danoy, N. Cassagnes, J. Pecero, and
P. Bouvry, “Privacy and security of big data in ai systems: A research
and standards perspective,” in 2019 IEEE International Conference on
Big Data (Big Data).

IEEE, 2019, pp. 5737–5743.

[231] T. McIntosh, “Intercepting ransomware attacks with staged event-

driven access control,” Ph.D. dissertation, La Trobe, 2022.

[232] T. McIntosh, A. Kayes, Y.-P. P. Chen, A. Ng, and P. Watters, “Applying
staged event-driven access control to combat ransomware,” Computers
& Security, vol. 128, p. 103160, 2023.

[233] P. Hummel, M. Braun, M. Tretter, and P. Dabrock, “Data sovereignty:
A review,” Big Data & Society, vol. 8, no. 1, p. 2053951720982012,
2021.

[234] M. Lukings and A. Habibi Lashkari, “Data sovereignty,” in Under-
standing Cybersecurity Law in Data Sovereignty and Digital Gover-
nance: An Overview from a Legal Perspective.
Springer, 2022, pp.
1–38.

[235] M. Hickok, “Lessons learned from ai ethics principles for future

actions,” AI and Ethics, vol. 1, no. 1, pp. 41–47, 2021.

[236] J. Zhou and F. Chen, “Ai ethics: From principles to practice,” AI &

SOCIETY, pp. 1–11, 2022.

[237] J. A. Kroll, “Outlining traceability: A principle for operationalizing
accountability in computing systems,” in Proceedings of the 2021 ACM
Conference on Fairness, Accountability, and Transparency, 2021, pp.
758–771.

[238] A. Oseni, N. Moustafa, H. Janicke, P. Liu, Z. Tari, and A. Vasilakos,
intelligence: Opportunities and

“Security and privacy for artiﬁcial
challenges,” arXiv preprint arXiv:2102.04661, 2021.

[239] B. C. Stahl and D. Wright, “Ethics and privacy in ai and big data:
Implementing responsible research and innovation,” IEEE Security &
Privacy, vol. 16, no. 3, pp. 26–33, 2018.

[240] C. Ma, J. Li, K. Wei, B. Liu, M. Ding, L. Yuan, Z. Han, and H. V.
Poor, “Trusted ai in multiagent systems: An overview of privacy and
security for distributed learning,” Proceedings of the IEEE, vol. 111,
no. 9, pp. 1097–1132, 2023.

[241] M. Song, Z. Wang, Z. Zhang, Y. Song, Q. Wang, J. Ren, and H. Qi,
“Analyzing user-level privacy attack against federated learning,” IEEE
Journal on Selected Areas in Communications, vol. 38, no. 10, pp.
2430–2444, 2020.

[242] I. Misra and L. v. d. Maaten, “Self-supervised learning of pretext-
invariant representations,” in Proceedings of the IEEE/CVF conference
on computer vision and pattern recognition, 2020, pp. 6707–6717.

[243] X. Zhai, A. Oliver, A. Kolesnikov, and L. Beyer, “S4l: Self-supervised
semi-supervised learning,” in Proceedings of the IEEE/CVF interna-
tional conference on computer vision, 2019, pp. 1476–1485.

[244] T. Chen, X. Zhai, M. Ritter, M. Lucic, and N. Houlsby, “Self-supervised
gans via auxiliary rotation loss,” in Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition, 2019, pp.
12 154–12 163.

[245] S. Jenni and P. Favaro, “Self-supervised feature learning by learning
to spot artifacts,” in Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, 2018, pp. 2733–2742.

[246] P. Patel, N. Kumari, M. Singh, and B. Krishnamurthy, “Lt-gan: Self-
supervised gan with latent transformation detection,” in Proceedings of
the IEEE/CVF winter conference on applications of computer vision,
2021, pp. 3189–3198.

[247] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, “A simple frame-
work for contrastive learning of visual representations,” in International
conference on machine learning. PMLR, 2020, pp. 1597–1607.
[248] K. He, H. Fan, Y. Wu, S. Xie, and R. Girshick, “Momentum contrast
for unsupervised visual representation learning,” in Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition,
2020, pp. 9729–9738.

[249] A. T. Liu, S.-W. Li, and H.-y. Lee, “Tera: Self-supervised learning of
transformer encoder representation for speech,” IEEE/ACM Transac-
tions on Audio, Speech, and Language Processing, vol. 29, pp. 2351–
2366, 2021.

[250] Y. Pang, W. Wang, F. E. Tay, W. Liu, Y. Tian, and L. Yuan, “Masked
autoencoders for point cloud self-supervised learning,” in European
conference on computer vision. Springer, 2022, pp. 604–621.
[251] T. Hospedales, A. Antoniou, P. Micaelli, and A. Storkey, “Meta-
learning in neural networks: A survey,” IEEE transactions on pattern
analysis and machine intelligence, vol. 44, no. 9, pp. 5149–5169, 2021.
[252] R. Vilalta and Y. Drissi, “A perspective view and survey of meta-
learning,” Artiﬁcial intelligence review, vol. 18, pp. 77–95, 2002.
[253] M. Al-Shedivat, L. Li, E. Xing, and A. Talwalkar, “On data efﬁciency
of meta-learning,” in International Conference on Artiﬁcial Intelligence
and Statistics. PMLR, 2021, pp. 1369–1377.

[254] Y. Hu, R. Liu, X. Li, D. Chen, and Q. Hu, “Task-sequencing meta
learning for intelligent few-shot fault diagnosis with limited data,”
IEEE Transactions on Industrial Informatics, vol. 18, no. 6, pp. 3894–
3904, 2021.

[255] S. Baik, J. Choi, H. Kim, D. Cho, J. Min, and K. M. Lee, “Meta-
learning with task-adaptive loss function for few-shot learning,” in
Proceedings of the IEEE/CVF international conference on computer
vision, 2021, pp. 9465–9474.

[256] Y. Chen, Z. Liu, H. Xu, T. Darrell, and X. Wang, “Meta-baseline:
Exploring simple meta-learning for few-shot learning,” in Proceedings
of the IEEE/CVF international conference on computer vision, 2021,
pp. 9062–9071.

[257] M. A. Jamal and G.-J. Qi, “Task agnostic meta-learning for few-shot
learning,” in Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition, 2019, pp. 11 719–11 727.

[258] R. Behnia, M. R. Ebrahimi, J. Pacheco, and B. Padmanabhan, “Ew-
tune: A framework for privately ﬁne-tuning large language models with
differential privacy,” in 2022 IEEE International Conference on Data
Mining Workshops (ICDMW).

IEEE, 2022, pp. 560–566.

[259] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du,
A. M. Dai, and Q. V. Le, “Finetuned language models are zero-shot
learners,” arXiv preprint arXiv:2109.01652, 2021.

[260] W. Kuang, B. Qian, Z. Li, D. Chen, D. Gao, X. Pan, Y. Xie, Y. Li,
B. Ding, and J. Zhou, “Federatedscope-llm: A comprehensive package
for ﬁne-tuning large language models in federated learning,” arXiv
preprint arXiv:2309.00363, 2023.

[261] M. Nguyen, K. Kishan, T. Nguyen, A. Chadha, and T. Vu, “Efﬁ-
cient ﬁne-tuning large language models for knowledge-aware response
planning,” in Joint European Conference on Machine Learning and
Knowledge Discovery in Databases. Springer, 2023, pp. 593–611.

[262] M. Engelbach, D. Klau, F. Scheerer, J. Drawehn, and M. Kintz,
“Fine-tuning and aligning question answering models for complex
information extraction tasks,” arXiv preprint arXiv:2309.14805, 2023.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

29

[263] T. T. Nguyen, C. Wilson, and J. Dalins, “Fine-tuning llama 2 large
language models for detecting online sexual predatory chats and
abusive texts,” arXiv preprint arXiv:2308.14683, 2023.

[264] Q. Zhou, C. Yu, S. Zhang, S. Wu, Z. Wang, and F. Wang, “Regionblip:
A uniﬁed multi-modal pre-training framework for holistic and regional
comprehension,” arXiv preprint arXiv:2308.02299, 2023.

[265] T. Arnold and D. Kasenberg, “Value alignment or misalignment - what
will keep systems accountable?” in AAAI Workshop on AI, Ethics, and
Society, 2017.

[266] I. Gabriel and V. Ghazavi, “The challenge of value alignment: From
fairer algorithms to ai safety,” arXiv preprint arXiv:2101.06060, 2021.
[267] S. Nyholm, “Responsibility gaps, value alignment, and meaningful
human control over artiﬁcial intelligence,” in Risk and responsibility
in context. Routledge, 2023, pp. 191–213.

[268] S. Wu, H. Fei, L. Qu, W. Ji, and T.-S. Chua, “Next-gpt: Any-to-any

multimodal llm,” arXiv preprint arXiv:2309.05519, 2023.

[269] K. Bayoudh, R. Knani, F. Hamdaoui, and A. Mtibaa, “A survey
on deep multimodal learning for computer vision: advances, trends,
applications, and datasets,” The Visual Computer, pp. 1–32, 2021.

[270] P. Hu, L. Zhen, D. Peng, and P. Liu, “Scalable deep multimodal learning
for cross-modal retrieval,” in Proceedings of the 42nd international
ACM SIGIR conference on research and development in information
retrieval, 2019, pp. 635–644.

[271] A. Rahate, R. Walambe, S. Ramanna, and K. Kotecha, “Multimodal co-
learning: Challenges, applications with datasets, recent advances and
future directions,” Information Fusion, vol. 81, pp. 203–239, 2022.

[272] L. Che, J. Wang, Y. Zhou, and F. Ma, “Multimodal federated learning:

A survey,” Sensors, vol. 23, no. 15, p. 6986, 2023.

[273] P. P. Liang, Y. Lyu, X. Fan, Z. Wu, Y. Cheng, J. Wu, L. Chen, P. Wu,
M. A. Lee, Y. Zhu et al., “Multibench: Multiscale benchmarks for
multimodal representation learning,” arXiv preprint arXiv:2107.07502,
2021.

[274] Z. Ashktorab, Q. V. Liao, C. Dugan, J. Johnson, Q. Pan, W. Zhang,
S. Kumaravel, and M. Campbell, “Human-ai collaboration in a co-
operative game setting: Measuring social perception and outcomes,”
Proceedings of the ACM on Human-Computer Interaction, vol. 4, no.
CSCW2, pp. 1–20, 2020.

[275] P. Esmaeilzadeh, T. Mirzaei, and S. Dharanikota, “Patients’ perceptions
toward human–artiﬁcial intelligence interaction in health care: exper-
imental study,” Journal of medical Internet research, vol. 23, no. 11,
p. e25856, 2021.

[276] M. Nazar, M. M. Alam, E. Yaﬁ, and M. M. Su’ud, “A systematic review
of human–computer interaction and explainable artiﬁcial intelligence in
healthcare with artiﬁcial intelligence techniques,” IEEE Access, vol. 9,
pp. 153 316–153 348, 2021.

[277] A. S. Rajawat, R. Rawat, K. Barhanpurkar, R. N. Shaw, and A. Ghosh,
“Robotic process automation with increasing productivity and improv-
ing product quality using artiﬁcial intelligence and machine learning,”
in Artiﬁcial Intelligence for Future Generation Robotics.
Elsevier,
2021, pp. 1–13.

[278] S. Mohseni, N. Zarei, and E. D. Ragan, “A multidisciplinary survey
and framework for design and evaluation of explainable ai systems,”
ACM Transactions on Interactive Intelligent Systems (TiiS), vol. 11, no.
3-4, pp. 1–45, 2021.

[279] M. C. Buehler and T. H. Weisswange, “Theory of mind based com-
munication for human agent cooperation,” in 2020 IEEE International
Conference on Human-Machine Systems (ICHMS).
IEEE, 2020, pp.
1–6.

[280] M. M. C¸ elikok, T. Peltola, P. Daee, and S. Kaski, “Interactive ai with

a theory of mind,” arXiv preprint arXiv:1912.05284, 2019.

[281] A. Dafoe, E. Hughes, Y. Bachrach, T. Collins, K. R. McKee, J. Z.
Leibo, K. Larson, and T. Graepel, “Open problems in cooperative ai,”
arXiv preprint arXiv:2012.08630, 2020.

[282] S. Bubeck, V. Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz,
E. Kamar, P. Lee, Y. T. Lee, Y. Li, S. Lundberg et al., “Sparks of
intelligence: Early experiments with gpt-4,” arXiv
artiﬁcial general
preprint arXiv:2303.12712, 2023.

[283] N. Fei, Z. Lu, Y. Gao, G. Yang, Y. Huo, J. Wen, H. Lu, R. Song,
X. Gao, T. Xiang et al., “Towards artiﬁcial general intelligence via a
multimodal foundation model,” Nature Communications, vol. 13, no. 1,
p. 3094, 2022.

[284] R. Williams and R. Yampolskiy, “Understanding and avoiding ai

failures: A practical guide,” Philosophies, vol. 6, no. 3, p. 53, 2021.

[285] W. Fedus, B. Zoph, and N. Shazeer, “Switch transformers: Scaling
to trillion parameter models with simple and efﬁcient sparsity,” The
Journal of Machine Learning Research, vol. 23, no. 1, pp. 5232–5270,
2022.

[286] S. Shen, L. Hou, Y. Zhou, N. Du, S. Longpre, J. Wei, H. W.
Chung, B. Zoph, W. Fedus, X. Chen et al., “Mixture-of-experts meets
instruction tuning: A winning combination for large language models,”
arXiv preprint arXiv:2305.14705, 2023.

[287] S. Rajbhandari, C. Li, Z. Yao, M. Zhang, R. Y. Aminabadi, A. A.
Awan, J. Rasley, and Y. He, “Deepspeed-moe: Advancing mixture-of-
experts inference and training to power next-generation ai scale,” in
International Conference on Machine Learning.
PMLR, 2022, pp.
18 332–18 346.

[288] L. Shen, Z. Wu, W. Gong, H. Hao, Y. Bai, H. Wu, X. Wu, J. Bian,
H. Xiong, D. Yu et al., “Se-moe: A scalable and efﬁcient mixture-
of-experts distributed training and inference system,” arXiv preprint
arXiv:2205.10034, 2022.

[289] C. Hwang, W. Cui, Y. Xiong, Z. Yang, Z. Liu, H. Hu, Z. Wang, R. Salas,
J. Jose, P. Ram et al., “Tutel: Adaptive mixture-of-experts at scale,”
Proceedings of Machine Learning and Systems, vol. 5, 2023.
[290] Y. Wang, S. Mukherjee, X. Liu, J. Gao, A. H. Awadallah, and J. Gao,
“Adamix: Mixture-of-adapter for parameter-efﬁcient
tuning of large
language models,” arXiv preprint arXiv:2205.12410, vol. 1, no. 2, p. 4,
2022.

[291] T. Chen, Z. Zhang, A. Jaiswal, S. Liu, and Z. Wang, “Sparse moe
as the new dropout: Scaling dense and self-slimmable transformers,”
arXiv preprint arXiv:2303.01610, 2023.

[292] H. Zhu, B. He, and X. Zhang, “Multi-gate mixture-of-experts stacked
autoencoders for quality prediction in blast furnace ironmaking,” ACS
omega, vol. 7, no. 45, pp. 41 296–41 303, 2022.

[293] Z. Chi, L. Dong, S. Huang, D. Dai, S. Ma, B. Patra, S. Singhal,
P. Bajaj, X. Song, X.-L. Mao et al., “On the representation collapse of
sparse mixture of experts,” Advances in Neural Information Processing
Systems, vol. 35, pp. 34 600–34 613, 2022.

[294] S. Gupta, S. Mukherjee, K. Subudhi, E. Gonzalez, D. Jose, A. H.
Awadallah, and J. Gao, “Sparsely activated mixture-of-experts are
robust multi-task learners,” arXiv preprint arXiv:2204.07689, 2022.

[295] N. Dikkala, N. Ghosh, R. Meka, R. Panigrahy, N. Vyas, and X. Wang,
“On the beneﬁts of learning to route in mixture-of-experts models,” in
Proceedings of the 2023 Conference on Empirical Methods in Natural
Language Processing, 2023, pp. 9376–9396.

[296] N. Dryden and T. Hoeﬂer, “Spatial mixture-of-experts,” Advances in
Neural Information Processing Systems, vol. 35, pp. 11 697–11 713,
2022.

[297] Z. You, S. Feng, D. Su, and D. Yu, “Speechmoe2: Mixture-of-
experts model with improved routing,” in ICASSP 2022-2022 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP).

IEEE, 2022, pp. 7217–7221.

[298] J. Puigcerver, R. Jenatton, C. Riquelme, P. Awasthi, and S. Bhojana-
palli, “On the adversarial robustness of mixture of experts,” Advances
in Neural Information Processing Systems, vol. 35, pp. 9660–9671,
2022.

[299] J. Li, Y. Jiang, Y. Zhu, C. Wang, and H. Xu, “Accelerating distributed
{MoE} training and inference with lina,” in 2023 USENIX Annual
Technical Conference (USENIX ATC 23), 2023, pp. 945–959.
[300] L. Wu, M. Liu, Y. Chen, D. Chen, X. Dai, and L. Yuan, “Residual

mixture of experts,” arXiv preprint arXiv:2204.09636, 2022.

[301] B. Zoph, I. Bello, S. Kumar, N. Du, Y. Huang, J. Dean, N. Shazeer, and
W. Fedus, “Designing effective sparse expert models,” arXiv preprint
arXiv:2202.08906, vol. 2, 2022.

[302] ——, “St-moe: Designing stable and transferable sparse expert mod-

els,” arXiv preprint arXiv:2202.08906, 2022.

[303] Y. Chow, A. Tulepbergenov, O. Nachum, M. Ryu, M. Ghavamzadeh,
and C. Boutilier, “A mixture-of-expert approach to rl-based dialogue
management,” arXiv preprint arXiv:2206.00059, 2022.

[304] Z. Fan, R. Sarkar, Z. Jiang, T. Chen, K. Zou, Y. Cheng, C. Hao, Z. Wang
et al., “M3vit: Mixture-of-experts vision transformer for efﬁcient multi-
task learning with model-accelerator co-design,” Advances in Neural
Information Processing Systems, vol. 35, pp. 28 441–28 457, 2022.

[305] T. Zadouri, A.

¨Ust¨un, A. Ahmadian, B. Ermis¸, A. Locatelli, and
S. Hooker, “Pushing mixture of experts to the limit: Extremely
instruction tuning,” arXiv preprint
parameter efﬁcient moe for
arXiv:2309.05444, 2023.

[306] J. Zhu, X. Zhu, W. Wang, X. Wang, H. Li, X. Wang, and J. Dai, “Uni-
perceiver-moe: Learning sparse generalist models with conditional
moes,” Advances in Neural Information Processing Systems, vol. 35,
pp. 2664–2678, 2022.

[307] F. Dou, J. Ye, G. Yuan, Q. Lu, W. Niu, H. Sun, L. Guan, G. Lu,
G. Mai, N. Liu et al., “Towards artiﬁcial general intelligence (agi)
in the internet of things (iot): Opportunities and challenges,” arXiv
preprint arXiv:2309.07438, 2023.

JOURNAL OF LATEX CLASS FILES, VOL. 1, NO. 1, DECEMBER 2023

30

from twitter,” Journal of university teaching & learning practice,
vol. 19, no. 3, p. 02, 2022.

[308] Z. Jia, X. Li, Z. Ling, S. Liu, Y. Wu, and H. Su, “Improving
policy optimization with generalist-specialist learning,” in International
Conference on Machine Learning. PMLR, 2022, pp. 10 104–10 119.
[309] M. Simeone, “Unknown future, repeated present: A narrative-centered
analysis of long-term ai discourse,” Humanist Studies & the Digital
Age, vol. 7, no. 1, 2022.

[310] A. Nair and F. Banaei-Kashani, “Bridging the gap between ar-
tiﬁcial
intelligence: A ten com-
mandment framework for human-like intelligence,” arXiv preprint
arXiv:2210.09366, 2022.

intelligence and artiﬁcial general

[311] M. H. Jarrahi, D. Askay, A. Eshraghi, and P. Smith, “Artiﬁcial intelli-
gence and knowledge management: A partnership between human and
ai,” Business Horizons, vol. 66, no. 1, pp. 87–99, 2023.

[312] D. J. Edwards, C. McEnteggart, and Y. Barnes-Holmes, “A functional
contextual account of background knowledge in categorization: Im-
plications for artiﬁcial general intelligence and cognitive accounts of
general knowledge,” Frontiers in Psychology, vol. 13, p. 745306, 2022.
[313] J. McCarthy, “Artiﬁcial intelligence, logic, and formalising common
sense,” Machine Learning and the City: Applications in Architecture
and Urban Design, pp. 69–90, 2022.

[314] S. Friederich, “Symbiosis, not alignment, as the goal for liberal
democracies in the transition to artiﬁcial general intelligence,” AI and
Ethics, pp. 1–10, 2023.

[315] S. Makridakis, “The forthcoming artiﬁcial intelligence (ai) revolution:

Its impact on society and ﬁrms,” Futures, vol. 90, pp. 46–60, 2017.

[316] S. Pal, K. Kumari, S. Kadam, and A. Saha, “The ai revolution,” IARA

Publication, 2023.

[317] S. Verma, R. Sharma, S. Deb, and D. Maitra, “Artiﬁcial intelligence in
marketing: Systematic review and future research direction,” Interna-
tional Journal of Information Management Data Insights, vol. 1, no. 1,
p. 100002, 2021.

[318] P. Budhwar, S. Chowdhury, G. Wood, H. Aguinis, G. J. Bamber, J. R.
Beltran, P. Boselie, F. Lee Cooke, S. Decker, A. DeNisi et al., “Human
resource management in the age of generative artiﬁcial intelligence:
Perspectives and research directions on chatgpt,” Human Resource
Management Journal, vol. 33, no. 3, pp. 606–659, 2023.

[319] J. B. Telkamp and M. H. Anderson, “The implications of diverse human
moral foundations for assessing the ethicality of artiﬁcial intelligence,”
Journal of Business Ethics, vol. 178, no. 4, pp. 961–976, 2022.
[320] X. Zhou, C. Liu, L. Zhai, Z. Jia, C. Guan, and Y. Liu, “Interpretable and
robust ai in eeg systems: A survey,” arXiv preprint arXiv:2304.10755,
2023.

[321] C. Zhang, C. Zhang, C. Li, Y. Qiao, S. Zheng, S. K. Dam, M. Zhang,
J. U. Kim, S. T. Kim, J. Choi et al., “One small step for generative
ai, one giant leap for agi: A complete survey on chatgpt in aigc era,”
arXiv preprint arXiv:2304.06488, 2023.

[322] K. Singhal, T. Tu, J. Gottweis, R. Sayres, E. Wulczyn, L. Hou,
K. Clark, S. Pfohl, H. Cole-Lewis, D. Neal et al., “Towards expert-
level medical question answering with large language models,” arXiv
preprint arXiv:2305.09617, 2023.

[323] S. Wu, O. Irsoy, S. Lu, V. Dabravolski, M. Dredze, S. Gehrmann,
P. Kambadur, D. Rosenberg, and G. Mann, “Bloomberggpt: A large
language model for ﬁnance,” arXiv preprint arXiv:2303.17564, 2023.
[324] P. Henderson, K. Sinha, N. Angelard-Gontier, N. R. Ke, G. Fried,
R. Lowe, and J. Pineau, “Ethical challenges in data-driven dialogue
systems,” in Proceedings of the 2018 AAAI/ACM Conference on AI,
Ethics, and Society, 2018, pp. 123–129.

[325] S. A. Bin-Nashwan, M. Sadallah, and M. Bouteraa, “Use of chatgpt
in academia: Academic integrity hangs in the balance,” Technology in
Society, vol. 75, p. 102370, 2023.

[326] N. Liu, A. Brown et al., “Ai increases the pressure to overhaul the
scientiﬁc peer review process. comment on “artiﬁcial intelligence can
generate fraudulent but authentic-looking scientiﬁc medical articles:
Pandora’s box has been opened”,” J Med Internet Res, vol. 25, p.
e50591, 2023.

[327] A. P. Siddaway, A. M. Wood, and L. V. Hedges, “How to do a
systematic review: a best practice guide for conducting and reporting
narrative reviews, meta-analyses, and meta-syntheses,” Annual review
of psychology, vol. 70, pp. 747–770, 2019.

[328] E. Landhuis, “Scientiﬁc literature: Information overload,” Nature, vol.

535, no. 7612, pp. 457–458, 2016.

[329] G. D. Chloros, V. P. Giannoudis, and P. V. Giannoudis, “Peer-reviewing
in surgical journals: revolutionize or perish?” Annals of surgery, vol.
275, no. 1, pp. e82–e90, 2022.

[330] K.-A. Allen, J. Reardon, Y. Lu, D. V. Smith, E. Rainsford, and
L. Walsh, “Towards improving peer review: Crowd-sourced insights

","JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 1 From Google Gemini to OpenAI Q * ( Q-Star ) : A Survey of Reshaping the Generative Artiﬁcial Intelligence ( AI ) Research Landscape Timothy R. McIntosh , Teo Susnjak , Tong Liu , Paul Watters , Senior Member , IEEE , and Malka N. Halgamuge , Senior Member , IEEE 3 2 0 2 c e D 8 1 ] I A . s c [ 1 v 8 6 8 0 1 . 2 1 3 2 : v i X r a Abstract—This comprehensive survey explored the evolving landscape of generative Artiﬁcial Intelligence ( AI ) , with a speciﬁc focus on the transformative impacts of Mixture of Experts ( MoE ) , multimodal learning , and the speculated advancements towards Artiﬁcial General Intelligence ( AGI ) . It critically examined the current state and future trajectory of generative Artiﬁcial In- telligence ( AI ) , exploring how innovations like Google ’ s Gemini and the anticipated OpenAI Q * project are reshaping research priorities and applications across various domains , including an impact analysis on the generative AI research taxonomy . It assessed the computational challenges , scalability , and real- world implications of these technologies while highlighting their potential in driving signiﬁcant progress in ﬁelds like healthcare , ﬁnance , and education . It also addressed the emerging academic challenges posed by the proliferation of both AI-themed and AI- generated preprints , examining their impact on the peer-review process and scholarly communication . The study highlighted the importance of incorporating ethical and human-centric methods in AI development , ensuring alignment with societal norms and welfare , and outlined a strategy for future AI research that focuses on a balanced and conscientious use of MoE , multimodality , and AGI in generative AI . Index Terms—AI Ethics , Artiﬁcial General Intelligence ( AGI ) , Artiﬁcial Intelligence ( AI ) , Gemini , Generative AI , Mixture of Experts ( MoE ) , Multimodality , Q * ( Q-star ) , Research Impact Analysis . I . INTRODUCTION T HE historical context of AI , tracing back to Alan Turing ’ s “ Imitation Game ” [ 1 ] , early computational theories [ 2 ] , [ 3 ] , and the development of the ﬁrst neural networks and machine learning [ 4 ] , [ 5 ] , [ 6 ] , has set the foundation for to- day ’ s advanced models . This evolution , accentuated by crucial moments such as the rise of deep learning and reinforcement learning , has been vital in shaping the contemporary trends in AI , including the sophisticated Mixture of Experts ( MoE ) models and multimodal AI systems , illustrating the ﬁeld ’ s dynamic and continuously evolving character . These advance- ments are a testament to the dynamic and ever-evolving nature of AI technology . The evolution of Artiﬁcial Intelligence Manuscript received December 19 , 2023 . ( Corresponding author : Timothy R . McIntosh . ) Timothy McIntosh is with Academies Australasia Polytechnic , Melbourne , VIC 3000 , Australia ( e-mail : t.mcintosh @ aapoly.edu.au ) . Teo Susnjak and Tong Liu are with Massey University , Auckland 0632 , New Zealand ( e-mail : t.liu @ massey.ac.nz ; t.susnjak @ massey.ac.nz ) . Paul Watters is with Cyberstronomy Pty Ltd , Ballarat , VIC 3350 , Australia ( e-mail : ceo @ cyberstronomy.com ) . Malka N. Halgamuge is with RMIT University , Melbourne , VIC 3000 , Australia ( e-mail : malka.halgamuge @ rmit.edu.au ) . ( AI ) has witnessed a crucial turn with the advent of Large Language Models ( LLMs ) , notably ChatGPT , developed by OpenAI , and the recent unveiling of Google ’ s Gemini [ 7 ] , [ 8 ] . This technology has not only revolutionized the industry and academia , but has also reignited critical discussions concerning AI consciousness and its potential threats to humanity [ 9 ] , [ 10 ] , [ 11 ] . The development of such advanced AI systems , including notable competitors like Anthropic ’ s Claude , and now Gemini , which demonstrates several advances over pre- vious models like GPT-3 and Google ’ s own LaMDA , has reshaped the research landscape . Gemini ’ s ability to learn from two-way conversations and its “ spike-and-slab ” attention method , which allows it to focus on relevant parts of the context during multi-turn conversations , represents a signiﬁ- cant leap in developing models that are better equipped for multidomain conversational applications1 . These innovations in LLMs , including the mixture-of-experts methods employed by Gemini , signal a move towards models that can handle a diversity of inputs and foster multimodal approaches . Amidst this backdrop , speculations of an OpenAI project known as Q * ( Q-Star ) have surfaced , allegedly combining the power of LLMs with sophisticated algorithms such as Q-learning and A * ( A-Star algorithm ) , further contributing to the dynamic research environment2 . A . Changing AI Research Popularity As the ﬁeld of LLMs continues to evolve , exempliﬁed by innovations such as Gemini and Q * , a multitude of stud- ies have surfaced with the aim of charting future research paths , which have varied from identifying emerging trends to highlighting areas poised for swift progress . The dichotomy of established methods and early adoption is evident , with “ hot topics ” in LLM research increasingly shifting towards multimodal capabilities and conversation-driven learning , as demonstrated by Gemini . The propagation of preprints has expedited knowledge sharing , but also brings the risk of re- duced academic scrutiny . Issues like inherent biases , noted by Retraction Watch , along with concerns about plagiarism and forgery , present substantial hurdles [ 12 ] . The academic world , therefore , stands at an intersection , necessitating a uniﬁed drive 1https : 2https : JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 2 to reﬁne research directions in light of the fast-paced evolution of the ﬁeld , which appears to be partly traced through the changing popularity of various research keywords over time . The release of generative models like GPT and the widespread commercial success of ChatGPT have been inﬂuential . As depicted in Figure 1 , the rise and fall of certain keywords appear to have correlated with signiﬁcant industry milestones , such as the release of the “ Transformer ” model in 2017 [ 13 ] , the GPT model in 2018 [ 14 ] , and the commercial ChatGPT-3.5 in December 2022 . For instance , the spike in searches related to “ Deep Learning ” coincides with the breakthroughs in neural network applications , while the interest in “ Natural Language Processing ” surges as models like GPT and LLaMA redeﬁne what ’ s possible in language understanding and generation . The enduring attention to “ Ethics / Ethical ” in AI research , despite some ﬂuctuations , reﬂects the continuous and deep-rooted concern for the moral dimensions of AI , underscoring that ethical considerations are not merely a reactionary measure , but an integral and persistent dialogue within the AI discussion [ 15 ] . It is academically intriguing to postulate whether these trends signify a causal relationship , where technological ad- vancements drive research focus , or if the burgeoning research itself propels technological development . This paper also explores the profound societal and economic impacts of AI advancements . We examine how AI technologies are reshap- ing various industries , altering employment landscapes , and inﬂuencing socio-economic structures . This analysis highlights both the opportunities and challenges posed by AI in the modern world , emphasizing its role in driving innovation and economic growth , while also considering the ethical implica- tions and potential for societal disruption . Future studies could yield more deﬁnitive insights , yet the synchronous interplay between innovation and academic curiosity remains a hallmark of AI ’ s progress . Meanwhile , increase in the number of preprints posted on arXiv under the Computer Science > Ar- tiﬁcial Intelligence ( cs.AI ) category , as illustrated in Figure 2 , appears to signify a paradigm shift in research dissemination within the AI community . While the rapid distribution of ﬁndings enables swift knowledge exchange , it also raises concerns regarding the validation of information . The surge in preprints may lead to the propagation of unvalidated or biased information , as these studies do not undergo the rigor- ous scrutiny and potential retraction typical of peer-reviewed publications [ 16 ] , [ 17 ] . This trend underlines the need for careful consideration and critique in the academic community , especially given the potential for such unvetted studies to be cited and their ﬁndings propagated . the exponential B . Objectives The impetus for this investigation is the ofﬁcial unveiling of Gemini and the speculative discourse surrounding Q * project , which prompts a timely examination of the prevailing currents 3The legend entries correspond to the keywords used in the search query , which is constructed as : “ ( AI OR artiﬁcial OR ( machine learning ) OR ( neural network ) OR computer OR software ) AND ( [ speciﬁc keyword ] ) ” . in generative AI research . This paper speciﬁcally contributes to the understanding of how MoE , multimodality , and Artiﬁ- cial General Intelligence ( AGI ) are impacting generative AI models , offering detailed analysis and future directions for each of these three key areas . This study does not aim to perpetuate conjecture about the unrevealed Q-Star initiative , but rather to critically appraise the potential for obsolescence or insigniﬁcance in extant research themes , whilst concur- rently delving into burgeoning prospects within the rapidly transforming LLM panorama . This inquiry is reminiscent of the obsolete nature of encryption-centric or ﬁle-entropy- based ransomware detection methodologies , which have been eclipsed by the transition of ransomware collectives towards data theft strategies utilizing varied attack vectors , relegating contemporary studies on crypto-ransomware to the status of latecomers [ 18 ] , [ 19 ] . Advances in AI are anticipated to not only enhance capabilities in language analysis and knowledge synthesis but also to pioneer in areas like Mixture of Experts ( MoE ) [ 20 ] , [ 21 ] , [ 22 ] , [ 23 ] , [ 24 ] , [ 25 ] , multimodality [ 26 ] , [ 27 ] , [ 28 ] , [ 29 ] , [ 30 ] , and Artiﬁcial General Intelligence ( AGI ) [ 31 ] , [ 32 ] , [ 10 ] , [ 11 ] , and has already heralded the obso- lescence of conventional , statistics-driven natural language processing techniques in many domains [ 8 ] . Nonetheless , the perennial imperative for AI to align with human ethics and values persists as a fundamental tenet [ 33 ] , [ 34 ] , [ 35 ] , and the conjectural Q-Star initiative offers an unprecedented opportunity to instigate discourse on how such advancements might reconﬁgure the LLM research topography . Within this milieu , insights from Dr. Jim Fan ( senior research scientist & lead of AI agents at NVIDIA ) on Q * , particularly concerning the amalgamation of learning and search algorithms , furnish an invaluable perspective on the prospective technical con- struct and proﬁciencies of such an undertaking4 . Our research methodology involved a structured literature search using key terms like ‘ Large Language Models ’ and ‘ Generative AI ’ . We utilized ﬁlters across several academic databases such as IEEE Xplore , Scopus , ACM Digital Library , ScienceDirect , Web of Science , and ProQuest Central , tailored to identify relevant articles published in the timeframe from 2017 ( the release of the “ Transformer ” model ) to 2023 ( the writing time of this manuscript ) . This paper aspires to dissect the technical ramiﬁcations of Gemini and Q * , probing how they ( and similar technologies whose emergence is now inevitable ) may transﬁgure research trajectories and disclose new vistas in the domain of AI . In doing so , we have pinpointed three nascent research domains—MoE , multimodality , and AGI—that stand to reshape the generative AI research landscape profoundly . This investigation adopts a survey-style approach , systemat- ically mapping out a research roadmap that synthesizes and analyzes the current and emergent trends in generative AI . The major contributions of this study is as follows : 1 ) Detailed examination of the evolving landscape in genera- tive AI , emphasizing the advancements and innovations in technologies like Gemini and Q * , and their wide-ranging implications within the AI domain . 4https : JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 3 700k 600k 500k 400k 300k 200k 100k s t l u s e r h c r a e s f o r e b m u N 2011 2012 2013 2014 Deep Learning Convolutional Neural Network ( s ) Unsupervised Learning Fine ( - ) tuning 2018 2015 2016 2017 Year Transfer Learning Explainable AI Reinforcement Learning Ethics / Ethical 2019 2020 2021 2022 2023 Supervised Learning Natural Language Processing Generative Adversarial Networks Language Model ( s ) Figure 1 : Number of search results on Google Scholar with different keywords by year 3 s t n i r p e r P f o r e b m u N 25,000 20,000 15,000 10,000 5,000 0 cs.AI Preprints on arXiv 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Year Figure 2 : Annual number of preprints posted under the cs.AI category on arXiv.org 2 ) Analysis of the transformative effect of advanced gener- ative AI systems on academic research , exploring how these developments are altering research methodologies , setting new trends , and potentially leading to the obso- lescence of traditional approaches . 3 ) Thorough assessment of the ethical , societal , and tech- nical challenges arising from the integration of genera- tive AI in academia , underscoring the crucial need for aligning these technologies with ethical norms , ensuring data privacy , and developing comprehensive governance frameworks . The rest of this paper is organized as follows : Section II explores the historical development of Generative AI . Section III presents a taxonomy of current Generative AI research . Section IV explores the Mixture of Experts ( MoE ) model architecture , its innovative features , and its impact on transformer-based language models . Section V discusses the speculated capabilities of the Q * project . Section VI discusses the projected capabilities of AGI . Section VII examines the impact of recent advancements on the Generative AI research taxonomy . Section VIII identiﬁes emerging research priorities in Generative AI . Section X discusses the academic challenges of the rapid surge of preprints in AI . The paper concludes in Section XI , summarizing the overall effects of these develop- ments in generative AI . II . BACKGROUND : EVOLUTION OF GENERATIVE AI The ascent of Generative AI has been marked by signiﬁcant milestones , with each new model paving the way for the next evolutionary leap . From single-purpose algorithms to LLMs like OpenAI ’ s ChatGPT and the latest multimodal systems , the AI landscape has been transformed , while countless other ﬁelds have been disrupted . A . The Evolution of Language Models Language models have undergone a transformative journey ( Fig . 3 ) , evolving from rudimentary statistical methods to the JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 4 1980s : Statistical Models ( n-grams ) 1990s : Adoption in NLP , n-gram Usage 1997 : Introduction of LSTMs 2000s : LSTMs in Text/Voice Processing 2010s : Deep Learning Era , GPT , BERT 2020s : LLaMA , Gemini ; ChatGPT Launch Figure 3 : Timeline of Key Developments in Language Model Evolution complex neural network architectures that underpin today ’ s LLMs [ 36 ] , [ 37 ] . This evolution has been driven by a relentless quest for models that more accurately reﬂect the nuances of human language , as well as the desire to push the boundaries of what machines can understand and generate [ 36 ] , [ 38 ] , [ 37 ] . However , this rapid advancement has not been without its challenges . As language models have grown in capability , so too have the ethical and safety concerns surrounding their use , prompting a reevaluation of how these models are developed and the purposes for which they are employed [ 36 ] , [ 39 ] , [ 40 ] . 1 ) Language Models as Precursors : The inception of lan- guage modeling can be traced to the statistical approaches of the late 1980s , a period marked by a transition from rule-based to machine learning algorithms in Natural Language Process- ing ( NLP ) [ 41 ] , [ 42 ] , [ 43 ] , [ 44 ] , [ 45 ] . Early models , primarily n-gram based , calculated the probability of word sequences in a corpus , thus providing a rudimentary understanding of language structure [ 41 ] . Those models , simplistic yet ground- breaking , laid the groundwork for future advances in language understanding . With the increase of computational power , the late 1980s witnessed a revolution in NLP , pivoting towards statistical models capable of ‘ soft ’ probabilistic decisions , as opposed to the rigid , ‘ handwritten ’ rule-based systems that dominated early NLP systems [ 43 ] . IBM ’ s development of complicated statistical models throughout this period signiﬁed the growing importance and success of these approaches . In the subsequent decade , the popularity and applicability of statistical models surged , proving invaluable in managing the ﬂourishing ﬂow of digital text . The 1990s saw statistical methods ﬁrmly established in NLP research , with n-grams becoming instrumental in numerically capturing linguistic pat- terns . The introduction of Long Short-Term Memory ( LSTM ) networks in 1997 [ 46 ] , and their application to voice and text processing a decade later [ 47 ] , [ 48 ] , [ 49 ] , marked a signiﬁcant milestone , leading to the current era where neural network models represent the cutting edge of NLP research and development . 2 ) Large Language Models : Technical Advancement and Commercial Success : The advent of deep learning has revolu- tionized the ﬁeld of NLP , leading to the development of LLMs like GPT , BERT , and notably , OpenAI ’ s ChatGPT . Recent models such as GPT-4 and LLaMA have pushed the bound- aries by integrating sophisticated techniques like transformer architectures and advanced natural language understanding , illustrating the rapid evolution in this ﬁeld [ 37 ] . These models represent a signiﬁcant leap in NLP capabilities , leveraging vast computational resources and extensive datasets to achieve new heights in language understanding and generation [ 37 ] , [ 50 ] . ChatGPT has shown impressive conversational skills and contextual understanding with a broad spectrum of func- tional uses in many areas , as evidenced by its technical and commercial success , including rapid adoption by over 100 million users shortly after launch , which underscores a robust market demand for natural language AI and has catalyzed interdisciplinary research into its applications in sectors like education , healthcare , and commerce [ 8 ] , [ 50 ] , [ 51 ] , [ 52 ] , [ 53 ] . In education , ChatGPT offers innovative approaches to personalized learning and interactive teaching [ 54 ] , [ 51 ] , [ 55 ] , [ 56 ] , while in commerce , it revolutionizes customer service and content creation [ 57 ] , [ 58 ] . The widespread use of ChatGPT , Google Bard , Anthropic Claude and similar commercial LLMs has reignited important debates in the ﬁeld of AI , particularly concerning AI consciousness and safety , as its human-like interaction capabilities raise signiﬁcant ethical questions and highlight the need for robust governance and safety measures in AI development [ 59 ] , [ 31 ] , [ 32 ] , [ 11 ] . Such inﬂuence appears to extend beyond its technical achievements , shaping cultural and societal discussions about the role and future of AI in our world . The advancements in LLMs , including the development of models like GPT and BERT , have paved the way for the conceptualization of Q * . Speciﬁcally , the scalable architecture and extensive training data that characterize these models are foundational to the proposed capabilities of Q * . The success of ChatGPT in contextual understanding and con- versational AI , for example , informs the design principles of Q * , suggesting a trajectory towards more sophisticated , context-aware , and adaptive language processing capabilities . Similarly , the emergence of multimodal systems like Gemini , capable of integrating text , images , audio , and video , reﬂects an evolutionary path that Q * could extend , combining the versatility of LLMs with advanced learning and pathﬁnding algorithms for a more holistic AI solution . 3 ) Fine-tuning , Hallucination Reduction , and Alignment in LLMs : The advancement of LLMs has underlined the signiﬁcance of ﬁne-tuning [ 60 ] , [ 61 ] , [ 62 ] , [ 63 ] , hallucination reduction [ 64 ] , [ 65 ] , [ 66 ] , [ 67 ] , and alignment [ 68 ] , [ 69 ] , [ 70 ] , [ 71 ] , [ 72 ] . These aspects are crucial in enhancing the functionality and reliability of LLMs . Fine-tuning , which involves adapting pre-trained models to speciﬁc tasks , has seen signiﬁcant progress : techniques like prompt-based and few-shot learning [ 73 ] , [ 74 ] , [ 75 ] , [ 76 ] , alongside supervised ﬁne-tuning on specialized datasets [ 60 ] , [ 77 ] , [ 78 ] , [ 79 ] , have enhanced the adaptability of LLMs in various contexts , but challenges remain , particularly in bias mitigation and the JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 5 generalization of models across diverse tasks [ 60 ] , [ 80 ] , [ 72 ] . Hallucination reduction is a persistent challenge in LLMs , characterized by the generation of conﬁdent but factually in- correct information [ 36 ] . Strategies such as conﬁdence penalty regularization during ﬁne-tuning have been implemented to mitigate overconﬁdence and improve accuracy [ 81 ] , [ 82 ] , [ 83 ] . Despite these efforts , the complexity of human language and the breadth of topics make completely eradicating hallucina- tions a daunting task , especially in culturally sensitive contexts [ 36 ] , [ 9 ] . Alignment , ensuring LLM outputs are congruent with human values and ethics , is an area of ongoing research . Innovative approaches , from constrained optimization [ 84 ] , [ 85 ] , [ 86 ] , [ 87 ] , [ 88 ] , to different types of reward modeling [ 89 ] , [ 90 ] , [ 91 ] , [ 92 ] , aim to embed human preferences within AI systems . While advancements in ﬁne-tuning , hallucination reduction , and alignment have propelled LLMs forward , these areas still present considerable challenges . The complexity of aligning AI with the diverse spectrum of human ethics and the persistence of hallucinations , particularly on culturally sensi- tive topics , highlight the need for continued interdisciplinary research in the development and application of LLMs [ 9 ] . 4 ) Mixture of Experts : A Paradigm Shift : The adoption of the MoE architecture in LLMs marks a critical evolution in AI technology . This innovative approach , exempliﬁed by advanced models like Google ’ s Switch Transformer5 and MistralAI s Mixtral-8x7B6 , leverages multiple transformer- based expert modules for dynamic token routing , enhancing modeling efﬁciency and scalability . The primary advantage of MoE lies in its ability to handle vast parameter scales , reduc- ing memory footprint and computational costs signiﬁcantly [ 93 ] , [ 94 ] , [ 95 ] , [ 96 ] , [ 97 ] . This is achieved through model parallelism across specialized experts , allowing the training of models with trillions of parameters , and its specialization in handling diverse data distributions enhances its capability in few-shot learning and other complex tasks [ 94 ] , [ 95 ] . To illustrate the practicality of MoE , consider its application in healthcare . For example , an MoE-based system could be used for personalized medicine , where different ‘ expert ’ modules specialize in various aspects of patient data analysis , including genomics , medical imaging , and electronic health records . This approach could signiﬁcantly enhance diagnostic accuracy and treatment personalization . Similarly , in ﬁnance , MoE models can be deployed for risk assessment , where experts analyze trends , and regulatory distinct ﬁnancial compliance factors . indicators , market Despite its beneﬁts , MoE confronts challenges in dynamic routing complexity [ 98 ] , [ 99 ] , [ 100 ] , [ 101 ] , [ 102 ] , expert imbalance [ 103 ] , [ 104 ] , [ 105 ] , [ 106 ] , and probability dilu- tion [ 107 ] , and such technical hurdles demand sophisticated solutions to fully harness MoE ’ s potential . Moreover , while MoE may offer performance gains , it does not inherently solve ethical alignment issues in AI [ 108 ] , [ 109 ] , [ 110 ] . The complexity and specialization of MoE models can obscure the decision-making processes , complicating efforts to ensure ethi- cal compliance and alignment with human values [ 108 ] , [ 111 ] . Although the paradigm shift to MoE signiﬁes a major leap in LLM development , offering signiﬁcant scalability and special- ization advantages , ensuring the safety , ethical alignment , and transparency of these models remains a paramount concern . The MoE architecture , while technologically advanced , entails continued interdisciplinary research and governance to align AI with broader societal values and ethical standards . B. Multimodal AI and the Future of Interaction The advent of multimodal AI marks a transformative era in AI development , revolutionizing how machines interpret and interact with a diverse array of human sensory inputs and contextual data . 1 ) Gemini : Redeﬁning Benchmarks in Multimodality : Gem- ini , a pioneering multimodal conversational system , marks a signiﬁcant shift in AI technology by surpassing traditional text-based LLMs like GPT-3 and even its multimodal coun- terpart , ChatGPT-4 . Gemini ’ s architecture has been designed to incorporate the processing of diverse data types such as text , images , audio , and video , a feat facilitated by its unique multimodal encoder , cross-modal attention network , and multimodal decoder [ 112 ] . The architectural core of Gemini is its dual-encoder structure , with separate encoders for visual and textual data , enabling sophisticated multimodal contextualization [ 112 ] . This architecture is believed to surpass the capabilities of single-encoder systems , allowing Gemini to associate textual concepts with image regions and achieve a compositional understanding of scenes [ 112 ] . Furthermore , Gemini integrates structured knowledge and employs special- ized training paradigms for cross-modal intelligence , setting new benchmarks in AI [ 112 ] . In [ 112 ] , Google has claimed and demonstrated that Gemini distinguishes itself from ChatGPT-4 through several key features : • Breadth of Modalities : Unlike ChatGPT-4 , which pri- marily focuses on text , documents , images , and code , Gemini handles a wider range of modalities including audio , and video . This extensive range allows Gemini to tackle complex tasks and understand real-world contexts more effectively . • Performance : Gemini Ultra excels in key multimodality benchmarks , notably in massive multitask language un- derstanding ( MMLU ) which encompasses a diverse array of domains like science , law , and medicine , outperform- ing ChatGPT-4 . • Scalability and Accessibility : Gemini is available in three tailored versions – Ultra , Pro , and Nano – catering to a range of applications from data centers to on-device tasks , a level of ﬂexibility not yet seen in ChatGPT-4 . • Code Generation : Gemini ’ s proﬁciency in understanding and generating code across various programming lan- guages is more advanced , offering practical applications beyond ChatGPT-4 ’ s capabilities . • Transparency and Explainability : A focus on explainabil- ity sets Gemini apart , as it provides justiﬁcations for its outputs , enhancing user trust and understanding of the AI ’ s reasoning process . 5https : 6https : Despite these advancements , Gemini ’ s real-world perfor- mance in complex reasoning tasks that require integration JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 6 of commonsense knowledge across modalities remains to be thoroughly evaluated . 2 ) Technical Challenges in Multimodal Systems : The devel- opment of multimodal AI systems faces several technical hur- dles , including creating robust and diverse datasets , managing scalability , and enhancing user trust and system interpretability [ 113 ] , [ 114 ] , [ 115 ] . Challenges like data skew and bias are prevalent due to data acquisition and annotation issues , which requires effective dataset management by employing strate- gies such as data augmentation , active learning , and transfer learning [ 113 ] , [ 116 ] , [ 80 ] , [ 115 ] . A signiﬁcant challenge is the computational demands of processing various data streams simultaneously , requiring powerful hardware and optimized model architectures for multiple encoders [ 117 ] , [ 118 ] . Ad- vanced algorithms and multimodal attention mechanisms are needed to balance attention across different input media and resolve conﬂicts between modalities , especially when they pro- vide contradictory information [ 119 ] , [ 120 ] , [ 118 ] . Scalability issues , due to the extensive computational resources needed , are exacerbated by limited high-performance hardware avail- ability [ 121 ] , [ 122 ] . There is also a pressing need for calibrated multimodal encoders for compositional scene understanding and data integration [ 120 ] . Reﬁning evaluation metrics for these systems is necessary to accurately assess performance in real-world tasks , calling for comprehensive datasets and uniﬁed benchmarks , and for enhancing user trust and system interpretability through explainable AI in multimodal contexts . Addressing these challenges is vital for the advancement of multimodal AI systems , enabling seamless and intelligent interaction aligned with human expectations . 3 ) Multimodal AI : Beyond Text in Ethical and Social Con- texts : The expansion of multimodal AI systems introduces both beneﬁts and complex ethical and social challenges that extend beyond those faced by text-based AI . In commerce , multimodal AI can transform customer engagement by inte- grating visual , textual , and auditory data [ 123 ] , [ 124 ] , [ 125 ] . For autonomous vehicles , multimodality can enhance safety and navigation by synthesizing data from various sensors , including visual , radar , and Light Detection and Ranging ( LIDAR ) [ 126 ] , [ 125 ] , [ 127 ] . Still , DeepFake technology ’ s ability to generate convincingly realistic videos , audio , and images is a critical concern in multimodality , as it poses risks of misinformation and manipulation that signiﬁcantly impact public opinion , political landscapes , and personal reputations , thereby compromising the authenticity of digital media and raising issues in social engineering and digital forensics where distinguishing genuine from AI-generated content becomes increasingly challenging [ 128 ] , [ 129 ] . Privacy concerns are ampliﬁed in multimodal AI due to its ability to process and correlate diverse data sources , potentially leading to intrusive surveillance and proﬁling , which raises questions about the consent and rights of individuals , especially when personal media is used without permission for AI training or content creation [ 113 ] , [ 130 ] , [ 131 ] . Moreover , multimodal AI can propagate and amplify biases and stereotypes across different modalities , and if unchecked , this can perpetuate discrimination and social inequities , making it imperative to address algorithmic bias effectively [ 132 ] , [ 133 ] , [ 134 ] . The ethical development of multimodal AI systems requires robust governance frameworks focusing on transparency , consent , data handling protocols , and public awareness , when ethical guidelines must evolve to address the unique challenges posed by these technologies , including setting standards for data usage and safeguarding against the nonconsensual exploita- tion of personal information [ 135 ] , [ 136 ] . Additionally , the development of AI literacy programs will be crucial in helping society understand and responsibly interact with multimodal AI technologies [ 113 ] , [ 135 ] . As the ﬁeld progresses , interdis- ciplinary collaboration will be key in ensuring these systems are developed and deployed in a manner that aligns with societal values and ethical principles [ 113 ] . C. Speculative Advances and Chronological Trends In the dynamic landscape of AI , the speculative capabilities of the Q * project , blending LLMs , Q-learning , and A * ( A- Star algorithm ) , embodies a signiﬁcant leap forward . This section explores the evolutionary trajectory from game-centric AI systems to the broad applications anticipated with Q * . 1 ) From AlphaGo ’ s Groundtruth to Q-Star ’ s Exploration : The journey from AlphaGo , a game-centric AI , to the con- ceptual Q-Star project represents a signiﬁcant paradigm shift in AI . AlphaGo ’ s mastery in the game of Go highlighted the effectiveness of deep learning and tree search algorithms within well-deﬁned rule-based environments , underscoring the potential of AI in complex strategy and decision-making [ 137 ] , [ 138 ] . Q-Star , however , is speculated to move beyond these conﬁnes , aiming to amalgamate the strengths of reinforcement learning ( as seen in AlphaGo ) , with the knowledge , NLG , creativity and versatility of LLMs , and the strategic efﬁ- ciency of pathﬁnding algorithms like A * . This blend , merging pathﬁnding algorithms and LLMs , could enable AI systems to transcend board game conﬁnes and , with Q-Star ’ s natural language processing , interact with human language , enabling nuanced interactions and marking a leap towards AI adept in both structured tasks and complex human-like communication and reasoning . Moreover , the incorporation of Q-learning and A * algorithms would enable Q-Star to optimize decision paths and learn from its interactions , making it more adaptable and intelligent over time . The combination of these technologies could lead to AI that is not only more efﬁcient in problem- solving but also creative and insightful in its approach . This speculative advancement from the game-focused power of Al- phaGo to the comprehensive potential of Q-Star illustrates the dynamic and ever-evolving nature of AI research , and opens up possibilities for AI applications that are more integrated with human life and capable of handling a broader range of tasks with greater autonomy and sophistication . 2 ) Bridging Structured Learning with Creativity : The antic- ipated Q * project , blending Q-learning and A * algorithms with the creativity of LLMs , embodies a groundbreaking step in AI , potentially surpassing recent innovations like Gemini . The fusion suggested in Q * points to an integration of structured , goal-oriented learning with generative , creative capabilities , a combination that could transcend the existing achievements leap in of Gemini . While Gemini represents a signiﬁcant JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 7 multimodal AI , combining various forms of data inputs such as text , images , audio , and video , Q * is speculated to bring a more profound integration of creative reasoning and structured problem-solving . This would be achieved by merging the precision and efﬁciency of algorithms like A * with the learning adaptability of Q-learning , and the complex understanding of human language and context offered by LLMs . Such an integration could enable AI systems to not only process and analyze complex multimodal data but also to autonomously navigate through structured tasks while engaging in creative problem-solving and knowledge generation , mirroring the multifaceted nature of human cognition . The implications of this potential advancement are vast , suggesting applications that span beyond the capabilities of current multimodal sys- tems like Gemini . By aligning the deterministic aspects of traditional AI algorithms with the creative and generative potential of LLMs , Q * could offer a more holistic approach to AI development . This could bridge the gap between the logical , rule-based processing of AI and the creative , abstract thinking characteristic of human intelligence . The anticipated unveiling of Q * , merging structured learning techniques and creative problem-solving in a singular , advanced framework , holds the promise of not only extending but also signiﬁcantly surpassing the multimodal capabilities of systems like Gemini , thus heralding another game-changing era in the domain of generative AI , showcasing its potential as a crucial develop- ment eagerly awaited in the ongoing evolution of AI . III . THE CURRENT GENERATIVE AI RESEARCH TAXONOMY The ﬁeld of Generative AI is evolving rapidly , which necessitates a comprehensive taxonomy that encompasses the breadth and depth of research within this domain . Detailed in Table I , this taxonomy categorizes the key areas of inquiry and innovation in generative AI , and serves as a foundational framework to understand the current state of the ﬁeld , guiding through the complexities of evolving model architectures , advanced training methodologies , diverse application domains , ethical implications , and the frontiers of emerging technolo- gies . A . Model Architectures • Recurrent Neural Networks ( RNNs ) : RNNs excel in the realm of sequence modeling , making them particularly effective for tasks involving language and temporal data , as their architecture is speciﬁcally designed to process sequences of data , such as text , enabling them to capture the context and order of the input effectively [ 150 ] , [ 151 ] , [ 152 ] , [ 153 ] , [ 154 ] . This proﬁciency in handling sequential information renders them indispensable in applications that require a deep understanding of the temporal dynamics within data , such as natural language tasks and time-series analysis [ 155 ] , [ 156 ] . RNNs ’ ability to maintain a sense of continuity over sequences is a critical asset in the broader ﬁeld of AI , especially in scenarios where context and historical data play crucial roles [ 157 ] . • Mixture of Experts ( MoE ) : MoE models can signiﬁ- cantly enhance efﬁciency by deploying model parallelism across multiple specialized expert modules , which en- ables these models to leverage transformer-based modules for dynamic token routing , and to scale to trillions of parameters , thereby reducing both memory footprint and computational costs [ 94 ] , [ 98 ] . MoE models stand out for their ability to divide computational loads among various experts , each specializing in different aspects of the data , which allows for handling vast scales of parameters more effectively , leading to a more efﬁcient and specialized handling of complex tasks [ 94 ] , [ 21 ] . • Multimodal Models : Multimodal models , which inte- grate a variety of sensory inputs such as text , vision , and audio , are crucial in achieving a comprehensive understanding of complex data sets , particularly trans- formative in ﬁelds like medical imaging [ 113 ] , [ 112 ] , [ 115 ] . These models facilitate accurate and data-efﬁcient analysis by employing multi-view pipelines and cross- attention blocks [ 158 ] , [ 159 ] . This integration of diverse sensory inputs allows for a more nuanced and detailed interpretation of data , enhancing the model ’ s ability to accurately analyze and understand various types of infor- mation [ 160 ] . The combination of different data types , processed concurrently , enables these models to provide a holistic view , making them especially effective in applica- tions that require a deep and multifaceted understanding of complex scenarios [ 113 ] , [ 161 ] , [ 162 ] , [ 160 ] . Generative AI model architectures have seen signiﬁcant developments , with four key domains standing out : B . Training Techniques • Transformer Models : Transformer models have signiﬁ- cantly revolutionized the ﬁeld of AI , especially in NLP , due to their higher efﬁciency and scalability [ 139 ] , [ 140 ] , [ 141 ] . They employ advanced attention mechanisms to achieve enhanced contextual processing , allowing for more subtle understanding and interaction [ 142 ] , [ 143 ] , [ 144 ] . These models have also made notable strides in computer vision , as evidenced by the development of vision transformers like EfﬁcientViT [ 145 ] , [ 146 ] and YOLOv8 [ 147 ] , [ 148 ] , [ 149 ] . These innovations symbol- ize the extended capabilities of transformer models in areas such as object detection , offering not only improved performance but also increased computational efﬁciency . The training of generative AI models leverages four key techniques , each contributing uniquely to the ﬁeld : • Supervised Learning : Supervised learning , a founda- tional approach in AI , uses labeled datasets to guide models towards accurate predictions , and it has been integral to various applications , including image recogni- tion and NLP [ 163 ] , [ 164 ] , [ 165 ] . Recent advancements have focused on developing sophisticated loss functions and regularization techniques , aimed at enhancing the performance and generalization capabilities of supervised learning models , ensuring they remain robust and effec- tive across a wide range of tasks and data types [ 166 ] , [ 167 ] , [ 168 ] . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 8 Table I : Comprehensive Taxonomy of Current Generative AI and LLM Research Subdomain Transformer Models Key Focus Efﬁciency , Scalability Description Optimizing network structures for faster processing and larger datasets . Domain Model Architec- ture Training Techniques Application Do- mains Compliance and Ethical Consider- ations Advanced Learn- ing Neural Recurrent Networks Mixture of Experts Multimodal Models Supervised Learning Unsupervised Learn- ing Reinforcement Learn- ing Transfer Learning Language Natural Understanding Natural Generation Conversational AI Language Creative AI Bias Mitigation Data Security AI Ethics Privacy Preservation Self-supervised Learning Meta-learning Fine Tuning Human Value Align- ment Emerging Trends Multimodal Learning Interactive and Coop- erative AI AGI Development AGI Containment Sequence Processing Handling sequences of data , like text , for improved contextual understanding . Specialization , Efﬁciency Sensory Integration Data Labeling , Accu- racy Pattern Discovery Adaptability , Optimization Versatility , Generalization Comprehension , Con- textualization Creativity , Coherence Interaction , Natural- ness Innovation , Artistic Generation Fairness , Representa- tion Data Protection , Con- ﬁdentiality Fairness , Accountability Privacy Compliance , Anonymization Autonomy , Efﬁciency Tuning , Integration , Rapid Adaptation Domain- Speciﬁc Personalization Ethical Societal Alignment Integration with Vi- sion , Audio Collaboration , Human-AI Interaction Holistic Understand- ing Safety Protocols , Control Mechanisms Leveraging multiple expert modules for enhanced efﬁciency and task-speciﬁc performance . Integrating text , vision , and audio inputs for comprehensive understanding . Using labeled datasets to train models for precise predictions . Finding patterns and structures from unlabeled data . Training models through feedback mechanisms for optimal decision-making . Applying knowledge gained in one task to different but related tasks . Enhancing the ability to understand and interpret human language in context . Generating coherent and contextually relevant text responses . Developing systems for natural and contextually relevant human-computer conversations . Generating creative content , including text , art , and music . Addressing and reducing biases in AI outputs . Ensuring data conﬁdentiality , integrity and availability security in AI models and outputs . Addressing ethical systems . Protecting data privacy in model training and outputs . issues such as bias , fairness , and accountability in AI Utilizing unlabeled data for model training , enhancing learning efﬁciency . Enabling AI models to quickly adapt to new tasks with minimal data . Adapting models to speciﬁc domains or user preferences for enhanced relevance and accuracy . Aligning AI outputs with human ethics and societal norms , ensuring decisions are ethically and socially responsible . Combining language models with other sensory data types for richer under- standing . Enhancing AI ’ s ability to work alongside humans in collaborative tasks . Pursuing the development of AI systems with comprehensive , human-like understanding . Developing methods to contain and control AGI systems to prevent unintended consequences . • Unsupervised Learning : Unsupervised learning is es- sential in AI for uncovering patterns within unlabeled to tasks like feature learning data , a process central and clustering [ 169 ] , [ 170 ] . This method has seen sig- niﬁcant advancements with the introduction of autoen- coders [ 171 ] , [ 172 ] and Generative Adversarial Networks ( GANs ) [ 173 ] , [ 174 ] , [ 175 ] , which have notably expanded unsupervised learning ’ s applicability , enabling more so- phisticated data generation and representation learning capabilities . Such innovations are crucial for understand- ing and leveraging the complex structures often inherent in unstructured datasets , highlighting the growing versa- tility and depth of unsupervised learning techniques . • Reinforcement Learning : Reinforcement learning , char- acterized by its adaptability and optimization capabilities , has become increasingly vital in decision-making and autonomous systems [ 176 ] , [ 177 ] . This training technique has undergone signiﬁcant advancements , particularly with the development of Deep Q-Networks ( DQN ) [ 178 ] , [ 179 ] , [ 180 ] and Proximal Policy Optimization ( PPO ) algorithms [ 181 ] , [ 182 ] , [ 183 ] . These enhancements have been crucial in improving the efﬁcacy and applicability of reinforcement learning , especially in complex and dynamic environments . By optimizing decisions and poli- cies through interactive feedback loops , reinforcement learning has established itself as a crucial tool for training AI systems in scenarios that demand a high degree of adaptability and precision in decision-making [ 184 ] , [ 185 ] . • Transfer Learning : Transfer learning emphasizes ver- satility and efﬁciency in AI training , allowing models to apply knowledge acquired from one task to different JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 9 yet related tasks , which signiﬁcantly reduces the need for large labeled datasets [ 186 ] , [ 187 ] . Transfer learning , through the use of pre-trained networks , streamlines the training process by allowing models to be efﬁciently ﬁne-tuned for speciﬁc applications , thereby enhancing adaptability and performance across diverse tasks , and proving particularly beneﬁcial in scenarios where acquir- ing extensive labeled data is impractical or unfeasible [ 188 ] , [ 189 ] . C. Application Domains The application domains of Generative AI are remarkably diverse and evolving , encompassing both established and emerging areas of research and application . These domains have been signiﬁcantly inﬂuenced by recent advancements in AI technology and the expanding scope of AI applications . • Natural Language Understanding ( NLU ) : NLU is cen- tral to enhancing the comprehension and contextualiza- tion of human language in AI systems , and involves key capabilities such as semantic analysis , named en- tity recognition , sentiment analysis , textual entailment , and machine reading comprehension [ 190 ] , [ 191 ] , [ 192 ] , [ 193 ] . Advances in NLU have been crucial in improving AI ’ s proﬁciency in interpreting and analyzing language across a spectrum of contexts , ranging from straightfor- ward conversational exchanges to intricate textual data [ 190 ] , [ 192 ] , [ 193 ] . NLU is fundamental in applications like sentiment analysis , language translation , information extraction , and more [ 194 ] , [ 195 ] , [ 196 ] . Recent advance- ments have prominently featured large transformer-based models like BERT and GPT-3 , which have signiﬁcantly advanced the ﬁeld by enabling a deeper and more com- plex understanding of language subtleties [ 197 ] , [ 198 ] . • Natural Language Generation ( NLG ) : NLG em- phasizes the training of models to generate coherent , contextually-relevant , and creative text responses , a crit- ical component in chatbots , virtual assistants , and auto- mated content creation tools [ 199 ] , [ 36 ] , [ 200 ] , [ 201 ] . NLG encompasses challenges such as topic model- ing , discourse planning , concept-to-text generation , style transfer , and controllable text generation [ 36 ] , [ 202 ] . The recent surge in NLG capabilities , exempliﬁed by advanced models like GPT-3 , has signiﬁcantly enhanced the sophistication and nuance of text generation , which enable AI systems to produce text that closely mirrors human writing styles , thereby broadening the scope and applicability of NLG in various interactive and creative contexts [ 203 ] , [ 55 ] , [ 51 ] . • Conversational AI : This subdomain is dedicated to developing AI systems capable of smooth , natural , and context-aware human-computer interactions , by focusing on dialogue modeling , question answering , user intent recognition , and multi-turn context tracking [ 204 ] , [ 205 ] , [ 206 ] , [ 207 ] . In ﬁnance and cybersecurity , AI ’ s predictive analytics have transformed risk assessment and fraud detection , leading to more secure and efﬁcient operations [ 205 ] , [ 19 ] . The advancements in this area , demonstrated by large pre-trained models like Meena7 and BlenderBot8 , have signiﬁcantly enhanced the empathetic and respon- sive capabilities of AI interactions . These systems not only improve user engagement and satisfaction , but also maintain the ﬂow of conversation over multiple turns , providing coherent , contextually relevant , and engaging experiences [ 208 ] , [ 209 ] . • Creative AI : This emerging subdomain spans across text , art , music , and more , pushing the boundaries of AI ’ s creative and innovative potential across various modalities including images , audio , and video , by engaging in the generation of artistic content , encompassing applications in idea generation , storytelling , poetry , music composi- tion , visual arts , and creative writing , and has resulted in commercial success like MidJourney and DALL-E [ 210 ] , [ 211 ] , [ 212 ] . The challenges in this ﬁeld involve ﬁnding suitable data representations , algorithms , and evaluation metrics to effectively assess and foster creativity [ 212 ] , [ 213 ] . Creative AI serves not only as a tool for automating and enhancing artistic processes , but also as a medium for exploring new forms of artistic expression , enabling the creation of novel and diverse creative outputs [ 212 ] . This domain represents a signiﬁcant leap in AI ’ s capability to engage in and contribute to creative endeavors , redeﬁning the intersection of technology and art . D. Compliance and Ethical Considerations As AI technologies rapidly evolve and become more in- tegrated into various sectors , ethical considerations and legal compliance have become increasingly crucial , which requires a focus on developing ‘ Ethical AI Frameworks ’ , a new category in our taxonomy reﬂecting the trend towards responsible AI development in generative AI [ 214 ] , [ 215 ] , [ 15 ] , [ 216 ] , [ 217 ] . Such frameworks are crucial in ensuring AI systems are built with a core emphasis on ethical considerations , fairness , and transparency , as they address critical aspects such as bias mitigation for fairness , privacy and security concerns for data protection , and AI ethics for accountability , thus responding to the evolving landscape where accountability in AI is of paramount importance [ 214 ] , [ 15 ] . The need for rigorous approaches to uphold ethical integrity and legal conformity has never been more pressing , reﬂecting the complexity and multifaceted challenges introduced by the adoption of these technologies [ 15 ] . • Bias Mitigation : Bias Mitigation in AI systems is a critical endeavor to ensure fairness and representation , which involves not only balanced data collection to avoid skewed perspectives but also involves implementing algorithmic adjustments and regularization techniques to minimize biases [ 218 ] , [ 219 ] . Continuous monitoring and bias testing are essential to identify and address any biases that may emerge from AI ’ s predictive patterns [ 220 ] , [ 219 ] . A signiﬁcant challenge in this area is dealing with intersectional biases [ 221 ] , [ 222 ] , [ 223 ] and 7https : 8https : //blenderbot.ai JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 10 understanding the causal interactions that may contribute to these biases [ 224 ] , [ 225 ] , [ 226 ] , [ 227 ] . • Data Security : In AI data security , key requirements and challenges include ensuring data conﬁdentiality , adhering to consent norms , and safeguarding against vulnerabilities like membership inference attacks [ 228 ] , [ 229 ] . Compli- ance with stringent legal standards within applicable juris- dictions , such as the General Data Protection Regulation ( GDPR ) and California Consumer Privacy Act ( CCPA ) , is essential , necessitating purpose limitation and data minimization [ 230 ] , [ 231 ] , [ 232 ] . Additionally , issues of data sovereignty and copyright emphasize the need for robust encryption , access control , and continuous security assessments [ 233 ] , [ 234 ] . These efforts are critical for maintaining the integrity of AI systems and protecting user privacy in an evolving digital landscape . • AI Ethics : The ﬁeld of AI ethics focuses on fairness , accountability , and societal impact , addresses the surge in ethical challenges posed by AI ’ s increasing complexity and potential misalignment with human values , and re- quires ethical governance frameworks , multidisciplinary collaborations , and technological solutions [ 214 ] , [ 235 ] , [ 15 ] , [ 236 ] . Furthermore , AI Ethics involves ensuring traceability , auditability , and transparency throughout the model development lifecycle , employing practices such as algorithmic auditing , establishing ethics boards , and ad- hering to documentation standards and model cards [ 237 ] , [ 236 ] . However , the adoption of these initiatives remains uneven , highlighting the ongoing need for comprehensive and consistent ethical practices in AI development and deployment [ 214 ] . • Privacy Preservation : This domain focuses on maintain- ing data conﬁdentiality and integrity , employing strategies like anonymization and federated learning to minimize direct data exposure , especially when the rise of genera- tive AI poses risks of user proﬁling [ 238 ] , [ 239 ] . Despite these efforts , challenges such as achieving true anonymity against correlation attacks highlight the complexities in effectively protecting against intrusive surveillance [ 240 ] , [ 241 ] . Ensuring compliance with privacy laws and im- plementing secure data handling practices are crucial in this context , demonstrating the continuous need for robust privacy preservation mechanisms . E. Advanced Learning Advanced learning techniques , including self-supervised learning , meta-learning , and ﬁne-tuning , are at the forefront of AI research , enhancing the autonomy , efﬁciency , and ver- satility of AI models . • Self-supervised Learning : This method emphasizes au- tonomous model training using unlabeled data , reducing manual labeling efforts and model biases [ 242 ] , [ 165 ] , [ 243 ] . It incorporates generative models like autoencoders and GANs for data distribution learning and original input reconstruction [ 244 ] , [ 245 ] , [ 246 ] , and also includes contrastive methods such as SimCLR [ 247 ] and MoCo [ 248 ] , designed to differentiate between positive and negative sample pairs . Further , it employs self-prediction strategies , inspired by NLP , using techniques like mask- ing for input reconstruction , signiﬁcantly enhanced by recent Vision Transformers developments [ 249 ] , [ 250 ] , [ 165 ] . This integration of varied methods highlights self- supervised learning ’ s role in advancing AI ’ s autonomous training capabilities . • Meta-learning : Meta-learning , or ‘ learning to learn ’ , centers on equipping AI models with the ability to rapidly adapt to new tasks and domains using limited data samples [ 251 ] , [ 252 ] . This technique involves mastering the optimization process and is critical in situations with limited data availability , to ensure models can quickly adapt and perform across diverse tasks , essential in the current data-driven landscape [ 253 ] , [ 254 ] . It focuses on few-shot generalization , enabling AI to handle a wide range of tasks with minimal data , underlining its impor- tance in developing versatile and adaptable AI systems [ 255 ] , [ 256 ] , [ 254 ] , [ 257 ] . • Fine Tuning : Involves customizing pre-trained models to speciﬁc domains or user preferences , enhancing accuracy and relevance for niche applications [ 60 ] , [ 258 ] , [ 259 ] . Its two primary approaches are end-to-end ﬁne-tuning , which adjusts all weights of the encoder and classiﬁer [ 260 ] , [ 261 ] , and feature-extraction ﬁne-tuning , where the encoder weights are frozen to extract features for a downstream classiﬁer [ 262 ] , [ 263 ] , [ 264 ] . This tech- nique ensures that generative models are more effectively adapted to speciﬁc user needs or domain requirements , making them more versatile and applicable across various contexts . • Human Value Alignment : This emerging aspect con- centrates on harmonizing AI models with human ethics and values to ensure that their decisions and actions mirror societal norms and ethical standards , involving the integration of ethical decision-making processes and the adaptation of AI outputs to conform with human moral values [ 265 ] , [ 89 ] , [ 266 ] . This is increasingly important in scenarios where AI interacts closely with humans , such as in healthcare , ﬁnance , and personal assistants , to ensure that AI systems make decisions that are not only technically sound , but also ethically and socially responsible , which means human value alignment is becoming crucial in developing AI systems that are trusted and accepted by society [ 89 ] , [ 267 ] . F. Emerging Trends Emerging trends in generative AI research are shaping the future of technology and human interaction , and they indicate a dynamic shift interactive , and towards more integrated , intelligent AI systems , driving forward the boundaries of what is possible in the realm of AI . Key developments in this area include : • Multimodal Learning : Multimodal Learning in AI , a rapidly evolving subdomain , focuses on combining lan- guage understanding with computer vision and audio processing to achieve a richer , multi-sensory context JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 11 awareness [ 114 ] , [ 268 ] . Recent developments like Gem- ini model have set new benchmarks by demonstrating state-of-the-art performance in various multimodal tasks , including natural image , audio , and video understanding , and mathematical reasoning [ 112 ] . Gemini ’ s inherently multimodal design exempliﬁes the seamless integration and operation across different information types [ 112 ] . Despite the advancements , the ﬁeld of multimodal learn- ing still confronts ongoing challenges , such as reﬁning the architectures to handle diverse data types more ef- fectively [ 269 ] , [ 270 ] , developing comprehensive datasets that accurately represent multifaceted information [ 269 ] , [ 271 ] , and establishing benchmarks for evaluating the performance of these complex systems [ 272 ] , [ 273 ] . • Interactive and Cooperative AI : This subdomain aims to enhance the capabilities of AI models to collaborate ef- fectively with humans in complex tasks [ 274 ] , [ 35 ] . This trend focuses on developing AI systems that can work alongside humans , thereby improving user experience and efﬁciency across various applications , including produc- tivity and healthcare [ 275 ] , [ 276 ] , [ 277 ] . Core aspects of this subdomain involve advancing AI in areas such as explainability [ 278 ] , understanding human intentions and behavior ( theory of mind ) [ 279 ] , [ 280 ] , and scalable coor- dination between AI systems and humans , a collaborative approach crucial in creating more intuitive and interactive AI systems , capable of assisting and augmenting human capabilities in diverse contexts [ 281 ] , [ 35 ] . • AGI Development : AGI , representing the visionary goal of crafting AI systems that emulate the comprehensive and multifaceted aspects of human cognition , is a sub- domain focused on developing AI with the capability for holistic understanding and complex reasoning that closely aligns with the depth and breadth of human cognitive abilities [ 282 ] , [ 283 ] , [ 32 ] . AGI is not just about replicating human intelligence , but also involves crafting systems that can autonomously perform a variety of tasks , demonstrating adaptability and learning capabilities akin to those of humans [ 282 ] , [ 283 ] . The pursuit of AGI is a long-term aspiration , continually pushing the boundaries of AI research and development . • AGI Containment : AGI Safety and Containment ac- knowledges the potential risks associated with highly advanced AI systems , focused on ensuring that these ad- vanced systems are not only technically proﬁcient but also ethically aligned with human values and societal norms [ 15 ] , [ 32 ] , [ 11 ] . As we progress towards developing superintelligent systems , it becomes crucial to establish rigorous safety protocols and control mechanisms [ 11 ] . Key areas of concern include mitigating representational biases , addressing distribution shifts , and correcting spu- rious correlations within AI models [ 11 ] , [ 284 ] . The objective is to prevent unintended societal consequences by aligning AI development with responsible and ethical standards . Training Efﬁciency Load Balancing Core Concept Parallelism Techniques Future Directions Figure 4 : Conceptual Diagram of MoE ’ s Innovation IV . INNOVATIVE HORIZON OF MOE The MoE model architecture represents a pioneering ad- vancement in transformer-based language models , offering unparalleled scalability and efﬁciency ( Fig . 4 ) . As evidenced by recent models like the 1.6 trillion parameter Switch Trans- former [ 285 ] and the 8x7B parameter Mixtra [ 286 ] , MoE- based designs are rapidly redeﬁning the frontiers of model scale and performance across diverse language tasks . A . Core Concept and Structure MoE models represent a signiﬁcant innovation in neural network design , offering enhanced scalability and efﬁciency in training and inference [ 287 ] , [ 288 ] , [ 110 ] . At their core , MoE models utilize a sparsity-driven architecture by replacing dense layers with sparse MoE layers comprising multiple expert networks , where each expert is dedicated to a speciﬁc subset of the training data or task , and a trainable gating mechanism dynamically allocates input tokens to these experts , thereby optimizing computational resources and effectively adapting to the task ’ s complexity [ 94 ] , [ 21 ] , [ 110 ] . MoE models demon- strate a substantial advantage in terms of pretraining speed , outperforming dense models [ 94 ] , [ 287 ] . However , they face challenges in ﬁne-tuning and require substantial memory for inference due to the necessity of loading all experts into Video Random Access Memory ( VRAM ) [ 289 ] , [ 290 ] , [ 110 ] . The structure of MoE involves alternating transformer layers with router layers containing gating networks for expert routing , leading to an architecture that allows signiﬁcant parameter scaling and advanced specialization in problem-solving [ 291 ] , [ 21 ] . A distinguishing characteristic of MoE models is their ﬂexi- bility in managing large datasets , capable of amplifying model capacity by over a thousand times while only experiencing minor reductions in computational efﬁciency [ 289 ] , [ 292 ] . The Sparsely-Gated Mixture-of-Experts Layer , a key component of these models , comprises numerous simple feed-forward expert networks and a trainable gating network responsible for expert selection , which can facilitate the dynamic and sparse activation of experts for each input instance , maintaining high computational efﬁciency [ 293 ] , [ 294 ] , [ 110 ] . Recent advancements in MoE models , such as those in the Switch Transformer , have highlighted the signiﬁcant beneﬁts of intelligent routing , when the router ’ s ability to intelligently JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 12 route tokens to appropriate experts confers considerable ad- vantages to MoE models , allowing them to scale up model sizes while keeping compute time constant [ 295 ] , [ 296 ] , [ 297 ] . Experimental evidence suggests that routers learn to route inputs according to data clusters , demonstrating their potential in real-world applications [ 295 ] , [ 289 ] . The core concept and structure of MoE models lie in their dynamic routing and specialization capabilities , offering promising avenues for scaling up neural networks and enhancing their efﬁciency and adaptability in various tasks , but the robustness of the router must be protected against adversarial attacks [ 289 ] , [ 298 ] . B . Training and Inference Efﬁciency MoE models , notably Mixtral 8x7B , are renowned for their superior pretraining speed compared to dense models , yet they face hurdles in ﬁne-tuning and demand considerable VRAM for inference , owing to the requirement of loading all experts [ 289 ] , [ 290 ] , [ 110 ] . Recent advancements in MoE architecture have resulted in notable training cost efﬁciencies , especially in encoder-decoder models , with evidence showing cost savings of up to ﬁvefold in certain contexts when compared to dense models [ 21 ] , [ 289 ] , [ 298 ] , [ 287 ] . Innovations like DeepSpeed- MoE [ 287 ] offered new architectural designs and model com- pression , decreasing the MoE model size by approximately 3.7x and optimizing inference to achieve up to 7.3x better latency and cost efﬁciency . The progression in distributed MoE training and inference , notably with innovations like Lina [ 299 ] , has effectively tackled the all-to-all communication bottleneck by enhancing tensor partitioning , which not only improves all-to-all communication and training step time , but also optimizes resource scheduling during inference , leading to a substantial reduction in training step time by up to 1.73 times and lowering the 95th percentile inference time by an average of 1.63 times compared to existing systems . These developments have marked a crucial shift in the large model landscape , from dense to sparse MoE models , expanding the potential applications of AI by training higher-quality models with fewer resources . C. Load Balancing and Router Optimization Effective load balancing is essential in MoE models to guarantee a uniform distribution of computational load among experts , with the router network in MoE layers , responsible for selecting the appropriate experts for processing speciﬁc tokens , playing a pivotal role in achieving this balance , which is funda- mental to the stability and overall performance of MoE models [ 293 ] , [ 289 ] , [ 288 ] , [ 300 ] , [ 110 ] . Developments in router Z- loss regularization techniques plays a crucial role in addressing expert imbalance in MoE models by ﬁne-tuning the gating mechanism , ensuring a more equitable workload distribution across experts and fostering a stable training environment , thereby enhancing model performance and reducing training time and computational overhead [ 301 ] , [ 302 ] . Concurrently , the integration of expert capacity management strategies , emerges as a crucial approach in MoE models to regulate the processing abilities of individual experts by setting thresholds on the number of tokens each can handle , effectively averting bottlenecks and ensuring a more efﬁcient and streamlined model operation , leading to improved training processes and heightened performance during complex computational tasks [ 293 ] , [ 303 ] , [ 289 ] . D. Parallelism and Serving Techniques Recent developments in MoE models highlighted their ef- ﬁciency in parallelism and serving techniques , signiﬁcantly inﬂuencing large-scale neural networks . DeepSpeed-MoE , for instance , introduces advanced parallelism modes like data par- allelism , tensor-slicing for non-expert parameters , and expert parallelism for expert parameters , enhancing model efﬁciency , as their approach optimizes both latency and throughput in MoE model inference , offering scalable solutions in produc- tion environments using multiple Graphics Processing Unit ( GPU ) devices [ 287 ] . MoE models , versatile in applications like multilingual tasks and coding , demonstrated impressive capabilities in handling complex tasks due to their ensemble- like structure within a single framework [ 304 ] , [ 305 ] , [ 306 ] . Notably , models like Mixtral and Switch Transformer , with over 1.6 trillion parameters , achieved computational efﬁciency equivalent to a 10 billion-parameter dense model , because they beneﬁted from the sublinear scaling of MoE compute versus model size , leading to substantial accuracy gains within ﬁxed compute budgets [ 21 ] , [ 289 ] , [ 287 ] , [ 110 ] . Moreover , DeepSpeed-MoE included model compression techniques , re- ducing model size by up to 3.7x while maintaining accuracy , and an end-to-end MoE training and inference solution , part of the DeepSpeed library , which was instrumental in serv- ing large-scale MoE models with enhanced speed and cost- efﬁciency [ 287 ] . These innovations open new directions in AI , shifting from dense to sparse MoE models , where training and deploying higher-quality models with fewer resources become more widely achievable . E. Future Directions and Applications Emerging research on MoE architectures could focus on advancing sparse ﬁne-tuning techniques , exploring instruction tuning methods , and improving routing algorithms to fully utilize performance and efﬁciency gains . As models scale over one billion parameters , MoE represents a paradigm shift for vastly expanding capabilities across scientiﬁc , medical , creative , and real-world applications . Frontier work could also aim to reﬁne auto-tuning of hyperparameters during ﬁne- tuning to optimize accuracy , calibration , and safety . MoE re- search continues to push model scale limits while maintaining specialization for transfer learning . Adaptive sparse access allows coordinating thousands of experts to cooperate on tasks ranging from reasoning to open domain dialogue . Continued analysis of routing mechanisms seeks to balance load across experts and minimize redundant computation . As the AI community further investigates MoE methods at scale , these models hold promise for new breakthroughs in language , code generation , reasoning , and multimodal applications . There is great interest in evaluating implications across education , healthcare , ﬁnancial analysis , and other ﬁelds . Outcomes may yield insights not only into model optimization but also for understanding principles behind combinatorial generalization . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 13 Human-Level Understanding Self- Learning and Exploration General Intelligence Real-World Knowledge Integration Common Sense Reasoning Figure 5 : Conceptual Diagram of Speculated Q * Capabilities V. SPECULATED CAPABILITIES OF Q * In the burgeoning realm of AI , the anticipated Q * project stands as a beacon of potential breakthroughs , heralding ad- vancements that could redeﬁne the landscape of AI capabilities ( Fig . 5 ) . A . Enhanced General Intelligence Q * ’ s development in the arena of general intelligence rep- resents a paradigm shift from specialized to holistic AI , indi- cating a broadening of the model ’ s cognitive abilities akin to human intelligence . This advanced form of general intelligence involves integrating diverse neural network architectures and machine learning techniques , enabling the AI to process and synthesize multifaceted information seamlessly . The universal adapter approach , mirroring models like T0 , could endow Q * with the capability to rapidly assimilate knowledge from various domains . This method allows Q * to learn adaptable module plugins , enhancing its ability to tackle new data types while preserving existing skills , leading to an AI model that combines narrow specializations into a comprehensive , adaptive , and versatile reasoning system . The corresponding quasi-mathematical formulation can be expressed as : n EGI ( Q∗ ) = ( N Ni ⊙ M LTi ) M i=1 ( 1 ) Where : • EGI : “ Enhanced General Intelligence ” • N Ni : a diverse set of neural network architectures . • M LTi : various machine learning techniques . • L : the integration of these components . • ⊙ : a functional interaction between neural networks and machine learning techniques . Such advancements in AI suggest the emergence of an intel- ligence that not only parallels but potentially exceeds human cognitive ﬂexibility , with far-reaching implications in facil- itating cross-disciplinary innovations and complex problem- solving . The speculated capabilities of Q * bring forth com- plex ethical implications and governance challenges . As AI systems approach higher levels of autonomy and decision- making , it is crucial to establish robust ethical frameworks and governance structures to ensure responsible and transparent AI development . This involves mitigating potential risks associ- ated with advanced AI capabilities , emphasizing the need for comprehensive and dynamic ethical guidelines that evolve in tandem with AI advancements . B . Advanced Self-Learning and Exploration In the realm of advanced AI development , Q * is antici- pated to represent a signiﬁcant evolution in self-learning and exploration capabilities . It is speculated to utilize sophisticated Policy Neural Networks ( NNs ) , similar to those in AlphaGo , but with substantial enhancements to handle the complexities of language and reasoning tasks . These networks are expected to employ advanced reinforcement learning techniques like Proximal Policy Optimization ( PPO ) , which stabilizes policy updates and improves sample efﬁciency , a crucial factor in autonomous learning . The integration of these NNs with cutting-edge search algorithms , potentially including novel iterations of Tree or Graph of Thought , is predicted to en- able Q * to autonomously navigate and assimilate complex information . This approach might be augmented with graph neural networks to bolster meta-learning capacities , allowing Q * to rapidly adapt to new tasks and environments while retaining previously acquired knowledge . The corresponding quasi-mathematical formulation can be represented as : ASLE ( Q∗ ) = RL ( P N N , SA ) × GN N ( 2 ) Where : • ASLE : “ Advanced Self-Learning and Exploration ” • RL : to reinforcement learning algorithms , particularly Proximal Policy Optimization ( PPO ) . • P N N : Policy Neural Networks , adapted for language and reasoning tasks . • SA : sophisticated search algorithms , like Tree or Graph of Thought . • GN N : the incorporation of Graph Neural Networks for meta-learning . • × : the cross-functional enhancement of RL with GNN . Such capabilities indicate a model not limited to understand- ing existing data but equipped to actively seek and synthesize new knowledge , effectively adapting to evolving scenarios without the need for frequent retraining . This signiﬁes a leap beyond current AI models , embedding a level of autonomy and efﬁciency previously unattained . C. Superior Human-Level Understanding Q * ’ s aspiration to achieve superior human-level under- standing is speculated to hinge on an advanced integration of multiple neural networks , including a Value Neural Net- work ( VNN ) , paralleling the evaluative components found in systems like AlphaGo . This network would extend beyond assessing accuracy and relevance in language and reasoning processes , delving into the subtleties of human communica- tion . The model ’ s deep comprehension capabilities may be enhanced by advanced natural language processing algorithms and techniques , such as those found in transformer architec- tures like DeBERTa . These algorithms would empower Q * to interpret not just the text but also the nuanced socio-emotional aspects such as intent , emotion , and underlying meanings . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 14 Incorporating sentiment analysis and natural language infer- ence , Q * could navigate layers of socio-emotional insights , including empathy , sarcasm , and attitude . The corresponding quasi-mathematical formulation can be expressed as : SHLU ( Q∗ ) = X ( V N N ⊕ alg ) ( 3 ) alg∈N LP Where : • SHLU : “ Superior Human-Level Understanding ” . • V N N : the Value Neural Network , similar to evaluative components in systems like AlphaGo . • N LP : a set of advanced NLP algorithms . • ⊕ : the combination of VNN evaluation with NLP algo- rithms . • alg : individual algorithms within the NLP set . This level of understanding , surpassing current language models , would position Q * to excel in empathetic , context- aware interactions , thus enabling a new echelon of personal- ization and user engagement in AI applications . D. Advanced Common Sense Reasoning Q * ’ s anticipated development in advanced common sense reasoning is predicted to integrate sophisticated logic and decision-making algorithms , potentially combining elements of symbolic AI and probabilistic reasoning . This integration aims to endow Q * with an intuitive grasp of everyday logic and an understanding akin to human common sense , thus bridging a signiﬁcant gap between artiﬁcial and natural intelligence . Enhancements in Q * ’ s reasoning abilities might involve graph- structured world knowledge , incorporating physics and social engines similar to those in models like CogSKR . This ap- proach , grounded in physical reality , is expected to capture and interpret the everyday logic often absent in contemporary AI systems . By leveraging large-scale knowledge bases and semantic networks , Q * could effectively navigate and respond to complex social and practical scenarios , aligning its infer- ences and decisions more closely with human experiences and expectations . The corresponding quasi-mathematical formula- tion can be represented as : ACSR ( Q∗ ) = LogicAI ⊙ P robAI ⊙ W orldK ( 4 ) Where : • ACSR : “ Advanced Common Sense Reasoning ” . • LogicAI and P robAI : symbolic AI and probabilistic reasoning components , respectively . • W orldK : the integration of graph-structured world knowledge . • ⊙ : the integrated operation of these elements for common sense reasoning . E. Extensive Real-World Knowledge Integration Q * ’ s approach to integrating extensive real-world knowl- edge is speculated to involve the use of advanced formal veriﬁcation systems , which would provide a robust basis for validating its logical and factual reasoning . This method , when Understanding and Interaction Autonomous Learning Cognitive Abilities Knowledge Integration Common Sense Reasoning Figure 6 : Conceptual Diagram of Projected AGI Capabilities coupled with sophisticated neural network architectures and dynamic learning algorithms , would enable Q * to engage deeply with the complexities of the real world , transcending conventional AI limitations . Additionally , Q * might employ mathematical theorem proving techniques for validation , en- suring that its reasoning and outputs are not only accurate but also ethically grounded . The incorporation of Ethics classiﬁers in this process further strengthens its capacity to deliver reliable and responsible understanding and interaction with real-world scenarios . The corresponding quasi-mathematical formulation can be represented as : ERW KI ( Q∗ ) = F V S ⊗ N N ⊗ LT P ⊗ EC ( 5 ) Where : • ERW KI : “ Extensive Real-World Knowledge Integra- tion ” . • F V S : Formal Veriﬁcation Systems . • N N : neural network architectures . • LT P : mathematical factual validation . theorem proving for logical and • EC : the incorporation of Ethics classiﬁers . • ⊗ : the comprehensive integration for knowledge synthesis and ethical alignment . Furthermore , the speculated capabilities of Q * have the potential to signiﬁcantly reshape the job market and labor dynamics . With its advanced functionalities , Q * could auto- mate complex tasks , leading to a shift in job requirements and the emergence of new skill demands . This necessitates a re- evaluation of workforce strategies and educational paradigms , aligning them with the evolving technological landscape and ensuring that the workforce is equipped to interact with and complement these advanced AI systems . VI . PROJECTED CAPABILITIES OF AGI AGI stands as a transformative leap in AI , endeavoring to mirror human cognitive abilities in a software paradigm ( Fig . 6 ) . AGI ’ s evolution is marked by advanced self-learning capabilities , utilizing policy neural networks and sophisticated reinforcement learning techniques for autonomous adaptation . The integration of algorithms like Tree/Graph of Thought with these networks suggests a future where AGI can independently acquire and apply knowledge across diverse domains . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 15 A . Revolution in Autonomous Learning F. Challenges and Opportunities in AGI Development AGI is anticipated to revolutionize self-learning and ex- ploration [ 282 ] , [ 307 ] , [ 283 ] , [ 32 ] . By incorporating methods like PPO , AGI models are positioned to achieve a level of autonomous learning and problem-solving that exceeds the current AI models ’ dependence on training data , indicating a potential paradigm shift towards reducing the need for frequent retraining and facilitating dynamic adaptation in response to evolving scenarios [ 181 ] , [ 308 ] . B . Broadening of Cognitive Abilities Envisaged to integrate various architectures , AGI could promise a level of general intelligence that replicates the multi- faceted nature of human cognition [ 282 ] , [ 309 ] . The universal adapter approach , mirroring models like GPT and BERT , could facilitate rapid assimilation of diverse information , positioning AGI as a system capable of performing tasks across multiple domains with an adaptability akin to human intellect [ 282 ] , [ 310 ] . While AGI ’ s full capabilities remain speculative , current trends suggest its potential application in advanced healthcare diagnostics , which is evidenced by recent breakthroughs in AI- driven predictive medicine models , indicating AGI ’ s potential to revolutionize medical diagnosis and treatment . C. Elevating Understanding and Interaction AGI is projected to achieve an unparalleled understanding of human language and socio-emotional subtleties , leverag- ing algorithms like those in transformer architectures , which would enable AGI to engage in complex , empathetic , and con- textually aware interactions , suggesting potential applications that revolutionize how AI systems communicate and interact [ 282 ] , [ 307 ] , [ 311 ] . The development of AGI encompasses both challenges and opportunities . While AGI promises productivity boosts in creative ﬁelds and innovations in cross-modal generation techniques , substantial challenges like data bias , computational efﬁciency , and ethical implications persist [ 15 ] , [ 32 ] . These challenges necessitate a balanced approach in AGI develop- ment , focusing on data curation , efﬁcient systems , and societal impacts [ 309 ] . In the context of AGI development , experts from various domains caution against overestimating current AI capabilities and highlight the gap between the theoretical framework of AGI and the practical realities of today ’ s AI [ 314 ] , [ 32 ] . The envisioned autonomy and cognitive abilities of AGI separate it from current AI models , suggesting a future where AI systems could perform tasks across various domains without human intervention [ 282 ] . This development trajectory underscores the importance of ethical considerations and technological breakthroughs in AGI ’ s journey towards becoming a transfor- mative force in society [ 15 ] , [ 32 ] . While projecting the time- line for achieving true AGI remains speculative , recognizing potential roadblocks is crucial , such as the current limitations in computational power , and the complexity of replicating human-like cognitive abilities . These emphasize the need for sustained research and ethical considerations in the pursuit of AGI , ensuring responsible and conscientious development . VII . IMPACT ANALYSIS ON GENERATIVE AI RESEARCH TAXONOMY With the advent of advanced AI developments such as MoE , multimodality , and AGI , the landscape of Generative AI research is undergoing a signiﬁcant transformation . This section analyzes how these developments are reshaping the research taxonomy in generative AI . D. Advanced Common Sense Reasoning A . Criteria for Impact Analysis Symbolic AI and probabilistic reasoning , integrated into AGI , could imbue these systems with an innate grasp of common sense , to bridge the gap between artiﬁcial and natural intelligence , enabling AGI to navigate and respond effectively to real-world scenarios with reasoning aligned closely with human thought processes [ 282 ] , [ 312 ] , [ 313 ] . E. Holistic Integration of Knowledge AGI ’ s potential in integrating extensive real-world knowl- edge , guided by formal veriﬁcation systems , hints at future capabilities where AGI ’ s outputs are not only accurate but ethically grounded , suggesting AGI ’ s ability for responsible interaction with real-world complexities [ 282 ] , [ 311 ] . The projected capabilities of AGI extend to addressing signiﬁcant global challenges , such as climate change , in which AGI ’ s advanced data analysis and predictive modeling can play a better and more crucial role in environmental monitoring , fore- casting climate patterns , and devising sustainable solutions , contributing signiﬁcantly to global ecological efforts [ 282 ] , [ 283 ] , [ 32 ] . The continuously evolving landscape of Generative AI , which instigates transformative changes across various re- search domains , necessitates a systematic evaluation of these advancements ’ inﬂuence , for which we have established a set of criteria detailed in Table II , serving as analytical lenses to quantify and categorize the impact , deeply rooted in the dynamic interplay between technological progress and the evolving paradigms of research focus areas . Our analysis framework has been constructed on a gradient scale ranging from emergent to obsolete , reﬂecting the extent to which areas of Generative AI research are being reshaped . The categorization into ﬁve distinct classes allows for a complex assessment , acknowledging that not all areas will be uniformly affected . This multi-tiered approach is informed by historical patterns of technological disruption and the adaptability of scientiﬁc inquiry . At the apex of our evaluative hierarchy , ‘ Emerging Direc- tion ’ encapsulates the advent of uncharted research vistas , propelled by ongoing AI breakthroughs , which is predicated not on conjecture , but on a historical continuum of AI evo- lution , where each surge in technological power unfurls new JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 16 Table II : Criteria for Analyzing Impact on Generative AI Research Symbol ր ֒→ ↔ ց △ Criteria Emerging Direc- tion Requiring Redi- rection Still Relevant to Likely Become Redundant Inherently Unre- solvable Score 5 4 3 2 1 Deﬁnition New research areas expected to arise as a direct consequence of AI advancements . Areas that need to shift focus or methodol- ogy to stay relevant with new AI develop- ments . Areas where the advancements have mini- mal or no impact , maintaining their current status and methodologies . Areas that may lose relevance or become obsolete with the advent of new AI tech- nologies . Challenges that may remain unresolved due to complexities like subjective human per- spectives and diverse cultural values . Justiﬁcation Emphasizes novel research domains emerging from AI break- throughs [ 315 ] , [ 316 ] . Technological shifts necessitate reevaluation and redirection in AI research [ 315 ] , [ 317 ] . Observes the persistence of certain AI research areas despite technological advancements [ 317 ] . Discusses rapid obsolescence in AI methodologies due to new technologies [ 318 ] . Inherent difﬁculties in issues such as aligning AI with diverse human values and ethics [ 319 ] , [ 320 ] . scientiﬁc enigmas and avenues [ 315 ] , [ 316 ] . ‘ Areas Requiring Redirection ’ denote research spheres that , though established , ﬁnd themselves at an inﬂection point , necessitating a strategic pivot to assimilate emergent AI paradigms and an overhaul of traditional methodologies , akin to the transition from rule- based expert systems to adaptive machine learning frameworks [ 315 ] , [ 317 ] . The ‘ Still Relevant ’ classiﬁcation afﬁrms the tenacity of select research domains that , by addressing persis- tent scientiﬁc inquiries or through their inherent malleability , remain impervious to the tides of AI innovation [ 317 ] . In contrast , domains categorized as ‘ Likely to Become Redun- dant ’ confront potential obsolescence , inviting strategic fore- sight and resource reallocation to forestall scientiﬁc stagnation [ 318 ] . Lastly , ‘ Inherently Unresolvable ’ challenges serve as a sobering reminder of the perpetual dilemmas within AI research that defy resolution , rooted in the complex web of human ethics and cultural diversity , thus anchoring the pursuit of AI within the intractable tapestry of human values and societal imperatives [ 319 ] , [ 320 ] . B. Overview of Impact Analysis This subsection offers a detailed overview of the impact analysis carried out on the research taxonomy within the realm of generative AI , with a speciﬁc focus on recent progress in MoE , multimodality , and AGI , aiming to evaluate the impact of these innovative developments on various facets of generative AI research , ranging from model architecture to sophisticated learning methodologies , and includes both quantitative and qualitative assessments across a multitude of domains and subdomains in LLM research , shedding light on the extent to which each area is inﬂuenced by these techno- logical advancements . This evaluation considered factors such as the emergence of new research directions , the necessity for redirection in existing research areas , the continued relevance of certain methodologies , and the potential redundancy of others , and has encapsulated in Table III . 1 ) Impact On Model Architecture : Transformer Models have been scored with a redirection requirement ( ֒→ ) of 4 in both MoE and AGI , and a relevance ( ↔ ) of 3 in multimodality , leading to an overall score of 11 . These models , forming the backbone of many current AI architectures , continue to be relevant for handling complex input sequences . However , the emergence of MoE and AGI indicates a shift towards more dynamic and specialized architectures . While transformers re- main essential , there is a need for them to evolve and integrate with these advanced systems for enhanced performance and adaptability . Recurrent Neural Networks ( RNNs ) are facing a potential decline in relevance , as indicated by their scores : likely to become redundant ( ց ) 2 in both MoE and AGI contexts and still relevant ( ↔ ) 3 in multimodality , totaling a score of 7 . Although effective for sequence processing , RNNs are challenged by their limitations in handling long-range depen- dencies and lower efﬁciency compared to newer models like transformers . They may retain some relevance in multimodal tasks involving sequential data but are generally overshadowed by more advanced architectures . The MoE models have scored a consistent relevance ( ↔ ) of 3 in their own development and a score of 5 ( ր ) in multimodality , combined with a redirection score ( ֒→ ) of 4 in the context of AGI , amounting to an overall score of 12 . MoE models are at the forefront of emerging research in multimodality due to their ability to handle diverse data types . For AGI , these models will require adjustments to effectively integrate into systems exhibiting general intelligence , espe- cially in areas beyond their initial specialization . Multimodal Models have received high scores for emerging research directions ( ր ) of 5 in both MoE and AGI contexts , alongside a score of 3 ( ↔ ) for current relevance in multi- modality , culminating in an overall score of 13 . The integration of MoE and the pursuit of AGI are opening new pathways for research in multimodal models . These developments are crucial for enhancing the ability to process and synthesize information from multiple modalities , a key aspect for both specialized and generalized AI systems . 2 ) Impact On Training Techniques : Supervised Learning has been assigned a redirection score ( ֒→ ) of 4 , a relevance score ( ↔ ) of 3 in multimodality , and a score indicating poten- tial redundancy ( ց ) of 2 in the context of AGI , culminating in an overall score of 9 . While supervised learning requires adaptation to ﬁt the MoE framework , it remains relevant for multimodal AI models that depend on labeled data . However , with the shift towards more autonomous learning methods in AGI , the dependence on extensive labeled datasets typically associated with supervised learning may diminish , leading to its potential decrease in signiﬁcance . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 17 Table III : Impact of MoE , Multimodality , and AGI on Generative AI Research Domain Model Architecture Training Techniques Application Domains Compliance and Ethical Considerations Advanced Learning Emerging Trends Subdomain Transformer Models Recurrent Neural Networks Mixture of Experts Multimodal Models Supervised Learning Unsupervised Learning Reinforcement Learning Transfer Learning Natural Language Understanding Natural Language Generation Conversational AI Creative AI Bias Mitigation Data Security AI Ethics Privacy Preservation Self-supervised Learning Meta-learning Fine Tuning Human Value Alignment Multimodal Learning Interactive and Cooperative AI AGI Development AGI Containment MoE Multimodality ֒→ ( 4 ) ց ( 2 ) ↔ ( 3 ) ր ( 5 ) ֒→ ( 4 ) ֒→ ( 4 ) ↔ ( 3 ) ↔ ( 3 ) ↔ ( 3 ) ↔ ( 3 ) ֒→ ( 4 ) ֒→ ( 4 ) ֒→ ( 4 ) ↔ ( 3 ) ֒→ ( 4 ) ֒→ ( 4 ) ֒→ ( 4 ) ↔ ( 3 ) ↔ ( 3 ) △ ( 1 ) ր ( 5 ) ֒→ ( 4 ) ֒→ ( 4 ) △ ( 1 ) ↔ ( 3 ) ↔ ( 3 ) ր ( 5 ) ↔ ( 3 ) ↔ ( 3 ) ↔ ( 3 ) ֒→ ( 4 ) ր ( 5 ) ↔ ( 3 ) ֒→ ( 4 ) ր ( 5 ) ր ( 5 ) ֒→ ( 4 ) ↔ ( 3 ) ֒→ ( 4 ) ֒→ ( 4 ) ր ( 5 ) ↔ ( 3 ) ↔ ( 3 ) △ ( 1 ) ↔ ( 3 ) ↔ ( 3 ) ֒→ ( 4 ) △ ( 1 ) AGI ֒→ ( 4 ) ց ( 2 ) ֒→ ( 4 ) ր ( 5 ) ց ( 2 ) ֒→ ( 4 ) ր ( 5 ) ֒→ ( 4 ) ր ( 5 ) ր ( 5 ) ր ( 5 ) ր ( 5 ) ր ( 5 ) ↔ ( 3 ) △ ( 1 ) ֒→ ( 4 ) ↔ ( 3 ) ր ( 5 ) ց ( 2 ) △ ( 1 ) ր ( 5 ) ր ( 5 ) ↔ ( 3 ) ր ( 5 ) Overall Score 11 7 12 13 9 11 12 12 11 12 14 14 13 9 9 12 12 11 8 3 13 12 11 7 Unsupervised Learning scores a redirection requirement ( ֒→ ) of 4 in both MoE and AGI contexts and maintains its relevance ( ↔ ) with a score of 3 in multimodality , resulting in a total score of 11 . In the MoE architecture , unsupervised learn- ing methods may need adjustments , particularly in managing dynamic task allocation . It remains crucial for understanding unlabeled data across various modalities . In AGI , unsupervised learning is expected to evolve beyond traditional techniques , focusing on more advanced self-discovery and intrinsic learn- ing mechanisms . Reinforcement Learning is rated as still relevant ( ↔ ) with a score of 3 in MoE , requiring redirection ( ֒→ ) with a score of 4 in multimodality , and identiﬁed as an emerging research area ( ր ) with a score of 5 in AGI , giving it a total score of 12 . This technique continues to play a signiﬁcant role in optimizing MoE model structures . In the realm of multimodality , it necessitates a strategic shift to effectively manage complex interactions between different modalities . As for AGI , reinforcement learning is emerging as a crucial area , particularly in the development of autonomous systems that learn from their environment . Transfer Learning receives a consistent relevance score ( ↔ ) of 3 in MoE , a high score for emerging research directions ( ր ) of 5 in multimodality , and a redirection requirement ( ֒→ ) of 4 in AGI , accumulating to an overall score of 12 . It remains important in the MoE framework for leveraging knowledge across different experts . In multimodal contexts , transfer learning is becoming increasingly crucial as it facili- tates the transfer of learning between different modalities . With the evolution of AGI , this technique is expected to undergo signiﬁcant changes to cater to broader and more generalized knowledge applications . 3 ) Impact On Application Domains : Natural Language Understanding holds steady relevance ( ↔ ) with a score of 3 in both MoE and multimodality , and an emerging direction ( ր ) score of 5 in AGI , totaling an overall score of 11 . MoE models support the relevance of NLU by enhancing its precision and depth through their ability to handle large , diverse datasets . In multimodal AI , NLU remains a critical component for comprehending language in diverse data formats . With AGI ’ s progress , NLU is expected to undergo signiﬁcant expansion , moving towards more advanced , human-like comprehension and interpretation capabilities . Natural Language Generation maintains relevance ( ↔ ) with a score of 3 in MoE , requires redirection ( ֒→ ) with a score of 4 in multimodality , and is identiﬁed as an emerging research area ( ր ) with a score of 5 in AGI , resulting in a total score of 12 . MoE ’ s scalability is crucial for enhancing NLG , while in multimodal contexts , NLG may need strategic adjustments to align effectively with other modalities . As AGI evolves , NLG is anticipated to venture into new research domains , especially that reﬂects human-like creativity and in creating content adaptability . Conversational AI is marked for redirection ( ֒→ ) with a score of 4 in MoE , emerging research directions ( ր ) with a score of 5 in both multimodality and AGI , accumulating an overall score of 14 . While MoE enhances conversational AI , it may require strategic changes to fully utilize MoE ’ s distributed expertise . The integration of multiple modalities opens new avenues for conversational AI , expanding its scope to include various sensory data . The development of AGI is set to bring revolutionary advancements in this domain , paving the way for more autonomous , context-aware , and human-like interactions . Creative AI scores a redirection requirement ( ֒→ ) of 4 in JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 18 MoE , and high scores for emerging research directions ( ր ) of 5 in both multimodality and AGI , leading to a total score of 14 . In the context of MoE , Creative AI may need to be realigned to capitalize on MoE ’ s capacity for generating novel content . The combination of different modalities in creative AI presents exciting new research opportunities , enabling the creation of more intricate and diverse outputs . As AGI progresses , it is expected to signiﬁcantly broaden the capabilities of creative AI , potentially surpassing existing boundaries and exploring new realms of creativity . 4 ) Impact On Compliance and Ethical Considerations : Bias Mitigation in the context of MoE , multimodality , and AGI scores a redirection requirement ( ֒→ ) of 4 in both MoE and multimodality , and an emerging research direction ( ր ) with a score of 5 in AGI , resulting in an overall score of 13 . MoE architectures demand a new approach in bias mitigation due to the diversity of expert networks , which could other- wise amplify biases . In multimodal systems , bias mitigation requires novel strategies to address biases in various data types , including non-textual forms like images and audio . With AGI ’ s broad cognitive capabilities , a comprehensive approach towards understanding and addressing biases across diverse domains is emerging as a critical research area . Data Security maintains a consistent relevance ( ↔ ) with a score of 3 across MoE , multimodality , and AGI , leading to a total score of 9 . The fundamental principles of data security remain crucial despite the advancements in MoE , which may necessitate tailored strategies for its distributed nature . In multimodal AI , the secure handling of diverse data types continues to be of paramount importance . The core tenets of data security are sustained even with the advancement of AGI , though the complexity and scope of security measures are likely to increase . AI Ethics is marked for redirection ( ֒→ ) with a score of 4 in both MoE and multimodality , and faces inherently unresolvable challenges ( △ ) with a score of 1 in AGI , accu- mulating a total score of 9 . The decision-making processes and transparency of MoE models necessitate a reevaluation of ethical considerations . In multimodal AI , ethical concerns , particularly in the interpretation and use of multimodal data , require new approaches . The ethical challenges in AGI are expected to be complex and involve deep philosophical and societal implications that might be difﬁcult to fully resolve . Privacy Preservation scores a redirection need ( ֒→ ) of 4 across MoE , multimodality , and AGI , leading to an overall score of 12 . The distributed nature of MoE systems requires a reassessment of privacy preservation techniques to handle data processed by multiple experts . Multimodal AI systems , espe- cially those handling sensitive data such as images and sounds , necessitate tailored privacy strategies . With the extensive data processing capabilities of AGI , advanced and potentially new approaches to privacy preservation are called for . 5 ) Impact On Advanced Learning : In the context of MoE , self-supervised learning requires redirection ( ֒→ ) with a score of 4 , signaling the need to adapt to the evolving architecture . Emerging research directions ( ր ) with a score of 5 are iden- tiﬁed in multimodality , suggesting the integration of various autonomous data types like text , image , and audio . For AGI , self-supervised learning remains relevant ( ↔ ) with a score of 3 , contributing to the system ’ s autonomy and adaptability , though likely to be integrated with more complex strategies . The overall impact score is 12 . Meta-learning maintains consistent relevance ( ↔ ) with a score of 3 across MoE and multimodality , aligning well with the dynamic nature of MoE and aiding quick adaptation to varying data types and tasks in multimodal contexts . In AGI , it is marked as an emerging research direction ( ր ) with a score of 5 , suggesting novel research in achieving human-like adaptability and learning efﬁciency . The total score for meta- learning is 11 . Fine tuning continues to be relevant ( ↔ ) with a score of 3 in both MoE and multimodality , being essential for adapting pre-trained models to speciﬁc tasks and tailoring multimodal models . However , in AGI , it is likely to become redundant ( ց ) with a score of 2 , as AGI aims to develop systems that autonomously understand and learn across a broad range of domains , reducing the need for traditional ﬁne- tuning processes . The overall impact score for ﬁne tuning is 8 . Aligning AI with human values poses inherently unresolv- able challenges ( △ ) in all contexts—MoE , multimodality , and AGI—with a score of 1 . This reﬂects the complexity and diversity of tasks MoE models handle , the integration of various data types in multimodal AI , and the broad range of cognitive abilities encompassed by AGI . These factors contribute to the signiﬁcant ongoing challenges in aligning AI with human values , resulting in a total score of 3 . 6 ) Impact On Emerging Trends : Multimodal learning is marked as an emerging research direction ( ր ) with a score of 5 in both MoE and AGI contexts , reﬂecting its capacity to integrate various data types such as text , images , and audio . This integration is crucial for specialized tasks in MoE and processing diverse forms of data in AGI . In the realm of multimodality , it remains a core aspect ( ↔ ) with a score of 3 , being essential for ongoing multimodal AI development . The overall impact score is 13 . Interactive and Cooperative AI requires redirection ( ֒→ ) in MoE with a score of 4 , as MoE models adapt to include more interactive elements for broader applications . In multimodality , interaction and cooperation continue to be central ( ↔ ) with a score of 3 , especially in ﬁelds like robotics and virtual assistants . AGI ’ s evolution includes signiﬁcant advancements in interactive AI , marking it as an emerging research area ( ր ) with a score of 5 . The total score for this trend is 12 . The development of AGI necessitates redirection ( ֒→ ) in both MoE and multimodality , each with a score of 4 , indicating the need for more integrated and complex systems . AGI remains at the forefront of its own ﬁeld ( ↔ ) with a score of 3 , with each breakthrough directly inﬂuencing its progress . The overall impact score for AGI development is 11 . AGI containment is identiﬁed as a challenge not required to be solved ( △ ) in both MoE and multimodality , with a score of 1 , as these areas are not expected to reach the levels of autonomy and complexity associated with AGI . However , as AGI progresses , the emerging need for effective containment strategies is marked ( ր ) with a score of 5 , highlighting the JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 19 importance of ensuring safe and controlled AI deployment . The total impact score is 7. effectively engage with and leverage the advancements in AI , equipping them with the necessary skills to navigate its complexities and innovations . VIII . EMERGENT RESEARCH PRIORITIES IN GENERATIVE AI As we are likely to approach the precipice of a new era marked by the advent of Q * , nudging us closer to the realization of usable AGI , the research landscape in generative AI is undergoing a crucial transformation . A. Emergent Research Priorities in MoE The MoE domain is increasingly focusing on two critical areas : • Multimodal Models in Model Architecture : The in- tegration of MoE and AGI is opening new pathways for research in multimodal models . These developments are enhancing the capability to process and synthesize information from multiple modalities , which is crucial for both specialized and generalized AI systems . • Multimodal Learning in Emerging Trends : MoE is at the forefront of multimodal learning , integrating diverse data types like text , images , and audio for specialized tasks . This trend is directly impacting the enhancement of the ﬁeld . Furthermore , an analysis of funding trends and investment patterns in AI research could indicate a substantial shift towards areas like multimodal models in MoE . This trend , characterized by increased capital ﬂow into ﬁelds involving complex data processing and autonomous systems , is shaping the direction of future research priorities . It underscores the growing interest and investment in the potential of generative AI , inﬂuencing both academic and industry-led initiatives . B. Emergent Research Priorities in Multimodality In the realm of multimodality , several areas are identiﬁed as emerging research priorities : • MoE in Model Architecture : MoE models are becoming increasingly relevant for handling diverse data types in multimodal contexts . • Transfer Learning in Training Techniques : Transfer learning is emerging as a key research direction , espe- cially for learning between different modalities . • Conversational AI and Creative AI in Application Domains : Both conversational AI and creative AI are expanding in multimodal contexts , encompassing visual , auditory , and other sensory data integration . • Self-Supervised Learning in Advanced Learning : New research directions in self-supervised learning are emerg- ing , focusing on the integration of various data types autonomously . Additionally , the rise of generative AI , particularly in multi- modal contexts , can signiﬁcantly impact educational curricula and skill development . There is a growing need to update academic programs to include comprehensive AI literacy , with a focus on multimodal AI technologies . This evolution in education is aimed at preparing future professionals to C. Emergent Research Priorities in AGI The AGI domain is witnessing a surge in research priorities across multiple areas : • Multimodal Models in Model Architecture : Similar to MoE , multimodal models are crucial in AGI , enabling deeper and more nuanced understanding . • Reinforcement Learning in Training Techniques : Emerging as a key area in AGI , reinforcement learning focuses on developing autonomous systems learning from their environment . • Application Domains : AGI is extending the boundaries of natural language understanding and generation , conver- sational AI , and creative AI , with a focus on human-like comprehension and creativity . • Bias Mitigation in Compliance and Ethical Consid- erations : New directions in bias mitigation are focusing on a comprehensive approach to addressing biases across diverse domains in AGI . • Meta-Learning in Advanced Learning : AGI ’ s pursuit of human-like adaptability is leading to novel research in meta-learning . • Emerging Trends : Multimodal learning , interactive and cooperative AI , and AGI containment strategies are be- coming crucial research areas as AGI progresses . In line with these developments in AGI , a noticeable trend in AI research funding and investment patterns is evident . There is a signiﬁcant inclination towards supporting projects and studies in AGI , particularly in areas such as natural language understanding and generation , and autonomous systems . This funding trend not only mirrors the escalating interest in the capabilities of AGI but also directs the trajectory of future research , shaping both academic exploration and industry- driven projects . IX . PRACTICAL IMPLICATIONS AND LIMITATIONS OF GENERATIVE AI TECHNOLOGIES Generative AI technologies , encompassing MoE , multi- modality , and AGI , present unique computational challenges . This section explores the processing power requirements , memory usage , and scalability concerns inherent in these advanced AI models . A. Computational Complexity and Real-world Applications of Generative AI Technologies 1 ) Computational Complexity : Generative AI technologies , encompassing MoE , multimodality , and AGI , present unique computational challenges . This section explores the processing power requirements , memory usage , and scalability concerns inherent in these advanced AI models . • Processing Power Requirements : Advanced generative AI models , including MoE architectures and AGI sys- tems , require signiﬁcant processing power [ 321 ] . The JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 20 demand for GPUs and TPUs is accentuated , particularly when handling complex computations and large datasets typical in multimodal AI applications . 2 ) Existing Industry Solutions : Generative AI is reshaping various industries by offering innovative solutions and altering market dynamics . • Memory Usage in AI Modeling : A critical challenge in training and deploying large-scale AI models , particularly in multimodal and AGI systems executed on GPUs , lies in the substantial GPU and VRAM requirements . Unlike computer RAM , VRAM often can not be expanded easily on many platforms , posing signiﬁcant constraints . Developing strategies for GPU and VRAM optimization and efﬁcient model scaling is thus crucial for the practical deployment of these AI technologies . • Scalability and Efﬁciency in AI Deployment : Address- ing scalability challenges in generative AI , especially in MoE and AGI contexts , involves optimizing load man- agement and parallel processing techniques . This is vital for their practical application in ﬁelds like healthcare , ﬁnance , and education . 2 ) Real-world Application Examples of Generative AI Tech- nologies : The application of generative AI models in real- world scenarios demonstrates their transformative potential and challenges in various sectors . • Healthcare : In healthcare , generative AI facilitates ad- vancements in diagnostic imaging and personalized medicine , but also raises signiﬁcant concerns regarding data privacy and the potential for misuse of sensitive health information [ 322 ] . • Finance : The use of AI for fraud detection and al- gorithmic trading in ﬁnance underlines its efﬁciency and accuracy , while at the same time , it raises ethical concerns , particularly in automated decision-making pro- cesses , which may lack transparency and accountability [ 323 ] . • Education : Generative AI ’ s role in creating personalized learning experiences offers immense beneﬁts in terms of educational accessibility and tailored instruction . How- ever , it poses challenges in equitable access to technology , potential biases in AI-Generated Content ( AIGC ) , and could reduce demand for human educators . Addition- ally , there ’ s a growing concern about educators who are against the use of AIGC , fearing it may undermine tradi- tional teaching methodologies and the role of educators . B . Commercial Viability and Industry Solutions in Generative AI Technologies 1 ) Market Readiness : Assessing the market readiness of generative AI technologies involves analyzing cost , accessi- bility , deployment challenges , and user adoption trends . • Cost Analysis : The ﬁnancial aspects of deploying gen- erative AI , including MoE , multimodality , and AGI , are crucial for market adoption . • Accessibility and Deployment : Integration of these tech- nologies into existing systems and the technical expertise required are key factors inﬂuencing their adoption . • User Adoption Trends : Understanding current adoption patterns provides insights into market acceptance and the role of user trust and perceived beneﬁts . • Sector-Wise Deployment : The diverse applications of generative AI , from digital content creation to process streamlining , also raise questions about originality and intellectual property rights . • Impact on Market Dynamics : The effect of AI solutions on traditional industry structures and the introduction of novel business models are signiﬁcant considerations . • Challenges and Constraints : Addressing limitations such as scalability , data management complexity , privacy concerns , and ethical implications is essential for robust governance frameworks . C. Limitations and Future Directions in Generative AI Tech- nologies 1 ) Technical Limitations : Identifying and addressing tech- nical limitations in generative AI models is crucial for their advancement and reliability . • Contextual Understanding : Enhancing AI ’ s ability to understand and interpret context , especially in natural language processing and image recognition , is a key area for improvement . • Handling Ambiguous Data : Developing better algo- rithms for processing ambiguous or incomplete data sets is essential for decision-making accuracy and reliability . • Navigating Human Judgment : Despite generative AI ’ s accuracy in interpreting policies and procedures , its im- pact is limited in replacing human judgment . This is especially true in legal and political contexts where decision-makers might selectively use AIGC , leading to biased outcomes . Thus , the effectiveness of generative AI in such scenarios should be realistically assessed . 2 ) Future Research Directions to Enhance the Practicality of Generative AI : Future research in generative AI should focus on addressing current limitations and expanding its practical applications . • Improved Contextual Understanding : Research should aim at developing models with better contextual aware- ness , particularly in complex natural language and image processing tasks . • Robust Handling of Ambiguous Data : Investigating techniques for effective processing of ambiguous data is vital for advancing the decision-making capabilities of AI models . • Ethical Integration of AIGC in Legal and Political Arenas : Future research should focus on the ethical integration of AI-generated content into legal and political decision-making processes , which involves developing frameworks that utilize AIGC in a supportive role , en- suring it enhances human judgment and contributes to transparency and fairness [ 324 ] . Importantly , researchers should consider the biases and limitations inherent in AI [ 324 ] , alongside the potential for human fallibility , ethical complexities , and possible corruption in these domains . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 21 s t n i r p e r P f o r e b m u N 100k 80k 60k 40k 20k 0 physics math stat cs.AI cs 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Year Figure 7 : Annual preprint submissions to different categories on arXiv.org X . IMPACT OF GENERATIVE AI ON PREPRINTS ACROSS DISCIPLINES The challenges detailed in this section are not directly related to the knowledge domains within generative AI , but are fueled by the success of Generative AI , particularly the commercialization of ChatGPT . The proliferation of preprints in the ﬁeld of AI ( Fig . 7 ) , especially in the cs.AI category on platforms like arXiv , has introduced a set of academic challenges that merit careful consideration and strategic re- sponse . The rapid commercialization and adoption of tools such as ChatGPT , as evidenced by over 55,700 entries on Google Scholar mentioning “ ChatGPT ” within just one year of its commercialization , exemplify the accelerated pace at which the ﬁeld is advancing . This rapid development is not mirrored in the traditional peer-review process , which is con- siderably slower . The peer-review process now appears to be overwhelmed with manuscripts that are either generated with ChatGPT ( or other LLMs ) , or whose writing processes have been signiﬁcantly accelerated by such LLMs , contributing to a bottleneck in scholarly communication [ 325 ] , [ 326 ] . This situation is further compounded by the fact that many journals in disciplines outside of computer science are also experiencing longer review times and higher rates of desk re- jections . Additionally , the ﬂourishing trend of manuscripts and preprints , either generated by or signiﬁcantly expedited using tools like ChatGPT , extends beyond computer science into diverse academic disciplines . This trend presents a looming challenge , potentially overwhelming both the traditional peer- review process and the ﬂourishing preprint ecosystem with a volume of work that may not always adhere to established academic standards . The sheer volume of preprints has made the task of se- lecting and scrutinizing research exceedingly demanding . In the current research era , the exploration of scientiﬁc literature has become increasingly complex , as knowledge has continued to expand and disseminate exponentially , while concurrently , integrative research efforts attempting to distill these vast liter- ature , attempt to identify and understand a smaller sets of core contributions [ 327 ] . Thus , the rapid expansion of academic literature across various ﬁelds presents a signiﬁcant challenge for researchers seeking to perform evidence syntheses over the increasingly vast body of available knowledge [ 328 ] . Further- more , this explosion in publication volume poses a distinct challenge for literature reviews and surveys , where the human capacity for manually selecting , understanding , and critically evaluating articles is increasingly strained , potentially leading to gaps in synthesizing comprehensive knowledge landscapes . Although reproduction of results is a theoretical possibility , practical constraints such as the lack of technical expertise , computational resources , or access to proprietary datasets hin- der rigorous evaluation . This is concerning , as the inability to thoroughly assess preprint research undermines the foundation of scientiﬁc reliability and validity . Furthermore , the peer- review system , a cornerstone of academic rigour , is under the threat of being further overwhelmed [ 325 ] , [ 329 ] . The potential consequences are signiﬁcant , with unvetted preprints possibly perpetuating biases or errors within the scientiﬁc community and beyond . The absence of established retraction mechanisms for preprints , akin to those for published articles , exacerbates the risk of persistent dissemination of ﬂawed research . The academic community is at a crossroads , necessitating an urgent and thoughtful discourse on navigating this emerging “ mess ” — a situation that risks spiraling out of control if left unaddressed . In this context , the role of peer review becomes increasingly crucial , as it serves as a critical checkpoint for quality and validity , ensuring that the rapid production of AI research is rigorously studied for scientiﬁc accuracy and relevance . However , the current modus operandi of traditional peer review does not appear to be sustainable , primarily due to its inability to keep pace with the exponential growth in AI-themed research and Generative-AI-accelerated research submissions , and the increasingly specialized nature of emerg- ing AI topics [ 325 ] , [ 326 ] . This situation is compounded by a ﬁnite pool of qualiﬁed reviewers , leading to delays , potential biases , and a burden on the scholarly community . This reality demands an exploration of new paradigms for peer review and dissemination of research that can keep pace with swift advancements in AI . Innovative models for community- driven vetting processes , enhanced reproducibility checks , and dynamic frameworks for post-publication scrutiny and correction may be necessary . Efforts to incorporate automated tools and AI-assisted review processes could also be explored to alleviate the strain on human reviewers . In this rapidly evolving landscape , envision a convergence between the traditional peer review system and the ﬂour- ishing preprint ecosystem , which could involve creating hy- brid models ( Fig . 8 ) , where preprints undergo a preliminary community-based review , harnessing the collective expertise and rapid feedback of the academic community , similar to product review websites and Twitter [ 330 ] . This approach could provide an initial layer of validation , offering addi- tional insights on issues that may be overlooked by a lim- ited number of peer reviewers . The Editors-in-Chief ( EICs ) could consider the major criticisms and suggestions of an article from the community-based review , ensuring a more JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 22 Preprint Submission Rapid Feedback ( Similar to Product Review Sites ) Community- Based Review Initial Validation In-depth Academic Assessment Formal Peer Review Rigor and Quality Assurance Final Publication Figure 8 : Possible Convergence Between Traditional Peer Review and the Preprint Ecosystem thorough and diverse evaluation . Subsequent , more formal peer review processes could then reﬁne and endorse these preprints for academic rigor and quality assurance . This hybrid model would require robust technological support , possibly leveraging AI and machine learning tools to assist in initial screening and identiﬁcation of suitable reviewers . The aim would be to establish a seamless continuum from rapid dis- semination to validated publication , ensuring both the speed of preprints and the credibility of peer-reviewed research . A balanced approach must be struck to harness the beneﬁts of preprints—such as rapid dissemination of ﬁndings and open access—while mitigating their drawbacks . The development of new infrastructure and norms could be instrumental in steering the academic community towards a sustainable model that upholds the integrity and trustworthiness of scientiﬁc research in the age of Generative AI . XI . CONCLUSIONS This roadmap survey has embarked on an exploration of the transformative trends in generative AI research , particularly focusing on speculated advancements like Q * and the pro- gressive strides towards AGI . Our analysis highlights a crucial paradigm shift , driven by innovations such as MoE , multi- modal learning , and the pursuit of AGI . These advancements signal a future where AI systems could signiﬁcantly extend their capabilities in reasoning , contextual understanding , and creative problem-solving . This study reﬂects on AI ’ s dual potential to either contribute to or impede global equity and justice . The equitable distribution of AI beneﬁts and its role in decision-making processes raise crucial questions about fairness and inclusivity . It is imperative to thoughtfully integrate AI into societal structures to enhance justice and reduce disparities . Despite these advancements , several open questions and research gaps remain . These include ensuring the ethical alignment of advanced AI systems with human values and societal norms , a challenge compounded by their increasing autonomy . The safety and robustness of AGI sys- tems in diverse environments also remain a signiﬁcant research gap . Addressing these challenges requires a multidisciplinary approach , incorporating ethical , social , and philosophical per- spectives . Our survey has highlighted key areas for future inter- disciplinary research in AI , emphasizing the integration of ethical , sociological , and technical perspectives . This approach will foster collaborative research , bridging the gap between technological advancement and societal needs , ensuring that AI development is aligned with human values and global welfare . The roles of MoE , multimodal , and AGI in reshaping generative AI have been identiﬁed as signiﬁcant , as their advancements can enhance model performance and versatility , and pave the way for future research in areas like ethical AI alignment and AGI . As we forge ahead , the balance between AI advancements and human creativity is not just a goal but a necessity , ensuring AI ’ s role as a complementary force that ampliﬁes our capacity to innovate and solve complex challenges . Our responsibility is to guide these advancements towards enriching the human experience , aligning technolog- ical progress with ethical standards and societal well-being . DISCLAIMER The authors hereby declare no conﬂict of interest . ABBREVIATIONS Artiﬁcial General Intelligence AGI Artiﬁcial Intelligence AI AI-generated content AIGC Bidirectional Encoder Representations from Transformers BERT California Consumer Privacy Act CCPA Deep Q-Networks DQN European Union EU Generative Adversarial Network GAN General Data Protection Regulation GDPR Generative Pre-trained Transformers GPT Graphics Processing Unit GPU Light Detection and Ranging LIDAR Large Language Model LLM Long Short-Term Memory LSTM Monte Carlo Tree Search MCTS Machine Learning ML Mixture of Experts MoE Natural Language Generation NLG Natural Language Processing NLP Natural Language Understanding NLU Neural Network NN Proximal Policy Optimization PPO Recurrent Neural Networks RNNs Value Neural Network VNN VRAM Video Random Access Memory REFERENCES [ 1 ] A. Turing , “ Computing machinery and intelligence , ” Mind , vol . 59 , no . 236 , p. 433 , 1950 . [ 2 ] D. McDermott , “ Artiﬁcial intelligence meets natural stupidity , ” Acm Sigart Bulletin , no . 57 , pp . 4–9 , 1976 . [ 3 ] M. Minsky , “ Steps toward artiﬁcial intelligence , ” Proceedings of the IRE , vol . 49 , no . 1 , pp . 8–30 , 1961 . [ 4 ] Y. LeCun , Y. Bengio , and G. Hinton , “ Deep learning , ” nature , vol . 521 , no . 7553 , pp . 436–444 , 2015 . [ 5 ] M. Minsky and S. Papert , “ An introduction to computational geometry , ” Cambridge tiass. , HIT , vol . 479 , no . 480 , p. 104 , 1969 . [ 6 ] D. E. Rumelhart , G. E. Hinton , and R. J. Williams , “ Learning repre- sentations by back-propagating errors , ” nature , vol . 323 , no . 6088 , pp . 533–536 , 1986 . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 23 [ 7 ] G.-G. Lee , L. Shi , E. Latif , Y. Gao , A. Bewersdorf , M. Nyaaba , S. Guo , Z. Wu , Z. Liu , H. Wang et al. , “ Multimodality of ai for education : To- wards artiﬁcial general intelligence , ” arXiv preprint arXiv:2312.06037 , 2023 . [ 8 ] P. Maddigan and T. Susnjak , “ Chat2vis : Generating data visualisations via natural language using chatgpt , codex and gpt-3 large language models , ” IEEE Access , 2023 . [ 9 ] T. R. McIntosh , T. Liu , T. Susnjak , P. Watters , A. Ng , and M. N. Halgamuge , “ A culturally sensitive test to evaluate nuanced gpt hallu- cination , ” IEEE Transactions on Artiﬁcial Intelligence , vol . 1 , no . 01 , pp . 1–13 , 2023 . [ 10 ] M. R. Morris , J. Sohl-dickstein , N. Fiedel , T. Warkentin , A. Dafoe , A. Faust , C. Farabet , and S. Legg , “ Levels of agi : Operationalizing progress on the path to agi , ” arXiv preprint arXiv:2311.02462 , 2023 . [ 11 ] J. Schuett , N. Dreksler , M. Anderljung , D. McCaffary , L. Heim , E. Bluemke , and B. Garﬁnkel , “ Towards best practices in agi safety and governance : A survey of expert opinion , ” arXiv preprint arXiv:2305.07153 , 2023 . [ 12 ] X. Shuai , J. Rollins , I. Moulinier , T. Custis , M. Edmunds , and F. Schilder , “ A multidimensional investigation of the effects of pub- lication retraction on scholarly impact , ” Journal of the Association for Information Science and Technology , vol . 68 , no . 9 , pp . 2225–2236 , 2017 . [ 13 ] A. Vaswani , N. Shazeer , N. Parmar , J. Uszkoreit , L. Jones , A. N. Gomez , Ł. Kaiser , and I. Polosukhin , “ Attention is all you need , ” Advances in neural information processing systems , vol . 30 , 2017 . [ 14 ] A. Radford , K. Narasimhan , T. Salimans , I. Sutskever et al. , “ Improving language understanding by generative pre-training , ” 2018 . [ 15 ] C. Huang , Z. Zhang , B. Mao , and X. Yao , “ An overview of artiﬁcial intelligence ethics , ” IEEE Transactions on Artiﬁcial Intelligence , 2022 . [ 16 ] L. Besanc¸on , N. Peiffer-Smadja , C. Segalas , H. Jiang , P. Masuzzo , C. Smout , E. Billy , M. Deforet , and C. Leyrat , “ Open science saves lives : lessons from the covid-19 pandemic , ” BMC Medical Research Methodology , vol . 21 , no . 1 , pp . 1–18 , 2021 . [ 17 ] C. R. Triggle , R. MacDonald , D. J. Triggle , and D. Grierson , “ Requiem for impact factors and high publication charges , ” Accountability in Research , vol . 29 , no . 3 , pp . 133–164 , 2022 . [ 18 ] T. McIntosh , A. Kayes , Y.-P. P. Chen , A. Ng , and P. Watters , “ Ran- somware mitigation in the modern era : A comprehensive review , research challenges , and future directions , ” ACM Computing Surveys ( CSUR ) , vol . 54 , no . 9 , pp . 1–36 , 2021 . [ 19 ] T. McIntosh , T. Liu , T. Susnjak , H. Alavizadeh , A. Ng , R. Nowrozy , and P. Watters , “ Harnessing gpt-4 for generation of cybersecurity grc policies : A focus on ransomware attack mitigation , ” Computers & Security , vol . 134 , p. 103424 , 2023 . [ 20 ] H. Bao , W. Wang , L. Dong , Q. Liu , O. K. Mohammed , K. Aggarwal , S. Som , S. Piao , and F. Wei , “ Vlmo : Uniﬁed vision-language pre- training with mixture-of-modality-experts , ” Advances in Neural Infor- mation Processing Systems , vol . 35 , pp . 32 897–32 912 , 2022 . [ 21 ] N. Du , Y. Huang , A. M. Dai , S. Tong , D. Lepikhin , Y. Xu , M. Krikun , Y. Zhou , A. W. Yu , O. Firat et al. , “ Glam : Efﬁcient scaling of language models with mixture-of-experts , ” in International Conference on Machine Learning . PMLR , 2022 , pp . 5547–5569 . [ 22 ] S. Masoudnia and R. Ebrahimpour , “ Mixture of experts : a literature survey , ” Artiﬁcial Intelligence Review , vol . 42 , pp . 275–293 , 2014 . [ 23 ] C. Riquelme , J. Puigcerver , B. Mustafa , M. Neumann , R. Jenatton , A. Susano Pinto , D. Keysers , and N. Houlsby , “ Scaling vision with sparse mixture of experts , ” Advances in Neural Information Processing Systems , vol . 34 , pp . 8583–8595 , 2021 . [ 24 ] S. E. Yuksel , J. N. Wilson , and P. D. Gader , “ Twenty years of mixture of experts , ” IEEE transactions on neural networks and learning systems , vol . 23 , no . 8 , pp . 1177–1193 , 2012 . [ 25 ] L. Zhang , S. Huang , W. Liu , and D. Tao , “ Learning a mixture of granularity-speciﬁc experts for ﬁne-grained categorization , ” in Proceed- ings of the IEEE/CVF International Conference on Computer Vision , 2019 , pp . 8331–8340 . [ 26 ] D. Martin , S. Malpica , D. Gutierrez , B. Masia , and A. Serrano , “ Multimodality in vr : A survey , ” ACM Computing Surveys ( CSUR ) , vol . 54 , no . 10s , pp . 1–36 , 2022 . [ 27 ] Q . Sun , Q. Yu , Y. Cui , F. Zhang , X. Zhang , Y. Wang , H. Gao , J. Liu , T. Huang , and X. Wang , “ Generative pretraining in multimodality , ” arXiv preprint arXiv:2307.05222 , 2023 . [ 28 ] L. Wei , L. Xie , W. Zhou , H. Li , and Q. Tian , “ Mvp : Multimodality- guided visual pre-training , ” in European Conference on Computer Vision . Springer , 2022 , pp . 337–353 . [ 29 ] J. Wu , W. Zhou , X. Qian , J. Lei , L. Yu , and T. Luo , “ Menet : Lightweight multimodality enhancement network for detecting salient objects in rgb-thermal images , ” Neurocomputing , vol . 527 , pp . 119– 129 , 2023 . [ 30 ] Q. Ye , H. Xu , G. Xu , J. Ye , M. Yan , Y. Zhou , J. Wang , A. Hu , P. Shi , Y. Shi et al. , “ mplug-owl : Modularization empowers large language models with multimodality , ” arXiv preprint arXiv:2304.14178 , 2023 . [ 31 ] K. LaGrandeur , “ How safe is our reliance on ai , and should we regulate it ? ” AI and Ethics , vol . 1 , pp . 93–99 , 2021 . [ 32 ] S. McLean , G. J . Read , J. Thompson , C. Baber , N. A. Stanton , and P. M. Salmon , “ The risks associated with artiﬁcial general intelligence : A systematic review , ” Journal of Experimental & Theoretical Artiﬁcial Intelligence , vol . 35 , no . 5 , pp . 649–663 , 2023 . [ 33 ] Y. K. Dwivedi , L. Hughes , E. Ismagilova , G. Aarts , C. Coombs , T. Crick , Y. Duan , R. Dwivedi , J. Edwards , A. Eirug , V. Galanos , P. V. Ilavarasan , M. Janssen , P. Jones , A. K. Kar , H. Kizgin , B. Kro- nemann , B. Lal , B. Lucini , R. Medaglia , K. Le Meunier-FitzHugh , L. C. Le Meunier-FitzHugh , S. Misra , E. Mogaji , S. K. Sharma , J . B. Singh , V. Raghavan , R. Raman , N. P. Rana , S. Samothrakis , J. Spencer , K. Tamilmani , A. Tubadji , P. Walton , and M. D. Williams , “ Artiﬁcial intelligence ( ai ) : Multidisciplinary perspectives on emerging challenges , opportunities , and agenda for research , practice and policy , ” International Journal of Information Management , vol . 57 , p. 101994 , 2021 . [ 34 ] I. Gabriel , “ Artiﬁcial intelligence , values , and alignment , ” Minds and Machines , vol . 30 , pp . 411–437 , 2020 . [ 35 ] A. Shaban-Nejad , M. Michalowski , S. Bianco , J. S. Brownstein , D. L. Buckeridge , and R. L. Davis , “ Applied artiﬁcial intelligence in healthcare : Listening to the winds of change in a post-covid-19 world , ” pp . 1969–1971 , 2022 . [ 36 ] Z. Ji , N. Lee , R. Frieske , T. Yu , D. Su , Y. Xu , E. Ishii , Y. J . Bang , A. Madotto , and P. Fung , “ Survey of hallucination in natural language generation , ” ACM Computing Surveys , vol . 55 , no . 12 , pp . 1–38 , 2023 . [ 37 ] B. Min , H. Ross , E. Sulem , A. P. B. Veyseh , T. H. Nguyen , O. Sainz , E. Agirre , I. Heintz , and D. Roth , “ Recent advances in natural language processing via large pre-trained language models : A survey , ” ACM Computing Surveys , vol . 56 , no . 2 , pp . 1–40 , 2023 . [ 38 ] J. Li , X. Cheng , W. X. Zhao , J.-Y . Nie , and J.-R. Wen , “ Halueval : A large-scale hallucination evaluation benchmark for large language models , ” in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , 2023 , pp . 6449–6464 . [ 39 ] L. Weidinger , J. Mellor , M. Rauh , C. Grifﬁn , J. Uesato , P.-S. Huang , M. Cheng , M. Glaese , B. Balle , A. Kasirzadeh et al. , “ Ethical and social risks of harm from language models , ” arXiv preprint arXiv:2112.04359 , 2021 . [ 40 ] X. Zhiheng , Z. Rui , and G. Tao , “ Safety and ethical concerns of large language models , ” in Proceedings of the 22nd Chinese National Con- ference on Computational Linguistics ( Volume 4 : Tutorial Abstracts ) , 2023 , pp . 9–16 . [ 41 ] P. F. Brown , V. J. Della Pietra , P. V. Desouza , J. C. Lai , and R. L. Mer- cer , “ Class-based n-gram models of natural language , ” Computational linguistics , vol . 18 , no . 4 , pp . 467–480 , 1992 . [ 42 ] S. Katz , “ Estimation of probabilities from sparse data for the language model component of a speech recognizer , ” IEEE transactions on acoustics , speech , and signal processing , vol . 35 , no . 3 , pp . 400–401 , 1987 . [ 43 ] R. Kneser and H. Ney , “ Improved backing-off for m-gram language modeling , ” in 1995 international conference on acoustics , speech , and signal processing , vol . 1 . IEEE , 1995 , pp . 181–184 . [ 44 ] R. Kuhn and R. De Mori , “ A cache-based natural language model for speech recognition , ” IEEE transactions on pattern analysis and machine intelligence , vol . 12 , no . 6 , pp . 570–583 , 1990 . [ 45 ] H. Ney , U. Essen , and R. Kneser , “ On structuring probabilistic de- pendences in stochastic language modelling , ” Computer Speech & Language , vol . 8 , no . 1 , pp . 1–38 , 1994 . [ 46 ] S. Hochreiter and J. Schmidhuber , “ Long short-term memory , ” Neural computation , vol . 9 , no . 8 , pp . 1735–1780 , 1997 . [ 47 ] M. K. Nammous and K. Saeed , “ Natural language processing : speaker , language , and gender identiﬁcation with lstm , ” Advanced Computing and Systems for Security : Volume Eight , pp . 143–156 , 2019 . [ 48 ] D. Wei , B. Wang , G. Lin , D. Liu , Z. Dong , H. Liu , and Y. Liu , “ Re- search on unstructured text data mining and fault classiﬁcation based on rnn-lstm with malfunction inspection report , ” Energies , vol . 10 , no . 3 , p. 406 , 2017 . [ 49 ] L. Yao and Y. Guan , “ An improved lstm structure for natural language processing , ” in 2018 IEEE International Conference of Safety Produce Informatization ( IICSPI ) . IEEE , 2018 , pp . 565–569 . [ 50 ] L. Ouyang , J. Wu , X. Jiang , D. Almeida , C. Wainwright , P. Mishkin , C. Zhang , S. Agarwal , K. Slama , A. Ray et al. , “ Training language JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 24 models to follow instructions with human feedback , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 27 730–27 744 , 2022 . [ 51 ] T. Susnjak , “ Beyond predictive learning analytics modelling and onto explainable artiﬁcial intelligence with prescriptive analytics and chat- gpt , ” International Journal of Artiﬁcial Intelligence in Education , pp . 1–31 , 2023 . [ 52 ] T. Susnjak , E. Grifﬁn , M. McCutcheon , and K. Potter , “ Towards clinical prediction with transparency : An explainable ai approach to survival modelling in residential aged care , ” arXiv preprint arXiv:2312.00271 , 2023 . [ 53 ] R. Yang , T. F. Tan , W. Lu , A. J. Thirunavukarasu , D. S. W. Ting , and N. Liu , “ Large language models in health care : Development , applications , and challenges , ” Health Care Science , vol . 2 , no . 4 , pp . 255–263 , 2023 . [ 54 ] D. Baidoo-Anu and L. O. Ansah , “ Education in the era of generative artiﬁcial intelligence ( ai ) : Understanding the potential beneﬁts of chat- gpt in promoting teaching and learning , ” Journal of AI , vol . 7 , no . 1 , pp . 52–62 , 2023 . [ 55 ] T. Susnjak , “ Chatgpt : The end of online exam integrity ? ” arXiv preprint arXiv:2212.09292 , 2022 . [ 56 ] A. Tlili , B. Shehata , M. A. Adarkwah , A. Bozkurt , D. T. Hickey , R. Huang , and B. Agyemang , “ What if the devil is my guardian angel : Chatgpt as a case study of using chatbots in education , ” Smart Learning Environments , vol . 10 , no . 1 , p. 15 , 2023 . [ 57 ] M. A. AlAfnan , S. Dishari , M. Jovic , and K. Lomidze , “ Chatgpt as an educational tool : Opportunities , challenges , and recommendations for communication , business writing , and composition courses , ” Journal of Artiﬁcial Intelligence and Technology , vol . 3 , no . 2 , pp . 60–68 , 2023 . [ 58 ] A. S. George and A. H. George , “ A review of chatgpt ai ’ s impact on several business sectors , ” Partners Universal International Innovation Journal , vol . 1 , no . 1 , pp . 9–23 , 2023 . [ 59 ] G. K. Hadﬁeld and J. Clark , “ Regulatory markets : The future of ai governance , ” arXiv preprint arXiv:2304.04914 , 2023 . [ 60 ] M. Bakker , M. Chadwick , H. Sheahan , M. Tessler , L. Campbell- Gillingham , J. Balaguer , N. McAleese , A. Glaese , J. Aslanides , M. Botvinick et al. , “ Fine-tuning language models to ﬁnd agreement among humans with diverse preferences , ” Advances in Neural Infor- mation Processing Systems , vol . 35 , pp . 38 176–38 189 , 2022 . [ 61 ] Z. Hu , Y. Lan , L. Wang , W. Xu , E.-P. Lim , R. K.-W. Lee , L. Bing , and S. Poria , “ Llm-adapters : An adapter family for parameter-efﬁcient ﬁne- tuning of large language models , ” arXiv preprint arXiv:2304.01933 , 2023 . [ 62 ] H. Liu , D. Tam , M. Muqeeth , J. Mohta , T. Huang , M. Bansal , and C. A. Raffel , “ Few-shot parameter-efﬁcient ﬁne-tuning is better and cheaper than in-context learning , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 1950–1965 , 2022 . [ 63 ] H. Zheng , L. Shen , A. Tang , Y. Luo , H. Hu , B . Du , and D. Tao , “ Learn from model beyond ﬁne-tuning : A survey , ” arXiv preprint arXiv:2310.08184 , 2023 . [ 64 ] P. Manakul , A. Liusie , and M. J. Gales , “ Selfcheckgpt : Zero-resource black-box hallucination detection for generative large language mod- els , ” arXiv preprint arXiv:2303.08896 , 2023 . [ 65 ] A. Martino , M. Iannelli , and C. Truong , “ Knowledge injection to counter large language model ( llm ) hallucination , ” in European Se- mantic Web Conference . Springer , 2023 , pp . 182–185 . [ 66 ] J.-Y . Yao , K.-P. Ning , Z.-H. Liu , M.-N. Ning , and L. Yuan , “ Llm lies : Hallucinations are not bugs , but features as adversarial examples , ” arXiv preprint arXiv:2310.01469 , 2023 . [ 67 ] Y. Zhang , Y. Li , L. Cui , D. Cai , L. Liu , T. Fu , X. Huang , E. Zhao , Y. Zhang , Y. Chen et al. , “ Siren ’ s song in the ai ocean : A survey on hal- lucination in large language models , ” arXiv preprint arXiv:2309.01219 , 2023 . [ 68 ] J. Ji , M. Liu , J. Dai , X. Pan , C. Zhang , C. Bian , R. Sun , Y. Wang , and Y. Yang , “ Beavertails : Towards improved safety alignment of llm via a human-preference dataset , ” arXiv preprint arXiv:2307.04657 , 2023 . [ 69 ] Y. Liu , Y. Yao , J.-F . Ton , X. Zhang , R. G. H. Cheng , Y. Klochkov , M. F. Tauﬁq , and H. Li , “ Trustworthy llms : a survey and guideline for evaluating large language models ’ alignment , ” arXiv preprint arXiv:2308.05374 , 2023 . [ 70 ] Y. Wang , W. Zhong , L. Li , F. Mi , X. Zeng , W. Huang , L. Shang , X. Jiang , and Q. Liu , “ Aligning large language models with human : A survey , ” arXiv preprint arXiv:2307.12966 , 2023 . [ 71 ] Z . Sun , Y. Shen , Q. Zhou , H. Zhang , Z. Chen , D. Cox , Y. Yang , and C. Gan , “ Principle-driven self-alignment of language mod- els from scratch with minimal human supervision , ” arXiv preprint arXiv:2305.03047 , 2023 . [ 72 ] Y. Wolf , N. Wies , Y. Levine , and A. Shashua , “ Fundamental lim- in large language models , ” arXiv preprint itations of alignment arXiv:2304.11082 , 2023 . [ 73 ] H. Dang , L. Mecke , F. Lehmann , S. Goller , and D. Buschek , “ How to prompt ? opportunities and challenges of zero-and few-shot learning for human-ai interaction in creative applications of generative models , ” arXiv preprint arXiv:2209.01390 , 2022 . [ 74 ] R. Ma , X. Zhou , T. Gui , Y. Tan , L. Li , Q. Zhang , and X. Huang , few-shot ner , ” arXiv preprint tuning for “ Template-free prompt arXiv:2109.13532 , 2021 . [ 75 ] C. Qin and S. Joty , “ Lfpt5 : A uniﬁed framework for lifelong few- shot language learning based on prompt tuning of t5 , ” arXiv preprint arXiv:2110.07298 , 2021 . [ 76 ] S. Wang , L. Tang , A. Majety , J. F. Rousseau , G. Shih , Y. Ding , and Y. Peng , “ Trustworthy assertion classiﬁcation through prompting , ” Journal of biomedical informatics , vol . 132 , p. 104139 , 2022 . [ 77 ] Y . Fan , F. Jiang , P. Li , and H. Li , “ Grammargpt : Exploring open-source llms for native chinese grammatical error correction with supervised ﬁne-tuning , ” in CCF International Conference on Natural Language Processing and Chinese Computing . Springer , 2023 , pp . 69–80 . [ 78 ] D. Liga and L. Robaldo , “ Fine-tuning gpt-3 for legal rule classiﬁca- tion , ” Computer Law & Security Review , vol . 51 , p. 105864 , 2023 . [ 79 ] Y. Liu , A. Singh , C. D. Freeman , J. D. Co-Reyes , and P. J. Liu , “ Im- proving large language model ﬁne-tuning for solving math problems , ” arXiv preprint arXiv:2310.10047 , 2023 . [ 80 ] Z. Talat , A. N´ev´eol , S. Biderman , M. Clinciu , M. Dey , S. Longpre , S. Luccioni , M. Masoud , M. Mitchell , D. Radev et al. , “ You reap what you sow : On the challenges of bias evaluation under multilingual settings , ” in Proceedings of BigScience Episode # 5–Workshop on Challenges & Perspectives in Creating Large Language Models , 2022 , pp . 26–41 . [ 81 ] Y. Liu , S. Yu , and T. Lin , “ Hessian regularization of deep neural networks : A novel approach based on stochastic estimators of hessian trace , ” Neurocomputing , vol . 536 , pp . 13–20 , 2023 . [ 82 ] Y. Lu , Y. Bo , and W. He , “ Conﬁdence adaptive regularization for deep learning with noisy labels , ” arXiv preprint arXiv:2108.08212 , 2021 . [ 83 ] G. Pereyra , G. Tucker , J. Chorowski , Ł. Kaiser , and G. Hinton , “ Regu- larizing neural networks by penalizing conﬁdent output distributions , ” arXiv preprint arXiv:1701.06548 , 2017 . [ 84 ] E. Chen , Z.-W. Hong , J. Pajarinen , and P. Agrawal , “ Redeeming intrinsic rewards via constrained optimization , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 4996–5008 , 2022 . [ 85 ] Y. Jiang , Z. Li , M. Tan , S. Wei , G. Zhang , Z. Guan , and B. Han , “ A stable block adjustment method without ground control points using bound constrained optimization , ” International Journal of Remote Sensing , vol . 43 , no . 12 , pp . 4708–4722 , 2022 . [ 86 ] M. Kachuee and S. Lee , “ Constrained policy optimization for con- trolled self-learning in conversational ai systems , ” arXiv preprint arXiv:2209.08429 , 2022 . [ 87 ] Z . Song , H. Wang , and Y. Jin , “ A surrogate-assisted evolutionary framework with regions of interests-based data selection for expensive constrained optimization , ” IEEE Transactions on Systems , Man , and Cybernetics : Systems , 2023 . [ 88 ] J. Yu , T. Xu , Y. Rong , J. Huang , and R. He , “ Structure-aware condi- tional variational auto-encoder for constrained molecule optimization , ” Pattern Recognition , vol . 126 , p. 108581 , 2022 . [ 89 ] P. Butlin , “ Ai alignment and human reward , ” in Proceedings of the 2021 AAAI/ACM Conference on AI , Ethics , and Society , 2021 , pp . 437–445 . [ 90 ] F. Faal , K. Schmitt , and J. Y. Yu , “ Reward modeling for mitigating toxicity in transformer-based language models , ” Applied Intelligence , vol . 53 , no . 7 , pp . 8421–8435 , 2023 . [ 91 ] J. Leike , D. Krueger , T. Everitt , M. Martic , V. Maini , and S. Legg , “ Scalable agent alignment via reward modeling : a research direction , ” arXiv preprint arXiv:1811.07871 , 2018 . [ 92 ] L. Li , Y. Chai , S. Wang , Y . Sun , H. Tian , N. Zhang , and H. Wu , “ Tool- augmented reward modeling , ” arXiv preprint arXiv:2310.01045 , 2023 . [ 93 ] F. Barreto , L. Moharkar , M. Shirodkar , V. Sarode , S. Gonsalves , and A. Johns , “ Generative artiﬁcial intelligence : Opportunities and challenges of large language models , ” in International Conference on Intelligent Computing and Networking . Springer , 2023 , pp . 545–553 . [ 94 ] Z. Chen , Z. Wang , Z. Wang , H. Liu , Z. Yin , S. Liu , L. Sheng , W. Ouyang , Y. Qiao , and J. Shao , “ Octavius : Mitigating task inter- ference in mllms via moe , ” arXiv preprint arXiv:2311.02684 , 2023 . [ 95 ] C. Dun , M. D. C. H. Garcia , G. Zheng , A. H. Awadallah , A. Kyrillidis , and R. Sim , “ Sweeping heterogeneity with smart mops : Mixture of prompts for llm task adaptation , ” arXiv preprint arXiv:2310.02842 , 2023 . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 25 [ 96 ] H. Naveed , A. U. Khan , S. Qiu , M. Saqib , S. Anwar , M. Usman , N. Barnes , and A. Mian , “ A comprehensive overview of large language models , ” arXiv preprint arXiv:2307.06435 , 2023 . [ 97 ] F. Xue , Y. Fu , W. Zhou , Z. Zheng , and Y . You , “ To repeat or not to repeat : Insights from scaling llm under token-crisis , ” arXiv preprint arXiv:2305.13230 , 2023 . [ 98 ] M. Nowaz Rabbani Chowdhury , S. Zhang , M. Wang , S. Liu , and P.-Y . Chen , “ Patch-level routing in mixture-of-experts is provably sample- efﬁcient for convolutional neural networks , ” arXiv e-prints , pp . arXiv– 2306 , 2023 . [ 99 ] J. Peng , K. Zhou , R. Zhou , T. Hartvigsen , Y. Zhang , Z. Wang , and T. Chen , “ Sparse moe as a new treatment : Addressing forgetting , ﬁtting , learning issues in multi-modal multi-task learning , ” in Conference on Parsimony and Learning ( Recent Spotlight Track ) , 2023 . [ 100 ] C. N. d. Santos , J. Lee-Thorp , I. Noble , C.-C. Chang , and D. Uthus , “ Memory augmented language models through mixture of word ex- perts , ” arXiv preprint arXiv:2311.10768 , 2023 . [ 101 ] W. Wang , G. Ma , Y. Li , and B . Du , “ Language-routing mixture of experts for multilingual and code-switching speech recognition , ” arXiv preprint arXiv:2307.05956 , 2023 . [ 102 ] X. Zhao , X. Chen , Y. Cheng , and T. Chen , “ Sparse moe with language guided routing for multilingual machine translation , ” in Conference on Parsimony and Learning ( Recent Spotlight Track ) , 2023 . [ 103 ] W. Huang , H. Zhang , P. Peng , and H. Wang , “ Multi-gate mixture- of-expert combined with synthetic minority over-sampling technique for multimode imbalanced fault diagnosis , ” in 2023 26th International Conference on Computer Supported Cooperative Work in Design ( CSCWD ) . IEEE , 2023 , pp . 456–461 . [ 104 ] B. Liu , L. Ding , L. Shen , K. Peng , Y. Cao , D. Cheng , and D. Tao , “ Diversifying the mixture-of-experts representation for language mod- els with orthogonal optimizer , ” arXiv preprint arXiv:2310.09762 , 2023 . [ 105 ] W. Wang , Z. Lai , S. Li , W. Liu , K. Ge , Y. Liu , A. Shen , and D. Li , “ Prophet : Fine-grained load balancing for parallel training of large- scale moe models , ” in 2023 IEEE International Conference on Cluster Computing ( CLUSTER ) . IEEE , 2023 , pp . 82–94 . [ 106 ] X. Yao , S. Liang , S. Han , and H. Huang , “ Enhancing molecular property prediction via mixture of collaborative experts , ” arXiv preprint arXiv:2312.03292 , 2023 . [ 107 ] Z. Xiao , Y. Jiang , G. Tang , L. Liu , S. Xu , Y. Xiao , and W. Yan , “ Ad- versarial mixture of experts with category hierarchy soft constraint , ” in 2021 IEEE 37th International Conference on Data Engineering ( ICDE ) . IEEE , 2021 , pp . 2453–2463 . [ 108 ] M. Agbese , R. Mohanani , A. Khan , and P. Abrahamsson , “ Implement- ing ai ethics : Making sense of the ethical requirements , ” in Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering , 2023 , pp . 62–71 . [ 109 ] Z. Chen , Y. Deng , Y. Wu , Q. Gu , and Y. Li , “ Towards understanding the mixture-of-experts layer in deep learning , ” Advances in neural information processing systems , vol . 35 , pp . 23 049–23 062 , 2022 . [ 110 ] Y. Zhou , T. Lei , H. Liu , N. Du , Y. Huang , V. Zhao , A. M. Dai , Q. V. Le , J. Laudon et al. , “ Mixture-of-experts with expert choice routing , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 7103– 7114 , 2022 . [ 111 ] N. Guha , C. Lawrence , L. A. Gailmard , K. Rodolfa , F. Surani , R. Bommasani , I. Raji , M.-F. Cu´ellar , C. Honigsberg , P. Liang et al. , “ Ai regulation has its own alignment problem : The technical and insti- tutional feasibility of disclosure , registration , licensing , and auditing , ” George Washington Law Review , Forthcoming , 2023 . Team , [ 112 ] Gemini of accessed : https : 1 report.pdf family 2023 , Available : multimodal 2023 . December “ Gemini : [ Online ] . models , ” Google , capable highly 17 A [ 113 ] J. N. Acosta , G. J. Falcone , P. Rajpurkar , and E. J. Topol , “ Multimodal biomedical ai , ” Nature Medicine , vol . 28 , no . 9 , pp . 1773–1784 , 2022 . [ 114 ] S. Qi , Z. Cao , J. Rao , L. Wang , J. Xiao , and X. Wang , “ What is the limitation of multimodal llms ? a deeper look into multimodal llms through prompt probing , ” Information Processing & Management , vol . 60 , no . 6 , p. 103510 , 2023 . [ 115 ] B. Xu , D. Kocyigit , R. Grimm , B. P. Grifﬁn , and F. Cheng , “ Applica- tions of artiﬁcial intelligence in multimodality cardiovascular imaging : a state-of-the-art review , ” Progress in cardiovascular diseases , vol . 63 , no . 3 , pp . 367–376 , 2020 . [ 116 ] A. Birhane , V. U. Prabhu , and E. Kahembwe , “ Multimodal datasets : misogyny , pornography , and malignant stereotypes , ” arXiv preprint arXiv:2110.01963 , 2021 . [ 117 ] Y. Li , W. Li , N. Li , X. Qiu , and K. B. Manokaran , “ Multimodal infor- mation interaction and fusion for the parallel computing system using ai techniques , ” International Journal of High Performance Systems Architecture , vol . 10 , no . 3-4 , pp . 185–196 , 2021 . [ 118 ] C. Zhang , Z. Yang , X . He , and L. Deng , “ Multimodal intelligence : Representation learning , information fusion , and applications , ” IEEE Journal of Selected Topics in Signal Processing , vol . 14 , no . 3 , pp . 478–493 , 2020 . [ 119 ] H. Qiao , V. Liu , and L. Chilton , “ Initial images : using image prompts to improve subject representation in multimodal ai generated art , ” in Proceedings of the 14th Conference on Creativity and Cognition , 2022 , pp . 15–28 . [ 120 ] A. E. Stewart , Z. Keirn , and S. K. D ’ Mello , “ Multimodal modeling of collaborative problem-solving facets in triads , ” User Modeling and User-Adapted Interaction , pp . 1–39 , 2021 . [ 121 ] L. Xue , N. Yu , S. Zhang , J. Li , R. Mart´ın-Mart´ın , J. Wu , C. Xiong , R. Xu , J. C. Niebles , and S. Savarese , “ Ulip-2 : Towards scal- able multimodal pre-training for 3d understanding , ” arXiv preprint arXiv:2305.08275 , 2023 . [ 122 ] L. Yan , L. Zhao , D. Gasevic , and R. Martinez-Maldonado , “ Scalability , sustainability , and ethicality of multimodal learning analytics , ” in LAK22 : 12th international learning analytics and knowledge confer- ence , 2022 , pp . 13–23 . [ 123 ] Y. Liu-Thompkins , S. Okazaki , and H. Li , “ Artiﬁcial empathy in marketing interactions : Bridging the human-ai gap in affective and social customer experience , ” Journal of the Academy of Marketing Science , vol . 50 , no . 6 , pp . 1198–1218 , 2022 . [ 124 ] M. S. Rahman , S. Bag , M. A. Hossain , F. A. M. A. Fattah , M. O. Gani , and N. P. Rana , “ The new wave of ai-powered luxury brands online shopping experience : The role of digital multisensory cues and customers ’ engagement , ” Journal of Retailing and Consumer Services , vol . 72 , p. 103273 , 2023 . [ 125 ] E. Sachdeva , N. Agarwal , S. Chundi , S. Roelofs , J. Li , B. Dariush , C. Choi , and M. Kochenderfer , “ Rank2tell : A multimodal driving dataset for joint importance ranking and reasoning , ” arXiv preprint arXiv:2309.06597 , 2023 . [ 126 ] C. Cui , Y. Ma , X. Cao , W. Ye , Y. Zhou , K. Liang , J. Chen , J. Lu , Z. Yang , K.-D. Liao et al. , “ A survey on multimodal large language models for autonomous driving , ” arXiv preprint arXiv:2311.12320 , 2023 . [ 127 ] A . B. Temsamani , A. K. Chavali , W. Vervoort , T. Tuytelaars , G. Rade- vski , H. Van Hamme , K. Mets , M. Hutsebaut-Buysse , T. De Schepper , and S. Latr´e , “ A multimodal ai approach for intuitively instructable autonomous systems : a case study of an autonomous off-highway vehicle , ” in The Eighteenth International Conference on Autonomic and Autonomous Systems , ICAS 2022 , May 22-26 , 2022 , Venice , Italy , 2022 , pp . 31–39 . [ 128 ] J. Lee and S. Y. Shin , “ Something that they never said : Multimodal disinformation and source vividness in understanding the power of ai- enabled deepfake news , ” Media Psychology , vol . 25 , no . 4 , pp . 531– 546 , 2022 . [ 129 ] S. Muppalla , S. Jia , and S. Lyu , “ Integrating audio-visual features for multimodal deepfake detection , ” arXiv preprint arXiv:2310.03827 , 2023 . [ 130 ] S. Kumar , M. K. Chaube , S. N. Nenavath , S. K. Gupta , and S. K. Tetarave , “ Privacy preservation and security challenges : a new frontier multimodal machine learning research , ” International Journal of Sensor Networks , vol . 39 , no . 4 , pp . 227–245 , 2022 . [ 131 ] J. Marchang and A . Di Nuovo , “ Assistive multimodal robotic system ( amrsys ) : security and privacy issues , challenges , and possible solu- tions , ” Applied Sciences , vol . 12 , no . 4 , p. 2174 , 2022 . [ 132 ] A. Pe˜na , I. Serna , A. Morales , J. Fierrez , A. Ortega , A. Herrarte , M. Al- cantara , and J. Ortega-Garcia , “ Human-centric multimodal machine learning : Recent advances and testbed on ai-based recruitment , ” SN Computer Science , vol . 4 , no . 5 , p. 434 , 2023 . [ 133 ] R. Wolfe and A. Caliskan , “ American== white in multimodal language- and-image ai , ” in Proceedings of the 2022 AAAI/ACM Conference on AI , Ethics , and Society , 2022 , pp . 800–812 . [ 134 ] R. Wolfe , Y. Yang , B. Howe , and A. Caliskan , “ Contrastive language- vision ai models pretrained on web-scraped multimodal data exhibit sexual objectiﬁcation bias , ” in Proceedings of the 2023 ACM Confer- ence on Fairness , Accountability , and Transparency , 2023 , pp . 1174– 1185 . [ 135 ] M. Afshar , B. Sharma , D. Dligach , M. Oguss , R. Brown , N. Chhabra , H. M. Thompson , T. Markossian , C. Joyce , M. M. Churpek et al. , “ Development and multimodal validation of a substance misuse algo- rithm for referral to treatment using artiﬁcial intelligence ( smart-ai ) : a retrospective deep learning study , ” The Lancet Digital Health , vol . 4 , no . 6 , pp . e426–e435 , 2022 . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 26 [ 136 ] H. Alwahaby , M. Cukurova , Z. Papamitsiou , and M. Giannakos , “ The evidence of impact and ethical considerations of multimodal learning analytics : A systematic literature review , ” The Multimodal Learning Analytics Handbook , pp . 289–325 , 2022 . [ 137 ] Q. Miao , W. Zheng , Y. Lv , M. Huang , W. Ding , and F.-Y . Wang , “ Dao to hanoi via desci : Ai paradigm shifts from alphago to chatgpt , ” IEEE/CAA Journal of Automatica Sinica , vol . 10 , no . 4 , pp . 877–897 , 2023 . [ 138 ] Y. Rong , “ Roadmap of alphago to alphastar : Problems and challenges , ” in 2nd International Conference on Artiﬁcial Intelligence , Automation , and High-Performance Computing ( AIAHPC 2022 ) , vol . 12348 . SPIE , 2022 , pp . 904–914 . [ 139 ] Y. Gao , M. Zhou , D. Liu , Z. Yan , S. Zhang , and D. N. Metaxas , “ A data-scalable transformer for medical image segmentation : architecture , model efﬁciency , and benchmark , ” arXiv preprint arXiv:2203.00131 , 2022 . [ 140 ] W. Peebles and S. Xie , “ Scalable diffusion models with transformers , ” in Proceedings of the IEEE/CVF International Conference on Com- puter Vision , 2023 , pp . 4195–4205 . [ 141 ] R. Pope , S. Douglas , A. Chowdhery , J. Devlin , J. Bradbury , J. Heek , K. Xiao , S. Agrawal , and J . Dean , “ Efﬁciently scaling transformer inference , ” Proceedings of Machine Learning and Systems , vol . 5 , 2023 . [ 142 ] Y. Ding and M. Jia , “ Convolutional transformer : An enhanced atten- tion mechanism architecture for remaining useful life estimation of bearings , ” IEEE Transactions on Instrumentation and Measurement , vol . 71 , pp . 1–10 , 2022 . [ 143 ] Y. Ding , M. Jia , Q. Miao , and Y. Cao , “ A novel time–frequency transformer based on self–attention mechanism and its application in fault diagnosis of rolling bearings , ” Mechanical Systems and Signal Processing , vol . 168 , p. 108616 , 2022 . [ 144 ] G. Wang , Y. Zhao , C. Tang , C. Luo , and W. Zeng , “ When shift operation meets vision transformer : An extremely simple alternative to attention mechanism , ” in Proceedings of the AAAI Conference on Artiﬁcial Intelligence , vol . 36 , no . 2 , 2022 , pp . 2423–2430 . [ 145 ] H. Cai , J. Li , M. Hu , C. Gan , and S. Han , “ Efﬁcientvit : Lightweight multi-scale attention for high-resolution dense prediction , ” in Proceed- ings of the IEEE/CVF International Conference on Computer Vision , 2023 , pp . 17 302–17 313 . [ 146 ] X. Liu , H. Peng , N. Zheng , Y. Yang , H. Hu , and Y. Yuan , “ Efﬁcientvit : Memory efﬁcient vision transformer with cascaded group attention , ” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2023 , pp . 14 420–14 430 . [ 147 ] Y. Li , Q . Fan , H. Huang , Z. Han , and Q. Gu , “ A modiﬁed yolov8 detection network for uav aerial image recognition , ” Drones , vol . 7 , no . 5 , p. 304 , 2023 . [ 148 ] F. M. Talaat and H. ZainEldin , “ An improved ﬁre detection approach based on yolo-v8 for smart cities , ” Neural Computing and Applications , vol . 35 , no . 28 , pp . 20 939–20 954 , 2023 . [ 149 ] S. Tamang , B. Sen , A. Pradhan , K. Sharma , and V. K. Singh , “ Enhanc- ing covid-19 safety : Exploring yolov8 object detection for accurate face mask classiﬁcation , ” International Journal of Intelligent Systems and Applications in Engineering , vol . 11 , no . 2 , pp . 892–897 , 2023 . [ 150 ] J. Lu , R. Xiong , J. Tian , C. Wang , C.-W. Hsu , N.-T. Tsou , F. Sun , and J. Li , “ Battery degradation prediction against uncertain future con- ditions with recurrent neural network enabled deep learning , ” Energy Storage Materials , vol . 50 , pp . 139–151 , 2022 . [ 151 ] A. Onan , “ Bidirectional convolutional recurrent neural network archi- tecture with group-wise enhancement mechanism for text sentiment classiﬁcation , ” Journal of King Saud University-Computer and Infor- mation Sciences , vol . 34 , no . 5 , pp . 2098–2117 , 2022 . [ 152 ] F. Shan , X . He , D. J. Armaghani , P. Zhang , and D. Sheng , “ Success and challenges in predicting tbm penetration rate using recurrent neural networks , ” Tunnelling and Underground Space Technology , vol . 130 , p. 104728 , 2022 . [ 153 ] C. Sridhar , P. K. Pareek , R. Kalidoss , S. S. Jamal , P. K. Shukla , S. J. Nuagah et al. , “ Optimal medical image size reduction model creation using recurrent neural network and genpsowvq , ” Journal of Healthcare Engineering , vol . 2022 , 2022 . [ 154 ] J. Zhu , Q. Jiang , Y. Shen , C. Qian , F. Xu , and Q. Zhu , “ Application of recurrent neural network to mechanical fault diagnosis : A review , ” Journal of Mechanical Science and Technology , vol . 36 , no . 2 , pp . 527–542 , 2022 . [ 156 ] Z. Wei , X. Zhang , and M. Sun , “ Extracting weighted ﬁnite automata from recurrent neural networks for natural languages , ” in International Conference on Formal Engineering Methods . Springer , 2022 , pp . 370–385 . [ 157 ] F. Bonassi , M. Farina , J. Xie , and R. Scattolini , “ On recurrent neural networks for learning-based control : recent results and ideas for future developments , ” Journal of Process Control , vol . 114 , pp . 92–104 , 2022 . [ 158 ] Z. Guo , Y. Tang , R. Zhang , D. Wang , Z. Wang , B. Zhao , and X. Li , “ Viewrefer : Grasp the multi-view knowledge for 3d visual grounding , ” in Proceedings of the IEEE/CVF International Conference on Computer Vision , 2023 , pp . 15 372–15 383 . [ 159 ] C. Pan , Y . He , J. Peng , Q. Zhang , W. Sui , and Z. Zhang , “ Baeformer : Bi-directional and early interaction transformers for bird ’ s eye view semantic segmentation , ” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2023 , pp . 9590–9599 . [ 160 ] P. Xu , X. Zhu , and D. A. Clifton , “ Multimodal learning with transform- ers : A survey , ” IEEE Transactions on Pattern Analysis and Machine Intelligence , 2023 . [ 161 ] I. Molenaar , S. de Mooij , R. Azevedo , M. Bannert , S. J¨arvel¨a , and D. Gaˇsevi´c , “ Measuring self-regulated learning and the role of ai : Five years of research using multimodal multichannel data , ” Computers in Human Behavior , vol . 139 , p. 107540 , 2023 . [ 162 ] S. Steyaert , M. Pizurica , D. Nagaraj , P. Khandelwal , T. Hernandez- Boussard , A. J. Gentles , and O. Gevaert , “ Multimodal data fusion for cancer biomarker discovery with deep learning , ” Nature Machine Intelligence , vol . 5 , no . 4 , pp . 351–362 , 2023 . [ 163 ] V. Rani , S. T. Nabi , M. Kumar , A. Mittal , and K. Kumar , “ Self- supervised learning : A succinct review , ” Archives of Computational Methods in Engineering , vol . 30 , no . 4 , pp . 2761–2775 , 2023 . [ 164 ] M. C. Schiappa , Y. S. Rawat , and M. Shah , “ Self-supervised learning for videos : A survey , ” ACM Computing Surveys , vol . 55 , no . 13s , pp . 1–37 , 2023 . [ 165 ] J. Yu , H. Yin , X. Xia , T. Chen , J. Li , and Z. Huang , “ Self-supervised learning for recommender systems : A survey , ” IEEE Transactions on Knowledge and Data Engineering , 2023 . [ 166 ] V. Bharti , A. Kumar , V. Purohit , R. Singh , A. K. Singh , and S. K. Singh , “ A label efﬁcient semi self-supervised learning framework for iot devices in industrial process , ” IEEE Transactions on Industrial Informatics , 2023 . [ 167 ] D. Sam and J . Z. Kolter , “ Losses over labels : Weakly supervised loss construction , ” in Proceedings of the AAAI learning via direct Conference on Artiﬁcial Intelligence , vol . 37 , no . 8 , 2023 , pp . 9695– 9703 . [ 168 ] M. Wang , P. Xie , Y . Du , and X. Hu , “ T5-based model for abstractive summarization : A semi-supervised learning approach with consistency loss functions , ” Applied Sciences , vol . 13 , no . 12 , p. 7111 , 2023 . [ 169 ] Q. Li , X. Peng , Y. Qiao , and Q. Hao , “ Unsupervised person re- identiﬁcation with multi-label learning guided self-paced clustering , ” Pattern Recognition , vol . 125 , p. 108521 , 2022 . [ 170 ] P. Nancy , H. Pallathadka , M. Naved , K. Kaliyaperumal , K. Arumugam , and V. Garchar , “ Deep learning and machine learning based efﬁcient framework for image based plant disease classiﬁcation and detection , ” in 2022 International Conference on Advanced Computing Technolo- gies and Applications ( ICACTA ) . IEEE , 2022 , pp . 1–6 . [ 171 ] P. An , Z. Wang , and C. Zhang , “ Ensemble unsupervised autoencoders and gaussian mixture model for cyberattack detection , ” Information Processing & Management , vol . 59 , no . 2 , p. 102844 , 2022 . [ 172 ] S. Yan , H. Shao , Y. Xiao , B. Liu , and J. Wan , “ Hybrid robust convo- lutional autoencoder for unsupervised anomaly detection of machine tools under noises , ” Robotics and Computer-Integrated Manufacturing , vol . 79 , p. 102441 , 2023 . [ 173 ] E. Ayanoglu , K. Davaslioglu , and Y. E. Sagduyu , “ Machine learning in nextg networks via generative adversarial networks , ” IEEE Trans- actions on Cognitive Communications and Networking , vol . 8 , no . 2 , pp . 480–501 , 2022 . [ 174 ] K. Yan , X. Chen , X. Zhou , Z. Yan , and J. Ma , “ Physical model informed fault detection and diagnosis of air handling units based on transformer generative adversarial network , ” IEEE Transactions on Industrial Informatics , vol . 19 , no . 2 , pp . 2192–2199 , 2022 . [ 175 ] N.-R. Zhou , T.-F. Zhang , X.-W. Xie , and J.-Y . Wu , “ Hybrid quantum– classical generative adversarial networks for image generation via learning discrete distribution , ” Signal Processing : Image Communica- tion , vol . 110 , p. 116891 , 2023 . [ 155 ] S. Lin , W. Lin , W. Wu , F. Zhao , R. Mo , and H. Zhang , “ Segrnn : Seg- ment recurrent neural network for long-term time series forecasting , ” arXiv preprint arXiv:2308.11200 , 2023 . [ 176 ] P. Ladosz , L. Weng , M. Kim , and H. Oh , “ Exploration in deep reinforcement learning : A survey , ” Information Fusion , vol . 85 , pp . 1–22 , 2022 . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 27 [ 177 ] Y. Matsuo , Y. LeCun , M. Sahani , D. Precup , D. Silver , M. Sugiyama , E. Uchibe , and J. Morimoto , “ Deep learning , reinforcement learning , and world models , ” Neural Networks , vol . 152 , pp . 267–275 , 2022 . [ 178 ] D. Bertoin , A. Zouitine , M. Zouitine , and E. Rachelson , “ Look where you look ! saliency-guided q-networks for generalization in visual reinforcement learning , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 30 693–30 706 , 2022 . [ 179 ] A. Haﬁz , “ A survey of deep q-networks used for reinforcement learning : State of the art , ” Intelligent Communication Technologies and Virtual Mobile Networks : Proceedings of ICICV 2022 , pp . 393–402 , 2022 . [ 180 ] A. Haﬁz , M. Hassaballah , A. Alqahtani , S. Alsubai , and M. A. Hameed , “ Reinforcement learning with an ensemble of binary action deep q- networks. ” Computer Systems Science & Engineering , vol . 46 , no . 3 , 2023 . [ 181 ] A. Alagha , S. Singh , R. Mizouni , J. Bentahar , and H. Otrok , “ Target localization using multi-agent deep reinforcement learning with prox- imal policy optimization , ” Future Generation Computer Systems , vol . 136 , pp . 342–357 , 2022 . [ 182 ] S. S. Hassan , Y. M. Park , Y. K. Tun , W. Saad , Z. Han , and C. S. Hong , “ 3to : Thz-enabled throughput and trajectory optimization of uavs in 6g networks by proximal policy optimization deep reinforcement learn- ing , ” in ICC 2022-IEEE International Conference on Communications . IEEE , 2022 , pp . 5712–5718 . [ 183 ] A. K. Jayant and S. Bhatnagar , “ Model-based safe deep reinforcement learning via a constrained proximal policy optimization algorithm , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 24 432–24 445 , 2022 . [ 184 ] B. Lin , “ Reinforcement learning and bandits for speech and language processing : Tutorial , review and outlook , ” Expert Systems with Appli- cations , p. 122254 , 2023 . [ 185 ] B. Luo , Z. Wu , F. Zhou , and B.-C. Wang , “ Human-in-the-loop rein- forcement learning in continuous-action space , ” IEEE Transactions on Neural Networks and Learning Systems , 2023 . [ 186 ] A. Raza , K. P. Tran , L. Koehl , and S. Li , “ Designing ecg monitoring healthcare system with federated transfer learning and explainable ai , ” Knowledge-Based Systems , vol . 236 , p. 107763 , 2022 . [ 187 ] S. Siahpour , X. Li , and J. Lee , “ A novel transfer learning approach life prediction for incomplete dataset , ” IEEE in remaining useful Transactions on Instrumentation and Measurement , vol . 71 , pp . 1–11 , 2022 . [ 188 ] Z. Guo , K. Lin , X. Chen , and C.-Y . Chit , “ Transfer learning for angle of arrivals estimation in massive mimo system , ” in 2022 IEEE/CIC International Conference on Communications in China ( ICCC ) . IEEE , 2022 , pp . 506–511 . [ 189 ] S. Liu , Y. Lu , P. Zheng , H. Shen , and J. Bao , “ Adaptive reconstruction of digital twins for machining systems : A transfer learning approach , ” Robotics and Computer-Integrated Manufacturing , vol . 78 , p. 102390 , 2022 . [ 190 ] H. Liu , J. Liu , L. Cui , Z. Teng , N. Duan , M. Zhou , and Y. Zhang , “ Logiqa 2.0—an improved dataset for logical reasoning in natural language understanding , ” IEEE/ACM Transactions on Audio , Speech , and Language Processing , 2023 . [ 191 ] Y. Meng , J. Huang , Y. Zhang , and J. Han , “ Generating training data with language models : Towards zero-shot language understanding , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 462– 477 , 2022 . [ 192 ] R. M. Samant , M. R. Bachute , S. Gite , and K. Kotecha , “ Framework for deep learning-based language models using multi-task learning in natural language understanding : A systematic literature review and future directions , ” IEEE Access , vol . 10 , pp . 17 078–17 097 , 2022 . [ 193 ] H. Weld , X. Huang , S. Long , J. Poon , and S. C. Han , “ A survey of joint intent detection and slot ﬁlling models in natural language understanding , ” ACM Computing Surveys , vol . 55 , no . 8 , pp . 1–38 , 2022 . [ 194 ] S. Ajmal , A . A. I. Ahmed , and C. Jalota , “ Natural language process- ing in improving information retrieval and knowledge discovery in healthcare conversational agents , ” Journal of Artiﬁcial Intelligence and Machine Learning in Management , vol . 7 , no . 1 , pp . 34–47 , 2023 . [ 195 ] A. Montejo-R´aez and S. M. Jim´enez-Zafra , “ Current approaches and applications in natural language processing , ” Applied Sciences , vol . 12 , no . 10 , p. 4859 , 2022 . [ 196 ] K. Vijayan , O. Anand , and A. Sahaj , “ Language-agnostic text process- ing for information extraction , ” in CS & IT Conference Proceedings , vol . 12 , no . 23 . CS & IT Conference Proceedings , 2022 . [ 197 ] C. D. Manning , “ Human language understanding & reasoning , ” Daedalus , vol . 151 , no . 2 , pp . 127–138 , 2022 . [ 198 ] W. Peng , D. Xu , T. Xu , J. Zhang , and E. Chen , “ Are gpt embeddings useful for ads and recommendation ? ” in International Conference on Knowledge Science , Engineering and Management . Springer , 2023 , pp . 151–162 . [ 199 ] E. Erdem , M. Kuyu , S. Yagcioglu , A. Frank , L. Parcalabescu , B. Plank , A. Babii , O. Turuta , A. Erdem , I. Calixto et al. , “ Neural natural language generation : A survey on multilinguality , multimodality , con- trollability and learning , ” Journal of Artiﬁcial Intelligence Research , vol . 73 , pp . 1131–1207 , 2022 . [ 200 ] J. Qian , L. Dong , Y. Shen , F. Wei , and W. Chen , “ Controllable natural language generation with contrastive preﬁxes , ” arXiv preprint arXiv:2202.13257 , 2022 . [ 201 ] H. Rashkin , V. Nikolaev , M. Lamm , L. Aroyo , M. Collins , D. Das , S. Petrov , G. S. Tomar , I. Turc , and D. Reitter , “ Measuring attribution in natural language generation models , ” Computational Linguistics , pp . 1–64 , 2023 . [ 202 ] A. K. Pandey and S. S. Roy , “ Natural language generation using sequential models : A survey , ” Neural Processing Letters , pp . 1–34 , 2023 . [ 203 ] J. Y. Khan and G. Uddin , “ Automatic code documentation generation the 37th IEEE/ACM International using gpt-3 , ” in Proceedings of Conference on Automated Software Engineering , 2022 , pp . 1–6 . [ 204 ] Y. K. Dwivedi , N. Kshetri , L. Hughes , E. L. Slade , A. Jeyaraj , A. K. Kar , A. M. Baabdullah , A. Koohang , V. Raghavan , M. Ahuja et al. , “ “ so what if chatgpt wrote it ? ” multidisciplinary perspectives on op- portunities , challenges and implications of generative conversational ai for research , practice and policy , ” International Journal of Information Management , vol . 71 , p. 102642 , 2023 . [ 205 ] T. Fu , S. Gao , X. Zhao , J.-r. Wen , and R. Yan , “ Learning towards conversational ai : A survey , ” AI Open , vol . 3 , pp . 14–28 , 2022 . [ 206 ] H. Ji , I. Han , and Y. Ko , “ A systematic review of conversational ai in language education : Focusing on the collaboration with human teachers , ” Journal of Research on Technology in Education , vol . 55 , no . 1 , pp . 48–63 , 2023 . [ 207 ] Y. Wan , W. Wang , P. He , J. Gu , H. Bai , and M. R. Lyu , “ Biasasker : Measuring the bias in conversational ai system , ” in Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering , 2023 , pp . 515–527 . [ 208 ] S. Kusal , S. Patil , J. Choudrie , K. Kotecha , S. Mishra , and A. Abraham , “ Ai-based conversational agents : A scoping review from technologies to future directions , ” IEEE Access , 2022 . [ 209 ] Z. Xiao , “ Seeing us through machines : designing and building con- versational ai to understand humans , ” Ph.D. dissertation , University of Illinois at Urbana-Champaign , 2023 . [ 210 ] H.-K. Ko , G. Park , H. Jeon , J. Jo , J. Kim , and J. Seo , “ Large-scale text-to-image generation models for visual artists ’ creative works , ” in Proceedings of the 28th International Conference on Intelligent User Interfaces , 2023 , pp . 919–933 . [ 211 ] A. Pearson , “ The rise of crealtives : Using ai to enable and speed up the creative process , ” Journal of AI , Robotics & Workplace Automation , vol . 2 , no . 2 , pp . 101–114 , 2023 . [ 212 ] J. Rezwana and M. L. Maher , “ Designing creative ai partners with coﬁ : A framework for modeling interaction in human-ai co-creative systems , ” ACM Transactions on Computer-Human Interaction , vol . 30 , no . 5 , pp . 1–28 , 2023 . [ 213 ] S. Sharma and S. Bvuma , “ Generative adversarial networks ( gans ) for creative applications : Exploring art and music generation , ” Interna- tional Journal of Multidisciplinary Innovation and Research Method- ology , ISSN : 2960-2068 , vol . 2 , no . 4 , pp . 29–33 , 2023 . [ 214 ] B. Attard-Frost , A . De los R´ıos , and D. R. Walters , “ The ethics of ai business practices : a review of 47 ai ethics guidelines , ” AI and Ethics , vol . 3 , no . 2 , pp . 389–406 , 2023 . [ 215 ] A. Gardner , A. L. Smith , A. Steventon , E. Coughlan , and M. Oldﬁeld , “ Ethical funding for trustworthy ai : proposals to address the respon- sibilities of funders to ensure that projects adhere to trustworthy ai practice , ” AI and Ethics , pp . 1–15 , 2022 . [ 216 ] J. Schuett , “ Three lines of defense against risks from ai , ” AI & SOCIETY , pp . 1–15 , 2023 . [ 217 ] M. Sloane and J. Zakrzewski , “ German ai start-ups and “ ai ethics ” : Using a social practice lens for assessing and implementing socio- technical innovation , ” in Proceedings of the 2022 ACM Conference on Fairness , Accountability , and Transparency , 2022 , pp . 935–947 . [ 218 ] M. Vasconcelos , C. Cardonha , and B. Gonc¸alves , “ Modeling epistemo- logical principles for bias mitigation in ai systems : an illustration in hiring decisions , ” in Proceedings of the 2018 AAAI/ACM Conference on AI , Ethics , and Society , 2018 , pp . 323–329 . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 28 [ 219 ] Y. Yang , A. Gupta , J. Feng , P. Singhal , V. Yadav , Y. Wu , P. Natarajan , V. Hedau , and J. Joo , “ Enhancing fairness in face detection in computer vision systems by demographic bias mitigation , ” in Proceedings of the 2022 AAAI/ACM Conference on AI , Ethics , and Society , 2022 , pp . 813– 822 . [ 220 ] R. Schwartz , A. Vassilev , K. Greene , L. Perine , A. Burt , P. Hall et al. , “ Towards a standard for identifying and managing bias in artiﬁcial intelligence , ” NIST special publication , vol . 1270 , no . 10.6028 , 2022 . [ 221 ] W. Guo and A. Caliskan , “ Detecting emergent intersectional biases : Contextualized word embeddings contain a distribution of human-like biases , ” in Proceedings of the 2021 AAAI/ACM Conference on AI , Ethics , and Society , 2021 , pp . 122–133 . [ 222 ] Y. Kong , “ Are “ intersectionally fair ” ai algorithms really fair to women of color ? a philosophical analysis , ” in Proceedings of the 2022 ACM Conference on Fairness , Accountability , and Transparency , 2022 , pp . 485–494 . [ 223 ] Y. C. Tan and L. E. Celis , “ Assessing social and intersectional biases in contextualized word representations , ” Advances in neural information processing systems , vol . 32 , 2019 . [ 224 ] L. Cheng , A. Mosallanezhad , P. Sheth , and H. Liu , “ Causal learning for socially responsible ai , ” arXiv preprint arXiv:2104.12278 , 2021 . [ 225 ] J. D. Correa , J. Tian , and E. Bareinboim , “ Identiﬁcation of causal effects in the presence of selection bias , ” in Proceedings of the AAAI Conference on Artiﬁcial Intelligence , vol . 33 , no . 01 , 2019 , pp . 2744– 2751 . [ 226 ] B. Ghai and K. Mueller , “ D-bias : a causality-based human-in-the- loop system for tackling algorithmic bias , ” IEEE Transactions on Visualization and Computer Graphics , vol . 29 , no . 1 , pp . 473–482 , 2022 . [ 227 ] J. N. Yan , Z. Gu , H. Lin , and J. M. Rzeszotarski , “ Silva : Interactively assessing machine learning fairness using causality , ” in Proceedings of the 2020 chi conference on human factors in computing systems , 2020 , pp . 1–13 . [ 228 ] E. Bertino , M. Kantarcioglu , C. G. Akcora , S. Samtani , S. Mittal , and M. Gupta , “ Ai for security and security for ai , ” in Proceedings of the Eleventh ACM Conference on Data and Application Security and Privacy , 2021 , pp . 333–334 . [ 229 ] H. Susanto , L. F. Yie , D. Rosiyadi , A. I. Basuki , and D. Setiana , “ Data security for connected governments and organisations : Managing au- tomation and artiﬁcial intelligence , ” in Web 2.0 and cloud technologies for implementing connected government . IGI Global , 2021 , pp . 229– 251 . [ 230 ] S. Dilmaghani , M. R. Brust , G. Danoy , N. Cassagnes , J. Pecero , and P. Bouvry , “ Privacy and security of big data in ai systems : A research and standards perspective , ” in 2019 IEEE International Conference on Big Data ( Big Data ) . IEEE , 2019 , pp . 5737–5743 . [ 231 ] T. McIntosh , “ Intercepting ransomware attacks with staged event- driven access control , ” Ph.D. dissertation , La Trobe , 2022 . [ 232 ] T. McIntosh , A. Kayes , Y.-P. P. Chen , A. Ng , and P. Watters , “ Applying staged event-driven access control to combat ransomware , ” Computers & Security , vol . 128 , p. 103160 , 2023 . [ 233 ] P. Hummel , M. Braun , M. Tretter , and P. Dabrock , “ Data sovereignty : A review , ” Big Data & Society , vol . 8 , no . 1 , p. 2053951720982012 , 2021 . [ 234 ] M. Lukings and A. Habibi Lashkari , “ Data sovereignty , ” in Under- standing Cybersecurity Law in Data Sovereignty and Digital Gover- nance : An Overview from a Legal Perspective . Springer , 2022 , pp . 1–38 . [ 235 ] M. Hickok , “ Lessons learned from ai ethics principles for future actions , ” AI and Ethics , vol . 1 , no . 1 , pp . 41–47 , 2021 . [ 236 ] J. Zhou and F. Chen , “ Ai ethics : From principles to practice , ” AI & SOCIETY , pp . 1–11 , 2022 . [ 237 ] J . A. Kroll , “ Outlining traceability : A principle for operationalizing accountability in computing systems , ” in Proceedings of the 2021 ACM Conference on Fairness , Accountability , and Transparency , 2021 , pp . 758–771 . [ 238 ] A. Oseni , N. Moustafa , H. Janicke , P. Liu , Z. Tari , and A. Vasilakos , intelligence : Opportunities and “ Security and privacy for artiﬁcial challenges , ” arXiv preprint arXiv:2102.04661 , 2021 . [ 239 ] B. C. Stahl and D. Wright , “ Ethics and privacy in ai and big data : Implementing responsible research and innovation , ” IEEE Security & Privacy , vol . 16 , no . 3 , pp . 26–33 , 2018 . [ 240 ] C. Ma , J. Li , K. Wei , B. Liu , M. Ding , L. Yuan , Z. Han , and H. V. Poor , “ Trusted ai in multiagent systems : An overview of privacy and security for distributed learning , ” Proceedings of the IEEE , vol . 111 , no . 9 , pp . 1097–1132 , 2023 . [ 241 ] M. Song , Z. Wang , Z. Zhang , Y . Song , Q. Wang , J. Ren , and H. Qi , “ Analyzing user-level privacy attack against federated learning , ” IEEE Journal on Selected Areas in Communications , vol . 38 , no . 10 , pp . 2430–2444 , 2020 . [ 242 ] I. Misra and L. v. d. Maaten , “ Self-supervised learning of pretext- invariant representations , ” in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2020 , pp . 6707–6717 . [ 243 ] X. Zhai , A. Oliver , A. Kolesnikov , and L. Beyer , “ S4l : Self-supervised semi-supervised learning , ” in Proceedings of the IEEE/CVF interna- tional conference on computer vision , 2019 , pp . 1476–1485 . [ 244 ] T. Chen , X. Zhai , M. Ritter , M. Lucic , and N. Houlsby , “ Self-supervised gans via auxiliary rotation loss , ” in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2019 , pp . 12 154–12 163 . [ 245 ] S. Jenni and P. Favaro , “ Self-supervised feature learning by learning to spot artifacts , ” in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018 , pp . 2733–2742 . [ 246 ] P. Patel , N. Kumari , M. Singh , and B. Krishnamurthy , “ Lt-gan : Self- supervised gan with latent transformation detection , ” in Proceedings of the IEEE/CVF winter conference on applications of computer vision , 2021 , pp . 3189–3198 . [ 247 ] T. Chen , S. Kornblith , M. Norouzi , and G. Hinton , “ A simple frame- work for contrastive learning of visual representations , ” in International conference on machine learning . PMLR , 2020 , pp . 1597–1607 . [ 248 ] K. He , H. Fan , Y. Wu , S. Xie , and R. Girshick , “ Momentum contrast for unsupervised visual representation learning , ” in Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 2020 , pp . 9729–9738 . [ 249 ] A. T. Liu , S.-W. Li , and H.-y . Lee , “ Tera : Self-supervised learning of transformer encoder representation for speech , ” IEEE/ACM Transac- tions on Audio , Speech , and Language Processing , vol . 29 , pp . 2351– 2366 , 2021 . [ 250 ] Y. Pang , W. Wang , F. E. Tay , W. Liu , Y. Tian , and L. Yuan , “ Masked autoencoders for point cloud self-supervised learning , ” in European conference on computer vision . Springer , 2022 , pp . 604–621 . [ 251 ] T. Hospedales , A. Antoniou , P. Micaelli , and A. Storkey , “ Meta- learning in neural networks : A survey , ” IEEE transactions on pattern analysis and machine intelligence , vol . 44 , no . 9 , pp . 5149–5169 , 2021 . [ 252 ] R. Vilalta and Y. Drissi , “ A perspective view and survey of meta- learning , ” Artiﬁcial intelligence review , vol . 18 , pp . 77–95 , 2002 . [ 253 ] M. Al-Shedivat , L. Li , E. Xing , and A. Talwalkar , “ On data efﬁciency of meta-learning , ” in International Conference on Artiﬁcial Intelligence and Statistics . PMLR , 2021 , pp . 1369–1377 . [ 254 ] Y. Hu , R. Liu , X. Li , D. Chen , and Q. Hu , “ Task-sequencing meta learning for intelligent few-shot fault diagnosis with limited data , ” IEEE Transactions on Industrial Informatics , vol . 18 , no . 6 , pp . 3894– 3904 , 2021 . [ 255 ] S. Baik , J. Choi , H. Kim , D. Cho , J. Min , and K. M. Lee , “ Meta- learning with task-adaptive loss function for few-shot learning , ” in Proceedings of the IEEE/CVF international conference on computer vision , 2021 , pp . 9465–9474 . [ 256 ] Y. Chen , Z. Liu , H. Xu , T. Darrell , and X. Wang , “ Meta-baseline : Exploring simple meta-learning for few-shot learning , ” in Proceedings of the IEEE/CVF international conference on computer vision , 2021 , pp . 9062–9071 . [ 257 ] M. A. Jamal and G.-J . Qi , “ Task agnostic meta-learning for few-shot learning , ” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 2019 , pp . 11 719–11 727 . [ 258 ] R. Behnia , M. R. Ebrahimi , J. Pacheco , and B. Padmanabhan , “ Ew- tune : A framework for privately ﬁne-tuning large language models with differential privacy , ” in 2022 IEEE International Conference on Data Mining Workshops ( ICDMW ) . IEEE , 2022 , pp . 560–566 . [ 259 ] J. Wei , M. Bosma , V. Y. Zhao , K. Guu , A. W. Yu , B. Lester , N. Du , A. M. Dai , and Q. V. Le , “ Finetuned language models are zero-shot learners , ” arXiv preprint arXiv:2109.01652 , 2021 . [ 260 ] W. Kuang , B. Qian , Z. Li , D. Chen , D. Gao , X. Pan , Y. Xie , Y. Li , B. Ding , and J. Zhou , “ Federatedscope-llm : A comprehensive package for ﬁne-tuning large language models in federated learning , ” arXiv preprint arXiv:2309.00363 , 2023 . [ 261 ] M. Nguyen , K. Kishan , T. Nguyen , A. Chadha , and T. Vu , “ Efﬁ- cient ﬁne-tuning large language models for knowledge-aware response planning , ” in Joint European Conference on Machine Learning and Knowledge Discovery in Databases . Springer , 2023 , pp . 593–611 . [ 262 ] M. Engelbach , D. Klau , F. Scheerer , J. Drawehn , and M. Kintz , “ Fine-tuning and aligning question answering models for complex information extraction tasks , ” arXiv preprint arXiv:2309.14805 , 2023 . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 29 [ 263 ] T. T. Nguyen , C. Wilson , and J. Dalins , “ Fine-tuning llama 2 large language models for detecting online sexual predatory chats and abusive texts , ” arXiv preprint arXiv:2308.14683 , 2023 . [ 264 ] Q. Zhou , C. Yu , S. Zhang , S. Wu , Z. Wang , and F. Wang , “ Regionblip : A uniﬁed multi-modal pre-training framework for holistic and regional comprehension , ” arXiv preprint arXiv:2308.02299 , 2023 . [ 265 ] T. Arnold and D. Kasenberg , “ Value alignment or misalignment - what will keep systems accountable ? ” in AAAI Workshop on AI , Ethics , and Society , 2017 . [ 266 ] I. Gabriel and V. Ghazavi , “ The challenge of value alignment : From fairer algorithms to ai safety , ” arXiv preprint arXiv:2101.06060 , 2021 . [ 267 ] S. Nyholm , “ Responsibility gaps , value alignment , and meaningful human control over artiﬁcial intelligence , ” in Risk and responsibility in context . Routledge , 2023 , pp . 191–213 . [ 268 ] S. Wu , H. Fei , L. Qu , W. Ji , and T.-S. Chua , “ Next-gpt : Any-to-any multimodal llm , ” arXiv preprint arXiv:2309.05519 , 2023 . [ 269 ] K. Bayoudh , R. Knani , F. Hamdaoui , and A. Mtibaa , “ A survey on deep multimodal learning for computer vision : advances , trends , applications , and datasets , ” The Visual Computer , pp . 1–32 , 2021 . [ 270 ] P. Hu , L. Zhen , D. Peng , and P. Liu , “ Scalable deep multimodal learning for cross-modal retrieval , ” in Proceedings of the 42nd international ACM SIGIR conference on research and development in information retrieval , 2019 , pp . 635–644 . [ 271 ] A. Rahate , R. Walambe , S. Ramanna , and K. Kotecha , “ Multimodal co- learning : Challenges , applications with datasets , recent advances and future directions , ” Information Fusion , vol . 81 , pp . 203–239 , 2022 . [ 272 ] L. Che , J. Wang , Y. Zhou , and F. Ma , “ Multimodal federated learning : A survey , ” Sensors , vol . 23 , no . 15 , p. 6986 , 2023 . [ 273 ] P. P. Liang , Y. Lyu , X . Fan , Z. Wu , Y. Cheng , J. Wu , L. Chen , P. Wu , M. A. Lee , Y. Zhu et al. , “ Multibench : Multiscale benchmarks for multimodal representation learning , ” arXiv preprint arXiv:2107.07502 , 2021 . [ 274 ] Z. Ashktorab , Q. V. Liao , C. Dugan , J. Johnson , Q. Pan , W. Zhang , S. Kumaravel , and M. Campbell , “ Human-ai collaboration in a co- operative game setting : Measuring social perception and outcomes , ” Proceedings of the ACM on Human-Computer Interaction , vol . 4 , no . CSCW2 , pp . 1–20 , 2020 . [ 275 ] P. Esmaeilzadeh , T. Mirzaei , and S. Dharanikota , “ Patients ’ perceptions toward human–artiﬁcial intelligence interaction in health care : exper- imental study , ” Journal of medical Internet research , vol . 23 , no . 11 , p. e25856 , 2021 . [ 276 ] M. Nazar , M. M. Alam , E. Yaﬁ , and M. M. Su ’ ud , “ A systematic review of human–computer interaction and explainable artiﬁcial intelligence in healthcare with artiﬁcial intelligence techniques , ” IEEE Access , vol . 9 , pp . 153 316–153 348 , 2021 . [ 277 ] A. S. Rajawat , R. Rawat , K. Barhanpurkar , R. N. Shaw , and A. Ghosh , “ Robotic process automation with increasing productivity and improv- ing product quality using artiﬁcial intelligence and machine learning , ” in Artiﬁcial Intelligence for Future Generation Robotics . Elsevier , 2021 , pp . 1–13 . [ 278 ] S. Mohseni , N. Zarei , and E. D. Ragan , “ A multidisciplinary survey and framework for design and evaluation of explainable ai systems , ” ACM Transactions on Interactive Intelligent Systems ( TiiS ) , vol . 11 , no . 3-4 , pp . 1–45 , 2021 . [ 279 ] M. C. Buehler and T. H. Weisswange , “ Theory of mind based com- munication for human agent cooperation , ” in 2020 IEEE International Conference on Human-Machine Systems ( ICHMS ) . IEEE , 2020 , pp . 1–6 . [ 280 ] M. M. C¸ elikok , T. Peltola , P. Daee , and S. Kaski , “ Interactive ai with a theory of mind , ” arXiv preprint arXiv:1912.05284 , 2019 . [ 281 ] A. Dafoe , E. Hughes , Y. Bachrach , T. Collins , K. R. McKee , J . Z. Leibo , K. Larson , and T. Graepel , “ Open problems in cooperative ai , ” arXiv preprint arXiv:2012.08630 , 2020 . [ 282 ] S. Bubeck , V. Chandrasekaran , R. Eldan , J. Gehrke , E. Horvitz , E. Kamar , P. Lee , Y. T. Lee , Y. Li , S. Lundberg et al. , “ Sparks of intelligence : Early experiments with gpt-4 , ” arXiv artiﬁcial general preprint arXiv:2303.12712 , 2023 . [ 283 ] N. Fei , Z. Lu , Y. Gao , G. Yang , Y. Huo , J. Wen , H. Lu , R. Song , X. Gao , T. Xiang et al. , “ Towards artiﬁcial general intelligence via a multimodal foundation model , ” Nature Communications , vol . 13 , no . 1 , p. 3094 , 2022 . [ 284 ] R. Williams and R. Yampolskiy , “ Understanding and avoiding ai failures : A practical guide , ” Philosophies , vol . 6 , no . 3 , p. 53 , 2021 . [ 285 ] W. Fedus , B. Zoph , and N. Shazeer , “ Switch transformers : Scaling to trillion parameter models with simple and efﬁcient sparsity , ” The Journal of Machine Learning Research , vol . 23 , no . 1 , pp . 5232–5270 , 2022 . [ 286 ] S. Shen , L. Hou , Y. Zhou , N. Du , S. Longpre , J. Wei , H. W. Chung , B. Zoph , W. Fedus , X. Chen et al. , “ Mixture-of-experts meets instruction tuning : A winning combination for large language models , ” arXiv preprint arXiv:2305.14705 , 2023 . [ 287 ] S. Rajbhandari , C. Li , Z. Yao , M. Zhang , R. Y. Aminabadi , A . A. Awan , J. Rasley , and Y . He , “ Deepspeed-moe : Advancing mixture-of- experts inference and training to power next-generation ai scale , ” in International Conference on Machine Learning . PMLR , 2022 , pp . 18 332–18 346 . [ 288 ] L. Shen , Z. Wu , W. Gong , H. Hao , Y. Bai , H. Wu , X. Wu , J. Bian , H. Xiong , D. Yu et al. , “ Se-moe : A scalable and efﬁcient mixture- of-experts distributed training and inference system , ” arXiv preprint arXiv:2205.10034 , 2022 . [ 289 ] C. Hwang , W. Cui , Y. Xiong , Z. Yang , Z. Liu , H. Hu , Z. Wang , R. Salas , J. Jose , P. Ram et al. , “ Tutel : Adaptive mixture-of-experts at scale , ” Proceedings of Machine Learning and Systems , vol . 5 , 2023 . [ 290 ] Y. Wang , S. Mukherjee , X. Liu , J. Gao , A. H. Awadallah , and J. Gao , “ Adamix : Mixture-of-adapter for parameter-efﬁcient tuning of large language models , ” arXiv preprint arXiv:2205.12410 , vol . 1 , no . 2 , p. 4 , 2022 . [ 291 ] T. Chen , Z. Zhang , A. Jaiswal , S. Liu , and Z. Wang , “ Sparse moe as the new dropout : Scaling dense and self-slimmable transformers , ” arXiv preprint arXiv:2303.01610 , 2023 . [ 292 ] H. Zhu , B . He , and X. Zhang , “ Multi-gate mixture-of-experts stacked autoencoders for quality prediction in blast furnace ironmaking , ” ACS omega , vol . 7 , no . 45 , pp . 41 296–41 303 , 2022 . [ 293 ] Z. Chi , L. Dong , S. Huang , D. Dai , S. Ma , B. Patra , S. Singhal , P. Bajaj , X . Song , X.-L. Mao et al. , “ On the representation collapse of sparse mixture of experts , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 34 600–34 613 , 2022 . [ 294 ] S. Gupta , S. Mukherjee , K. Subudhi , E. Gonzalez , D. Jose , A. H. Awadallah , and J. Gao , “ Sparsely activated mixture-of-experts are robust multi-task learners , ” arXiv preprint arXiv:2204.07689 , 2022 . [ 295 ] N. Dikkala , N. Ghosh , R. Meka , R. Panigrahy , N. Vyas , and X. Wang , “ On the beneﬁts of learning to route in mixture-of-experts models , ” in Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , 2023 , pp . 9376–9396 . [ 296 ] N. Dryden and T. Hoeﬂer , “ Spatial mixture-of-experts , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 11 697–11 713 , 2022 . [ 297 ] Z . You , S. Feng , D. Su , and D. Yu , “ Speechmoe2 : Mixture-of- experts model with improved routing , ” in ICASSP 2022-2022 IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) . IEEE , 2022 , pp . 7217–7221 . [ 298 ] J. Puigcerver , R. Jenatton , C. Riquelme , P. Awasthi , and S. Bhojana- palli , “ On the adversarial robustness of mixture of experts , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 9660–9671 , 2022 . [ 299 ] J. Li , Y. Jiang , Y. Zhu , C. Wang , and H. Xu , “ Accelerating distributed { MoE } training and inference with lina , ” in 2023 USENIX Annual Technical Conference ( USENIX ATC 23 ) , 2023 , pp . 945–959 . [ 300 ] L. Wu , M. Liu , Y. Chen , D. Chen , X. Dai , and L. Yuan , “ Residual mixture of experts , ” arXiv preprint arXiv:2204.09636 , 2022 . [ 301 ] B. Zoph , I. Bello , S. Kumar , N. Du , Y. Huang , J . Dean , N. Shazeer , and W. Fedus , “ Designing effective sparse expert models , ” arXiv preprint arXiv:2202.08906 , vol . 2 , 2022 . [ 302 ] —— , “ St-moe : Designing stable and transferable sparse expert mod- els , ” arXiv preprint arXiv:2202.08906 , 2022 . [ 303 ] Y. Chow , A. Tulepbergenov , O. Nachum , M. Ryu , M. Ghavamzadeh , and C. Boutilier , “ A mixture-of-expert approach to rl-based dialogue management , ” arXiv preprint arXiv:2206.00059 , 2022 . [ 304 ] Z . Fan , R. Sarkar , Z. Jiang , T. Chen , K. Zou , Y. Cheng , C. Hao , Z. Wang et al. , “ M3vit : Mixture-of-experts vision transformer for efﬁcient multi- task learning with model-accelerator co-design , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 28 441–28 457 , 2022 . [ 305 ] T. Zadouri , A . ¨Ust¨un , A. Ahmadian , B. Ermis¸ , A. Locatelli , and S. Hooker , “ Pushing mixture of experts to the limit : Extremely instruction tuning , ” arXiv preprint parameter efﬁcient moe for arXiv:2309.05444 , 2023 . [ 306 ] J. Zhu , X. Zhu , W. Wang , X. Wang , H. Li , X. Wang , and J. Dai , “ Uni- perceiver-moe : Learning sparse generalist models with conditional moes , ” Advances in Neural Information Processing Systems , vol . 35 , pp . 2664–2678 , 2022 . [ 307 ] F. Dou , J. Ye , G. Yuan , Q. Lu , W. Niu , H. Sun , L. Guan , G. Lu , G. Mai , N. Liu et al. , “ Towards artiﬁcial general intelligence ( agi ) in the internet of things ( iot ) : Opportunities and challenges , ” arXiv preprint arXiv:2309.07438 , 2023 . JOURNAL OF LATEX CLASS FILES , VOL . 1 , NO . 1 , DECEMBER 2023 30 from twitter , ” Journal of university teaching & learning practice , vol . 19 , no . 3 , p. 02 , 2022 . [ 308 ] Z. Jia , X. Li , Z. Ling , S. Liu , Y. Wu , and H. Su , “ Improving policy optimization with generalist-specialist learning , ” in International Conference on Machine Learning . PMLR , 2022 , pp . 10 104–10 119 . [ 309 ] M. Simeone , “ Unknown future , repeated present : A narrative-centered analysis of long-term ai discourse , ” Humanist Studies & the Digital Age , vol . 7 , no . 1 , 2022 . [ 310 ] A. Nair and F. Banaei-Kashani , “ Bridging the gap between ar- tiﬁcial intelligence : A ten com- mandment framework for human-like intelligence , ” arXiv preprint arXiv:2210.09366 , 2022. intelligence and artiﬁcial general [ 311 ] M. H. Jarrahi , D. Askay , A. Eshraghi , and P. Smith , “ Artiﬁcial intelli- gence and knowledge management : A partnership between human and ai , ” Business Horizons , vol . 66 , no . 1 , pp . 87–99 , 2023 . [ 312 ] D. J. Edwards , C. McEnteggart , and Y. Barnes-Holmes , “ A functional contextual account of background knowledge in categorization : Im- plications for artiﬁcial general intelligence and cognitive accounts of general knowledge , ” Frontiers in Psychology , vol . 13 , p. 745306 , 2022 . [ 313 ] J. McCarthy , “ Artiﬁcial intelligence , logic , and formalising common sense , ” Machine Learning and the City : Applications in Architecture and Urban Design , pp . 69–90 , 2022 . [ 314 ] S. Friederich , “ Symbiosis , not alignment , as the goal for liberal democracies in the transition to artiﬁcial general intelligence , ” AI and Ethics , pp . 1–10 , 2023 . [ 315 ] S. Makridakis , “ The forthcoming artiﬁcial intelligence ( ai ) revolution : Its impact on society and ﬁrms , ” Futures , vol . 90 , pp . 46–60 , 2017 . [ 316 ] S. Pal , K. Kumari , S. Kadam , and A. Saha , “ The ai revolution , ” IARA Publication , 2023 . [ 317 ] S. Verma , R. Sharma , S. Deb , and D. Maitra , “ Artiﬁcial intelligence in marketing : Systematic review and future research direction , ” Interna- tional Journal of Information Management Data Insights , vol . 1 , no . 1 , p. 100002 , 2021 . [ 318 ] P. Budhwar , S. Chowdhury , G. Wood , H. Aguinis , G. J. Bamber , J. R. Beltran , P. Boselie , F. Lee Cooke , S. Decker , A. DeNisi et al. , “ Human resource management in the age of generative artiﬁcial intelligence : Perspectives and research directions on chatgpt , ” Human Resource Management Journal , vol . 33 , no . 3 , pp . 606–659 , 2023 . [ 319 ] J . B. Telkamp and M. H. Anderson , “ The implications of diverse human moral foundations for assessing the ethicality of artiﬁcial intelligence , ” Journal of Business Ethics , vol . 178 , no . 4 , pp . 961–976 , 2022 . [ 320 ] X. Zhou , C. Liu , L. Zhai , Z. Jia , C. Guan , and Y. Liu , “ Interpretable and robust ai in eeg systems : A survey , ” arXiv preprint arXiv:2304.10755 , 2023 . [ 321 ] C. Zhang , C. Zhang , C. Li , Y. Qiao , S. Zheng , S. K. Dam , M. Zhang , J. U. Kim , S. T. Kim , J. Choi et al. , “ One small step for generative ai , one giant leap for agi : A complete survey on chatgpt in aigc era , ” arXiv preprint arXiv:2304.06488 , 2023 . [ 322 ] K. Singhal , T. Tu , J. Gottweis , R. Sayres , E. Wulczyn , L. Hou , K. Clark , S. Pfohl , H. Cole-Lewis , D. Neal et al. , “ Towards expert- level medical question answering with large language models , ” arXiv preprint arXiv:2305.09617 , 2023 . [ 323 ] S. Wu , O. Irsoy , S. Lu , V. Dabravolski , M. Dredze , S. Gehrmann , P. Kambadur , D. Rosenberg , and G. Mann , “ Bloomberggpt : A large language model for ﬁnance , ” arXiv preprint arXiv:2303.17564 , 2023 . [ 324 ] P. Henderson , K. Sinha , N. Angelard-Gontier , N. R. Ke , G. Fried , R. Lowe , and J. Pineau , “ Ethical challenges in data-driven dialogue systems , ” in Proceedings of the 2018 AAAI/ACM Conference on AI , Ethics , and Society , 2018 , pp . 123–129 . [ 325 ] S. A. Bin-Nashwan , M. Sadallah , and M. Bouteraa , “ Use of chatgpt in academia : Academic integrity hangs in the balance , ” Technology in Society , vol . 75 , p. 102370 , 2023 . [ 326 ] N. Liu , A . Brown et al. , “ Ai increases the pressure to overhaul the scientiﬁc peer review process . comment on “ artiﬁcial intelligence can generate fraudulent but authentic-looking scientiﬁc medical articles : Pandora ’ s box has been opened ” , ” J Med Internet Res , vol . 25 , p. e50591 , 2023 . [ 327 ] A. P. Siddaway , A. M. Wood , and L. V. Hedges , “ How to do a systematic review : a best practice guide for conducting and reporting narrative reviews , meta-analyses , and meta-syntheses , ” Annual review of psychology , vol . 70 , pp . 747–770 , 2019 . [ 328 ] E. Landhuis , “ Scientiﬁc literature : Information overload , ” Nature , vol . 535 , no . 7612 , pp . 457–458 , 2016 . [ 329 ] G. D. Chloros , V. P. Giannoudis , and P. V. Giannoudis , “ Peer-reviewing in surgical journals : revolutionize or perish ? ” Annals of surgery , vol . 275 , no . 1 , pp . e82–e90 , 2022 . [ 330 ] K.-A . Allen , J. Reardon , Y. Lu , D. V. Smith , E. Rainsford , and L. Walsh , “ Towards improving peer review : Crowd-sourced insights","['latex', 'class', 'file', 'vol', 'openai', 'q', 'qstar', 'survey', 'reshape', 'generative', 'artiﬁcial', 'intelligence', 'ai', 'research', 'landscape', 'senior', 'member', 'ieee', 'senior', 'member', 'ieee', 'c', 'e', 'c', 'v', 'r', 'abstract', 'comprehensive', 'survey', 'explore', 'evolve', 'landscape', 'generative', 'artiﬁcial', 'intelligence', 'ai', 'speciﬁc', 'focus', 'transformative', 'impact', 'mixture', 'expert', 'moe', 'multimodal', 'learn', 'speculate', 'advancement', 'artiﬁcial', 'general', 'intelligence', 'agi', 'critically', 'examine', 'current', 'state', 'future', 'trajectory', 'generative', 'artiﬁcial', 'telligence', 'explore', 'innovation', 'anticipate', 'q', 'project', 'reshape', 'research', 'priority', 'application', 'various', 'domain', 'include', 'impact', 'analysis', 'generative', 'ai', 'research', 'taxonomy', 'assess', 'computational', 'challenge', 'scalability', 'real', 'world', 'implication', 'technology', 'highlight', 'potential', 'drive', 'signiﬁcant', 'progress', 'ﬁeld', 'healthcare', 'ﬁnance', 'education', 'also', 'address', 'emerge', 'academic', 'challenge', 'pose', 'proliferation', 'aithemed', 'ai', 'generate', 'preprint', 'examine', 'impact', 'peerreview', 'process', 'scholarly', 'communication', 'study', 'highlight', 'importance', 'incorporate', 'ethical', 'humancentric', 'method', 'development', 'ensure', 'alignment', 'societal', 'norm', 'welfare', 'outline', 'strategy', 'future', 'ai', 'research', 'focus', 'balanced', 'conscientious', 'use', 'moe', 'multimodality', 'generative', 'ai', 'index', 'term', 'ai', 'ethic', 'artiﬁcial', 'general', 'intelligence', 'agi', 'artiﬁcial', 'intelligence', 'ai', 'gemini', 'generative', 'ai', 'mixture', 'expert', 'moe', 'multimodality', 'q', 'qstar', 'research', 'impact', 'analysis', 'introduction', 'historical', 'context', 'trace', 'back', 'ture', 'imitation', 'game', 'early', 'computational', 'theory', 'development', 'neural', 'network', 'machine', 'learn', 'set', 'foundation', 'day', 'advanced', 'model', 'evolution', 'accentuate', 'crucial', 'moment', 'rise', 'deep', 'learning', 'reinforcement', 'learning', 'vital', 'shape', 'contemporary', 'trend', 'ai', 'include', 'sophisticated', 'mixture', 'expert', 'moe', 'model', 'multimodal', 'system', 'illustrate', 'ﬁeld', 'dynamic', 'continuously', 'evolve', 'character', 'advance', 'ment', 'testament', 'dynamic', 'everevolve', 'nature', 'technology', 'evolution', 'artiﬁcial', 'intelligence', 'manuscript', 'receive', 'correspond', 'author', 'academy', 'polytechnic', 'melbourne', 'vic', 'email', 'aapolyeduau', 'email', 'tliu', 'masseyacnz', 'tsusnjak', 'masseyacnz', 'watter', 'cyberstronomy', 'vic', 'email', 'ceo', 'halgamuge', 'university', 'melbourne', 'vic', 'email', 'malkahalgamuge', 'rmiteduau', 'witness', 'crucial', 'turn', 'advent', 'large', 'language', 'model', 'llm', 'notably', 'chatgpt', 'develop', 'recent', 'unveiling', 'gemini', 'technology', 'revolutionize', 'industry', 'academia', 'also', 'reignite', 'critical', 'discussion', 'concern', 'ai', 'consciousness', 'potential', 'threat', 'humanity', 'development', 'advanced', 'system', 'include', 'notable', 'competitor', 'anthropic', 'claude', 'gemini', 'demonstrate', 'several', 'advance', 'pre', 'vious', 'model', 'gpt3', 'lamda', 'reshape', 'research', 'landscape', 'gemini', 'ability', 'learn', 'twoway', 'conversation', 'spikeandslab', 'attention', 'method', 'allow', 'focus', 'relevant', 'part', 'context', 'multiturn', 'conversation', 'represent', 'signiﬁ', 'leap', 'develop', 'model', 'well', 'equip', 'multidomain', 'conversational', 'applications1', 'innovation', 'llm', 'include', 'mixtureofexpert', 'method', 'employ', 'gemini', 'signal', 'move', 'model', 'handle', 'diversity', 'input', 'foster', 'approach', 'backdrop', 'speculation', 'openai', 'project', 'know', 'q', 'qstar', 'surface', 'allegedly', 'combine', 'power', 'llm', 'sophisticated', 'algorithm', 'qlearne', 'astar', 'far', 'contribute', 'dynamic', 'research', 'environment2', 'change', 'research', 'popularity', 'ﬁeld', 'llm', 'continue', 'evolve', 'exempliﬁed', 'innovation', 'gemini', 'q', 'multitude', 'stud', 'ie', 'surface', 'aim', 'chart', 'future', 'research', 'path', 'vary', 'identify', 'emerge', 'trend', 'highlight', 'area', 'poise', 'swift', 'progress', 'dichotomy', 'establish', 'method', 'early', 'adoption', 'evident', 'hot', 'topic', 'llm', 'research', 'increasingly', 'shift', 'multimodal', 'capability', 'conversationdriven', 'learn', 'demonstrate', 'propagation', 'preprint', 'expedite', 'knowledge', 'sharing', 'also', 'bring', 'risk', 'duce', 'academic', 'scrutiny', 'issue', 'inherent', 'bias', 'note', 'retraction', 'watch', 'concern', 'plagiarism', 'forgery', 'present', 'substantial', 'hurdle', 'academic', 'world', 'therefore', 'stand', 'intersection', 'necessitate', 'uniﬁed', 'drive', 'journal', 'latex', 'class', 'file', 'vol', 'reﬁne', 'research', 'direction', 'light', 'fastpaced', 'evolution', 'ﬁeld', 'appear', 'partly', 'trace', 'change', 'popularity', 'various', 'research', 'keyword', 'time', 'release', 'generative', 'model', 'gpt', 'widespread', 'commercial', 'success', 'chatgpt', 'inﬂuential', 'depict', 'figure', 'rise', 'fall', 'certain', 'keyword', 'appear', 'correlate', 'signiﬁcant', 'industry', 'milestone', 'release', 'transformer', 'model', 'gpt', 'model', 'commercial', 'chatgpt35', 'instance', 'spike', 'search', 'relate', 'deep', 'learning', 'coincide', 'breakthrough', 'neural', 'network', 'application', 'interest', 'natural', 'language', 'processing', 'surge', 'model', 'gpt', 'redeﬁne', 'possible', 'language', 'understanding', 'generation', 'endure', 'attention', 'ethic', 'ethical', 'research', 'ﬂuctuation', 'reﬂect', 'continuous', 'deeprooted', 'concern', 'moral', 'dimension', 'underscore', 'ethical', 'consideration', 'merely', 'reactionary', 'measure', 'integral', 'persistent', 'dialogue', 'discussion', 'academically', 'intriguing', 'postulate', 'trend', 'signify', 'causal', 'relationship', 'technological', 'ad', 'vancement', 'drive', 'research', 'focus', 'burgeon', 'research', 'propel', 'technological', 'development', 'paper', 'also', 'explore', 'profound', 'societal', 'economic', 'impact', 'advancement', 'examine', 'ai', 'technology', 'reshap', 'ing', 'various', 'industry', 'alter', 'employment', 'landscape', 'inﬂuence', 'socioeconomic', 'structure', 'analysis', 'highlight', 'opportunity', 'challenge', 'pose', 'ai', 'modern', 'world', 'emphasize', 'role', 'drive', 'innovation', 'economic', 'growth', 'also', 'consider', 'tion', 'potential', 'societal', 'disruption', 'future', 'study', 'yield', 'deﬁnitive', 'insight', 'yet', 'synchronous', 'interplay', 'innovation', 'academic', 'curiosity', 'remain', 'hallmark', 'progress', 'meanwhile', 'increase', 'number', 'preprint', 'post', 'arxiv', 'computer', 'science', 'ar', 'tiﬁcial', 'intelligence', 'csai', 'category', 'illustrate', 'figure', 'appear', 'signify', 'paradigm', 'shift', 'research', 'dissemination', 'community', 'rapid', 'distribution', 'ﬁnding', 'enable', 'swift', 'knowledge', 'exchange', 'also', 'raise', 'concern', 'regard', 'validation', 'information', 'surge', 'preprint', 'lead', 'propagation', 'unvalidated', 'biased', 'information', 'study', 'undergo', 'rigor', 'ous', 'scrutiny', 'potential', 'retraction', 'typical', 'peerreviewe', 'publication', 'trend', 'underline', 'need', 'careful', 'consideration', 'critique', 'academic', 'community', 'especially', 'give', 'potential', 'unvetted', 'study', 'cite', 'ﬁnding', 'propagate', 'exponential', 'b', 'objective', 'impetus', 'investigation', 'ofﬁcial', 'unveiling', 'gemini', 'speculative', 'discourse', 'surround', 'q', 'project', 'prompt', 'timely', 'examination', 'prevail', 'current', 'legend', 'entry', 'correspond', 'keyword', 'use', 'search', 'query', 'construct', 'ai', 'artiﬁcial', 'machine', 'learning', 'neural', 'network', 'computer', 'software', 'speciﬁc', 'generative', 'ai', 'research', 'paper', 'speciﬁcally', 'contribute', 'understanding', 'moe', 'multimodality', 'cial', 'general', 'intelligence', 'agi', 'impact', 'generative', 'ai', 'model', 'offer', 'detailed', 'analysis', 'future', 'direction', 'key', 'area', 'study', 'aim', 'perpetuate', 'conjecture', 'unrevealed', 'initiative', 'rather', 'critically', 'appraise', 'potential', 'obsolescence', 'insigniﬁcance', 'extant', 'research', 'theme', 'concur', 'rently', 'delve', 'burgeon', 'prospect', 'rapidly', 'transform', 'llm', 'panorama', 'inquiry', 'reminiscent', 'obsolete', 'nature', 'encryptioncentric', 'ﬁleentropy', 'base', 'ransomware', 'detection', 'methodology', 'eclipse', 'transition', 'ransomware', 'collective', 'datum', 'theft', 'strategy', 'utilize', 'varied', 'attack', 'vector', 'relegate', 'contemporary', 'study', 'cryptoransomware', 'status', 'latecomer', 'advance', 'anticipate', 'enhance', 'capability', 'language', 'analysis', 'knowledge', 'synthesis', 'also', 'pioneer', 'area', 'mixture', 'expert', 'moe', 'multimodality', 'artiﬁcial', 'general', 'intelligence', 'agi', 'already', 'herald', 'lescence', 'conventional', 'statisticsdriven', 'natural', 'language', 'processing', 'technique', 'many', 'domain', 'nonetheless', 'perennial', 'imperative', 'align', 'human', 'ethic', 'value', 'persist', 'fundamental', 'tenet', 'conjectural', 'initiative', 'offer', 'unprecedented', 'opportunity', 'instigate', 'discourse', 'advancement', 'reconﬁgure', 'llm', 'research', 'topography', 'milieu', 'insight', 'senior', 'research', 'scientist', 'lead', 'agent', 'q', 'particularly', 'concern', 'amalgamation', 'learning', 'search', 'algorithm', 'furnish', 'invaluable', 'perspective', 'prospective', 'technical', 'con', 'struct', 'proﬁciencie', 'undertaking4', 'research', 'methodology', 'involve', 'structured', 'literature', 'search', 'use', 'key', 'term', 'large', 'language', 'model', 'generative', 'ai', 'utilize', 'ﬁlter', 'several', 'academic', 'database', 'ieee', 'digital', 'library', 'sciencedirect', 'web', 'science', 'proquest', 'central', 'tailor', 'identify', 'relevant', 'article', 'publish', 'timeframe', 'release', 'transformer', 'model', 'writing', 'time', 'manuscript', 'paper', 'aspire', 'dissect', 'technical', 'ramiﬁcation', 'gemini', 'q', 'probe', 'similar', 'technology', 'emergence', 'inevitable', 'transﬁgure', 'research', 'trajectory', 'disclose', 'new', 'vista', 'domain', 'ai', 'pinpoint', 'nascent', 'research', 'domain', 'moe', 'multimodality', 'stand', 'reshape', 'generative', 'ai', 'research', 'landscape', 'profoundly', 'investigation', 'adopt', 'surveystyle', 'approach', 'systemat', 'ically', 'map', 'research', 'roadmap', 'synthesize', 'analyze', 'current', 'emergent', 'trend', 'generative', 'ai', 'major', 'contribution', 'study', 'follow', 'detailed', 'examination', 'evolve', 'landscape', 'tive', 'emphasize', 'advancement', 'innovation', 'technology', 'gemini', 'q', 'wideranging', 'implication', 'journal', 'latex', 'class', 'file', 'vol', '600k', '500k', 'e', 'r', 'h', 'c', 'r', 'e', 'e', 'deep', 'learn', 'convolutional', 'neural', 'network', 'unsupervised', 'learning', 'fine', 'tune', 'year', 'transfer', 'learn', 'explainable', 'reinforcement', 'learn', 'ethic', 'ethical', 'supervise', 'learn', 'natural', 'language', 'processing', 'generative', 'adversarial', 'network', 'language', 'model', 'figure', 'number', 'search', 'result', 'scholar', 'different', 'keyword', 'year', 'r', 'p', 'e', 'r', 'e', 'csai', 'preprint', 'arxiv', 'year', 'figure', 'annual', 'number', 'preprint', 'post', 'csai', 'category', 'arxivorg', 'analysis', 'transformative', 'effect', 'advanced', 'ai', 'system', 'academic', 'research', 'explore', 'development', 'alter', 'research', 'methodology', 'set', 'new', 'trend', 'potentially', 'lead', 'lescence', 'traditional', 'approach', 'thorough', 'assessment', 'ethical', 'societal', 'tech', 'nical', 'challenge', 'arise', 'integration', 'tive', 'ai', 'academia', 'underscore', 'crucial', 'need', 'align', 'technology', 'ethical', 'norm', 'ensure', 'datum', 'privacy', 'develop', 'comprehensive', 'governance', 'framework', 'rest', 'paper', 'organize', 'follow', 'explore', 'historical', 'development', 'generative', 'ai', 'section', 'present', 'taxonomy', 'current', 'generative', 'ai', 'research', 'section', 'explore', 'mixture', 'expert', 'moe', 'model', 'architecture', 'innovative', 'feature', 'impact', 'transformerbase', 'language', 'model', 'section', 'v', 'discuss', 'speculate', 'capability', 'q', 'project', 'section', 'discuss', 'project', 'capability', 'agi', 'section', 'examine', 'impact', 'recent', 'advancement', 'generative', 'ai', 'research', 'taxonomy', 'section', 'viii', 'identiﬁes', 'emerge', 'research', 'priority', 'generative', 'ai', 'section', 'discuss', 'academic', 'challenge', 'rapid', 'surge', 'preprint', 'ai', 'paper', 'conclude', 'section', 'summarize', 'overall', 'effect', 'develop', 'ment', 'generative', 'ai', 'background', 'evolution', 'generative', 'ai', 'ascent', 'generative', 'ai', 'mark', 'signiﬁcant', 'milestone', 'new', 'model', 'pave', 'way', 'next', 'evolutionary', 'leap', 'singlepurpose', 'algorithm', 'llm', 'chatgpt', 'late', 'multimodal', 'system', 'ai', 'landscape', 'transform', 'countless', 'ﬁeld', 'disrupt', 'evolution', 'language', 'model', 'language', 'model', 'undergo', 'transformative', 'journey', 'fig', 'evolve', 'rudimentary', 'statistical', 'method', 'journal', 'latex', 'class', 'file', 'vol', 'statistical', 'model', 'ngram', 'adoption', 'ngram', 'usage', 'introduction', 'lstms', 'lstms', 'textvoice', 'processing', 'deep', 'learning', 'era', 'chatgpt', 'launch', 'figure', 'timeline', 'key', 'development', 'language', 'model', 'complex', 'neural', 'network', 'architecture', 'underpin', 'today', 'llm', 'evolution', 'drive', 'relentless', 'quest', 'model', 'accurately', 'reﬂect', 'nuance', 'human', 'language', 'well', 'desire', 'push', 'boundary', 'machine', 'understand', 'generate', 'however', 'rapid', 'advancement', 'challenge', 'language', 'model', 'grow', 'capability', 'ethical', 'safety', 'concern', 'surround', 'use', 'prompt', 'reevaluation', 'model', 'develop', 'purpose', 'employ', 'language', 'model', 'precursor', 'inception', 'lan', 'guage', 'modeling', 'trace', 'statistical', 'approach', 'late', '1980', 'period', 'mark', 'transition', 'rulebase', 'machine', 'learn', 'algorithm', 'natural', 'language', 'process', 'nlp', 'early', 'model', 'primarily', 'ngram', 'base', 'calculate', 'probability', 'word', 'sequence', 'corpus', 'thus', 'provide', 'rudimentary', 'understanding', 'language', 'structure', 'model', 'simplistic', 'yet', 'ground', 'break', 'lay', 'groundwork', 'future', 'advance', 'language', 'understanding', 'increase', 'computational', 'power', 'late', '1980', 'witness', 'revolution', 'nlp', 'pivot', 'statistical', 'model', 'capable', 'soft', 'probabilistic', 'decision', 'oppose', 'rigid', 'handwritten', 'rulebase', 'system', 'dominate', 'early', 'system', 'development', 'complicated', 'statistical', 'model', 'period', 'signiﬁe', 'grow', 'importance', 'success', 'approach', 'subsequent', 'decade', 'popularity', 'applicability', 'statistical', 'model', 'surge', 'prove', 'invaluable', 'manage', 'ﬂourishe', 'ﬂow', 'digital', 'text', '1990', 'see', 'statistical', 'method', 'ﬁrmly', 'establish', 'research', 'ngram', 'become', 'instrumental', 'numerically', 'capture', 'linguistic', 'pat', 'tern', 'introduction', 'long', 'memory', 'lstm', 'network', 'application', 'voice', 'text', 'process', 'decade', 'later', 'mark', 'signiﬁcant', 'milestone', 'lead', 'current', 'era', 'neural', 'network', 'model', 'represent', 'cut', 'edge', 'research', 'development', 'large', 'language', 'model', 'technical', 'advancement', 'commercial', 'success', 'advent', 'deep', 'learning', 'revolu', 'tionize', 'ﬁeld', 'nlp', 'lead', 'development', 'llm', 'gpt', 'notably', 'chatgpt', 'recent', 'model', 'gpt4', 'push', 'bind', 'arie', 'integrate', 'sophisticated', 'technique', 'transformer', 'architecture', 'advanced', 'natural', 'language', 'understanding', 'illustrate', 'rapid', 'evolution', 'ﬁeld', 'model', 'represent', 'signiﬁcant', 'leap', 'capability', 'leverage', 'vast', 'computational', 'resource', 'extensive', 'dataset', 'achieve', 'new', 'height', 'language', 'understanding', 'generation', 'chatgpt', 'show', 'impressive', 'conversational', 'skill', 'contextual', 'understanding', 'broad', 'spectrum', 'func', 'tional', 'use', 'many', 'area', 'evidence', 'technical', 'commercial', 'success', 'include', 'rapid', 'adoption', 'user', 'shortly', 'launch', 'underscore', 'robust', 'market', 'demand', 'natural', 'language', 'ai', 'catalyze', 'interdisciplinary', 'research', 'application', 'sector', 'education', 'healthcare', 'commerce', 'education', 'chatgpt', 'offer', 'innovative', 'approach', 'personalized', 'learning', 'interactive', 'teaching', 'commerce', 'revolutionize', 'customer', 'service', 'content', 'creation', 'widespread', 'use', 'chatgpt', 'anthropic', 'claude', 'similar', 'commercial', 'llm', 'reignite', 'important', 'debate', 'ﬁeld', 'ai', 'particularly', 'concern', 'ai', 'consciousness', 'safety', 'humanlike', 'interaction', 'capability', 'raise', 'signiﬁcant', 'ethical', 'question', 'highlight', 'need', 'robust', 'governance', 'safety', 'measure', 'development', 'inﬂuence', 'appear', 'extend', 'technical', 'achievement', 'shape', 'cultural', 'societal', 'discussion', 'role', 'future', 'ai', 'world', 'advancement', 'llm', 'include', 'development', 'model', 'gpt', 'pave', 'way', 'conceptualization', 'q', 'speciﬁcally', 'scalable', 'architecture', 'extensive', 'training', 'datum', 'characterize', 'model', 'foundational', 'propose', 'capability', 'q', 'success', 'chatgpt', 'contextual', 'understanding', 'con', 'versational', 'ai', 'example', 'inform', 'design', 'principle', 'q', 'suggest', 'trajectory', 'sophisticated', 'contextaware', 'adaptive', 'language', 'processing', 'capability', 'similarly', 'emergence', 'multimodal', 'system', 'gemini', 'capable', 'integrate', 'text', 'image', 'audio', 'video', 'reﬂect', 'evolutionary', 'path', 'q', 'extend', 'combine', 'versatility', 'llm', 'advanced', 'learning', 'pathﬁnde', 'algorithm', 'holistic', 'ai', 'solution', 'finetune', 'hallucination', 'reduction', 'alignment', 'llm', 'advancement', 'llm', 'underline', 'signiﬁcance', 'ﬁnetune', 'hallucination', 'reduction', 'alignment', 'aspect', 'crucial', 'enhance', 'functionality', 'reliability', 'llm', 'finetune', 'involve', 'adapt', 'pretraine', 'model', 'speciﬁc', 'task', 'see', 'signiﬁcant', 'progress', 'technique', 'promptbase', 'fewshot', 'learn', 'supervised', 'ﬁnetuning', 'specialized', 'dataset', 'enhance', 'adaptability', 'llm', 'various', 'context', 'challenge', 'remain', 'particularly', 'bias', 'mitigation', 'journal', 'latex', 'class', 'file', 'vol', 'generalization', 'model', 'diverse', 'task', 'hallucination', 'reduction', 'persistent', 'challenge', 'llm', 'characterize', 'generation', 'conﬁdent', 'factually', 'correct', 'information', 'strategy', 'conﬁdence', 'penalty', 'regularization', 'ﬁnetuning', 'implement', 'mitigate', 'overconﬁdence', 'improve', 'accuracy', 'effort', 'complexity', 'human', 'language', 'breadth', 'topic', 'make', 'completely', 'eradicate', 'hallucina', 'tion', 'daunting', 'task', 'especially', 'culturally', 'sensitive', 'alignment', 'ensure', 'llm', 'output', 'congruent', 'human', 'value', 'ethic', 'area', 'ongoing', 'research', 'innovative', 'approach', 'constrained', 'optimization', 'different', 'type', 'reward', 'model', 'aim', 'embed', 'human', 'preference', 'system', 'advancement', 'ﬁnetuning', 'hallucination', 'reduction', 'alignment', 'propel', 'llm', 'forward', 'area', 'still', 'present', 'considerable', 'challenge', 'complexity', 'align', 'diverse', 'spectrum', 'human', 'ethic', 'persistence', 'hallucination', 'particularly', 'culturally', 'sensi', 'tive', 'topic', 'highlight', 'need', 'continue', 'interdisciplinary', 'research', 'development', 'application', 'llm', 'mixture', 'expert', 'paradigm', 'shift', 'adoption', 'moe', 'architecture', 'llm', 'mark', 'critical', 'evolution', 'technology', 'innovative', 'approach', 'exempliﬁed', 'advanced', 'model', 'switch', 'transformer5', 'leverage', 'transformer', 'base', 'expert', 'module', 'dynamic', 'token', 'routing', 'enhance', 'modeling', 'efﬁciency', 'scalability', 'primary', 'advantage', 'moe', 'lie', 'ability', 'handle', 'vast', 'parameter', 'scale', 'reduc', 'memory', 'footprint', 'computational', 'cost', 'signiﬁcantly', 'achieve', 'model', 'parallelism', 'specialized', 'expert', 'allow', 'training', 'model', 'trillion', 'parameter', 'specialization', 'handle', 'diverse', 'datum', 'distribution', 'enhance', 'capability', 'fewshot', 'learning', 'complex', 'task', 'illustrate', 'practicality', 'moe', 'consider', 'application', 'healthcare', 'example', 'moebased', 'system', 'use', 'personalized', 'medicine', 'different', 'expert', 'module', 'specialize', 'various', 'aspect', 'patient', 'data', 'analysis', 'include', 'genomics', 'medical', 'imaging', 'electronic', 'health', 'record', 'approach', 'signiﬁcantly', 'enhance', 'diagnostic', 'accuracy', 'treatment', 'personalization', 'similarly', 'ﬁnance', 'moe', 'model', 'deploy', 'risk', 'assessment', 'expert', 'analyze', 'trend', 'regulatory', 'distinct', 'ﬁnancial', 'compliance', 'factor', 'indicator', 'market', 'beneﬁts', 'moe', 'confront', 'challenge', 'dynamic', 'routing', 'complexity', 'expert', 'imbalance', 'probability', 'dilu', 'tion', 'technical', 'hurdle', 'demand', 'sophisticated', 'solution', 'fully', 'harness', 'moe', 'potential', 'moreover', 'moe', 'offer', 'performance', 'gain', 'inherently', 'solve', 'ethical', 'alignment', 'issue', 'ai', 'complexity', 'specialization', 'moe', 'model', 'obscure', 'decisionmaking', 'process', 'complicate', 'effort', 'ensure', 'ethi', 'cal', 'compliance', 'alignment', 'human', 'value', 'paradigm', 'shift', 'moe', 'signiﬁes', 'major', 'leap', 'llm', 'development', 'offer', 'signiﬁcant', 'scalability', 'special', 'ization', 'advantage', 'ensure', 'safety', 'ethical', 'alignment', 'transparency', 'model', 'remain', 'paramount', 'concern', 'moe', 'architecture', 'technologically', 'advanced', 'entail', 'continued', 'interdisciplinary', 'research', 'governance', 'align', 'ai', 'broad', 'societal', 'value', 'ethical', 'standard', 'ai', 'future', 'interaction', 'advent', 'multimodal', 'mark', 'transformative', 'era', 'development', 'revolutionize', 'machine', 'interpret', 'interact', 'diverse', 'array', 'human', 'sensory', 'input', 'contextual', 'datum', 'gemini', 'redeﬁne', 'benchmark', 'multimodality', 'gem', 'ini', 'pioneer', 'multimodal', 'conversational', 'system', 'mark', 'signiﬁcant', 'shift', 'technology', 'surpass', 'traditional', 'textbase', 'llm', 'gpt3', 'even', 'multimodal', 'coun', 'terpart', 'architecture', 'design', 'incorporate', 'processing', 'diverse', 'data', 'type', 'text', 'image', 'audio', 'video', 'feat', 'facilitate', 'unique', 'multimodal', 'encoder', 'crossmodal', 'attention', 'network', 'multimodal', 'decoder', 'architectural', 'core', 'gemini', 'dualencod', 'structure', 'separate', 'encoder', 'visual', 'textual', 'datum', 'enable', 'sophisticated', 'multimodal', 'contextualization', 'architecture', 'believe', 'surpass', 'capability', 'singleencoder', 'system', 'allow', 'gemini', 'associate', 'textual', 'concept', 'image', 'region', 'achieve', 'compositional', 'understanding', 'scene', 'furthermore', 'gemini', 'integrate', 'structure', 'knowledge', 'employ', 'special', 'ized', 'training', 'paradigm', 'crossmodal', 'intelligence', 'set', 'new', 'benchmark', 'ai', 'claim', 'demonstrate', 'gemini', 'distinguish', 'chatgpt4', 'several', 'key', 'feature', 'breadth', 'modality', 'chatgpt4', 'marily', 'focus', 'text', 'document', 'image', 'handle', 'wide', 'range', 'modality', 'include', 'audio', 'video', 'extensive', 'range', 'allow', 'gemini', 'tackle', 'complex', 'task', 'understand', 'realworld', 'effectively', 'performance', 'gemini', 'ultra', 'excel', 'key', 'multimodality', 'benchmark', 'notably', 'massive', 'language', 'derstande', 'mmlu', 'encompass', 'diverse', 'array', 'domain', 'science', 'law', 'medicine', 'outperform', 'scalability', 'accessibility', 'gemini', 'available', 'tailor', 'version', 'ultra', 'pro', 'cater', 'range', 'application', 'datum', 'center', 'ondevice', 'task', 'level', 'ﬂexibility', 'yet', 'see', 'chatgpt4', 'code', 'generation', 'gemini', 'proﬁciency', 'understanding', 'generate', 'code', 'various', 'programming', 'lan', 'guage', 'advanced', 'offer', 'practical', 'application', 'capability', 'transparency', 'explainability', 'focus', 'explainabil', 'ity', 'set', 'apart', 'provide', 'justiﬁcation', 'output', 'enhance', 'user', 'trust', 'understanding', 'reasoning', 'process', '6https', 'advancement', 'gemini', 'realworld', 'mance', 'complex', 'reasoning', 'task', 'require', 'integration', 'journal', 'latex', 'class', 'file', 'vol', 'knowledge', 'modality', 'remain', 'thoroughly', 'evaluate', 'technical', 'challenge', 'multimodal', 'system', 'devel', 'opment', 'multimodal', 'system', 'face', 'several', 'technical', 'hur', 'dle', 'include', 'create', 'robust', 'diverse', 'dataset', 'manage', 'scalability', 'enhance', 'user', 'trust', 'system', 'interpretability', 'challenge', 'datum', 'skew', 'bias', 'prevalent', 'data', 'acquisition', 'annotation', 'issue', 'require', 'effective', 'dataset', 'management', 'employ', 'strate', 'gy', 'datum', 'augmentation', 'active', 'learning', 'transfer', 'learn', 'signiﬁcant', 'challenge', 'computational', 'demand', 'process', 'various', 'datum', 'stream', 'simultaneously', 'require', 'powerful', 'hardware', 'optimize', 'model', 'architecture', 'multiple', 'encoder', 'ad', 'vance', 'algorithm', 'multimodal', 'attention', 'mechanism', 'need', 'balance', 'attention', 'different', 'input', 'medium', 'resolve', 'conﬂict', 'modality', 'especially', 'pro', 'vide', 'contradictory', 'information', 'scalability', 'issue', 'extensive', 'computational', 'resource', 'need', 'exacerbate', 'limited', 'highperformance', 'hardware', 'avail', 'ability', 'also', 'press', 'need', 'calibrate', 'multimodal', 'encoder', 'compositional', 'scene', 'understanding', 'datum', 'integration', 'reﬁning', 'evaluation', 'metric', 'system', 'necessary', 'accurately', 'assess', 'performance', 'realworld', 'task', 'call', 'comprehensive', 'dataset', 'uniﬁed', 'benchmark', 'enhance', 'user', 'trust', 'system', 'interpretability', 'explainable', 'ai', 'multimodal', 'address', 'challenge', 'vital', 'advancement', 'multimodal', 'system', 'enable', 'seamless', 'intelligent', 'interaction', 'align', 'human', 'expectation', 'multimodal', 'text', 'ethical', 'social', 'text', 'expansion', 'multimodal', 'ai', 'system', 'introduce', 'beneﬁts', 'complex', 'ethical', 'social', 'challenge', 'extend', 'face', 'textbase', 'ai', 'commerce', 'transform', 'customer', 'engagement', 'inte', 'grate', 'visual', 'textual', 'auditory', 'datum', 'autonomous', 'vehicle', 'multimodality', 'enhance', 'safety', 'navigation', 'synthesize', 'datum', 'various', 'sensor', 'include', 'visual', 'radar', 'light', 'detection', 'range', 'lidar', 'still', 'deepfake', 'technology', 'ability', 'generate', 'convincingly', 'realistic', 'video', 'audio', 'image', 'critical', 'concern', 'multimodality', 'pose', 'risk', 'misinformation', 'manipulation', 'signiﬁcantly', 'impact', 'public', 'opinion', 'political', 'landscape', 'personal', 'reputation', 'thereby', 'compromise', 'authenticity', 'digital', 'medium', 'raise', 'issue', 'social', 'engineering', 'digital', 'forensic', 'distinguish', 'genuine', 'aigenerate', 'content', 'become', 'increasingly', 'challenge', 'privacy', 'concern', 'ampliﬁed', 'multimodal', 'ai', 'due', 'ability', 'process', 'correlate', 'diverse', 'data', 'source', 'potentially', 'lead', 'intrusive', 'surveillance', 'proﬁling', 'raise', 'question', 'consent', 'right', 'individual', 'especially', 'personal', 'medium', 'use', 'permission', 'ai', 'training', 'content', 'creation', 'moreover', 'multimodal', 'propagate', 'amplify', 'bias', 'stereotype', 'different', 'modality', 'unchecked', 'perpetuate', 'discrimination', 'social', 'inequity', 'make', 'imperative', 'address', 'algorithmic', 'bias', 'effectively', 'ethical', 'development', 'multimodal', 'system', 'require', 'robust', 'governance', 'framework', 'focus', 'transparency', 'consent', 'datum', 'handle', 'protocol', 'public', 'awareness', 'ethical', 'guideline', 'evolve', 'address', 'unique', 'challenge', 'pose', 'technology', 'include', 'set', 'standard', 'datum', 'usage', 'safeguarding', 'nonconsensual', 'exploita', 'tion', 'personal', 'information', 'additionally', 'development', 'literacy', 'program', 'crucial', 'help', 'society', 'understand', 'responsibly', 'interact', 'ai', 'technology', 'ﬁeld', 'progress', 'interdi', 'ciplinary', 'collaboration', 'key', 'ensure', 'system', 'develop', 'deploy', 'manner', 'align', 'societal', 'value', 'ethical', 'principle', 'speculative', 'advance', 'chronological', 'trend', 'dynamic', 'landscape', 'ai', 'speculative', 'capability', 'q', 'project', 'blend', 'llm', 'qlearne', 'star', 'embody', 'signiﬁcant', 'leap', 'forward', 'section', 'explore', 'evolutionary', 'trajectory', 'gamecentric', 'system', 'broad', 'application', 'anticipate', 'q', 'alphago', 'groundtruth', 'qstar', 'exploration', 'journey', 'alphago', 'gamecentric', 'ai', 'project', 'represent', 'signiﬁcant', 'paradigm', 'shift', 'ai', 'alphago', 'mastery', 'game', 'go', 'highlight', 'effectiveness', 'deep', 'learning', 'tree', 'search', 'algorithm', 'welldeﬁned', 'rulebased', 'environment', 'underscore', 'potential', 'ai', 'complex', 'strategy', 'decisionmake', 'however', 'speculate', 'move', 'conﬁne', 'aim', 'amalgamate', 'strength', 'reinforcement', 'learning', 'see', 'alphago', 'knowledge', 'creativity', 'versatility', 'llm', 'strategic', 'efﬁ', 'ciency', 'pathﬁnde', 'algorithm', 'blend', 'merge', 'pathﬁnde', 'algorithm', 'llm', 'enable', 'ai', 'system', 'transcend', 'board', 'game', 'conﬁne', 'natural', 'language', 'processing', 'interact', 'human', 'language', 'enable', 'nuance', 'interaction', 'mark', 'leap', 'ai', 'adept', 'structured', 'task', 'complex', 'humanlike', 'communication', 'reasoning', 'moreover', 'incorporation', 'qlearning', 'algorithm', 'enable', 'qstar', 'optimize', 'decision', 'path', 'learn', 'interaction', 'make', 'adaptable', 'intelligent', 'time', 'combination', 'technology', 'lead', 'ai', 'efﬁcient', 'problem', 'solve', 'also', 'creative', 'insightful', 'approach', 'speculative', 'advancement', 'gamefocuse', 'power', 'comprehensive', 'potential', 'illustrate', 'dynamic', 'everevolve', 'nature', 'research', 'open', 'possibility', 'ai', 'application', 'integrated', 'human', 'life', 'capable', 'handle', 'broad', 'range', 'task', 'great', 'autonomy', 'sophistication', 'bridge', 'structured', 'learning', 'creativity', 'antic', 'ipate', 'project', 'blending', 'qlearning', 'algorithm', 'creativity', 'llm', 'embody', 'groundbreaking', 'step', 'potentially', 'surpass', 'recent', 'innovation', 'gemini', 'fusion', 'suggest', 'q', 'point', 'integration', 'structured', 'goaloriente', 'learning', 'generative', 'creative', 'capability', 'combination', 'transcend', 'exist', 'achievement', 'leap', 'gemini', 'gemini', 'represent', 'signiﬁcant', 'journal', 'latex', 'class', 'file', 'vol', 'multimodal', 'combine', 'various', 'form', 'datum', 'input', 'text', 'image', 'audio', 'video', 'q', 'speculate', 'bring', 'profound', 'integration', 'creative', 'reasoning', 'structured', 'problemsolve', 'achieve', 'merge', 'precision', 'efﬁciency', 'algorithm', 'learning', 'adaptability', 'qlearne', 'complex', 'understanding', 'human', 'language', 'context', 'offer', 'llm', 'integration', 'enable', 'ai', 'system', 'process', 'analyze', 'complex', 'multimodal', 'datum', 'also', 'autonomously', 'navigate', 'structured', 'task', 'engage', 'creative', 'problemsolving', 'knowledge', 'generation', 'mirror', 'multifacete', 'nature', 'human', 'cognition', 'implication', 'potential', 'advancement', 'vast', 'suggest', 'application', 'span', 'capability', 'current', 'multimodal', 'sys', 'tem', 'gemini', 'align', 'deterministic', 'aspect', 'traditional', 'ai', 'algorithm', 'creative', 'generative', 'potential', 'llm', 'q', 'offer', 'holistic', 'approach', 'ai', 'development', 'bridge', 'gap', 'logical', 'rulebase', 'processing', 'ai', 'creative', 'abstract', 'think', 'characteristic', 'human', 'intelligence', 'anticipate', 'unveiling', 'q', 'merging', 'structured', 'learn', 'technique', 'creative', 'problemsolving', 'singular', 'advanced', 'framework', 'hold', 'promise', 'extend', 'also', 'signiﬁcantly', 'surpass', 'multimodal', 'capability', 'system', 'thus', 'herald', 'gamechange', 'era', 'domain', 'generative', 'showcase', 'potential', 'crucial', 'develop', 'ment', 'eagerly', 'await', 'ongoing', 'evolution', 'iii', 'current', 'generative', 'ai', 'research', 'taxonomy', 'ﬁeld', 'generative', 'ai', 'evolve', 'rapidly', 'necessitate', 'comprehensive', 'taxonomy', 'encompass', 'breadth', 'depth', 'research', 'domain', 'detail', 'table', 'taxonomy', 'categorize', 'key', 'area', 'inquiry', 'innovation', 'generative', 'ai', 'serve', 'foundational', 'framework', 'understand', 'current', 'state', 'ﬁeld', 'guide', 'complexity', 'evolve', 'model', 'architecture', 'advanced', 'training', 'methodology', 'diverse', 'application', 'domain', 'ethical', 'implication', 'frontier', 'emerge', 'gy', 'model', 'architecture', 'recurrent', 'neural', 'network', 'rnns', 'rnn', 'excel', 'realm', 'sequence', 'model', 'make', 'particularly', 'effective', 'task', 'involve', 'language', 'temporal', 'datum', 'architecture', 'speciﬁcally', 'design', 'process', 'sequence', 'datum', 'text', 'enable', 'capture', 'context', 'order', 'input', 'effectively', 'proﬁciency', 'handle', 'sequential', 'information', 'render', 'indispensable', 'application', 'require', 'deep', 'understanding', 'temporal', 'dynamic', 'datum', 'natural', 'language', 'task', 'timeserie', 'analysis', 'rnn', 'ability', 'maintain', 'sense', 'continuity', 'sequence', 'critical', 'asset', 'broad', 'ﬁeld', 'ai', 'especially', 'scenario', 'context', 'historical', 'datum', 'play', 'crucial', 'role', 'mixture', 'expert', 'moe', 'moe', 'model', 'signiﬁ', 'cantly', 'enhance', 'efﬁciency', 'deploy', 'model', 'parallelism', 'multiple', 'specialized', 'expert', 'module', 'able', 'model', 'leverage', 'transformerbase', 'module', 'dynamic', 'token', 'routing', 'scale', 'trillion', 'parameter', 'thereby', 'reduce', 'memory', 'footprint', 'computational', 'cost', 'moe', 'model', 'stand', 'ability', 'divide', 'computational', 'load', 'various', 'expert', 'specialize', 'different', 'aspect', 'datum', 'allow', 'handle', 'vast', 'scale', 'parameter', 'effectively', 'lead', 'efﬁcient', 'specialized', 'handling', 'complex', 'task', 'multimodal', 'model', 'multimodal', 'model', 'inte', 'grate', 'variety', 'sensory', 'input', 'text', 'vision', 'audio', 'crucial', 'achieve', 'comprehensive', 'understanding', 'complex', 'data', 'set', 'particularly', 'tran', 'formative', 'ﬁeld', 'medical', 'imaging', 'model', 'facilitate', 'accurate', 'dataefﬁcient', 'analysis', 'employ', 'multiview', 'pipeline', 'cross', 'attention', 'block', 'integration', 'diverse', 'sensory', 'input', 'allow', 'nuanced', 'detailed', 'interpretation', 'datum', 'enhance', 'model', 'ability', 'accurately', 'analyze', 'understand', 'various', 'type', 'mation', 'combination', 'different', 'datum', 'type', 'process', 'concurrently', 'enable', 'model', 'provide', 'holistic', 'view', 'make', 'especially', 'effective', 'tion', 'require', 'deep', 'multifaceted', 'understanding', 'complex', 'scenario', 'generative', 'model', 'architecture', 'see', 'signiﬁcant', 'development', 'key', 'domain', 'stand', 'b', 'training', 'technique', 'transformer', 'model', 'transformer', 'model', 'signiﬁ', 'cantly', 'revolutionize', 'ﬁeld', 'ai', 'especially', 'nlp', 'high', 'efﬁciency', 'scalability', 'employ', 'advanced', 'attention', 'mechanism', 'achieve', 'enhanced', 'contextual', 'processing', 'allow', 'subtle', 'understanding', 'interaction', 'model', 'also', 'make', 'notable', 'stride', 'computer', 'vision', 'evidence', 'development', 'vision', 'transformer', 'innovation', 'symbol', 'ize', 'extended', 'capability', 'transformer', 'model', 'area', 'object', 'detection', 'offer', 'improve', 'performance', 'also', 'increase', 'computational', 'efﬁciency', 'training', 'generative', 'model', 'leverage', 'key', 'technique', 'contribute', 'uniquely', 'ﬁeld', 'supervised', 'learning', 'supervised', 'learn', 'founda', 'tional', 'approach', 'ai', 'use', 'label', 'dataset', 'guide', 'model', 'accurate', 'prediction', 'integral', 'various', 'application', 'include', 'image', 'recogni', 'tion', 'nlp', 'recent', 'advancement', 'focus', 'develop', 'sophisticated', 'loss', 'function', 'regularization', 'technique', 'aim', 'enhance', 'performance', 'generalization', 'capability', 'supervised', 'learning', 'model', 'ensure', 'remain', 'robust', 'effec', 'tive', 'wide', 'range', 'task', 'datum', 'type', 'journal', 'latex', 'class', 'file', 'vol', 'table', 'comprehensive', 'taxonomy', 'current', 'generative', 'ai', 'llm', 'research', 'subdomain', 'transformer', 'model', 'key', 'focus', 'efﬁciency', 'scalability', 'description', 'optimize', 'network', 'structure', 'fast', 'processing', 'large', 'dataset', 'domain', 'model', 'architec', 'ture', 'training', 'technique', 'application', 'main', 'compliance', 'ethical', 'consider', 'ation', 'advanced', 'learn', 'ing', 'neural', 'recurrent', 'network', 'mixture', 'expert', 'multimodal', 'model', 'supervise', 'learn', 'unsupervised', 'learn', 'reinforcement', 'learn', 'transfer', 'learn', 'language', 'natural', 'understanding', 'natural', 'generation', 'conversational', 'ai', 'language', 'creative', 'bias', 'mitigation', 'datum', 'security', 'ai', 'ethic', 'privacy', 'preservation', 'selfsupervise', 'learn', 'metalearning', 'fine', 'tune', 'human', 'value', 'align', 'ment', 'emerge', 'trend', 'multimodal', 'learn', 'interactive', 'coop', 'erative', 'agi', 'containment', 'sequence', 'process', 'handle', 'sequence', 'datum', 'text', 'improve', 'contextual', 'understanding', 'specialization', 'efﬁciency', 'sensory', 'integration', 'datum', 'labeling', 'racy', 'pattern', 'discovery', 'adaptability', 'optimization', 'versatility', 'generalization', 'comprehension', 'con', 'textualization', 'creativity', 'coherence', 'interaction', 'natural', 'ness', 'innovation', 'artistic', 'generation', 'fairness', 'representa', 'tion', 'datum', 'protection', 'ﬁdentiality', 'fairness', 'accountability', 'privacy', 'compliance', 'anonymization', 'autonomy', 'efﬁciency', 'tune', 'integration', 'rapid', 'adaptation', 'domain', 'speciﬁc', 'personalization', 'ethical', 'societal', 'alignment', 'integration', 'sion', 'audio', 'collaboration', 'humanai', 'interaction', 'holistic', 'understand', 'safety', 'protocol', 'control', 'mechanism', 'leverage', 'multiple', 'expert', 'module', 'enhanced', 'efﬁciency', 'taskspeciﬁc', 'performance', 'integrate', 'text', 'vision', 'audio', 'input', 'comprehensive', 'understanding', 'use', 'label', 'dataset', 'train', 'model', 'precise', 'prediction', 'find', 'pattern', 'structure', 'unlabeled', 'data', 'training', 'model', 'feedback', 'mechanism', 'optimal', 'decisionmaking', 'apply', 'knowledge', 'gain', 'task', 'different', 'related', 'task', 'enhance', 'ability', 'understand', 'interpret', 'human', 'language', 'context', 'generating', 'coherent', 'contextually', 'relevant', 'text', 'response', 'develop', 'system', 'natural', 'contextually', 'relevant', 'humancomputer', 'conversation', 'generate', 'creative', 'content', 'include', 'text', 'art', 'music', 'address', 'reduce', 'bias', 'output', 'ensure', 'data', 'conﬁdentiality', 'integrity', 'availability', 'security', 'model', 'output', 'address', 'ethical', 'system', 'protect', 'datum', 'privacy', 'model', 'training', 'output', 'issue', 'bias', 'fairness', 'accountability', 'utilize', 'unlabeled', 'datum', 'model', 'training', 'enhance', 'learn', 'efﬁciency', 'enable', 'model', 'quickly', 'adapt', 'new', 'task', 'minimal', 'datum', 'adapt', 'model', 'speciﬁc', 'domain', 'user', 'preference', 'enhance', 'relevance', 'accuracy', 'align', 'output', 'human', 'ethic', 'societal', 'norm', 'ensure', 'decision', 'ethically', 'socially', 'responsible', 'combine', 'language', 'model', 'sensory', 'datum', 'type', 'rich', 'stand', 'enhance', 'ai', 'ability', 'work', 'human', 'collaborative', 'task', 'pursue', 'development', 'system', 'comprehensive', 'humanlike', 'understand', 'develop', 'method', 'contain', 'control', 'agi', 'system', 'prevent', 'unintended', 'consequence', 'unsupervised', 'learning', 'unsupervised', 'learning', 'es', 'sential', 'ai', 'uncover', 'pattern', 'unlabeled', 'task', 'feature', 'learn', 'datum', 'process', 'central', 'cluster', 'method', 'see', 'sig', 'niﬁcant', 'advancement', 'introduction', 'coder', 'generative', 'adversarial', 'network', 'gan', 'notably', 'expand', 'unsupervised', 'learning', 'applicability', 'enable', 'phisticated', 'data', 'generation', 'representation', 'learn', 'capability', 'innovation', 'crucial', 'understand', 'ing', 'leverage', 'complex', 'structure', 'often', 'inherent', 'unstructured', 'dataset', 'highlight', 'grow', 'versa', 'tility', 'depth', 'unsupervised', 'learn', 'technique', 'reinforcement', 'learning', 'reinforcement', 'learning', 'char', 'acterize', 'adaptability', 'optimization', 'capability', 'become', 'increasingly', 'vital', 'decisionmake', 'autonomous', 'system', 'training', 'technique', 'undergo', 'signiﬁcant', 'advancement', 'particularly', 'development', 'deep', 'qnetwork', 'dqn', 'proximal', 'policy', 'optimization', 'ppo', 'algorithm', 'enhancement', 'crucial', 'improve', 'efﬁcacy', 'applicability', 'reinforcement', 'learning', 'especially', 'complex', 'dynamic', 'environment', 'optimize', 'decision', 'poli', 'cie', 'interactive', 'feedback', 'loop', 'reinforcement', 'learning', 'establish', 'crucial', 'tool', 'training', 'ai', 'system', 'scenario', 'demand', 'high', 'degree', 'adaptability', 'precision', 'decisionmake', 'transfer', 'learn', 'transfer', 'learning', 'emphasize', 'ver', 'satility', 'efﬁciency', 'ai', 'train', 'allow', 'model', 'apply', 'knowledge', 'acquire', 'task', 'different', 'journal', 'latex', 'class', 'file', 'vol', 'yet', 'relate', 'task', 'signiﬁcantly', 'reduce', 'need', 'large', 'label', 'dataset', 'transfer', 'learn', 'use', 'pretraine', 'network', 'streamline', 'training', 'process', 'allow', 'model', 'efﬁciently', 'ﬁnetune', 'speciﬁc', 'application', 'thereby', 'enhance', 'adaptability', 'performance', 'diverse', 'task', 'prove', 'particularly', 'beneﬁcial', 'scenario', 'acquir', 'extensive', 'label', 'datum', 'impractical', 'unfeasible', 'c', 'application', 'domain', 'application', 'domain', 'generative', 'ai', 'remarkably', 'diverse', 'evolve', 'encompass', 'establish', 'emerge', 'area', 'research', 'application', 'domain', 'signiﬁcantly', 'inﬂuence', 'recent', 'advancement', 'technology', 'expand', 'scope', 'application', 'natural', 'language', 'understand', 'nlu', 'nlu', 'cen', 'tral', 'enhance', 'comprehension', 'contextualiza', 'tion', 'human', 'language', 'system', 'involve', 'key', 'capability', 'semantic', 'analysis', 'name', 'tity', 'recognition', 'sentiment', 'analysis', 'textual', 'entailment', 'machine', 'reading', 'comprehension', 'advance', 'nlu', 'crucial', 'improve', 'proﬁciency', 'interpreting', 'analyze', 'language', 'spectrum', 'range', 'ward', 'conversational', 'exchange', 'intricate', 'textual', 'datum', 'nlu', 'fundamental', 'application', 'sentiment', 'analysis', 'language', 'translation', 'information', 'extraction', 'recent', 'advance', 'ment', 'prominently', 'feature', 'large', 'transformerbase', 'model', 'signiﬁcantly', 'advance', 'ﬁeld', 'enable', 'deep', 'com', 'plex', 'understanding', 'language', 'subtletie', 'natural', 'language', 'generation', 'nlg', 'phasize', 'training', 'model', 'generate', 'coherent', 'contextuallyrelevant', 'creative', 'text', 'response', 'crit', 'ical', 'component', 'chatbot', 'virtual', 'assistant', 'auto', 'mate', 'content', 'creation', 'tool', 'nlg', 'encompasse', 'challenge', 'topic', 'model', 'ing', 'discourse', 'planning', 'concepttotext', 'generation', 'style', 'transfer', 'controllable', 'text', 'generation', 'recent', 'surge', 'capability', 'exempliﬁed', 'advanced', 'model', 'gpt3', 'signiﬁcantly', 'enhance', 'sophistication', 'nuance', 'text', 'generation', 'enable', 'ai', 'system', 'produce', 'text', 'closely', 'mirror', 'human', 'writing', 'style', 'thereby', 'broaden', 'scope', 'applicability', 'various', 'interactive', 'creative', 'context', 'conversational', 'ai', 'subdomain', 'dedicate', 'develop', 'system', 'capable', 'smooth', 'natural', 'contextaware', 'humancomputer', 'interaction', 'focus', 'dialogue', 'modeling', 'question', 'answer', 'user', 'intent', 'recognition', 'multiturn', 'context', 'track', 'ﬁnance', 'cybersecurity', 'ai', 'predictive', 'analytic', 'transform', 'risk', 'assessment', 'fraud', 'detection', 'lead', 'secure', 'efﬁcient', 'operation', 'advancement', 'area', 'demonstrate', 'large', 'pretraine', 'model', 'meena7', 'blenderbot8', 'signiﬁcantly', 'enhance', 'empathetic', 'respon', 'sive', 'capability', 'interaction', 'system', 'improve', 'user', 'engagement', 'satisfaction', 'also', 'maintain', 'ﬂow', 'conversation', 'multiple', 'turn', 'provide', 'coherent', 'contextually', 'relevant', 'engage', 'experience', 'creative', 'emerge', 'subdomain', 'span', 'text', 'art', 'music', 'push', 'boundary', 'ai', 'creative', 'innovative', 'potential', 'various', 'modality', 'include', 'image', 'audio', 'video', 'engage', 'generation', 'artistic', 'content', 'encompass', 'application', 'idea', 'generation', 'storytelle', 'poetry', 'music', 'composi', 'tion', 'visual', 'art', 'creative', 'writing', 'result', 'commercial', 'success', 'midjourney', 'dalle', 'challenge', 'ﬁeld', 'involve', 'ﬁnde', 'suitable', 'datum', 'representation', 'algorithm', 'evaluation', 'metric', 'effectively', 'assess', 'foster', 'creativity', 'creative', 'serve', 'tool', 'automate', 'enhance', 'artistic', 'process', 'also', 'medium', 'explore', 'new', 'form', 'artistic', 'expression', 'enable', 'creation', 'novel', 'diverse', 'creative', 'output', 'domain', 'represent', 'signiﬁcant', 'leap', 'capability', 'engage', 'contribute', 'creative', 'endeavor', 'redeﬁne', 'intersection', 'technology', 'art', 'compliance', 'ethical', 'consideration', 'technology', 'rapidly', 'evolve', 'become', 'tegrated', 'various', 'sector', 'ethical', 'consideration', 'legal', 'compliance', 'become', 'increasingly', 'crucial', 'require', 'focus', 'develop', 'ethical', 'ai', 'framework', 'new', 'category', 'taxonomy', 'reﬂecte', 'trend', 'responsible', 'ai', 'development', 'generative', 'ai', 'framework', 'crucial', 'ensure', 'system', 'build', 'core', 'emphasis', 'ethical', 'consideration', 'fairness', 'transparency', 'address', 'critical', 'aspect', 'bias', 'mitigation', 'fairness', 'privacy', 'security', 'concern', 'datum', 'protection', 'ai', 'ethic', 'accountability', 'thus', 'respond', 'evolve', 'landscape', 'accountability', 'paramount', 'importance', 'need', 'rigorous', 'approach', 'uphold', 'ethical', 'integrity', 'legal', 'conformity', 'never', 'press', 'reﬂecte', 'complexity', 'multifaceted', 'challenge', 'introduce', 'adoption', 'technology', 'bias', 'mitigation', 'bias', 'mitigation', 'system', 'critical', 'endeavor', 'ensure', 'fairness', 'representation', 'involve', 'balanced', 'datum', 'collection', 'avoid', 'skewed', 'perspective', 'also', 'involve', 'implement', 'algorithmic', 'adjustment', 'regularization', 'technique', 'minimize', 'bias', 'continuous', 'monitoring', 'bias', 'testing', 'essential', 'identify', 'address', 'bias', 'emerge', 'predictive', 'pattern', 'signiﬁcant', 'challenge', 'area', 'deal', 'intersectional', 'bias', 'blenderbotai', 'journal', 'latex', 'class', 'file', 'vol', 'understand', 'causal', 'interaction', 'contribute', 'bias', 'datum', 'security', 'security', 'key', 'requirement', 'challenge', 'include', 'ensure', 'data', 'conﬁdentiality', 'adhere', 'consent', 'norm', 'safeguard', 'vulnerability', 'membership', 'inference', 'attack', 'compli', 'ance', 'stringent', 'legal', 'standard', 'applicable', 'diction', 'general', 'datum', 'protection', 'regulation', 'gdpr', 'consumer', 'act', 'essential', 'necessitating', 'purpose', 'limitation', 'datum', 'minimization', 'additionally', 'issue', 'datum', 'sovereignty', 'copyright', 'emphasize', 'need', 'robust', 'encryption', 'access', 'control', 'continuous', 'security', 'assessment', 'effort', 'critical', 'maintain', 'integrity', 'system', 'protect', 'user', 'privacy', 'evolve', 'digital', 'landscape', 'ai', 'ethic', 'ﬁeld', 'ethic', 'focus', 'fairness', 'accountability', 'societal', 'impact', 'address', 'surge', 'ethical', 'challenge', 'pose', 'increase', 'complexity', 'potential', 'misalignment', 'human', 'value', 'quire', 'ethical', 'governance', 'framework', 'multidisciplinary', 'collaboration', 'technological', 'solution', 'furthermore', 'ai', 'ethic', 'involve', 'ensure', 'traceability', 'auditability', 'transparency', 'model', 'development', 'lifecycle', 'employing', 'practice', 'algorithmic', 'auditing', 'establish', 'ethic', 'board', 'ad', 'hering', 'documentation', 'standard', 'model', 'card', 'however', 'adoption', 'initiative', 'remain', 'uneven', 'highlight', 'ongoing', 'need', 'comprehensive', 'consistent', 'ethical', 'practice', 'development', 'deployment', 'privacy', 'preservation', 'domain', 'focus', 'maintain', 'ing', 'datum', 'conﬁdentiality', 'integrity', 'employing', 'strategy', 'anonymization', 'federate', 'learn', 'minimize', 'direct', 'data', 'exposure', 'especially', 'rise', 'tive', 'ai', 'pose', 'risk', 'user', 'proﬁle', 'effort', 'challenge', 'achieve', 'true', 'anonymity', 'correlation', 'attack', 'highlight', 'complexity', 'effectively', 'protect', 'intrusive', 'surveillance', 'ensure', 'compliance', 'privacy', 'law', 'plemente', 'secure', 'datum', 'handling', 'practice', 'crucial', 'context', 'demonstrate', 'continuous', 'need', 'robust', 'privacy', 'preservation', 'mechanism', 'e', 'advance', 'learn', 'advanced', 'learn', 'technique', 'include', 'selfsupervise', 'learn', 'metalearning', 'ﬁnetuning', 'forefront', 'research', 'enhance', 'autonomy', 'efﬁciency', 'ver', 'satility', 'model', 'selfsupervise', 'learning', 'method', 'emphasize', 'au', 'tonomous', 'model', 'training', 'use', 'unlabeled', 'datum', 'reduce', 'manual', 'labeling', 'effort', 'model', 'bias', 'incorporate', 'generative', 'model', 'autoencoder', 'gan', 'datum', 'distribution', 'learning', 'original', 'input', 'reconstruction', 'also', 'include', 'contrastive', 'method', 'simclr', 'moco', 'design', 'differentiate', 'positive', 'negative', 'sample', 'pair', 'far', 'employ', 'selfprediction', 'strategy', 'inspire', 'nlp', 'use', 'technique', 'mask', 'input', 'reconstruction', 'signiﬁcantly', 'enhance', 'recent', 'vision', 'transformer', 'development', 'integration', 'varied', 'method', 'highlight', 'self', 'supervise', 'learn', 'role', 'advance', 'autonomous', 'training', 'capability', 'metalearning', 'metalearning', 'learn', 'learn', 'center', 'equip', 'model', 'ability', 'rapidly', 'adapt', 'new', 'task', 'domain', 'use', 'limited', 'datum', 'sample', 'technique', 'involve', 'master', 'optimization', 'process', 'critical', 'situation', 'limited', 'data', 'availability', 'ensure', 'model', 'quickly', 'adapt', 'perform', 'diverse', 'task', 'essential', 'current', 'datadriven', 'landscape', 'focus', 'fewshot', 'generalization', 'enable', 'ai', 'handle', 'wide', 'range', 'task', 'minimal', 'datum', 'underline', 'impor', 'tance', 'develop', 'versatile', 'adaptable', 'ai', 'system', 'fine', 'tuning', 'involve', 'customizing', 'pretraine', 'model', 'speciﬁc', 'domain', 'user', 'preference', 'enhance', 'accuracy', 'relevance', 'niche', 'application', 'primary', 'approach', 'endtoend', 'ﬁnetune', 'adjust', 'weight', 'encoder', 'classiﬁer', 'featureextraction', 'ﬁnetune', 'encoder', 'weight', 'freeze', 'extract', 'feature', 'downstream', 'classiﬁer', 'tech', 'nique', 'ensure', 'generative', 'model', 'effectively', 'adapt', 'speciﬁc', 'user', 'need', 'domain', 'requirement', 'make', 'versatile', 'applicable', 'various', 'context', 'human', 'value', 'alignment', 'emerge', 'aspect', 'centrate', 'harmonize', 'ai', 'model', 'human', 'ethic', 'value', 'ensure', 'decision', 'action', 'mirror', 'societal', 'norm', 'ethical', 'standard', 'involve', 'integration', 'ethical', 'decisionmaking', 'process', 'adaptation', 'output', 'conform', 'human', 'moral', 'value', 'increasingly', 'important', 'scenario', 'ai', 'interact', 'closely', 'human', 'healthcare', 'ﬁnance', 'personal', 'assistant', 'ensure', 'ai', 'system', 'make', 'decision', 'technically', 'sound', 'also', 'ethically', 'socially', 'responsible', 'mean', 'human', 'value', 'alignment', 'become', 'crucial', 'develop', 'system', 'trust', 'accept', 'society', 'emerge', 'trend', 'emerge', 'trend', 'generative', 'ai', 'research', 'shape', 'future', 'technology', 'human', 'interaction', 'indicate', 'dynamic', 'shift', 'interactive', 'integrated', 'intelligent', 'system', 'drive', 'forward', 'boundary', 'possible', 'realm', 'ai', 'key', 'development', 'area', 'include', 'multimodal', 'learn', 'multimodal', 'learn', 'rapidly', 'evolve', 'subdomain', 'focus', 'combine', 'lan', 'guage', 'understanding', 'computer', 'vision', 'audio', 'processing', 'achieve', 'rich', 'multisensory', 'context', 'journal', 'latex', 'class', 'file', 'vol', 'awareness', 'recent', 'development', 'gem', 'model', 'set', 'new', 'benchmark', 'demonstrate', 'stateoftheart', 'performance', 'various', 'multimodal', 'task', 'include', 'natural', 'image', 'audio', 'video', 'understanding', 'mathematical', 'reasoning', 'gemini', 'inherently', 'multimodal', 'design', 'exempliﬁes', 'seamless', 'integration', 'operation', 'different', 'information', 'type', 'advancement', 'ﬁeld', 'multimodal', 'learn', 'still', 'confront', 'ongoing', 'challenge', 'reﬁne', 'architecture', 'handle', 'diverse', 'datum', 'type', 'fectively', 'develop', 'comprehensive', 'dataset', 'accurately', 'represent', 'multifaceted', 'information', 'establish', 'benchmark', 'evaluate', 'performance', 'complex', 'system', 'interactive', 'cooperative', 'ai', 'subdomain', 'aim', 'enhance', 'capability', 'ai', 'model', 'collaborate', 'fectively', 'human', 'complex', 'task', 'trend', 'focus', 'develop', 'ai', 'system', 'work', 'human', 'thereby', 'improve', 'user', 'experience', 'efﬁciency', 'various', 'application', 'include', 'tivity', 'healthcare', 'core', 'aspect', 'subdomain', 'involve', 'advance', 'ai', 'area', 'explainability', 'understand', 'human', 'intention', 'behavior', 'theory', 'mind', 'scalable', 'coor', 'dination', 'system', 'human', 'collaborative', 'approach', 'crucial', 'create', 'intuitive', 'interactive', 'ai', 'system', 'capable', 'assist', 'augment', 'human', 'capability', 'diverse', 'agi', 'development', 'agi', 'represent', 'visionary', 'goal', 'craft', 'ai', 'system', 'emulate', 'comprehensive', 'multifaceted', 'aspect', 'human', 'cognition', 'sub', 'domain', 'focus', 'develop', 'ai', 'capability', 'holistic', 'understanding', 'complex', 'reasoning', 'closely', 'align', 'depth', 'breadth', 'human', 'cognitive', 'ability', 'agi', 'replicate', 'human', 'intelligence', 'also', 'involve', 'craft', 'system', 'autonomously', 'perform', 'variety', 'task', 'demonstrating', 'adaptability', 'learn', 'capability', 'akin', 'human', 'pursuit', 'agi', 'longterm', 'aspiration', 'continually', 'push', 'boundary', 'research', 'development', 'agi', 'containment', 'agi', 'safety', 'containment', 'knowledge', 'potential', 'risk', 'associate', 'highly', 'advanced', 'system', 'focus', 'ensure', 'ad', 'vance', 'system', 'technically', 'proﬁcient', 'also', 'ethically', 'align', 'human', 'value', 'societal', 'norm', 'progress', 'develop', 'superintelligent', 'system', 'become', 'crucial', 'establish', 'rigorous', 'safety', 'protocol', 'control', 'mechanism', 'key', 'area', 'concern', 'include', 'mitigate', 'representational', 'bias', 'address', 'distribution', 'shift', 'correct', 'spu', 'rious', 'correlation', 'model', 'objective', 'prevent', 'unintended', 'societal', 'consequence', 'align', 'development', 'responsible', 'ethical', 'standard', 'training', 'efﬁciency', 'load', 'balance', 'core', 'concept', 'parallelism', 'technique', 'future', 'direction', 'figure', 'conceptual', 'diagram', 'moe', 'innovation', 'innovative', 'horizon', 'moe', 'moe', 'model', 'architecture', 'represent', 'pioneer', 'ad', 'vancement', 'transformerbase', 'language', 'model', 'offer', 'unparalleled', 'scalability', 'efﬁciency', 'fig', 'evidence', 'recent', 'model', 'parameter', 'former', '8x7b', 'parameter', 'mixtra', 'moe', 'base', 'design', 'rapidly', 'redeﬁne', 'frontier', 'model', 'scale', 'performance', 'diverse', 'language', 'task', 'core', 'concept', 'structure', 'moe', 'model', 'represent', 'signiﬁcant', 'innovation', 'neural', 'network', 'design', 'offer', 'enhanced', 'scalability', 'efﬁciency', 'training', 'inference', 'core', 'moe', 'model', 'utilize', 'sparsitydriven', 'architecture', 'replace', 'dense', 'layer', 'sparse', 'moe', 'layer', 'comprise', 'multiple', 'expert', 'network', 'expert', 'dedicate', 'speciﬁc', 'subset', 'training', 'datum', 'task', 'trainable', 'gating', 'mechanism', 'dynamically', 'allocate', 'input', 'token', 'expert', 'thereby', 'optimize', 'computational', 'resource', 'effectively', 'adapt', 'task', 'complexity', 'moe', 'model', 'demon', 'strate', 'substantial', 'advantage', 'term', 'pretraine', 'speed', 'outperform', 'dense', 'model', 'however', 'face', 'challenge', 'ﬁnetuning', 'require', 'substantial', 'memory', 'inference', 'necessity', 'load', 'expert', 'video', 'random', 'access', 'memory', 'vram', 'structure', 'moe', 'involve', 'alternate', 'transformer', 'layer', 'router', 'layer', 'contain', 'gate', 'network', 'expert', 'route', 'lead', 'architecture', 'allow', 'signiﬁcant', 'parameter', 'scaling', 'advanced', 'specialization', 'problemsolve', 'distinguish', 'characteristic', 'moe', 'model', 'ﬂexi', 'bility', 'manage', 'large', 'dataset', 'capable', 'amplify', 'model', 'capacity', 'time', 'experience', 'minor', 'reduction', 'computational', 'efﬁciency', 'sparselygate', 'mixtureofexpert', 'layer', 'key', 'component', 'model', 'comprise', 'numerous', 'simple', 'feedforward', 'expert', 'network', 'trainable', 'gate', 'network', 'responsible', 'expert', 'selection', 'facilitate', 'dynamic', 'sparse', 'activation', 'expert', 'input', 'instance', 'maintain', 'high', 'computational', 'efﬁciency', 'recent', 'advancement', 'moe', 'model', 'switch', 'transformer', 'highlight', 'signiﬁcant', 'beneﬁts', 'intelligent', 'routing', 'router', 'ability', 'intelligently', 'journal', 'latex', 'class', 'file', 'vol', 'route', 'token', 'appropriate', 'expert', 'confer', 'considerable', 'ad', 'vantage', 'moe', 'model', 'allow', 'scale', 'model', 'size', 'keep', 'compute', 'time', 'constant', 'experimental', 'evidence', 'suggest', 'router', 'learn', 'route', 'input', 'accord', 'data', 'cluster', 'demonstrate', 'potential', 'realworld', 'application', 'core', 'concept', 'structure', 'moe', 'model', 'lie', 'dynamic', 'routing', 'specialization', 'capability', 'offer', 'promise', 'avenue', 'scale', 'neural', 'network', 'enhance', 'efﬁciency', 'adaptability', 'various', 'task', 'robustness', 'router', 'protect', 'adversarial', 'attack', 'training', 'inference', 'efﬁciency', 'moe', 'model', 'notably', 'mixtral', '8x7b', 'renowne', 'superior', 'pretraining', 'speed', 'compare', 'dense', 'model', 'yet', 'face', 'hurdle', 'ﬁnetuning', 'demand', 'considerable', 'vram', 'inference', 'owe', 'requirement', 'load', 'expert', 'recent', 'advancement', 'moe', 'architecture', 'result', 'notable', 'training', 'cost', 'efﬁciencie', 'especially', 'encoderdecod', 'model', 'evidence', 'show', 'cost', 'saving', 'ﬁvefold', 'certain', 'context', 'compare', 'dense', 'model', 'innovation', 'deepspee', 'moe', 'offer', 'new', 'architectural', 'design', 'model', 'com', 'pression', 'decrease', 'moe', 'model', 'size', 'approximately', '37x', 'optimize', 'inference', 'achieve', 'well', 'latency', 'cost', 'efﬁciency', 'progression', 'distribute', 'moe', 'training', 'inference', 'notably', 'innovation', 'lina', 'effectively', 'tackle', 'alltoall', 'communication', 'bottleneck', 'enhance', 'tensor', 'partitioning', 'improve', 'communication', 'training', 'step', 'time', 'also', 'optimize', 'resource', 'scheduling', 'inference', 'lead', 'substantial', 'reduction', 'training', 'step', 'time', 'time', 'lower', '95th', 'percentile', 'inference', 'time', 'average', 'time', 'compare', 'exist', 'system', 'development', 'mark', 'crucial', 'shift', 'large', 'model', 'landscape', 'dense', 'sparse', 'moe', 'model', 'expand', 'potential', 'application', 'ai', 'train', 'higherquality', 'model', 'resource', 'c', 'load', 'balancing', 'router', 'optimization', 'effective', 'load', 'balancing', 'essential', 'moe', 'model', 'guarantee', 'uniform', 'distribution', 'computational', 'load', 'expert', 'router', 'network', 'moe', 'layer', 'responsible', 'select', 'appropriate', 'expert', 'processing', 'speciﬁc', 'token', 'play', 'pivotal', 'role', 'achieve', 'balance', 'funda', 'mental', 'stability', 'overall', 'performance', 'moe', 'model', 'development', 'router', 'z', 'loss', 'regularization', 'technique', 'play', 'crucial', 'role', 'address', 'expert', 'imbalance', 'moe', 'model', 'ﬁnetune', 'gate', 'mechanism', 'ensure', 'equitable', 'workload', 'distribution', 'expert', 'foster', 'stable', 'training', 'environment', 'thereby', 'enhance', 'model', 'performance', 'reduce', 'training', 'time', 'computational', 'overhead', 'concurrently', 'integration', 'expert', 'capacity', 'management', 'strategy', 'emerge', 'crucial', 'approach', 'moe', 'model', 'regulate', 'processing', 'ability', 'individual', 'expert', 'set', 'threshold', 'number', 'token', 'handle', 'effectively', 'avert', 'bottleneck', 'ensure', 'efﬁcient', 'streamlined', 'model', 'operation', 'lead', 'improved', 'training', 'process', 'heighten', 'performance', 'complex', 'computational', 'task', 'parallelism', 'serve', 'technique', 'recent', 'development', 'moe', 'model', 'highlight', 'ﬁciency', 'parallelism', 'serve', 'technique', 'signiﬁcantly', 'inﬂuence', 'largescale', 'neural', 'network', 'deepspeedmoe', 'instance', 'introduce', 'advanced', 'parallelism', 'mode', 'datum', 'allelism', 'tensorslicing', 'nonexpert', 'parameter', 'expert', 'parallelism', 'expert', 'parameter', 'enhance', 'model', 'efﬁciency', 'approach', 'optimize', 'latency', 'throughput', 'moe', 'model', 'inference', 'offer', 'scalable', 'solution', 'environment', 'use', 'multiple', 'graphic', 'processing', 'unit', 'device', 'moe', 'model', 'versatile', 'application', 'multilingual', 'task', 'code', 'demonstrate', 'impressive', 'capability', 'handle', 'complex', 'task', 'ensemble', 'structure', 'single', 'framework', 'notably', 'model', 'mixtral', 'switch', 'transformer', 'parameter', 'achieve', 'computational', 'efﬁciency', 'equivalent', 'billionparameter', 'dense', 'model', 'beneﬁte', 'sublinear', 'scaling', 'moe', 'compute', 'model', 'size', 'lead', 'substantial', 'accuracy', 'gain', 'ﬁxe', 'compute', 'budget', 'moreover', 'deepspeedmoe', 'include', 'model', 'compression', 'technique', 'duce', 'model', 'size', '37x', 'maintain', 'accuracy', 'endtoend', 'moe', 'training', 'inference', 'solution', 'part', 'deepspeed', 'library', 'instrumental', 'serv', 'largescale', 'moe', 'model', 'enhance', 'speed', 'cost', 'efﬁciency', 'innovation', 'open', 'new', 'direction', 'shift', 'dense', 'sparse', 'moe', 'model', 'training', 'deploy', 'higherquality', 'model', 'resource', 'become', 'widely', 'achievable', 'e', 'future', 'direction', 'application', 'emerge', 'research', 'moe', 'architecture', 'focus', 'advance', 'sparse', 'ﬁnetune', 'technique', 'explore', 'instruction', 'tuning', 'method', 'improve', 'route', 'algorithm', 'fully', 'utilize', 'performance', 'efﬁciency', 'gain', 'model', 'scale', 'parameter', 'moe', 'represent', 'paradigm', 'shift', 'vastly', 'expand', 'capability', 'scientiﬁc', 'medical', 'creative', 'realworld', 'application', 'frontier', 'work', 'also', 'aim', 'reﬁne', 'autotune', 'hyperparameter', 'ﬁne', 'tuning', 'optimize', 'accuracy', 'calibration', 'safety', 'moe', 'search', 'continue', 'push', 'model', 'scale', 'limit', 'maintain', 'specialization', 'transfer', 'learn', 'adaptive', 'sparse', 'access', 'allow', 'coordinate', 'thousand', 'expert', 'cooperate', 'task', 'range', 'reason', 'open', 'domain', 'dialogue', 'continue', 'analysis', 'route', 'mechanism', 'seek', 'balance', 'load', 'expert', 'minimize', 'redundant', 'computation', 'community', 'far', 'investigate', 'moe', 'method', 'scale', 'model', 'hold', 'promise', 'new', 'breakthrough', 'language', 'code', 'generation', 'reasoning', 'multimodal', 'application', 'great', 'interest', 'evaluate', 'implication', 'education', 'healthcare', 'ﬁnancial', 'analysis', 'ﬁeld', 'outcome', 'yield', 'insight', 'model', 'optimization', 'also', 'understand', 'principle', 'combinatorial', 'generalization', 'journal', 'latex', 'class', 'file', 'vol', 'humanlevel', 'understand', 'self', 'learning', 'exploration', 'general', 'intelligence', 'integration', 'common', 'sense', 'reasoning', 'figure', 'conceptual', 'diagram', 'speculate', 'q', 'capability', 'speculate', 'capability', 'q', 'burgeon', 'realm', 'ai', 'anticipate', 'q', 'project', 'stand', 'beacon', 'potential', 'breakthrough', 'herald', 'ad', 'vancement', 'redeﬁne', 'landscape', 'capability', 'fig', 'enhance', 'general', 'intelligence', 'development', 'arena', 'general', 'resent', 'paradigm', 'shift', 'ai', 'indi', 'cat', 'broadening', 'model', 'cognitive', 'ability', 'akin', 'human', 'intelligence', 'advanced', 'form', 'general', 'intelligence', 'involve', 'integrate', 'diverse', 'neural', 'network', 'architecture', 'machine', 'learn', 'technique', 'enable', 'ai', 'process', 'synthesize', 'multifacete', 'information', 'seamlessly', 'universal', 'adapter', 'approach', 'mirroring', 'model', 'endow', 'q', 'capability', 'rapidly', 'assimilate', 'knowledge', 'various', 'domain', 'method', 'allow', 'q', 'learn', 'adaptable', 'module', 'plugin', 'enhance', 'ability', 'tackle', 'new', 'datum', 'type', 'preserve', 'exist', 'skill', 'lead', 'ai', 'model', 'combine', 'narrow', 'specialization', 'comprehensive', 'adaptive', 'versatile', 'reasoning', 'system', 'correspond', 'quasimathematical', 'formulation', 'express', 'q∗', 'enhance', 'general', 'intelligence', 'diverse', 'set', 'neural', 'network', 'architecture', 'lti', 'various', 'machine', 'learn', 'technique', 'l', 'integration', 'component', '⊙', 'functional', 'interaction', 'neural', 'network', 'machine', 'learn', 'technique', 'advancement', 'ai', 'suggest', 'emergence', 'intel', 'ligence', 'parallel', 'potentially', 'exceed', 'human', 'cognitive', 'ﬂexibility', 'farreache', 'implication', 'facil', 'itate', 'crossdisciplinary', 'innovation', 'complex', 'problem', 'solve', 'speculate', 'capability', 'q', 'bring', 'forth', 'com', 'plex', 'ethical', 'implication', 'governance', 'challenge', 'system', 'approach', 'high', 'level', 'autonomy', 'decision', 'make', 'crucial', 'establish', 'robust', 'ethical', 'framework', 'governance', 'structure', 'ensure', 'responsible', 'transparent', 'ai', 'development', 'involve', 'mitigate', 'potential', 'risk', 'ate', 'advanced', 'capability', 'emphasize', 'need', 'comprehensive', 'dynamic', 'ethical', 'guideline', 'evolve', 'tandem', 'advancement', 'b', 'advanced', 'selflearning', 'exploration', 'realm', 'advanced', 'development', 'q', 'antici', 'pat', 'represent', 'signiﬁcant', 'evolution', 'selflearning', 'exploration', 'capability', 'speculate', 'utilize', 'sophisticated', 'policy', 'neural', 'network', 'nn', 'similar', 'alphago', 'substantial', 'enhancement', 'handle', 'complexity', 'language', 'reasoning', 'task', 'network', 'expect', 'employ', 'advanced', 'reinforcement', 'learning', 'technique', 'proximal', 'policy', 'optimization', 'ppo', 'stabilize', 'policy', 'update', 'improve', 'sample', 'efﬁciency', 'crucial', 'factor', 'autonomous', 'learning', 'integration', 'nn', 'cuttingedge', 'search', 'algorithm', 'potentially', 'include', 'novel', 'iteration', 'tree', 'graph', 'thought', 'predict', 'able', 'q', 'autonomously', 'navigate', 'assimilate', 'complex', 'information', 'approach', 'augment', 'graph', 'neural', 'network', 'bolster', 'metalearning', 'capacity', 'allow', 'q', 'rapidly', 'adapt', 'new', 'task', 'environment', 'retain', 'previously', 'acquire', 'knowledge', 'correspond', 'quasimathematical', 'formulation', 'represent', 'asle', 'q∗', 'rl', 'n', 'asle', 'advanced', 'selflearning', 'exploration', 'rl', 'reinforcement', 'learning', 'algorithm', 'particularly', 'proximal', 'policy', 'optimization', 'ppo', '•', 'p', 'n', 'policy', 'neural', 'network', 'adapt', 'language', 'reasoning', 'task', 'sophisticated', 'search', 'algorithm', 'tree', 'graph', 'thought', 'n', 'incorporation', 'graph', 'neural', 'network', 'metalearning', 'crossfunctional', 'enhancement', 'rl', 'capability', 'indicate', 'model', 'limit', 'understand', 'ing', 'exist', 'datum', 'equip', 'actively', 'seek', 'synthesize', 'new', 'knowledge', 'effectively', 'adapt', 'evolve', 'scenario', 'need', 'frequent', 'retraining', 'signiﬁes', 'leap', 'current', 'model', 'embed', 'level', 'autonomy', 'efﬁciency', 'previously', 'unattaine', 'c', 'superior', 'humanlevel', 'understand', 'q', 'aspiration', 'achieve', 'superior', 'humanlevel', 'standing', 'speculate', 'hinge', 'advanced', 'integration', 'multiple', 'neural', 'network', 'include', 'value', 'neural', 'net', 'work', 'parallel', 'evaluative', 'component', 'find', 'system', 'alphago', 'network', 'extend', 'assess', 'accuracy', 'relevance', 'language', 'reasoning', 'process', 'delve', 'subtlety', 'model', 'deep', 'comprehension', 'capability', 'enhance', 'advanced', 'natural', 'language', 'processing', 'algorithm', 'technique', 'find', 'transformer', 'architec', 'ture', 'algorithm', 'empower', 'q', 'interpret', 'text', 'also', 'nuance', 'socioemotional', 'aspect', 'intent', 'emotion', 'underlying', 'meaning', 'journal', 'latex', 'class', 'file', 'vol', 'incorporate', 'sentiment', 'analysis', 'natural', 'language', 'infer', 'ence', 'q', 'navigate', 'layer', 'socioemotional', 'insight', 'include', 'empathy', 'sarcasm', 'attitude', 'correspond', 'quasimathematical', 'formulation', 'express', 'shlu', 'q∗', 'n', 'alg∈n', 'lp', 'shlu', 'superior', 'humanlevel', 'understanding', '•', 'n', 'value', 'neural', 'network', 'similar', 'evaluative', 'component', 'system', 'alphago', '•', 'n', 'lp', 'set', 'advanced', 'nlp', 'algorithm', '•', '⊕', 'combination', 'evaluation', 'individual', 'algorithm', 'nlp', 'set', 'level', 'understand', 'surpass', 'current', 'language', 'model', 'position', 'q', 'excel', 'empathetic', 'context', 'aware', 'interaction', 'thus', 'enable', 'new', 'echelon', 'personal', 'ization', 'user', 'engagement', 'application', 'advanced', 'common', 'sense', 'reason', 'q', 'anticipate', 'development', 'advanced', 'common', 'sense', 'reasoning', 'predict', 'integrate', 'sophisticated', 'logic', 'decisionmake', 'algorithm', 'potentially', 'combine', 'element', 'symbolic', 'ai', 'probabilistic', 'reasoning', 'integration', 'aim', 'endow', 'q', 'intuitive', 'grasp', 'everyday', 'logic', 'understanding', 'akin', 'human', 'common', 'sense', 'thus', 'bridge', 'signiﬁcant', 'gap', 'artiﬁcial', 'natural', 'intelligence', 'enhancement', 'q', 'reasoning', 'ability', 'involve', 'graph', 'structured', 'world', 'knowledge', 'incorporate', 'physics', 'social', 'engine', 'similar', 'model', 'cogskr', 'proach', 'ground', 'physical', 'reality', 'expect', 'capture', 'interpret', 'everyday', 'logic', 'often', 'absent', 'system', 'leverage', 'largescale', 'knowledge', 'basis', 'semantic', 'network', 'q', 'effectively', 'navigate', 'respond', 'complex', 'social', 'practical', 'scenario', 'align', 'infer', 'ence', 'decision', 'closely', 'human', 'experience', 'expectation', 'correspond', 'quasimathematical', 'formula', 'tion', 'represent', 'acsr', 'q∗', 'acsr', 'advanced', 'common', 'sense', 'reason', 'logicai', 'p', 'robai', 'symbolic', 'ai', 'probabilistic', 'reasoning', 'component', 'respectively', 'w', 'integration', 'graphstructured', 'world', 'knowledge', '⊙', 'integrate', 'operation', 'element', 'common', 'sense', 'reason', 'e', 'extensive', 'approach', 'integrate', 'extensive', 'realworld', 'edge', 'speculate', 'involve', 'use', 'advanced', 'formal', 'veriﬁcation', 'system', 'provide', 'robust', 'basis', 'validate', 'logical', 'factual', 'reasoning', 'method', 'understanding', 'interaction', 'autonomous', 'learn', 'cognitive', 'ability', 'knowledge', 'integration', 'common', 'sense', 'reasoning', 'figure', 'conceptual', 'diagram', 'project', 'agi', 'capability', 'couple', 'sophisticated', 'neural', 'network', 'architecture', 'dynamic', 'learning', 'algorithm', 'enable', 'q', 'engage', 'deeply', 'complexity', 'real', 'world', 'transcend', 'conventional', 'ai', 'limitation', 'additionally', 'q', 'employ', 'mathematical', 'theorem', 'prove', 'technique', 'validation', 'sure', 'reasoning', 'output', 'accurate', 'also', 'ethically', 'ground', 'incorporation', 'ethic', 'classiﬁer', 'process', 'far', 'strengthen', 'capacity', 'deliver', 'reliable', 'responsible', 'understanding', 'interaction', 'realworld', 'scenario', 'correspond', 'quasimathematical', 'formulation', 'represent', 'erw', 'q∗', '⊗', 'n', 'p', 'erw', 'extensive', '•', 'f', 'formal', 'veriﬁcation', 'system', 'n', 'neural', 'network', 'architecture', '•', 'p', 'mathematical', 'factual', 'validation', 'theorem', 'proving', 'logical', 'incorporation', 'ethic', 'classiﬁer', '⊗', 'comprehensive', 'integration', 'knowledge', 'synthesis', 'ethical', 'alignment', 'furthermore', 'speculate', 'capability', 'q', 'potential', 'signiﬁcantly', 'reshape', 'job', 'market', 'labor', 'dynamic', 'advanced', 'functionality', 'q', 'auto', 'mate', 'complex', 'task', 'lead', 'shift', 'job', 'requirement', 'emergence', 'new', 'skill', 'demand', 'necessitate', 'evaluation', 'strategy', 'educational', 'paradigm', 'align', 'evolve', 'technological', 'landscape', 'ensure', 'workforce', 'equip', 'interact', 'complement', 'advanced', 'system', 'project', 'capability', 'agi', 'agi', 'stand', 'transformative', 'leap', 'endeavor', 'mirror', 'human', 'cognitive', 'ability', 'software', 'paradigm', 'fig', 'agi', 'evolution', 'mark', 'advanced', 'selflearning', 'capability', 'utilize', 'policy', 'neural', 'network', 'sophisticated', 'reinforcement', 'learning', 'technique', 'autonomous', 'adaptation', 'integration', 'algorithm', 'treegraph', 'thought', 'network', 'suggest', 'future', 'agi', 'independently', 'acquire', 'apply', 'knowledge', 'diverse', 'domain', 'journal', 'latex', 'class', 'file', 'vol', 'revolution', 'autonomous', 'learn', 'challenge', 'opportunity', 'development', 'agi', 'anticipate', 'revolutionize', 'selflearning', 'ex', 'ploration', 'incorporate', 'method', 'agi', 'model', 'position', 'achieve', 'level', 'autonomous', 'learning', 'problemsolve', 'exceed', 'current', 'model', 'dependence', 'training', 'datum', 'indicate', 'potential', 'paradigm', 'shift', 'reduce', 'need', 'frequent', 'retraining', 'facilitate', 'dynamic', 'adaptation', 'response', 'evolve', 'scenario', 'b', 'broadening', 'cognitive', 'ability', 'envisage', 'integrate', 'various', 'architecture', 'agi', 'promise', 'level', 'general', 'intelligence', 'replicate', 'multi', 'faceted', 'nature', 'human', 'cognition', 'universal', 'adapter', 'approach', 'mirroring', 'model', 'gpt', 'facilitate', 'rapid', 'assimilation', 'diverse', 'information', 'position', 'agi', 'system', 'capable', 'perform', 'task', 'multiple', 'domain', 'adaptability', 'akin', 'human', 'intellect', 'full', 'capability', 'remain', 'speculative', 'current', 'trend', 'suggest', 'potential', 'application', 'advanced', 'healthcare', 'diagnostic', 'evidence', 'recent', 'breakthrough', 'drive', 'predictive', 'medicine', 'model', 'indicate', 'agi', 'potential', 'revolutionize', 'medical', 'diagnosis', 'treatment', 'elevate', 'understanding', 'interaction', 'agi', 'project', 'achieve', 'unparalleled', 'understanding', 'human', 'language', 'socioemotional', 'subtlety', 'leverag', 'algorithm', 'transformer', 'architecture', 'enable', 'agi', 'engage', 'complex', 'empathetic', 'textually', 'aware', 'interaction', 'suggest', 'potential', 'application', 'revolutionize', 'system', 'communicate', 'interact', 'development', 'agi', 'encompass', 'challenge', 'opportunity', 'agi', 'promise', 'productivity', 'boost', 'creative', 'ﬁeld', 'innovation', 'crossmodal', 'generation', 'technique', 'substantial', 'challenge', 'data', 'bias', 'computational', 'efﬁciency', 'ethical', 'implication', 'persist', 'challenge', 'necessitate', 'balanced', 'approach', 'agi', 'develop', 'ment', 'focus', 'data', 'curation', 'efﬁcient', 'system', 'societal', 'impact', 'context', 'development', 'expert', 'various', 'domain', 'caution', 'overestimate', 'current', 'ai', 'capability', 'highlight', 'gap', 'theoretical', 'framework', 'agi', 'practical', 'reality', 'today', 'ai', 'envision', 'autonomy', 'cognitive', 'ability', 'agi', 'separate', 'current', 'model', 'suggest', 'future', 'system', 'perform', 'task', 'various', 'domain', 'human', 'intervention', 'development', 'trajectory', 'underscore', 'importance', 'ethical', 'consideration', 'technological', 'breakthrough', 'journey', 'become', 'mative', 'force', 'society', 'project', 'time', 'line', 'achieve', 'true', 'agi', 'remain', 'speculative', 'recognize', 'potential', 'roadblock', 'crucial', 'current', 'limitation', 'computational', 'power', 'complexity', 'replicate', 'humanlike', 'cognitive', 'ability', 'emphasize', 'need', 'sustained', 'research', 'ethical', 'consideration', 'pursuit', 'agi', 'ensure', 'responsible', 'conscientious', 'development', 'vii', 'impact', 'analysis', 'generative', 'ai', 'research', 'taxonomy', 'advent', 'advanced', 'ai', 'development', 'moe', 'multimodality', 'agi', 'landscape', 'generative', 'ai', 'research', 'undergo', 'signiﬁcant', 'transformation', 'section', 'analyze', 'development', 'reshape', 'research', 'taxonomy', 'generative', 'ai', 'advanced', 'common', 'sense', 'reason', 'criterion', 'impact', 'analysis', 'symbolic', 'ai', 'probabilistic', 'reasoning', 'integrate', 'imbue', 'system', 'innate', 'grasp', 'common', 'sense', 'bridge', 'gap', 'artiﬁcial', 'natural', 'intelligence', 'enable', 'agi', 'navigate', 'respond', 'effectively', 'realworld', 'scenario', 'reasoning', 'align', 'closely', 'human', 'thought', 'process', 'e', 'holistic', 'integration', 'knowledge', 'potential', 'integrate', 'extensive', 'realworld', 'edge', 'guide', 'formal', 'veriﬁcation', 'system', 'hint', 'future', 'capability', 'output', 'accurate', 'ethically', 'ground', 'suggest', 'agi', 'ability', 'responsible', 'interaction', 'realworld', 'complexity', 'project', 'capability', 'agi', 'extend', 'address', 'signiﬁcant', 'global', 'challenge', 'climate', 'change', 'agi', 'advanced', 'datum', 'analysis', 'predictive', 'modeling', 'play', 'well', 'crucial', 'role', 'environmental', 'monitoring', 'fore', 'cast', 'climate', 'pattern', 'devise', 'sustainable', 'solution', 'contribute', 'signiﬁcantly', 'global', 'ecological', 'effort', 'continuously', 'evolve', 'landscape', 'generative', 'ai', 'instigate', 'transformative', 'change', 'various', 'search', 'domain', 'necessitate', 'systematic', 'evaluation', 'advancement', 'inﬂuence', 'establish', 'set', 'criterion', 'detail', 'table', 'serve', 'analytical', 'lense', 'quantify', 'categorize', 'impact', 'deeply', 'rooted', 'dynamic', 'interplay', 'technological', 'progress', 'evolve', 'paradigm', 'research', 'focus', 'area', 'analysis', 'framework', 'construct', 'gradient', 'scale', 'range', 'emergent', 'obsolete', 'reﬂecte', 'extent', 'area', 'generative', 'ai', 'research', 'reshape', 'categorization', 'distinct', 'class', 'allow', 'complex', 'assessment', 'acknowledge', 'area', 'uniformly', 'affect', 'multitiered', 'approach', 'inform', 'historical', 'pattern', 'technological', 'disruption', 'adaptability', 'scientiﬁc', 'inquiry', 'apex', 'evaluative', 'hierarchy', 'emerge', 'tion', 'encapsulate', 'advent', 'uncharted', 'research', 'vista', 'propel', 'ongoing', 'breakthrough', 'predicate', 'conjecture', 'historical', 'continuum', 'surge', 'technological', 'power', 'latex', 'class', 'file', 'vol', 'table', 'criterion', 'analyze', 'impact', 'generative', 'ai', 'research', 'symbol', '↔', 'criterion', 'emerge', 'tion', 'require', 'rection', 'still', 'relevant', 'likely', 'become', 'redundant', 'inherently', 'unre', 'solvable', 'score', 'deﬁnition', 'new', 'research', 'area', 'expect', 'arise', 'direct', 'consequence', 'advancement', 'area', 'need', 'shift', 'focus', 'ogy', 'stay', 'relevant', 'new', 'develop', 'ment', 'area', 'advancement', 'mini', 'mal', 'impact', 'maintain', 'current', 'status', 'methodology', 'area', 'lose', 'relevance', 'become', 'obsolete', 'advent', 'new', 'tech', 'nologie', 'challenge', 'remain', 'unresolved', 'complexity', 'subjective', 'human', 'spective', 'diverse', 'cultural', 'value', 'justiﬁcation', 'emphasize', 'novel', 'research', 'domain', 'emerge', 'technological', 'shift', 'necessitate', 'reevaluation', 'redirection', 'research', 'observe', 'persistence', 'certain', 'ai', 'research', 'area', 'technological', 'advancement', 'discuss', 'rapid', 'obsolescence', 'methodology', 'new', 'technology', 'inherent', 'difﬁcultie', 'issue', 'align', 'diverse', 'human', 'value', 'ethic', 'scientiﬁc', 'enigma', 'avenue', 'area', 'require', 'redirection', 'denote', 'research', 'sphere', 'establish', 'inﬂection', 'point', 'necessitate', 'strategic', 'pivot', 'assimilate', 'emergent', 'ai', 'paradigms', 'overhaul', 'traditional', 'methodology', 'akin', 'transition', 'rule', 'base', 'expert', 'system', 'adaptive', 'machine', 'learn', 'framework', 'still', 'relevant', 'classiﬁcation', 'afﬁrm', 'tenacity', 'select', 'research', 'domain', 'address', 'persis', 'tent', 'scientiﬁc', 'inquiry', 'inherent', 'malleability', 'remain', 'impervious', 'tide', 'innovation', 'contrast', 'domain', 'categorize', 'likely', 'become', 'dant', 'confront', 'potential', 'obsolescence', 'invite', 'strategic', 'fore', 'sight', 'resource', 'reallocation', 'forestall', 'scientiﬁc', 'stagnation', 'lastly', 'inherently', 'unresolvable', 'challenge', 'serve', 'sobering', 'reminder', 'perpetual', 'dilemma', 'research', 'defy', 'resolution', 'root', 'complex', 'web', 'human', 'ethic', 'cultural', 'diversity', 'thus', 'anchor', 'pursuit', 'ai', 'intractable', 'tapestry', 'human', 'value', 'societal', 'imperative', 'b', 'overview', 'impact', 'analysis', 'subsection', 'offer', 'detailed', 'overview', 'impact', 'analysis', 'carry', 'research', 'taxonomy', 'realm', 'generative', 'ai', 'speciﬁc', 'focus', 'recent', 'progress', 'moe', 'multimodality', 'agi', 'aim', 'evaluate', 'impact', 'innovative', 'development', 'various', 'facet', 'generative', 'ai', 'research', 'range', 'model', 'architecture', 'sophisticated', 'learn', 'methodology', 'include', 'quantitative', 'qualitative', 'assessment', 'multitude', 'domain', 'subdomain', 'llm', 'research', 'shed', 'light', 'extent', 'area', 'inﬂuence', 'techno', 'logical', 'advancement', 'evaluation', 'consider', 'factor', 'emergence', 'new', 'research', 'direction', 'necessity', 'redirection', 'exist', 'research', 'area', 'continue', 'relevance', 'certain', 'methodology', 'potential', 'redundancy', 'encapsulate', 'table', 'impact', 'model', 'architecture', 'transformer', 'model', 'score', 'redirection', 'requirement', 'moe', 'agi', 'relevance', 'multimodality', 'lead', 'overall', 'score', 'model', 'form', 'backbone', 'many', 'current', 'architecture', 'continue', 'relevant', 'handle', 'complex', 'input', 'sequence', 'however', 'emergence', 'moe', 'indicate', 'shift', 'dynamic', 'specialized', 'architecture', 'transformer', 'main', 'essential', 'need', 'evolve', 'integrate', 'advanced', 'system', 'enhance', 'performance', 'adaptability', 'recurrent', 'neural', 'network', 'rnns', 'face', 'potential', 'decline', 'relevance', 'indicate', 'score', 'likely', 'become', 'redundant', 'ց', 'moe', 'agi', 'context', 'still', 'relevant', '↔', 'multimodality', 'total', 'score', 'effective', 'sequence', 'process', 'rnn', 'challenge', 'limitation', 'handle', 'longrange', 'depen', 'dencie', 'low', 'efﬁciency', 'compare', 'new', 'model', 'transformer', 'retain', 'relevance', 'multimodal', 'task', 'involve', 'sequential', 'datum', 'generally', 'overshadow', 'advanced', 'architecture', 'moe', 'model', 'score', 'consistent', 'relevance', 'development', 'score', 'ր', 'multimodality', 'combine', 'redirection', 'score', 'context', 'agi', 'amount', 'overall', 'score', 'moe', 'model', 'forefront', 'emerge', 'research', 'multimodality', 'ability', 'handle', 'diverse', 'data', 'type', 'agi', 'model', 'require', 'adjustment', 'effectively', 'integrate', 'system', 'exhibit', 'general', 'intelligence', 'espe', 'cially', 'area', 'initial', 'specialization', 'multimodal', 'model', 'receive', 'high', 'score', 'emerge', 'research', 'direction', 'moe', 'agi', 'context', 'score', '↔', 'current', 'relevance', 'multi', 'modality', 'culminate', 'overall', 'score', 'integration', 'moe', 'pursuit', 'agi', 'open', 'new', 'pathway', 'research', 'multimodal', 'model', 'development', 'crucial', 'enhance', 'ability', 'process', 'synthesize', 'information', 'multiple', 'modality', 'key', 'aspect', 'specialized', 'generalize', 'ai', 'system', 'impact', 'training', 'technique', 'supervised', 'learning', 'assign', 'redirection', 'score', 'relevance', 'score', 'multimodality', 'score', 'indicate', 'poten', 'tial', 'redundancy', 'ց', 'context', 'agi', 'culminate', 'overall', 'score', 'supervise', 'learning', 'require', 'adaptation', 'ﬁt', 'moe', 'framework', 'remain', 'relevant', 'multimodal', 'model', 'depend', 'label', 'datum', 'however', 'shift', 'autonomous', 'learn', 'method', 'agi', 'dependence', 'extensive', 'label', 'dataset', 'typically', 'associate', 'supervised', 'learning', 'diminish', 'lead', 'potential', 'decrease', 'signiﬁcance', 'latex', 'class', 'file', 'vol', 'table', 'impact', 'moe', 'multimodality', 'generative', 'ai', 'research', 'domain', 'model', 'architecture', 'training', 'technique', 'application', 'domain', 'compliance', 'ethical', 'consideration', 'advanced', 'learn', 'emerge', 'trend', 'subdomain', 'transformer', 'model', 'recurrent', 'neural', 'network', 'mixture', 'expert', 'multimodal', 'model', 'supervise', 'learn', 'unsupervised', 'learn', 'reinforcement', 'learning', 'transfer', 'learn', 'natural', 'language', 'understand', 'natural', 'language', 'generation', 'conversational', 'ai', 'creative', 'bias', 'mitigation', 'datum', 'security', 'ai', 'ethic', 'privacy', 'preservation', 'selfsupervise', 'learn', 'metalearning', 'fine', 'tune', 'human', 'value', 'alignment', 'multimodal', 'learn', 'interactive', 'cooperative', 'ai', 'development', 'agi', 'containment', 'moe', 'multimodality', '֒→', 'ց', '↔', 'ր', '֒→', '֒→', '↔', '↔', '↔', '↔', '֒→', '֒→', '֒→', '↔', '֒→', '֒→', '֒→', '↔', '↔', 'ր', '֒→', '֒→', '↔', '↔', 'ր', '↔', '↔', '↔', '֒→', 'ր', '↔', '֒→', 'ր', 'ր', '֒→', '↔', '֒→', '֒→', 'ր', '↔', '↔', '↔', '↔', '֒→', 'agi', 'ց', '֒→', 'ր', 'ց', '֒→', 'ր', '֒→', 'ր', 'ր', 'ր', 'ր', 'ր', '↔', '֒→', '↔', 'ր', 'ց', '△', 'ր', 'ր', '↔', 'ր', 'overall', 'score', 'unsupervised', 'learning', 'score', 'redirection', 'requirement', 'moe', 'agi', 'context', 'maintain', 'relevance', 'score', 'multimodality', 'result', 'total', 'score', 'moe', 'architecture', 'unsupervise', 'learn', 'ing', 'method', 'need', 'adjustment', 'particularly', 'manage', 'dynamic', 'task', 'allocation', 'remain', 'crucial', 'understand', 'unlabeled', 'datum', 'various', 'modality', 'agi', 'unsupervised', 'learning', 'expect', 'evolve', 'traditional', 'technique', 'focus', 'advanced', 'selfdiscovery', 'intrinsic', 'learn', 'ing', 'mechanism', 'reinforcement', 'learning', 'rate', 'still', 'relevant', 'score', 'moe', 'require', 'redirection', 'score', 'multimodality', 'identiﬁed', 'emerge', 'research', 'area', 'score', 'agi', 'give', 'total', 'score', 'technique', 'continue', 'play', 'signiﬁcant', 'role', 'optimize', 'moe', 'model', 'structure', 'realm', 'multimodality', 'necessitate', 'strategic', 'shift', 'effectively', 'manage', 'complex', 'interaction', 'different', 'modality', 'agi', 'reinforcement', 'learning', 'emerge', 'crucial', 'area', 'particularly', 'development', 'autonomous', 'system', 'learn', 'environment', 'transfer', 'learning', 'receive', 'consistent', 'relevance', 'score', 'moe', 'high', 'score', 'emerge', 'research', 'direction', 'multimodality', 'redirection', 'requirement', 'agi', 'accumulate', 'overall', 'score', 'remain', 'important', 'moe', 'framework', 'leverage', 'knowledge', 'different', 'expert', 'multimodal', 'context', 'transfer', 'learning', 'become', 'increasingly', 'crucial', 'facili', 'tat', 'transfer', 'learn', 'different', 'modality', 'evolution', 'agi', 'technique', 'expect', 'undergo', 'signiﬁcant', 'change', 'cater', 'broad', 'generalized', 'knowledge', 'application', 'impact', 'application', 'domain', 'natural', 'language', 'understanding', 'hold', 'steady', 'relevance', 'score', 'moe', 'multimodality', 'emerge', 'direction', 'ր', 'score', 'agi', 'total', 'overall', 'score', 'moe', 'model', 'support', 'relevance', 'nlu', 'enhance', 'precision', 'depth', 'ability', 'handle', 'large', 'diverse', 'dataset', 'multimodal', 'nlu', 'remain', 'critical', 'component', 'comprehend', 'language', 'diverse', 'data', 'format', 'progress', 'nlu', 'expect', 'undergo', 'signiﬁcant', 'expansion', 'move', 'advanced', 'humanlike', 'comprehension', 'interpretation', 'capability', 'natural', 'language', 'generation', 'maintain', 'relevance', 'score', 'moe', 'require', 'redirection', 'score', 'multimodality', 'identiﬁe', 'emerge', 'research', 'area', 'score', 'agi', 'result', 'total', 'score', 'moe', 'scalability', 'crucial', 'enhance', 'multimodal', 'need', 'strategic', 'adjustment', 'align', 'effectively', 'modality', 'agi', 'evolve', 'anticipate', 'venture', 'new', 'research', 'domain', 'especially', 'reﬂect', 'humanlike', 'creativity', 'create', 'content', 'adaptability', 'conversational', 'mark', 'redirection', 'score', 'moe', 'emerge', 'research', 'direction', 'score', 'multimodality', 'agi', 'accumulate', 'overall', 'score', 'moe', 'enhance', 'conversational', 'require', 'strategic', 'change', 'fully', 'utilize', 'moe', 'distribute', 'expertise', 'integration', 'multiple', 'modality', 'open', 'new', 'avenue', 'conversational', 'expand', 'scope', 'include', 'various', 'sensory', 'datum', 'development', 'agi', 'set', 'bring', 'revolutionary', 'advancement', 'domain', 'pave', 'way', 'autonomous', 'contextaware', 'humanlike', 'interaction', 'creative', 'ai', 'score', 'redirection', 'requirement', 'journal', 'latex', 'class', 'file', 'vol', 'moe', 'high', 'score', 'emerge', 'research', 'direction', 'multimodality', 'agi', 'lead', 'total', 'score', 'context', 'moe', 'creative', 'ai', 'need', 'realign', 'capitalize', 'moe', 'capacity', 'generate', 'novel', 'content', 'combination', 'different', 'modality', 'creative', 'ai', 'present', 'exciting', 'new', 'research', 'opportunity', 'enable', 'creation', 'intricate', 'diverse', 'output', 'agi', 'progress', 'expect', 'signiﬁcantly', 'broaden', 'capability', 'creative', 'potentially', 'surpass', 'exist', 'boundary', 'explore', 'new', 'realm', 'creativity', 'impact', 'compliance', 'ethical', 'consideration', 'bias', 'mitigation', 'context', 'moe', 'multimodality', 'agi', 'score', 'redirection', 'requirement', 'moe', 'multimodality', 'emerge', 'research', 'direction', 'score', 'agi', 'result', 'overall', 'score', 'moe', 'architecture', 'demand', 'new', 'approach', 'bias', 'mitigation', 'diversity', 'expert', 'network', 'wise', 'amplify', 'bias', 'multimodal', 'system', 'bias', 'mitigation', 'require', 'novel', 'strategy', 'address', 'bias', 'various', 'data', 'type', 'include', 'nontextual', 'form', 'image', 'audio', 'broad', 'cognitive', 'capability', 'comprehensive', 'approach', 'understanding', 'address', 'bias', 'diverse', 'domain', 'emerge', 'critical', 'research', 'area', 'datum', 'security', 'maintain', 'consistent', 'relevance', 'score', 'moe', 'multimodality', 'lead', 'total', 'score', 'fundamental', 'principle', 'datum', 'security', 'remain', 'crucial', 'advancement', 'moe', 'necessitate', 'tailor', 'strategy', 'distribute', 'nature', 'multimodal', 'ai', 'secure', 'handling', 'diverse', 'datum', 'type', 'continue', 'paramount', 'importance', 'core', 'tenet', 'datum', 'security', 'sustain', 'even', 'advancement', 'agi', 'complexity', 'scope', 'security', 'measure', 'likely', 'increase', 'ethic', 'mark', 'redirection', 'score', 'moe', 'multimodality', 'face', 'inherently', 'unresolvable', 'challenge', '△', 'score', 'agi', 'mulate', 'total', 'score', 'decisionmake', 'process', 'transparency', 'moe', 'model', 'necessitate', 'reevaluation', 'ethical', 'consideration', 'multimodal', 'ai', 'ethical', 'concern', 'particularly', 'interpretation', 'use', 'multimodal', 'datum', 'require', 'new', 'approach', 'ethical', 'challenge', 'agi', 'expect', 'complex', 'involve', 'deep', 'philosophical', 'societal', 'implication', 'difﬁcult', 'fully', 'resolve', 'privacy', 'preservation', 'score', 'redirection', 'need', 'moe', 'multimodality', 'lead', 'overall', 'score', 'distribute', 'nature', 'moe', 'system', 'require', 'reassessment', 'privacy', 'preservation', 'technique', 'handle', 'datum', 'process', 'multiple', 'expert', 'multimodal', 'system', 'espe', 'cially', 'handle', 'sensitive', 'datum', 'image', 'sound', 'necessitate', 'tailor', 'privacy', 'strategy', 'extensive', 'datum', 'processing', 'capability', 'agi', 'advanced', 'potentially', 'new', 'approach', 'privacy', 'preservation', 'call', 'impact', 'advanced', 'learning', 'context', 'moe', 'selfsupervise', 'learning', 'require', 'redirection', 'score', 'signal', 'need', 'adapt', 'evolve', 'architecture', 'emerge', 'research', 'direction', 'score', 'iden', 'tiﬁe', 'multimodality', 'suggest', 'integration', 'various', 'autonomous', 'datum', 'type', 'text', 'image', 'audio', 'agi', 'selfsupervise', 'learning', 'remain', 'relevant', '↔', 'score', 'contribute', 'system', 'autonomy', 'adaptability', 'though', 'likely', 'integrate', 'complex', 'strategy', 'overall', 'impact', 'score', 'metalearning', 'maintain', 'consistent', 'relevance', 'score', 'moe', 'multimodality', 'align', 'well', 'dynamic', 'nature', 'moe', 'aid', 'quick', 'adaptation', 'vary', 'datum', 'type', 'task', 'multimodal', 'context', 'mark', 'emerge', 'research', 'direction', 'score', 'suggest', 'novel', 'research', 'achieve', 'humanlike', 'adaptability', 'learn', 'efﬁciency', 'total', 'score', 'meta', 'learning', 'fine', 'tuning', 'continue', 'relevant', 'score', 'moe', 'multimodality', 'essential', 'adapt', 'pretraine', 'model', 'speciﬁc', 'task', 'tailor', 'multimodal', 'model', 'however', 'likely', 'become', 'redundant', 'ց', 'score', 'agi', 'aim', 'develop', 'system', 'autonomously', 'understand', 'learn', 'broad', 'range', 'domain', 'reduce', 'need', 'traditional', 'ﬁne', 'tuning', 'process', 'overall', 'impact', 'score', 'ﬁne', 'tuning', 'align', 'human', 'value', 'pose', 'inherently', 'unresolv', 'able', 'challenge', '△', 'context', 'moe', 'multimodality', 'score', 'reﬂect', 'complexity', 'diversity', 'task', 'moe', 'model', 'handle', 'integration', 'various', 'datum', 'type', 'multimodal', 'ai', 'broad', 'range', 'cognitive', 'ability', 'encompass', 'factor', 'contribute', 'signiﬁcant', 'ongoing', 'challenge', 'align', 'human', 'value', 'result', 'total', 'score', 'impact', 'emerge', 'trend', 'multimodal', 'learning', 'mark', 'emerge', 'research', 'direction', 'score', 'moe', 'agi', 'reﬂecte', 'capacity', 'integrate', 'various', 'data', 'type', 'text', 'image', 'audio', 'integration', 'crucial', 'specialized', 'task', 'moe', 'process', 'diverse', 'form', 'datum', 'agi', 'realm', 'multimodality', 'remain', 'core', 'aspect', 'score', 'essential', 'ongoing', 'multimodal', 'ai', 'development', 'overall', 'impact', 'score', 'interactive', 'cooperative', 'require', 'redirection', 'moe', 'score', 'moe', 'model', 'adapt', 'include', 'interactive', 'element', 'broad', 'application', 'multimodality', 'interaction', 'cooperation', 'continue', 'central', '↔', 'score', 'especially', 'ﬁeld', 'robotic', 'virtual', 'assistant', 'agi', 'evolution', 'include', 'signiﬁcant', 'advancement', 'interactive', 'mark', 'emerge', 'research', 'area', 'score', 'total', 'score', 'trend', 'development', 'redirection', 'moe', 'multimodality', 'score', 'indicate', 'need', 'integrated', 'complex', 'system', 'agi', 'remain', 'forefront', 'ﬁeld', 'score', 'breakthrough', 'directly', 'inﬂuence', 'progress', 'overall', 'impact', 'score', 'agi', 'development', 'agi', 'containment', 'identiﬁe', 'challenge', 'require', 'solve', '△', 'moe', 'multimodality', 'score', 'area', 'expect', 'reach', 'level', 'autonomy', 'complexity', 'associate', 'agi', 'however', 'agi', 'progress', 'emerge', 'need', 'effective', 'containment', 'strategy', 'mark', 'score', 'highlight', 'journal', 'latex', 'class', 'file', 'vol', 'importance', 'ensure', 'safe', 'control', 'deployment', 'total', 'impact', 'score', 'effectively', 'engage', 'leverage', 'advancement', 'equip', 'necessary', 'skill', 'navigate', 'complexity', 'innovation', 'viii', 'emergent', 'research', 'priority', 'generative', 'ai', 'likely', 'approach', 'precipice', 'new', 'era', 'mark', 'advent', 'q', 'nudge', 'close', 'realization', 'usable', 'agi', 'research', 'landscape', 'generative', 'ai', 'undergo', 'crucial', 'transformation', 'emergent', 'research', 'priority', 'moe', 'moe', 'domain', 'increasingly', 'focus', 'critical', 'area', 'multimodal', 'model', 'model', 'architecture', 'tegration', 'moe', 'agi', 'open', 'new', 'pathway', 'research', 'multimodal', 'model', 'development', 'enhance', 'capability', 'process', 'synthesize', 'information', 'multiple', 'modality', 'crucial', 'specialized', 'generalize', 'ai', 'system', 'multimodal', 'learn', 'emerge', 'trend', 'moe', 'forefront', 'multimodal', 'learn', 'integrate', 'diverse', 'datum', 'type', 'text', 'image', 'audio', 'specialized', 'task', 'trend', 'directly', 'impact', 'enhancement', 'ﬁeld', 'furthermore', 'analysis', 'funding', 'trend', 'investment', 'pattern', 'research', 'indicate', 'substantial', 'shift', 'area', 'multimodal', 'model', 'moe', 'trend', 'characterize', 'increase', 'capital', 'ﬁeld', 'involve', 'complex', 'datum', 'processing', 'autonomous', 'system', 'shape', 'direction', 'future', 'research', 'priority', 'underscore', 'grow', 'interest', 'investment', 'potential', 'generative', 'inﬂuence', 'academic', 'industryled', 'initiative', 'emergent', 'research', 'priority', 'multimodality', 'realm', 'multimodality', 'several', 'area', 'identiﬁe', 'emerge', 'research', 'priority', 'moe', 'model', 'architecture', 'moe', 'model', 'become', 'increasingly', 'relevant', 'handle', 'diverse', 'datum', 'type', 'multimodal', 'transfer', 'learning', 'training', 'technique', 'transfer', 'learning', 'emerge', 'key', 'research', 'direction', 'espe', 'cially', 'learn', 'different', 'modality', 'conversational', 'ai', 'creative', 'ai', 'application', 'domain', 'conversational', 'creative', 'expand', 'multimodal', 'encompass', 'visual', 'auditory', 'sensory', 'datum', 'integration', 'selfsupervise', 'learning', 'advanced', 'learn', 'new', 'research', 'direction', 'selfsupervise', 'learning', 'focus', 'integration', 'various', 'datum', 'type', 'autonomously', 'additionally', 'rise', 'generative', 'ai', 'particularly', 'modal', 'context', 'signiﬁcantly', 'impact', 'educational', 'curriculum', 'skill', 'development', 'grow', 'need', 'update', 'academic', 'program', 'include', 'comprehensive', 'literacy', 'focus', 'multimodal', 'ai', 'technology', 'evolution', 'education', 'aim', 'prepare', 'future', 'professional', 'emergent', 'research', 'priority', 'agi', 'agi', 'domain', 'witness', 'surge', 'research', 'priority', 'multiple', 'area', 'multimodal', 'model', 'model', 'architecture', 'similar', 'moe', 'multimodal', 'model', 'crucial', 'agi', 'enable', 'deep', 'nuance', 'understanding', 'reinforcement', 'learning', 'training', 'technique', 'emerge', 'key', 'area', 'agi', 'reinforcement', 'learning', 'focus', 'develop', 'autonomous', 'system', 'learn', 'environment', 'application', 'domain', 'agi', 'extend', 'boundary', 'natural', 'language', 'understanding', 'generation', 'conver', 'sational', 'ai', 'creative', 'ai', 'focus', 'humanlike', 'comprehension', 'creativity', 'bias', 'mitigation', 'compliance', 'ethical', 'consid', 'eration', 'new', 'direction', 'bias', 'mitigation', 'focus', 'comprehensive', 'approach', 'address', 'bias', 'diverse', 'domain', 'agi', 'metalearning', 'advanced', 'learning', 'agi', 'pursuit', 'humanlike', 'adaptability', 'lead', 'novel', 'research', 'metalearning', 'emerge', 'trend', 'learn', 'interactive', 'cooperative', 'ai', 'agi', 'containment', 'strategy', 'come', 'crucial', 'research', 'area', 'agi', 'progress', 'line', 'development', 'agi', 'noticeable', 'trend', 'research', 'funding', 'investment', 'pattern', 'evident', 'signiﬁcant', 'inclination', 'support', 'project', 'study', 'particularly', 'area', 'natural', 'language', 'understanding', 'generation', 'autonomous', 'system', 'funding', 'trend', 'mirror', 'escalate', 'interest', 'capability', 'agi', 'also', 'direct', 'trajectory', 'future', 'research', 'shape', 'academic', 'exploration', 'industry', 'drive', 'project', 'practical', 'implication', 'limitation', 'generative', 'ai', 'technology', 'generative', 'ai', 'technology', 'encompass', 'moe', 'multi', 'modality', 'agi', 'present', 'unique', 'computational', 'challenge', 'section', 'explore', 'processing', 'power', 'requirement', 'memory', 'usage', 'scalability', 'concern', 'inherent', 'advanced', 'model', 'computational', 'complexity', 'realworld', 'application', 'generative', 'ai', 'technology', 'computational', 'complexity', 'generative', 'ai', 'technology', 'encompass', 'moe', 'multimodality', 'agi', 'present', 'unique', 'computational', 'challenge', 'section', 'explore', 'processing', 'power', 'requirement', 'memory', 'usage', 'scalability', 'concern', 'inherent', 'advanced', 'model', 'processing', 'power', 'requirement', 'advanced', 'generative', 'model', 'include', 'moe', 'architecture', 'agi', 'sys', 'tem', 'require', 'signiﬁcant', 'processing', 'power', 'journal', 'latex', 'class', 'file', 'vol', 'demand', 'gpu', 'accentuate', 'particularly', 'handle', 'complex', 'computation', 'large', 'dataset', 'typical', 'multimodal', 'ai', 'application', 'exist', 'industry', 'solution', 'generative', 'ai', 'reshape', 'various', 'industry', 'offer', 'innovative', 'solution', 'alter', 'market', 'dynamic', 'memory', 'usage', 'ai', 'model', 'critical', 'challenge', 'training', 'deploy', 'largescale', 'ai', 'model', 'particularly', 'multimodal', 'agi', 'system', 'execute', 'gpu', 'lie', 'substantial', 'vram', 'requirement', 'computer', 'ram', 'vram', 'often', 'expand', 'easily', 'many', 'platform', 'pose', 'signiﬁcant', 'constraint', 'develop', 'strategy', 'vram', 'optimization', 'efﬁcient', 'model', 'scaling', 'thus', 'crucial', 'practical', 'deployment', 'ai', 'technology', 'scalability', 'efﬁciency', 'deployment', 'address', 'ing', 'scalability', 'challenge', 'generative', 'ai', 'especially', 'moe', 'agi', 'context', 'involve', 'optimize', 'load', 'man', 'agement', 'parallel', 'processing', 'technique', 'vital', 'practical', 'application', 'ﬁeld', 'healthcare', 'ﬁnance', 'education', 'realworld', 'application', 'example', 'generative', 'ai', 'tech', 'nologie', 'application', 'generative', 'ai', 'model', 'real', 'world', 'scenario', 'demonstrate', 'transformative', 'potential', 'challenge', 'various', 'sector', 'healthcare', 'healthcare', 'generative', 'facilitate', 'ad', 'vancement', 'diagnostic', 'imaging', 'personalized', 'medicine', 'also', 'raise', 'signiﬁcant', 'concern', 'regard', 'datum', 'privacy', 'potential', 'misuse', 'sensitive', 'health', 'information', 'finance', 'use', 'ai', 'fraud', 'detection', 'trading', 'ﬁnance', 'underline', 'efﬁciency', 'accuracy', 'time', 'raise', 'ethical', 'concern', 'particularly', 'automate', 'decisionmake', 'pro', 'cesse', 'lack', 'transparency', 'accountability', 'education', 'generative', 'ai', 'role', 'create', 'personalized', 'learning', 'experience', 'offer', 'immense', 'beneﬁts', 'term', 'educational', 'accessibility', 'tailor', 'instruction', 'ever', 'pose', 'challenge', 'equitable', 'access', 'technology', 'potential', 'bias', 'aigenerate', 'content', 'aigc', 'reduce', 'demand', 'human', 'educator', 'addition', 'ally', 'grow', 'concern', 'educator', 'use', 'aigc', 'fear', 'undermine', 'tradi', 'tional', 'teaching', 'methodology', 'role', 'educator', 'commercial', 'viability', 'industry', 'solution', 'generative', 'ai', 'technology', 'market', 'readiness', 'assess', 'market', 'readiness', 'generative', 'ai', 'technology', 'involve', 'analyze', 'cost', 'accessi', 'bility', 'deployment', 'challenge', 'user', 'adoption', 'trend', 'cost', 'analysis', 'ﬁnancial', 'aspect', 'deploy', 'erative', 'ai', 'include', 'moe', 'multimodality', 'crucial', 'market', 'adoption', 'accessibility', 'deployment', 'integration', 'tech', 'nologie', 'exist', 'system', 'technical', 'expertise', 'require', 'key', 'factor', 'inﬂuence', 'adoption', 'user', 'adoption', 'trend', 'understand', 'current', 'adoption', 'pattern', 'provide', 'insight', 'market', 'acceptance', 'role', 'user', 'trust', 'perceive', 'beneﬁts', 'sectorwise', 'deployment', 'diverse', 'application', 'generative', 'ai', 'digital', 'content', 'creation', 'process', 'streamline', 'also', 'raise', 'question', 'originality', 'intellectual', 'property', 'right', 'impact', 'market', 'dynamic', 'effect', 'ai', 'solution', 'traditional', 'industry', 'structure', 'introduction', 'novel', 'business', 'model', 'signiﬁcant', 'consideration', 'challenge', 'constraint', 'address', 'limitation', 'scalability', 'datum', 'management', 'complexity', 'privacy', 'concern', 'ethical', 'implication', 'essential', 'robust', 'governance', 'framework', 'c', 'limitation', 'future', 'direction', 'generative', 'ai', 'tech', 'nologie', 'technical', 'limitation', 'identify', 'address', 'tech', 'nical', 'limitation', 'generative', 'model', 'crucial', 'advancement', 'reliability', 'contextual', 'understanding', 'enhance', 'ai', 'ability', 'understand', 'interpret', 'context', 'especially', 'natural', 'language', 'processing', 'image', 'recognition', 'key', 'area', 'improvement', 'handle', 'ambiguous', 'datum', 'develop', 'well', 'algo', 'rithms', 'process', 'ambiguous', 'incomplete', 'data', 'set', 'essential', 'decisionmake', 'accuracy', 'reliability', 'navigate', 'human', 'judgment', 'generative', 'accuracy', 'interpret', 'policy', 'procedure', 'pact', 'limit', 'replace', 'human', 'judgment', 'especially', 'true', 'legal', 'political', 'context', 'decisionmaker', 'selectively', 'use', 'aigc', 'lead', 'biased', 'outcome', 'thus', 'effectiveness', 'generative', 'ai', 'scenario', 'realistically', 'assess', 'future', 'research', 'direction', 'enhance', 'practicality', 'generative', 'ai', 'future', 'research', 'generative', 'ai', 'focus', 'address', 'current', 'limitation', 'expand', 'practical', 'application', 'improve', 'contextual', 'understanding', 'research', 'aim', 'develop', 'model', 'well', 'contextual', 'aware', 'particularly', 'complex', 'natural', 'language', 'image', 'processing', 'task', 'robust', 'handling', 'ambiguous', 'datum', 'investigate', 'technique', 'effective', 'processing', 'ambiguous', 'datum', 'vital', 'advance', 'decisionmake', 'capability', 'model', 'ethical', 'integration', 'aigc', 'legal', 'political', 'arena', 'future', 'research', 'focus', 'ethical', 'integration', 'aigenerate', 'content', 'legal', 'political', 'decisionmaking', 'process', 'involve', 'develop', 'framework', 'utilize', 'aigc', 'supportive', 'role', 'sure', 'enhance', 'human', 'judgment', 'contribute', 'transparency', 'fairness', 'importantly', 'researcher', 'consider', 'bias', 'limitation', 'inherent', 'ai', 'potential', 'human', 'fallibility', 'ethical', 'complexity', 'possible', 'corruption', 'domain', 'journal', 'latex', 'class', 'file', 'vol', 'r', 'p', 'e', 'r', 'e', '80k', '60k', '40k', '20k', 'physics', 'math', 'csai', 'year', 'figure', 'annual', 'preprint', 'submission', 'different', 'category', 'impact', 'generative', 'ai', 'preprint', 'discipline', 'challenge', 'detail', 'section', 'directly', 'relate', 'knowledge', 'domain', 'generative', 'ai', 'fuel', 'success', 'generative', 'ai', 'particularly', 'commercialization', 'chatgpt', 'proliferation', 'preprint', 'ﬁeld', 'fig', 'especially', 'csai', 'category', 'platform', 'arxiv', 'introduce', 'set', 'academic', 'challenge', 'merit', 'careful', 'consideration', 'strategic', 'sponse', 'rapid', 'commercialization', 'adoption', 'tool', 'chatgpt', 'evidence', 'entry', 'scholar', 'mention', 'chatgpt', 'year', 'commercialization', 'exemplify', 'accelerated', 'pace', 'ﬁeld', 'advance', 'rapid', 'development', 'mirror', 'traditional', 'peerreview', 'process', 'siderably', 'slow', 'peerreview', 'process', 'appear', 'overwhelmed', 'manuscript', 'either', 'generate', 'chatgpt', 'llm', 'writing', 'process', 'signiﬁcantly', 'accelerate', 'llm', 'contribute', 'bottleneck', 'scholarly', 'communication', 'situation', 'far', 'compound', 'fact', 'many', 'journal', 'discipline', 'computer', 'science', 'also', 'experience', 'long', 'review', 'time', 'high', 'rate', 'desk', 'jection', 'additionally', 'ﬂourishing', 'trend', 'manuscript', 'preprint', 'generate', 'signiﬁcantly', 'expedite', 'use', 'tool', 'chatgpt', 'extend', 'computer', 'science', 'diverse', 'academic', 'discipline', 'trend', 'present', 'loom', 'challenge', 'potentially', 'overwhelm', 'traditional', 'peer', 'review', 'process', 'ﬂourishing', 'preprint', 'ecosystem', 'volume', 'work', 'always', 'adhere', 'establish', 'academic', 'standard', 'sheer', 'volume', 'preprint', 'make', 'task', 'lecte', 'scrutinize', 'research', 'exceedingly', 'demand', 'current', 'research', 'era', 'exploration', 'scientiﬁc', 'become', 'increasingly', 'complex', 'knowledge', 'continue', 'expand', 'disseminate', 'exponentially', 'concurrently', 'integrative', 'research', 'effort', 'attempt', 'distill', 'vast', 'liter', 'ature', 'attempt', 'identify', 'understand', 'small', 'set', 'core', 'contribution', 'thus', 'rapid', 'expansion', 'academic', 'literature', 'various', 'ﬁeld', 'present', 'signiﬁcant', 'challenge', 'researcher', 'seek', 'perform', 'evidence', 'synthese', 'increasingly', 'vast', 'body', 'available', 'knowledge', 'far', 'explosion', 'publication', 'volume', 'pose', 'distinct', 'challenge', 'literature', 'review', 'survey', 'human', 'capacity', 'manually', 'select', 'understanding', 'critically', 'evaluate', 'article', 'increasingly', 'strain', 'potentially', 'lead', 'gap', 'synthesize', 'comprehensive', 'knowledge', 'landscape', 'reproduction', 'result', 'theoretical', 'possibility', 'practical', 'constraint', 'lack', 'technical', 'expertise', 'computational', 'resource', 'access', 'proprietary', 'dataset', 'rigorous', 'evaluation', 'concern', 'inability', 'thoroughly', 'assess', 'preprint', 'research', 'undermine', 'foundation', 'scientiﬁc', 'reliability', 'validity', 'furthermore', 'peer', 'review', 'system', 'cornerstone', 'academic', 'rigour', 'threat', 'far', 'overwhelm', 'potential', 'consequence', 'signiﬁcant', 'unvetted', 'preprint', 'possibly', 'perpetuate', 'bias', 'error', 'scientiﬁc', 'community', 'absence', 'establish', 'retraction', 'mechanism', 'preprint', 'akin', 'publish', 'article', 'exacerbate', 'risk', 'persistent', 'dissemination', 'ﬂawed', 'research', 'academic', 'community', 'crossroad', 'necessitate', 'urgent', 'thoughtful', 'discourse', 'navigate', 'emerge', 'mess', 'situation', 'risk', 'spiral', 'control', 'leave', 'unaddresse', 'context', 'role', 'peer', 'review', 'become', 'increasingly', 'crucial', 'serve', 'critical', 'checkpoint', 'quality', 'validity', 'ensure', 'rapid', 'production', 'ai', 'research', 'rigorously', 'study', 'scientiﬁc', 'accuracy', 'relevance', 'however', 'current', 'modu', 'operandi', 'traditional', 'peer', 'review', 'appear', 'sustainable', 'primarily', 'due', 'inability', 'keep', 'pace', 'exponential', 'growth', 'aithemed', 'research', 'generativeaiaccelerate', 'research', 'submission', 'increasingly', 'specialized', 'nature', 'ai', 'topic', 'situation', 'compound', 'ﬁnite', 'pool', 'reviewer', 'lead', 'delay', 'potential', 'bias', 'burden', 'scholarly', 'community', 'reality', 'demand', 'exploration', 'new', 'paradigm', 'peer', 'review', 'dissemination', 'research', 'keep', 'pace', 'swift', 'advancement', 'ai', 'innovative', 'model', 'community', 'drive', 'vetting', 'process', 'enhance', 'reproducibility', 'check', 'dynamic', 'framework', 'postpublication', 'scrutiny', 'correction', 'necessary', 'effort', 'incorporate', 'automate', 'tool', 'aiassisted', 'review', 'process', 'also', 'explore', 'alleviate', 'strain', 'human', 'reviewer', 'rapidly', 'evolve', 'landscape', 'envision', 'convergence', 'traditional', 'peer', 'review', 'system', 'ﬂour', 'ishe', 'preprint', 'ecosystem', 'involve', 'create', 'brid', 'model', 'fig', 'preprint', 'undergo', 'preliminary', 'communitybase', 'review', 'harness', 'collective', 'expertise', 'rapid', 'feedback', 'academic', 'community', 'similar', 'product', 'review', 'website', 'twitter', 'approach', 'provide', 'initial', 'layer', 'validation', 'offer', 'addi', 'tional', 'insight', 'issue', 'overlook', 'ite', 'number', 'peer', 'reviewer', 'editorsinchief', 'eic', 'consider', 'major', 'criticism', 'suggestion', 'article', 'communitybase', 'review', 'ensure', 'journal', 'latex', 'class', 'file', 'vol', 'preprint', 'submission', 'rapid', 'feedback', 'similar', 'product', 'review', 'site', 'community', 'base', 'review', 'initial', 'validation', 'indepth', 'academic', 'assessment', 'formal', 'peer', 'review', 'rigor', 'quality', 'assurance', 'final', 'publication', 'figure', 'possible', 'convergence', 'traditional', 'peer', 'review', 'preprint', 'ecosystem', 'thorough', 'diverse', 'evaluation', 'subsequent', 'formal', 'peer', 'review', 'process', 'reﬁne', 'endorse', 'preprint', 'academic', 'rigor', 'quality', 'assurance', 'hybrid', 'model', 'require', 'robust', 'technological', 'support', 'possibly', 'leverage', 'ai', 'machine', 'learn', 'tool', 'assist', 'initial', 'screening', 'identiﬁcation', 'suitable', 'reviewer', 'aim', 'establish', 'seamless', 'continuum', 'rapid', 'semination', 'validate', 'publication', 'ensure', 'speed', 'preprint', 'credibility', 'peerreviewed', 'research', 'balanced', 'approach', 'strike', 'harness', 'beneﬁts', 'preprint', 'rapid', 'dissemination', 'ﬁnding', 'open', 'access', 'mitigate', 'drawback', 'development', 'new', 'infrastructure', 'norm', 'instrumental', 'steer', 'academic', 'community', 'sustainable', 'model', 'uphold', 'integrity', 'trustworthiness', 'scientiﬁc', 'research', 'age', 'generative', 'ai', 'conclusion', 'roadmap', 'survey', 'embark', 'exploration', 'transformative', 'trend', 'generative', 'ai', 'research', 'particularly', 'focus', 'speculate', 'advancement', 'q', 'pro', 'gressive', 'stride', 'agi', 'analysis', 'highlight', 'crucial', 'paradigm', 'shift', 'drive', 'innovation', 'moe', 'multi', 'modal', 'learning', 'pursuit', 'agi', 'advancement', 'signal', 'future', 'system', 'signiﬁcantly', 'extend', 'capability', 'reason', 'contextual', 'understanding', 'creative', 'problemsolving', 'study', 'reﬂect', 'ai', 'dual', 'potential', 'contribute', 'impede', 'global', 'equity', 'justice', 'equitable', 'distribution', 'ai', 'beneﬁts', 'role', 'decisionmake', 'process', 'raise', 'crucial', 'question', 'fairness', 'inclusivity', 'imperative', 'thoughtfully', 'integrate', 'ai', 'societal', 'structure', 'enhance', 'justice', 'reduce', 'disparity', 'advancement', 'several', 'open', 'question', 'research', 'gap', 'remain', 'include', 'ensure', 'ethical', 'alignment', 'advanced', 'system', 'human', 'value', 'societal', 'norm', 'challenge', 'compound', 'increase', 'autonomy', 'safety', 'robustness', 'agi', 'sys', 'tem', 'diverse', 'environment', 'also', 'remain', 'signiﬁcant', 'research', 'gap', 'address', 'challenge', 'require', 'multidisciplinary', 'approach', 'incorporate', 'ethical', 'social', 'philosophical', 'spective', 'survey', 'highlight', 'key', 'area', 'future', 'disciplinary', 'research', 'emphasize', 'integration', 'ethical', 'sociological', 'technical', 'perspective', 'approach', 'foster', 'collaborative', 'research', 'bridge', 'gap', 'technological', 'advancement', 'societal', 'need', 'ensure', 'ai', 'development', 'align', 'human', 'value', 'global', 'welfare', 'role', 'moe', 'multimodal', 'agi', 'reshape', 'generative', 'identiﬁe', 'signiﬁcant', 'advancement', 'enhance', 'model', 'performance', 'versatility', 'pave', 'way', 'future', 'research', 'area', 'ai', 'alignment', 'agi', 'forge', 'ahead', 'balance', 'advancement', 'human', 'creativity', 'goal', 'necessity', 'ensure', 'ai', 'role', 'complementary', 'force', 'ampliﬁes', 'capacity', 'innovate', 'solve', 'complex', 'challenge', 'responsibility', 'guide', 'advancement', 'enrich', 'human', 'experience', 'align', 'technolog', 'ical', 'progress', 'ethical', 'standard', 'societal', 'wellbeing', 'disclaimer', 'author', 'hereby', 'declare', 'conﬂict', 'interest', 'abbreviation', 'artiﬁcial', 'general', 'intelligence', 'agi', 'artiﬁcial', 'intelligence', 'aigenerate', 'bidirectional', 'encoder', 'representation', 'transformer', 'deep', 'qnetwork', 'generative', 'adversarial', 'network', 'datum', 'protection', 'regulation', 'gdpr', 'generative', 'pretraine', 'transformer', 'gpt', 'graphic', 'processing', 'unit', 'light', 'detection', 'range', 'lidar', 'large', 'language', 'model', 'llm', 'long', 'search', 'mct', 'machine', 'learn', 'mixture', 'expert', 'moe', 'natural', 'language', 'generation', 'nlg', 'natural', 'language', 'processing', 'nlp', 'natural', 'language', 'understand', 'neural', 'network', 'proximal', 'policy', 'optimization', 'ppo', 'recurrent', 'neural', 'network', 'rnns', 'value', 'neural', 'video', 'random', 'access', 'memory', 'reference', 'ture', 'compute', 'machinery', 'intelligence', 'mind', 'vol', 'p', 'mcdermott', 'artiﬁcial', 'intelligence', 'meet', 'natural', 'stupidity', 'acm', 'sigart', 'bulletin', 'pp', 'minsky', 'step', 'artiﬁcial', 'intelligence', 'proceeding', 'ire', 'vol', 'pp', 'lecun', 'deep', 'learn', 'nature', 'vol', 'pp', 'minsky', 'papert', 'introduction', 'computational', 'geometry', 'cambridge', 'tiass', 'hit', 'vol', 'p', 'e', 'learn', 'repre', 'sentation', 'backpropagate', 'error', 'nature', 'vol', 'pp', 'journal', 'latex', 'class', 'file', 'vol', 'gao', 'multimodality', 'ai', 'education', 'ward', 'artiﬁcial', 'general', 'intelligence', 'arxiv', 'preprint', 'p', 'generate', 'datum', 'visualisation', 'natural', 'language', 'use', 'chatgpt', 'codex', 'gpt3', 'large', 'language', 'model', 'ieee', 'access', 'r', 'p', 'watter', 'culturally', 'sensitive', 'test', 'evaluate', 'nuance', 'cination', 'ieee', 'transaction', 'artiﬁcial', 'intelligence', 'vol', 'pp', 'dafoe', 'faust', 'legg', 'level', 'agi', 'operationalize', 'progress', 'path', 'agi', 'arxiv', 'preprint', 'mccaffary', 'bluemke', 'garﬁnkel', 'good', 'practice', 'agi', 'safety', 'governance', 'survey', 'expert', 'opinion', 'arxiv', 'preprint', 'rollin', 'moulini', 'custis', 'edmund', 'multidimensional', 'investigation', 'effect', 'pub', 'lication', 'retraction', 'scholarly', 'impact', 'journal', 'association', 'information', 'science', 'technology', 'vol', 'pp', 'vaswani', 'n', 'shazeer', 'n', 'gomez', 'ł', 'kaiser', 'polosukhin', 'attention', 'need', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'radford', 'sutskever', 'improve', 'language', 'understanding', 'generative', 'pretraine', 'c', 'overview', 'artiﬁcial', 'intelligence', 'ethic', 'ieee', 'transaction', 'artiﬁcial', 'intelligence', 'l', 'e', 'billy', 'deforet', 'open', 'science', 'save', 'live', 'lesson', 'covid19', 'pandemic', 'bmc', 'medical', 'research', 'methodology', 'vol', 'pp', '1–18', 'c', 'r', 'triggle', 'r', 'j', 'triggle', 'grierson', 'requiem', 'impact', 'factor', 'high', 'publication', 'charge', 'accountability', 'research', 'vol', 'pp', 'kaye', 'watter', 'run', 'mitigation', 'modern', 'era', 'comprehensive', 'review', 'research', 'challenge', 'future', 'direction', 'acm', 'computing', 'survey', 'vol', 'pp', 'alavizadeh', 'r', 'nowrozy', 'p', 'watter', 'harness', 'gpt4', 'generation', 'cybersecurity', 'grc', 'policy', 'focus', 'ransomware', 'attack', 'mitigation', 'computer', 'security', 'vol', 'p', 'h', 'bao', 'mohamme', 'aggarwal', 'som', 'vlmo', 'visionlanguage', 'pre', 'training', 'mixtureofmodalityexpert', 'advance', 'neural', 'mation', 'processing', 'system', 'vol', 'pp', 'lepikhin', 'glam', 'efﬁcient', 'scaling', 'language', 'model', 'mixtureofexpert', 'international', 'conference', 'machine', 'learn', 'pmlr', 'pp', 'masoudnia', 'r', 'mixture', 'expert', 'literature', 'survey', 'artiﬁcial', 'intelligence', 'review', 'vol', 'pp', 'c', 'riquelme', 'susano', 'pinto', 'keyser', 'n', 'scale', 'vision', 'sparse', 'mixture', 'expert', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', '8583–8595', 'p', 'gader', 'year', 'mixture', 'expert', 'ieee', 'transaction', 'neural', 'network', 'learn', 'system', 'vol', 'pp', 'learn', 'mixture', 'granularityspeciﬁc', 'expert', 'ﬁnegrained', 'categorization', 'proceed', 'ing', 'ieeecvf', 'international', 'conference', 'computer', 'vision', 'pp', 'serrano', 'multimodality', 'survey', 'acm', 'computing', 'survey', 'vol', '10', 'pp', 'q', 'sun', 'generative', 'pretraining', 'multimodality', 'arxiv', 'preprint', 'arxiv230705222', 'tian', 'mvp', 'multimodality', 'guide', 'visual', 'pretraining', 'european', 'conference', 'computer', 'vision', 'pp', 'luo', 'menet', 'lightweight', 'multimodality', 'enhancement', 'network', 'detect', 'salient', 'object', 'rgbthermal', 'image', 'neurocompute', 'vol', 'pp', 'q', 'ye', 'h', 'hu', 'mplugowl', 'modularization', 'empower', 'large', 'language', 'model', 'multimodality', 'arxiv', 'preprint', 'arxiv230414178', 'safe', 'reliance', 'ai', 'regulate', 'ai', 'ethic', 'vol', 'pp', '93–99', 'mclean', 'g', 'j', 'read', 'baber', 'risk', 'associate', 'artiﬁcial', 'general', 'intelligence', 'systematic', 'review', 'journal', 'experimental', 'theoretical', 'artiﬁcial', 'intelligence', 'vol', 'pp', 'e', 'ismagilova', 'aart', 'coomb', 'crick', 'r', 'dwivedi', 'edward', 'eirug', 'galanos', 'b', 'lucini', 'r', 'l', 'c', 'misra', 'e', 'mogaji', 'r', 'raman', 'spencer', 'p', 'walton', 'artiﬁcial', 'intelligence', 'ai', 'multidisciplinary', 'perspective', 'emerge', 'challenge', 'opportunity', 'agenda', 'research', 'practice', 'policy', 'international', 'journal', 'information', 'management', 'vol', 'p', 'gabriel', 'artiﬁcial', 'intelligence', 'value', 'alignment', 'mind', 'machine', 'vol', 'pp', 'shabannejad', 'bianco', 'l', 'buckeridge', 'l', 'apply', 'artiﬁcial', 'intelligence', 'healthcare', 'listen', 'wind', 'change', 'postcovid19', 'world', 'pp', 'z', 'frieske', 'ishii', 'madotto', 'p', 'fung', 'survey', 'hallucination', 'natural', 'language', 'generation', 'acm', 'computing', 'survey', 'vol', 'pp', 'min', 'e', 'sulem', 'p', 'h', 'agirre', 'heintz', 'roth', 'recent', 'advance', 'natural', 'language', 'processing', 'large', 'pretrained', 'language', 'model', 'survey', 'acm', 'computing', 'survey', 'vol', 'pp', '1–40', 'halueval', 'largescale', 'hallucination', 'evaluation', 'benchmark', 'large', 'language', 'model', 'proceeding', 'conference', 'empirical', 'method', 'natural', 'language', 'processing', 'pp', 'l', 'weidinger', 'grifﬁn', 'balle', 'kasirzadeh', 'ethical', 'social', 'risk', 'harm', 'language', 'model', 'arxiv', 'preprint', 'rui', 'safety', 'ethical', 'concern', 'large', 'language', 'model', 'proceeding', '22nd', 'chinese', 'national', 'con', 'ference', 'computational', 'linguistic', 'volume', 'tutorial', 'abstract', 'pp', '9–16', 'p', 'j', 'pietra', 'p', 'v', 'desouza', 'l', 'cer', 'classbase', 'ngram', 'model', 'natural', 'language', 'computational', 'linguistic', 'vol', 'pp', 'estimation', 'probability', 'sparse', 'datum', 'language', 'model', 'component', 'speech', 'recognizer', 'ieee', 'transaction', 'acoustic', 'speech', 'signal', 'processing', 'vol', 'pp', 'r', 'kneser', 'ney', 'improve', 'language', 'modeling', 'international', 'conference', 'acoustic', 'speech', 'signal', 'processing', 'vol', 'ieee', 'pp', 'r', 'kuhn', 'mori', 'cachebase', 'natural', 'language', 'model', 'speech', 'recognition', 'ieee', 'transaction', 'pattern', 'analysis', 'machine', 'intelligence', 'vol', 'pp', 'h', 'ney', 'essen', 'kneser', 'structure', 'probabilistic', 'pendence', 'stochastic', 'language', 'modelling', 'computer', 'speech', 'language', 'vol', 'pp', 'schmidhuber', 'long', 'memory', 'neural', 'computation', 'vol', 'pp', 'k', 'nammous', 'saeed', 'natural', 'language', 'processing', 'speaker', 'language', 'gender', 'identiﬁcation', 'lstm', 'advanced', 'computing', 'system', 'security', 'volume', 'pp', 'search', 'unstructured', 'text', 'datum', 'mining', 'fault', 'classiﬁcation', 'base', 'rnnlstm', 'malfunction', 'inspection', 'report', 'energie', 'vol', 'p', 'yao', 'improve', 'lstm', 'structure', 'natural', 'language', 'processing', 'ieee', 'international', 'conference', 'safety', 'produce', 'informatization', 'ieee', 'pp', 'wainwright', 'agarwal', 'ray', 'et', 'training', 'language', 'journal', 'latex', 'class', 'file', 'vol', 'model', 'follow', 'instruction', 'human', 'feedback', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'predictive', 'learning', 'analytic', 'modelling', 'explainable', 'artiﬁcial', 'intelligence', 'prescriptive', 'analytic', 'chat', 'international', 'journal', 'artiﬁcial', 'intelligence', 'education', 'pp', 'potter', 'clinical', 'prediction', 'transparency', 'explainable', 'ai', 'approach', 'survival', 'model', 'residential', 'aged', 'care', 'arxiv', 'preprint', 'arxiv231200271', 'r', 'large', 'language', 'model', 'health', 'care', 'development', 'application', 'challenge', 'health', 'care', 'science', 'vol', 'pp', 'baidooanu', 'l', 'ansah', 'education', 'era', 'generative', 'artiﬁcial', 'intelligence', 'understand', 'potential', 'beneﬁts', 'chat', 'gpt', 'promote', 'teaching', 'learning', 'journal', 'ai', 'vol', 'pp', 'chatgpt', 'end', 'online', 'exam', 'integrity', 'arxiv', 'preprint', 'arxiv221209292', 'tlili', 'adarkwah', 'bozkurt', 'hickey', 'r', 'agyemang', 'devil', 'guardian', 'angel', 'chatgpt', 'case', 'study', 'use', 'chatbot', 'education', 'smart', 'learn', 'environment', 'vol', 'p', 'chatgpt', 'educational', 'tool', 'opportunity', 'challenge', 'recommendation', 'communication', 'business', 'writing', 'composition', 'course', 'journal', 'artiﬁcial', 'intelligence', 'technology', 'vol', 'pp', 'george', 'h', 'george', 'review', 'impact', 'several', 'business', 'sector', 'partner', 'universal', 'international', 'vol', 'pp', '9–23', 'g', 'k', 'hadﬁeld', 'clark', 'regulatory', 'market', 'future', 'governance', 'arxiv', 'preprint', 'sheahan', 'tessler', 'glaese', 'j', 'finetune', 'language', 'model', 'agreement', 'human', 'diverse', 'preference', 'advance', 'neural', 'mation', 'processing', 'system', 'vol', 'pp', '176–38', 'bing', 'llmadapter', 'adapter', 'family', 'parameterefﬁcient', 'ﬁne', 'tuning', 'large', 'language', 'model', 'arxiv', 'preprint', 'h', 'bansal', 'c', 'raffel', 'fewshot', 'parameterefﬁcient', 'ﬁnetuning', 'well', 'cheap', 'incontext', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'b', 'learn', 'model', 'ﬁnetune', 'survey', 'arxiv', 'preprint', 'p', 'manakul', 'liusie', 'gale', 'selfcheckgpt', 'hallucination', 'detection', 'generative', 'large', 'language', 'mod', 'els', 'arxiv', 'preprint', 'martino', 'knowledge', 'injection', 'counter', 'large', 'language', 'model', 'llm', 'hallucination', 'web', 'conference', 'springer', 'pp', 'ning', 'yuan', 'llm', 'lie', 'hallucination', 'bug', 'feature', 'adversarial', 'example', 'arxiv', 'preprint', 'cui', 'song', 'survey', 'lucination', 'large', 'language', 'model', 'arxiv', 'preprint', 'j', 'r', 'sun', 'beavertail', 'improve', 'safety', 'alignment', 'llm', 'humanpreference', 'dataset', 'arxiv', 'preprint', 'arxiv230704657', 'ton', 'trustworthy', 'llm', 'survey', 'guideline', 'evaluate', 'large', 'language', 'model', 'alignment', 'arxiv', 'preprint', 'align', 'large', 'language', 'model', 'human', 'survey', 'arxiv', 'preprint', 'arxiv230712966', 'z', 'sun', 'cox', 'principledriven', 'selfalignment', 'language', 'el', 'scratch', 'minimal', 'human', 'supervision', 'arxiv', 'preprint', 'wy', 'levine', 'shashua', 'fundamental', 'large', 'language', 'model', 'arxiv', 'preprint', 'itation', 'alignment', 'goller', 'prompt', 'opportunity', 'challenge', 'zeroand', 'learn', 'humanai', 'interaction', 'creative', 'application', 'generative', 'model', 'arxiv', 'preprint', 'r', 'gui', 'arxiv', 'preprint', 'tune', 'templatefree', 'prompt', 'c', 'lfpt5', 'uniﬁed', 'framework', 'lifelong', 'shot', 'language', 'learning', 'base', 'prompt', 'tuning', 'arxiv', 'preprint', 'arxiv211007298', 'majety', 'de', 'trustworthy', 'assertion', 'classiﬁcation', 'prompt', 'journal', 'biomedical', 'informatic', 'vol', 'p', 'grammargpt', 'explore', 'opensource', 'llm', 'native', 'chinese', 'grammatical', 'error', 'correction', 'supervised', 'ﬁnetuning', 'conference', 'natural', 'language', 'processing', 'chinese', 'pp', 'liga', 'l', 'robaldo', 'finetune', 'gpt3', 'legal', 'rule', 'classiﬁca', 'tion', 'computer', 'law', 'security', 'review', 'vol', 'p', 'c', 'freeman', 'coreye', 'prove', 'large', 'language', 'model', 'ﬁnetune', 'solve', 'math', 'problem', 'arxiv', 'preprint', 'z', 'talat', 'biderman', 'radev', 'et', 'reap', 'sow', 'challenge', 'bias', 'evaluation', 'multilingual', 'setting', 'proceeding', 'bigscience', 'episode', 'workshop', 'challenge', 'perspective', 'create', 'large', 'language', 'model', 'pp', 'hessian', 'regularization', 'deep', 'neural', 'network', 'novel', 'approach', 'base', 'stochastic', 'estimator', 'hessian', 'trace', 'neurocompute', 'vol', 'pp', 'conﬁdence', 'adaptive', 'regularization', 'deep', 'learning', 'noisy', 'label', 'arxiv', 'preprint', 'arxiv210808212', 'tucker', 'chorowski', 'ł', 'kaiser', 'regu', 'larize', 'neural', 'network', 'penalize', 'conﬁdent', 'output', 'distribution', 'arxiv', 'preprint', 'pajarinen', 'agrawal', 'redeem', 'intrinsic', 'reward', 'constrained', 'optimization', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'stable', 'block', 'adjustment', 'method', 'ground', 'control', 'point', 'use', 'bind', 'constrained', 'optimization', 'international', 'journal', 'remote', 'sensing', 'vol', 'pp', 'constrain', 'policy', 'optimization', 'troll', 'selflearning', 'conversational', 'system', 'arxiv', 'preprint', 'z', 'song', 'jin', 'surrogateassisted', 'evolutionary', 'framework', 'region', 'interestsbase', 'data', 'selection', 'expensive', 'constrained', 'optimization', 'ieee', 'transaction', 'system', 'man', 'cybernetic', 'system', 'r', 'structureaware', 'tional', 'variational', 'autoencoder', 'constrained', 'molecule', 'optimization', 'pattern', 'recognition', 'vol', 'p', 'p', 'ai', 'alignment', 'human', 'reward', 'proceeding', 'aaaiacm', 'conference', 'ai', 'ethic', 'society', 'pp', 'schmitt', 'reward', 'model', 'mitigate', 'toxicity', 'transformerbase', 'language', 'model', 'apply', 'intelligence', 'vol', 'pp', '8421–8435', 'leike', 'krueger', 'martic', 'maini', 'legg', 'scalable', 'agent', 'alignment', 'reward', 'model', 'research', 'direction', 'arxiv', 'preprint', 'tool', 'augment', 'reward', 'model', 'arxiv', 'preprint', 'gonsalve', 'johns', 'generative', 'artiﬁcial', 'intelligence', 'opportunity', 'challenge', 'large', 'language', 'model', 'international', 'conference', 'intelligent', 'computing', 'networking', 'springer', 'pp', 'qiao', 'octavius', 'mitigate', 'task', 'int', 'ference', 'mllm', 'moe', 'arxiv', 'preprint', 'c', 'kyrillidi', 'r', 'sim', 'sweeping', 'heterogeneity', 'smart', 'mop', 'mixture', 'prompt', 'llm', 'task', 'adaptation', 'arxiv', 'preprint', 'arxiv231002842', 'journal', 'latex', 'class', 'file', 'vol', 'h', 'navee', 'usman', 'barne', 'mian', 'comprehensive', 'overview', 'large', 'language', 'model', 'arxiv', 'preprint', 'arxiv230706435', 'repeat', 'repeat', 'insight', 'scale', 'llm', 'tokencrisis', 'arxiv', 'preprint', 'rabbani', 'chowdhury', 'patchlevel', 'routing', 'mixtureofexpert', 'provably', 'sample', 'efﬁcient', 'convolutional', 'neural', 'network', 'arxiv', 'eprint', 'pp', 'arxiv', 'r', 'hartvigsen', 'sparse', 'moe', 'new', 'treatment', 'address', 'forget', 'ﬁtting', 'learn', 'issue', 'multimodal', 'multitask', 'learn', 'conference', 'parsimony', 'learn', 'recent', 'spotlight', 'track', 'c', 'n', 'santo', 'noble', 'memory', 'augment', 'language', 'model', 'mixture', 'word', 'pert', 'arxiv', 'preprint', 'languageroute', 'mixture', 'expert', 'multilingual', 'codeswitche', 'speech', 'recognition', 'arxiv', 'preprint', 'sparse', 'moe', 'language', 'guide', 'routing', 'multilingual', 'machine', 'translation', 'conference', 'parsimony', 'learn', 'recent', 'spotlight', 'track', 'multigate', 'mixture', 'ofexpert', 'combine', 'synthetic', 'minority', 'oversampling', 'technique', 'imbalance', 'fault', 'diagnosis', 'international', 'conference', 'computer', 'support', 'cooperative', 'work', 'design', 'cscwd', 'ieee', 'pp', 'de', 'diversify', 'mixtureofexpert', 'representation', 'language', 'el', 'orthogonal', 'optimizer', 'arxiv', 'preprint', 'shen', 'prophet', 'finegraine', 'load', 'balance', 'parallel', 'training', 'large', 'scale', 'moe', 'model', 'ieee', 'international', 'conference', 'cluster', 'computing', 'cluster', 'ieee', 'pp', 'enhance', 'molecular', 'property', 'prediction', 'mixture', 'collaborative', 'expert', 'arxiv', 'preprint', 'ad', 'versarial', 'mixture', 'expert', 'category', 'hierarchy', 'soft', 'constraint', 'ieee', '37th', 'international', 'conference', 'datum', 'engineering', 'icde', 'ieee', 'pp', 'agbese', 'r', 'mohanani', 'p', 'abrahamsson', 'implement', 'ai', 'ethic', 'make', 'sense', 'ethical', 'requirement', 'proceeding', '27th', 'international', 'conference', 'evaluation', 'assessment', 'software', 'engineering', 'pp', 'understand', 'mixtureofexpert', 'layer', 'deep', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'h', 'v', 'mixtureofexpert', 'expert', 'choice', 'route', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'guha', 'l', 'surani', 'r', 'bommasani', 'raji', 'p', 'ai', 'regulation', 'alignment', 'problem', 'technical', 'insti', 'tutional', 'disclosure', 'registration', 'licensing', 'audit', 'review', 'forthcoming', 'team', 'gemini', 'access', 'https', 'reportpdf', 'family', 'available', 'multimodal', 'gemini', 'online', 'model', 'capable', 'highly', 'n', 'g', 'j', 'falcone', 'p', 'topol', 'multimodal', 'biomedical', 'ai', 'nature', 'medicine', 'vol', 'pp', 'qi', 'l', 'limitation', 'multimodal', 'llm', 'deep', 'look', 'multimodal', 'llm', 'prompt', 'probe', 'information', 'processing', 'management', 'vol', 'p', 'b', 'r', 'grimm', 'p', 'grifﬁn', 'tion', 'artiﬁcial', 'intelligence', 'multimodality', 'cardiovascular', 'image', 'stateoftheart', 'review', 'progress', 'cardiovascular', 'disease', 'vol', 'pp', 'birhane', 'u', 'prabhu', 'e', 'kahembwe', 'multimodal', 'dataset', 'misogyny', 'pornography', 'malignant', 'stereotype', 'arxiv', 'preprint', 'mation', 'interaction', 'fusion', 'parallel', 'computing', 'system', 'use', 'ai', 'technique', 'international', 'journal', 'high', 'performance', 'system', 'architecture', 'vol', 'pp', 'l', 'deng', 'multimodal', 'intelligence', 'representation', 'learn', 'information', 'fusion', 'application', 'ieee', 'journal', 'select', 'topic', 'signal', 'processing', 'vol', 'pp', 'qiao', 'initial', 'image', 'use', 'image', 'prompt', 'improve', 'subject', 'representation', 'multimodal', 'ai', 'generate', 'art', 'proceeding', '14th', 'conference', 'creativity', 'cognition', 'pp', 'e', 'stewart', 'mello', 'multimodal', 'modeling', 'collaborative', 'problemsolving', 'facet', 'triad', 'user', 'modeling', 'useradapted', 'interaction', 'pp', 'l', 'xue', 'r', 'r', 'j', 'c', 'nieble', 'savarese', 'ulip2', 'scal', 'able', 'multimodal', 'pretraine', '3d', 'understand', 'arxiv', 'preprint', 'gasevic', 'scalability', 'sustainability', 'ethicality', 'multimodal', 'learn', 'analytic', 'lak22', '12th', 'international', 'learning', 'analytic', 'knowledge', 'pp', 'liuthompkin', 'artiﬁcial', 'empathy', 'marketing', 'interaction', 'bridge', 'humanai', 'gap', 'affective', 'social', 'customer', 'experience', 'journal', 'marketing', 'science', 'vol', 'pp', 'bag', 'hossain', 'n', 'new', 'wave', 'aipowere', 'luxury', 'brand', 'shopping', 'experience', 'role', 'digital', 'multisensory', 'cue', 'customer', 'engagement', 'journal', 'retailing', 'consumer', 'service', 'vol', 'p', 'chundi', 'roelofs', 'c', 'kochenderfer', 'multimodal', 'drive', 'dataset', 'joint', 'importance', 'ranking', 'reasoning', 'arxiv', 'preprint', 'arxiv230906597', 'c', 'cui', 'ye', 'survey', 'multimodal', 'large', 'language', 'model', 'autonomous', 'driving', 'arxiv', 'preprint', 'b', 'temsamani', 'k', 'chavali', 'tuytelaar', 'h', 'hamme', 'met', 'schepper', 'latr´e', 'multimodal', 'ai', 'approach', 'intuitively', 'instructable', 'autonomous', 'system', 'case', 'study', 'autonomous', 'offhighway', 'vehicle', 'eighteenth', 'international', 'conference', 'autonomic', 'autonomous', 'system', 'ica', 'pp', 'never', 'say', 'multimodal', 'disinformation', 'source', 'vividness', 'understand', 'power', 'enable', 'deepfake', 'news', 'medium', 'psychology', 'vol', 'pp', 'lyu', 'integrate', 'audiovisual', 'feature', 'multimodal', 'deepfake', 'detection', 'arxiv', 'preprint', 'gupta', 'tetarave', 'privacy', 'preservation', 'security', 'challenge', 'new', 'frontier', 'multimodal', 'machine', 'learn', 'research', 'international', 'journal', 'sensor', 'network', 'vol', 'pp', 'j', 'assistive', 'multimodal', 'robotic', 'system', 'amrsys', 'security', 'privacy', 'issue', 'challenge', 'possible', 'tion', 'apply', 'science', 'vol', 'p', 'serna', 'morale', 'j', 'fierrez', 'ortega', 'herrarte', 'humancentric', 'multimodal', 'machine', 'learn', 'recent', 'advance', 'testbe', 'aibased', 'recruitment', 'sn', 'computer', 'science', 'vol', 'p', 'r', 'wolfe', 'caliskan', 'american', 'white', 'multimodal', 'language', 'andimage', 'ai', 'proceeding', 'aaaiacm', 'conference', 'ai', 'ethic', 'society', 'pp', 'r', 'wolfe', 'howe', 'caliskan', 'contrastive', 'language', 'vision', 'model', 'pretraine', 'webscrape', 'multimodal', 'datum', 'exhibit', 'sexual', 'objectiﬁcation', 'bias', 'proceeding', 'acm', 'confer', 'ence', 'fairness', 'accountability', 'transparency', 'pp', 'r', 'brown', 'chhabra', 'h', 'development', 'multimodal', 'validation', 'substance', 'misuse', 'referral', 'treatment', 'use', 'artiﬁcial', 'intelligence', 'smartai', 'retrospective', 'deep', 'learning', 'study', 'vol', 'pp', 'journal', 'latex', 'class', 'file', 'vol', 'z', 'papamitsiou', 'giannakos', 'evidence', 'impact', 'ethical', 'consideration', 'multimodal', 'learn', 'analytic', 'systematic', 'literature', 'review', 'multimodal', 'learn', 'analytic', 'handbook', 'pp', 'dao', 'ai', 'paradigm', 'shift', 'alphago', 'chatgpt', 'vol', 'pp', 'roadmap', 'alphago', 'alphastar', 'problem', 'challenge', '2nd', 'international', 'conference', 'artiﬁcial', 'intelligence', 'automation', 'highperformance', 'computing', 'aiahpc', 'vol', 'spie', 'pp', 'datascalable', 'transformer', 'medical', 'image', 'segmentation', 'architecture', 'model', 'efﬁciency', 'benchmark', 'arxiv', 'preprint', 'w', 'peeble', 'scalable', 'diffusion', 'model', 'transformer', 'proceeding', 'ieeecvf', 'international', 'conference', 'com', 'puter', 'vision', 'pp', 'r', 'pope', 'dougla', 'chowdhery', 'heek', 'agrawal', 'efﬁciently', 'scale', 'transformer', 'inference', 'proceeding', 'machine', 'learning', 'system', 'vol', 'transformer', 'enhanced', 'atten', 'tion', 'mechanism', 'architecture', 'remain', 'useful', 'life', 'estimation', 'bearing', 'ieee', 'transaction', 'instrumentation', 'measurement', 'vol', 'pp', '1–10', 'de', 'novel', 'time', 'frequency', 'transformer', 'base', 'self', 'attention', 'mechanism', 'application', 'fault', 'diagnosis', 'rolling', 'bearing', 'mechanical', 'system', 'signal', 'processing', 'vol', 'p', 'shift', 'operation', 'meet', 'extremely', 'simple', 'alternative', 'attention', 'mechanism', 'proceeding', 'conference', 'artiﬁcial', 'intelligence', 'vol', 'pp', 'h', 'lightweight', 'multiscale', 'attention', 'highresolution', 'dense', 'prediction', 'proceed', 'ing', 'ieeecvf', 'international', 'conference', 'computer', 'vision', 'pp', 'efﬁcientvit', 'memory', 'efﬁcient', 'vision', 'transformer', 'cascade', 'group', 'attention', 'proceeding', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', 'fan', 'modiﬁed', 'detection', 'network', 'uav', 'aerial', 'image', 'recognition', 'drone', 'vol', 'p', 'zaineldin', 'improve', 'ﬁre', 'detection', 'approach', 'base', 'smart', 'city', 'neural', 'computing', 'application', 'vol', 'pp', 'enhanc', 'ing', 'covid19', 'safety', 'explore', 'yolov8', 'object', 'detection', 'accurate', 'face', 'mask', 'classiﬁcation', 'international', 'journal', 'intelligent', 'system', 'application', 'engineering', 'vol', 'pp', 'r', 'c', 'sun', 'battery', 'degradation', 'prediction', 'uncertain', 'future', 'con', 'dition', 'recurrent', 'neural', 'network', 'enable', 'deep', 'learning', 'energy', 'storage', 'material', 'vol', 'pp', 'onan', 'bidirectional', 'convolutional', 'recurrent', 'neural', 'network', 'archi', 'tecture', 'groupwise', 'enhancement', 'mechanism', 'text', 'sentiment', 'classiﬁcation', 'journal', 'king', 'saud', 'mation', 'science', 'vol', 'pp', 'armaghani', 'sheng', 'success', 'challenge', 'predict', 'tbm', 'penetration', 'rate', 'use', 'recurrent', 'neural', 'network', 'tunnelling', 'underground', 'space', 'technology', 'vol', 'p', 'r', 'kalidoss', 'jamal', 'p', 'nuagah', 'optimal', 'medical', 'image', 'size', 'reduction', 'model', 'creation', 'use', 'recurrent', 'neural', 'network', 'genpsowvq', 'journal', 'engineering', 'vol', 'zhu', 'application', 'recurrent', 'neural', 'network', 'mechanical', 'fault', 'diagnosis', 'review', 'journal', 'mechanical', 'science', 'technology', 'vol', 'pp', 'extract', 'weight', 'ﬁnite', 'automata', 'recurrent', 'neural', 'network', 'natural', 'language', 'international', 'conference', 'formal', 'engineering', 'method', 'pp', 'r', 'scattolini', 'recurrent', 'neural', 'network', 'learningbased', 'control', 'recent', 'result', 'idea', 'future', 'development', 'journal', 'process', 'control', 'vol', 'pp', '92–104', 'z', 'guo', 'viewrefer', 'grasp', 'multiview', 'knowledge', '3d', 'visual', 'grounding', 'proceeding', 'ieeecvf', 'international', 'conference', 'computer', 'vision', 'pp', 'baeformer', 'bidirectional', 'early', 'interaction', 'transformer', 'bird', 'eye', 'view', 'semantic', 'segmentation', 'proceeding', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', 'p', 'clifton', 'multimodal', 'learn', 'transform', 'er', 'survey', 'ieee', 'transaction', 'pattern', 'analysis', 'machine', 'intelligence', 'gaˇsevi´c', 'measure', 'selfregulate', 'learning', 'role', 'ai', 'year', 'research', 'use', 'multimodal', 'datum', 'computer', 'human', 'behavior', 'vol', 'p', 'steyaert', 'nagaraj', 'j', 'gentle', 'multimodal', 'datum', 'fusion', 'cancer', 'biomarker', 'discovery', 'deep', 'learning', 'nature', 'machine', 'intelligence', 'vol', 'pp', 'mittal', 'self', 'supervise', 'learn', 'succinct', 'review', 'archive', 'computational', 'method', 'engineering', 'vol', 'pp', 'rawat', 'shah', 'selfsupervise', 'learning', 'video', 'survey', 'acm', 'computing', 'survey', 'vol', '13', 'pp', '1–37', 'selfsupervise', 'learning', 'recommender', 'system', 'survey', 'ieee', 'transaction', 'knowledge', 'datum', 'engineering', 'bharti', 'purohit', 'r', 'k', 'label', 'efﬁcient', 'semi', 'selfsupervise', 'learning', 'framework', 'device', 'industrial', 'process', 'ieee', 'transaction', 'industrial', 'informatic', 'z', 'kolter', 'loss', 'label', 'weakly', 'supervise', 'loss', 'construction', 'proceeding', 'direct', 'conference', 'artiﬁcial', 'intelligence', 'vol', 'pp', 't5base', 'model', 'abstractive', 'summarization', 'semisupervised', 'learning', 'approach', 'consistency', 'loss', 'function', 'apply', 'science', 'vol', 'p', 'qiao', 'unsupervise', 'person', 'identiﬁcation', 'learn', 'guide', 'selfpace', 'clustering', 'pattern', 'recognition', 'vol', 'p', 'pallathadka', 'nave', 'arumugam', 'garchar', 'deep', 'learning', 'machine', 'learn', 'base', 'efﬁcient', 'framework', 'image', 'base', 'plant', 'disease', 'classiﬁcation', 'detection', 'international', 'conference', 'advanced', 'compute', 'gy', 'application', 'icacta', 'ieee', 'pp', 'p', 'z', 'ensemble', 'unsupervised', 'autoencoder', 'gaussian', 'mixture', 'model', 'cyberattack', 'detection', 'information', 'processing', 'management', 'vol', 'p', 'hybrid', 'robust', 'autoencoder', 'unsupervised', 'detection', 'machine', 'tool', 'noise', 'robotic', 'computerintegrate', 'manufacturing', 'vol', 'p', 'machine', 'learning', 'nextg', 'network', 'generative', 'adversarial', 'network', 'ieee', 'action', 'cognitive', 'communication', 'network', 'vol', 'pp', 'physical', 'model', 'inform', 'fault', 'detection', 'diagnosis', 'air', 'handle', 'unit', 'base', 'transformer', 'generative', 'adversarial', 'network', 'ieee', 'transaction', 'industrial', 'informatic', 'vol', 'pp', 'hybrid', 'quantum', 'classical', 'generative', 'adversarial', 'network', 'image', 'generation', 'learn', 'discrete', 'distribution', 'signal', 'processing', 'image', 'vol', 'p', 'r', 'mo', 'recurrent', 'neural', 'network', 'longterm', 'time', 'series', 'forecasting', 'arxiv', 'preprint', 'exploration', 'deep', 'reinforcement', 'learn', 'survey', 'information', 'fusion', 'vol', 'pp', 'journal', 'latex', 'class', 'file', 'vol', 'sahani', 'precup', 'silver', 'uchibe', 'morimoto', 'deep', 'learning', 'reinforcement', 'learning', 'world', 'model', 'neural', 'network', 'vol', 'pp', 'bertoin', 'zouitine', 'rachelson', 'look', 'look', 'saliencyguided', 'qnetwork', 'generalization', 'visual', 'reinforcement', 'learning', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'haﬁz', 'survey', 'deep', 'qnetwork', 'use', 'reinforcement', 'learning', 'state', 'art', 'intelligent', 'communication', 'technology', 'virtual', 'mobile', 'network', 'proceeding', 'pp', 'haﬁz', 'alsubai', 'hameed', 'reinforcement', 'learning', 'ensemble', 'binary', 'action', 'deep', 'q', 'network', 'computer', 'system', 'science', 'engineering', 'vol', 'r', 'mizouni', 'j', 'bentahar', 'target', 'localization', 'use', 'multiagent', 'deep', 'reinforcement', 'learning', 'imal', 'policy', 'optimization', 'future', 'generation', 'computer', 'system', 'vol', 'pp', '3to', 'thzenable', 'throughput', 'trajectory', 'optimization', 'uavs', 'g', 'network', 'proximal', 'policy', 'optimization', 'deep', 'reinforcement', 'learn', 'icc', 'international', 'conference', 'communication', 'ieee', 'pp', 'k', 'jayant', 'bhatnagar', 'modelbase', 'safe', 'deep', 'reinforcement', 'learning', 'constrain', 'proximal', 'policy', 'optimization', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'reinforcement', 'learning', 'bandit', 'speech', 'language', 'processing', 'tutorial', 'review', 'outlook', 'expert', 'system', 'appli', 'cation', 'rein', 'forcement', 'learning', 'continuousaction', 'space', 'ieee', 'transaction', 'neural', 'network', 'learn', 'system', 'raza', 'tran', 'l', 'koehl', 'design', 'ecg', 'monitor', 'healthcare', 'system', 'federate', 'transfer', 'learning', 'explainable', 'knowledgebase', 'system', 'vol', 'p', 'siahpour', 'novel', 'transfer', 'learn', 'approach', 'life', 'prediction', 'incomplete', 'dataset', 'ieee', 'remain', 'useful', 'transaction', 'instrumentation', 'measurement', 'vol', 'pp', '1–11', 'z', 'guo', 'chit', 'transfer', 'learn', 'angle', 'arrival', 'estimation', 'massive', 'mimo', 'system', 'ieeecic', 'international', 'conference', 'communication', 'ieee', 'pp', 'bao', 'adaptive', 'reconstruction', 'digital', 'twin', 'machining', 'system', 'transfer', 'learn', 'approach', 'robotic', 'computerintegrate', 'manufacturing', 'vol', 'p', 'cui', 'logiqa', 'improved', 'dataset', 'logical', 'reasoning', 'natural', 'language', 'understand', 'ieeeacm', 'transaction', 'audio', 'speech', 'language', 'processing', 'generate', 'training', 'datum', 'language', 'model', 'zeroshot', 'language', 'understanding', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'r', 'samant', 'bachute', 'gite', 'framework', 'deep', 'learningbased', 'language', 'model', 'use', 'multitask', 'learning', 'natural', 'language', 'understand', 'systematic', 'literature', 'review', 'future', 'direction', 'ieee', 'access', 'vol', 'pp', 'h', 'weld', 'long', 'j', 'poon', 'survey', 'joint', 'intent', 'detection', 'slot', 'ﬁlling', 'model', 'natural', 'language', 'understand', 'acm', 'computing', 'survey', 'vol', 'pp', 'ajmal', 'ahme', 'natural', 'language', 'process', 'ing', 'improve', 'information', 'retrieval', 'knowledge', 'conversational', 'agent', 'journal', 'artiﬁcial', 'intelligence', 'machine', 'learning', 'management', 'vol', 'pp', 'montejor´aez', 'current', 'approach', 'application', 'natural', 'language', 'processing', 'apply', 'science', 'vol', 'p', 'anand', 'sahaj', 'languageagnostic', 'text', 'process', 'ing', 'information', 'extraction', 'conference', 'proceeding', 'vol', 'conference', 'proceeding', 'c', 'man', 'human', 'language', 'understand', 'reasoning', 'daedalus', 'vol', 'pp', 'embedding', 'useful', 'ad', 'recommendation', 'international', 'conference', 'knowledge', 'science', 'engineering', 'management', 'springer', 'pp', 'e', 'erdem', 'frank', 'l', 'parcalabescu', 'plank', 'babii', 'turuta', 'erdem', 'calixto', 'neural', 'natural', 'language', 'generation', 'survey', 'multilinguality', 'multimodality', 'con', 'trollability', 'learning', 'journal', 'artiﬁcial', 'intelligence', 'research', 'vol', 'pp', 'controllable', 'natural', 'language', 'generation', 'contrastive', 'preﬁxe', 'arxiv', 'preprint', 'arxiv220213257', 'aroyo', 'petrov', 'tomar', 'turc', 'reitter', 'measure', 'attribution', 'natural', 'language', 'generation', 'model', 'computational', 'linguistic', 'pp', 'k', 'pandey', 'roy', 'natural', 'language', 'generation', 'use', 'sequential', 'model', 'survey', 'neural', 'processing', 'letter', 'pp', 'uddin', 'automatic', 'code', 'documentation', 'generation', '37th', 'ieeeacm', 'international', 'use', 'gpt3', 'proceeding', 'conference', 'automate', 'software', 'engineering', 'pp', 'l', 'slade', 'koohang', 'chatgpt', 'write', 'multidisciplinary', 'perspective', 'op', 'portunitie', 'challenge', 'implication', 'generative', 'conversational', 'ai', 'research', 'practice', 'policy', 'international', 'journal', 'information', 'management', 'vol', 'p', 'fu', 'gao', 'learn', 'conversational', 'ai', 'survey', 'ai', 'open', 'vol', 'pp', 'h', 'ko', 'systematic', 'review', 'conversational', 'ai', 'language', 'education', 'focus', 'collaboration', 'human', 'teacher', 'journal', 'research', 'technology', 'education', 'vol', 'pp', 'h', 'bai', 'biasasker', 'measure', 'bias', 'conversational', 'system', 'proceeding', '31st', 'acm', 'joint', 'european', 'software', 'engineering', 'conference', 'symposium', 'foundation', 'software', 'engineering', 'pp', 'aibase', 'conversational', 'agent', 'scope', 'review', 'technology', 'future', 'direction', 'ieee', 'access', 'see', 'machine', 'design', 'build', 'versational', 'ai', 'understand', 'human', 'phd', 'dissertation', 'urbanachampaign', 'park', 'seo', 'largescale', 'texttoimage', 'generation', 'model', 'visual', 'artist', 'creative', 'work', 'proceeding', '28th', 'international', 'conference', 'intelligent', 'user', 'interface', 'pp', 'pearson', 'rise', 'crealtive', 'use', 'ai', 'enable', 'speed', 'creative', 'process', 'journal', 'ai', 'robotic', 'workplace', 'automation', 'vol', 'pp', 'maher', 'design', 'creative', 'ai', 'partner', 'framework', 'model', 'interaction', 'humanai', 'cocreative', 'system', 'acm', 'transaction', 'computerhuman', 'interaction', 'vol', 'pp', 'sharma', 'generative', 'adversarial', 'network', 'gan', 'creative', 'application', 'explore', 'art', 'music', 'generation', 'tional', 'journal', 'multidisciplinary', 'innovation', 'research', 'method', 'ology', 'vol', 'pp', 'attardfrost', 'r', 'walter', 'ethic', 'business', 'practice', 'review', 'ai', 'ethic', 'guideline', 'ai', 'ethic', 'vol', 'pp', 'gardner', 'l', 'coughlan', 'ethical', 'funding', 'trustworthy', 'ai', 'proposal', 'address', 'respon', 'sibilitie', 'funder', 'ensure', 'project', 'adhere', 'trustworthy', 'practice', 'ai', 'ethic', 'pp', 'line', 'defense', 'risk', 'ai', 'society', 'pp', 'sloane', 'german', 'ai', 'startup', 'ai', 'ethic', 'use', 'social', 'practice', 'lens', 'assess', 'implement', 'technical', 'innovation', 'proceeding', 'acm', 'conference', 'fairness', 'accountability', 'transparency', 'pp', 'cardonha', 'gonc¸alve', 'modeling', 'epistemo', 'logical', 'principle', 'bias', 'mitigation', 'system', 'illustration', 'hire', 'decision', 'proceeding', 'aaaiacm', 'conference', 'ai', 'ethic', 'society', 'pp', 'journal', 'latex', 'class', 'file', 'vol', 'gupta', 'singhal', 'yadav', 'natarajan', 'hedau', 'joo', 'enhance', 'fairness', 'face', 'detection', 'computer', 'vision', 'system', 'demographic', 'bias', 'mitigation', 'proceeding', 'aaaiacm', 'conference', 'ai', 'ethic', 'society', 'pp', 'r', 'schwartz', 'vassilev', 'burt', 'p', 'hall', 'standard', 'identify', 'manage', 'bias', 'artiﬁcial', 'intelligence', 'nist', 'special', 'publication', 'vol', 'w', 'caliskan', 'detect', 'emergent', 'intersectional', 'bias', 'contextualize', 'word', 'embedding', 'contain', 'distribution', 'humanlike', 'bias', 'proceeding', 'aaaiacm', 'conference', 'ai', 'ethic', 'society', 'pp', 'intersectionally', 'fair', 'ai', 'algorithm', 'really', 'fair', 'woman', 'color', 'philosophical', 'analysis', 'proceeding', 'acm', 'conference', 'fairness', 'accountability', 'transparency', 'pp', 'celi', 'assess', 'social', 'intersectional', 'bias', 'contextualize', 'word', 'representation', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'mosallanezhad', 'p', 'learning', 'socially', 'responsible', 'ai', 'arxiv', 'preprint', 'arxiv210412278', 'correa', 'identiﬁcation', 'causal', 'effect', 'presence', 'selection', 'bias', 'proceeding', 'conference', 'artiﬁcial', 'intelligence', 'vol', 'pp', 'dbia', 'causalitybased', 'loop', 'system', 'tackle', 'algorithmic', 'bias', 'ieee', 'transaction', 'visualization', 'computer', 'graphic', 'vol', 'pp', 'h', 'rzeszotarski', 'silva', 'interactively', 'assess', 'machine', 'learning', 'fairness', 'use', 'causality', 'proceeding', 'chi', 'conference', 'human', 'factor', 'compute', 'system', 'pp', 'bertino', 'mittal', 'gupta', 'ai', 'security', 'security', 'ai', 'proceeding', 'eleventh', 'acm', 'conference', 'datum', 'application', 'security', 'privacy', 'pp', 'h', 'susanto', 'rosiyadi', 'basuki', 'datum', 'security', 'connected', 'government', 'organisation', 'manage', 'tomation', 'artiﬁcial', 'intelligence', 'web', 'cloud', 'technology', 'implement', 'connected', 'government', 'global', 'pp', 'r', 'brust', 'g', 'danoy', 'cassagne', 'pecero', 'privacy', 'security', 'big', 'datum', 'system', 'research', 'standard', 'perspective', 'ieee', 'international', 'conference', 'big', 'datum', 'big', 'datum', 'ieee', 'pp', 'intercept', 'ransomware', 'attack', 'stage', 'event', 'drive', 'access', 'control', 'phd', 'dissertation', 'trobe', 'kaye', 'p', 'watter', 'apply', 'stage', 'eventdriven', 'access', 'control', 'combat', 'ransomware', 'computer', 'security', 'vol', 'p', 'braun', 'tretter', 'p', 'dabrock', 'datum', 'sovereignty', 'review', 'big', 'data', 'society', 'vol', 'p', 'luking', 'habibi', 'lashkari', 'datum', 'sovereignty', 'stand', 'cybersecurity', 'law', 'datum', 'sovereignty', 'digital', 'overview', 'legal', 'perspective', 'springer', 'pp', 'lesson', 'learn', 'ethic', 'principle', 'future', 'action', 'ai', 'ethic', 'vol', 'pp', 'ai', 'ethic', 'principle', 'practice', 'ai', 'society', 'pp', '1–11', 'j', 'kroll', 'outline', 'traceability', 'principle', 'operationalize', 'accountability', 'computing', 'system', 'proceeding', 'acm', 'conference', 'fairness', 'accountability', 'transparency', 'pp', 'oseni', 'z', 'tari', 'vasilakos', 'intelligence', 'opportunity', 'security', 'privacy', 'artiﬁcial', 'challenge', 'arxiv', 'preprint', 'b', 'wright', 'ethic', 'privacy', 'big', 'datum', 'implement', 'responsible', 'research', 'innovation', 'ieee', 'security', 'privacy', 'vol', 'pp', 'de', 'yuan', 'h', 'poor', 'trust', 'ai', 'multiagent', 'system', 'overview', 'privacy', 'security', 'distribute', 'learn', 'proceeding', 'ieee', 'vol', 'pp', 'song', 'h', 'analyze', 'userlevel', 'privacy', 'attack', 'federated', 'learning', 'ieee', 'journal', 'select', 'area', 'communication', 'vol', 'pp', 'misra', 'l', 'maaten', 'selfsupervise', 'learning', 'pretext', 'invariant', 'representation', 'proceeding', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', '6707–6717', 'kolesnikov', 'l', 'beyer', 'selfsupervise', 'semisupervised', 'learning', 'proceeding', 'ieeecvf', 'interna', 'tional', 'conference', 'computer', 'vision', 'pp', 'ritter', 'lucic', 'selfsupervise', 'gan', 'auxiliary', 'rotation', 'loss', 'proceeding', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', 'favaro', 'selfsupervise', 'feature', 'learning', 'learn', 'spot', 'artifact', 'proceeding', 'ieee', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', 'krishnamurthy', 'self', 'supervise', 'gan', 'latent', 'transformation', 'detection', 'proceeding', 'ieeecvf', 'winter', 'conference', 'application', 'computer', 'vision', 'pp', 'simple', 'frame', 'work', 'contrastive', 'learning', 'visual', 'representation', 'international', 'conference', 'machine', 'learn', 'pmlr', 'pp', 'k', 'fan', 'girshick', 'momentum', 'contrast', 'unsupervised', 'visual', 'representation', 'learn', 'proceeding', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', 'tera', 'selfsupervise', 'learning', 'transformer', 'encoder', 'representation', 'speech', 'ieeeacm', 'transac', 'tion', 'audio', 'speech', 'language', 'processing', 'vol', 'pp', 'yuan', 'mask', 'autoencoder', 'point', 'cloud', 'selfsupervise', 'learning', 'european', 'conference', 'computer', 'vision', 'pp', 'hospedale', 'antoniou', 'storkey', 'meta', 'learning', 'neural', 'network', 'survey', 'ieee', 'transaction', 'pattern', 'analysis', 'machine', 'intelligence', 'vol', 'pp', 'r', 'perspective', 'view', 'survey', 'meta', 'learning', 'artiﬁcial', 'intelligence', 'review', 'vol', 'pp', '77–95', 'e', 'talwalkar', 'datum', 'efﬁciency', 'metalearning', 'international', 'conference', 'artiﬁcial', 'intelligence', 'statistic', 'pmlr', 'pp', '1369–1377', 'r', 'tasksequence', 'meta', 'learning', 'intelligent', 'fewshot', 'fault', 'diagnosis', 'limited', 'data', 'ieee', 'transaction', 'industrial', 'informatic', 'vol', 'pp', 'baik', 'h', 'min', 'meta', 'learning', 'taskadaptive', 'loss', 'function', 'fewshot', 'learning', 'proceeding', 'ieeecvf', 'international', 'conference', 'computer', 'vision', 'pp', 'h', 'darrell', 'metabaseline', 'explore', 'simple', 'metalearning', 'fewshot', 'learning', 'proceeding', 'ieeecvf', 'international', 'conference', 'computer', 'vision', 'pp', 'jamal', 'gj', 'qi', 'task', 'agnostic', 'metalearning', 'fewshot', 'learning', 'proceeding', 'ieeecvf', 'conference', 'computer', 'vision', 'pattern', 'recognition', 'pp', 'r', 'behnia', 'tune', 'framework', 'privately', 'ﬁnetune', 'large', 'language', 'model', 'differential', 'privacy', 'ieee', 'international', 'conference', 'datum', 'mining', 'workshop', 'ieee', 'pp', 'lester', 'v', 'finetune', 'language', 'model', 'zeroshot', 'learner', 'arxiv', 'preprint', 'gao', 'ding', 'federatedscopellm', 'comprehensive', 'package', 'ﬁnetune', 'large', 'language', 'model', 'federate', 'learn', 'arxiv', 'preprint', 'arxiv230900363', 'nguyen', 'chadha', 'vu', 'efﬁ', 'ﬁnetune', 'large', 'language', 'model', 'knowledgeaware', 'response', 'plan', 'joint', 'european', 'conference', 'machine', 'learning', 'knowledge', 'discovery', 'database', 'springer', 'pp', 'klau', 'scheerer', 'drawehn', 'finetune', 'align', 'question', 'answering', 'model', 'complex', 'information', 'extraction', 'task', 'arxiv', 'preprint', 'journal', 'latex', 'class', 'file', 'vol', 'wilson', 'finetune', 'large', 'language', 'model', 'detect', 'online', 'sexual', 'predatory', 'chat', 'abusive', 'text', 'arxiv', 'preprint', 'arxiv230814683', 'q', 'regionblip', 'uniﬁed', 'multimodal', 'pretraining', 'framework', 'holistic', 'regional', 'comprehension', 'arxiv', 'preprint', 'arxiv230802299', 'arnold', 'kasenberg', 'value', 'alignment', 'misalignment', 'keep', 'system', 'accountable', 'ai', 'ethic', 'society', 'gabriel', 'ghazavi', 'challenge', 'value', 'alignment', 'fair', 'algorithm', 'ai', 'safety', 'arxiv', 'preprint', 'arxiv210106060', 'nyholm', 'responsibility', 'gap', 'value', 'alignment', 'meaningful', 'human', 'control', 'artiﬁcial', 'intelligence', 'risk', 'responsibility', 'context', 'routledge', 'pp', 'nextgpt', 'multimodal', 'llm', 'arxiv', 'preprint', 'mtibaa', 'survey', 'deep', 'multimodal', 'learn', 'computer', 'vision', 'advance', 'trend', 'application', 'dataset', 'visual', 'computer', 'pp', '1–32', 'scalable', 'deep', 'multimodal', 'learn', 'crossmodal', 'retrieval', 'proceeding', '42nd', 'international', 'conference', 'research', 'development', 'information', 'retrieval', 'pp', 'rahate', 'r', 'walambe', 'ramanna', 'learn', 'challenge', 'application', 'dataset', 'recent', 'advance', 'future', 'direction', 'information', 'fusion', 'vol', 'pp', 'multimodal', 'federate', 'learn', 'survey', 'sensor', 'vol', 'p', 'p', 'p', 'fan', 'multibench', 'multiscale', 'benchmark', 'multimodal', 'representation', 'learn', 'arxiv', 'preprint', 'z', 'kumaravel', 'humanai', 'collaboration', 'co', 'operative', 'game', 'set', 'measure', 'social', 'perception', 'outcome', 'proceeding', 'acm', 'humancomputer', 'interaction', 'vol', 'cscw2', 'pp', 'mirzaei', 'dharanikota', 'patient', 'perception', 'human', 'artiﬁcial', 'intelligence', 'interaction', 'health', 'care', 'exper', 'imental', 'study', 'journal', 'medical', 'internet', 'research', 'vol', 'p', 'systematic', 'review', 'human', 'computer', 'interaction', 'explainable', 'artiﬁcial', 'intelligence', 'healthcare', 'artiﬁcial', 'intelligence', 'technique', 'ieee', 'access', 'vol', 'rajawat', 'r', 'rawat', 'ghosh', 'robotic', 'process', 'automation', 'increase', 'productivity', 'improv', 'ing', 'product', 'quality', 'use', 'artiﬁcial', 'intelligence', 'machine', 'learning', 'artiﬁcial', 'intelligence', 'future', 'generation', 'robotic', 'elsevi', 'pp', 'mohseni', 'zarei', 'e', 'ragan', 'multidisciplinary', 'survey', 'framework', 'design', 'evaluation', 'explainable', 'system', 'acm', 'transaction', 'interactive', 'intelligent', 'system', 'tiis', 'vol', 'pp', '1–45', 'c', 'buehler', 'weisswange', 'theory', 'mind', 'base', 'com', 'munication', 'human', 'agent', 'cooperation', 'ieee', 'international', 'conference', 'humanmachine', 'system', 'ichm', 'ieee', 'pp', 'interactive', 'ai', 'theory', 'mind', 'arxiv', 'preprint', 'dafoe', 'e', 'hughe', 'bachrach', 'leibo', 'graepel', 'open', 'problem', 'cooperative', 'ai', 'arxiv', 'preprint', 'arxiv201208630', 'bubeck', 'chandrasekaran', 'r', 'spark', 'intelligence', 'early', 'experiment', 'gpt4', 'arxiv', 'artiﬁcial', 'general', 'preprint', 'gao', 'r', 'song', 'artiﬁcial', 'general', 'intelligence', 'multimodal', 'foundation', 'model', 'nature', 'communication', 'vol', 'p', 'r', 'r', 'yampolskiy', 'understanding', 'avoid', 'failure', 'practical', 'guide', 'philosophy', 'vol', 'p', 'zoph', 'shazeer', 'switch', 'transformer', 'scale', 'parameter', 'model', 'simple', 'efﬁcient', 'sparsity', 'journal', 'machine', 'learn', 'research', 'vol', 'pp', 'hou', 'mixtureofexpert', 'meet', 'instruction', 'tune', 'win', 'combination', 'large', 'language', 'model', 'arxiv', 'preprint', 'awan', 'deepspeedmoe', 'advance', 'mixtureof', 'expert', 'inference', 'training', 'power', 'nextgeneration', 'scale', 'international', 'conference', 'machine', 'learn', 'pmlr', 'pp', 'semoe', 'scalable', 'efﬁcient', 'mixture', 'ofexpert', 'distribute', 'training', 'inference', 'system', 'arxiv', 'preprint', 'c', 'r', 'salas', 'jose', 'p', 'adaptive', 'mixtureofexpert', 'scale', 'proceeding', 'machine', 'learning', 'system', 'vol', 'gao', 'h', 'j', 'gao', 'adamix', 'mixtureofadapter', 'parameterefﬁcient', 'tuning', 'large', 'language', 'model', 'arxiv', 'preprint', 'vol', 'p', 'jaiswal', 'sparse', 'moe', 'new', 'dropout', 'scale', 'dense', 'selfslimmable', 'transformer', 'arxiv', 'preprint', 'multigate', 'mixtureofexpert', 'stack', 'autoencoder', 'quality', 'prediction', 'blast', 'furnace', 'ironmaking', 'acs', 'omega', 'vol', 'pp', 'singhal', 'p', 'song', 'representation', 'collapse', 'sparse', 'mixture', 'expert', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'gupta', 'mukherjee', 'jose', 'h', 'gao', 'sparsely', 'activate', 'mixtureofexpert', 'robust', 'learner', 'arxiv', 'preprint', 'arxiv220407689', 'r', 'meka', 'r', 'panigrahy', 'vyas', 'beneﬁts', 'learn', 'route', 'mixtureofexpert', 'model', 'proceeding', 'conference', 'empirical', 'method', 'natural', 'language', 'processing', 'pp', 'dryden', 'hoeﬂer', 'spatial', 'mixtureofexpert', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'z', 'yu', 'speechmoe2', 'mixtureof', 'expert', 'model', 'improved', 'routing', 'ieee', 'international', 'conference', 'acoustic', 'speech', 'signal', 'processing', 'ieee', 'pp', 'puigcerver', 'r', 'riquelme', 'p', 'awasthi', 'adversarial', 'robustness', 'mixture', 'expert', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'c', 'accelerate', 'distribute', 'moe', 'training', 'inference', 'lina', 'usenix', 'annual', 'technical', 'conference', 'usenix', 'atc', 'pp', '945–959', 'yuan', 'residual', 'mixture', 'expert', 'arxiv', 'preprint', 'zoph', 'bello', 'shazeer', 'design', 'effective', 'sparse', 'expert', 'model', 'arxiv', 'preprint', 'arxiv220208906', 'vol', 'stmoe', 'design', 'stable', 'transferable', 'sparse', 'expert', 'els', 'arxiv', 'preprint', 'arxiv220208906', 'chow', 'tulepbergenov', 'c', 'boutili', 'mixtureofexpert', 'approach', 'rlbase', 'dialogue', 'management', 'arxiv', 'preprint', 'z', 'fan', 'r', 'sarkar', 'mixtureofexpert', 'transformer', 'efﬁcient', 'multi', 'task', 'learn', 'modelaccelerator', 'codesign', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', '¨ust¨un', 'ahmadian', 'locatelli', 'hooker', 'push', 'mixture', 'expert', 'limit', 'extremely', 'instruction', 'tune', 'arxiv', 'preprint', 'parameter', 'efﬁcient', 'moe', 'perceivermoe', 'learn', 'sparse', 'generalist', 'model', 'conditional', 'moe', 'advance', 'neural', 'information', 'processing', 'system', 'vol', 'pp', 'j', 'ye', 'artiﬁcial', 'general', 'intelligence', 'agi', 'internet', 'thing', 'iot', 'opportunity', 'challenge', 'arxiv', 'preprint', 'journal', 'latex', 'class', 'file', 'vol', 'twitter', 'journal', 'university', 'teaching', 'learn', 'practice', 'vol', 'p', 'ling', 'improve', 'policy', 'optimization', 'generalistspecialist', 'learn', 'international', 'conference', 'machine', 'learn', 'pmlr', 'pp', 'simeone', 'unknown', 'future', 'repeat', 'present', 'narrativecentered', 'analysis', 'longterm', 'ai', 'discourse', 'humanist', 'study', 'digital', 'age', 'vol', 'nair', 'banaeikashani', 'bridge', 'gap', 'ar', 'tiﬁcial', 'intelligence', 'com', 'mandment', 'framework', 'humanlike', 'intelligence', 'arxiv', 'preprint', 'intelligence', 'artiﬁcial', 'general', 'askay', 'artiﬁcial', 'gence', 'knowledge', 'management', 'partnership', 'human', 'ai', 'business', 'horizon', 'vol', 'pp', 'mcenteggart', 'barnesholme', 'functional', 'contextual', 'account', 'background', 'knowledge', 'categorization', 'plication', 'artiﬁcial', 'general', 'intelligence', 'cognitive', 'account', 'general', 'knowledge', 'frontier', 'psychology', 'vol', 'p', 'artiﬁcial', 'intelligence', 'logic', 'formalise', 'common', 'sense', 'machine', 'learning', 'city', 'application', 'architecture', 'urban', 'design', 'pp', 'friederich', 'symbiosis', 'alignment', 'goal', 'liberal', 'democracy', 'transition', 'artiﬁcial', 'general', 'intelligence', 'ai', 'ethic', 'pp', '1–10', 'makridakis', 'forthcoming', 'artiﬁcial', 'intelligence', 'ai', 'revolution', 'impact', 'society', 'ﬁrm', 'future', 'vol', 'pp', 'pal', 'saha', 'publication', 'r', 'sharma', 'deb', 'artiﬁcial', 'intelligence', 'marketing', 'systematic', 'review', 'future', 'research', 'direction', 'tional', 'journal', 'information', 'management', 'datum', 'insight', 'vol', 'p', 'chowdhury', 'wood', 'h', 'aguini', 'bamber', 'p', 'decker', 'denisi', 'et', 'human', 'resource', 'management', 'age', 'generative', 'artiﬁcial', 'intelligence', 'perspective', 'research', 'direction', 'chatgpt', 'human', 'resource', 'management', 'journal', 'vol', 'pp', 'j', 'telkamp', 'implication', 'diverse', 'human', 'moral', 'foundation', 'assess', 'ethicality', 'artiﬁcial', 'intelligence', 'journal', 'business', 'ethic', 'vol', 'pp', 'interpretable', 'robust', 'ai', 'eeg', 'system', 'survey', 'arxiv', 'preprint', 'c', 'small', 'step', 'generative', 'ai', 'giant', 'leap', 'complete', 'survey', 'chatgpt', 'aigc', 'era', 'arxiv', 'preprint', 'singhal', 'r', 'sayre', 'e', 'wulczyn', 'l', 'hou', 'pfohl', 'h', 'neal', 'et', 'expert', 'level', 'medical', 'question', 'answer', 'large', 'language', 'model', 'arxiv', 'preprint', 'arxiv230509617', 'irsoy', 'lu', 'dredze', 'gehrmann', 'p', 'kambadur', 'bloomberggpt', 'large', 'language', 'model', 'ﬁnance', 'arxiv', 'preprint', 'sinha', 'angelardgonti', 'r', 'ke', 'fry', 'r', 'lowe', 'ethical', 'challenge', 'datadriven', 'dialogue', 'system', 'proceeding', 'aaaiacm', 'conference', 'ai', 'ethic', 'society', 'pp', 'bouteraa', 'use', 'chatgpt', 'academia', 'academic', 'integrity', 'hang', 'balance', 'technology', 'society', 'vol', 'p', 'brown', 'increase', 'pressure', 'overhaul', 'scientiﬁc', 'peer', 'review', 'process', 'comment', 'artiﬁcial', 'intelligence', 'generate', 'fraudulent', 'authenticlooke', 'scientiﬁc', 'medical', 'article', 'open', 'j', 'internet', 'res', 'vol', 'p', 'p', 'siddaway', 'wood', 'l', 'v', 'hedge', 'systematic', 'review', 'good', 'practice', 'guide', 'conduct', 'report', 'narrative', 'review', 'metaanalyse', 'metasynthese', 'annual', 'review', 'psychology', 'vol', 'pp', 'e', 'literature', 'information', 'overload', 'nature', 'vol', 'pp', 'g', 'chloros', 'p', 'giannoudis', 'p', 'v', 'giannoudis', 'peerreviewe', 'surgical', 'journal', 'revolutionize', 'perish', 'annal', 'surgery', 'vol', 'pp', 'e82', 'e90', 'rainsford', 'l', 'walsh', 'improve', 'peer', 'review', 'crowdsource', 'insight']"
"On-Device Recommender Systems: A Tutorial on The New-Generation
  Recommendation Paradigm","[{'href': 'http://arxiv.org/abs/2312.10864v1', 'rel': 'alternate', 'type': 'text/html'}, {'title': 'pdf', 'href': 'http://arxiv.org/pdf/2312.10864v1', 'rel': 'related', 'type': 'application/pdf'}]",2023-12-18 00:57:03,"3
2
0
2

c
e
D
8
1

]

R

I
.
s
c
[

1
v
4
6
8
0
1
.
2
1
3
2
:
v
i
X
r
a

On-Device Recommender Systems: A Tutorial on
The New-Generation Recommendation Paradigm

Hongzhi Yin
The University of Queensland
Brisbane, QLD, Australia
h.yin1@uq.edu.au

Liang Qu
The University of Queensland
Brisbane, QLD, Australia
liang.qu@uq.edu.au

Tong Chen
The University of Queensland
Brisbane, QLD, Australia
tong.chen@uq.edu.au

Bin Cui
Peking University
Beijing, China
bin.cui@pku.edu.cn

ABSTRACT
Given the sheer volume of contemporary e-commerce applications,
recommender systems (RSs) have gained signiﬁcant attention in
both academia and industry. However, traditional cloud-based RSs
face inevitable challenges, such as resource-intensive computation,
reliance on network access, and privacy breaches. In response, a
new paradigm called on-device recommender systems (ODRSs) has
emerged recently in various industries like Taobao, Google, and
Kuaishou. ODRSs unleash the computational capacity of user de-
vices with lightweight recommendation models tailored for resource-
constrained environments, enabling real-time inference with users’
local data. This tutorial aims to systematically introduce method-
ologies of ODRSs, including (1) an overview of existing research on
ODRSs; (2) a comprehensive taxonomy of ODRSs, where the core
technical content to be covered span across three major ODRS re-
search directions, including on-device deployment and inference,
on-device training, and privacy/security of ODRSs; (3) limitations
and future directions of ODRSs. This tutorial expects to lay the
foundation and spark new insights for follow-up research and ap-
plications concerning this new recommendation paradigm.

CCS CONCEPTS
• Information systems → Recommender systems.

KEYWORDS
On-device Learning, Recommender Systems, Federated Learning,
Privacy and Security

ACM Reference Format:
Hongzhi Yin, Tong Chen, Liang Qu, and Bin Cui. 2024. On-Device Rec-
ommender Systems: A Tutorial on The New-Generation Recommendation
Paradigm. In Proceedings of The Web Conference 2024. ACM, New York, NY,
USA, 4 pages. https://doi.org/TBD

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
The Web Conference 2024, May 13–17, 2024, Singapore
© 2024 Association for Computing Machinery.
ACM ISBN 978-1-4503-XXXX-X/18/06. . . $15.00
https://doi.org/TBD

1 TOPIC AND RELEVANCE
As an indispensable means for web users to counteract informa-
tion overload, recommender systems (RSs) that can automatically
match user interests with relevant items (e.g., products, services,
information) have seen a substantial amount of research interest
over the last decade. In the digital industry, prosperous enterprise-
level applications are projected to drive the global RS market to an
unprecedented value of USD $54 billion by 20301.

Traditional RSs are subsumed under a fully cloud-based par-
adigm, where the cloud server trains the RS model with all the
user data it hosts and pushes recommendation results to users’ per-
sonal devices upon request. Though this paradigm enjoys beneﬁts
from the “inﬁnite” computing power to support sophisticated RS
models, some increasingly harsh obstacles are arising in the mean-
time, including the high resource and energy consumption [20],
reliance on network access for timeliness [13], and threat to user
privacy [15], which challenge the sustainability and trustworthi-
ness of cloud-based RSs.

To this end, recent years have witnessed the development of
a new yet fast-evolving recommendation paradigm – on-device
recommender systems (ODRSs). Compared with cloud-based RSs,
the most signiﬁcant diﬀerence of ODRSs is that users’ devices be-
come a key part of the computation on top of their original role
of displaying generated recommendations. Typical ODRSs are op-
timized towards three objectives: (1) on-device deployment and in-
ference that aims to derive a resource-eﬃcient model with min-
imum accuracy degradation; (2) on-device training and updating
that enables the lightweight model to stay up-to-date; and (3) pri-
vacy and security mechanisms that respectively keep users and
on-device models from malicious attacks. As a result, the heavy
cloud-based RS models could be replaced by their lightweight on-
device counterparts, such that the inference can be eﬃciently per-
formed on resource-constrained user devices with locally stored
user data [2]. In the industry, ODRSs have seen an emerging list of
applications, including Taobao’s mobile service [4], Google’s Ten-
sorFlow Lite Recommendation API2, real-time short video recom-
mendation on Kuaishou [3], and the built-in recommendation en-
gine in the Brave Web Browser3.

1https://straitsresearch.com/report/recommendation/
2https://www.tensorﬂow.org/lite/examples/recommendation/overview
3https://brave.com/federated-learning/

 
 
 
 
 
 
The Web Conference 2024, May 13–17, 2024, Singapore

Hongzhi Yin, et al.

Rationale of The Tutorial. Given the rapidly growing research
community and widening market for ODRSs, as well as the surging
wave of edge intelligence, we ﬁnd our proposed tutorial a timely
opportunity to provide an overview of existing research on this
new-generation lightweight recommendation paradigm and an out-
look on the future development of ODRSs. This tutorial, or any
form of its variation, has not been previously presented in a dif-
ferent venue by any member of the tutorial team. Furthermore,
we have conducted a thorough search for relevant ODRSs tutori-
als with the keyword recommendation or recommender systems at
all the top computer science conferences in the recent ﬁve years
and only identiﬁed one relevant tutorial presented at the IJCAI’20,
called Federated Recommender Systems4. This tutorial introduced
the concepts of vertical and horizontal federated RSs, where two
case studies on news recommendation and online advertising were
presented. However, federated recommendation is only one of the
possible technical pathways with on-device training, which in turn
is a subset of ODRSs. Our tutorial will not only introduce addi-
tional on-device training methods, such as semi-decentralized on-
device recommendation and on-device recommender ﬁnetuning
but will also cover on-device deployment and inference as well as
privacy and security mechanisms in ODRSs. To our knowledge,
the proposed tutorial will debut the very ﬁrst comprehensive sum-
mary of the fundamentals and recent advances of on-device rec-
ommender systems in the research community.

Relevance to the Web Conference (WWW). Every year, WWW

attracts a considerable proportion of high-quality papers and con-
ference attendees working on RSs. The growing signiﬁcance of RSs
is evident, as demonstrated by the dedicated recommendation re-
search track at WWW, as well as the increasing number of research
papers and industry participation. For instance, in WWW’23, 19.3%
accepted regular papers (79/409) contained the keyword recom-
mendation or recommender systems, highlighting the substantial
interest in this ﬁeld. The dense population of experts in relevant
areas ensures a vibrant environment for knowledge exchange, con-
structive discussions, and the exploration of innovative ideas that
can shape the future of RSs.

Furthermore, the regular industry sponsors of WWW, includ-
ing renowned companies like Google, Amazon, Baidu, Ebay, Net-
ﬂix, and Booking, have dedicated commercial branches focused on
recommendation services. Their involvement signiﬁes the practi-
cal implications and economic potential of RSs, further solidify-
ing WWW’s status as a prominent conference for promoting next-
generation ODRSs.

Given the conference’s widespread presence of research and in-
dustry leaders in the recommendation domain, WWW’24 holds
great promise as an ideal platform to disseminate fundamental knowl-
edge, promote recent research outcomes, and foster collaborative
eﬀorts to enhance ODRSs. By embracing the wisdom and collec-
tive expertise of the conference participants, this tutorial expects
to advance the ﬁeld and address the open challenges associated
with on-device recommendation technologies.

4https://www.fedai.org/research/conferences/ijcai-2020-tutorial/

1.1 THE TUTORIAL TEAM
Prof. Hongzhi Yin and his research group are the pioneers of this
emerging research ﬁeld and have consistently worked on recom-
mender systems for years. Together with co-authors, their work
on on-device recommender systems has been published in top-tier
venues such as KDD, WWW, SIGIR, AAAI, TKDE, WSDM, TOIS
and etc.

1.1.1 Brief Bio of Organizers.

• Prof. Hongzhi Yin works as an ARC Future Fellow, Full
Professor, and Director of the Responsible Big Data Intel-
ligence Lab (RBDI) at The University of Queensland, Aus-
tralia. He has published 260+ papers with an H-index of
66, making notable contributions to recommendation sys-
tems, graph learning, decentralized learning, and edge intel-
ligence. His research has won 8 international and national
Best Paper Awards, including Best Paper Award (Honorable
Mention) at WSDM 2023, Best Paper Award at ICDE 2019,
and Best Student Paper Award at DASFAA 2020. He has
received the prestigious 2023 AIPS Young Tall Poppy Sci-
ence Awards, 2022 IEEE Computer Society AI’s 10 to Watch,
2021 ARC Future Fellowship, and 2016 ARC DECRA Fellow-
ship. He has been an SPC or area chair for many top confer-
ences, such as WWW, IJCAI, AAAI, KDD, SIGIR, WSDM,
ICDE, CIKM, and DASFAA. Prof. Yin has rich lecture expe-
rience and taught ﬁve relevant courses, such as information
retrieval and web search, data mining, social media analyt-
ics, and responsible data science. He won the Faculty Teach-
ing and Learning Excellence Award 2022 and the University
Teaching and Learning Excellence Award 2022 (ﬁnalist). In
addition, he has delivered 20+ keynotes and tutorials at the
top international conferences like DASFAA’23, WWW’22,
BESC’22, ADMA’19, WWW’17, and KDD’17.

• Dr. Tong Chen is a senior lecturer at The University of
Queensland, and an awardee of the 2023 Discovery Early Ca-
reer Researcher Award from the Australian Research Coun-
cil (ARC). Dr. Chen’s research on lightweight and on-device
recommender systems has been published on top-tier inter-
national venues such as KDD, SIGIR, WWW, TKDE, WSDM,
TNNLS, TOIS, and CIKM. Dr. Chen has ample track records
in lecturing, witnessed by his course design and delivery ex-
perience in business analytics, teaching experience in social
media analytics, as well as invited talks on cutting-edge rec-
ommender systems at the DASFAA’23 Tutorial, WWW’22
Tutorial, and ICDM’20 NeuRec Workshop.

• Mr. Liang Qu is currently pursuing his Ph.D. under a joint
program between The University of Queensland and South-
ern University of Science and Technology. In 2017, he earned
his B.E. in Applied Physics from the South China University
of Technology, followed by an M.S. in Computer Science in
2019 from the Harbin Institute of Technology. His research
work has been published on top data mining venues such
as KDD, SIGIR, WWW, and TOIS. In addition, he has been
an PC and/or reviewer for many top venues, such as KDD,
WWW, CIKM, and VLDB. His research interest primarily
lies in the development of lightweight, privacy-preserving,

On-Device Recommender Systems: A Tutorial on
The New-Generation Recommendation Paradigm

and trustworthy recommender systems, such as federated
recommendation and on-device recommendation.

• Prof. Bin Cui is a Cheung Kong Distinguished Professor,
Vice Dean of the School of Computer Science at Peking Uni-
versity, and Director of Peking University-Tencent Joint In-
novation Laboratory. His research interests include recom-
mendation and search system architectures, query and in-
dex techniques, big data management and mining, and dis-
tributed machine learning systems. He has served on the
Technical Program Committee of various international con-
ferences, including SIGMOD, VLDB, ICDE, WWW, KDD, and
as Area Chair of ICDE 2011&2018, Demo Co-Chair of ICDE
2014, Area Chair of VLDB 2014, PC Co-Chair of APWeb
2015, WAIM 2016 and DASFAA 2020. He serves as Vice Chair
of Technical Committee on Database China Computer Fed-
eration (CCF) and Trustee Board Member of VLDB Endow-
ment. He is also on the Editorial Board of Distributed and
Parallel Databases, Journal of Computer Science and Tech-
nology, and SCIENCE CHINA Information Sciences, and was
an associate editor of IEEE Transactions on Knowledge and
Data Engineering (TKDE) and VLDB Journal. He was awarded
Microsoft Young Professorship Award (MSRA 2008), CCF
Young Scientist Award (2009), Second Prize of Natural Sci-
ence Award of MOE China (2014), and appointed as Cheung
Kong Distinguished Professor by MOE in 2016.

1.1.2 Relevant Publications by Organizers. In order to further demon-
strate that the presenters are qualiﬁed for a high-quality introduc-
tion of the ODRSs, below we list the relevant papers on ODRSs
published by the presenters.

• Deployment and inference for ODRSs [2, 9, 17, 18, 23–25, 27]
• Training for ODRSs [5, 12, 13, 16, 21]
• Privacy and security for ODRSs [29–31, 34, 35]

Overall, this tutorial aims to beneﬁt the participating audience

from the following three aspects:

• We aim to furnish participants with a comprehensive and
current picture of ODRSs, enabling them to grasp the cur-
rent state-of-the-art technologies and methodologies employed
in ODRSs.

• We will lay out a systematic categorization of ODRSs for
participants, facilitating a structured understanding of the
various methods involved. Each category will be explored
in detail, discussing the technical aspects that diﬀerentiate
them.

• We will outline potential future research directions in the
ODRS, aiding participants in identifying areas where they
can contribute and further the body of knowledge in this
ﬁeld.

2 STYLE
This tutorial is delivered as a lecture-style tutorial, which aims to
provide a comprehensive introduction to research on ODRSs, from
pioneering work to state-of-the-art research, and also discuss fu-
ture research directions and challenges.

The Web Conference 2024, May 13–17, 2024, Singapore

3 SCHEDULE
The content is planned for 3 hours and consists of ﬁve sections. In
what follows, we provide an outline of our tutorial.
Section 1. Welcome and Introduction (10 mins)
Presenter: Prof. Hongzhi Yin
1.1 Overview of Recommender Systems (RSs) [7]
1.2 On-Device Recommender Systems (ODRSs): Background and
Applications [3, 4, 14, 20]

Section 2. Deﬁnition and Taxonomy of ODRSs (20 mins)
Presenter: Prof. Hongzhi Yin
2.1 Deﬁnition of On-Device Recommendation Tasks
2.2 Categorization of Existing ODRSs

Section 3. A Review of ODRSs (110 mins)
Presenters: Dr. Tong Chen and Mr. Liang Qu
3.1 On-Device Deployment and Inference:
• Binary Code-based Methods [33, 36]
• Embedding Sparsiﬁcation Methods [11, 18]
• Compositional Embedding Methods [8, 19, 20, 23, 24]
• Variable Size Embedding Methods [2, 6, 10]
• Sustainable Deployment [25]

3.2 On-Device Training:

• Server-coordinated/Federated Learning for On-device Rec-

ommendation [5, 15, 32]

• Semi-decentralized ODRSs [12, 13, 16]
• On-device Recommender Finetuning [21, 26, 28]

3.3 Privacy and Security:

• Privacy Risks and Countermeasures [1, 30, 31, 35]
• Poisoning Attacks and Defense Methods [22, 29, 34]

Section 4. Limitations and New Trends (20 mins)
Presenter: Prof. Bin Cui
4.1 Open Challenges for Existing ODRSs
4.2 Emerging Research Directions

Section 5. Open Discussions (20 mins)
Presenters: Prof. Hongzhi Yin, Dr. Tong Chen, Mr. Liang Qu
and Prof. Bin Cui
5.1 Questions and Answers
5.2 Reﬂections, Suggestions, and Link to Our Resources

4 AUDIENCE
This tutorial targets a diverse audience cohort from both academia
and industry, with a background of recommendation or any rele-
vant areas, including but not limited to information retrieval, web
mining, and internet-of-things (IoT). For prerequisites, basic knowl-
edge of recommender systems is preferred, while the tutorial will
also cover all necessary foundations for better audience engage-
ment. After the tutorial, we expect the audience to form an up-to-
date picture of diﬀerent application scenarios of ODRSs, as well as
their core technical building blocks. Considering the high accessi-
bility of the conference, we expect around a hundred participants
for the tutorial.

The Web Conference 2024, May 13–17, 2024, Singapore

Hongzhi Yin, et al.

5 TUTORIAL MATERIALS
Upon acceptance of the tutorial, the slides and video recordings
will be made available to all attendees on our tutorial website two
weeks before the scheduled conference date.

6 VIDEO TEASER
The video teaser is available at https://bit.ly/odrs.

ACKNOWLEDGMENT
This work is supported by the Australian Research Council un-
der the streams of Future Fellowship (No. FT210100624), Discov-
ery Project (No. DP190101985, DP240101108, DP240101814), and
Discovery Early Career Researcher Award (No. DE230101033).

REFERENCES
[1] Di Chai, Leye Wang, Kai Chen, and Qiang Yang. 2022. Eﬃcient Federated Matrix

Factorization Against Inference Attacks. TIST 13, 4 (2022), 1–20.

[2] Tong Chen, Hongzhi Yin, Yujia Zheng, Zi Huang, Yang Wang, and Meng Wang.
2021. Learning elastic embeddings for customizing on-device recommenders. In
SIGKDD. 138–147.

[3] Xudong Gong, Qinlin Feng, Yuan Zhang, Jiangling Qin, Weijie Ding, Biao Li,
Peng Jiang, and Kun Gai. 2022. Real-time Short Video Recommendation on Mo-
bile Devices. In CIKM. 3103–3112.

[4] Yu Gong, Ziwen Jiang, Yufei Feng, Binbin Hu, Kaiqi Zhao, Qingwen Liu, and
Wenwu Ou. 2020. EdgeRec: recommender system on edge in Mobile Taobao. In
CIKM. 2477–2484.

[5] Mubashir Imran, Hongzhi Yin, Tong Chen, Quoc Viet Hung Nguyen, Alexander
Zhou, and Kai Zheng. 2023. ReFRS: Resource-eﬃcient federated recommender
system for dynamic and diversiﬁed user preferences. TOIS 41, 3 (2023), 1–30.
[6] Wang-Cheng Kang, Derek Zhiyuan Cheng, Tiansheng Yao, Xinyang Yi, Ting
Chen, Lichan Hong, and Ed H Chi. 2021. Learning to embed categorical features
without embedding tables for recommendation. In SIGKDD. 840–850.

[20] Qinyong Wang, Hongzhi Yin, Tong Chen, Zi Huang, Hao Wang, Yanchang Zhao,
and Nguyen Quoc Viet Hung. 2020. Next Point-of-Interest Recommendation on
Resource-Constrained Mobile Devices. In The Web Conference. 906–916.
[21] Qinyong Wang, Hongzhi Yin, Tong Chen, Junliang Yu, Alexander Zhou, and
Xiangliang Zhang. 2021. Fast-adapting and privacy-preserving federated rec-
ommender system. VLDBJ (2021), 1–20.

[22] Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang, and Xing Xie. 2022. Fe-
dAttack: Eﬀective and covert poisoning attack on federated recommendation via
hard sampling. In SIGKDD. 4164–4172.

[23] Xin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Guandong Xu, and Quoc
Viet Hung Nguyen. 2022. On-Device Next-Item Recommendation with Self-
Supervised Knowledge Distillation. In SIGIR. 546–555.

[24] Xin Xia, Junliang Yu, Qinyong Wang, Chaoqun Yang, Nguyen Quoc Viet Hung,
and Hongzhi Yin. 2023. Eﬃcient on-device session-based recommendation.
ACM Transactions on Information Systems 41, 4 (2023), 1–24.
[25] Xin Xia, Junliang Yu, Guandong Xu, and Hongzhi Yin. 2023.

Towards
Communication-Eﬃcient Model Updating for On-Device Session-Based Recom-
mendation. In Proceedings of the 32nd ACM International Conference on Informa-
tion and Knowledge Management. 2795–2804.

[26] Yikai Yan, Chaoyue Niu, Renjie Gu, Fan Wu, Shaojie Tang, Lifeng Hua, Chengfei
Lyu, and Guihai Chen. 2022. On-Device Learning for Model Personalization with
Large-Scale Cloud-Coordinated Domain Adaption. In SIGKDD. 2180–2190.
[27] Ling Yang, Ye Tian, Minkai Xu, Zhongyi Liu, Shenda Hong, Wei Qu, Wen-
VQGraph:
arXiv preprint

tao Zhang, Bin Cui, Muhan Zhang, and Jure Leskovec. 2023.
Graph Vector-Quantization for Bridging GNNs and MLPs.
arXiv:2308.02117 (2023).

[28] Jiangchao Yao, Feng Wang, Kunyang Jia, Bo Han, Jingren Zhou, and Hongxia
Device-cloud collaborative learning for recommendation. In

Yang. 2021.
SIGKDD. 3865–3874.

[29] Wei Yuan, Quoc Viet Hung Nguyen, Tieke He, Liang Chen, and Hongzhi Yin.
2023. Manipulating Federated Recommender Systems: Poisoning with Synthetic
Users and Its Countermeasures. SIGIR (2023).

[30] Wei Yuan, Chaoqun Yang, Quoc Viet Hung Nguyen, Lizhen Cui, Tieke He, and
Hongzhi Yin. 2023. Interaction-level Membership Inference Attack Against Fed-
erated Recommender Systems. In WWW. 1053–1062.

[31] Wei Yuan, Hongzhi Yin, Fangzhao Wu, Shijie Zhang, Tieke He, and Hao Wang.
2023. Federated unlearning for on-device recommendation. In WSDM. 393–401.
[32] Honglei Zhang, Fangyuan Luo, Jun Wu, Xiangnan He, and Yidong Li. 2023.
LightFR: Lightweight federated recommendation with privacy-preserving ma-
trix factorization. TOIS 41, 4 (2023), 1–28.

[7] Yehuda Koren, Steﬀen Rendle, and Robert Bell. 2021. Advances in collaborative

[33] Hanwang Zhang, Fumin Shen, Wei Liu, Xiangnan He, Huanbo Luan, and Tat-

Seng Chua. 2016. Discrete collaborative ﬁltering. In SIGIR. 325–334.

[34] Shijie Zhang, Hongzhi Yin, Tong Chen, Zi Huang, Quoc Viet Hung Nguyen, and
Lizhen Cui. 2022. Pipattack: Poisoning federated recommender systems for ma-
nipulating item promotion. In WSDM. 1415–1423.

[35] Shijie Zhang, Wei Yuan, and Hongzhi Yin. 2023. Comprehensive privacy analy-
sis on federated recommender system against attribute inference attacks. IEEE
Transactions on Knowledge and Data Engineering (2023).

[36] Yan Zhang, Defu Lian, and Guowu Yang. 2017. Discrete personalized ranking

for fast collaborative ﬁltering from implicit feedback. In AAAI, Vol. 31.

ﬁltering. Recommender systems handbook (2021), 91–142.

[8] Defu Lian, Haoyu Wang, Zheng Liu, Jianxun Lian, Enhong Chen, and Xing Xie.
2020. LightRec: A Memory and Search-Eﬃcient Recommender System. In The
Web Conference. 695–705.

[9] Xurong Liang, Tong Chen, Quoc Viet Hung Nguyen, Jianxin Li, and Hongzhi Yin.
2023. Learning Compact Compositional Embeddings via Regularized Pruning
for Recommendation. arXiv preprint arXiv:2309.03518 (2023).

[10] Haochen Liu, Xiangyu Zhao, Chong Wang, Xiaobing Liu, and Jiliang Tang. 2020.
Automated Embedding Size Search in Deep Recommender Systems. In SIGIR.
2307–2316.

[11] Siyi Liu, Chen Gao, Yihong Chen, Depeng Jin, and Yong Li. 2021. Learnable

Embedding sizes for Recommender Systems. In ICLR.

[12] Jing Long, Tong Chen, Nguyen Quoc Viet Hung, Guandong Xu, Kai Zheng, and
Hongzhi Yin. 2023. Model-Agnostic Decentralized Collaborative Learning for
On-Device POI Recommendation. SIGIR (2023).

[13] Jing Long, Tong Chen, Quoc Viet Hung Nguyen, and Hongzhi Yin. 2023. Decen-
tralized collaborative learning framework for next POI recommendation. TOIS
41, 3 (2023), 1–25.

[14] Zheqi Lv et al. 2023. DUET: A Tuning-Free Device-Cloud Collaborative Param-
eters Generation Framework for Eﬃcient Device Model Generalization. In Pro-
ceedings of the ACM Web Conference 2023. 3077–3085.

[15] Khalil Muhammad, Qinqin Wang, Diarmuid O’Reilly-Morgan, Elias Tragos,
Barry Smyth, Neil Hurley, James Geraci, and Aonghus Lawlor. 2020. Fedfast:
Going beyond average for faster training of federated recommender systems. In
SIGKDD. 1234–1242.

[16] Liang Qu, Ningzhi Tang, Ruiqi Zheng, Quoc Viet Hung Nguyen, Zi Huang, Yuhui
Shi, and Hongzhi Yin. 2023. Semi-decentralized Federated Ego Graph Learning
for Recommendation. In WWW. 339–348.

[17] Yunke Qu, Tong Chen, Quoc Viet Hung Nguyen, and Hongzhi Yin. 2023.
arXiv preprint

Budgeted Embedding Table For Recommender Systems.
arXiv:2310.14884 (2023).

[18] Yunke Qu, Tong Chen, Xiangyu Zhao, Lizhen Cui, Kai Zheng, and Hongzhi Yin.
2023. Continuous Input Embedding Size Search For Recommender Systems. SI-
GIR (2023).

[19] Hao-Jun Michael Shi, Dheevatsa Mudigere, Maxim Naumov, and Jiyan Yang.
2020. Compositional embeddings using complementary partitions for memory-
eﬃcient recommendation systems. In SIGKDD. 165–175.

","3 2 0 2 c e D 8 1 ] R I . s c [ 1 v 4 6 8 0 1 . 2 1 3 2 : v i X r a On-Device Recommender Systems : A Tutorial on The New-Generation Recommendation Paradigm Hongzhi Yin The University of Queensland Brisbane , QLD , Australia h.yin1 @ uq.edu.au Liang Qu The University of Queensland Brisbane , QLD , Australia liang.qu @ uq.edu.au Tong Chen The University of Queensland Brisbane , QLD , Australia tong.chen @ uq.edu.au Bin Cui Peking University Beijing , China bin.cui @ pku.edu.cn ABSTRACT Given the sheer volume of contemporary e-commerce applications , recommender systems ( RSs ) have gained signiﬁcant attention in both academia and industry . However , traditional cloud-based RSs face inevitable challenges , such as resource-intensive computation , reliance on network access , and privacy breaches . In response , a new paradigm called on-device recommender systems ( ODRSs ) has emerged recently in various industries like Taobao , Google , and Kuaishou . ODRSs unleash the computational capacity of user de- vices with lightweight recommendation models tailored for resource- constrained environments , enabling real-time inference with users ’ local data . This tutorial aims to systematically introduce method- ologies of ODRSs , including ( 1 ) an overview of existing research on ODRSs ; ( 2 ) a comprehensive taxonomy of ODRSs , where the core technical content to be covered span across three major ODRS re- search directions , including on-device deployment and inference , on-device training , and privacy/security of ODRSs ; ( 3 ) limitations and future directions of ODRSs . This tutorial expects to lay the foundation and spark new insights for follow-up research and ap- plications concerning this new recommendation paradigm . CCS CONCEPTS • Information systems → Recommender systems . KEYWORDS On-device Learning , Recommender Systems , Federated Learning , Privacy and Security ACM Reference Format : Hongzhi Yin , Tong Chen , Liang Qu , and Bin Cui . 2024 . On-Device Rec- ommender Systems : A Tutorial on The New-Generation Recommendation Paradigm . In Proceedings of The Web Conference 2024 . ACM , New York , NY , USA , 4 pages . https : //doi.org/TBD Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that copies bear this notice and the full cita- tion on the ﬁrst page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or re- publish , to post on servers or to redistribute to lists , requires prior speciﬁc permission and/or a fee . Request permissions from permissions @ acm.org . The Web Conference 2024 , May 13–17 , 2024 , Singapore © 2024 Association for Computing Machinery . ACM ISBN 978-1-4503-XXXX-X/18/06 . . . $ 15.00 https : //doi.org/TBD 1 TOPIC AND RELEVANCE As an indispensable means for web users to counteract informa- tion overload , recommender systems ( RSs ) that can automatically match user interests with relevant items ( e.g. , products , services , information ) have seen a substantial amount of research interest over the last decade . In the digital industry , prosperous enterprise- level applications are projected to drive the global RS market to an unprecedented value of USD $ 54 billion by 20301 . Traditional RSs are subsumed under a fully cloud-based par- adigm , where the cloud server trains the RS model with all the user data it hosts and pushes recommendation results to users ’ per- sonal devices upon request . Though this paradigm enjoys beneﬁts from the “ inﬁnite ” computing power to support sophisticated RS models , some increasingly harsh obstacles are arising in the mean- time , including the high resource and energy consumption [ 20 ] , reliance on network access for timeliness [ 13 ] , and threat to user privacy [ 15 ] , which challenge the sustainability and trustworthi- ness of cloud-based RSs . To this end , recent years have witnessed the development of a new yet fast-evolving recommendation paradigm – on-device recommender systems ( ODRSs ) . Compared with cloud-based RSs , the most signiﬁcant diﬀerence of ODRSs is that users ’ devices be- come a key part of the computation on top of their original role of displaying generated recommendations . Typical ODRSs are op- timized towards three objectives : ( 1 ) on-device deployment and in- ference that aims to derive a resource-eﬃcient model with min- imum accuracy degradation ; ( 2 ) on-device training and updating that enables the lightweight model to stay up-to-date ; and ( 3 ) pri- vacy and security mechanisms that respectively keep users and on-device models from malicious attacks . As a result , the heavy cloud-based RS models could be replaced by their lightweight on- device counterparts , such that the inference can be eﬃciently per- formed on resource-constrained user devices with locally stored user data [ 2 ] . In the industry , ODRSs have seen an emerging list of applications , including Taobao ’ s mobile service [ 4 ] , Google ’ s Ten- sorFlow Lite Recommendation API2 , real-time short video recom- mendation on Kuaishou [ 3 ] , and the built-in recommendation en- gine in the Brave Web Browser3 . 1https : 2https : 3https : //brave.com/federated-learning/ The Web Conference 2024 , May 13–17 , 2024 , Singapore Hongzhi Yin , et al . Rationale of The Tutorial . Given the rapidly growing research community and widening market for ODRSs , as well as the surging wave of edge intelligence , we ﬁnd our proposed tutorial a timely opportunity to provide an overview of existing research on this new-generation lightweight recommendation paradigm and an out- look on the future development of ODRSs . This tutorial , or any form of its variation , has not been previously presented in a dif- ferent venue by any member of the tutorial team . Furthermore , we have conducted a thorough search for relevant ODRSs tutori- als with the keyword recommendation or recommender systems at all the top computer science conferences in the recent ﬁve years and only identiﬁed one relevant tutorial presented at the IJCAI ’ 20 , called Federated Recommender Systems4 . This tutorial introduced the concepts of vertical and horizontal federated RSs , where two case studies on news recommendation and online advertising were presented . However , federated recommendation is only one of the possible technical pathways with on-device training , which in turn is a subset of ODRSs . Our tutorial will not only introduce addi- tional on-device training methods , such as semi-decentralized on- device recommendation and on-device recommender ﬁnetuning but will also cover on-device deployment and inference as well as privacy and security mechanisms in ODRSs . To our knowledge , the proposed tutorial will debut the very ﬁrst comprehensive sum- mary of the fundamentals and recent advances of on-device rec- ommender systems in the research community . Relevance to the Web Conference ( WWW ) . Every year , WWW attracts a considerable proportion of high-quality papers and con- ference attendees working on RSs . The growing signiﬁcance of RSs is evident , as demonstrated by the dedicated recommendation re- search track at WWW , as well as the increasing number of research papers and industry participation . For instance , in WWW ’ 23 , 19.3 % accepted regular papers ( 79/409 ) contained the keyword recom- mendation or recommender systems , highlighting the substantial interest in this ﬁeld . The dense population of experts in relevant areas ensures a vibrant environment for knowledge exchange , con- structive discussions , and the exploration of innovative ideas that can shape the future of RSs . Furthermore , the regular industry sponsors of WWW , includ- ing renowned companies like Google , Amazon , Baidu , Ebay , Net- ﬂix , and Booking , have dedicated commercial branches focused on recommendation services . Their involvement signiﬁes the practi- cal implications and economic potential of RSs , further solidify- ing WWW ’ s status as a prominent conference for promoting next- generation ODRSs . Given the conference ’ s widespread presence of research and in- dustry leaders in the recommendation domain , WWW ’ 24 holds great promise as an ideal platform to disseminate fundamental knowl- edge , promote recent research outcomes , and foster collaborative eﬀorts to enhance ODRSs . By embracing the wisdom and collec- tive expertise of the conference participants , this tutorial expects to advance the ﬁeld and address the open challenges associated with on-device recommendation technologies . 4https : 1.1 THE TUTORIAL TEAM Prof. Hongzhi Yin and his research group are the pioneers of this emerging research ﬁeld and have consistently worked on recom- mender systems for years . Together with co-authors , their work on on-device recommender systems has been published in top-tier venues such as KDD , WWW , SIGIR , AAAI , TKDE , WSDM , TOIS and etc . 1.1.1 Brief Bio of Organizers . • Prof. Hongzhi Yin works as an ARC Future Fellow , Full Professor , and Director of the Responsible Big Data Intel- ligence Lab ( RBDI ) at The University of Queensland , Aus- tralia . He has published 260+ papers with an H-index of 66 , making notable contributions to recommendation sys- tems , graph learning , decentralized learning , and edge intel- ligence . His research has won 8 international and national Best Paper Awards , including Best Paper Award ( Honorable Mention ) at WSDM 2023 , Best Paper Award at ICDE 2019 , and Best Student Paper Award at DASFAA 2020 . He has received the prestigious 2023 AIPS Young Tall Poppy Sci- ence Awards , 2022 IEEE Computer Society AI ’ s 10 to Watch , 2021 ARC Future Fellowship , and 2016 ARC DECRA Fellow- ship . He has been an SPC or area chair for many top confer- ences , such as WWW , IJCAI , AAAI , KDD , SIGIR , WSDM , ICDE , CIKM , and DASFAA . Prof. Yin has rich lecture expe- rience and taught ﬁve relevant courses , such as information retrieval and web search , data mining , social media analyt- ics , and responsible data science . He won the Faculty Teach- ing and Learning Excellence Award 2022 and the University Teaching and Learning Excellence Award 2022 ( ﬁnalist ) . In addition , he has delivered 20+ keynotes and tutorials at the top international conferences like DASFAA ’ 23 , WWW ’ 22 , BESC ’ 22 , ADMA ’ 19 , WWW ’ 17 , and KDD ’ 17 . • Dr. Tong Chen is a senior lecturer at The University of Queensland , and an awardee of the 2023 Discovery Early Ca- reer Researcher Award from the Australian Research Coun- cil ( ARC ) . Dr. Chen ’ s research on lightweight and on-device recommender systems has been published on top-tier inter- national venues such as KDD , SIGIR , WWW , TKDE , WSDM , TNNLS , TOIS , and CIKM . Dr. Chen has ample track records in lecturing , witnessed by his course design and delivery ex- perience in business analytics , teaching experience in social media analytics , as well as invited talks on cutting-edge rec- ommender systems at the DASFAA ’ 23 Tutorial , WWW ’ 22 Tutorial , and ICDM ’ 20 NeuRec Workshop . • Mr. Liang Qu is currently pursuing his Ph.D. under a joint program between The University of Queensland and South- ern University of Science and Technology . In 2017 , he earned his B.E . in Applied Physics from the South China University of Technology , followed by an M.S . in Computer Science in 2019 from the Harbin Institute of Technology . His research work has been published on top data mining venues such as KDD , SIGIR , WWW , and TOIS . In addition , he has been an PC and/or reviewer for many top venues , such as KDD , WWW , CIKM , and VLDB . His research interest primarily lies in the development of lightweight , privacy-preserving , On-Device Recommender Systems : A Tutorial on The New-Generation Recommendation Paradigm and trustworthy recommender systems , such as federated recommendation and on-device recommendation . • Prof. Bin Cui is a Cheung Kong Distinguished Professor , Vice Dean of the School of Computer Science at Peking Uni- versity , and Director of Peking University-Tencent Joint In- novation Laboratory . His research interests include recom- mendation and search system architectures , query and in- dex techniques , big data management and mining , and dis- tributed machine learning systems . He has served on the Technical Program Committee of various international con- ferences , including SIGMOD , VLDB , ICDE , WWW , KDD , and as Area Chair of ICDE 2011 & 2018 , Demo Co-Chair of ICDE 2014 , Area Chair of VLDB 2014 , PC Co-Chair of APWeb 2015 , WAIM 2016 and DASFAA 2020 . He serves as Vice Chair of Technical Committee on Database China Computer Fed- eration ( CCF ) and Trustee Board Member of VLDB Endow- ment . He is also on the Editorial Board of Distributed and Parallel Databases , Journal of Computer Science and Tech- nology , and SCIENCE CHINA Information Sciences , and was an associate editor of IEEE Transactions on Knowledge and Data Engineering ( TKDE ) and VLDB Journal . He was awarded Microsoft Young Professorship Award ( MSRA 2008 ) , CCF Young Scientist Award ( 2009 ) , Second Prize of Natural Sci- ence Award of MOE China ( 2014 ) , and appointed as Cheung Kong Distinguished Professor by MOE in 2016 . 1.1.2 Relevant Publications by Organizers . In order to further demon- strate that the presenters are qualiﬁed for a high-quality introduc- tion of the ODRSs , below we list the relevant papers on ODRSs published by the presenters . • Deployment and inference for ODRSs [ 2 , 9 , 17 , 18 , 23–25 , 27 ] • Training for ODRSs [ 5 , 12 , 13 , 16 , 21 ] • Privacy and security for ODRSs [ 29–31 , 34 , 35 ] Overall , this tutorial aims to beneﬁt the participating audience from the following three aspects : • We aim to furnish participants with a comprehensive and current picture of ODRSs , enabling them to grasp the cur- rent state-of-the-art technologies and methodologies employed in ODRSs . • We will lay out a systematic categorization of ODRSs for participants , facilitating a structured understanding of the various methods involved . Each category will be explored in detail , discussing the technical aspects that diﬀerentiate them . • We will outline potential future research directions in the ODRS , aiding participants in identifying areas where they can contribute and further the body of knowledge in this ﬁeld . 2 STYLE This tutorial is delivered as a lecture-style tutorial , which aims to provide a comprehensive introduction to research on ODRSs , from pioneering work to state-of-the-art research , and also discuss fu- ture research directions and challenges . The Web Conference 2024 , May 13–17 , 2024 , Singapore 3 SCHEDULE The content is planned for 3 hours and consists of ﬁve sections . In what follows , we provide an outline of our tutorial . Section 1 . Welcome and Introduction ( 10 mins ) Presenter : Prof. Hongzhi Yin 1.1 Overview of Recommender Systems ( RSs ) [ 7 ] 1.2 On-Device Recommender Systems ( ODRSs ) : Background and Applications [ 3 , 4 , 14 , 20 ] Section 2 . Deﬁnition and Taxonomy of ODRSs ( 20 mins ) Presenter : Prof. Hongzhi Yin 2.1 Deﬁnition of On-Device Recommendation Tasks 2.2 Categorization of Existing ODRSs Section 3 . A Review of ODRSs ( 110 mins ) Presenters : Dr. Tong Chen and Mr. Liang Qu 3.1 On-Device Deployment and Inference : • Binary Code-based Methods [ 33 , 36 ] • Embedding Sparsiﬁcation Methods [ 11 , 18 ] • Compositional Embedding Methods [ 8 , 19 , 20 , 23 , 24 ] • Variable Size Embedding Methods [ 2 , 6 , 10 ] • Sustainable Deployment [ 25 ] 3.2 On-Device Training : • Server-coordinated/Federated Learning for On-device Rec- ommendation [ 5 , 15 , 32 ] • Semi-decentralized ODRSs [ 12 , 13 , 16 ] • On-device Recommender Finetuning [ 21 , 26 , 28 ] 3.3 Privacy and Security : • Privacy Risks and Countermeasures [ 1 , 30 , 31 , 35 ] • Poisoning Attacks and Defense Methods [ 22 , 29 , 34 ] Section 4 . Limitations and New Trends ( 20 mins ) Presenter : Prof. Bin Cui 4.1 Open Challenges for Existing ODRSs 4.2 Emerging Research Directions Section 5 . Open Discussions ( 20 mins ) Presenters : Prof. Hongzhi Yin , Dr. Tong Chen , Mr. Liang Qu and Prof. Bin Cui 5.1 Questions and Answers 5.2 Reﬂections , Suggestions , and Link to Our Resources 4 AUDIENCE This tutorial targets a diverse audience cohort from both academia and industry , with a background of recommendation or any rele- vant areas , including but not limited to information retrieval , web mining , and internet-of-things ( IoT ) . For prerequisites , basic knowl- edge of recommender systems is preferred , while the tutorial will also cover all necessary foundations for better audience engage- ment . After the tutorial , we expect the audience to form an up-to- date picture of diﬀerent application scenarios of ODRSs , as well as their core technical building blocks . Considering the high accessi- bility of the conference , we expect around a hundred participants for the tutorial . The Web Conference 2024 , May 13–17 , 2024 , Singapore Hongzhi Yin , et al . 5 TUTORIAL MATERIALS Upon acceptance of the tutorial , the slides and video recordings will be made available to all attendees on our tutorial website two weeks before the scheduled conference date . 6 VIDEO TEASER The video teaser is available at https : //bit.ly/odrs . ACKNOWLEDGMENT This work is supported by the Australian Research Council un- der the streams of Future Fellowship ( No . FT210100624 ) , Discov- ery Project ( No . DP190101985 , DP240101108 , DP240101814 ) , and Discovery Early Career Researcher Award ( No . DE230101033 ) . REFERENCES [ 1 ] Di Chai , Leye Wang , Kai Chen , and Qiang Yang . 2022 . Eﬃcient Federated Matrix Factorization Against Inference Attacks . TIST 13 , 4 ( 2022 ) , 1–20 . [ 2 ] Tong Chen , Hongzhi Yin , Yujia Zheng , Zi Huang , Yang Wang , and Meng Wang . 2021 . Learning elastic embeddings for customizing on-device recommenders . In SIGKDD . 138–147 . [ 3 ] Xudong Gong , Qinlin Feng , Yuan Zhang , Jiangling Qin , Weijie Ding , Biao Li , Peng Jiang , and Kun Gai . 2022 . Real-time Short Video Recommendation on Mo- bile Devices . In CIKM . 3103–3112 . [ 4 ] Yu Gong , Ziwen Jiang , Yufei Feng , Binbin Hu , Kaiqi Zhao , Qingwen Liu , and Wenwu Ou . 2020 . EdgeRec : recommender system on edge in Mobile Taobao . In CIKM . 2477–2484 . [ 5 ] Mubashir Imran , Hongzhi Yin , Tong Chen , Quoc Viet Hung Nguyen , Alexander Zhou , and Kai Zheng . 2023 . ReFRS : Resource-eﬃcient federated recommender system for dynamic and diversiﬁed user preferences . TOIS 41 , 3 ( 2023 ) , 1–30 . [ 6 ] Wang-Cheng Kang , Derek Zhiyuan Cheng , Tiansheng Yao , Xinyang Yi , Ting Chen , Lichan Hong , and Ed H Chi . 2021 . Learning to embed categorical features without embedding tables for recommendation . In SIGKDD . 840–850 . [ 20 ] Qinyong Wang , Hongzhi Yin , Tong Chen , Zi Huang , Hao Wang , Yanchang Zhao , and Nguyen Quoc Viet Hung . 2020 . Next Point-of-Interest Recommendation on Resource-Constrained Mobile Devices . In The Web Conference . 906–916 . [ 21 ] Qinyong Wang , Hongzhi Yin , Tong Chen , Junliang Yu , Alexander Zhou , and Xiangliang Zhang . 2021 . Fast-adapting and privacy-preserving federated rec- ommender system . VLDBJ ( 2021 ) , 1–20 . [ 22 ] Chuhan Wu , Fangzhao Wu , Tao Qi , Yongfeng Huang , and Xing Xie . 2022 . Fe- dAttack : Eﬀective and covert poisoning attack on federated recommendation via hard sampling . In SIGKDD . 4164–4172 . [ 23 ] Xin Xia , Hongzhi Yin , Junliang Yu , Qinyong Wang , Guandong Xu , and Quoc Viet Hung Nguyen . 2022 . On-Device Next-Item Recommendation with Self- Supervised Knowledge Distillation . In SIGIR . 546–555 . [ 24 ] Xin Xia , Junliang Yu , Qinyong Wang , Chaoqun Yang , Nguyen Quoc Viet Hung , and Hongzhi Yin . 2023 . Eﬃcient on-device session-based recommendation . ACM Transactions on Information Systems 41 , 4 ( 2023 ) , 1–24 . [ 25 ] Xin Xia , Junliang Yu , Guandong Xu , and Hongzhi Yin . 2023 . Towards Communication-Eﬃcient Model Updating for On-Device Session-Based Recom- mendation . In Proceedings of the 32nd ACM International Conference on Informa- tion and Knowledge Management . 2795–2804 . [ 26 ] Yikai Yan , Chaoyue Niu , Renjie Gu , Fan Wu , Shaojie Tang , Lifeng Hua , Chengfei Lyu , and Guihai Chen . 2022 . On-Device Learning for Model Personalization with Large-Scale Cloud-Coordinated Domain Adaption . In SIGKDD . 2180–2190 . [ 27 ] Ling Yang , Ye Tian , Minkai Xu , Zhongyi Liu , Shenda Hong , Wei Qu , Wen- VQGraph : arXiv preprint tao Zhang , Bin Cui , Muhan Zhang , and Jure Leskovec . 2023 . Graph Vector-Quantization for Bridging GNNs and MLPs . arXiv:2308.02117 ( 2023 ) . [ 28 ] Jiangchao Yao , Feng Wang , Kunyang Jia , Bo Han , Jingren Zhou , and Hongxia Device-cloud collaborative learning for recommendation . In Yang . 2021 . SIGKDD . 3865–3874 . [ 29 ] Wei Yuan , Quoc Viet Hung Nguyen , Tieke He , Liang Chen , and Hongzhi Yin . 2023 . Manipulating Federated Recommender Systems : Poisoning with Synthetic Users and Its Countermeasures . SIGIR ( 2023 ) . [ 30 ] Wei Yuan , Chaoqun Yang , Quoc Viet Hung Nguyen , Lizhen Cui , Tieke He , and Hongzhi Yin . 2023 . Interaction-level Membership Inference Attack Against Fed- erated Recommender Systems . In WWW . 1053–1062 . [ 31 ] Wei Yuan , Hongzhi Yin , Fangzhao Wu , Shijie Zhang , Tieke He , and Hao Wang . 2023 . Federated unlearning for on-device recommendation . In WSDM . 393–401 . [ 32 ] Honglei Zhang , Fangyuan Luo , Jun Wu , Xiangnan He , and Yidong Li . 2023 . LightFR : Lightweight federated recommendation with privacy-preserving ma- trix factorization . TOIS 41 , 4 ( 2023 ) , 1–28 . [ 7 ] Yehuda Koren , Steﬀen Rendle , and Robert Bell . 2021 . Advances in collaborative [ 33 ] Hanwang Zhang , Fumin Shen , Wei Liu , Xiangnan He , Huanbo Luan , and Tat- Seng Chua . 2016 . Discrete collaborative ﬁltering . In SIGIR . 325–334 . [ 34 ] Shijie Zhang , Hongzhi Yin , Tong Chen , Zi Huang , Quoc Viet Hung Nguyen , and Lizhen Cui . 2022 . Pipattack : Poisoning federated recommender systems for ma- nipulating item promotion . In WSDM . 1415–1423 . [ 35 ] Shijie Zhang , Wei Yuan , and Hongzhi Yin . 2023 . Comprehensive privacy analy- sis on federated recommender system against attribute inference attacks . IEEE Transactions on Knowledge and Data Engineering ( 2023 ) . [ 36 ] Yan Zhang , Defu Lian , and Guowu Yang . 2017 . Discrete personalized ranking for fast collaborative ﬁltering from implicit feedback . In AAAI , Vol . 31. ﬁltering . Recommender systems handbook ( 2021 ) , 91–142 . [ 8 ] Defu Lian , Haoyu Wang , Zheng Liu , Jianxun Lian , Enhong Chen , and Xing Xie . 2020 . LightRec : A Memory and Search-Eﬃcient Recommender System . In The Web Conference . 695–705 . [ 9 ] Xurong Liang , Tong Chen , Quoc Viet Hung Nguyen , Jianxin Li , and Hongzhi Yin . 2023 . Learning Compact Compositional Embeddings via Regularized Pruning for Recommendation . arXiv preprint arXiv:2309.03518 ( 2023 ) . [ 10 ] Haochen Liu , Xiangyu Zhao , Chong Wang , Xiaobing Liu , and Jiliang Tang . 2020 . Automated Embedding Size Search in Deep Recommender Systems . In SIGIR . 2307–2316 . [ 11 ] Siyi Liu , Chen Gao , Yihong Chen , Depeng Jin , and Yong Li . 2021 . Learnable Embedding sizes for Recommender Systems . In ICLR . [ 12 ] Jing Long , Tong Chen , Nguyen Quoc Viet Hung , Guandong Xu , Kai Zheng , and Hongzhi Yin . 2023 . Model-Agnostic Decentralized Collaborative Learning for On-Device POI Recommendation . SIGIR ( 2023 ) . [ 13 ] Jing Long , Tong Chen , Quoc Viet Hung Nguyen , and Hongzhi Yin . 2023 . Decen- tralized collaborative learning framework for next POI recommendation . TOIS 41 , 3 ( 2023 ) , 1–25 . [ 14 ] Zheqi Lv et al . 2023 . DUET : A Tuning-Free Device-Cloud Collaborative Param- eters Generation Framework for Eﬃcient Device Model Generalization . In Pro- ceedings of the ACM Web Conference 2023 . 3077–3085 . [ 15 ] Khalil Muhammad , Qinqin Wang , Diarmuid O ’ Reilly-Morgan , Elias Tragos , Barry Smyth , Neil Hurley , James Geraci , and Aonghus Lawlor . 2020 . Fedfast : Going beyond average for faster training of federated recommender systems . In SIGKDD . 1234–1242 . [ 16 ] Liang Qu , Ningzhi Tang , Ruiqi Zheng , Quoc Viet Hung Nguyen , Zi Huang , Yuhui Shi , and Hongzhi Yin . 2023 . Semi-decentralized Federated Ego Graph Learning for Recommendation . In WWW . 339–348 . [ 17 ] Yunke Qu , Tong Chen , Quoc Viet Hung Nguyen , and Hongzhi Yin . 2023. arXiv preprint Budgeted Embedding Table For Recommender Systems . arXiv:2310.14884 ( 2023 ) . [ 18 ] Yunke Qu , Tong Chen , Xiangyu Zhao , Lizhen Cui , Kai Zheng , and Hongzhi Yin . 2023 . Continuous Input Embedding Size Search For Recommender Systems . SI- GIR ( 2023 ) . [ 19 ] Hao-Jun Michael Shi , Dheevatsa Mudigere , Maxim Naumov , and Jiyan Yang . 2020 . Compositional embeddings using complementary partitions for memory- eﬃcient recommendation systems . In SIGKDD . 165–175 .","['c', 'e', 'r', 'c', 'r', 'ondevice', 'recommender', 'system', 'tutorial', 'newgeneration', 'uqeduau', 'uqeduau', 'uqeduau', 'cui', 'peke', 'bincui', 'pkueducn', 'abstract', 'give', 'sheer', 'volume', 'contemporary', 'ecommerce', 'application', 'recommender', 'system', 'rss', 'gain', 'signiﬁcant', 'attention', 'academia', 'industry', 'however', 'traditional', 'cloudbase', 'rss', 'face', 'inevitable', 'challenge', 'resourceintensive', 'computation', 'reliance', 'network', 'access', 'privacy', 'breach', 'response', 'new', 'paradigm', 'call', 'ondevice', 'recommender', 'system', 'odrss', 'emerge', 'recently', 'various', 'industry', 'kuaishou', 'unleash', 'computational', 'capacity', 'user', 'vice', 'lightweight', 'recommendation', 'model', 'tailor', 'resource', 'constrain', 'environment', 'enable', 'realtime', 'inference', 'user', 'local', 'datum', 'tutorial', 'aim', 'systematically', 'introduce', 'method', 'ology', 'odrss', 'include', 'overview', 'exist', 'research', 'odrss', 'comprehensive', 'taxonomy', 'core', 'technical', 'content', 'cover', 'span', 'major', 'odr', 'search', 'direction', 'include', 'ondevice', 'deployment', 'inference', 'ondevice', 'training', 'privacysecurity', 'odrss', 'limitation', 'future', 'direction', 'odrss', 'tutorial', 'expect', 'lay', 'foundation', 'spark', 'new', 'insight', 'followup', 'research', 'plication', 'concern', 'new', 'recommendation', 'paradigm', 'ccs', 'concept', 'information', 'system', 'recommender', 'system', 'keyword', 'ondevice', 'learn', 'recommender', 'system', 'federate', 'learning', 'privacy', 'security', 'acm', 'reference', 'format', 'cui', 'ondevice', 'rec', 'ommender', 'system', 'tutorial', 'newgeneration', 'recommendation', 'paradigm', 'proceeding', 'web', 'conference', 'acm', 'page', 'https', 'doiorgtbd', 'permission', 'make', 'digital', 'hard', 'copy', 'part', 'work', 'personal', 'classroom', 'use', 'grant', 'fee', 'provide', 'copy', 'make', 'distribute', 'proﬁt', 'commercial', 'advantage', 'copy', 'bear', 'notice', 'full', 'cita', 'tion', 'ﬁrst', 'page', 'copyright', 'component', 'work', 'acm', 'honor', 'abstract', 'credit', 'permit', 'copy', 'otherwise', 'publish', 'post', 'server', 'redistribute', 'list', 'require', 'prior', 'speciﬁc', 'permission', 'andor', 'fee', 'request', 'permission', 'permission', 'acmorg', 'web', 'conference', 'association', 'compute', 'machinery', 'isbn', '97814503xxxxx1806', 'https', 'doiorgtbd', 'topic', 'relevance', 'indispensable', 'mean', 'web', 'user', 'counteract', 'informa', 'tion', 'overload', 'recommender', 'system', 'rss', 'automatically', 'match', 'user', 'interest', 'relevant', 'item', 'eg', 'product', 'service', 'information', 'see', 'substantial', 'amount', 'research', 'interest', 'last', 'decade', 'digital', 'industry', 'prosperous', 'enterprise', 'level', 'application', 'project', 'drive', 'global', 'rs', 'market', 'unprecedented', 'value', 'usd', 'traditional', 'rss', 'subsume', 'fully', 'cloudbase', 'cloud', 'server', 'train', 'rs', 'model', 'user', 'datum', 'host', 'push', 'recommendation', 'result', 'user', 'sonal', 'device', 'request', 'paradigm', 'enjoy', 'beneﬁts', 'inﬁnite', 'compute', 'power', 'support', 'sophisticated', 'rs', 'model', 'increasingly', 'harsh', 'obstacle', 'arise', 'mean', 'time', 'include', 'high', 'resource', 'energy', 'consumption', 'reliance', 'network', 'access', 'timeliness', 'threat', 'user', 'privacy', 'challenge', 'sustainability', 'trustworthi', 'ness', 'cloudbased', 'rss', 'end', 'recent', 'year', 'witness', 'development', 'new', 'yet', 'fastevolve', 'recommendation', 'paradigm', 'ondevice', 'recommender', 'system', 'odrss', 'compare', 'cloudbase', 'rss', 'signiﬁcant', 'diﬀerence', 'odrss', 'user', 'device', 'come', 'key', 'part', 'computation', 'top', 'original', 'role', 'display', 'generate', 'recommendation', 'typical', 'odrss', 'op', 'timize', 'objective', 'ondevice', 'deployment', 'ference', 'aim', 'derive', 'resourceeﬃcient', 'model', 'imum', 'accuracy', 'degradation', 'ondevice', 'training', 'update', 'enable', 'lightweight', 'model', 'stay', 'uptodate', 'pri', 'vacy', 'security', 'mechanism', 'respectively', 'keep', 'user', 'ondevice', 'model', 'malicious', 'attack', 'result', 'heavy', 'cloudbase', 'r', 'model', 'replace', 'lightweight', 'device', 'counterpart', 'inference', 'eﬃciently', 'form', 'resourceconstraine', 'user', 'device', 'locally', 'store', 'user', 'datum', 'industry', 'odrss', 'see', 'emerge', 'list', 'application', 'include', 'mobile', 'service', 'sorflow', 'lite', 'recommendation', 'api2', 'realtime', 'short', 'video', 'recom', 'mendation', 'kuaishou', 'builtin', 'recommendation', 'gine', 'brave', 'web', 'browser3', 'bravecomfederatedlearne', 'web', 'conference', 'rationale', 'tutorial', 'give', 'rapidly', 'grow', 'research', 'community', 'widen', 'market', 'odrss', 'well', 'surging', 'wave', 'edge', 'intelligence', 'propose', 'tutorial', 'timely', 'opportunity', 'provide', 'overview', 'exist', 'research', 'newgeneration', 'lightweight', 'recommendation', 'paradigm', 'look', 'future', 'development', 'odrss', 'tutorial', 'form', 'variation', 'previously', 'present', 'dif', 'ferent', 'venue', 'member', 'tutorial', 'team', 'furthermore', 'conduct', 'thorough', 'search', 'relevant', 'odrss', 'tutori', 'al', 'recommendation', 'recommender', 'system', 'top', 'computer', 'science', 'conference', 'recent', 'ﬁve', 'year', 'identiﬁed', 'relevant', 'tutorial', 'present', 'call', 'federate', 'recommender', 'tutorial', 'introduce', 'concept', 'vertical', 'horizontal', 'federate', 'rss', 'case', 'study', 'news', 'recommendation', 'online', 'advertising', 'present', 'however', 'federate', 'recommendation', 'possible', 'technical', 'pathway', 'ondevice', 'training', 'turn', 'subset', 'odrss', 'tutorial', 'introduce', 'addi', 'tional', 'ondevice', 'training', 'method', 'semidecentralize', 'device', 'recommendation', 'ondevice', 'recommender', 'ﬁnetuning', 'also', 'cover', 'ondevice', 'deployment', 'inference', 'well', 'privacy', 'security', 'mechanism', 'odrss', 'knowledge', 'propose', 'tutorial', 'debut', 'ﬁrst', 'comprehensive', 'sum', 'mary', 'fundamental', 'recent', 'advance', 'ondevice', 'rec', 'ommender', 'system', 'research', 'community', 'relevance', 'web', 'conference', 'www', 'year', 'www', 'attract', 'considerable', 'proportion', 'highquality', 'paper', 'con', 'ference', 'attendee', 'work', 'rss', 'grow', 'signiﬁcance', 'rss', 'evident', 'demonstrate', 'dedicated', 'recommendation', 'search', 'track', 'www', 'well', 'increase', 'number', 'research', 'paper', 'industry', 'participation', 'instance', 'www', 'accept', 'regular', 'paper', 'contain', 'recom', 'mendation', 'recommender', 'system', 'highlight', 'substantial', 'interest', 'ﬁeld', 'dense', 'population', 'expert', 'relevant', 'area', 'ensure', 'vibrant', 'environment', 'structive', 'discussion', 'exploration', 'innovative', 'idea', 'shape', 'future', 'rss', 'furthermore', 'regular', 'industry', 'sponsor', 'www', 'includ', 'ing', 'renowned', 'company', 'baidu', 'net', 'ﬂix', 'booking', 'dedicate', 'commercial', 'branch', 'focus', 'recommendation', 'service', 'involvement', 'signiﬁes', 'practi', 'cal', 'implication', 'economic', 'potential', 'rss', 'far', 'solidify', 'status', 'prominent', 'conference', 'promote', 'next', 'generation', 'odrss', 'give', 'conference', 'widespread', 'presence', 'research', 'dustry', 'leader', 'recommendation', 'domain', 'www', 'hold', 'great', 'promise', 'ideal', 'platform', 'disseminate', 'fundamental', 'knowl', 'edge', 'promote', 'recent', 'research', 'outcome', 'foster', 'collaborative', 'eﬀort', 'enhance', 'odrss', 'embrace', 'wisdom', 'collec', 'tive', 'expertise', 'conference', 'participant', 'tutorial', 'expect', 'advance', 'ﬁeld', 'address', 'open', 'challenge', 'associate', 'ondevice', 'recommendation', 'technology', 'tutorial', 'team', 'research', 'group', 'pioneer', 'emerge', 'research', 'ﬁeld', 'consistently', 'work', 'recom', 'mender', 'system', 'year', 'together', 'coauthor', 'work', 'ondevice', 'recommender', 'system', 'publish', 'toptier', 'venue', 'tkde', 'wsdm', 'tois', 'brief', 'bio', 'organizer', 'work', 'arc', 'future', 'fellow', 'full', 'professor', 'director', 'responsible', 'big', 'datum', 'ligence', 'rbdi', 'publish', 'paper', 'hindex', 'make', 'notable', 'contribution', 'recommendation', 'sys', 'tem', 'graph', 'learn', 'decentralized', 'learn', 'edge', 'ligence', 'research', 'win', 'international', 'national', 'good', 'paper', 'award', 'include', 'good', 'paper', 'award', 'honorable', 'mention', 'wsdm', 'good', 'paper', 'award', 'good', 'student', 'paper', 'award', 'dasfaa', 'receive', 'prestigious', 'aip', 'tall', 'poppy', 'ence', 'award', 'ieee', 'computer', 'society', 'ai', 'watch', 'arc', 'future', 'fellowship', 'arc', 'fellow', 'ship', 'spc', 'area', 'chair', 'many', 'top', 'confer', 'ence', 'www', 'ijcai', 'sigir', 'wsdm', 'icde', 'cikm', 'dasfaa', 'rich', 'lecture', 'expe', 'rience', 'teach', 'ﬁve', 'relevant', 'course', 'information', 'retrieval', 'web', 'search', 'datum', 'mining', 'social', 'medium', 'responsible', 'datum', 'science', 'win', 'faculty', 'teach', 'learn', 'university', 'teaching', 'learn', 'ﬁnalist', 'addition', 'deliver', 'keynote', 'tutorial', 'top', 'international', 'conference', 'dasfaa', 'www', 'www', 'senior', 'lecturer', 'awardee', 'discovery', 'early', 'reer', 'researcher', 'award', 'australian', 'research', 'research', 'lightweight', 'ondevice', 'recommender', 'system', 'publish', 'toptier', 'national', 'venue', 'www', 'tkde', 'wsdm', 'tnnls', 'tois', 'cikm', 'ample', 'track', 'record', 'lecture', 'witness', 'course', 'design', 'delivery', 'ex', 'perience', 'business', 'analytic', 'teaching', 'experience', 'social', 'medium', 'analytic', 'well', 'invite', 'talk', 'cuttingedge', 'rec', 'ommender', 'system', 'dasfaa', 'tutorial', 'www', 'tutorial', 'icdm', 'neurec', 'workshop', '•', 'currently', 'pursue', 'phd', 'joint', 'program', 'science', 'technology', 'earn', 'apply', 'physics', 'technology', 'follow', 'ms', 'computer', 'science', 'technology', 'research', 'work', 'publish', 'top', 'datum', 'mining', 'venue', 'www', 'tois', 'addition', 'pc', 'andor', 'reviewer', 'many', 'top', 'venue', 'cikm', 'vldb', 'research', 'interest', 'primarily', 'lie', 'development', 'lightweight', 'privacypreserve', 'ondevice', 'recommender', 'system', 'tutorial', 'newgeneration', 'recommendation', 'paradigm', 'trustworthy', 'recommender', 'system', 'federate', 'recommendation', 'ondevice', 'recommendation', 'prof', 'cui', 'vice', 'dean', 'school', 'computer', 'science', 'peke', 'uni', 'versity', 'director', 'peke', 'universitytencent', 'joint', 'novation', 'laboratory', 'research', 'interest', 'include', 'recom', 'mendation', 'search', 'system', 'architecture', 'query', 'dex', 'technique', 'big', 'datum', 'management', 'mining', 'tribute', 'machine', 'learning', 'system', 'serve', 'technical', 'program', 'various', 'international', 'con', 'ference', 'include', 'icde', 'www', 'kdd', 'area', 'chair', 'icde', 'demo', 'cochair', 'icde', 'area', 'chair', 'vldb', 'pc', 'cochair', 'waim', 'dasfaa', 'serve', 'vice', 'chair', 'technical', 'database', 'trustee', 'board', 'member', 'endow', 'also', 'editorial', 'board', 'distribute', 'parallel', 'database', 'journal', 'computer', 'science', 'tech', 'nology', 'associate', 'editor', 'ieee', 'transaction', 'knowledge', 'datum', 'engineering', 'tkde', 'journal', 'award', 'young', 'professorship', 'award', 'second', 'prize', 'natural', 'ence', 'award', 'appoint', 'professor', 'moe', 'relevant', 'publication', 'organizer', 'order', 'demon', 'strate', 'presenter', 'qualiﬁe', 'highquality', 'introduc', 'tion', 'odrss', 'list', 'relevant', 'paper', 'odrss', 'publish', 'presenter', 'deployment', 'inference', 'odrss', 'training', 'odrss', 'privacy', 'security', 'odrss', '29–31', 'overall', 'tutorial', 'aim', 'beneﬁt', 'participate', 'audience', 'follow', 'aspect', '•', 'aim', 'furnish', 'participant', 'comprehensive', 'current', 'picture', 'odrss', 'enable', 'grasp', 'cur', 'rent', 'stateoftheart', 'technology', 'methodology', 'employ', 'odrss', '•', 'lay', 'systematic', 'categorization', 'odrss', 'participant', 'facilitate', 'structured', 'understanding', 'various', 'method', 'involve', 'category', 'explore', 'detail', 'discuss', 'technical', 'aspect', 'diﬀerentiate', '•', 'outline', 'potential', 'future', 'research', 'direction', 'aid', 'participant', 'identify', 'area', 'contribute', 'far', 'body', 'knowledge', 'ﬁeld', 'style', 'tutorial', 'deliver', 'lecturestyle', 'tutorial', 'aim', 'provide', 'comprehensive', 'introduction', 'research', 'odrss', 'pioneer', 'work', 'stateoftheart', 'research', 'also', 'discuss', 'fu', 'ture', 'research', 'direction', 'challenge', 'web', 'conference', 'schedule', 'content', 'plan', 'hour', 'consist', 'ﬁve', 'section', 'follow', 'provide', 'outline', 'tutorial', 'section', 'welcome', 'introduction', 'min', 'presenter', 'overview', 'recommender', 'system', 'rss', 'ondevice', 'recommender', 'system', 'odrss', 'background', 'application', 'section', 'deﬁnition', 'taxonomy', 'odrss', 'min', 'presenter', 'deﬁnition', 'ondevice', 'recommendation', 'task', 'categorization', 'exist', 'odrss', 'section', 'review', 'odrss', 'min', 'presenter', 'ondevice', 'deployment', 'inference', 'binary', 'codebase', 'method', 'embed', 'sparsiﬁcation', 'method', 'compositional', 'embed', 'method', 'variable', 'size', 'embed', 'method', 'sustainable', 'deployment', 'ondevice', 'training', 'servercoordinatedfederate', 'learn', 'ondevice', 'rec', 'ommendation', 'semidecentralize', 'odrss', 'ondevice', 'recommender', 'finetune', 'privacy', 'security', 'privacy', 'risk', 'countermeasure', 'poisoning', 'attack', 'defense', 'method', 'section', 'limitation', 'new', 'trend', 'min', 'presenter', 'prof', 'cui', 'open', 'challenge', 'exist', 'odrss', 'emerge', 'research', 'direction', 'section', 'open', 'discussion', 'min', 'presenter', 'cui', 'question', 'answer', 'reﬂection', 'suggestion', 'link', 'resource', 'audience', 'tutorial', 'target', 'diverse', 'audience', 'cohort', 'academia', 'industry', 'background', 'recommendation', 'rele', 'vant', 'area', 'include', 'limit', 'information', 'retrieval', 'web', 'mining', 'internetofthing', 'iot', 'prerequisite', 'basic', 'knowl', 'edge', 'recommender', 'system', 'prefer', 'tutorial', 'also', 'cover', 'necessary', 'foundation', 'well', 'audience', 'engage', 'tutorial', 'expect', 'audience', 'form', 'upto', 'date', 'picture', 'diﬀerent', 'application', 'scenario', 'odrss', 'well', 'core', 'technical', 'building', 'block', 'consider', 'high', 'accessi', 'bility', 'conference', 'expect', 'participant', 'tutorial', 'web', 'conference', 'tutorial', 'material', 'acceptance', 'tutorial', 'slide', 'video', 'recording', 'make', 'available', 'attendee', 'tutorial', 'website', 'week', 'scheduled', 'conference', 'date', 'video', 'teaser', 'video', 'teaser', 'available', 'https', 'bitlyodr', 'acknowledgment', 'work', 'support', 'australian', 'stream', 'future', 'fellowship', 'ft210100624', 'discov', 'ery', 'project', 'dp240101108', 'discovery', 'early', 'career', 'researcher', 'award', 'reference', 'federate', 'matrix', 'factorization', 'inference', 'attack', 'tist', 'learn', 'elastic', 'embedding', 'customize', 'ondevice', 'recommender', 'sigkdd', 'jiangle', 'de', 'realtime', 'short', 'video', 'recommendation', 'bile', 'device', 'cikm', 'kaiqi', 'recommender', 'system', 'edge', 'mobile', 'cikm', 'alexander', 'refrs', 'resourceeﬃcient', 'federate', 'recommender', 'system', 'dynamic', 'diversiﬁed', 'user', 'preference', 'tois', '1–30', 'te', 'learn', 'embed', 'categorical', 'feature', 'embed', 'table', 'recommendation', 'sigkdd', 'qinyong', 'next', 'pointofinterest', 'recommendation', 'resourceconstraine', 'mobile', 'device', 'web', 'conference', 'qinyong', 'fastadapting', 'privacypreserve', 'federate', 'rec', 'ommender', 'system', 'vldbj', 'dattack', 'eﬀective', 'covert', 'poisoning', 'attack', 'federate', 'recommendation', 'hard', 'sampling', 'sigkdd', 'ondevice', 'nextitem', 'recommendation', 'self', 'supervise', 'knowledge', 'distillation', 'sigir', 'eﬃcient', 'ondevice', 'sessionbase', 'recommendation', 'acm', 'transaction', 'information', 'system', 'communicationeﬃcient', 'model', 'update', 'ondevice', 'sessionbase', 'recom', 'mendation', 'proceeding', '32nd', 'acm', 'international', 'conference', 'informa', 'tion', 'knowledge', 'management', 'chaoyue', 'ondevice', 'learning', 'model', 'personalization', 'largescale', 'cloudcoordinate', 'domain', 'adaption', 'sigkdd', 'le', 'tian', 'minkai', 'arxiv', 'preprint', 'jure', 'leskovec', 'graph', 'vectorquantization', 'bridge', 'gnn', 'mlp', 'collaborative', 'learning', 'recommendation', 'sigkdd', 'tieke', 'manipulate', 'federate', 'recommender', 'system', 'poisoning', 'synthetic', 'user', 'countermeasure', 'sigir', 'chaoqun', 'tieke', 'interactionlevel', 'membership', 'inference', 'attack', 'erate', 'recommender', 'system', 'www', 'tieke', 'federate', 'unlearning', 'ondevice', 'recommendation', 'wsdm', 'honglei', 'xiangnan', 'lightfr', 'lightweight', 'federate', 'recommendation', 'privacypreserve', 'trix', 'factorization', 'tois', 'yehuda', 'koren', 'rendle', 'advance', 'collaborative', 'huanbo', 'tat', 'seng', 'discrete', 'collaborative', 'ﬁltering', 'sigir', 'shijie', 'pipattack', 'poisoning', 'federate', 'recommender', 'system', 'nipulating', 'item', 'promotion', 'wsdm', 'shijie', 'comprehensive', 'privacy', 'sis', 'federate', 'recommender', 'system', 'attribute', 'inference', 'attack', 'ieee', 'transaction', 'knowledge', 'datum', 'engineering', 'discrete', 'personalize', 'rank', 'fast', 'collaborative', 'ﬁltering', 'implicit', 'feedback', 'vol', 'ﬁltere', 'recommender', 'system', 'handbook', 'lightrec', 'memory', 'searcheﬃcient', 'recommender', 'system', 'web', 'conference', 'learn', 'compact', 'compositional', 'embedding', 'regularize', 'pruning', 'recommendation', 'arxiv', 'preprint', 'automate', 'embed', 'size', 'search', 'deep', 'recommender', 'system', 'sigir', 'gao', 'learnable', 'embed', 'size', 'recommender', 'system', 'iclr', 'jing', 'long', 'modelagnostic', 'decentralize', 'collaborative', 'learning', 'ondevice', 'poi', 'recommendation', 'sigir', 'jing', 'long', 'decen', 'tralize', 'collaborative', 'learning', 'framework', 'next', 'poi', 'recommendation', 'tois', 'zheqi', 'duet', 'tuningfree', 'devicecloud', 'collaborative', 'param', 'eter', 'generation', 'framework', 'eﬃcient', 'device', 'model', 'generalization', 'pro', 'ceeding', 'web', 'conference', 'qinqin', 'reillymorgan', 'fedfast', 'go', 'average', 'fast', 'training', 'federated', 'recommender', 'system', 'sigkdd', 'ruiqi', 'semidecentralize', 'federate', 'ego', 'graph', 'learn', 'recommendation', 'www', 'yunke', 'arxiv', 'preprint', 'budget', 'embed', 'table', 'recommender', 'system', 'yunke', 'continuous', 'input', 'embed', 'size', 'search', 'recommender', 'system', 'dheevatsa', 'mudigere', 'maxim', 'compositional', 'embedding', 'use', 'complementary', 'partition', 'memory', 'eﬃcient', 'recommendation', 'system', 'sigkdd']"
