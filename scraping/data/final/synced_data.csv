title,url,date,summary,text,cleaning,tokens
Adobe’s DMV3D Achieves SOTA Performance for High-Fidelity 3D Objects Generation Within Seconds,https://syncedreview.com/2023/11/28/adobes-dmv3d-achieves-sota-performance-for-high-fidelity-3d-objects-generation-within-seconds/,2023-11-28,"
A research team innovative single-stage category-agnostic diffusion model. This model can generate 3D Neural Radiance Fields (NeRFs) from either text or a single-image input condition through direct model inference, enabling the creation of diverse high-fidelity 3D objects in just 30s/asset. 

 ","The recent surge in the popularity of 3D diffusion models is transforming the landscape of 3D asset generation, particularly in applications such as Augmented Reality (AR), Virtual Reality (VR), robotics, and gaming. These models excel in simplifying the complex 3D asset creation process, significantly reducing the manual workload involved. However, a common challenge with these models is the need for access to ground-truth 3D models or point clouds for training, which can be challenging to obtain for real images. Additionally, the latent 3D diffusion approach often results in an intricate and challenging-to-denoise latent space on highly diverse, category-free 3D datasets, posing a hurdle for achieving high-quality rendering. In a new paper DMV3D: Denoising Multi-View Diffusion using 3D Large Reconstruction Model, a research team from Adobe Research, Stanford University, HKU, TTIC and HKUST proposes DMV3D, an innovative single-stage category-agnostic diffusion model. This model can generate 3D Neural Radiance Fields (NeRFs) from either text or a single-image input condition through direct model inference, enabling the creation of diverse high-fidelity 3D objects in just 30 seconds per asset. The team summarizes their main contributions as follows: The primary objective of this research is to realize rapid, realistic, and generic 3D generation. The proposed DMV3D integrates 3D NeRF reconstruction and rendering into its denoiser, creating a 2D multi-view image diffusion model trained without direct 3D supervision. This approach avoids the need for separately training 3D NeRF encoders for latent-space diffusion and eliminates the laborious per-asset optimization process. Essentially, DMV3D incorporates a 3D reconstruction model as the 2D multi-view denoiser within a multi-view diffusion framework. The team strategically considers a sparse set of four multi-view images surrounding an object, effectively describing a 3D object without significant self-occlusions. Leveraging large transformer models, the researchers address the challenging task of sparse-view 3D reconstruction. Built upon the recent 3D Large Reconstruction Model (LRM), they introduce a novel model for joint reconstruction and denoising, capable of handling various noise levels in the diffusion process. This model can be seamlessly integrated as the multi-view image denoiser in a multi-view image diffusion framework. The team trained their model on large-scale datasets comprising synthetic renderings from Objaverse and real captures from MVImgNet, using only image-space supervision. DMV3D not only demonstrates the ability for single-stage 3D generation in approximately 30 seconds on a single A100 GPU but also achieves state-of-the-art results in single-image 3D reconstruction, surpassing prior methods based on SDS (Self-Supervised Depth Sensing) and other 3D diffusion models. In summary, this work provides a fresh perspective on addressing 3D generation tasks by bridging the realms of 2D and 3D generative models, unifying 3D reconstruction and generation. The implications extend beyond the immediate applications, opening doors for the development of foundational models to tackle a diverse array of challenges in 3D vision and graphics. The project website is at: https: //justimyhxu.github.io/projects/dmv3d/. The paper DMV3D: Denoising Multi-View Diffusion using 3D Large Reconstruction Model on arXiv. Author: Hecate He | Editor: Chain Zhang We know you don’t want to miss any news or research breakthroughs. Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates.","The recent surge in the popularity of 3D diffusion models is transforming the landscape of 3D asset generation , particularly in applications such as Augmented Reality ( AR ) , Virtual Reality ( VR ) , robotics , and gaming . These models excel in simplifying the complex 3D asset creation process , significantly reducing the manual workload involved . However , a common challenge with these models is the need for access to ground-truth 3D models or point clouds for training , which can be challenging to obtain for real images . Additionally , the latent 3D diffusion approach often results in an intricate and challenging-to-denoise latent space on highly diverse , category-free 3D datasets , posing a hurdle for achieving high-quality rendering . In a new paper DMV3D : Denoising Multi-View Diffusion using 3D Large Reconstruction Model , a research team from Adobe Research , Stanford University , HKU , TTIC and HKUST proposes DMV3D , an innovative single-stage category-agnostic diffusion model . This model can generate 3D Neural Radiance Fields ( NeRFs ) from either text or a single-image input condition through direct model inference , enabling the creation of diverse high-fidelity 3D objects in just 30 seconds per asset . The team summarizes their main contributions as follows : The primary objective of this research is to realize rapid , realistic , and generic 3D generation . The proposed DMV3D integrates 3D NeRF reconstruction and rendering into its denoiser , creating a 2D multi-view image diffusion model trained without direct 3D supervision . This approach avoids the need for separately training 3D NeRF encoders for latent-space diffusion and eliminates the laborious per-asset optimization process . Essentially , DMV3D incorporates a 3D reconstruction model as the 2D multi-view denoiser within a multi-view diffusion framework . The team strategically considers a sparse set of four multi-view images surrounding an object , effectively describing a 3D object without significant self-occlusions . Leveraging large transformer models , the researchers address the challenging task of sparse-view 3D reconstruction . Built upon the recent 3D Large Reconstruction Model ( LRM ) , they introduce a novel model for joint reconstruction and denoising , capable of handling various noise levels in the diffusion process . This model can be seamlessly integrated as the multi-view image denoiser in a multi-view image diffusion framework . The team trained their model on large-scale datasets comprising synthetic renderings from Objaverse and real captures from MVImgNet , using only image-space supervision . DMV3D not only demonstrates the ability for single-stage 3D generation in approximately 30 seconds on a single A100 GPU but also achieves state-of-the-art results in single-image 3D reconstruction , surpassing prior methods based on SDS ( Self-Supervised Depth Sensing ) and other 3D diffusion models . In summary , this work provides a fresh perspective on addressing 3D generation tasks by bridging the realms of 2D and 3D generative models , unifying 3D reconstruction and generation . The implications extend beyond the immediate applications , opening doors for the development of foundational models to tackle a diverse array of challenges in 3D vision and graphics . The project website is at : https : . The paper DMV3D : Denoising Multi-View Diffusion using 3D Large Reconstruction Model on arXiv . Author : Hecate He | Editor : Chain Zhang We know you don ’ t want to miss any news or research breakthroughs . Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates .","['recent', 'surge', 'popularity', '3d', 'diffusion', 'model', 'transform', 'landscape', '3d', 'asset', 'generation', 'particularly', 'application', 'augment', 'reality', 'ar', 'virtual', 'reality', 'vr', 'robotic', 'game', 'model', 'excel', 'simplify', 'complex', '3d', 'asset', 'creation', 'process', 'significantly', 'reduce', 'manual', 'workload', 'involve', 'however', 'common', 'challenge', 'model', 'need', 'access', 'groundtruth', '3d', 'model', 'point', 'cloud', 'training', 'challenge', 'obtain', 'real', 'image', 'additionally', 'latent', '3d', 'diffusion', 'approach', 'often', 'result', 'intricate', 'challengingtodenoise', 'latent', 'space', 'highly', 'diverse', 'categoryfree', '3d', 'dataset', 'pose', 'hurdle', 'achieve', 'highquality', 'rendering', 'new', 'paper', 'denoise', 'multiview', 'diffusion', 'use', '3d', 'large', 'reconstruction', 'model', 'research', 'team', 'hku', 'ttic', 'hkust', 'propose', 'innovative', 'singlestage', 'categoryagnostic', 'diffusion', 'model', 'model', 'generate', '3d', 'neural', 'radiance', 'field', 'nerf', 'text', 'singleimage', 'input', 'condition', 'direct', 'model', 'inference', 'enable', 'creation', 'diverse', 'highfidelity', '3d', 'object', 'second', 'asset', 'team', 'summarize', 'main', 'contribution', 'follow', 'primary', 'objective', 'research', 'realize', 'rapid', 'realistic', 'generic', '3d', 'generation', 'propose', 'integrate', '3d', 'nerf', 'reconstruction', 'render', 'denoiser', 'create', 'multiview', 'image', 'diffusion', 'model', 'train', 'direct', '3d', 'supervision', 'approach', 'avoid', 'need', 'separately', 'train', '3d', 'nerf', 'encoder', 'latentspace', 'diffusion', 'eliminate', 'laborious', 'perasset', 'optimization', 'process', 'essentially', 'incorporate', '3d', 'reconstruction', 'model', 'multiview', 'denoiser', 'multiview', 'diffusion', 'framework', 'team', 'strategically', 'consider', 'sparse', 'set', 'multiview', 'image', 'surround', 'object', 'effectively', 'describe', '3d', 'object', 'significant', 'selfocclusion', 'leverage', 'large', 'transformer', 'model', 'researcher', 'address', 'challenging', 'task', 'sparseview', '3d', 'reconstruction', 'build', 'recent', '3d', 'large', 'reconstruction', 'model', 'introduce', 'novel', 'model', 'joint', 'reconstruction', 'denoise', 'capable', 'handle', 'various', 'noise', 'level', 'diffusion', 'process', 'model', 'seamlessly', 'integrate', 'multiview', 'image', 'denoiser', 'multiview', 'image', 'diffusion', 'framework', 'team', 'train', 'model', 'largescale', 'dataset', 'comprise', 'synthetic', 'rendering', 'real', 'capture', 'mvimgnet', 'use', 'imagespace', 'supervision', 'demonstrate', 'ability', 'singlestage', '3d', 'generation', 'approximately', 'second', 'single', 'also', 'achieve', 'stateoftheart', 'result', 'singleimage', '3d', 'reconstruction', 'surpass', 'prior', 'method', 'base', 'sds', 'selfsupervise', 'depth', 'sensing', '3d', 'diffusion', 'model', 'summary', 'work', 'provide', 'fresh', 'perspective', 'address', '3d', 'generation', 'task', 'bridge', 'realm', '2d', '3d', 'generative', 'model', 'unify', '3d', 'reconstruction', 'generation', 'implication', 'extend', 'immediate', 'application', 'opening', 'door', 'development', 'foundational', 'model', 'tackle', 'diverse', 'array', 'challenge', '3d', 'vision', 'graphic', 'project', 'website', 'https', 'paper', 'denoise', 'multiview', 'diffusion', 'use', '3d', 'large', 'reconstruction', 'model', 'arxiv', 'author', 'hecate', 'editor', 'chain', 'know', 'want', 'miss', 'news', 'research', 'breakthrough', 'subscribe', 'popular', 'newsletter', 'sync', 'global', 'ai', 'weekly', 'get', 'weekly', 'update']"
DeepMind’s DiLoCo Revolutionizes Language Model Training with 500× Less Communication,https://syncedreview.com/2023/11/27/deepminds-diloco-revolutionizes-language-model-training-with-500x-less-communication/,2023-11-27,"
In a new paper DiLoCo: Distributed Low-Communication Training of Language Models, a Google DeepMind research team presents Distributed Low-Communication (DiLoCo). DiLoCo employs a distributed optimization algorithm that facilitates the training of language models on islands of poorly connected devices, surpassing the performance of fully synchronous models while reducing communication by 500 times.
","Language models have demonstrated exceptional performance across various real-world applications. However, at contemporary scales, the conventional training method employing standard backpropagation introduces formidable engineering and infrastructure challenges. The difficulty lies in co-locating and synchronizing a large number of accelerators. In response to this challenge, in a new paper DiLoCo: Distributed Low-Communication Training of Language Models, a Google DeepMind research team presents Distributed Low-Communication (DiLoCo). DiLoCo employs a distributed optimization algorithm that facilitates the training of language models on islands of poorly connected devices, surpassing the performance of fully synchronous models while reducing communication by 500 times. Drawing inspiration from Federated Learning literature, the researchers propose a variant of the widely-used Federated Averaging (FedAvg) algorithm. They introduce a specific instantiation with a momentum-based optimizer, akin to the FedOpt algorithm. Notably, DiLoCo replaces the inner optimizer with AdamW and the outer optimizer with Nesterov Momentum for optimal performance. This innovative combination effectively addresses the challenges posed by conventional training approaches. The DiLoCo approach mitigates the aforementioned challenges through three key elements: a) Limited co-location requirements: While each worker requires co-located devices, their number is smaller than the total, easing the logistical burden. b) Reduced communication frequency: Workers need not communicate at each step, but only every 𝐻 steps, potentially in the order of hundreds or even thousands, significantly lowering communication overhead. c) Device heterogeneity: While devices within an island need to be homogeneous, different islands can operate with different types of devices, enhancing flexibility. In the DiLoCo training process, a pretrained model 𝜃 (0) is replicated 𝑘 times. Each worker independently and in parallel trains a model replica on its own shard of data for 𝐻 steps. Subsequently, workers average their outer gradients, and an outer optimizer updates the global parameter copy 𝜃 (1), which is then redistributed to the workers. This process repeats 𝑇 times. Notably, each replica can be trained in different global locations using various accelerators. On the widely-used C4 dataset, DiLoCo with 8 workers demonstrates performance on par with fully synchronous optimization while reducing communication by 500 times. Furthermore, DiLoCo exhibits remarkable robustness to variations in the data distribution of each worker and adapts seamlessly to changes in resource availability during training. In summary, DiLoCo presents a robust and effective solution for distributing the training of transformer language models when multiple machines are available but poorly connected. This innovative approach not only overcomes infrastructure challenges but also showcases superior performance and adaptability, marking a significant advancement in the field of language model optimization. The paper DiLoCo: Distributed Low-Communication Training of Language Models on arXiv. Author: Hecate He | Editor: Chain Zhang We know you don’t want to miss any news or research breakthroughs. Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates.","Language models have demonstrated exceptional performance across various real-world applications . However , at contemporary scales , the conventional training method employing standard backpropagation introduces formidable engineering and infrastructure challenges . The difficulty lies in co-locating and synchronizing a large number of accelerators . In response to this challenge , in a new paper DiLoCo : Distributed Low-Communication Training of Language Models , a Google DeepMind research team presents Distributed Low-Communication ( DiLoCo ) . DiLoCo employs a distributed optimization algorithm that facilitates the training of language models on islands of poorly connected devices , surpassing the performance of fully synchronous models while reducing communication by 500 times . Drawing inspiration from Federated Learning literature , the researchers propose a variant of the widely-used Federated Averaging ( FedAvg ) algorithm . They introduce a specific instantiation with a momentum-based optimizer , akin to the FedOpt algorithm . Notably , DiLoCo replaces the inner optimizer with AdamW and the outer optimizer with Nesterov Momentum for optimal performance . This innovative combination effectively addresses the challenges posed by conventional training approaches . The DiLoCo approach mitigates the aforementioned challenges through three key elements : a ) Limited co-location requirements : While each worker requires co-located devices , their number is smaller than the total , easing the logistical burden . b ) Reduced communication frequency : Workers need not communicate at each step , but only every 𝐻 steps , potentially in the order of hundreds or even thousands , significantly lowering communication overhead . c ) Device heterogeneity : While devices within an island need to be homogeneous , different islands can operate with different types of devices , enhancing flexibility . In the DiLoCo training process , a pretrained model 𝜃 ( 0 ) is replicated 𝑘 times . Each worker independently and in parallel trains a model replica on its own shard of data for 𝐻 steps . Subsequently , workers average their outer gradients , and an outer optimizer updates the global parameter copy 𝜃 ( 1 ) , which is then redistributed to the workers . This process repeats 𝑇 times . Notably , each replica can be trained in different global locations using various accelerators . On the widely-used C4 dataset , DiLoCo with 8 workers demonstrates performance on par with fully synchronous optimization while reducing communication by 500 times . Furthermore , DiLoCo exhibits remarkable robustness to variations in the data distribution of each worker and adapts seamlessly to changes in resource availability during training . In summary , DiLoCo presents a robust and effective solution for distributing the training of transformer language models when multiple machines are available but poorly connected . This innovative approach not only overcomes infrastructure challenges but also showcases superior performance and adaptability , marking a significant advancement in the field of language model optimization . The paper DiLoCo : Distributed Low-Communication Training of Language Models on arXiv . Author : Hecate He | Editor : Chain Zhang We know you don ’ t want to miss any news or research breakthroughs . Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates .","['language', 'model', 'demonstrate', 'exceptional', 'performance', 'various', 'realworld', 'application', 'however', 'contemporary', 'scale', 'conventional', 'training', 'method', 'employ', 'standard', 'backpropagation', 'introduce', 'formidable', 'engineering', 'infrastructure', 'challenge', 'difficulty', 'lie', 'colocate', 'synchronize', 'large', 'number', 'accelerator', 'response', 'challenge', 'new', 'paper', 'diloco', 'distribute', 'lowcommunication', 'training', 'language', 'model', 'research', 'team', 'present', 'distribute', 'lowcommunication', 'diloco', 'diloco', 'employ', 'distribute', 'optimization', 'facilitate', 'training', 'language', 'model', 'island', 'poorly', 'connect', 'device', 'surpass', 'performance', 'fully', 'synchronous', 'model', 'reduce', 'communication', 'time', 'draw', 'inspiration', 'federated', 'learn', 'literature', 'researcher', 'propose', 'variant', 'widelyused', 'federate', 'average', 'introduce', 'specific', 'instantiation', 'momentumbase', 'optimizer', 'akin', 'notably', 'diloco', 'replace', 'inner', 'optimizer', 'adamw', 'outer', 'optimizer', 'nesterov', 'momentum', 'optimal', 'performance', 'innovative', 'combination', 'effectively', 'address', 'challenge', 'pose', 'conventional', 'training', 'approach', 'approach', 'mitigate', 'aforementione', 'challenge', 'key', 'element', 'limited', 'colocation', 'requirement', 'worker', 'require', 'colocate', 'device', 'number', 'small', 'total', 'ease', 'logistical', 'burden', 'b', 'reduce', 'communication', 'frequency', 'worker', 'communicate', 'step', 'step', 'potentially', 'order', 'hundred', 'even', 'thousand', 'significantly', 'lower', 'communication', 'overhead', 'c', 'device', 'heterogeneity', 'device', 'island', 'need', 'homogeneous', 'different', 'island', 'operate', 'different', 'type', 'device', 'enhance', 'flexibility', 'diloco', 'training', 'process', 'pretraine', 'model', 'replicate', 'time', 'worker', 'independently', 'parallel', 'train', 'model', 'replica', 'shard', 'datum', 'step', 'subsequently', 'worker', 'average', 'outer', 'gradient', 'outer', 'optimizer', 'update', 'global', 'parameter', 'redistribute', 'worker', 'process', 'repeat', 'notably', 'replica', 'train', 'different', 'global', 'location', 'use', 'various', 'accelerator', 'widelyused', 'c4', 'dataset', 'diloco', 'worker', 'demonstrate', 'performance', 'par', 'fully', 'synchronous', 'optimization', 'reduce', 'communication', 'time', 'furthermore', 'diloco', 'exhibit', 'remarkable', 'robustness', 'variation', 'data', 'distribution', 'worker', 'adapt', 'seamlessly', 'change', 'resource', 'availability', 'training', 'summary', 'diloco', 'present', 'robust', 'effective', 'solution', 'distribute', 'training', 'transformer', 'language', 'model', 'multiple', 'machine', 'available', 'poorly', 'connect', 'innovative', 'approach', 'overcome', 'infrastructure', 'challenge', 'also', 'showcase', 'superior', 'performance', 'adaptability', 'mark', 'significant', 'advancement', 'field', 'language', 'model', 'optimization', 'paper', 'diloco', 'distribute', 'lowcommunication', 'training', 'language', 'model', 'arxiv', 'author', 'hecate', 'editor', 'chain', 'know', 'want', 'miss', 'news', 'research', 'breakthrough', 'subscribe', 'popular', 'newsletter', 'sync', 'global', 'ai', 'weekly', 'get', 'weekly', 'update']"
Meet LEO: An Embodied Generalist Agent Excelling in 3D World Tasks,https://syncedreview.com/2023/11/26/meet-leo-an-embodied-generalist-agent-excelling-in-3d-world-tasks/,2023-11-26,"
In a new paper An Embodied Generalist Agent in 3D World, a research team introduces LEO, which stands as an embodied multi-modal and multi-task generalist agent that excels in essential capabilities such as perception, grounding, reasoning, planning, and action within the intricate 3D world.
","The quest to develop a single, versatile model capable of performing diverse tasks akin to human abilities has been a longstanding pursuit in the realms of artificial intelligence and neuroscience. Recent strides in the realm of large language models (LLMs) have presented a promising avenue for creating such generalist models. Leveraging expansive datasets and scalable Transformer architectures, these models have shown immense potential. However, a significant challenge persists: the limited capacity of these models to comprehend and engage with the three-dimensional environment that encompasses humans and other intelligent entities. This constraint acts as a bottleneck, impeding the successful execution of real-world tasks and the achievement of true general intelligence. In a new paper An Embodied Generalist Agent in 3D World, a research team from Beijing Institute for General Artificial Intelligence (BIGAI), Peking University, Carnegie Mellon University and Tsinghua University introduce LEO, which stands as an embodied multi-modal and multi-task generalist agent that excels in essential capabilities such as perception, grounding, reasoning, planning, and action within the intricate 3D world. The team summarizes their main contributions as follows: LEO undergoes training in two stages, utilizing shared LLM-based model architectures, objectives, and weights: (i) 3D vision-language alignment and (ii) 3D vision-language-action instruction tuning. LEO’s perceptual abilities stem from an egocentric 2D image encoder for embodied views and an object-centric 3D point cloud encoder for a global, third-person perspective. The output tokens from the 3D encoder, representing observed entities, are interleaved with text tokens to form a scene-grounded instructional task sequence. This sequence serves as input to a decoder-only LLM, framing all tasks as sequence prediction problems. Autoregressive training objectives allow LEO to be trained with task-agnostic inputs and outputs. The team conducts a comprehensive empirical study, quantitatively evaluating and ablating LEO on diverse 3D tasks. Tasks include object-level and scene-level captioning, 3D question answering, and robotic manipulation. Results indicate that LEO achieves state-of-the-art performance on most tasks. Task-agnostic instruction tuning, enabled by a unified model, surpasses previous task-specific models across various domains. Moreover, pretraining of 3D vision-language alignment significantly enhances the performance of VLA instruction-tuning. The study also highlights the positive impact of scaling up training data on the generalist agent’s performance. In conclusion, LEO stands as a pioneering embodiment of a generalist agent, showcasing remarkable capabilities in navigating and interacting within the 3D world. The insights and methodologies introduced by the research team open new avenues for the development of artificial intelligence with enhanced perceptual and action-oriented competencies. The paper An Embodied Generalist Agent in 3D World on arXiv. Author: Hecate He | Editor: Chain Zhang We know you don’t want to miss any news or research breakthroughs. Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates.","The quest to develop a single , versatile model capable of performing diverse tasks akin to human abilities has been a longstanding pursuit in the realms of artificial intelligence and neuroscience . Recent strides in the realm of large language models ( LLMs ) have presented a promising avenue for creating such generalist models . Leveraging expansive datasets and scalable Transformer architectures , these models have shown immense potential . However , a significant challenge persists : the limited capacity of these models to comprehend and engage with the three-dimensional environment that encompasses humans and other intelligent entities . This constraint acts as a bottleneck , impeding the successful execution of real-world tasks and the achievement of true general intelligence . In a new paper An Embodied Generalist Agent in 3D World , a research team from Beijing Institute for General Artificial Intelligence ( BIGAI ) , Peking University , Carnegie Mellon University and Tsinghua University introduce LEO , which stands as an embodied multi-modal and multi-task generalist agent that excels in essential capabilities such as perception , grounding , reasoning , planning , and action within the intricate 3D world . The team summarizes their main contributions as follows : LEO undergoes training in two stages , utilizing shared LLM-based model architectures , objectives , and weights : ( i ) 3D vision-language alignment and ( ii ) 3D vision-language-action instruction tuning . LEO ’ s perceptual abilities stem from an egocentric 2D image encoder for embodied views and an object-centric 3D point cloud encoder for a global , third-person perspective . The output tokens from the 3D encoder , representing observed entities , are interleaved with text tokens to form a scene-grounded instructional task sequence . This sequence serves as input to a decoder-only LLM , framing all tasks as sequence prediction problems . Autoregressive training objectives allow LEO to be trained with task-agnostic inputs and outputs . The team conducts a comprehensive empirical study , quantitatively evaluating and ablating LEO on diverse 3D tasks . Tasks include object-level and scene-level captioning , 3D question answering , and robotic manipulation . Results indicate that LEO achieves state-of-the-art performance on most tasks . Task-agnostic instruction tuning , enabled by a unified model , surpasses previous task-specific models across various domains . Moreover , pretraining of 3D vision-language alignment significantly enhances the performance of VLA instruction-tuning . The study also highlights the positive impact of scaling up training data on the generalist agent ’ s performance . In conclusion , LEO stands as a pioneering embodiment of a generalist agent , showcasing remarkable capabilities in navigating and interacting within the 3D world . The insights and methodologies introduced by the research team open new avenues for the development of artificial intelligence with enhanced perceptual and action-oriented competencies . The paper An Embodied Generalist Agent in 3D World on arXiv . Author : Hecate He | Editor : Chain Zhang We know you don ’ t want to miss any news or research breakthroughs . Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates .","['quest', 'develop', 'single', 'versatile', 'model', 'capable', 'perform', 'diverse', 'task', 'akin', 'human', 'ability', 'longstanding', 'pursuit', 'realm', 'artificial', 'intelligence', 'neuroscience', 'recent', 'stride', 'realm', 'large', 'language', 'model', 'llm', 'present', 'promising', 'avenue', 'create', 'generalist', 'model', 'leverage', 'expansive', 'dataset', 'scalable', 'transformer', 'architecture', 'model', 'show', 'immense', 'potential', 'however', 'significant', 'challenge', 'persist', 'limited', 'capacity', 'model', 'comprehend', 'engage', 'threedimensional', 'environment', 'encompass', 'human', 'intelligent', 'entity', 'constraint', 'act', 'bottleneck', 'impede', 'successful', 'execution', 'realworld', 'task', 'achievement', 'true', 'general', 'intelligence', 'new', 'paper', 'embody', 'generalist', 'agent', '3d', 'world', 'research', 'team', 'general', 'artificial', 'intelligence', 'bigai', 'peke', 'university', 'carnegie', 'introduce', 'stand', 'embody', 'multimodal', 'multitask', 'generalist', 'agent', 'excel', 'essential', 'capability', 'perception', 'ground', 'reasoning', 'planning', 'action', 'intricate', '3d', 'world', 'team', 'summarize', 'main', 'contribution', 'follow', 'training', 'stage', 'utilize', 'share', 'llmbased', 'model', 'architecture', 'objective', 'weight', '3d', 'visionlanguage', 'alignment', '3d', 'visionlanguageaction', 'instruction', 'tune', 'perceptual', 'ability', 'stem', 'egocentric', 'image', 'encoder', 'embody', 'view', 'objectcentric', '3d', 'point', 'cloud', 'encoder', 'global', 'perspective', 'output', 'token', '3d', 'encoder', 'represent', 'observed', 'entity', 'interleave', 'text', 'token', 'form', 'scenegrounde', 'instructional', 'task', 'sequence', 'sequence', 'serve', 'input', 'decoderonly', 'llm', 'frame', 'task', 'sequence', 'prediction', 'problem', 'autoregressive', 'training', 'objective', 'allow', 'train', 'taskagnostic', 'input', 'output', 'team', 'conduct', 'comprehensive', 'empirical', 'study', 'quantitatively', 'evaluate', 'ablate', 'diverse', '3d', 'task', 'task', 'include', 'objectlevel', 'scenelevel', 'captioning', '3d', 'question', 'answer', 'robotic', 'manipulation', 'result', 'indicate', 'achieve', 'stateoftheart', 'performance', 'task', 'taskagnostic', 'instruction', 'tuning', 'enable', 'unified', 'model', 'surpass', 'previous', 'taskspecific', 'model', 'various', 'domain', 'moreover', 'pretraining', '3d', 'visionlanguage', 'alignment', 'significantly', 'enhance', 'performance', 'vla', 'instructiontune', 'study', 'also', 'highlight', 'positive', 'impact', 'scale', 'training', 'datum', 'generalist', 'agent', 'performance', 'conclusion', 'stand', 'pioneer', 'embodiment', 'generalist', 'agent', 'showcase', 'remarkable', 'capability', 'navigate', 'interact', '3d', 'world', 'insight', 'methodology', 'introduce', 'research', 'team', 'open', 'new', 'avenue', 'development', 'artificial', 'intelligence', 'enhanced', 'perceptual', 'actionoriented', 'competency', 'paper', 'embody', 'generalist', 'agent', '3d', 'world', 'arxiv', 'author', 'hecate', 'editor', 'chain', 'know', 'want', 'miss', 'news', 'research', 'breakthrough', 'subscribe', 'popular', 'newsletter', 'sync', 'global', 'ai', 'weekly', 'get', 'weekly', 'update']"
ETH Zurich’s UltraFastBERT Realizes 78x Speedup for Language Models,https://syncedreview.com/2023/11/24/eth-zurichs-ultrafastbert-realizes-78x-speedup-for-language-models/,2023-11-24,"
In a new paper Exponentially Faster Language Modelling, an ETH Zurich research team introduces UltraFastBERT, a variant of the BERT architecture. UltraFastBERT takes a revolutionary approach by replacing feedforward layers with fast feedforward networks, resulting in an impressive 78x speedup over the optimized baseline feedforward implementation.
","The ever-expanding scale of language models, now boasting tens of billions of parameters, has undeniably enhanced performance across diverse tasks. However, the consequential surge in computation costs poses a significant hurdle for real-world applications. In a bid to overcome this challenge, researchers are diligently working to enhance the efficiency of Large Language Models (LLMs). Recent studies have spotlighted a crucial observation: the majority of parameters in these expansive language models reside within their feedforward layers. Intriguingly, not every neuron in these layers needs to be active during inference, presenting an opportunity to optimize their computation efficiency. In a new paper Exponentially Faster Language Modelling, an ETH Zurich research team introduces UltraFastBERT, a variant of the BERT architecture. UltraFastBERT takes a revolutionary approach by replacing feedforward layers with fast feedforward networks, resulting in an impressive 78x speedup over the optimized baseline feedforward implementation. The main contributions of the research team can be summarized as follows: UltraFastBERT’s architecture draws inspiration from crammedBERT but distinguishes itself by replacing intermediate layer feedforward networks with fast feedforward networks. The simplifying changes applied to these networks include uniform activation functions, output weights for all nodes, removing output biases, fixing leaf size to 1, and allowing multiple FFF trees in parallel. During the training phase, the team follows the final training procedure of crammedBERT, while in the evaluation phase, they fine-tune UltraFastBERT models for various tasks in the GLUE benchmark. Remarkably, the results demonstrate that UltraFastBERT variants trained for just one day on a single A6000 GPU retain at least 96.0% of the GLUE downstream predictive performance of the original BERTbase model. UltraFastBERT-1×11-long even performs on par with the original BERT-base model while utilizing a mere 0.3% of its neurons. In addition to these achievements, the team provides high-level CPU code showcasing a 78x speedup over the optimized baseline feedforward implementation, along with a PyTorch implementation delivering a 40x speedup over the equivalent batched feedforward inference. In conclusion, this work not only verifies the impressive efficiency of UltraFastBERT but also aims to inspire the integration of primitives for conditional neural execution into device programming interfaces. The hope is that these efforts will pave the way for more streamlined and efficient language models in the future. The paper Exponentially Faster Language Modelling on arXiv. Author: Hecate He | Editor: Chain Zhang We know you don’t want to miss any news or research breakthroughs. Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates.","The ever-expanding scale of language models , now boasting tens of billions of parameters , has undeniably enhanced performance across diverse tasks . However , the consequential surge in computation costs poses a significant hurdle for real-world applications . In a bid to overcome this challenge , researchers are diligently working to enhance the efficiency of Large Language Models ( LLMs ) . Recent studies have spotlighted a crucial observation : the majority of parameters in these expansive language models reside within their feedforward layers . Intriguingly , not every neuron in these layers needs to be active during inference , presenting an opportunity to optimize their computation efficiency . In a new paper Exponentially Faster Language Modelling , an ETH Zurich research team introduces UltraFastBERT , a variant of the BERT architecture . UltraFastBERT takes a revolutionary approach by replacing feedforward layers with fast feedforward networks , resulting in an impressive 78x speedup over the optimized baseline feedforward implementation . The main contributions of the research team can be summarized as follows : UltraFastBERT ’ s architecture draws inspiration from crammedBERT but distinguishes itself by replacing intermediate layer feedforward networks with fast feedforward networks . The simplifying changes applied to these networks include uniform activation functions , output weights for all nodes , removing output biases , fixing leaf size to 1 , and allowing multiple FFF trees in parallel . During the training phase , the team follows the final training procedure of crammedBERT , while in the evaluation phase , they fine-tune UltraFastBERT models for various tasks in the GLUE benchmark . Remarkably , the results demonstrate that UltraFastBERT variants trained for just one day on a single A6000 GPU retain at least 96.0 % of the GLUE downstream predictive performance of the original BERTbase model . UltraFastBERT-1×11-long even performs on par with the original BERT-base model while utilizing a mere 0.3 % of its neurons . In addition to these achievements , the team provides high-level CPU code showcasing a 78x speedup over the optimized baseline feedforward implementation , along with a PyTorch implementation delivering a 40x speedup over the equivalent batched feedforward inference . In conclusion , this work not only verifies the impressive efficiency of UltraFastBERT but also aims to inspire the integration of primitives for conditional neural execution into device programming interfaces . The hope is that these efforts will pave the way for more streamlined and efficient language models in the future . The paper Exponentially Faster Language Modelling on arXiv . Author : Hecate He | Editor : Chain Zhang We know you don ’ t want to miss any news or research breakthroughs . Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates .","['everexpande', 'scale', 'language', 'model', 'boast', 'ten', 'billion', 'parameter', 'undeniably', 'enhance', 'performance', 'diverse', 'task', 'however', 'consequential', 'surge', 'computation', 'cost', 'pose', 'significant', 'hurdle', 'realworld', 'application', 'bid', 'overcome', 'challenge', 'researcher', 'diligently', 'work', 'enhance', 'efficiency', 'large', 'language', 'model', 'llm', 'recent', 'study', 'spotlight', 'crucial', 'observation', 'majority', 'parameter', 'expansive', 'language', 'model', 'reside', 'feedforward', 'layer', 'intriguingly', 'neuron', 'layer', 'need', 'active', 'inference', 'present', 'opportunity', 'optimize', 'computation', 'efficiency', 'new', 'paper', 'exponentially', 'fast', 'language', 'model', 'research', 'team', 'introduce', 'ultrafastbert', 'variant', 'architecture', 'ultrafastbert', 'take', 'revolutionary', 'approach', 'replace', 'feedforward', 'layer', 'fast', 'feedforward', 'network', 'result', 'impressive', '78x', 'speedup', 'optimize', 'baseline', 'feedforward', 'implementation', 'main', 'contribution', 'research', 'team', 'summarize', 'follow', 'architecture', 'draw', 'inspiration', 'crammedbert', 'distinguish', 'replace', 'intermediate', 'layer', 'feedforward', 'network', 'fast', 'feedforward', 'network', 'simplifying', 'change', 'apply', 'network', 'include', 'uniform', 'activation', 'function', 'output', 'weight', 'node', 'remove', 'output', 'bias', 'fix', 'leaf', 'size', 'allow', 'multiple', 'fff', 'tree', 'parallel', 'training', 'phase', 'team', 'follow', 'final', 'training', 'procedure', 'crammedbert', 'evaluation', 'phase', 'finetune', 'ultrafastbert', 'model', 'various', 'task', 'glue', 'benchmark', 'remarkably', 'result', 'demonstrate', 'ultrafastbert', 'variant', 'train', 'day', 'single', 'retain', 'least', 'glue', 'downstream', 'predictive', 'performance', 'original', 'bertbase', 'model', 'even', 'perform', 'par', 'original', 'bertbase', 'model', 'utilize', 'mere', 'neuron', 'addition', 'achievement', 'team', 'provide', 'highlevel', 'cpu', 'code', 'showcase', '78x', 'speedup', 'optimize', 'baseline', 'feedforward', 'implementation', 'pytorch', 'implementation', 'deliver', '40x', 'speedup', 'equivalent', 'batch', 'feedforward', 'inference', 'conclusion', 'work', 'verify', 'impressive', 'efficiency', 'also', 'aim', 'inspire', 'integration', 'primitive', 'conditional', 'neural', 'execution', 'device', 'programming', 'interface', 'hope', 'effort', 'pave', 'way', 'streamlined', 'efficient', 'language', 'model', 'future', 'paper', 'exponentially', 'fast', 'language', 'modelling', 'arxiv', 'author', 'hecate', 'editor', 'chain', 'know', 'want', 'miss', 'news', 'research', 'breakthrough', 'subscribe', 'popular', 'newsletter', 'sync', 'global', 'ai', 'weekly', 'get', 'weekly', 'update']"
Microsoft Orca 2’s Triumph: Comparable or Superior Performance to Models 5-10x Its Size in Mastering Reasoning Tasks,https://syncedreview.com/2023/11/22/microsoft-orca-2s-triumph-comparable-or-superior-performance-to-models-5-10x-its-size-in-mastering-reasoning-tasks/,2023-11-22,"
Microsoft has recently unveiled Orca 2 in a new paper titled “Orca 2: Teaching Small Language Models How to Reason.” to explore how enhanced training signals can augment the reasoning abilities of smaller language models. Notably, Orca 2 surpasses models of similar size, achieving performance levels comparable to or better than models 5-10 times larger.
","The continuous scaling of Large Language Models (LLMs) such as GPT-4 and PaLM-2, with an increasing number of parameters, has revealed unprecedented emergent abilities, most notably the remarkable capacity for zero-shot reasoning. As these models evolve and gain more power, researchers are now delving into the possibility of these models autonomously supervising their behavior or even guiding other AI models. Previous studies have demonstrated that by sampling output from an initial model, student models can be trained to emulate the style of their teachers. However, these student models often fall short in terms of reasoning and comprehension skills compared to their larger foundation models. In June 2023, a Microsoft research team addressed this challenge by introducing Orca, a 13-billion parameter model designed to mimic the reasoning process of large foundation models (LFMs). Orca outperformed conventional instruction-tuned models on benchmarks like BigBench Hard and AGIEval. Continuing along this trajectory, Microsoft has recently unveiled Orca 2 in a new paper titled “Orca 2: Teaching Small Language Models How to Reason.” The focus of this release is to explore how enhanced training signals can augment the reasoning abilities of smaller language models. Notably, Orca 2 surpasses models of similar size, achieving performance levels comparable to or better than models 5-10 times larger. Orca 2’s objectives are twofold. Firstly, researchers aim to instruct smaller models in utilizing a suite of reasoning techniques, including step-by-step processing and recall-then-generate. Secondly, they aspire to assist these models in determining the most effective reasoning strategy for a given task, enabling optimal performance regardless of their size. Similar to its predecessor, Orca 1, the team leverages more capable LLMs to showcase various reasoning strategies across tasks. However, in Orca 2, these strategies are meticulously tailored to each task, considering the capabilities of the student model. A notable technique employed in Orca 2 is Prompt Erasure, making it a Cautious Reasoner. This technique enables the model not only to execute specific reasoning steps but also to strategize at a higher level in approaching a task. Instead of blindly imitating powerful LLMs, the team treats them as a repository of behaviors from which they judiciously select those best suited for the task at hand. In their empirical study, the researchers comprehensively evaluate Orca 2 on 15 benchmarks, covering approximately 100 tasks and over 36,000 unique prompts. The results show that Orca 2 significantly outperforms models of similar size, even matching or surpassing those 5 to 10 times larger, particularly on tasks requiring advanced reasoning. In conclusion, this work marks a significant step forward, emphasizing the importance of teaching smaller models to reason. The research team believes that advancing the capabilities of smaller models will pave the way for new applications with different deployment scenarios and trade-offs between efficiency and capability. The paper Orca 2: Teaching Small Language Models How to Reason on arXiv. Author: Hecate He | Editor: Chain Zhang We know you don’t want to miss any news or research breakthroughs. Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates.","The continuous scaling of Large Language Models ( LLMs ) such as GPT-4 and PaLM-2 , with an increasing number of parameters , has revealed unprecedented emergent abilities , most notably the remarkable capacity for zero-shot reasoning . As these models evolve and gain more power , researchers are now delving into the possibility of these models autonomously supervising their behavior or even guiding other AI models . Previous studies have demonstrated that by sampling output from an initial model , student models can be trained to emulate the style of their teachers . However , these student models often fall short in terms of reasoning and comprehension skills compared to their larger foundation models . In June 2023 , a Microsoft research team addressed this challenge by introducing Orca , a 13-billion parameter model designed to mimic the reasoning process of large foundation models ( LFMs ) . Orca outperformed conventional instruction-tuned models on benchmarks like BigBench Hard and AGIEval . Continuing along this trajectory , Microsoft has recently unveiled Orca 2 in a new paper titled “ Orca 2 : Teaching Small Language Models How to Reason. ” The focus of this release is to explore how enhanced training signals can augment the reasoning abilities of smaller language models . Notably , Orca 2 surpasses models of similar size , achieving performance levels comparable to or better than models 5-10 times larger . Orca 2 ’ s objectives are twofold . Firstly , researchers aim to instruct smaller models in utilizing a suite of reasoning techniques , including step-by-step processing and recall-then-generate . Secondly , they aspire to assist these models in determining the most effective reasoning strategy for a given task , enabling optimal performance regardless of their size . Similar to its predecessor , Orca 1 , the team leverages more capable LLMs to showcase various reasoning strategies across tasks . However , in Orca 2 , these strategies are meticulously tailored to each task , considering the capabilities of the student model . A notable technique employed in Orca 2 is Prompt Erasure , making it a Cautious Reasoner . This technique enables the model not only to execute specific reasoning steps but also to strategize at a higher level in approaching a task . Instead of blindly imitating powerful LLMs , the team treats them as a repository of behaviors from which they judiciously select those best suited for the task at hand . In their empirical study , the researchers comprehensively evaluate Orca 2 on 15 benchmarks , covering approximately 100 tasks and over 36,000 unique prompts . The results show that Orca 2 significantly outperforms models of similar size , even matching or surpassing those 5 to 10 times larger , particularly on tasks requiring advanced reasoning . In conclusion , this work marks a significant step forward , emphasizing the importance of teaching smaller models to reason . The research team believes that advancing the capabilities of smaller models will pave the way for new applications with different deployment scenarios and trade-offs between efficiency and capability . The paper Orca 2 : Teaching Small Language Models How to Reason on arXiv . Author : Hecate He | Editor : Chain Zhang We know you don ’ t want to miss any news or research breakthroughs . Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates .","['continuous', 'scaling', 'large', 'language', 'model', 'llm', 'gpt4', 'palm2', 'increase', 'number', 'parameter', 'reveal', 'unprecedented', 'emergent', 'ability', 'notably', 'remarkable', 'capacity', 'zeroshot', 'reasoning', 'model', 'evolve', 'gain', 'power', 'researcher', 'delve', 'possibility', 'model', 'autonomously', 'supervise', 'behavior', 'even', 'guide', 'model', 'previous', 'study', 'demonstrate', 'sample', 'output', 'initial', 'model', 'student', 'model', 'train', 'emulate', 'style', 'teacher', 'however', 'student', 'model', 'often', 'fall', 'short', 'term', 'reasoning', 'comprehension', 'skill', 'compare', 'large', 'foundation', 'model', 'research', 'team', 'address', 'challenge', 'introduce', 'orca', 'parameter', 'model', 'design', 'mimic', 'reasoning', 'process', 'large', 'foundation', 'model', 'orca', 'outperform', 'conventional', 'instructiontune', 'model', 'benchmark', 'bigbench', 'hard', 'agieval', 'continue', 'trajectory', 'recently', 'unveil', 'orca', 'new', 'paper', 'title', 'orca', 'teach', 'small', 'language', 'model', 'reason', 'focus', 'release', 'explore', 'enhanced', 'training', 'signal', 'augment', 'reasoning', 'ability', 'small', 'language', 'model', 'notably', 'orca', 'surpasse', 'model', 'similar', 'size', 'achieve', 'performance', 'level', 'comparable', 'well', 'model', 'time', 'large', 'orca', 'objective', 'twofold', 'firstly', 'researcher', 'aim', 'instruct', 'small', 'model', 'utilize', 'suite', 'reasoning', 'technique', 'include', 'stepbystep', 'processing', 'recallthengenerate', 'secondly', 'aspire', 'assist', 'model', 'determine', 'effective', 'reasoning', 'strategy', 'give', 'task', 'enable', 'optimal', 'performance', 'regardless', 'size', 'similar', 'predecessor', 'orca', 'team', 'leverage', 'capable', 'llm', 'showcase', 'various', 'reasoning', 'strategy', 'task', 'however', 'orca', 'strategy', 'meticulously', 'tailor', 'task', 'consider', 'capability', 'student', 'model', 'notable', 'technique', 'employ', 'orca', 'prompt', 'erasure', 'make', 'cautious', 'reasoner', 'technique', 'enable', 'model', 'execute', 'specific', 'reasoning', 'step', 'also', 'strategize', 'high', 'level', 'approach', 'task', 'instead', 'blindly', 'imitate', 'powerful', 'llm', 'team', 'treat', 'repository', 'behavior', 'judiciously', 'select', 'well', 'suit', 'task', 'hand', 'empirical', 'study', 'researcher', 'comprehensively', 'evaluate', 'orca', 'benchmark', 'cover', 'approximately', 'task', 'unique', 'prompt', 'result', 'show', 'orca', 'significantly', 'outperform', 'model', 'similar', 'size', 'even', 'match', 'surpass', 'time', 'large', 'particularly', 'task', 'require', 'advanced', 'reasoning', 'conclusion', 'work', 'mark', 'significant', 'step', 'forward', 'emphasize', 'importance', 'teach', 'small', 'model', 'reason', 'research', 'team', 'believe', 'advance', 'capability', 'small', 'model', 'pave', 'way', 'new', 'application', 'different', 'deployment', 'scenario', 'tradeoff', 'efficiency', 'capability', 'paper', 'orca', 'teach', 'small', 'language', 'model', 'reason', 'arxiv', 'author', 'hecate', 'editor', 'chain', 'know', 'want', 'miss', 'news', 'research', 'breakthrough', 'subscribe', 'popular', 'newsletter', 'sync', 'global', 'ai', 'weekly', 'get', 'weekly', 'update']"
Democratizing Data: How Apple and UW’s Data Filtering Networks Redefine Large-Scale Training Sets,https://syncedreview.com/2023/11/18/democratizing-data-how-apple-and-uws-data-filtering-networks-redefine-large-scale-training-sets/,2023-11-18,"
In a new paper Data Filtering Networks, a research team from Apple and University of Washington introduces the concept of data filtering networks (DFNs). These neural networks, specifically designed for data filtration, demonstrate the capacity to generate extensive, high-quality pre-training datasets efficiently. 
","Large training datasets have become integral to the field of machine learning, serving as the bedrock for recent breakthroughs in language modeling and multimodal learning. Despite their pivotal role, these datasets are seldom the focal point of active research, with many large-scale training sets remaining unreleased. This lack of accessibility hinders consistent dataset evaluation and the establishment of reproducible frameworks. In a new paper Data Filtering Networks, a research team from Apple and University of Washington introduces the concept of data filtering networks (DFNs). These neural networks, specifically designed for data filtration, demonstrate the capacity to generate extensive, high-quality pre-training datasets efficiently. Notably, DFNs can be trained from scratch and improved using the same techniques as standard machine learning models. The core focus of this work is on dataset filtering, assuming the existence of a large uncurated dataset. The research team highlights three key contributions: The ultimate goal of this research is to develop efficient functions capable of filtering potentially trillions of examples. The team refers to the dataset constructed by filtering a given pool with a DFN as the induced dataset, and the model trained exclusively on that dataset as the induced model. Employing a CLIP model as a DFN, the team defines its filtering performance based on the induced model’s evaluation on standard benchmarks. To enhance the DFN, the team initiates the process by training a CLIP model on a high-quality dataset. Subsequently, they fine-tune the filtering network on additional datasets, incorporating standard machine learning techniques such as augmentation, distinct initialization, and extended training with a larger batch size for further refinement. In their empirical study, the team demonstrates that the best performing dataset, DFN-5B, empowers the training of state-of-the-art CLIP models within specified compute budgets. Among various improvements, a ViT-H model trained on this dataset achieves an impressive 84.4% zero-shot transfer accuracy on ImageNet. In summary, this innovative research on data filtering networks opens new avenues for the efficient creation of high-quality datasets from public data, contributing significantly to the democratization of large-scale datasets and advancing the capabilities of machine learning models. The paper Data Filtering Networks on arXiv. Author: Hecate He | Editor: Chain Zhang We know you don’t want to miss any news or research breakthroughs. Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates.","Large training datasets have become integral to the field of machine learning , serving as the bedrock for recent breakthroughs in language modeling and multimodal learning . Despite their pivotal role , these datasets are seldom the focal point of active research , with many large-scale training sets remaining unreleased . This lack of accessibility hinders consistent dataset evaluation and the establishment of reproducible frameworks . In a new paper Data Filtering Networks , a research team from Apple and University of Washington introduces the concept of data filtering networks ( DFNs ) . These neural networks , specifically designed for data filtration , demonstrate the capacity to generate extensive , high-quality pre-training datasets efficiently . Notably , DFNs can be trained from scratch and improved using the same techniques as standard machine learning models . The core focus of this work is on dataset filtering , assuming the existence of a large uncurated dataset . The research team highlights three key contributions : The ultimate goal of this research is to develop efficient functions capable of filtering potentially trillions of examples . The team refers to the dataset constructed by filtering a given pool with a DFN as the induced dataset , and the model trained exclusively on that dataset as the induced model . Employing a CLIP model as a DFN , the team defines its filtering performance based on the induced model ’ s evaluation on standard benchmarks . To enhance the DFN , the team initiates the process by training a CLIP model on a high-quality dataset . Subsequently , they fine-tune the filtering network on additional datasets , incorporating standard machine learning techniques such as augmentation , distinct initialization , and extended training with a larger batch size for further refinement . In their empirical study , the team demonstrates that the best performing dataset , DFN-5B , empowers the training of state-of-the-art CLIP models within specified compute budgets . Among various improvements , a ViT-H model trained on this dataset achieves an impressive 84.4 % zero-shot transfer accuracy on ImageNet . In summary , this innovative research on data filtering networks opens new avenues for the efficient creation of high-quality datasets from public data , contributing significantly to the democratization of large-scale datasets and advancing the capabilities of machine learning models . The paper Data Filtering Networks on arXiv . Author : Hecate He | Editor : Chain Zhang We know you don ’ t want to miss any news or research breakthroughs . Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates .","['large', 'training', 'dataset', 'become', 'integral', 'field', 'machine', 'learn', 'serve', 'bedrock', 'recent', 'breakthrough', 'language', 'modeling', 'multimodal', 'learn', 'pivotal', 'role', 'dataset', 'seldom', 'focal', 'point', 'active', 'research', 'many', 'largescale', 'training', 'set', 'remain', 'unrelease', 'lack', 'accessibility', 'hinder', 'consistent', 'dataset', 'evaluation', 'establishment', 'reproducible', 'framework', 'new', 'paper', 'datum', 'filtering', 'network', 'research', 'team', 'apple', 'introduce', 'concept', 'datum', 'filtering', 'network', 'neural', 'network', 'specifically', 'design', 'datum', 'filtration', 'demonstrate', 'capacity', 'generate', 'extensive', 'highquality', 'pretraine', 'dataset', 'efficiently', 'notably', 'train', 'scratch', 'improve', 'use', 'technique', 'standard', 'machine', 'learning', 'model', 'core', 'focus', 'work', 'dataset', 'filtering', 'assume', 'existence', 'large', 'uncurated', 'dataset', 'research', 'team', 'highlight', 'key', 'contribution', 'ultimate', 'goal', 'research', 'develop', 'efficient', 'function', 'capable', 'filter', 'potentially', 'trillion', 'example', 'team', 'refer', 'dataset', 'construct', 'filter', 'give', 'pool', 'dfn', 'induce', 'dataset', 'model', 'train', 'exclusively', 'dataset', 'induce', 'model', 'employ', 'clip', 'model', 'dfn', 'team', 'define', 'filter', 'performance', 'base', 'induce', 'model', 'evaluation', 'standard', 'benchmark', 'enhance', 'dfn', 'team', 'initiate', 'process', 'train', 'clip', 'model', 'highquality', 'dataset', 'subsequently', 'finetune', 'filter', 'network', 'additional', 'dataset', 'incorporate', 'standard', 'machine', 'learn', 'technique', 'augmentation', 'distinct', 'initialization', 'extend', 'training', 'large', 'batch', 'size', 'refinement', 'empirical', 'study', 'team', 'demonstrate', 'well', 'perform', 'dataset', 'empower', 'training', 'stateoftheart', 'clip', 'model', 'specify', 'compute', 'budget', 'various', 'improvement', 'vith', 'model', 'train', 'dataset', 'achieve', 'impressive', 'zeroshot', 'transfer', 'accuracy', 'imagenet', 'summary', 'innovative', 'research', 'datum', 'filtering', 'network', 'open', 'new', 'avenue', 'efficient', 'creation', 'highquality', 'dataset', 'public', 'datum', 'contribute', 'significantly', 'democratization', 'largescale', 'dataset', 'advance', 'capability', 'machine', 'learning', 'model', 'paper', 'datum', 'filtering', 'network', 'arxiv', 'author', 'hecate', 'editor', 'chain', 'know', 'want', 'miss', 'news', 'research', 'breakthrough', 'subscribe', 'popular', 'newsletter', 'sync', 'global', 'ai', 'weekly', 'get', 'weekly', 'update']"
Adobe & ANU’s LRM Reconstructs Models For Single Image to 3D in 5s,https://syncedreview.com/2023/11/13/adobe-anus-lrm-reconstructs-models-for-single-image-to-3d-in-5s/,2023-11-13,"
In a new paper LRM: Large Reconstruction Model for Single Image to 3D, a research team from Adobe Research and Australian National Univerisity introduces an innovative Large Reconstruction Model (LRM). This groundbreaking model has the remarkable ability to predict a 3D model of an object from a single input image in a mere 5 seconds.
","The concept of instantly generating a 3D representation from a single image of any object is undeniably captivating. This breakthrough promises to significantly advance applications in industrial design, animation, gaming, and the realms of Augmented Reality (AR) and Virtual Reality (VR). Besides, the remarkable achievements in natural language processing and image processing have inspired researchers to delve into the realms of learning a universal 3D foundation for reconstructing objects from single images. In a new paper LRM: Large Reconstruction Model for Single Image to 3D, a research team from Adobe Research and Australian National University introduces an innovative Large Reconstruction Model (LRM). This groundbreaking model has the remarkable ability to predict a 3D model of an object from a single input image in a mere 5 seconds. The LRM approach adopts a robust transformer-based encoder-decoder architecture for acquiring 3D object representations from a single image in a data-driven fashion. The model takes an image as input and regresses a Neural Radiance Field (NeRF) in the form of a triplane representation. To achieve this, LRM employs the pre-trained visual transformer DINO (Caron et al., 2021) as the image encoder to generate image features. Subsequently, it learns an image-to-triplane transformer decoder to project the 2D image features onto the 3D triplane through cross-attention, effectively modeling relationships among the spatially-structured triplane tokens via self-attention. The output tokens from the decoder are then reshaped and upsampled to create the final triplane feature maps. This enables LRM to render images from any viewpoint by decoding the triplane feature of each point. It does so with the aid of an additional shared multi-layer perceptron (MLP) to determine color and density, facilitating volume rendering. What sets LRM apart is its design, which boasts high scalability and efficiency. In addition to employing a fully transformer-based pipeline, the triplane NeRF it employs stands out as a concise and scalable 3D representation. Compared to other alternatives like volumes and point clouds, it is computationally efficient. Furthermore, it offers superior locality with respect to the input image. One of the remarkable aspects of LRM is its training process, which involves minimizing the difference between rendered images and ground truth images at novel perspectives. This is done without the need for excessive 3D-aware regularization or intricate hyper-parameter tuning, making the model exceedingly efficient during training and adaptable to a wide range of multi-view image datasets. Empirical results underscore the remarkable fidelity of LRM when handling various inputs, spanning real-world images, synthetic creations, and rendered images featuring diverse subjects with distinct textures. It stands out as a state-of-the-art solution for single-image-to-3D reconstruction when compared to One-2-3-45. In summary, this groundbreaking work demonstrates the potential of LRM to swiftly predict a 3D model of any object from a single, arbitrary image found in the wild. This development opens up a broad array of real-world applications that can benefit from this rapid and accurate 3D reconstruction capability. Video demos and interactable 3D meshes can be found on this website: https://yiconghong.me/LRM/. The paper LRM: Large Reconstruction Model for Single Image to 3D on arXiv. Author: Hecate He | Editor: Chain Zhang We know you don’t want to miss any news or research breakthroughs. Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates.","The concept of instantly generating a 3D representation from a single image of any object is undeniably captivating . This breakthrough promises to significantly advance applications in industrial design , animation , gaming , and the realms of Augmented Reality ( AR ) and Virtual Reality ( VR ) . Besides , the remarkable achievements in natural language processing and image processing have inspired researchers to delve into the realms of learning a universal 3D foundation for reconstructing objects from single images . In a new paper LRM : Large Reconstruction Model for Single Image to 3D , a research team from Adobe Research and Australian National University introduces an innovative Large Reconstruction Model ( LRM ) . This groundbreaking model has the remarkable ability to predict a 3D model of an object from a single input image in a mere 5 seconds . The LRM approach adopts a robust transformer-based encoder-decoder architecture for acquiring 3D object representations from a single image in a data-driven fashion . The model takes an image as input and regresses a Neural Radiance Field ( NeRF ) in the form of a triplane representation . To achieve this , LRM employs the pre-trained visual transformer DINO ( Caron et al. , 2021 ) as the image encoder to generate image features . Subsequently , it learns an image-to-triplane transformer decoder to project the 2D image features onto the 3D triplane through cross-attention , effectively modeling relationships among the spatially-structured triplane tokens via self-attention . The output tokens from the decoder are then reshaped and upsampled to create the final triplane feature maps . This enables LRM to render images from any viewpoint by decoding the triplane feature of each point . It does so with the aid of an additional shared multi-layer perceptron ( MLP ) to determine color and density , facilitating volume rendering . What sets LRM apart is its design , which boasts high scalability and efficiency . In addition to employing a fully transformer-based pipeline , the triplane NeRF it employs stands out as a concise and scalable 3D representation . Compared to other alternatives like volumes and point clouds , it is computationally efficient . Furthermore , it offers superior locality with respect to the input image . One of the remarkable aspects of LRM is its training process , which involves minimizing the difference between rendered images and ground truth images at novel perspectives . This is done without the need for excessive 3D-aware regularization or intricate hyper-parameter tuning , making the model exceedingly efficient during training and adaptable to a wide range of multi-view image datasets . Empirical results underscore the remarkable fidelity of LRM when handling various inputs , spanning real-world images , synthetic creations , and rendered images featuring diverse subjects with distinct textures . It stands out as a state-of-the-art solution for single-image-to-3D reconstruction when compared to One-2-3-45 . In summary , this groundbreaking work demonstrates the potential of LRM to swiftly predict a 3D model of any object from a single , arbitrary image found in the wild . This development opens up a broad array of real-world applications that can benefit from this rapid and accurate 3D reconstruction capability . Video demos and interactable 3D meshes can be found on this website : https : //yiconghong.me/LRM/ . The paper LRM : Large Reconstruction Model for Single Image to 3D on arXiv . Author : Hecate He | Editor : Chain Zhang We know you don ’ t want to miss any news or research breakthroughs . Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates .","['concept', 'instantly', 'generate', '3d', 'representation', 'single', 'image', 'object', 'undeniably', 'captivate', 'breakthrough', 'promise', 'significantly', 'advance', 'application', 'industrial', 'design', 'animation', 'gaming', 'realm', 'augmented', 'reality', 'ar', 'virtual', 'reality', 'vr', 'remarkable', 'achievement', 'natural', 'language', 'processing', 'image', 'processing', 'inspire', 'researcher', 'delve', 'realm', 'learn', 'universal', '3d', 'foundation', 'reconstruct', 'object', 'single', 'image', 'new', 'paper', 'lrm', 'large', 'reconstruction', 'model', 'single', 'image', '3d', 'research', 'team', 'adobe', 'research', 'australian', 'national', 'introduce', 'innovative', 'large', 'reconstruction', 'model', 'lrm', 'groundbreaking', 'model', 'remarkable', 'ability', 'predict', '3d', 'model', 'object', 'single', 'input', 'image', 'mere', 'second', 'approach', 'adopt', 'robust', 'transformerbase', 'encoderdecod', 'architecture', 'acquire', '3d', 'object', 'representation', 'single', 'image', 'datadriven', 'fashion', 'model', 'take', 'image', 'input', 'regress', 'neural', 'radiance', 'field', 'nerf', 'form', 'triplane', 'representation', 'achieve', 'lrm', 'employ', 'pretraine', 'visual', 'transformer', 'caron', 'image', 'encoder', 'generate', 'image', 'feature', 'subsequently', 'learn', 'imagetotriplane', 'transformer', 'decoder', 'project', 'image', 'feature', '3d', 'triplane', 'crossattention', 'effectively', 'model', 'relationship', 'spatiallystructured', 'triplane', 'token', 'selfattention', 'output', 'token', 'decoder', 'reshape', 'upsample', 'create', 'final', 'triplane', 'feature', 'map', 'enable', 'render', 'image', 'viewpoint', 'decode', 'triplane', 'feature', 'point', 'aid', 'additional', 'share', 'determine', 'color', 'density', 'facilitate', 'volume', 'render', 'set', 'apart', 'design', 'boast', 'high', 'scalability', 'efficiency', 'addition', 'employ', 'fully', 'transformerbase', 'pipeline', 'triplane', 'nerf', 'employ', 'stand', 'concise', 'scalable', '3d', 'representation', 'compare', 'alternative', 'volume', 'point', 'cloud', 'computationally', 'efficient', 'furthermore', 'offer', 'superior', 'locality', 'respect', 'input', 'image', 'remarkable', 'aspect', 'training', 'process', 'involve', 'minimize', 'difference', 'render', 'image', 'ground', 'truth', 'image', 'novel', 'perspective', 'need', 'excessive', 'regularization', 'intricate', 'hyperparameter', 'tune', 'make', 'model', 'exceedingly', 'efficient', 'training', 'adaptable', 'wide', 'range', 'multiview', 'image', 'dataset', 'empirical', 'result', 'underscore', 'remarkable', 'fidelity', 'handle', 'various', 'input', 'span', 'realworld', 'image', 'synthetic', 'creation', 'render', 'image', 'feature', 'diverse', 'subject', 'distinct', 'texture', 'stand', 'stateoftheart', 'solution', 'singleimageto3d', 'reconstruction', 'compare', 'one2345', 'summary', 'groundbreaking', 'work', 'demonstrate', 'potential', 'swiftly', 'predict', '3d', 'model', 'object', 'single', 'arbitrary', 'image', 'find', 'wild', 'development', 'open', 'broad', 'array', 'realworld', 'application', 'benefit', 'rapid', 'accurate', '3d', 'reconstruction', 'capability', 'video', 'demos', 'interactable', '3d', 'mesh', 'find', 'website', 'https', 'yiconghongmelrm', 'paper', 'lrm', 'large', 'reconstruction', 'model', 'single', 'image', '3d', 'arxiv', 'author', 'hecate', 'editor', 'chain', 'know', 'want', 'miss', 'news', 'research', 'breakthrough', 'subscribe', 'popular', 'newsletter', 'sync', 'global', 'ai', 'weekly', 'get', 'weekly', 'update']"
Google’s E3 TTS Provides Effortless Approach to High-Quality Audio Synthesis Through Diffusion Models,https://syncedreview.com/2023/11/06/googles-e3-tts-provides-effortless-approach-to-high-quality-audio-synthesis-through-diffusion-models/,2023-11-06,"
In a new paper E3 TTS: Easy End-to-End Diffusion-based Text to Speech, a Google research team proposes Easy End-to-End Diffusion-based Text to Speech. This streamlined and efficient text-to-speech model hinges solely on diffusion to preserve temporal structure, allowing it to accept plain text as input and generate audio waveforms directly.
","Diffusion models have garnered significant recognition for their outstanding performance in a wide range of image and audio generation tasks. Text-to-speech (TTS) systems employing diffusion models have proven their mettle by delivering high-fidelity speech that stands on par with state-of-the-art systems. Nonetheless, many existing TTS systems face a litany of issues, such as heavy reliance on intermediate features’ quality and complex deployment, training, and setup procedures. In a new paper E3 TTS: Easy End-to-End Diffusion-based Text to Speech, a Google research team proposes Easy End-to-End Diffusion-based Text to Speech. This streamlined and efficient text-to-speech model hinges solely on diffusion to preserve temporal structure, allowing it to accept plain text as input and generate audio waveforms directly. The E3 TTS model takes text as input and operates in a non-autoregressive manner, producing waveform outputs without delay. The architecture consists of two primary modules: In a tangible sense, the E3 TTS leverages recent advancements in large language models. It relies on text representations provided by a pretrained BERT model. Unlike some prior approaches, which require representations like phonemes or graphemes, the E3 TTS simplifies the process by depending solely on a pretrained text language model. This model can be trained on multiple languages using only text data, which streamlines the system’s versatility. The U-Net structure encompasses a sequence of downsampling and upsampling blocks linked by residuals. To enhance information extraction from the BERT output, the team incorporates crossattention in the top downsampling/upsampling blocks. In the lower blocks, an adaptive softmax Convolutional Neural Network (CNN) kernel is employed, with its kernel size determined by the timestep and speaker. In other layers, speaker and timestep embeddings are combined through Feature-wise Linear Modulation (FiLM), which includes a composite layer for channel-wise scaling and bias prediction. The downsampler plays a crucial role in refining the noisy information, converting it from 24kHz to a sequence of similar length to the encoded BERT output, which significantly improves the overall quality. On the flip side, the upsampler predicts noise with the same length as the input waveform. Empirical evidence demonstrates that E3 TTS can generate high-fidelity audio, approaching the performance of state-of-the-art neural TTS systems. Furthermore, it enables various zero-shot tasks, such as speech editing and prompt-based generation. In summary, this work underscores the remarkable capabilities of E3 TTS in generating high-quality audio directly from BERT features. It simplifies the design of end-to-end TTS systems and has proven to deliver impressive results in experiments. Audio samples are available at https://e3tts.github.io. The paper E3 TTS: Easy End-to-End Diffusion-based Text to Speech on arXiv. Author: Hecate He | Editor: Chain Zhang We know you don’t want to miss any news or research breakthroughs. Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates.","Diffusion models have garnered significant recognition for their outstanding performance in a wide range of image and audio generation tasks . Text-to-speech ( TTS ) systems employing diffusion models have proven their mettle by delivering high-fidelity speech that stands on par with state-of-the-art systems . Nonetheless , many existing TTS systems face a litany of issues , such as heavy reliance on intermediate features ’ quality and complex deployment , training , and setup procedures . In a new paper E3 TTS : Easy End-to-End Diffusion-based Text to Speech , a Google research team proposes Easy End-to-End Diffusion-based Text to Speech . This streamlined and efficient text-to-speech model hinges solely on diffusion to preserve temporal structure , allowing it to accept plain text as input and generate audio waveforms directly . The E3 TTS model takes text as input and operates in a non-autoregressive manner , producing waveform outputs without delay . The architecture consists of two primary modules : In a tangible sense , the E3 TTS leverages recent advancements in large language models . It relies on text representations provided by a pretrained BERT model . Unlike some prior approaches , which require representations like phonemes or graphemes , the E3 TTS simplifies the process by depending solely on a pretrained text language model . This model can be trained on multiple languages using only text data , which streamlines the system ’ s versatility . The U-Net structure encompasses a sequence of downsampling and upsampling blocks linked by residuals . To enhance information extraction from the BERT output , the team incorporates crossattention in the top downsampling/upsampling blocks . In the lower blocks , an adaptive softmax Convolutional Neural Network ( CNN ) kernel is employed , with its kernel size determined by the timestep and speaker . In other layers , speaker and timestep embeddings are combined through Feature-wise Linear Modulation ( FiLM ) , which includes a composite layer for channel-wise scaling and bias prediction . The downsampler plays a crucial role in refining the noisy information , converting it from 24kHz to a sequence of similar length to the encoded BERT output , which significantly improves the overall quality . On the flip side , the upsampler predicts noise with the same length as the input waveform . Empirical evidence demonstrates that E3 TTS can generate high-fidelity audio , approaching the performance of state-of-the-art neural TTS systems . Furthermore , it enables various zero-shot tasks , such as speech editing and prompt-based generation . In summary , this work underscores the remarkable capabilities of E3 TTS in generating high-quality audio directly from BERT features . It simplifies the design of end-to-end TTS systems and has proven to deliver impressive results in experiments . Audio samples are available at https : //e3tts.github.io . The paper E3 TTS : Easy End-to-End Diffusion-based Text to Speech on arXiv . Author : Hecate He | Editor : Chain Zhang We know you don ’ t want to miss any news or research breakthroughs . Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates .","['diffusion', 'model', 'garner', 'significant', 'recognition', 'outstanding', 'performance', 'wide', 'range', 'image', 'audio', 'generation', 'task', 'system', 'employ', 'diffusion', 'model', 'prove', 'mettle', 'deliver', 'highfidelity', 'speech', 'stand', 'par', 'stateoftheart', 'system', 'nonetheless', 'many', 'exist', 'tts', 'system', 'face', 'litany', 'issue', 'heavy', 'reliance', 'intermediate', 'feature', 'quality', 'complex', 'deployment', 'training', 'setup', 'procedure', 'new', 'paper', 'tts', 'easy', 'endtoend', 'diffusionbase', 'text', 'speech', 'research', 'team', 'propose', 'easy', 'endtoend', 'diffusionbase', 'text', 'speech', 'streamlined', 'efficient', 'texttospeech', 'model', 'hinge', 'solely', 'diffusion', 'preserve', 'temporal', 'structure', 'allow', 'accept', 'plain', 'text', 'input', 'generate', 'audio', 'waveform', 'directly', 'tts', 'model', 'take', 'text', 'input', 'operate', 'nonautoregressive', 'manner', 'produce', 'waveform', 'output', 'delay', 'architecture', 'consist', 'primary', 'module', 'tangible', 'sense', 'tts', 'leverage', 'recent', 'advancement', 'large', 'language', 'model', 'rely', 'text', 'representation', 'provide', 'pretraine', 'model', 'prior', 'approach', 'require', 'representation', 'phoneme', 'grapheme', 'tts', 'simplifie', 'process', 'depend', 'solely', 'pretraine', 'text', 'language', 'model', 'model', 'train', 'multiple', 'language', 'use', 'text', 'datum', 'streamline', 'system', 'versatility', 'unet', 'structure', 'encompass', 'sequence', 'downsampling', 'upsampling', 'block', 'link', 'residual', 'enhance', 'information', 'extraction', 'output', 'team', 'incorporate', 'crossattention', 'top', 'downsamplingupsample', 'block', 'low', 'block', 'adaptive', 'softmax', 'convolutional', 'neural', 'network', 'kernel', 'employ', 'kernel', 'size', 'determine', 'timestep', 'speaker', 'layer', 'speaker', 'timestep', 'embedding', 'combine', 'featurewise', 'linear', 'modulation', 'film', 'include', 'composite', 'layer', 'channelwise', 'scaling', 'bias', 'prediction', 'downsampler', 'play', 'crucial', 'role', 'refine', 'noisy', 'information', 'convert', '24khz', 'sequence', 'similar', 'length', 'encoded', 'bert', 'output', 'significantly', 'improve', 'overall', 'quality', 'flip', 'side', 'upsampler', 'predict', 'noise', 'length', 'input', 'waveform', 'empirical', 'evidence', 'demonstrate', 'tts', 'generate', 'highfidelity', 'audio', 'approach', 'performance', 'stateoftheart', 'neural', 'system', 'furthermore', 'enable', 'various', 'zeroshot', 'task', 'speech', 'editing', 'promptbase', 'generation', 'summary', 'work', 'underscore', 'remarkable', 'capability', 'tt', 'generate', 'highquality', 'audio', 'directly', 'feature', 'simplify', 'design', 'endtoend', 'system', 'prove', 'deliver', 'impressive', 'result', 'experiment', 'audio', 'sample', 'available', 'paper', 'tts', 'easy', 'endtoend', 'diffusionbase', 'text', 'speech', 'arxiv', 'author', 'hecate', 'editor', 'chain', 'know', 'want', 'miss', 'news', 'research', 'breakthrough', 'subscribe', 'popular', 'newsletter', 'sync', 'global', 'ai', 'weekly', 'get', 'weekly', 'update']"
Apple Repurposes Large Language Models for Reinforcement Learning challenges in Embodied AI,https://syncedreview.com/2023/11/01/apple-repurposes-large-language-models-for-reinforcement-learning-challenges-in-embodied-ai/,2023-11-01,"
An Apple research team presents Large LAnguage model Reinforcement Learning Policy (LLaRP). LLaRP effectively repurposes LLMs for Reinforcement Learning (RL) challenges within the realm of Embodied Artificial Intelligence (AI), achieving a remarkable 1.7 times higher success rate compared to other established baselines and zero-shot LLM applications.
","Large Language Models (LLMs) have ushered in an era of unparalleled language understanding capabilities, raising the possibility of harnessing their prowess for complex embodied visual tasks. This new frontier explores whether these models can be the cornerstone of adaptable, generalizable policies for decision-making that seamlessly transfer to novel scenarios. In a new paper Large Language Models as Generalizable Policies for Embodied Tasks, an Apple research team presents Large LAnguage model Reinforcement Learning Policy (LLaRP). LLaRP effectively repurposes LLMs for Reinforcement Learning (RL) challenges within the realm of Embodied Artificial Intelligence (AI), achieving a remarkable 1.7 times higher success rate compared to other established baselines and zero-shot LLM applications. The LLaRP approach is a pioneering effort in adapting pre-trained LLMs to navigate multi-modal decision-making settings inherent to embodied tasks. The core of the problem is cast as a Partially-Observable Markov Decision Process (POMDP), wherein the policy’s inputs encompass task instructions and egocentric visual RGB frames from the current time step. These inputs are encoded using LLM embeddings or a vision encoder. These embeddings serve as the input to a pre-trained LLM, and the hidden outputs are subsequently projected to action and value predictions. Notably, the entire system learns through online RL, with the action output module and observation encoder MLP being the only trainable components while the others remain frozen. The research team demonstrates that using a pre-trained and frozen LLM as a Vision-Language Model (VLM) policy with learned input and output adapter layers results in a policy showcasing robust generalization capabilities. This policy is trained using online RL, and its generalization is assessed along two axes: Paraphrastic Robustness (PR) and Behavior Generalization (BG). LLaRP undergoes rigorous evaluation across over 1,000 unseen tasks, spanning the axes of PR and BG, and achieves an impressive 42% success rate. This surpasses the performance of alternative LSTM-based policies at 25% and zero-shot LLM applications at 22%. Importantly, LLaRP outperforms all baselines when given novel instructions and when assigned previously unseen tasks. Moreover, the researchers demonstrate that the LLaRP LLM-based policy provides a significant performance boost in a distinct domain, Atari, compared to a Transformer baseline. The research team further uncovers the benefits of infusing LLM-encoded world knowledge into RL. LLM-based models exhibit superior sample efficiency compared to other conventional architectures in both basic Proximal Policy Optimization (PPO) RL and continual learning settings. Furthermore, LLaRP proves to be more efficient in terms of required supervision when contrasted with commonly used imitation learning techniques. In a promising initiative to facilitate further exploration of generalization in Embodied AI, the researchers introduce the Language Rearrangement task. This task involves a staggering 150,000 distinct language instructions, each equipped with automatically generated rewards, providing a valuable framework for ongoing research in the field. In conclusion, this pioneering research paper exemplifies the transformative potential of integrating LLMs into embodied tasks. The LLaRP approach not only excels in achieving high success rates but also significantly enhances efficiency, opening up exciting possibilities for the future of Embodied AI research and development. Video examples of LLaRP in unseen Language Rearrangement instructions are at https://llm-rl.github.io. The paper Large Language Models as Generalizable Policies for Embodied Tasks on arXiv. Author: Hecate He | Editor: Chain Zhang We know you don’t want to miss any news or research breakthroughs. Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates.","Large Language Models ( LLMs ) have ushered in an era of unparalleled language understanding capabilities , raising the possibility of harnessing their prowess for complex embodied visual tasks . This new frontier explores whether these models can be the cornerstone of adaptable , generalizable policies for decision-making that seamlessly transfer to novel scenarios . In a new paper Large Language Models as Generalizable Policies for Embodied Tasks , an Apple research team presents Large LAnguage model Reinforcement Learning Policy ( LLaRP ) . LLaRP effectively repurposes LLMs for Reinforcement Learning ( RL ) challenges within the realm of Embodied Artificial Intelligence ( AI ) , achieving a remarkable 1.7 times higher success rate compared to other established baselines and zero-shot LLM applications . The LLaRP approach is a pioneering effort in adapting pre-trained LLMs to navigate multi-modal decision-making settings inherent to embodied tasks . The core of the problem is cast as a Partially-Observable Markov Decision Process ( POMDP ) , wherein the policy ’ s inputs encompass task instructions and egocentric visual RGB frames from the current time step . These inputs are encoded using LLM embeddings or a vision encoder . These embeddings serve as the input to a pre-trained LLM , and the hidden outputs are subsequently projected to action and value predictions . Notably , the entire system learns through online RL , with the action output module and observation encoder MLP being the only trainable components while the others remain frozen . The research team demonstrates that using a pre-trained and frozen LLM as a Vision-Language Model ( VLM ) policy with learned input and output adapter layers results in a policy showcasing robust generalization capabilities . This policy is trained using online RL , and its generalization is assessed along two axes : Paraphrastic Robustness ( PR ) and Behavior Generalization ( BG ) . LLaRP undergoes rigorous evaluation across over 1,000 unseen tasks , spanning the axes of PR and BG , and achieves an impressive 42 % success rate . This surpasses the performance of alternative LSTM-based policies at 25 % and zero-shot LLM applications at 22 % . Importantly , LLaRP outperforms all baselines when given novel instructions and when assigned previously unseen tasks . Moreover , the researchers demonstrate that the LLaRP LLM-based policy provides a significant performance boost in a distinct domain , Atari , compared to a Transformer baseline . The research team further uncovers the benefits of infusing LLM-encoded world knowledge into RL . LLM-based models exhibit superior sample efficiency compared to other conventional architectures in both basic Proximal Policy Optimization ( PPO ) RL and continual learning settings . Furthermore , LLaRP proves to be more efficient in terms of required supervision when contrasted with commonly used imitation learning techniques . In a promising initiative to facilitate further exploration of generalization in Embodied AI , the researchers introduce the Language Rearrangement task . This task involves a staggering 150,000 distinct language instructions , each equipped with automatically generated rewards , providing a valuable framework for ongoing research in the field . In conclusion , this pioneering research paper exemplifies the transformative potential of integrating LLMs into embodied tasks . The LLaRP approach not only excels in achieving high success rates but also significantly enhances efficiency , opening up exciting possibilities for the future of Embodied AI research and development . Video examples of LLaRP in unseen Language Rearrangement instructions are at https : //llm-rl.github.io . The paper Large Language Models as Generalizable Policies for Embodied Tasks on arXiv . Author : Hecate He | Editor : Chain Zhang We know you don ’ t want to miss any news or research breakthroughs . Subscribe to our popular newsletter Synced Global AI Weekly to get weekly AI updates .","['large', 'language', 'model', 'llm', 'usher', 'era', 'unparalleled', 'language', 'understand', 'capability', 'raise', 'possibility', 'harness', 'prowess', 'complex', 'embody', 'visual', 'task', 'new', 'frontier', 'explore', 'model', 'cornerstone', 'adaptable', 'generalizable', 'policy', 'decisionmake', 'seamlessly', 'transfer', 'novel', 'scenario', 'new', 'paper', 'large', 'language', 'model', 'generalizable', 'policy', 'embody', 'task', 'apple', 'research', 'team', 'present', 'large', 'language', 'model', 'reinforcement', 'learning', 'policy', 'llarp', 'llarp', 'effectively', 'repurpose', 'llm', 'reinforcement', 'learning', 'rl', 'challenge', 'realm', 'embody', 'artificial', 'intelligence', 'achieve', 'remarkable', 'time', 'high', 'success', 'rate', 'compare', 'establish', 'baseline', 'zeroshot', 'llm', 'application', 'llarp', 'approach', 'pioneering', 'effort', 'adapt', 'pretraine', 'llm', 'navigate', 'multimodal', 'decisionmake', 'setting', 'inherent', 'embody', 'task', 'core', 'problem', 'cast', 'partiallyobservable', 'markov', 'decision', 'process', 'pomdp', 'policy', 'input', 'encompass', 'task', 'instruction', 'egocentric', 'visual', 'frame', 'current', 'time', 'step', 'input', 'encode', 'use', 'llm', 'embedding', 'vision', 'encoder', 'embedding', 'serve', 'input', 'pretrained', 'llm', 'hidden', 'output', 'subsequently', 'project', 'action', 'value', 'prediction', 'notably', 'entire', 'system', 'learn', 'rl', 'action', 'output', 'module', 'observation', 'encoder', 'mlp', 'trainable', 'component', 'remain', 'frozen', 'research', 'team', 'demonstrate', 'use', 'pretraine', 'frozen', 'llm', 'visionlanguage', 'model', 'policy', 'learn', 'input', 'output', 'adapter', 'layer', 'result', 'policy', 'showcasing', 'robust', 'generalization', 'capability', 'policy', 'train', 'use', 'online', 'rl', 'generalization', 'assess', 'axis', 'paraphrastic', 'robustness', 'behavior', 'bg', 'rigorous', 'evaluation', 'unseen', 'task', 'span', 'axis', 'achieve', 'impressive', 'success', 'rate', 'surpass', 'performance', 'alternative', 'lstmbased', 'policy', 'zeroshot', 'llm', 'application', 'importantly', 'llarp', 'outperform', 'baseline', 'give', 'novel', 'instruction', 'assign', 'previously', 'unseen', 'task', 'moreover', 'researcher', 'demonstrate', 'llarp', 'llmbase', 'policy', 'provide', 'significant', 'performance', 'boost', 'distinct', 'domain', 'atari', 'compare', 'transformer', 'baseline', 'research', 'team', 'uncover', 'benefit', 'infuse', 'llmencoded', 'world', 'knowledge', 'llmbase', 'model', 'exhibit', 'superior', 'sample', 'efficiency', 'compare', 'conventional', 'architecture', 'basic', 'proximal', 'policy', 'optimization', 'ppo', 'continual', 'learning', 'setting', 'furthermore', 'llarp', 'prove', 'efficient', 'term', 'require', 'supervision', 'contrast', 'commonly', 'use', 'imitation', 'learn', 'technique', 'promising', 'initiative', 'facilitate', 'exploration', 'generalization', 'embody', 'ai', 'researcher', 'introduce', 'language', 'rearrangement', 'task', 'task', 'involve', 'staggering', 'distinct', 'language', 'instruction', 'equip', 'automatically', 'generate', 'reward', 'provide', 'valuable', 'framework', 'ongoing', 'research', 'field', 'conclusion', 'pioneer', 'research', 'paper', 'exemplify', 'transformative', 'potential', 'integrate', 'llm', 'embody', 'task', 'llarp', 'approach', 'excel', 'achieve', 'high', 'success', 'rate', 'also', 'significantly', 'enhance', 'efficiency', 'opening', 'exciting', 'possibility', 'future', 'embody', 'ai', 'research', 'development', 'video', 'example', 'llarp', 'unseen', 'language', 'rearrangement', 'instruction', 'https', 'llmrlgithubio', 'paper', 'large', 'language', 'model', 'generalizable', 'policy', 'embody', 'task', 'arxiv', 'author', 'hecate', 'editor', 'chain', 'know', 'want', 'miss', 'news', 'research', 'breakthrough', 'subscribe', 'popular', 'newsletter', 'sync', 'global', 'ai', 'weekly', 'get', 'weekly', 'update']"
